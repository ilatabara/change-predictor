id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fmurano-dashboard~master~If78e9c6525d1c1e07c99d94a297f0e201d70bc38,openstack/murano-dashboard,master,If78e9c6525d1c1e07c99d94a297f0e201d70bc38,Updated from global requirements,MERGED,2014-12-14 05:17:03.000000000,2014-12-15 16:07:04.000000000,2014-12-15 16:07:04.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-14 05:17:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a70cc96710588d24d1aa8fc9288b2fc088467cc9', 'message': 'Updated from global requirements\n\nChange-Id: If78e9c6525d1c1e07c99d94a297f0e201d70bc38\n'}, {'number': 2, 'created': '2014-12-14 05:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/b04901ece51a3206db4ffa8bc4f8775e726cac40', 'message': 'Updated from global requirements\n\nChange-Id: If78e9c6525d1c1e07c99d94a297f0e201d70bc38\n'}, {'number': 3, 'created': '2014-12-15 10:51:24.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'setup.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5f006b2eb710602007855879c78e8184a6a03746', 'message': 'Updated from global requirements\n\nChange-Id: If78e9c6525d1c1e07c99d94a297f0e201d70bc38\n'}]",0,141622,5f006b2eb710602007855879c78e8184a6a03746,16,4,3,7600,,,0,"Updated from global requirements

Change-Id: If78e9c6525d1c1e07c99d94a297f0e201d70bc38
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/22/141622/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'setup.py']",2,a70cc96710588d24d1aa8fc9288b2fc088467cc9,update-requirements,"# In python < 2.7.4, a lazy loading of package `pbr` will break # setuptools if some other modules registered functions in `atexit`. # solution from: http://bugs.python.org/issue15881#msg170215 try: import multiprocessing # noqa except ImportError: pass ",,16,6
openstack%2Fneutron-specs~master~I2e12aae1080bf59998a20f1294515da27adc9a04,openstack/neutron-specs,master,I2e12aae1080bf59998a20f1294515da27adc9a04,Remove trailing whitespace.,MERGED,2014-12-15 14:18:34.000000000,2014-12-15 16:05:23.000000000,2014-12-15 16:05:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}]","[{'number': 1, 'created': '2014-12-15 14:18:34.000000000', 'files': ['specs/kilo/lbaas-tls.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f0698d6dd592e25a1e89ae09df9601efd88c512c', 'message': 'Remove trailing whitespace.\n\nA later commit introduces a test case that fails on trailing\nwhitespace.  This spec went in recently with trailing whitespace, so\nfix it up so the tests will pass.\n\nChange-Id: I2e12aae1080bf59998a20f1294515da27adc9a04\n'}]",0,141810,f0698d6dd592e25a1e89ae09df9601efd88c512c,6,2,1,1561,,,0,"Remove trailing whitespace.

A later commit introduces a test case that fails on trailing
whitespace.  This spec went in recently with trailing whitespace, so
fix it up so the tests will pass.

Change-Id: I2e12aae1080bf59998a20f1294515da27adc9a04
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/10/141810/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/lbaas-tls.rst'],1,f0698d6dd592e25a1e89ae09df9601efd88c512c,bp/aims, reason of a failure in case of an invalid configuration. for a listener while it's still in use by this listener., reason of a failure in case of an invalid configuration. for a listener while it's still in use by this listener. ,2,2
openstack%2Fmurano~stable%2Fjuno~Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1,openstack/murano,stable/juno,Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1,Fix method lock release upon exception,MERGED,2014-11-19 14:28:25.000000000,2014-12-15 16:03:15.000000000,2014-12-15 16:03:14.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-19 14:28:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/03a35ceb98d4af9d8e4057aa48284a0804c49f46', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}, {'number': 2, 'created': '2014-11-19 20:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f4c55f72d8a60215ad9c49a314382e7528f79879', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block.\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}, {'number': 3, 'created': '2014-11-20 15:50:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/16e49855b7c29b1c3545f9c3ea5ced2715791df4', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}, {'number': 4, 'created': '2014-11-21 07:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c9a6c4f45a7ee33df2e1d9f236dfa153562c474f', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block.\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}, {'number': 5, 'created': '2014-12-12 13:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f1ecb15dac4492d9e62253511ea3711c561e9fed', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}, {'number': 6, 'created': '2014-12-12 18:40:49.000000000', 'files': ['murano/dsl/executor.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/c6712f8cc815fd998371c9ac10f2bdb1e0e5432e', 'message': 'Fix method lock release upon exception\n\nMethod lock was not released if method execution was ended\nwith uncaught exception. As a result dead lock could occur.\nThis commit moves lock release code into finally block\n\nChange-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1\nCloses-Bug: #1392102\n(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)\n'}]",0,135608,c6712f8cc815fd998371c9ac10f2bdb1e0e5432e,39,5,6,7226,,,0,"Fix method lock release upon exception

Method lock was not released if method execution was ended
with uncaught exception. As a result dead lock could occur.
This commit moves lock release code into finally block

Change-Id: Ie5794c55c9d5a30cd3255ac06e9af944eb732bb1
Closes-Bug: #1392102
(cherry picked from commit 5cc02804902b78a83d2ee3a5698f4807a13ebde6)
",git fetch https://review.opendev.org/openstack/murano refs/changes/08/135608/4 && git format-patch -1 --stdout FETCH_HEAD,['murano/dsl/executor.py'],1,03a35ceb98d4af9d8e4057aa48284a0804c49f46,," try: gt = eventlet.spawn(self._invoke_method_implementation_gt, body, this, params, murano_class, context, thread_marker) result = gt.wait() except Exception as e: LOG.debug( ""{0}: End execution: {1} with exception {2}"".format( thread_marker, method_info, e)) raise else: LOG.debug( ""{0}: End execution: {1}"".format(thread_marker, method_info)) finally: del self._locks[(method_id, this_id)] event.send() "," gt = eventlet.spawn(self._invoke_method_implementation_gt, body, this, params, murano_class, context, thread_marker) result = gt.wait() del self._locks[(method_id, this_id)] LOG.debug( ""{0}: End execution: {1}"".format(thread_marker, method_info)) event.send()",17,8
openstack%2Fpython-glanceclient~master~I4733578adfc70bd57afd5f0d4d361c8ef689a381,openstack/python-glanceclient,master,I4733578adfc70bd57afd5f0d4d361c8ef689a381,Output clear error message on invalid api version,MERGED,2014-12-10 18:22:31.000000000,2014-12-15 15:55:59.000000000,2014-12-15 15:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 8127}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-10 18:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/f5fe725e68acfc5496a58a748decf59d87a2780d', 'message': ""Fix invalid handling of incorrect image api version\n\nNow if --os-image-api-version mistakenly contains a string then\nyou will get a ValueError\n\nExample:\n$ glance --os-image-api-version hui\nValueError: invalid literal for int() with base 10: 'hui'\n\nThis code correctly handles this situation, prints a warning\nmessage and interrupts the execution of the client\n\nChange-Id: I4733578adfc70bd57afd5f0d4d361c8ef689a381\nCloses-bug: 1401197\n""}, {'number': 2, 'created': '2014-12-10 18:39:29.000000000', 'files': ['glanceclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/8e8dde2052148fea0135a19ad229da7114738024', 'message': ""Output clear error message on invalid api version\n\nNow if --os-image-api-version mistakenly contains a string then\nyou will get a ValueError\n\nExample:\n$ glance --os-image-api-version hui\nValueError: invalid literal for int() with base 10: 'hui'\n\nThis code correctly handles this situation, prints a warning\nmessage and interrupts the execution of the client\n\nChange-Id: I4733578adfc70bd57afd5f0d4d361c8ef689a381\nCloses-bug: 1401197\n""}]",0,140794,8e8dde2052148fea0135a19ad229da7114738024,9,4,2,11391,,,0,"Output clear error message on invalid api version

Now if --os-image-api-version mistakenly contains a string then
you will get a ValueError

Example:
$ glance --os-image-api-version hui
ValueError: invalid literal for int() with base 10: 'hui'

This code correctly handles this situation, prints a warning
message and interrupts the execution of the client

Change-Id: I4733578adfc70bd57afd5f0d4d361c8ef689a381
Closes-bug: 1401197
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/94/140794/2 && git format-patch -1 --stdout FETCH_HEAD,['glanceclient/shell.py'],1,f5fe725e68acfc5496a58a748decf59d87a2780d,bug/1401197," try: api_version = int(options.os_image_api_version or url_version or 1) except ValueError: print(""Incorrect API version parameter"") utils.exit()", api_version = int(options.os_image_api_version or url_version or 1),5,1
openstack%2Ffuel-docs~master~Ibcc473b230cedc29bf6bd4c042127295193ee340,openstack/fuel-docs,master,Ibcc473b230cedc29bf6bd4c042127295193ee340,Next steps to do after deploying the environment,MERGED,2014-11-21 05:07:25.000000000,2014-12-15 15:49:47.000000000,2014-12-15 15:49:45.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 12866}, {'_account_id': 13082}, {'_account_id': 13335}]","[{'number': 1, 'created': '2014-11-21 05:07:25.000000000', 'files': ['contents/contents-user.rst', 'pages/user-guide/6000-next-steps.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/19b7b9a1a1567990edaac48272ed87b3a27f224b', 'message': 'Next steps to do after deploying the environment\n\nThis is a quick list of steps to take after one deploys\nthe environment.\n\nList recommended tasks to do after deploying the environment\nto verify that it is good and then to begin managing the\nenvironment.\n\nChange-Id: Ibcc473b230cedc29bf6bd4c042127295193ee340\nCloses-Bug: 1370196\n'}]",0,136235,19b7b9a1a1567990edaac48272ed87b3a27f224b,12,9,1,10014,,,0,"Next steps to do after deploying the environment

This is a quick list of steps to take after one deploys
the environment.

List recommended tasks to do after deploying the environment
to verify that it is good and then to begin managing the
environment.

Change-Id: Ibcc473b230cedc29bf6bd4c042127295193ee340
Closes-Bug: 1370196
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/35/136235/1 && git format-patch -1 --stdout FETCH_HEAD,"['contents/contents-user.rst', 'pages/user-guide/6000-next-steps.rst']",2,19b7b9a1a1567990edaac48272ed87b3a27f224b,bug/1370196," .. next-steps-ug: Next Steps ========== After you successfully deploy your OpenStack environment, you should do the following: - Set up :ref:`shell access<shell-ops>` to the Fuel Master and target nodes. You will need to use some shell commands to manage your environment. - Run some tests to ensure that the deployed environment is sound: - Run :ref:`Verify Networks<verify-networks-ug>`. Even though you ran this before you deployed the environment, it is wise to run it again on the deployed network. `Network Troubleshooting <http://docs.openstack.org/openstack-ops/content/network_troubleshooting.html>`_ may be useful. - Run the :ref:`Post-Deployment Check<Post-Deployment-Check-run>` tests, including the ""Additional Checks"" listed. - Run the Post-Deployment checks for other services if you included them in your environment: - :ref:`Sahara<sahara_test_prepare>` - :ref:`Murano<murano-test-prepare>` - Check other components: - If you implemented Ceph as your storage back-end, follow the `Verifying the deployment <https://github.com/stackforge/fuel-library/tree/master/deployment/puppet/ceph>`_ instructions to check the deployment. If you find problems, `Troubleshooting Ceph <http://docs.ceph.com/docs/v0.80.5/radosgw/troubleshooting/>`_ may help you resolve them. - Run a :ref:`backup<Backup_and_restore_Fuel_Master>` and store the backup in an appropriate location. - Manage your environment using the Horizon dashboard (click on the link on your Fuel Dashboard) and command-line tools: - For more information about using the Horizon dashboard, see the `OpenStack User Guide <http://docs.openstack.org/user-guide/content/log_in_dashboard.html>`_. - Create projects/tenants and users; `Managing Projects and Users <http://docs.openstack.org/openstack-ops/content/projects_users.html>`_. - If you deployed an OpenStack environment that is integrated with the vCenter server, see :ref:`vcenter-operate` for information about managing the environment. ",,61,0
openstack%2Fdesignate~master~I9bfd9081160f31272353a11d31cdb96cba513462,openstack/designate,master,I9bfd9081160f31272353a11d31cdb96cba513462,Add Werkzeug>=0.7 to requirements.txt,MERGED,2014-12-09 16:29:09.000000000,2014-12-15 15:44:40.000000000,2014-12-15 15:44:39.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8094}, {'_account_id': 8099}]","[{'number': 1, 'created': '2014-12-09 16:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c5caa4db39f79e225a20de8744fb21034f99ce27', 'message': 'Add Add Werkzeug>=0.7 to requirements.txt\n\nWerkzeug>=0.7 is a direct dependency of Designate, and a transitive\ndependency of the Flask WSGI framework used by Designate.\n\nAdditionally, correct pip-missing-reqs deps in tox.ini\n\nChange-Id: I9bfd9081160f31272353a11d31cdb96cba513462\n'}, {'number': 2, 'created': '2014-12-09 16:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/f212f51240b0cfd4d50d3438829a2dc9ab77222c', 'message': 'Add Werkzeug>=0.7 to requirements.txt\n\nWerkzeug>=0.7 is a direct dependency of Designate, and a transitive\ndependency of the Flask WSGI framework used by Designate.\n\nAdditionally, correct pip-missing-reqs deps in tox.ini\n\nChange-Id: I9bfd9081160f31272353a11d31cdb96cba513462\n'}, {'number': 3, 'created': '2014-12-12 10:10:03.000000000', 'files': ['requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/designate/commit/784de71a630d89467d1a087cf923b67e40279e4e', 'message': 'Add Werkzeug>=0.7 to requirements.txt\n\nWerkzeug>=0.7 is a direct dependency of Designate, and a transitive\ndependency of the Flask WSGI framework used by Designate.\n\nAdditionally, correct pip-missing-reqs deps in tox.ini\n\nChange-Id: I9bfd9081160f31272353a11d31cdb96cba513462\n'}]",0,140394,784de71a630d89467d1a087cf923b67e40279e4e,15,4,3,741,,,0,"Add Werkzeug>=0.7 to requirements.txt

Werkzeug>=0.7 is a direct dependency of Designate, and a transitive
dependency of the Flask WSGI framework used by Designate.

Additionally, correct pip-missing-reqs deps in tox.ini

Change-Id: I9bfd9081160f31272353a11d31cdb96cba513462
",git fetch https://review.opendev.org/openstack/designate refs/changes/94/140394/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'tox.ini']",2,c5caa4db39f79e225a20de8744fb21034f99ce27,140394, -r{toxinidir}/requirements.txt, -rrequirements.txt,2,1
openstack%2Ffuel-docs~master~I198ca2e73ded7551ac1e62ba58bf52e41612a073,openstack/fuel-docs,master,I198ca2e73ded7551ac1e62ba58bf52e41612a073,Improve wording around PXE booting nodes,MERGED,2014-10-27 11:31:17.000000000,2014-12-15 15:44:00.000000000,2014-12-15 15:44:00.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8411}, {'_account_id': 8787}, {'_account_id': 8967}, {'_account_id': 8971}, {'_account_id': 10014}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-10-27 11:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e4e8a7d29d9039d545b29bdc983c56f35395bcb9', 'message': 'Improve wording around PXE booting nodes\n\nThis commit includes some minor changes in\nwording regarding PXE booting, specificically\nreminding the reader to consider which network\nthe node will PXE boot from.\n\nChange-Id: I198ca2e73ded7551ac1e62ba58bf52e41612a073\nCloses-Bug: 1382259\n'}, {'number': 2, 'created': '2014-11-19 06:21:23.000000000', 'files': ['pages/user-guide/initialize-fuel/0600-boot-nodes.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/289583df6d9b2846dbcd0be810035ed68b8c0354', 'message': 'Improve wording around PXE booting nodes\n\nThis commit includes some minor changes in\nwording regarding PXE booting, specificically\nreminding the reader to consider which network\nthe node will PXE boot from.\n\nChange-Id: I198ca2e73ded7551ac1e62ba58bf52e41612a073\nCloses-Bug: 1382259\n'}]",0,131088,289583df6d9b2846dbcd0be810035ed68b8c0354,17,8,2,9788,,,0,"Improve wording around PXE booting nodes

This commit includes some minor changes in
wording regarding PXE booting, specificically
reminding the reader to consider which network
the node will PXE boot from.

Change-Id: I198ca2e73ded7551ac1e62ba58bf52e41612a073
Closes-Bug: 1382259
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/88/131088/2 && git format-patch -1 --stdout FETCH_HEAD,['pages/user-guide/initialize-fuel/0600-boot-nodes.rst'],1,e4e8a7d29d9039d545b29bdc983c56f35395bcb9,bug/1382259,"After the Fuel Master Node is installed and booted, power on all slave nodes that you are going to use for the OpenStack environment. First, ensure that servers are physically connected to the same network as the Master node or, if you are using virtual servers, are bridged to it so they are in the same L2 network segment. Then you can boot each node (other than the Fuel master) via PXE by either modifying the BIOS boot order or pressing the appropriate key to initiate a PXE boot. If your nodes have serveral network interfaces, be sure to enable PXE-boot on the interface that is on the same network you configured for PXE booting on the Fuel Master Node.Follow the instructions in :ref:`boot-fuel-master-ug` to log into the Fuel UI if you have not already done so. You will see notifications in the user interface about the discovered nodes. Find the count of ""Discovered nodes"" in the upper right area of the Fuel Web UI; this value is incremented as each new node is ready. When the count of ""Discovered nodes"" becomes equal to the amount of the servers you have booted in the network, you can create an OpenStack environment, add nodes into it, and start configuration.","After the Fuel Master Node is installed and booted, power on all slave nodes that you are going to use for the OpenStack environment. First, ensure that servers are physically installed in the same network as the Master node or, if you are using virtual servers, are bridged to it so they are in the same L2 network segment. Then you can boot each node (other than the Fuel master) in PXE boot mode by either modifying the BIOS boot order or using F12 (or another key your server uses) to enable PXE booting.Follow the instructions in :ref:`boot-fuel-master-ug` to log into the Fuel UI if you have not already done so. You will see notifications in the user interface about the discovered nodes. Find the count of ""Discovered nodes"" in the upper right area of the Fuel Web UI; this value is incremented as each new node is ready. When the count of ""Discovered nodes"" becomes equal to the amount of the servers you have booted in the network, you can create an OpenStack environment, add nodes into it, and start configuration.",21,19
openstack%2Fbarbican-specs~master~I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3,openstack/barbican-specs,master,I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3,Add spec to support running functional tests as different users,MERGED,2014-11-19 21:32:31.000000000,2014-12-15 15:40:59.000000000,2014-12-15 15:40:59.000000000,"[{'_account_id': 3}, {'_account_id': 6783}, {'_account_id': 7262}, {'_account_id': 7687}, {'_account_id': 7789}, {'_account_id': 7973}, {'_account_id': 8004}, {'_account_id': 9234}, {'_account_id': 9914}, {'_account_id': 10873}, {'_account_id': 11970}, {'_account_id': 13510}]","[{'number': 1, 'created': '2014-11-19 21:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/d7aee7c1333638126dbd9645be713bacf36de3be', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 2, 'created': '2014-11-21 15:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/8ba13f67e1f1e44fa0d4ba9f5903c834309bea11', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 3, 'created': '2014-12-04 15:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/3e24add830898950f7ddb7fc8b8df72e7428514a', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 4, 'created': '2014-12-04 15:34:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/42ad5d84a8d4f6c020bfbfdae93441ece0698895', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 5, 'created': '2014-12-04 15:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/ad58fcc9d9ee2240d8bf3bc4d49d29fb2e1b953f', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 6, 'created': '2014-12-04 16:04:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/be811f58a3f5cf146a101f7c35fe973be98cd786', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 7, 'created': '2014-12-04 20:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/827625f5ad745501a06122e04165efe807b1f0d6', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 8, 'created': '2014-12-08 20:05:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/e986f4c8f3dbea4c8f6efaaede45cddabf253186', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}, {'number': 9, 'created': '2014-12-12 20:57:47.000000000', 'files': ['specs/kilo/add-run-as-for-functional-tests.rst'], 'web_link': 'https://opendev.org/openstack/barbican-specs/commit/b835c465201a5eda835f83a37abc0e53f344ea98', 'message': 'Add spec to support running functional tests as different users\n\nThis spec details a proposal for the ability to run one (or more)\nBarbican functional tests under a userid that is different\nfrom the default.\n\nChange-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3\nImplements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests\n'}]",23,135724,b835c465201a5eda835f83a37abc0e53f344ea98,41,12,9,9234,,,0,"Add spec to support running functional tests as different users

This spec details a proposal for the ability to run one (or more)
Barbican functional tests under a userid that is different
from the default.

Change-Id: I1c5e18faf73d26c2b34b9bf59e88ab86ab24a4a3
Implements: blueprint https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests
",git fetch https://review.opendev.org/openstack/barbican-specs refs/changes/24/135724/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/add-run-as-for-functional-tests.rst'],1,d7aee7c1333638126dbd9645be713bacf36de3be,bp/https,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================================== Add ability for functional tests to run as different users ========================================================== https://blueprints.launchpad.net/barbican/+spec/add-run-as-for-functional-tests Currently all Barbican functional tests run under the same userid/tenant. This blueprint adds the ability for a Barbican functional test to run under a different userid from that default. This is needed to support the ability to execute tests in parallel and ensure that the underlying system state doesn't change as a result of other concurrently executing tests. Problem Description =================== Today all Barbican functional tests run under the same user/tenant. Since these tests run in parallel then any assumptions about the underlying system state are invalid - for example, a test for paging secrets could fail if another tests does secret operations in parallel. This was not an issue under CloudCafe as these tests were run sequentially. Proposed Change =============== The proposed change not only solves this problem, but also provides a generalized way to run tests in an isolated manner, under their own userid/tenant. The first step involves determining which test(s) need to run as a non-default user. This is done at testcase creation time, by the testcase author. Next the testcase author will use a new decorator on the testcase method to indicate that the test(s) should not be run under the default user, but rather under a new user. This decorator is used as follows:: from barbican.tests import utils from functionaltests.api import base class SomeVeryInterestingTestCase(base.TestCase): @utils.run_as() def test_something_very_interesting(self, parms) # do your test stuff here This will cause the following to happen when the testcase is run: 1. create and login a new and unique user using defaults (see below) 2. run the test 3. logout and delete the user we created above The user name, password, and tenant name are derived from settings in barbican's etc/dev_tempest.conf file. Under the [identity] section are three settings:: dynamic_user_userid_prefix=testuser_ dynamic_user_password=topsecret dynamic_user_tenant_name_prefix=testtenant_ As part of each invocation of the decorated test, the oslotest fixture setUp() code will generate a new username by concatenating the value of ""dynanic_user_userid_prefix"" with a generated UUID (to ensure that each dynamically created user is unique). The password will be used as-is, and the tenant name will also be derived by concatenating the value of ""dynamic_user_tenant_name_prefix"" with the SAME UUID as used for the userid. Upon successful user creation, that user will be logged in. Next the test itself will be run as usual. When the test completes, the oslotest fixture tearDown() code will determine if a user was created for this test. If it was then the user will be logged out and deleted. Optionally, the testcase author can provide their own userid, password and tenant name that will be used in place of the defaults. For this use case, the user is assumed to already exist. Rather than create and delete the user, the fixtures will simply login (during setUp()) or logout (during tearDown()) using the data provided to the decorator:: @utils.run_as(user_name=user_name, password=password, tenant_name=tenant_name) def test_something_very_interesting(self, parms) # do your test stuff here The components of barbican that will need to be updated to support this new function are: 1. new decorator added to barbican.test.utils called run_as that will set a field in the decorated function's __dict__ called ""run_as"" with a value of either blank (indicating use defaults) or a dict of the 3 parameters to the decorator (user_name, password, tenant_name). 2. update to functionaltests.api.base.TestCase.setUp() to query the test function's __dict__ for the presence of the ""run_as"" key. - If not present then the test runs as it does today, under the default user. - If present and its value is an empty dict then generate a new user based on the settings in etc/dev_tempest.conf. This is the user that will be logged in for this test. Save this information for the subsequent tearDown() - see below. - If present and its value is NOT empty then use the user_name, password and tenant_name to login the specified user. 3. update to functionaltests.api.base.TestCase.tearDown() to check to see if a user has been dynamically created. If so then that user will be deleted. 4. support functions in functionaltests.api.base.TestCase to talk to keystone for userid creation, login and deletion. Alternatives ------------ One alternative that was discussed was to create a new subclass (possibly called functionaltests.api.DynamicUserTestcase) for which ALL tests in the class would be processed as above (only using the defaults). We rejected that approach for several reasons: 1. It causes otherwise related tests to be separated into another class (for example GET a single secret and GET a list of secrets) 2. It doesn't have the flexibility to take an existing test and easily change it to become a test that runs under its own user. Data model impact ----------------- No data model impact. REST API impact --------------- No REST API impact. Security impact --------------- This change allows dynamic user creation and deletion on a per-testcase basis. It also allows a testcase to specify an existing user to run under. There are no changes to any API as all of these updates are focused under the functionaltests and do not affect the Barbican API. Notifications & Audit Impact ---------------------------- No notification/audit impacts for this change. Other end user impact --------------------- The test logging will show the user id that each test runs under in the test logs. They are not part of the API, but could be useful for problem determination and debugging. Performance Impact ------------------ The only performance impact of this CR is on the functionaltests path. It has no effect on the product's performance. Additional pathlength for ALL functional tests will be added to: * check the calling function's variable pool for run_as data Tests that request a different user will incur additional pathlength to: * create and login the user (before the test runs) * delete the user (after the test completes) Other deployer impact --------------------- If a tester requires an existing user be created in keystone before a test is run then that would impact deployment. However, testers using the dynamic user creation/deletion will not require any support from deployers. Developer impact ---------------- Developers adding functional tests can choose to have those tests run under a different userid, if they desire. Otherwise, all functional tests will run under the default user. A developer can choose to let the system create and delete these new users dynamically, or they can choose a pre-existing user. Both of these options are controlled by the run_as decorator. Unit tests are NOT impacted by this change. Implementation ============== Assignee(s) ----------- Primary assignee: sheyman Work Items ---------- Upon approval of this blueprint we will code and post for review the implementation of the run_as decorator as well as the supporting code in the utilities and fixtures. Dependencies ============ This function depends on keystone for the user/tenant creation and deletion API. Testing ======= This code is part of the functional testing of Barbican and will be exercised in the devstack gate as well as locally on a developer/tester machine by running ""tox -e functional"" Documentation Impact ==================== Currently there is no documentation on how to write Barbican tests (it is an open story in the Barbican work backlog). The prose in this blueprint can be used as a starting point to describe the usage of the run_as decorator. References ========== * Barbican wiki: https://wiki.openstack.org/wiki/Barbican * Barbican source code: https://github.com/openstack/barbican * Barbican functional tests: https://github.com/openstack/barbican/tree/master/functionaltests",,256,0
openstack%2Fproject-config~master~Ic89244ecbdb317501f86ee4b7347a281b13cae91,openstack/project-config,master,Ic89244ecbdb317501f86ee4b7347a281b13cae91,Introduce Oslo-specific stable-maint team,MERGED,2014-12-15 11:04:47.000000000,2014-12-15 15:33:10.000000000,2014-12-15 15:33:09.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 11:04:47.000000000', 'files': ['gerrit/acls/openstack/oslo.rootwrap.config', 'gerrit/acls/openstack/oslo.log.config', 'gerrit/acls/openstack/oslo.version.config', 'gerrit/acls/openstack/oslo.i18n.config', 'gerrit/acls/openstack/oslo.messaging.config', 'gerrit/acls/openstack/oslo.utils.config', 'gerrit/acls/openstack/oslo.serialization.config', 'gerrit/acls/openstack/oslo-incubator.config', 'gerrit/acls/openstack/oslo.db.config', 'gerrit/acls/openstack/oslo.middleware.config', 'gerrit/acls/openstack/oslo.config.config', 'gerrit/acls/openstack/oslo.concurrency.config', 'gerrit/acls/openstack/oslo.vmware.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c1b6b7f3e0848facae72652265e2d6fa2fa741d9', 'message': 'Introduce Oslo-specific stable-maint team\n\nAs discussed in Paris and subsequently discussed on the mailing-list,\nwe are switching stable branch maintenance to project-specific teams\nunder the guidance and leadership of the stable-maint-core team.\n\nSome Oslo libraries follow a ""compatible"" release cycle and therefore\nuse stable branches -- the proposed change is to create a unique\noslo-stable-maint team to review such changes. Oslo libraries which\nfollow a free release cycle (taskflow, oslosphinx, pbr...) do not use\nstable branches and therefore do not need their ACLs changed.\n\nThe oslo-stable-maint team should be owned by stable-maint-core which\nwill vet the addition of members to make sure they are aware of the\nStable Branch policy.\n\nChange-Id: Ic89244ecbdb317501f86ee4b7347a281b13cae91\n'}]",0,141769,c1b6b7f3e0848facae72652265e2d6fa2fa741d9,7,3,1,308,,,0,"Introduce Oslo-specific stable-maint team

As discussed in Paris and subsequently discussed on the mailing-list,
we are switching stable branch maintenance to project-specific teams
under the guidance and leadership of the stable-maint-core team.

Some Oslo libraries follow a ""compatible"" release cycle and therefore
use stable branches -- the proposed change is to create a unique
oslo-stable-maint team to review such changes. Oslo libraries which
follow a free release cycle (taskflow, oslosphinx, pbr...) do not use
stable branches and therefore do not need their ACLs changed.

The oslo-stable-maint team should be owned by stable-maint-core which
will vet the addition of members to make sure they are aware of the
Stable Branch policy.

Change-Id: Ic89244ecbdb317501f86ee4b7347a281b13cae91
",git fetch https://review.opendev.org/openstack/project-config refs/changes/69/141769/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/oslo.rootwrap.config', 'gerrit/acls/openstack/oslo.log.config', 'gerrit/acls/openstack/oslo.version.config', 'gerrit/acls/openstack/oslo.i18n.config', 'gerrit/acls/openstack/oslo.messaging.config', 'gerrit/acls/openstack/oslo.utils.config', 'gerrit/acls/openstack/oslo.serialization.config', 'gerrit/acls/openstack/oslo-incubator.config', 'gerrit/acls/openstack/oslo.db.config', 'gerrit/acls/openstack/oslo.middleware.config', 'gerrit/acls/openstack/oslo.config.config', 'gerrit/acls/openstack/oslo.concurrency.config', 'gerrit/acls/openstack/oslo.vmware.config']",13,c1b6b7f3e0848facae72652265e2d6fa2fa741d9,oslo-stable-maint,"[access ""refs/heads/stable/*""] exclusiveGroupPermissions = abandon label-Code-Review label-Workflow abandon = group oslo-stable-maint label-Code-Review = -2..+2 group oslo-stable-maint label-Code-Review = -1..+1 group Registered Users label-Workflow = -1..+1 group oslo-stable-maint ",,91,0
openstack%2Foslo-incubator~stable%2Fjuno~I7981b723cee97ee65a7d58d5b058f24aa734c0e2,openstack/oslo-incubator,stable/juno,I7981b723cee97ee65a7d58d5b058f24aa734c0e2,Updated from global requirements,MERGED,2014-12-14 00:16:51.000000000,2014-12-15 15:30:59.000000000,2014-12-15 15:30:57.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-14 00:16:51.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/22671745b7f6ca22467cd84b520df18dd6c1f753', 'message': 'Updated from global requirements\n\nChange-Id: I7981b723cee97ee65a7d58d5b058f24aa734c0e2\n'}]",0,141602,22671745b7f6ca22467cd84b520df18dd6c1f753,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I7981b723cee97ee65a7d58d5b058f24aa734c0e2
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/02/141602/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,22671745b7f6ca22467cd84b520df18dd6c1f753,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",2,2
openstack%2Ffuel-web~stable%2F6.0~I181d08d8d482892f45f445ce887021225d246bde,openstack/fuel-web,stable/6.0,I181d08d8d482892f45f445ce887021225d246bde,Urgent fix for log page,MERGED,2014-12-12 18:13:32.000000000,2014-12-15 15:28:14.000000000,2014-12-15 15:28:14.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-12 18:13:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1ce4fbf1971bdcc27404fe8e8fabd036f388a788', 'message': 'Urgent fix for logging\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 3, 'created': '2014-12-12 21:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a60de3f9006db3041cfba179e009d8f193b5c519', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 4, 'created': '2014-12-15 12:42:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1af209846ecf853acaf270cba6b514280e39ffc9', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 5, 'created': '2014-12-15 14:25:17.000000000', 'files': ['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/test/unit/test_settings_config.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/37071fd821873e42a316997aaefa05918c957132', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}]",1,141450,37071fd821873e42a316997aaefa05918c957132,26,5,4,8749,,,0,"Urgent fix for log page

remote_openstack_log_format should also
include remote_syslog_log_format.

The reason for that is in 6.0 release
nova sends logs in new format, but we
have to support old environments with
old logging format.

Change-Id: I181d08d8d482892f45f445ce887021225d246bde
Related-bug: #1401852
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/50/141450/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/api/v1/handlers/logs.py']",2,1ce4fbf1971bdcc27404fe8e8fabd036f388a788,, if m.group('level2'): entry_level = m.group('level').upper() ,,7,1
openstack%2Ffuel-web~master~I181d08d8d482892f45f445ce887021225d246bde,openstack/fuel-web,master,I181d08d8d482892f45f445ce887021225d246bde,Urgent fix for log page,MERGED,2014-12-12 18:11:53.000000000,2014-12-15 15:27:59.000000000,2014-12-15 15:27:58.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8789}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-12 18:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/96b42973bdb7bc794fc005ada429dc9dffdf00a7', 'message': 'Urgent fix for logging\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 2, 'created': '2014-12-12 21:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9c68d89d5b56cc53ee88aa5433d315d1b219dcf', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 3, 'created': '2014-12-15 12:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aa52700d6defb2eabf24a39094a045e390c68b7d', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 4, 'created': '2014-12-15 13:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/74709a487df26af18e65b28d36a8e4b9642bcc42', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}, {'number': 5, 'created': '2014-12-15 14:08:29.000000000', 'files': ['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/test/unit/test_settings_config.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1dc4d6780d39b760feb16b3ea37664178db8587b', 'message': 'Urgent fix for log page\n\nremote_openstack_log_format should also\ninclude remote_syslog_log_format.\n\nThe reason for that is in 6.0 release\nnova sends logs in new format, but we\nhave to support old environments with\nold logging format.\n\nChange-Id: I181d08d8d482892f45f445ce887021225d246bde\nRelated-bug: #1401852\n'}]",3,141449,1dc4d6780d39b760feb16b3ea37664178db8587b,35,8,5,8749,,,0,"Urgent fix for log page

remote_openstack_log_format should also
include remote_syslog_log_format.

The reason for that is in 6.0 release
nova sends logs in new format, but we
have to support old environments with
old logging format.

Change-Id: I181d08d8d482892f45f445ce887021225d246bde
Related-bug: #1401852
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/49/141449/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/settings.yaml', 'nailgun/nailgun/api/v1/handlers/logs.py']",2,96b42973bdb7bc794fc005ada429dc9dffdf00a7,bug/1401852, if m.group('level2'): entry_level = m.group('level').upper() ,,7,1
openstack%2Fdevstack-gate~master~Ic695db9bbcd95f0c1086f6ca437744f7e079ced5,openstack/devstack-gate,master,Ic695db9bbcd95f0c1086f6ca437744f7e079ced5,Add tooz in project list,MERGED,2014-12-09 14:32:03.000000000,2014-12-15 15:17:48.000000000,2014-12-15 15:17:47.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1561}, {'_account_id': 1669}, {'_account_id': 1994}, {'_account_id': 2271}, {'_account_id': 2472}, {'_account_id': 2750}, {'_account_id': 2813}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 6786}, {'_account_id': 6928}, {'_account_id': 7069}, {'_account_id': 7450}, {'_account_id': 8122}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-12-09 14:32:03.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/82bf492bfee17638c7668626a6e60f03f2472f19', 'message': 'Add tooz in project list\n\nChange-Id: Ic695db9bbcd95f0c1086f6ca437744f7e079ced5\n'}]",0,140343,82bf492bfee17638c7668626a6e60f03f2472f19,11,21,1,1669,,,0,"Add tooz in project list

Change-Id: Ic695db9bbcd95f0c1086f6ca437744f7e079ced5
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/43/140343/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,82bf492bfee17638c7668626a6e60f03f2472f19,jd/tooz,"PROJECTS=""openstack/tooz $PROJECTS""",,1,0
openstack%2Fnova~master~Iec2bba18c8894302e3ba35af69379ea9c1da04fc,openstack/nova,master,Iec2bba18c8894302e3ba35af69379ea9c1da04fc,GET servers API sorting compute/instance/DB updates,MERGED,2014-05-28 07:37:22.000000000,2014-12-15 15:17:32.000000000,2014-11-14 15:03:36.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5292}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9622}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10559}, {'_account_id': 10612}, {'_account_id': 11881}, {'_account_id': 11902}]","[{'number': 1, 'created': '2014-05-28 07:37:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37d5366aaa9e64b7ae630cbfb30b2db626d875fe', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can be\nspecified multiple times to create a list of sort keys and directions.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions.\n\nThe layers that consume these new sort parameters on the DB APIs will be\nconsumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 2, 'created': '2014-05-28 19:02:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8aa0fccb1deab4d6c915144c3c681a8c92163b18', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 3, 'created': '2014-05-29 04:14:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/025ab6af1b5bb86dccc4087fcd16d783673b0261', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 4, 'created': '2014-05-29 15:00:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27a6d9a5b390355e0eadcc34a328fe9704035f4f', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 5, 'created': '2014-06-11 21:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a41c930c350f8db1c21dbe074646ef17b3d20291', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 6, 'created': '2014-06-16 14:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/79e53b0be7f818ffff215016ce512690d3a49191', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 7, 'created': '2014-06-17 13:59:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/90cd134526d3b1c3e1893d70ea4ddea0bad4f9a4', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 8, 'created': '2014-06-23 03:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/87df3b6972c8e7ba379c9d8f652adfed1d780d67', 'message': ""Nova GET servers API sorting enhancements DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nThis patch set contains the DB updates required for multiple keys and\nmultiple directions. Note that the defaulting of the sort keys and\ndirections is done in the dependent patch set in the new\n'process_sort_params' function; by default, the sort keys will be\n'created_at' and 'id' in the 'desc' direction.\n\nThe layers that consume these new sort parameters on the DB APIs will\nbe consumed in another change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nImplements: blueprint nova-pagination\n""}, {'number': 9, 'created': '2014-06-27 08:22:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/921847faee3fcd16fd00afe912f282a83c8fb949', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 10, 'created': '2014-06-27 14:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ee621a53666c3427346979343eb1b6a8afbb2876', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 11, 'created': '2014-07-07 05:10:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e650f52959f4cb4b5f93e53be2b871da31732660', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 12, 'created': '2014-07-21 15:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c5561dea3b25cf63ca743d8865b87d797b03693', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 13, 'created': '2014-07-24 19:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d54779152d1327ff18546321b698c68d64b9c8ba', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 14, 'created': '2014-07-28 15:45:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e6514f437736a90908ef55f2e05596632e028fce', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 15, 'created': '2014-07-28 19:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8eca3bff8c8192ed62c7c6ebe5b39c1397f110e1', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 16, 'created': '2014-08-12 16:33:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f426e4156fe93f1019f5701f24a135ccfe781fc8', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 17, 'created': '2014-08-12 20:27:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3d38096121259163b57c4d466bef52cf79e92278', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 18, 'created': '2014-08-27 19:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a37a224a5f5ade32a73ff7bebe8ff7484ed1beec', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 19, 'created': '2014-09-01 03:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc7505944d63c0af452656a4f26614df848f4db9', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 20, 'created': '2014-09-01 20:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7ff732db1ab16b00bdb538f733907ab2e94b3852', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 21, 'created': '2014-11-01 01:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/daed8baa72c2121cb1592bccd65d4e4691f9f0f2', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 22, 'created': '2014-11-10 15:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27a8382f0557406e34c51a7ebcfef8c675cffc8e', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}, {'number': 23, 'created': '2014-11-13 21:07:03.000000000', 'files': ['nova/tests/unit/objects/test_objects.py', 'nova/api/ec2/cloud.py', 'nova/objects/instance.py', 'nova/tests/unit/objects/test_instance.py', 'nova/db/api.py', 'nova/compute/api.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a98f5c86cdf3bd5eb4615b1b25f9b08aadc450f3', 'message': ""GET servers API sorting compute/instance/DB updates\n\nThis change is to support updating the v2 and v3 /servers and\n/servers/detail APIs to support multiple sort keys and sort directions\n(using the 'sort_key' and 'sort_dir' parameters); these parameters can\nbe specified multiple times to create a list of sort keys and\ndirections.\n\nContains the changes that will be used by the REST API layer:\n* Compute API updates on the get_all function to support sort keys\n  and directions\n* InstanceList updates on the get_by_filters function. The new\n  'sort_keys' and 'sort_dirs' kwargs are added but the existing\n  'sort_key' and 'sort_dir' kwargs must remain for backward\n  compatibility.\n* DB API has a new 'instance_get_all_by_filters_sort' function that\n  supports multiple keys/directions. The existing\n  'instance_get_all_by_filters' remains for backward compatibility\n  and calls the new sort function with the single sort values\n  wrapped in a list.\n\nNote that the defaulting of the sort keys and directions is done in\nthe dependent patch set in the new 'process_sort_params' function\n(invoked in db.sqlalchemy.api); by default, the sort keys are\n'created_at' and 'id' in the 'desc' direction.\n\nThe REST API changes that consume these updated will be pushed in\nanother change set.\n\nChange-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc\nPartially implements: blueprint nova-pagination\n""}]",39,96094,a98f5c86cdf3bd5eb4615b1b25f9b08aadc450f3,252,18,23,10559,,,0,"GET servers API sorting compute/instance/DB updates

This change is to support updating the v2 and v3 /servers and
/servers/detail APIs to support multiple sort keys and sort directions
(using the 'sort_key' and 'sort_dir' parameters); these parameters can
be specified multiple times to create a list of sort keys and
directions.

Contains the changes that will be used by the REST API layer:
* Compute API updates on the get_all function to support sort keys
  and directions
* InstanceList updates on the get_by_filters function. The new
  'sort_keys' and 'sort_dirs' kwargs are added but the existing
  'sort_key' and 'sort_dir' kwargs must remain for backward
  compatibility.
* DB API has a new 'instance_get_all_by_filters_sort' function that
  supports multiple keys/directions. The existing
  'instance_get_all_by_filters' remains for backward compatibility
  and calls the new sort function with the single sort values
  wrapped in a list.

Note that the defaulting of the sort keys and directions is done in
the dependent patch set in the new 'process_sort_params' function
(invoked in db.sqlalchemy.api); by default, the sort keys are
'created_at' and 'id' in the 'desc' direction.

The REST API changes that consume these updated will be pushed in
another change set.

Change-Id: Iec2bba18c8894302e3ba35af69379ea9c1da04fc
Partially implements: blueprint nova-pagination
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/96094/16 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/db/test_db_api.py', 'nova/db/api.py', 'nova/db/sqlalchemy/api.py']",3,37d5366aaa9e64b7ae630cbfb30b2db626d875fe,bp/nova-pagination,"from nova.api.openstack import common as api_commondef instance_get_all_by_filters(context, filters, sort_key=None, sort_dir=None, use_slave=False, sort_keys=None, sort_dirs=None): sort_keys, sort_dirs = api_common.process_sort_params(sort_key, sort_dir, sort_keys, sort_dirs, default_dir='desc') # Note: order_by is done in the sqlalchemy.utils.py paginate_query(), # no need to do it here as well sort_keys, sort_dirs=sort_dirs)","def instance_get_all_by_filters(context, filters, sort_key, sort_dir, use_slave=False): sort_fn = {'desc': desc, 'asc': asc} query_prefix = query_prefix.order_by(sort_fn[sort_dir]( getattr(models.Instance, sort_key))) [sort_key, 'created_at', 'id'], sort_dir=sort_dir)",173,13
openstack%2Fcinder-specs~master~I57b2015c512e44538e30b843110d43427a151be0,openstack/cinder-specs,master,I57b2015c512e44538e30b843110d43427a151be0,Support to manage block storage on Linux on System z.,ABANDONED,2014-12-15 14:10:36.000000000,2014-12-15 15:13:59.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-15 14:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/154d1f4994dd44f63e69d873f2ceefbe0948a908', 'message': 'Adds support to run Cinder on Linux on System z.\nImplements: blueprint linux-systemz\n\nChange-Id: I57b2015c512e44538e30b843110d43427a151be0\n'}, {'number': 2, 'created': '2014-12-15 14:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/425a33c02d964807d508f6d875b30c7b2058dc81', 'message': 'Adds support to run Cinder on Linux on System z.\n\nImplements: blueprint linux-systemz\n\nChange-Id: I57b2015c512e44538e30b843110d43427a151be0'}, {'number': 3, 'created': '2014-12-15 14:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0d6df25cd701ae11f1d3f909b6f3e5501aa6da86', 'message': 'Support to manage block storage on Linux on System z.\n\nImplements: blueprint linux-systemz\n\nChange-Id: I57b2015c512e44538e30b843110d43427a151be0'}, {'number': 4, 'created': '2014-12-15 14:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/4479eab997f59265afde80babf8cc71d227b57ef', 'message': 'Support to manage block storage on Linux on System z.\n\nImplements: blueprint linux-systemz\n\nChange-Id: I57b2015c512e44538e30b843110d43427a151be0'}, {'number': 5, 'created': '2014-12-15 15:05:35.000000000', 'files': ['specs/kilo/linux-systemz.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/825a24979f4be43a9c51333050d6a79d79e75d8a', 'message': 'Support to manage block storage on Linux on System z.\n\nImplements: blueprint linux-systemz\n\nChange-Id: I97c43754d372f8ff8d1c4ec216fd2f19c24755d1'}]",0,141804,825a24979f4be43a9c51333050d6a79d79e75d8a,10,1,5,11433,,,0,"Support to manage block storage on Linux on System z.

Implements: blueprint linux-systemz

Change-Id: I97c43754d372f8ff8d1c4ec216fd2f19c24755d1",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/04/141804/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/linux-systemz.rst'],1,154d1f4994dd44f63e69d873f2ceefbe0948a908,bp/linux-systemz,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================ Support Linux on System z (S/390) as a hypervisor platform ================================================================ https://blueprints.launchpad.net/cinder/+spec/linux-systemz There are some platform-specific changes needed in order to allow Cinder manage FCP-based block storage on Linux on System z. Additional OpenStack functionality beyond initial Cinder support is not part of this blueprint; we will have specific additional blueprints for that, as needed. Required support in Nova is described by a separate blueprint which is listed as a dependency below. iSCSI does not require any changes. Problem description =================== Linux on System z differs from other Linux platforms in two respects: * System z uses a different format for device file paths (ccw-based, rather than pci-based) * Auto-discovery for fibre-channel devices can be configured online, or offline. In case auto-discovery is turned off, devices need to be added, and removed explicitly by OpenStack (unit_add, unit_remove) Proposed change =============== Change code in Cinder to address these issues, dependent on the host capabilities indicating a CPU architecture of ``arch.S390X``, and ``arch.S390``. For details, see section `Work Items`_. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None (no need for platform-specific parameters in cinder.conf as part of this blueprint) Developer impact ---------------- None (changes should not affect other platforms) Implementation ============== Assignee(s) ----------- Primary assignee: stefan-amann Other contributors: mzoeller maiera Work Items ---------- In ``cinder/brick/initiator/connector.py``: * connect_volume and disconnect_volume need to support the System z specific format of the device file paths. * in connect_volume: issue unit_add command when adding a multipath device to the configuration. * in disconnect_volume: issue unit_remove command when removing a multipath device from the configuration. In ``cinder/brick/initiator/linuxfc.py``: * Utility functions for the FCP support issues described above. Dependencies ============ Nova blueprint to add support for KVM/libvirt in Linux on System z https://blueprints.launchpad.net/nova/+spec/libvirt-kvm-systemz Testing ======= Unit test: * Existing unit tests should suffice since no API changes are expected. Above code changes will be executed as part of main code execution paths, such as the initialize_connection/connect_volume sequence. * We will provide an environment for CI testing. This is described by the Nova blueprint which is listed as a dependency. Documentation Impact ==================== * No changes needed in config docs. * Doc changes for the platform will be made as needed (details are to be determined). References ========== * _`[1]` Linux on System z Device Driver book, http://public.dhe.ibm.com/software/dw/linux390/docu/l316dd25.pdf * _`[2]` Linux on System z,",".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================ Support Linux on System z (S/390) as a hypervisor platform ================================================================ https://blueprints.launchpad.net/cinder/+spec/linux-systemz There are some platform-specific changes needed in order to allow Cinder manage block storage on Linux on System z. Additional OpenStack functionality beyond initial Cinder support is not part of this blueprint; we will have specific additional blueprints for that, as needed. Problem description =================== Linux on System z differs from other Linux platforms in two respects: * System z uses a different format for device file paths (ccw-based, rather than pci-based) * Auto-discovery for fibre-channel devices can be configured online, or offline. In case auto-discovery is turned off, devices need to be added, and removed explicitly by OpenStack (unit_add, unit_remove) Proposed change =============== Change code in Cinder to address these issues, dependent on the host capabilities indicating a CPU architecture of ``arch.S390X``, and ``arch.S390``. For details, see section `Work Items`_. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None (no need for platform-specific parameters in cinder.conf as part of this blueprint) Developer impact ---------------- None (changes should not affect other platforms) Implementation ============== Assignee(s) ----------- Primary assignee: stefan-amann Other contributors: mzoeller maiera Work Items ---------- In ``cinder/brick/initiator/connector.py``: * connect_volume and disconnect_volume need to support the System z specific format of the device file paths. * in connect_volume: issue unit_add command when adding a multipath device to the configuration. * in disconnect_volume: issue unit_remove command when removing a multipath device from the configuration. In ``cinder/brick/initiator/linuxfc.py``: * Utility functions for the FCP support issues described above. Dependencies ============ Nova blueprint to add support for KVM/libvirt in Linux on System z https://blueprints.launchpad.net/nova/+spec/libvirt-kvm-systemz Testing ======= Unit test: * Existing unit tests should suffice since no API changes are expected Documentation Impact ==================== * No changes needed in config docs. * Doc changes for the platform will be made as needed (details are to be determined). References ========== * _`[1]` Linux on System z Device Driver book, http://public.dhe.ibm.com/software/dw/linux390/docu/l316dd25.pdf * _`[2]` Linux on System z, ",157,148
openstack%2Fmagnum~master~Id3e08334d106cf8a1f6cc94c4905d42095a0546d,openstack/magnum,master,Id3e08334d106cf8a1f6cc94c4905d42095a0546d,Reference proper file in cmd.conductor,MERGED,2014-12-12 23:51:16.000000000,2014-12-15 15:12:37.000000000,2014-12-15 15:12:35.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6924}, {'_account_id': 7494}, {'_account_id': 7770}, {'_account_id': 12385}]","[{'number': 1, 'created': '2014-12-12 23:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/31d238967254e2b5986f8ed140fcdc4da3959d15', 'message': 'Reference proper file in cmd.conductor\n\nThe cmd.conductor was referencing a file that was renamed by a previous\ncommit.  This resulted in the conductor not running.\n\nChange-Id: Id3e08334d106cf8a1f6cc94c4905d42095a0546d\n'}, {'number': 2, 'created': '2014-12-13 01:04:13.000000000', 'files': ['magnum/cmd/conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/4aac587695afe16bc0fe4ce28e4c95cf95aa5565', 'message': 'Reference proper file in cmd.conductor\n\nThe cmd.conductor was referencing a file that was renamed by a previous\ncommit.  This resulted in the conductor not running.\n\nChange-Id: Id3e08334d106cf8a1f6cc94c4905d42095a0546d\n'}]",0,141524,4aac587695afe16bc0fe4ce28e4c95cf95aa5565,12,6,2,2834,,,0,"Reference proper file in cmd.conductor

The cmd.conductor was referencing a file that was renamed by a previous
commit.  This resulted in the conductor not running.

Change-Id: Id3e08334d106cf8a1f6cc94c4905d42095a0546d
",git fetch https://review.opendev.org/openstack/magnum refs/changes/24/141524/2 && git format-patch -1 --stdout FETCH_HEAD,['magnum/cmd/conductor.py'],1,31d238967254e2b5986f8ed140fcdc4da3959d15,,"from magnum.conductor.handlers import kube as k8s_conductor# k8s_conductor.Handler(),","from magnum.conductor.handlers import k8s as k8s_conductor k8s_conductor.Handler(),",2,2
openstack%2Ffuel-main~stable%2F6.0~Iafbf677bb902d64ae7e33346f2701900e30c9342,openstack/fuel-main,stable/6.0,Iafbf677bb902d64ae7e33346f2701900e30c9342,Add wait for connection to restore after l3 agent migration,MERGED,2014-12-12 14:46:40.000000000,2014-12-15 15:08:51.000000000,2014-12-15 15:08:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2014-12-12 14:46:40.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cb6b221228ddd205d6256e69fb3ba60873c6570c', 'message': 'Add wait for connection to restore after l3 agent migration\n\n- After l3 agent rescheduling connectivity is restoring for some\nperiod of time so we need to wait a few minutes before checking\nconnectivity on instance\n\nChange-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342\nCloses-Bug: #1401819\n'}]",0,141390,cb6b221228ddd205d6256e69fb3ba60873c6570c,9,7,1,10136,,,0,"Add wait for connection to restore after l3 agent migration

- After l3 agent rescheduling connectivity is restoring for some
period of time so we need to wait a few minutes before checking
connectivity on instance

Change-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342
Closes-Bug: #1401819
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/90/141390/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_neutron.py'],1,cb6b221228ddd205d6256e69fb3ba60873c6570c,," wait(lambda: remote.execute(cmd)['exit_code'] == 0, timeout=120)",,1,0
openstack%2Ffuel-main~master~Iafbf677bb902d64ae7e33346f2701900e30c9342,openstack/fuel-main,master,Iafbf677bb902d64ae7e33346f2701900e30c9342,Add wait for connection to restore after l3 agent migration,MERGED,2014-12-12 13:13:19.000000000,2014-12-15 15:08:40.000000000,2014-12-15 15:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2014-12-12 13:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f62f353c72ea375d165b2a1005d84aaf0d6fa6ca', 'message': 'Add wait for connection to restore after\nl3 agent migration\n\nChange-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342\nCloses-Bug: #1401819\n'}, {'number': 2, 'created': '2014-12-12 14:10:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/dd686cf0330e9105e5233bef0bb1861d8184babe', 'message': 'Add wait for connection to restore after\nl3 agent migration\n\n- After l3 agent rescheduling connectivity is restoring for some\nperiod of time so we need to wait a few minutes before checking\nconnectivity on instance\n\nChange-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342\nCloses-Bug: #1401819\n'}, {'number': 3, 'created': '2014-12-12 14:45:39.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_neutron.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4f1fb34784b4d326f356bdde5c23b79b134b8af4', 'message': 'Add wait for connection to restore after l3 agent migration\n\n- After l3 agent rescheduling connectivity is restoring for some\nperiod of time so we need to wait a few minutes before checking\nconnectivity on instance\n\nChange-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342\nCloses-Bug: #1401819\n'}]",1,141365,4f1fb34784b4d326f356bdde5c23b79b134b8af4,24,8,3,10136,,,0,"Add wait for connection to restore after l3 agent migration

- After l3 agent rescheduling connectivity is restoring for some
period of time so we need to wait a few minutes before checking
connectivity on instance

Change-Id: Iafbf677bb902d64ae7e33346f2701900e30c9342
Closes-Bug: #1401819
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/65/141365/2 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_neutron.py'],1,f62f353c72ea375d165b2a1005d84aaf0d6fa6ca,fixL3test," wait(lambda: remote.execute(cmd)['exit_code'] == 0, timeout=120)",,1,0
openstack%2Fzaqar-specs~master~Ic843e2cfafcb2d6070b57daa923ed34912c4590e,openstack/zaqar-specs,master,Ic843e2cfafcb2d6070b57daa923ed34912c4590e,Add OSProfiler to Zaqar,MERGED,2014-11-19 14:47:46.000000000,2014-12-15 15:08:24.000000000,2014-12-15 15:08:23.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 6549}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-11-19 14:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/caac57028b9c742b30bdeae119cd61e6c1ad327b', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}, {'number': 2, 'created': '2014-11-19 14:49:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/73003af3b796af8378ed1456a676116dcdf90576', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}, {'number': 3, 'created': '2014-11-25 14:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/ca3b11187f40c8b8ddeef4023094cd7b8aa406e6', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}, {'number': 4, 'created': '2014-12-02 03:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/4cc4be4a6b48914849e8fdd58bd88d50b5fd8f25', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}, {'number': 5, 'created': '2014-12-12 15:34:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/650bbba4ad5b76efa11305558073e6a154cfca4b', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}, {'number': 6, 'created': '2014-12-12 16:00:09.000000000', 'files': ['specs/kilo/osprofiler.rst', 'specs/kilo/index.rst'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/c547cb410e344769b4f2a02b6f1aad7f30dde106', 'message': 'Add OSProfiler to Zaqar\n\nChange-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e\n'}]",17,135612,c547cb410e344769b4f2a02b6f1aad7f30dde106,26,6,6,6413,,,0,"Add OSProfiler to Zaqar

Change-Id: Ic843e2cfafcb2d6070b57daa923ed34912c4590e
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/12/135612/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/index.rst'],1,caac57028b9c742b30bdeae119cd61e6c1ad327b,osprofiler, *,.. FIXME(flaper87): Uncomment after adding first real spec. .. *,1,2
openstack%2Fcinder~stable%2Fjuno~I2eea528d12ed7e4cf87da19ee05fd49acf4f44a4,openstack/cinder,stable/juno,I2eea528d12ed7e4cf87da19ee05fd49acf4f44a4,Updated from global requirements,MERGED,2014-12-14 00:10:23.000000000,2014-12-15 14:52:28.000000000,2014-12-15 14:52:27.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 10622}]","[{'number': 1, 'created': '2014-12-14 00:10:23.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f0b3d735d8c87e143a24725d29ae41b1b7bc2a5d', 'message': 'Updated from global requirements\n\nChange-Id: I2eea528d12ed7e4cf87da19ee05fd49acf4f44a4\n'}]",0,141594,f0b3d735d8c87e143a24725d29ae41b1b7bc2a5d,9,5,1,11131,,,0,"Updated from global requirements

Change-Id: I2eea528d12ed7e4cf87da19ee05fd49acf4f44a4
",git fetch https://review.opendev.org/openstack/cinder refs/changes/94/141594/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f0b3d735d8c87e143a24725d29ae41b1b7bc2a5d,openstack/requirements,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fceilometer~master~Iddba9e58755945fd8553e767a05c767908b3dbff,openstack/ceilometer,master,Iddba9e58755945fd8553e767a05c767908b3dbff,Use oslo_context,ABANDONED,2014-12-13 16:53:47.000000000,2014-12-15 14:51:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 7770}]","[{'number': 1, 'created': '2014-12-13 16:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4d4b565eae9169437b4f20a0ea9798f30ce64be7', 'message': 'Use oslo_context\n\nThe context module from oslo-incubator has graduated\n\nChange-Id: Iddba9e58755945fd8553e767a05c767908b3dbff\n'}, {'number': 2, 'created': '2014-12-13 17:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d12af47b1dc327610393ea1fdbb39d3e273345ed', 'message': 'Use oslo_context\n\nThe context module from oslo-incubator has graduated\n\nChange-Id: Iddba9e58755945fd8553e767a05c767908b3dbff\n'}, {'number': 3, 'created': '2014-12-13 17:25:56.000000000', 'files': ['ceilometer/tests/test_notification.py', 'ceilometer/objectstore/swift_middleware.py', 'ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/messaging.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/network/services/test_vpnaas.py', 'ceilometer/alarm/notifier/rest.py', 'ceilometer/tests/alarm/test_notifier.py', 'ceilometer/alarm/rpc.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/tests/publisher/test_messaging_publisher.py', 'requirements.txt', 'ceilometer/tests/test_collector.py', 'ceilometer/openstack/common/context.py', 'ceilometer/agent.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/cli.py', 'openstack-common.conf', 'ceilometer/notifier.py', 'ceilometer/plugin.py', 'ceilometer/tests/network/services/test_fwaas.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6bb2becc24cdad5739d3cdb08ba028415d84b72f', 'message': 'Use oslo_context\n\nThe context module from oslo-incubator has graduated\n\nChange-Id: Iddba9e58755945fd8553e767a05c767908b3dbff\n'}]",0,141566,6bb2becc24cdad5739d3cdb08ba028415d84b72f,8,3,3,7770,,,0,"Use oslo_context

The context module from oslo-incubator has graduated

Change-Id: Iddba9e58755945fd8553e767a05c767908b3dbff
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/66/141566/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/test_notification.py', 'ceilometer/objectstore/swift_middleware.py', 'ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/messaging.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/network/services/test_vpnaas.py', 'ceilometer/alarm/notifier/rest.py', 'ceilometer/tests/alarm/test_notifier.py', 'ceilometer/alarm/rpc.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/tests/publisher/test_messaging_publisher.py', 'requirements.txt', 'ceilometer/tests/test_collector.py', 'ceilometer/openstack/common/context.py', 'ceilometer/agent.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/cli.py', 'openstack-common.conf', 'ceilometer/notifier.py', 'ceilometer/plugin.py', 'ceilometer/tests/network/services/test_fwaas.py']",22,4d4b565eae9169437b4f20a0ea9798f30ce64be7,oslo_context,from oslo_context import context,from ceilometer.openstack.common import context,21,144
openstack-attic%2Fvolume-api~master~I73df58716bfbda8a04472fc1da27c97d3367cc32,openstack-attic/volume-api,master,I73df58716bfbda8a04472fc1da27c97d3367cc32,Indicates frozen state in README,MERGED,2014-12-11 23:24:12.000000000,2014-12-15 14:50:59.000000000,2014-12-15 14:50:59.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 3114}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-11 23:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/78904cf93204effb3657b5b9f4cb9b1f897ffdef', 'message': 'Indicates frozen state in README\n\nChange-Id: I73df58716bfbda8a04472fc1da27c97d3367cc32\n'}, {'number': 2, 'created': '2014-12-14 17:52:29.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/volume-api/commit/096d5b0563d2afc136cf6224d913551fc2f8d316', 'message': 'Indicates frozen state in README\n\nChange-Id: I73df58716bfbda8a04472fc1da27c97d3367cc32\n'}]",0,141211,096d5b0563d2afc136cf6224d913551fc2f8d316,11,4,2,964,,,0,"Indicates frozen state in README

Change-Id: I73df58716bfbda8a04472fc1da27c97d3367cc32
",git fetch https://review.opendev.org/openstack-attic/volume-api refs/changes/11/141211/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,78904cf93204effb3657b5b9f4cb9b1f897ffdef,freeze, This repository is now frozen-in-time and will not accept new patches. It was the original holder for API information for the OpenStack,This repository contains the RESTful API information for the OpenStack,4,1
openstack%2Foslo.config~master~I238d5959b24898931080b99b65225dcecc51bdfe,openstack/oslo.config,master,I238d5959b24898931080b99b65225dcecc51bdfe,Remove argparse from requirements,ABANDONED,2014-12-13 12:54:19.000000000,2014-12-15 14:48:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 7770}]","[{'number': 1, 'created': '2014-12-13 12:54:19.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/fadfcbc3177506472e80d096849a4823d6bce806', 'message': 'Remove argparse from requirements\n\nIt is in the std lib\n\nChange-Id: I238d5959b24898931080b99b65225dcecc51bdfe\nCloses-Bug: #1401278\n'}]",0,141550,fadfcbc3177506472e80d096849a4823d6bce806,7,6,1,7770,,,0,"Remove argparse from requirements

It is in the std lib

Change-Id: I238d5959b24898931080b99b65225dcecc51bdfe
Closes-Bug: #1401278
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/50/141550/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,fadfcbc3177506472e80d096849a4823d6bce806,bug/1401278,,argparse,0,1
openstack%2Fsahara~master~Id2e23b0f1e42b1addf97f0b7fe08fb00fe5d17dd,openstack/sahara,master,Id2e23b0f1e42b1addf97f0b7fe08fb00fe5d17dd,Migrate to oslo.context,MERGED,2014-12-11 15:41:30.000000000,2014-12-15 14:42:22.000000000,2014-12-15 11:14:02.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-11 15:41:30.000000000', 'files': ['requirements.txt', 'sahara/context.py', 'sahara/openstack/common/context.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/fe1a3a6f3baf4fe2ec4a3501ca08566e306a9685', 'message': 'Migrate to oslo.context\n\nThe oslo.context lib version 0.1.0 has been just release and we\ncould migrate to it now.\n\nChange-Id: Id2e23b0f1e42b1addf97f0b7fe08fb00fe5d17dd\n'}]",0,141075,fe1a3a6f3baf4fe2ec4a3501ca08566e306a9685,14,6,1,6786,,,0,"Migrate to oslo.context

The oslo.context lib version 0.1.0 has been just release and we
could migrate to it now.

Change-Id: Id2e23b0f1e42b1addf97f0b7fe08fb00fe5d17dd
",git fetch https://review.opendev.org/openstack/sahara refs/changes/75/141075/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'sahara/context.py', 'sahara/openstack/common/context.py']",3,fe1a3a6f3baf4fe2ec4a3501ca08566e306a9685,,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Simple class that stores security context information in the web request. Projects should subclass this class if they wish to enhance the request context or provide additional information in their specific WSGI pipeline. """""" import itertools import uuid def generate_request_id(): return b'req-' + str(uuid.uuid4()).encode('ascii') class RequestContext(object): """"""Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """""" user_idt_format = '{user} {tenant} {domain} {user_domain} {p_domain}' def __init__(self, auth_token=None, user=None, tenant=None, domain=None, user_domain=None, project_domain=None, is_admin=False, read_only=False, show_deleted=False, request_id=None, instance_uuid=None): self.auth_token = auth_token self.user = user self.tenant = tenant self.domain = domain self.user_domain = user_domain self.project_domain = project_domain self.is_admin = is_admin self.read_only = read_only self.show_deleted = show_deleted self.instance_uuid = instance_uuid if not request_id: request_id = generate_request_id() self.request_id = request_id def to_dict(self): user_idt = ( self.user_idt_format.format(user=self.user or '-', tenant=self.tenant or '-', domain=self.domain or '-', user_domain=self.user_domain or '-', p_domain=self.project_domain or '-')) return {'user': self.user, 'tenant': self.tenant, 'domain': self.domain, 'user_domain': self.user_domain, 'project_domain': self.project_domain, 'is_admin': self.is_admin, 'read_only': self.read_only, 'show_deleted': self.show_deleted, 'auth_token': self.auth_token, 'request_id': self.request_id, 'instance_uuid': self.instance_uuid, 'user_identity': user_idt} @classmethod def from_dict(cls, ctx): return cls( auth_token=ctx.get(""auth_token""), user=ctx.get(""user""), tenant=ctx.get(""tenant""), domain=ctx.get(""domain""), user_domain=ctx.get(""user_domain""), project_domain=ctx.get(""project_domain""), is_admin=ctx.get(""is_admin"", False), read_only=ctx.get(""read_only"", False), show_deleted=ctx.get(""show_deleted"", False), request_id=ctx.get(""request_id""), instance_uuid=ctx.get(""instance_uuid"")) def get_admin_context(show_deleted=False): context = RequestContext(None, tenant=None, is_admin=True, show_deleted=show_deleted) return context def get_context_from_function_and_args(function, args, kwargs): """"""Find an arg of type RequestContext and return it. This is useful in a couple of decorators where we don't know much about the function we're wrapping. """""" for arg in itertools.chain(kwargs.values(), args): if isinstance(arg, RequestContext): return arg return None def is_user_context(context): """"""Indicates if the request context is a normal user."""""" if not context or context.is_admin: return False return context.user_id and context.project_id ",2,123
openstack%2Fdevstack~master~I5dcbdd27e7ef7a60fe3c7cb8b9c3c83b4197dfc1,openstack/devstack,master,I5dcbdd27e7ef7a60fe3c7cb8b9c3c83b4197dfc1,Add WSGIPassAuthorization to the keystone apache template,MERGED,2014-12-14 04:35:44.000000000,2014-12-15 14:40:50.000000000,2014-12-15 14:40:48.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 2903}, {'_account_id': 7118}, {'_account_id': 7191}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-14 04:35:44.000000000', 'files': ['files/apache-keystone.template'], 'web_link': 'https://opendev.org/openstack/devstack/commit/dc31f76a27a909d010408428d938121b3abd3101', 'message': 'Add WSGIPassAuthorization to the keystone apache template\n\nFor the OS-OAUTH1 Keystone extension to fully work under Apache,\nthe WSGIPassAuthorization parameter must be set to On, rather\nthan the default of Off. This will make functional testing of\nthis extension much easier.\n\nChange-Id: I5dcbdd27e7ef7a60fe3c7cb8b9c3c83b4197dfc1\n'}]",0,141618,dc31f76a27a909d010408428d938121b3abd3101,8,7,1,6482,,,0,"Add WSGIPassAuthorization to the keystone apache template

For the OS-OAUTH1 Keystone extension to fully work under Apache,
the WSGIPassAuthorization parameter must be set to On, rather
than the default of Off. This will make functional testing of
this extension much easier.

Change-Id: I5dcbdd27e7ef7a60fe3c7cb8b9c3c83b4197dfc1
",git fetch https://review.opendev.org/openstack/devstack refs/changes/18/141618/1 && git format-patch -1 --stdout FETCH_HEAD,['files/apache-keystone.template'],1,dc31f76a27a909d010408428d938121b3abd3101,add_wsgi_auth_headers, WSGIPassAuthorization On,,1,0
openstack%2Fhorizon~stable%2Ficehouse~I744fac28de0fb7060b50c5db689e74631a628c88,openstack/horizon,stable/icehouse,I744fac28de0fb7060b50c5db689e74631a628c88,Prevent leaking `target` info into subsequent `policy.check()` calls,MERGED,2014-12-02 10:50:58.000000000,2014-12-15 14:40:39.000000000,2014-12-15 14:40:37.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 4978}, {'_account_id': 5623}, {'_account_id': 6162}, {'_account_id': 6610}, {'_account_id': 6635}, {'_account_id': 6914}, {'_account_id': 8074}, {'_account_id': 9317}, {'_account_id': 9576}, {'_account_id': 9981}, {'_account_id': 12355}, {'_account_id': 12826}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-12-02 10:50:58.000000000', 'files': ['openstack_dashboard/policy.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/33f2b939fd20dbeb4555640937db645104c2a0fc', 'message': ""Prevent leaking `target` info into subsequent `policy.check()` calls\n\nDue to mutable dictionary being used as the default `target` argument\nvalue the first target calculated from scratch in POLICY_CHECK\nfunction will be used for all subsequent calls to POLICY_CHECK with 2\narguments. The wrong `target` can either lead to a reduced set of\noperations on an entity for a given user, or to enlarged one. Due to\nindependent policy checks at each service's side this doesn't pose a\nserious security breach, but can lead to weird UX behaviour.\n\nChange-Id: I744fac28de0fb7060b50c5db689e74631a628c88\nCloses-Bug: #1396544\n(cherry picked from commit dab964d781699d07883a659750c6913b649fed38)\n""}]",0,138314,33f2b939fd20dbeb4555640937db645104c2a0fc,21,17,1,8040,,,0,"Prevent leaking `target` info into subsequent `policy.check()` calls

Due to mutable dictionary being used as the default `target` argument
value the first target calculated from scratch in POLICY_CHECK
function will be used for all subsequent calls to POLICY_CHECK with 2
arguments. The wrong `target` can either lead to a reduced set of
operations on an entity for a given user, or to enlarged one. Due to
independent policy checks at each service's side this doesn't pose a
serious security breach, but can lead to weird UX behaviour.

Change-Id: I744fac28de0fb7060b50c5db689e74631a628c88
Closes-Bug: #1396544
(cherry picked from commit dab964d781699d07883a659750c6913b649fed38)
",git fetch https://review.opendev.org/openstack/horizon refs/changes/14/138314/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/policy.py'],1,33f2b939fd20dbeb4555640937db645104c2a0fc,bug/1396544,"def check(actions, request, target=None): if target is None: target = {}","def check(actions, request, target={}):",3,1
openstack%2Fproject-config~master~Ic281a233aae06b27096d315831e45bb3499a95fb,openstack/project-config,master,Ic281a233aae06b27096d315831e45bb3499a95fb,Normalize Gerrit ACLs,MERGED,2014-12-10 19:50:00.000000000,2014-12-15 14:36:57.000000000,2014-12-15 14:36:56.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6987}]","[{'number': 1, 'created': '2014-12-10 19:50:00.000000000', 'files': ['gerrit/acls/openstack-dev/devstack.config', 'gerrit/acls/stackforge/fuel.config', 'gerrit/acls/stackforge/powervc-driver.config', 'gerrit/acls/stackforge/puppet-openstack-cloud.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/stackforge/chef-cookbooks.config', 'gerrit/acls/openstack/python-saharaclient.config', 'gerrit/acls/stackforge/compass.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/python-troveclient.config', 'gerrit/acls/stackforge/os-ansible-deployment.config', 'gerrit/acls/stackforge/ec2-driver.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/stackforge/puppet-ceph.config', 'gerrit/acls/openstack/tempest.config', 'gerrit/acls/stackforge/congress.config', 'gerrit/acls/stackforge/murano.config', 'gerrit/acls/openstack/trove-integration.config', 'gerrit/acls/stackforge/xenapi-os-testing.config', 'gerrit/acls/stackforge/yaql.config', 'gerrit/acls/openstack/oslo.vmware.config', 'gerrit/acls/openstack/sahara.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4bf53d27580f1f85b654482ecbc6d4b1a7118d09', 'message': 'Normalize Gerrit ACLs\n\nThis is the result of running:\n\n    find gerrit/acls/ -type f -name ""*.config"" \\\n         -exec ./tools/normalize_acl.py {} 1 2 3 4 5 6 \\;\n\nChange-Id: Ic281a233aae06b27096d315831e45bb3499a95fb\n'}]",0,140822,4bf53d27580f1f85b654482ecbc6d4b1a7118d09,8,5,1,6547,,,0,"Normalize Gerrit ACLs

This is the result of running:

    find gerrit/acls/ -type f -name ""*.config"" \
         -exec ./tools/normalize_acl.py {} 1 2 3 4 5 6 \;

Change-Id: Ic281a233aae06b27096d315831e45bb3499a95fb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/140822/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack-dev/devstack.config', 'gerrit/acls/stackforge/fuel.config', 'gerrit/acls/stackforge/powervc-driver.config', 'gerrit/acls/stackforge/puppet-openstack-cloud.config', 'gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/stackforge/chef-cookbooks.config', 'gerrit/acls/openstack/python-saharaclient.config', 'gerrit/acls/stackforge/compass.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/python-troveclient.config', 'gerrit/acls/stackforge/os-ansible-deployment.config', 'gerrit/acls/stackforge/ec2-driver.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/stackforge/puppet-ceph.config', 'gerrit/acls/openstack/tempest.config', 'gerrit/acls/stackforge/congress.config', 'gerrit/acls/stackforge/murano.config', 'gerrit/acls/openstack/trove-integration.config', 'gerrit/acls/stackforge/xenapi-os-testing.config', 'gerrit/acls/stackforge/yaql.config', 'gerrit/acls/openstack/oslo.vmware.config', 'gerrit/acls/openstack/sahara.config']",24,4bf53d27580f1f85b654482ecbc6d4b1a7118d09,normalize-acls,label-Workflow = -1..+1 group sahara-core,label-Workflow = -1..+1 group sahara-core,29,29
openstack%2Fdevstack-gate~master~Ibb3269a534d5b28b2d7d8a531e30a77ba6011f2d,openstack/devstack-gate,master,Ibb3269a534d5b28b2d7d8a531e30a77ba6011f2d,Give a more specific error message when giving up in git_remote_update,MERGED,2014-11-19 17:01:03.000000000,2014-12-15 14:36:47.000000000,2014-12-15 14:36:46.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4395}, {'_account_id': 5174}, {'_account_id': 6786}, {'_account_id': 7118}, {'_account_id': 8576}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-11-19 17:01:03.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/aed2c8b87cafd43a53775622f19312b6dcb47fe5', 'message': ""Give a more specific error message when giving up in git_remote_update\n\ngit_remote_update is intermittently failing in the gate but we don't\nhave a good error message in the devstack logs for this specific case\ndue to the retry loop (we don't get 100% failure on a query for the\nerror messages in there today).\n\nThis change adds a specific error message when we fail the retry\nattempts and exit so we can fingerprint on this with an elastic recheck\nquery.\n\nRelated-Bug: #1365046\n\nChange-Id: Ibb3269a534d5b28b2d7d8a531e30a77ba6011f2d\n""}]",0,135656,aed2c8b87cafd43a53775622f19312b6dcb47fe5,24,8,1,6873,,,0,"Give a more specific error message when giving up in git_remote_update

git_remote_update is intermittently failing in the gate but we don't
have a good error message in the devstack logs for this specific case
due to the retry loop (we don't get 100% failure on a query for the
error messages in there today).

This change adds a specific error message when we fail the retry
attempts and exit so we can fingerprint on this with an elastic recheck
query.

Related-Bug: #1365046

Change-Id: Ibb3269a534d5b28b2d7d8a531e30a77ba6011f2d
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/56/135656/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,aed2c8b87cafd43a53775622f19312b6dcb47fe5,bug/1365046," echo ""Max attempts reached for git remote update; giving up.""",,1,0
openstack%2Fheat~master~I4b8b658a58ad0ef09763e99e9da8948cf72fed48,openstack/heat,master,I4b8b658a58ad0ef09763e99e9da8948cf72fed48,Support cinder volume retype,MERGED,2014-11-27 04:31:06.000000000,2014-12-15 14:36:38.000000000,2014-12-15 14:36:36.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 6610}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-11-27 04:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/65e599ab726f5358d09483f29c177acea5571d90', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, so do nothing\nif the volume api version is in v1 for volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 2, 'created': '2014-11-28 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3496e02ffa7e09ee7c1298967e7ef37d158e01a0', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, so do nothing\nif the volume api version is in v1 for volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 3, 'created': '2014-12-02 01:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3ef6152b84e3d7d22bd517573d712a5923ecd1de', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, so do nothing\nif the volume api version is in v1 for volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 4, 'created': '2014-12-04 07:10:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8ffab74e2ef0f5e0fe9a64ec0e31634d1a73740a', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, so do nothing\nif the volume api version is in v1 for volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 5, 'created': '2014-12-05 01:58:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4e45216b9e701deadcb13862a2fc44dab13109ac', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, so do nothing\nif the volume api version is in v1 for volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 6, 'created': '2014-12-05 08:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/56aefecedce89432c687fd3f212d252d78f8659a', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 7, 'created': '2014-12-08 05:02:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae016886786a82fc846aa06933c3ae0f97aa15e9', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 8, 'created': '2014-12-09 03:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/616daf78bfe5946582cc53e6ea7fed868e64fb4a', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 9, 'created': '2014-12-10 03:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f90820ca4dee14288db172ad60bf93109438e697', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 10, 'created': '2014-12-11 01:46:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4a88db623c33ebc7e1b24534b032df20cd2b3e41', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}, {'number': 11, 'created': '2014-12-12 08:42:04.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9aafa787465e09cd5637656bfbae7f9f26784b2c', 'message': 'Support cinder volume retype\n\nMake volume_type updatable for cinder volume resource.\nNotes: this feature support in volume api v2, to raise\nNotSupported exception if the volume api version is v1\nfor volume_type updation.\n\nChange-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48\nCloses-Bug: #1395975\n'}]",15,137509,9aafa787465e09cd5637656bfbae7f9f26784b2c,59,12,11,8289,,,0,"Support cinder volume retype

Make volume_type updatable for cinder volume resource.
Notes: this feature support in volume api v2, to raise
NotSupported exception if the volume api version is v1
for volume_type updation.

Change-Id: I4b8b658a58ad0ef09763e99e9da8948cf72fed48
Closes-Bug: #1395975
",git fetch https://review.opendev.org/openstack/heat refs/changes/09/137509/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/tests/test_volume.py']",2,65e599ab726f5358d09483f29c177acea5571d90,bug/1395975," def test_cinder_volume_retype(self): fv = FakeVolume('creating', 'available', size=1, name='my_vol', description='test') stack_name = 'test_volume_retype' new_vol_type = 'new_type' self.patchobject(cinder.CinderClientPlugin, '_create', return_value=self.cinder_fc) self.patchobject(self.cinder_fc.volumes, 'create', return_value=fv) stack = utils.parse_stack(self.t, stack_name=stack_name) rsrc = self.create_volume(self.t, stack, 'volume2') props = copy.deepcopy(rsrc.properties.data) props['volume_type'] = new_vol_type after = rsrc_defn.ResourceDefinition(rsrc.name, rsrc.type(), props) self.patchobject(self.cinder_fc.volumes, 'retype') scheduler.TaskRunner(rsrc.update, after)() self.assertEqual((rsrc.UPDATE, rsrc.COMPLETE), rsrc.state) ",,32,2
openstack%2Fheat~master~I2860418b8d4ee8ec076c35836d48a2c60aea7274,openstack/heat,master,I2860418b8d4ee8ec076c35836d48a2c60aea7274,Add cinder volume type constraint for resources,MERGED,2014-12-12 08:00:17.000000000,2014-12-15 14:36:27.000000000,2014-12-15 14:36:27.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 6610}, {'_account_id': 14101}]","[{'number': 1, 'created': '2014-12-12 08:00:17.000000000', 'files': ['heat/tests/common.py', 'heat/engine/clients/os/cinder.py', 'heat/common/exception.py', 'heat/engine/resources/volume.py', 'heat/tests/test_cinder_client.py', 'heat/tests/test_sahara_templates.py', 'heat/engine/resources/sahara_templates.py', 'heat/tests/test_volume.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/heat/commit/537860e2f9db7ff9dfed9f7a2b74687600e096be', 'message': 'Add cinder volume type constraint for resources\n\nAdd cinder volume type constraint for resources.\n\nChange-Id: I2860418b8d4ee8ec076c35836d48a2c60aea7274\nNotes: missed in bp/cinder-custom-constraints\n'}]",0,141295,537860e2f9db7ff9dfed9f7a2b74687600e096be,10,5,1,8289,,,0,"Add cinder volume type constraint for resources

Add cinder volume type constraint for resources.

Change-Id: I2860418b8d4ee8ec076c35836d48a2c60aea7274
Notes: missed in bp/cinder-custom-constraints
",git fetch https://review.opendev.org/openstack/heat refs/changes/95/141295/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/common.py', 'heat/engine/clients/os/cinder.py', 'heat/common/exception.py', 'heat/engine/resources/volume.py', 'heat/tests/test_cinder_client.py', 'heat/tests/test_sahara_templates.py', 'heat/engine/resources/sahara_templates.py', 'heat/tests/test_volume.py', 'setup.cfg']",9,537860e2f9db7ff9dfed9f7a2b74687600e096be,bp/cinder-custom-constraints-p2, cinder.vtype = heat.engine.clients.os.cinder:VolumeTypeConstraint,,63,2
openstack%2Fheat~master~I5698206bce16ef09a80fc44c36cb49b155b31365,openstack/heat,master,I5698206bce16ef09a80fc44c36cb49b155b31365,Add cinder volume constraint for Cinder Volume,MERGED,2014-12-12 06:38:14.000000000,2014-12-15 14:36:18.000000000,2014-12-15 14:36:17.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-12-12 06:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6a34a9cc8efa29bcc29e1d0bfc221e524ca01af0', 'message': ""Add cinder volume constraint for Cinder Volume\n\nAdd cinder volume constraint for Cinder Volume resource.\n\nNotes: missed for 'source_volid' property in\nbp/cinder-custom-constraints\n\nChange-Id: I5698206bce16ef09a80fc44c36cb49b155b31365\n""}, {'number': 2, 'created': '2014-12-12 08:00:17.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d91f36a6213d646816a3a3fa3bc8c95358fe1cf8', 'message': ""Add cinder volume constraint for Cinder Volume\n\nAdd cinder volume constraint for Cinder Volume resource.\n\nNotes: missed for 'source_volid' property in\nbp/cinder-custom-constraints\n\nChange-Id: I5698206bce16ef09a80fc44c36cb49b155b31365\n""}]",0,141284,d91f36a6213d646816a3a3fa3bc8c95358fe1cf8,13,7,2,8289,,,0,"Add cinder volume constraint for Cinder Volume

Add cinder volume constraint for Cinder Volume resource.

Notes: missed for 'source_volid' property in
bp/cinder-custom-constraints

Change-Id: I5698206bce16ef09a80fc44c36cb49b155b31365
",git fetch https://review.opendev.org/openstack/heat refs/changes/84/141284/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/tests/test_volume.py']",2,6a34a9cc8efa29bcc29e1d0bfc221e524ca01af0,bp/cinder-custom-constraints-p2, self.stub_VolumeConstraint_validate(),,5,1
openstack%2Ftripleo-ci~master~Iba2e52d2ce0e5c25c1ad7945bd4f8f1622432be6,openstack/tripleo-ci,master,Iba2e52d2ce0e5c25c1ad7945bd4f8f1622432be6,Force install of mariadb.i686 1:5.5.39-1.fc20,MERGED,2014-12-12 17:11:34.000000000,2014-12-15 14:32:04.000000000,2014-12-15 14:32:04.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1726}, {'_account_id': 1926}, {'_account_id': 6133}]","[{'number': 1, 'created': '2014-12-12 17:11:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/95c35b92db1b4c8b65927e28e265df6e49a2de84', 'message': 'Force install of mariadb.i686 1:5.5.39-1.fc20\n\nA Fedora update to this package is causing pip to fail to build\nthe mysql extension.\n\nUntil we get the problem fixed pull in a patch that forces\ntripleo-image-elements to install the old version.\n\nRelated-Bug: #1401957\nChange-Id: Iba2e52d2ce0e5c25c1ad7945bd4f8f1622432be6\n'}, {'number': 2, 'created': '2014-12-15 12:28:18.000000000', 'files': ['toci_devtest.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e7563c5477e12a7ad8e84d0618650da1f8a9d7c7', 'message': 'Force install of mariadb.i686 1:5.5.39-1.fc20\n\nA Fedora update to this package is causing pip to fail to build\nthe mysql extension.\n\nUntil we get the problem fixed pull in a patch that forces\ndib to install the old version. Doing this in tripleo-image-elements\nwould also work but needs to be done in multiple places since this is\nfor ci only doing it here should be fine.\n\nRelated-Bug: #1401957\nChange-Id: Iba2e52d2ce0e5c25c1ad7945bd4f8f1622432be6\n'}]",0,141430,e7563c5477e12a7ad8e84d0618650da1f8a9d7c7,14,5,2,1926,,,0,"Force install of mariadb.i686 1:5.5.39-1.fc20

A Fedora update to this package is causing pip to fail to build
the mysql extension.

Until we get the problem fixed pull in a patch that forces
dib to install the old version. Doing this in tripleo-image-elements
would also work but needs to be done in multiple places since this is
for ci only doing it here should be fine.

Related-Bug: #1401957
Change-Id: Iba2e52d2ce0e5c25c1ad7945bd4f8f1622432be6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/30/141430/2 && git format-patch -1 --stdout FETCH_HEAD,['toci_devtest.sh'],1,95c35b92db1b4c8b65927e28e265df6e49a2de84,,cherrypick tripleo-image-elements refs/changes/29/141429/1,,1,0
openstack%2Fpuppet-nova~master~Iecd247d35c9041ff865544b07811d728c27cf919,openstack/puppet-nova,master,Iecd247d35c9041ff865544b07811d728c27cf919,Initial rspec-beaker testing scaffolding,MERGED,2014-06-23 21:36:27.000000000,2014-12-15 14:31:31.000000000,2014-12-15 14:31:30.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6554}, {'_account_id': 7155}, {'_account_id': 7822}, {'_account_id': 8482}, {'_account_id': 8617}]","[{'number': 1, 'created': '2014-06-23 21:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/aab99adfa7c74e914783de729639f5011056572d', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 2, 'created': '2014-06-23 23:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/533a735297fca0e37435925dbb9f6f33aec186c0', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 3, 'created': '2014-06-24 00:58:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c2c36938da3cd94cea2ed2f34fdc0e1f0ed20f55', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 4, 'created': '2014-07-02 01:01:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/23b35063bad6f2d21c58c92f3ce6e27917248b86', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 5, 'created': '2014-07-03 00:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ddcf97560274ac8ce6d3d1644ac03a3efb9ac64f', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 6, 'created': '2014-07-03 20:38:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/fb1a041407e23595db785afcb4aaacfbf40afc2c', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 7, 'created': '2014-07-03 20:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/423018d9fcc2868755d632c7a3276d8fd76fcf79', 'message': 'Initial rspec-beaker testing scaffolding\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 8, 'created': '2014-08-12 01:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/550ab4c92001ac5f1cf00a2288ef8f6a0afaf68d', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 9, 'created': '2014-10-02 07:48:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6152a5534df7dbadf57a413a3cb4408c9ce049b0', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 10, 'created': '2014-10-02 22:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/9ece9b75c6b3e3e9c7e8c69799e13947347bfbf7', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 11, 'created': '2014-10-21 22:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1e4fd8b3207908752cd489c37ec7e35f75ca023e', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 12, 'created': '2014-11-04 10:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/162d6f2ae3a11c114d9bc93f6b439f48ab63ccaf', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}, {'number': 13, 'created': '2014-11-27 00:28:14.000000000', 'files': ['spec/acceptance/nodesets/nodepool.yml', 'spec/acceptance/nodesets/default.yml', '.gitignore', 'Gemfile', 'spec/acceptance/nodesets/centos-64-x64.yml', 'spec/acceptance/class_spec.rb', 'spec/spec_helper_acceptance.rb', 'README.md'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/14c16142e0f91949f90774beb03e221cb33a6e36', 'message': 'Initial rspec-beaker testing scaffolding\n\nThis allows basic beaker testing to be performed inside\nthe openstack testing framework.\n\nChange-Id: Iecd247d35c9041ff865544b07811d728c27cf919\n'}]",28,102020,14c16142e0f91949f90774beb03e221cb33a6e36,81,7,13,6554,,,0,"Initial rspec-beaker testing scaffolding

This allows basic beaker testing to be performed inside
the openstack testing framework.

Change-Id: Iecd247d35c9041ff865544b07811d728c27cf919
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/20/102020/12 && git format-patch -1 --stdout FETCH_HEAD,"['spec/acceptance/nodesets/default.yml', 'spec/acceptance/class_spec.rb', 'spec/acceptance/nodesets/centos-64-x64.yml', 'spec/spec_helper_acceptance.rb']",4,aab99adfa7c74e914783de729639f5011056572d,102020,"require 'beaker-rspec' hosts.each do |host| # Install Puppet install_package host, 'rubygems' on host, 'gem install puppet --no-ri --no-rdoc' on host, ""mkdir -p #{host['distmoduledir']}"" end RSpec.configure do |c| # Project root proj_root = File.expand_path(File.join(File.dirname(__FILE__), '..')) # Readable test descriptions c.formatter = :documentation # Configure all nodes in nodeset c.before :suite do # Install module puppet_module_install(:source => proj_root, :module_name => 'puppetboard') hosts.each do |host| on host, puppet('module','install','puppetlabs-stdlib'), { :acceptable_exit_codes => [0,1] } on host, puppet('module','install','stankevich-python'), { :acceptable_exit_codes => [0,1] } on host, puppet('module','install','puppetlabs-vcsrepo'), { :acceptable_exit_codes => [0,1] } end end end ",,77,0
openstack%2Fmagnetodb~master~I7886052cba8edc7025f4e118b0e24d49cfb0395a,openstack/magnetodb,master,I7886052cba8edc7025f4e118b0e24d49cfb0395a,Investigate gate problem,ABANDONED,2014-12-15 11:42:46.000000000,2014-12-15 14:28:14.000000000,,"[{'_account_id': 3}, {'_account_id': 10676}]","[{'number': 1, 'created': '2014-12-15 11:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/c1c622ebbd31e7d8d786b8f95f8021e6d4c9064a', 'message': 'Investigate gate problem\n\nChange-Id: I7886052cba8edc7025f4e118b0e24d49cfb0395a\n'}, {'number': 2, 'created': '2014-12-15 12:05:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/98cb6518b43d43ffba8458d018ee12c19b46ccc0', 'message': 'Investigate gate problem\n\nChange-Id: I7886052cba8edc7025f4e118b0e24d49cfb0395a\n'}, {'number': 3, 'created': '2014-12-15 12:45:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/2913f8aa382830ed1a728eb332beffe5144cd99c', 'message': 'Investigate gate problem\n\nChange-Id: I7886052cba8edc7025f4e118b0e24d49cfb0395a\n'}, {'number': 4, 'created': '2014-12-15 12:47:31.000000000', 'files': ['functionaltests/pre_test_hook.sh', 'contrib/devstack/extras.d/70-magnetodb.sh', 'functionaltests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/magnetodb/commit/e2b130179313abf889f79eb1c11b2adab34c8619', 'message': 'Investigate gate problem\n\nChange-Id: I7886052cba8edc7025f4e118b0e24d49cfb0395a\n'}]",0,141772,e2b130179313abf889f79eb1c11b2adab34c8619,9,2,4,10676,,,0,"Investigate gate problem

Change-Id: I7886052cba8edc7025f4e118b0e24d49cfb0395a
",git fetch https://review.opendev.org/openstack/magnetodb refs/changes/72/141772/4 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/extras.d/70-magnetodb.sh'],1,c1c622ebbd31e7d8d786b8f95f8021e6d4c9064a,,,,0,0
openstack%2Fopenstack-manuals~master~I6b6c28956f3148d955f35e2da3818475f7250c11,openstack/openstack-manuals,master,I6b6c28956f3148d955f35e2da3818475f7250c11,Add XML markup <replaceable>,MERGED,2014-12-15 00:17:38.000000000,2014-12-15 14:24:02.000000000,2014-12-15 14:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-12-15 00:17:38.000000000', 'files': ['doc/install-guide/section_ceilometer-nova.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/982dd4c7d2af37b7c54f7279503714a904a27b36', 'message': 'Add XML markup <replaceable>\n\nChange-Id: I6b6c28956f3148d955f35e2da3818475f7250c11\n'}]",0,141676,982dd4c7d2af37b7c54f7279503714a904a27b36,8,4,1,10497,,,0,"Add XML markup <replaceable>

Change-Id: I6b6c28956f3148d955f35e2da3818475f7250c11
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/76/141676/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_ceilometer-nova.xml'],1,982dd4c7d2af37b7c54f7279503714a904a27b36,add-markup, <para>Replace <replaceable>CEILOMETER_PASS</replaceable> with the password you chose for the, <para>Replace CEILOMETER_PASS with the password you chose for the,1,1
openstack%2Fceilometer~master~Iaedee8d6be6b58147413295b39d8d8b152caa39a,openstack/ceilometer,master,Iaedee8d6be6b58147413295b39d8d8b152caa39a,Refactor kwapi unit test,MERGED,2014-06-19 08:46:43.000000000,2014-12-15 14:23:54.000000000,2014-12-15 14:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 8871}, {'_account_id': 10987}, {'_account_id': 13273}]","[{'number': 1, 'created': '2014-06-19 08:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/22b1b99751b459571007d46219a2cd72a81c456d', 'message': 'Refactor kwapi unit test\n\nceilometer/tests/energy/test_kwapi.py has very similar test cases,\nthis patch refactors those unit test code.\n\nChange-Id: Iaedee8d6be6b58147413295b39d8d8b152caa39a\n'}, {'number': 2, 'created': '2014-06-19 11:00:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/424543dce4e5ebfffc3b898697219773e5063e11', 'message': 'Refactor kwapi unit test\n\nceilometer/tests/energy/test_kwapi.py has very similar test cases,\nthis patch refactors those unit test code.\n\nChange-Id: Iaedee8d6be6b58147413295b39d8d8b152caa39a\n'}, {'number': 3, 'created': '2014-06-27 03:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/708fec0849e3dadd58a2a69938a72c5ea638555e', 'message': 'Refactor kwapi unit test\n\nceilometer/tests/energy/test_kwapi.py has very similar test cases,\nthis patch refactors those unit test code.\n\nChange-Id: Iaedee8d6be6b58147413295b39d8d8b152caa39a\n'}, {'number': 4, 'created': '2014-11-07 02:34:39.000000000', 'files': ['ceilometer/tests/energy/test_kwapi.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0c960dc0a2536323bf54fdc30f4ba16d675c02de', 'message': 'Refactor kwapi unit test\n\nceilometer/tests/energy/test_kwapi.py has very similar test cases,\nthis patch refactors those unit test code.\n\nChange-Id: Iaedee8d6be6b58147413295b39d8d8b152caa39a\n'}]",15,101134,0c960dc0a2536323bf54fdc30f4ba16d675c02de,47,12,4,6676,,,0,"Refactor kwapi unit test

ceilometer/tests/energy/test_kwapi.py has very similar test cases,
this patch refactors those unit test code.

Change-Id: Iaedee8d6be6b58147413295b39d8d8b152caa39a
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/34/101134/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/tests/energy/test_kwapi.py'],1,22b1b99751b459571007d46219a2cd72a81c456d,kwapi-ut-refactor,"class _BaseTestCase(test.BaseTestCase): super(_BaseTestCase, self).setUp() class TestKwapi(_BaseTestCase): class _TestPollster(_BaseTestCase): pollster_cls = kwapi.EnergyPollster unit = 'kwh' def setUp(self): super(_TestPollster, self).setUp() samples = list(self.pollster_cls().get_samples(self.manager, cache)) self.assertEqual(len(PROBE_DICT['probes']), len(samples)) self.assertEqual(probe[self.unit], sample.volume) class TestEnergyPollster(_TestPollster): pass class TestPowerPollster(_TestPollster): pollster_cls = kwapi.PowerPollster unit = 'w' class _TestPollsterCache(_BaseTestCase): pollster_cls = kwapi.EnergyPollster self.pollster_cls.CACHE_KEY_PROBE: [probe], } pollster = self.pollster_cls()class TestEnergyPollsterCache(_TestPollsterCache): pass class TestPowerPollsterCache(_TestPollsterCache): pollster_cls = kwapi.PowerPollster","class TestKwapi(test.BaseTestCase): super(TestKwapi, self).setUp()class TestEnergyPollster(test.BaseTestCase): @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def setUp(self): super(TestEnergyPollster, self).setUp() self.context = context.get_admin_context() self.manager = TestManager() samples = list(kwapi.EnergyPollster().get_samples( self.manager, cache, )) self.assertEqual(3, len(samples)) self.assertEqual(probe['kwh'], sample.volume) # self.assert_( # any(map(lambda sample: sample.volume == probe['w'], # power_samples))) class TestEnergyPollsterCache(test.BaseTestCase): @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def setUp(self): super(TestEnergyPollsterCache, self).setUp() self.context = context.get_admin_context() self.manager = TestManager() kwapi.EnergyPollster.CACHE_KEY_PROBE: [probe], } self.manager.keystone = mock.Mock() pollster = kwapi.EnergyPollster()class TestPowerPollster(test.BaseTestCase): @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def setUp(self): super(TestPowerPollster, self).setUp() self.context = context.get_admin_context() self.manager = TestManager() self.useFixture(PatchObject(kwapi._Base, '_iter_probes', side_effect=self.fake_iter_probes)) @staticmethod def fake_iter_probes(ksclient, cache): probes = PROBE_DICT['probes'] for key, value in probes.iteritems(): probe_dict = value probe_dict['id'] = key yield probe_dict def test_sample(self): cache = {} samples = list(kwapi.PowerPollster().get_samples( self.manager, cache, )) self.assertEqual(3, len(samples)) samples_by_name = dict((s.resource_id, s) for s in samples) for name, probe in PROBE_DICT['probes'].items(): sample = samples_by_name[name] expected = datetime.datetime.fromtimestamp( probe['timestamp'] ).isoformat() self.assertEqual(expected, sample.timestamp) self.assertEqual(probe['w'], sample.volume) class TestPowerPollsterCache(test.BaseTestCase): @mock.patch('ceilometer.pipeline.setup_pipeline', mock.MagicMock()) def setUp(self): super(TestPowerPollsterCache, self).setUp() self.context = context.get_admin_context() self.manager = TestManager() def test_get_samples_cached(self): probe = {'id': 'A'} probe.update(PROBE_DICT['probes']['A']) cache = { kwapi.PowerPollster.CACHE_KEY_PROBE: [probe], } self.manager.keystone = mock.Mock() pollster = kwapi.PowerPollster() with mock.patch.object(pollster, '_get_probes') as do_not_call: do_not_call.side_effect = AssertionError('should not be called') samples = list(pollster.get_samples(self.manager, cache)) self.assertEqual(1, len(samples))",28,78
openstack%2Fpython-saharaclient~master~I8818c77a96685c8a557aa6fec77002c93064118e,openstack/python-saharaclient,master,I8818c77a96685c8a557aa6fec77002c93064118e,"Set default service_type to ""data-processing"" in client",MERGED,2014-12-02 12:07:47.000000000,2014-12-15 14:10:08.000000000,2014-12-15 11:01:01.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-02 12:07:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/725af5977363b3014fa07a8bec825fe02a7e4f0b', 'message': 'Set default service_type to ""data-processing"" in client\n\nWe\'re using the default value in many places, so, we should switch it\nto the data-processing by default. The fallback mechanism is already\nimplemented, so, backward compatibility supported.\n\nChange-Id: I8818c77a96685c8a557aa6fec77002c93064118e\nPartial-bug: #1356053\n'}, {'number': 2, 'created': '2014-12-02 12:09:50.000000000', 'files': ['saharaclient/api/client.py'], 'web_link': 'https://opendev.org/openstack/python-saharaclient/commit/be164236407d8bc3937292062969d8ea0ba946c0', 'message': 'Set default service_type to ""data-processing"" in client\n\nWe\'re using the default value in many places, so, we should switch it\nto the data-processing by default. The fallback mechanism is already\nimplemented, so, backward compatibility supported.\n\nIt\'s needed to make CLI support both endpoints.\n\nChange-Id: I8818c77a96685c8a557aa6fec77002c93064118e\nPartial-bug: #1356053'}]",0,138332,be164236407d8bc3937292062969d8ea0ba946c0,85,10,2,6786,,,0,"Set default service_type to ""data-processing"" in client

We're using the default value in many places, so, we should switch it
to the data-processing by default. The fallback mechanism is already
implemented, so, backward compatibility supported.

It's needed to make CLI support both endpoints.

Change-Id: I8818c77a96685c8a557aa6fec77002c93064118e
Partial-bug: #1356053",git fetch https://review.opendev.org/openstack/python-saharaclient refs/changes/32/138332/1 && git format-patch -1 --stdout FETCH_HEAD,['saharaclient/api/client.py'],1,725af5977363b3014fa07a8bec825fe02a7e4f0b,bug/1356053," endpoint_type='publicURL', service_type='data-processing',"," endpoint_type='publicURL', service_type='data_processing',",1,1
openstack%2Ffuel-main~master~Ia79ca9deef436357bcec19e78611c3b228874e63,openstack/fuel-main,master,Ia79ca9deef436357bcec19e78611c3b228874e63,Add decorator to check Fuel statistics sending,MERGED,2014-10-29 23:43:17.000000000,2014-12-15 14:10:03.000000000,2014-12-15 14:10:03.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8392}, {'_account_id': 8882}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 10959}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}]","[{'number': 1, 'created': '2014-10-29 23:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/eec91b5f968862f5eebb0a2a2d01338635168522', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 2, 'created': '2014-10-29 23:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/64fbed8756f515c22908b2beef176ac806fe855f', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 3, 'created': '2014-10-30 07:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/18eccec0ad74e84a7164d2dfd9eb81dc8b460904', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 4, 'created': '2014-10-30 08:52:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/26f2c70e95ba8d30aab1c2081a5ef8c66ebbfa6f', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 5, 'created': '2014-11-06 11:46:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3bf403f93a3a9cbcee20b3490dcd30d31740e9eb', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 6, 'created': '2014-11-06 11:54:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a5261ab56d1438e66241a1a921cd4dffc0f50a72', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 7, 'created': '2014-11-06 11:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/583ad0160d8957d6c2bc43d7eb9c153281e0a6c3', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 8, 'created': '2014-11-06 12:22:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/4544b077db0af160077eab58f4b9124f7e515788', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. Also it expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 9, 'created': '2014-11-19 09:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/12f10d781ecc7bb054807c6bc02d9e4be7b63a6f', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 10, 'created': '2014-11-19 13:46:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/50b4db13e62881d2f9ab74780f15af921e459967', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 11, 'created': '2014-11-19 14:44:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e5114eff4184592bc36288b183e1fa84e3eb9689', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 12, 'created': '2014-12-02 16:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6f5262ee04ce3a9db27fbf898c4a0d2d54b19a0a', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 13, 'created': '2014-12-02 16:25:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/275a67c046aa83f91fe03eb3ccf843c07b388054', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 14, 'created': '2014-12-11 17:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fea94ef33937adc7f04525e86472555199619fdd', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly. It expects that collector\nhost permit login via SSH using RSA key located in user's\nhome directory.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 15, 'created': '2014-12-12 14:18:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0ecaf5a6fa5663356991eec2df68316ddb88ced6', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly.\nIt expects that collector host permit login via SSH using\nRSA key located in user's home directory.\nIf sending of usage stats isn't enabled in tests, decorator\nwill check that statistics wasn't sent.\nAlso verify the absence of private info (e.g. passwords,\nIPs, nodes names) in collected data.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 16, 'created': '2014-12-12 14:39:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b7b2c18431b53306b785a65777dd5b2f426af5ff', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly.\nIt expects that collector host permit login via SSH using\nRSA key located in user's home directory.\nIf sending of usage stats isn't enabled in tests, decorator\nwill check that statistics wasn't sent.\nAlso verify the absence of private info (e.g. passwords,\nIPs, nodes names) in collected data.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}, {'number': 17, 'created': '2014-12-14 22:34:15.000000000', 'files': ['fuelweb_test/helpers/decorators.py', 'fuelweb_test/helpers/fuel_actions.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/helpers/checkers.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/e20ff6ddc4748d2a32511c472d3bcf510925f7df', 'message': ""Add decorator to check Fuel statistics sending\n\nAdd new decorator which can parse test docstring to\ndetermine what actions were performed during the test and\nthen check that they were logged and sent to statistics\ncollector service properly.\nIt expects that collector host permit login via SSH using\nRSA key located in user's home directory.\nIf sending of usage stats isn't enabled in tests, decorator\nwill check that statistics wasn't sent.\nAlso verify the absence of private info (e.g. passwords,\nIPs, nodes names) in collected data.\n\nChange-Id: Ia79ca9deef436357bcec19e78611c3b228874e63\nImplements: blueprint fuel-stats-test\n""}]",17,131895,e20ff6ddc4748d2a32511c472d3bcf510925f7df,90,11,17,11081,,,0,"Add decorator to check Fuel statistics sending

Add new decorator which can parse test docstring to
determine what actions were performed during the test and
then check that they were logged and sent to statistics
collector service properly.
It expects that collector host permit login via SSH using
RSA key located in user's home directory.
If sending of usage stats isn't enabled in tests, decorator
will check that statistics wasn't sent.
Also verify the absence of private info (e.g. passwords,
IPs, nodes names) in collected data.

Change-Id: Ia79ca9deef436357bcec19e78611c3b228874e63
Implements: blueprint fuel-stats-test
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/95/131895/17 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/helpers/decorators.py', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_simple.py', 'fuelweb_test/helpers/checkers.py']",5,eec91b5f968862f5eebb0a2a2d01338635168522,bp/fuel-stats-test," @logwrap def action_logs_contains(remote, action_name, table='action_logs'): logger.debug(""Checking that '{0}' action was added to logs..."".format( action_name)) cmd = (""PGPASSWORD=$(awk '/nailgun_password:/{{print $2}}' "" ""/etc/fuel/astute.yaml) dockerctl shell postgres psql"" "" -qt -h 127.0.0.1 -U nailgun nailgun -c \""select "" ""id from {0} where action_name = '{1}';\"""").format(table, action_name) logs = [id for id in ''.join(remote.execute(cmd)['stdout']).strip().split('\n') if re.compile(""\d+"").match(id)] logger.debug(""Found logs with ids: {0}"".format(logs)) if len(logs) > 0: return True else: return False @logwrap def get_count_of_sent_action_logs(remote, table='action_logs'): cmd = (""PGPASSWORD=$(awk '/nailgun_password:/{{print $2}}' "" ""/etc/fuel/astute.yaml) dockerctl shell postgres psql"" "" -qt -h 127.0.0.1 -U nailgun nailgun -c \""select "" ""count(id) from {0} where is_sent = True;\"""").format(table) return int(''.join(remote.execute(cmd)['stdout']).strip()) @logwrap def check_fuel_stats_on_collector(admin_remote, collector_remote, master_uuid, collector_db='collector', collector_db_user='collector', collector_db_pass='collector'): sent_logs_count = get_count_of_sent_action_logs(admin_remote) cmd = ('PGPASSWORD={0} psql -qt -h 127.0.0.1 -U {1} -d {2} -c ' '""select count(*) from action_logs where master_node_uid' ' = \'{3}\';""').format(collector_db_pass, collector_db_user, collector_db, master_uuid) logs_count = int(''.join(collector_remote.execute(cmd)['stdout']).strip()) assert_equal(sent_logs_count, logs_count, (""Count of action logs in Nailgun DB ({0}) and on Collector "" ""({1}) aren't equal"").format(sent_logs_count, logs_count)) cmd = ('PGPASSWORD={0} psql -qt -h 127.0.0.1 -U {1} -d {2} -c ' '""select count(*) from installation_structs where master_node_uid' ' = \'{3}\';""').format(collector_db_pass, collector_db_user, collector_db, master_uuid) install = int(''.join(collector_remote.execute(cmd)['stdout']).strip()) assert_equal(install, 1, (""Installation structure wasn't saved on "" ""Collector side properly: found {0} records""). format(install))",,131,0
openstack%2Frally~master~Ib4121f442196989ce77d6e3081f4288d35c52098,openstack/rally,master,Ib4121f442196989ce77d6e3081f4288d35c52098,Small refactor in run function,MERGED,2014-12-15 11:56:21.000000000,2014-12-15 13:49:33.000000000,2014-12-15 13:49:32.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 9545}, {'_account_id': 12395}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-15 11:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b0c8ee94633117d16ad5832d5c60287ae9ee2e0e', 'message': 'mall refactor in run function\n\nThis patch properly print in the debug the exception that might\nocurr when rally calls the cmd.cliutils.run command\n\nChange-Id: Ib4121f442196989ce77d6e3081f4288d35c52098\n'}, {'number': 2, 'created': '2014-12-15 12:17:32.000000000', 'files': ['rally/cmd/cliutils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/193b6b66daf213de2b98219d0762e91c253e9c80', 'message': 'Small refactor in run function\n\nThis patch properly print in the debug the exception that might\nocurr when rally calls the cmd.cliutils.run command\n\nChange-Id: Ib4121f442196989ce77d6e3081f4288d35c52098\n'}]",0,141776,193b6b66daf213de2b98219d0762e91c253e9c80,12,5,2,8367,,,0,"Small refactor in run function

This patch properly print in the debug the exception that might
ocurr when rally calls the cmd.cliutils.run command

Change-Id: Ib4121f442196989ce77d6e3081f4288d35c52098
",git fetch https://review.opendev.org/openstack/rally refs/changes/76/141776/1 && git format-patch -1 --stdout FETCH_HEAD,['rally/cmd/cliutils.py'],1,b0c8ee94633117d16ad5832d5c60287ae9ee2e0e,," except (IOError, TypeError, exceptions.DeploymentNotFound, exceptions.TaskNotFound) as e:"," except (IOError, TypeError, exceptions.DeploymentNotFound) as e: if logging.is_debug(): raise print(e) return 1 except exceptions.TaskNotFound as e:",2,6
openstack%2Ftricircle~master~I48032a466319959ec22a9a0044234e1d4d1bf8ea,openstack/tricircle,master,I48032a466319959ec22a9a0044234e1d4d1bf8ea,store cinderclient for admin user in proxy cache ,MERGED,2014-12-15 13:45:58.000000000,2014-12-15 13:47:34.000000000,2014-12-15 13:47:34.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-15 13:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/b7d6181ae48cea1f21a3e5955c744ee88b2e56b5', 'message': 'store cinderclient for admin user in cache w\n\nChange-Id: I48032a466319959ec22a9a0044234e1d4d1bf8ea\n'}, {'number': 2, 'created': '2014-12-15 13:46:55.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/6d4182e47ae583fe9329d15b8a8814805ce929c6', 'message': 'store cinderclient for admin user in proxy cache \n\nChange-Id: I48032a466319959ec22a9a0044234e1d4d1bf8ea\n'}]",0,141797,6d4182e47ae583fe9329d15b8a8814805ce929c6,8,2,2,13924,,,0,"store cinderclient for admin user in proxy cache 

Change-Id: I48032a466319959ec22a9a0044234e1d4d1bf8ea
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/97/141797/2 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,b7d6181ae48cea1f21a3e5955c744ee88b2e56b5,,"from cinderclient import exceptions as cinder_exception self.adminCinderClient = self._get_cinder_cascaded_admin_client() self._init_volume_mapping_cache() try: sear_op = {'all_tenants': True} volumes = self.adminCinderClient.volumes.list(search_opts=sear_op) self.adminCinderClient.volume_snapshots.list(search_opts=sear_op) sopt = {'all_tenants': True, 'sort_key': 'updated_at', 'sort_dir': 'desc', 'marker': marker, 'limit': page_limit, } vols = \ self.adminCinderClient.volumes.list(search_opts=sopt) sopt = {'all_tenants': True, 'changes-since': new_change_since_isotime} volumes = \ self.adminCinderClient.volumes.list(search_opts=sopt) return except cinder_exception.Unauthorized: self.adminCinderClient = self._get_cinder_cascaded_admin_client() return self._heal_volume_status(context) return volumetypes = self.adminCinderClient.volume_types.list() qosSpecs = self.adminCinderClient.qos_specs.list() qos = qos_cascaded._info['id'] self.adminCinderClient.qos_specs.get_associations(qos)"," self._init_volume_mapping_cache() cinderClient = self._get_cinder_cascaded_admin_client() try: search_op = {'all_tenants': True} volumes = cinderClient.volumes.list(search_opts=search_op) cinderClient.volume_snapshots.list(search_opts=search_op) cinderClient = self._get_cinder_cascaded_admin_client() search_opt = {'all_tenants': True, 'sort_key': 'updated_at', 'sort_dir': 'desc', 'marker': marker, 'limit': page_limit, } vols = cinderClient.volumes.list(search_opts=search_opt) search_op = {'all_tenants': True, 'changes-since': new_change_since_isotime} volumes = cinderClient.volumes.list(search_opts=search_op) cinderClient = self._get_cinder_cascaded_admin_client() volumetypes = cinderClient.volume_types.list() qosSpecs = cinderClient.qos_specs.list() qos_id = qos_cascaded._info['id'] cinderClient.qos_specs.get_associations(qos_id)",27,25
openstack%2Ffuel-web~master~Icf49bb534ccb19872402b66532ef44418bd66a53,openstack/fuel-web,master,Icf49bb534ccb19872402b66532ef44418bd66a53,Initial JSONSchema validation,MERGED,2014-12-04 11:33:01.000000000,2014-12-15 13:36:11.000000000,2014-12-15 13:36:10.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 12200}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-04 11:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/dbe2f78beefc72f1a3664740988f58e7185590db', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 2, 'created': '2014-12-04 12:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/018bf6a4aae4a1570f9ce0ffdab8e8c9138d0423', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 3, 'created': '2014-12-05 11:26:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/20b26bfc7e709339f6b1c1f71a054654352f8c40', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 4, 'created': '2014-12-05 12:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/17b6bbcd8fa379c1b90c7b60dd9fedc50d74c0c9', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 5, 'created': '2014-12-08 11:07:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c1e842459a0820815c7d3238ca5eef2129d5e4a4', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 6, 'created': '2014-12-09 11:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/74a6b248aae24179456ae2cc0b328b3901a52677', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 7, 'created': '2014-12-09 14:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8954936db2d30a09238c5dc16ef74c65730bce1a', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 8, 'created': '2014-12-11 13:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3cd6345fba515d899a419bfaedd56db862db0443', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 9, 'created': '2014-12-11 13:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/aeda55bf8eca229453580d275ef3b5feec440249', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 10, 'created': '2014-12-12 11:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ecd6ae86ad6b62179f9a90a159326208921173d7', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 11, 'created': '2014-12-12 15:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/affe098f5e8f6e4fb9d26e8a361f31db08b48847', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}, {'number': 12, 'created': '2014-12-15 10:09:19.000000000', 'files': ['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/api/v1/validators/json_schema/node.py', 'nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/handlers/notifications.py', 'nailgun/nailgun/api/v1/validators/json_schema/networks.py', 'nailgun/nailgun/api/v1/validators/json_schema/__init__.py', 'nailgun/nailgun/api/v1/handlers/capacity.py', 'nailgun/nailgun/api/v1/validators/json_schema/base_types.py', 'nailgun/nailgun/test/integration/test_attributes.py', 'nailgun/nailgun/test/integration/test_public_api.py', 'nailgun/nailgun/api/v1/validators/cluster.py', 'nailgun/nailgun/api/v1/handlers/tasks.py', 'nailgun/nailgun/api/v1/validators/node.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_node_handler.py', 'nailgun/nailgun/api/v1/validators/base.py', 'nailgun/nailgun/api/v1/handlers/logs.py', 'nailgun/nailgun/api/v1/handlers/orchestrator.py', 'nailgun/nailgun/api/v1/handlers/__init__.py', 'nailgun/nailgun/api/v1/handlers/disks.py', 'nailgun/nailgun/api/v1/validators/json_schema/cluster.py', 'nailgun/nailgun/api/v1/handlers/registration.py', 'nailgun/nailgun/api/v1/handlers/node_group.py', 'nailgun/nailgun/test/integration/test_node_collection_handlers.py', 'nailgun/nailgun/test/unit/test_handlers.py', 'nailgun/nailgun/api/v1/handlers/network_configuration.py', 'nailgun/nailgun/api/v1/handlers/release.py', 'nailgun/nailgun/api/v1/handlers/version.py', 'nailgun/nailgun/api/v1/handlers/assignment.py', 'nailgun/nailgun/api/v1/handlers/plugin.py', 'nailgun/nailgun/fake_keystone/handlers.py', 'nailgun/nailgun/api/v1/handlers/master_node_settings.py', 'nailgun/nailgun/api/v1/handlers/base.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7ba7a06ccd1637352091d2e0c85aa8d14138ffe9', 'message': 'Initial JSONSchema validation\n\n- errors are now returned as tracebacks, not HTML\n- added schema checking based on the handler type and validator\n- content_json decorator rewritten completely\n- common JSON types\n- creation of nodes with non-number ID is now forbidden according to scheme\n\nImplements: blueprint nailgun-api-requests-responses-validation\n\nChange-Id: Icf49bb534ccb19872402b66532ef44418bd66a53\n'}]",77,139020,7ba7a06ccd1637352091d2e0c85aa8d14138ffe9,100,13,12,8053,,,0,"Initial JSONSchema validation

- errors are now returned as tracebacks, not HTML
- added schema checking based on the handler type and validator
- content_json decorator rewritten completely
- common JSON types
- creation of nodes with non-number ID is now forbidden according to scheme

Implements: blueprint nailgun-api-requests-responses-validation

Change-Id: Icf49bb534ccb19872402b66532ef44418bd66a53
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/20/139020/7 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/handlers/node.py', 'nailgun/nailgun/api/v1/validators/json_schema/node.py', 'nailgun/nailgun/api/v1/handlers/cluster.py', 'nailgun/nailgun/api/v1/handlers/notifications.py', 'nailgun/nailgun/api/v1/validators/json_schema/__init__.py', 'nailgun/nailgun/api/v1/handlers/capacity.py', 'nailgun/nailgun/api/v1/validators/json_schema/base_types.py', 'nailgun/nailgun/test/integration/test_attributes.py', 'nailgun/nailgun/test/integration/test_public_api.py', 'nailgun/nailgun/api/v1/validators/cluster.py', 'nailgun/nailgun/api/v1/handlers/tasks.py', 'nailgun/nailgun/api/v1/validators/node.py', 'nailgun/nailgun/test/base.py', 'nailgun/nailgun/test/integration/test_node_handler.py', 'nailgun/nailgun/api/v1/validators/base.py', 'nailgun/nailgun/api/v1/handlers/logs.py', 'nailgun/nailgun/api/v1/handlers/orchestrator.py', 'nailgun/nailgun/api/v1/handlers/disks.py', 'nailgun/nailgun/api/v1/validators/json_schema/cluster.py', 'nailgun/nailgun/api/v1/handlers/registration.py', 'nailgun/nailgun/api/v1/handlers/node_group.py', 'nailgun/nailgun/test/integration/test_node_collection_handlers.py', 'nailgun/nailgun/api/v1/handlers/network_configuration.py', 'nailgun/nailgun/api/v1/handlers/release.py', 'nailgun/nailgun/api/v1/handlers/version.py', 'nailgun/nailgun/api/v1/handlers/assignment.py', 'nailgun/nailgun/api/v1/handlers/plugin.py', 'nailgun/nailgun/fake_keystone/handlers.py', 'nailgun/nailgun/api/v1/handlers/master_node_settings.py', 'nailgun/nailgun/api/v1/handlers/base.py']",30,dbe2f78beefc72f1a3664740988f58e7185590db,bp/nailgun-api-requests-responses-validation,"import traceback @classmethod def checked_data(cls, validate_method=None, **kwargs): method = validate_method or cls.validator.validate raise cls.http(400, exc.message) raise cls.http(403, exc.message) raise cls.http(409, exc.message) raise cls.http(400, exc.message) raise cls.http(404, exc.message) except Exception as exc: raise cls.http(500, traceback.format_exc())def content_json(func, *args, **kwargs): web.header('Content-Type', 'application/json') json_resp = lambda data: ( jsonutils.dumps(data) if isinstance(data, (dict, list)) else data ) validate_needed = True cls = args[0].__class__ resource_type = ""single"" if issubclass(cls, CollectionHandler) and not func.func_name == ""POST"": resource_type = ""collection"" if ( func.func_name in (""GET"", ""DELETE"") or not hasattr(cls, ""validator"") or cls.validator is None or resource_type == ""single"" and not cls.validator.single_schema or resource_type == ""collection"" and not cls.validator.collection_schema ): validate_needed = False if validate_needed: BaseHandler.checked_data( cls.validator.validate_request, resource_type=resource_type ) try: resp = func(*args, **kwargs) except web.notmodified: raise except web.HTTPError as http_error: http_error.data = json_resp(http_error.data) raise if validate_needed: BaseHandler.checked_data( cls.validator.validate_response, resource_type=resource_type ) return json_resp(resp) def content(mimetype): @decorator def wrapper(func, *args, **kwargs): return { ""json"": content_json }.get(mimetype)(func, *args, **kwargs) return wrapper @content(""json"") @content(""json"") @content(""json"") @content(""json"") @content(""json"")","@decorator def content_json(func, *args, **kwargs): try: data = func(*args, **kwargs) except web.notmodified: raise except web.HTTPError as http_error: web.header('Content-Type', 'application/json') if isinstance(http_error.data, (dict, list)): http_error.data = build_json_response(http_error.data) raise web.header('Content-Type', 'application/json') return build_json_response(data) def build_json_response(data): web.header('Content-Type', 'application/json') if type(data) in (dict, list): return jsonutils.dumps(data) return data def checked_data(self, validate_method=None, **kwargs): method = validate_method or self.validator.validate raise self.http(400, exc.message) raise self.http(403, exc.message) raise self.http(409, exc.message) raise self.http(400, exc.message) raise self.http(404, exc.message) except Exception as exc: raise @content_json @content_json @content_json @content_json @content_json",446,179
openstack%2Ffuel-web~master~Ia886d8d15cf63af4dc2b85928eb124d931d9c21d,openstack/fuel-web,master,Ia886d8d15cf63af4dc2b85928eb124d931d9c21d,Add test upgrader intended to use in system tests,MERGED,2014-12-11 15:51:37.000000000,2014-12-15 13:28:44.000000000,2014-12-15 13:28:44.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-12-11 15:51:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2c2e385cabbcb0a66f74c3f0a3dedfed9125b482', 'message': 'Add test upgrader intended to use in system tests\n\nIn order to test the rollback feature we used to inject raising error\ncode in one of our upgraders in-place:\n\n    self.fuel_web.modify_python_file(self.env.get_admin_remote(),\n                                    ""61i \\ \\ \\ \\ \\ \\ \\ \\ raise errors.""\n                                    ""ExecutedErrorNonZeroExitCode(\'{0}\')""\n                                    .format(\'Some bad error\'),\n                                    \'/var/upgrade/site-packages/\'\n                                    \'fuel_upgrade/engines/\'\n                                    \'openstack.py\')\n\nIt\'s a bad design decision which leads to time-to-time falls in tests due\nto changes in the upgrader\'s code. So the commit is going to solve this\nissue by providing a special upgrader which will always fail.\n\nUsage example:\n\n    $ UPGRADERS=""host-system docker openstack raise-error"" ./upgrade.sh\n\nChange-Id: Ia886d8d15cf63af4dc2b85928eb124d931d9c21d\n'}, {'number': 2, 'created': '2014-12-15 12:58:19.000000000', 'files': ['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/raise_error.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_raise_error_upgrader.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/cli.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c78688c43063f6d01c52006aa2f0d2a049246abc', 'message': 'Add test upgrader intended to use in system tests\n\nIn order to test the rollback feature we used to inject raising error\ncode in one of our upgraders in-place:\n\n    self.fuel_web.modify_python_file(self.env.get_admin_remote(),\n                                    ""61i \\ \\ \\ \\ \\ \\ \\ \\ raise errors.""\n                                    ""ExecutedErrorNonZeroExitCode(\'{0}\')""\n                                    .format(\'Some bad error\'),\n                                    \'/var/upgrade/site-packages/\'\n                                    \'fuel_upgrade/engines/\'\n                                    \'openstack.py\')\n\nIt\'s a bad design decision which leads to time-to-time falls in tests due\nto changes in the upgrader\'s code. So the commit is going to solve this\nissue by providing a special upgrader which will always fail.\n\nUsage example:\n\n    $ UPGRADERS=""host-system docker openstack raise-error"" ./upgrade.sh\n\nRelated-Bug: #1402630\nChange-Id: Ia886d8d15cf63af4dc2b85928eb124d931d9c21d\n'}]",4,141079,c78688c43063f6d01c52006aa2f0d2a049246abc,22,6,2,10391,,,0,"Add test upgrader intended to use in system tests

In order to test the rollback feature we used to inject raising error
code in one of our upgraders in-place:

    self.fuel_web.modify_python_file(self.env.get_admin_remote(),
                                    ""61i \ \ \ \ \ \ \ \ raise errors.""
                                    ""ExecutedErrorNonZeroExitCode('{0}')""
                                    .format('Some bad error'),
                                    '/var/upgrade/site-packages/'
                                    'fuel_upgrade/engines/'
                                    'openstack.py')

It's a bad design decision which leads to time-to-time falls in tests due
to changes in the upgrader's code. So the commit is going to solve this
issue by providing a special upgrader which will always fail.

Usage example:

    $ UPGRADERS=""host-system docker openstack raise-error"" ./upgrade.sh

Related-Bug: #1402630
Change-Id: Ia886d8d15cf63af4dc2b85928eb124d931d9c21d
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/79/141079/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuel_upgrade_system/fuel_upgrade/fuel_upgrade/engines/raise_error.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/tests/test_raise_error_upgrader.py', 'fuel_upgrade_system/fuel_upgrade/fuel_upgrade/cli.py']",3,2c2e385cabbcb0a66f74c3f0a3dedfed9125b482,raise-error-upgrader.py,"from fuel_upgrade.engines.raise_error import RaiseErrorUpgrader 'targetimages': TargetImagesUpgrader, 'raise-error': RaiseErrorUpgrader,", 'targetimages': TargetImagesUpgrader,87,1
openstack%2Fopenstack-ansible~master~I969bdcb07986563597729ddad4fb62d25deaa02b,openstack/openstack-ansible,master,I969bdcb07986563597729ddad4fb62d25deaa02b,Add missing tilde to swift rsyslog configuration,MERGED,2014-12-15 11:20:45.000000000,2014-12-15 13:14:38.000000000,2014-12-15 12:52:55.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 7217}, {'_account_id': 7634}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-15 11:20:45.000000000', 'files': ['rpc_deployment/roles/swift_common/templates/swift-rsyslog.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d23eec10937a94cf58998834cf70342b7c09c2c0', 'message': 'Add missing tilde to swift rsyslog configuration\n\nThis patch adds the missing drop action (~) to the swift rsyslog\nconfiguration to ensure that the logging only gets written to the\ndesignated swift log files.\n\nChange-Id: I969bdcb07986563597729ddad4fb62d25deaa02b\nCloses-Bug: #1402606\n'}]",0,141771,d23eec10937a94cf58998834cf70342b7c09c2c0,9,5,1,6816,,,0,"Add missing tilde to swift rsyslog configuration

This patch adds the missing drop action (~) to the swift rsyslog
configuration to ensure that the logging only gets written to the
designated swift log files.

Change-Id: I969bdcb07986563597729ddad4fb62d25deaa02b
Closes-Bug: #1402606
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/71/141771/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/roles/swift_common/templates/swift-rsyslog.conf.j2'],1,d23eec10937a94cf58998834cf70342b7c09c2c0,bug/1402606,local4.* ~,local4.*,1,1
openstack%2Fironic~master~I2b2b362f766bb82058af6f9ed92189165aa9a629,openstack/ironic,master,I2b2b362f766bb82058af6f9ed92189165aa9a629,rename oslo.concurrency to oslo_concurrency,MERGED,2014-12-06 04:21:04.000000000,2014-12-15 13:13:22.000000000,2014-12-15 13:13:21.000000000,"[{'_account_id': 3}, {'_account_id': 6676}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-06 04:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e8fd32c3c2a10ff7ddbe24d8ea2a32af3cc7b8a3', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: I2b2b362f766bb82058af6f9ed92189165aa9a629\n'}, {'number': 2, 'created': '2014-12-06 10:01:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/184baca1c9eecaf66dd7f5bd7e45d2580b9ea241', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: I2b2b362f766bb82058af6f9ed92189165aa9a629\nCloses-Bug: #1398656\n'}, {'number': 3, 'created': '2014-12-08 15:38:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ecd96aad806f34c43c567f2d742743c185876050', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: I2b2b362f766bb82058af6f9ed92189165aa9a629\nCloses-Bug: #1398656\n'}, {'number': 4, 'created': '2014-12-09 17:18:52.000000000', 'files': ['ironic/tests/drivers/test_ipmitool.py', 'ironic/tests/drivers/test_ssh.py', 'ironic/tests/test_utils.py', 'ironic/common/driver_factory.py', 'ironic/drivers/modules/console_utils.py', 'ironic/nova/compute/manager.py', 'ironic/common/utils.py', 'ironic/tests/drivers/test_console_utils.py', 'ironic/drivers/modules/image_cache.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/tests/test_images.py', 'ironic/common/images.py', 'ironic/drivers/modules/ssh.py', 'ironic/common/dhcp_factory.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/common/disk_partitioner.py', 'ironic/tests/drivers/test_deploy_utils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/c5e53000ec78dbb90f35b88498d447e217465fa4', 'message': 'rename oslo.concurrency to oslo_concurrency\n\noslo.concurrency-0.3.0 has moved its path to oslo_concurrency,\nthe old path oslo.concurrency can still work but is deprecated now.\n\nChange-Id: I2b2b362f766bb82058af6f9ed92189165aa9a629\nCloses-Bug: #1398656\n'}]",0,139782,c5e53000ec78dbb90f35b88498d447e217465fa4,29,5,4,6676,,,0,"rename oslo.concurrency to oslo_concurrency

oslo.concurrency-0.3.0 has moved its path to oslo_concurrency,
the old path oslo.concurrency can still work but is deprecated now.

Change-Id: I2b2b362f766bb82058af6f9ed92189165aa9a629
Closes-Bug: #1398656
",git fetch https://review.opendev.org/openstack/ironic refs/changes/82/139782/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/test_ipmitool.py', 'ironic/tests/drivers/test_ssh.py', 'ironic/tests/test_utils.py', 'ironic/common/driver_factory.py', 'ironic/drivers/modules/console_utils.py', 'ironic/nova/compute/manager.py', 'ironic/common/utils.py', 'ironic/tests/drivers/test_console_utils.py', 'ironic/drivers/modules/image_cache.py', 'ironic/conductor/manager.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/tests/test_images.py', 'ironic/common/images.py', 'ironic/drivers/modules/ssh.py', 'ironic/common/dhcp_factory.py', 'ironic/drivers/modules/ipmitool.py', 'ironic/common/disk_partitioner.py', 'ironic/tests/drivers/test_deploy_utils.py']",18,e8fd32c3c2a10ff7ddbe24d8ea2a32af3cc7b8a3,bug/1398656,from oslo_concurrency import processutils,from oslo.concurrency import processutils,18,18
openstack%2Fceilometer~master~I479221a9d4ec34cfef951d127af249e8c9432c29,openstack/ceilometer,master,I479221a9d4ec34cfef951d127af249e8c9432c29,Drop anyjson,MERGED,2014-12-13 15:31:23.000000000,2014-12-15 13:08:22.000000000,2014-12-15 13:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6537}]","[{'number': 1, 'created': '2014-12-13 15:31:23.000000000', 'files': ['requirements.txt', 'requirements-py3.txt', 'ceilometer/tests/alarm/test_notifier.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1cd9d727b23b471bdaecc10a98ac9981b25cbab2', 'message': 'Drop anyjson\n\noslo.serialization is a drop in replacement and already being used\n\nChange-Id: I479221a9d4ec34cfef951d127af249e8c9432c29\n'}]",0,141560,1cd9d727b23b471bdaecc10a98ac9981b25cbab2,12,6,1,7770,,,0,"Drop anyjson

oslo.serialization is a drop in replacement and already being used

Change-Id: I479221a9d4ec34cfef951d127af249e8c9432c29
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/60/141560/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt', 'ceilometer/tests/alarm/test_notifier.py']",3,1cd9d727b23b471bdaecc10a98ac9981b25cbab2,oslo_serialization,"from oslo.serialization import jsonutilsDATA_JSON = jsonutils.loads( self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data'])) self.assertEqual(DATA_JSON, jsonutils.loads(kwargs['data']))","import anyjsonDATA_JSON = anyjson.loads( self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data'])) self.assertEqual(DATA_JSON, anyjson.loads(kwargs['data']))",9,11
openstack%2Fsahara~master~Ib1c266933a4a3104af34586527148c2612019000,openstack/sahara,master,Ib1c266933a4a3104af34586527148c2612019000,Use xml.dom.minidom and xmlutils in unit tests,MERGED,2014-12-12 16:16:01.000000000,2014-12-15 13:02:00.000000000,2014-12-15 11:26:54.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-12 16:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/072fba376ab98bf53a08549e05c186b140da15dc', 'message': ""Use xml.dom.minidom and xmlutils in unit tests\n\nThis is an example using xml parsing in existing unit\ntests instead of assertIn and string comparisons to verify\nworkflow generation.  It's much less fragile.\n\nIf folks like this, we can change other tests similarly.\n\nChange-Id: Ib1c266933a4a3104af34586527148c2612019000\n""}, {'number': 2, 'created': '2014-12-12 18:40:06.000000000', 'files': ['sahara/plugins/mapr/util/config_file_utils.py', 'sahara/tests/unit/service/edp/test_job_manager.py', 'sahara/utils/xmlutils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a12701cf3299095ce53da3a3d9770a177e7c97f5', 'message': ""Use xml.dom.minidom and xmlutils in unit tests\n\nThis is an example using xml parsing in existing unit\ntests instead of assertIn and string comparisons to verify\nworkflow generation.  It's much less fragile.\n\nIf folks like this, we can change other tests similarly.\n\nChange-Id: Ib1c266933a4a3104af34586527148c2612019000\n""}]",0,141418,a12701cf3299095ce53da3a3d9770a177e7c97f5,13,5,2,8091,,,0,"Use xml.dom.minidom and xmlutils in unit tests

This is an example using xml parsing in existing unit
tests instead of assertIn and string comparisons to verify
workflow generation.  It's much less fragile.

If folks like this, we can change other tests similarly.

Change-Id: Ib1c266933a4a3104af34586527148c2612019000
",git fetch https://review.opendev.org/openstack/sahara refs/changes/18/141418/2 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/unit/service/edp/test_job_manager.py', 'sahara/utils/xmlutils.py']",2,072fba376ab98bf53a08549e05c186b140da15dc,xmltest," ""name"": get_text_from_node(elements, 'name'), ""value"": _adjust_field(get_text_from_node(elements, 'value')), get_text_from_node(elements, 'description')) 'name': get_text_from_node(elements, 'name'), 'value': get_text_from_node(elements, 'value')def get_text_from_node(element, name): def get_property_dict(elem): res = {} properties = elem.getElementsByTagName('property') for prop in properties: k = get_text_from_node(prop, 'name') v = get_text_from_node(prop, 'value') res[k] = v return res def get_param_dict(elem): res = {} params = elem.getElementsByTagName('param') for param in params: k, v = param.firstChild.nodeValue.split('=') res[k] = v return res"," ""name"": _get_text_from_node(elements, 'name'), ""value"": _adjust_field(_get_text_from_node(elements, 'value')), _get_text_from_node(elements, 'description')) 'name': _get_text_from_node(elements, 'name'), 'value': _get_text_from_node(elements, 'value')def _get_text_from_node(element, name):",60,45
openstack%2Fopenstack-ansible~stable%2Fjuno~Ia6194b0df34098f42dc5287528edd111fa67c40d,openstack/openstack-ansible,stable/juno,Ia6194b0df34098f42dc5287528edd111fa67c40d,updated the rc number.,MERGED,2014-12-12 22:57:22.000000000,2014-12-15 12:55:43.000000000,2014-12-15 12:55:43.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 2799}, {'_account_id': 6714}, {'_account_id': 7217}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-12 22:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/83dac44986684295bd8c363d21b2d827c5fbf8c8', 'message': 'updated the rc number.\n\nThis updates the present RC to rc2\n\nChange-Id: Ia6194b0df34098f42dc5287528edd111fa67c40d\n'}, {'number': 2, 'created': '2014-12-12 23:00:37.000000000', 'files': ['rpc_deployment/vars/repo_packages/raxmon_agent.yml', 'scripts/rpc-aio-rax-heat-template.yml', 'rpc_deployment/inventory/group_vars/all.yml', 'scripts/cloudserver-aio.sh', 'scripts/rpc-aio-heat-template.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/34cb331d0508ff82fa44dea9494cedcb30e94484', 'message': 'updated the rc number.\n\nThis updates the present RC to rc2\n\nChange-Id: Ia6194b0df34098f42dc5287528edd111fa67c40d\n'}]",0,141514,34cb331d0508ff82fa44dea9494cedcb30e94484,14,7,2,7353,,,0,"updated the rc number.

This updates the present RC to rc2

Change-Id: Ia6194b0df34098f42dc5287528edd111fa67c40d
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/14/141514/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/vars/repo_packages/raxmon_agent.yml', 'scripts/rpc-aio-rax-heat-template.yml', 'scripts/cloudserver-aio.sh', 'scripts/rpc-aio-heat-template.yml']",4,83dac44986684295bd8c363d21b2d827c5fbf8c8,, default: https://raw.githubusercontent.com/stackforge/os-ansible-deployment/10.1.0rc2/scripts/cloudserver-aio.sh default: 10.1.0rc2, default: https://raw.githubusercontent.com/stackforge/os-ansible-deployment/10.1.0rc1/scripts/cloudserver-aio.sh default: 10.1.0rc1,6,6
openstack%2Fironic~master~I28b205c8a8027de4168b65f272983b38bb09dd2d,openstack/ironic,master,I28b205c8a8027de4168b65f272983b38bb09dd2d,Remove Python 2.6 from setup.cfg,MERGED,2014-12-11 15:38:49.000000000,2014-12-15 12:52:38.000000000,2014-12-15 12:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 7882}, {'_account_id': 8106}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-11 15:38:49.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5f398aa2aecd5346a6e49b3c16a12ad2761e2898', 'message': 'Remove Python 2.6 from setup.cfg\n\nPython 2.6 support is dropped so it should be removed from setup.cfg.\n\nChange-Id: I28b205c8a8027de4168b65f272983b38bb09dd2d\n'}]",0,141074,5f398aa2aecd5346a6e49b3c16a12ad2761e2898,11,5,1,12356,,,0,"Remove Python 2.6 from setup.cfg

Python 2.6 support is dropped so it should be removed from setup.cfg.

Change-Id: I28b205c8a8027de4168b65f272983b38bb09dd2d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/74/141074/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,5f398aa2aecd5346a6e49b3c16a12ad2761e2898,rmpy2.6,, Programming Language :: Python :: 2.6,0,1
openstack%2Fdesignate~master~I326fa7f5f860fd5a1a19c67339e0cfede19afce7,openstack/designate,master,I326fa7f5f860fd5a1a19c67339e0cfede19afce7,Cleanup validation regex's,MERGED,2014-12-11 14:14:51.000000000,2014-12-15 12:48:31.000000000,2014-12-15 12:48:30.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-12-11 14:14:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/573ba4a6f0229ac96289450aeb76d47c0e43e0f2', 'message': ""Cleanup validation regex's\n\nUpdate the validation regexes to remove any unnecessary capture groups\n\nChange-Id: I326fa7f5f860fd5a1a19c67339e0cfede19afce7\n""}, {'number': 2, 'created': '2014-12-11 14:21:52.000000000', 'files': ['designate/schema/format.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/07e04ded21c2294b6434c8894142850576196a20', 'message': ""Cleanup validation regex's\n\nUpdate the validation regexes to remove any unnecessary capture groups\n\nChange-Id: I326fa7f5f860fd5a1a19c67339e0cfede19afce7\n""}]",1,141056,07e04ded21c2294b6434c8894142850576196a20,9,4,2,741,,,0,"Cleanup validation regex's

Update the validation regexes to remove any unnecessary capture groups

Change-Id: I326fa7f5f860fd5a1a19c67339e0cfede19afce7
",git fetch https://review.opendev.org/openstack/designate refs/changes/56/141056/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/schema/format.py'],1,573ba4a6f0229ac96289450aeb76d47c0e43e0f2,,"RE_DOMAINNAME = r'^(?!.{255,})(?:(?:^\*|(?!\-)[A-Za-z0-9_\-]{1,63})' \ r'(?<!\-)\.)+$' RE_HOSTNAME = r'^(?!.{255,})(?:(?:^\*|(?!\-)[A-Za-z0-9_\-]{1,63})(?<!\-)\.)+$' r'(?:\.(?:(?!\-)[A-Za-z0-9_\-]{1,63}(?<!\-)))*$' RE_UUID = r'^(?:[0-9a-fA-F]){8}-(?:[0-9a-fA-F]){4}-(?:[0-9a-fA-F]){4}-' \ r'(?:[0-9a-fA-F]){4}-(?:[0-9a-fA-F]){12}$'","RE_DOMAINNAME = r'^(?!.{255,})(?:(?!\-)[A-Za-z0-9_\-]{1,63}(?<!\-)\.)+$' RE_HOSTNAME = r'^(?!.{255,})(?:(^\*|(?!\-)[A-Za-z0-9_\-]{1,63})(?<!\-)\.)+$' r'(\.(?:(?!\-)[A-Za-z0-9_\-]{1,63}(?<!\-)))*$' RE_UUID = r'^([0-9a-fA-F]){8}-([0-9a-fA-F]){4}-([0-9a-fA-F]){4}-' \ r'([0-9a-fA-F]){4}-([0-9a-fA-F]){12}$'",6,5
openstack%2Fdesignate~master~Iec31efaa0c30829351d5eb04e419f9ace30537be,openstack/designate,master,Iec31efaa0c30829351d5eb04e419f9ace30537be,"Adds ""domain-servers-list"" to test_domains.py",MERGED,2014-12-11 06:57:25.000000000,2014-12-15 12:46:52.000000000,2014-12-15 12:46:51.000000000,"[{'_account_id': 3}, {'_account_id': 741}, {'_account_id': 1795}, {'_account_id': 2222}, {'_account_id': 8099}, {'_account_id': 8130}]","[{'number': 1, 'created': '2014-12-11 06:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/8ad83bdd29f4e40bbef1e18b3e4e710d3b439bcd', 'message': 'Adds ""domain-servers-list"" to test_domains.py\n\nThis submission adds a unittest ""test_list_servers_for_a_domain""\nunder ""designate/tests/test_api/test_v1/test_domains.py"" script\nto validate ""domain-servers-list"" functionality.\n\nChange-Id: Iec31efaa0c30829351d5eb04e419f9ace30537be\n'}, {'number': 2, 'created': '2014-12-12 07:53:58.000000000', 'files': ['designate/tests/test_api/test_v1/test_domains.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/eb4da0728028bfa7077f38df254c352d63303181', 'message': 'Adds ""domain-servers-list"" to test_domains.py\n\nThis submission adds a unittest ""test_list_servers_for_a_domain""\nunder ""designate/tests/test_api/test_v1/test_domains.py"" script\nto validate ""domain-servers-list"" functionality.\n\nChange-Id: Iec31efaa0c30829351d5eb04e419f9ace30537be\n'}]",4,140935,eb4da0728028bfa7077f38df254c352d63303181,14,6,2,1687,,,0,"Adds ""domain-servers-list"" to test_domains.py

This submission adds a unittest ""test_list_servers_for_a_domain""
under ""designate/tests/test_api/test_v1/test_domains.py"" script
to validate ""domain-servers-list"" functionality.

Change-Id: Iec31efaa0c30829351d5eb04e419f9ace30537be
",git fetch https://review.opendev.org/openstack/designate refs/changes/35/140935/2 && git format-patch -1 --stdout FETCH_HEAD,['designate/tests/test_api/test_v1/test_domains.py'],1,8ad83bdd29f4e40bbef1e18b3e4e710d3b439bcd,separate/designate_domains_unittest, def test_list_servers_for_a_domain(self): # Create a domain domain = self.create_domain() response = self.get('domains/%s/servers' % domain['id']) # Verify list servers for a domain self.assertIsNotNone(len(response.json['servers'])) ,,7,0
openstack%2Fdesignate~master~I46bae8890cff8f4117cf34d588ddc2fd3d113140,openstack/designate,master,I46bae8890cff8f4117cf34d588ddc2fd3d113140,DynECT tests using requests-mock,ABANDONED,2014-12-14 20:58:02.000000000,2014-12-15 12:45:37.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-14 20:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/c20ded78989e263a3904405e883cce2782462dc0', 'message': 'DynECT tests using requests-mock.\n\nThis tests that exception handling is done correctly when a domain exists and\nelse.\n\nChange-Id: I46bae8890cff8f4117cf34d588ddc2fd3d113140\n'}, {'number': 2, 'created': '2014-12-15 09:03:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/b5a4fb4b9d63c1fe283889c62bd7462e1ef045f7', 'message': 'DynECT tests using requests-mock.\n\nThis tests that exception handling is done correctly when a domain exists and\nelse.\n\nChange-Id: I46bae8890cff8f4117cf34d588ddc2fd3d113140\n'}, {'number': 3, 'created': '2014-12-15 09:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/designate/commit/2580efe32488ce1ef587b461f9f81b7791164141', 'message': 'DynECT tests using requests-mock.\n\nThis tests that exception handling is done correctly when a domain exists and\nelse.\n\nChange-Id: I46bae8890cff8f4117cf34d588ddc2fd3d113140\n'}, {'number': 4, 'created': '2014-12-15 10:11:14.000000000', 'files': ['test-requirements.txt', 'designate/tests/test_backend/test_dynect.py'], 'web_link': 'https://opendev.org/openstack/designate/commit/162c2c8879006ed43e23ebb9567da83e402cf50b', 'message': 'DynECT tests using requests-mock\n\nThis tests that exception handling is done correctly when a domain exists and\nelse.\n\nChange-Id: I46bae8890cff8f4117cf34d588ddc2fd3d113140\n'}]",0,141664,162c2c8879006ed43e23ebb9567da83e402cf50b,8,1,4,395,,,0,"DynECT tests using requests-mock

This tests that exception handling is done correctly when a domain exists and
else.

Change-Id: I46bae8890cff8f4117cf34d588ddc2fd3d113140
",git fetch https://review.opendev.org/openstack/designate refs/changes/64/141664/3 && git format-patch -1 --stdout FETCH_HEAD,['designate/tests/test_backend/test_dynect.py'],1,c20ded78989e263a3904405e883cce2782462dc0,dynect-tests,"# Copyright 2014 Hewlett-Packard Development Company, L.P. # # Author: Endre Karlson <endre.karlson@hp.com> # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import json as json_ from requests_mock.contrib import fixture as req_fixture from oslo.config import cfg import testtools from designate import tests from designate.backend import impl_dynect from designate.tests.test_backend import BackendTestMixin cfg.CONF.import_group(""backend:dynect"", 'designate.backend.impl_dynect') MASTERS = [""10.0.0.1""] CONTACT = 'jdoe@myco.biz' LOGIN_SUCCESS = { ""status"": ""success"", ""data"": { ""token"": ""foo"", ""version"": ""3.5.6"" }, ""job_id"": 1, ""msgs"": [{ ""INFO"": ""login: Login successful"", ""SOURCE"": ""BLL"", ""ERR_CD"": None, ""LVL"": ""INFO""}] } LOGOUT_SUCCESS = { ""status"": ""success"", ""data"": {}, ""job_id"": 1345964647, ""msgs"": [ { ""INFO"": ""logout: Logout successful"", ""SOURCE"": ""BLL"", ""ERR_CD"": None, ""LVL"": ""INFO"" } ] } INVALID_MASTER_DATA = { ""status"": ""failure"", ""data"": {}, ""job_id"": 1326038394, ""msgs"": [ { ""INFO"": ""master: IP address expected"", ""SOURCE"": ""DYN"", ""ERR_CD"": ""INVALID_DATA"", ""LVL"": ""ERROR"" }, { ""INFO"": ""create: Zone not created"", ""SOURCE"": ""BLL"", ""ERR_CD"": None, ""LVL"": ""INFO"" } ] } TARGET_EXISTS = { ""status"": ""failure"", ""data"": {}, ""job_id"": 1345944906, ""msgs"": [ { ""INFO"": ""name: Name already exists"", ""SOURCE"": ""BLL"", ""ERR_CD"": ""TARGET_EXISTS"", ""LVL"": ""ERROR"" }, { ""INFO"": ""create: You already have this zone."", ""SOURCE"": ""BLL"", ""ERR_CD"": None, ""LVL"": ""INFO"" } ] } ACTIVATE_SUCCESS = { ""status"": ""success"", ""data"": { ""active"": ""L"", ""masters"": MASTERS, ""contact_nickname"": CONTACT, ""tsig_key_name"": """", ""zone"": ""meep.io"" }, ""job_id"": 1345944927, ""msgs"": [ { ""INFO"": ""activate: Service activated"", ""SOURCE"": ""BLL"", ""ERR_CD"": None, ""LVL"": ""INFO"" } ] } class DynECTTestsCase(tests.TestCase, BackendTestMixin): def setUp(self): super(DynECTTestsCase, self).setUp() self.config(backend_driver='dynect', group='service:agent') self.config(customer_name='myco', username='jdoe', password='password', masters=MASTERS, contact_nickname=CONTACT, group=""backend:dynect"") self.backend = self.get_backend_driver() self.requests = self.useFixture(req_fixture.Fixture()) def stub_url(self, method, parts=None, base_url=None, json=None, **kwargs): if not base_url: base_url = 'https://api.dynect.net:443/REST' if json: kwargs['text'] = json_.dumps(json) headers = kwargs.setdefault('headers', {}) headers['Content-Type'] = 'application/json' if parts: url = '/'.join([p.strip('/') for p in [base_url] + parts]) else: url = base_url url = url.replace(""/?"", ""?"") return self.requests.register_uri(method, url, **kwargs) def _stub_login(self): self.stub_url('POST', ['/Session'], json=LOGIN_SUCCESS) self.stub_url('DELETE', ['/Session'], json=LOGIN_SUCCESS) def test_create_domain_raise_dynclienterror(self): context = self.get_context() domain = self.create_domain() self._stub_login() self.stub_url( 'POST', ['/Secondary/example.com'], json=INVALID_MASTER_DATA, status_code=400) with testtools.ExpectedException(impl_dynect.DynClientError): self.backend.create_domain(context, domain) def test_create_domain_duplicate_updates_existing(self): context = self.get_context() domain = self.create_domain() self._stub_login() parts = ['/Secondary', '/%s' % domain['name'].rstrip('.')] self.stub_url( 'POST', parts, json=TARGET_EXISTS, status_code=400) update = self.stub_url('PUT', parts, json=ACTIVATE_SUCCESS) self.backend.create_domain(context, domain) self.assertTrue(update.called) ",,188,0
openstack%2Fzaqar~master~I6fe450f731602ad2ec4766caecccfc00ec20c691,openstack/zaqar,master,I6fe450f731602ad2ec4766caecccfc00ec20c691,Fix the duplicate lines in autoindex doc,MERGED,2014-12-15 09:32:46.000000000,2014-12-15 12:44:05.000000000,2014-12-15 12:44:04.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2014-12-15 09:32:46.000000000', 'files': ['doc/source/api/autoindex.rst'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/561f000f82fa5a37757d875bf26fa06651c87d68', 'message': 'Fix the duplicate lines in autoindex doc\n\nChange-Id: I6fe450f731602ad2ec4766caecccfc00ec20c691\n'}]",0,141754,561f000f82fa5a37757d875bf26fa06651c87d68,7,3,1,7488,,,0,"Fix the duplicate lines in autoindex doc

Change-Id: I6fe450f731602ad2ec4766caecccfc00ec20c691
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/54/141754/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/api/autoindex.rst'],1,561f000f82fa5a37757d875bf26fa06651c87d68,fix/autoindex_duplication,, zaqar.api.v1_1.request.rst zaqar.api.v1_1.response.rst zaqar.api.v1.request.rst zaqar.api.v1.response.rst zaqar.bootstrap.rst zaqar.cmd.gc.rst zaqar.cmd.server.rst zaqar.common.access.rst zaqar.common.api.rst zaqar.common.cli.rst zaqar.common.decorators.rst zaqar.common.errors.rst zaqar.common.pipeline.rst zaqar.common.request.rst zaqar.common.response.rst zaqar.common.schemas.flavors.rst zaqar.common.schemas.pools.rst zaqar.common.storage.select.rst zaqar.common.transport.wsgi.helpers.rst zaqar.common.utils.rst zaqar.context.rst zaqar.i18n.rst zaqar.openstack.common.cache._backends.memory.rst zaqar.openstack.common.cache.backends.rst zaqar.openstack.common.cache.cache.rst zaqar.openstack.common.config.generator.rst zaqar.openstack.common.context.rst zaqar.openstack.common.excutils.rst zaqar.openstack.common.fileutils.rst zaqar.openstack.common.gettextutils.rst zaqar.openstack.common.importutils.rst zaqar.openstack.common.jsonutils.rst zaqar.openstack.common.local.rst zaqar.openstack.common.lockutils.rst zaqar.openstack.common.log.rst zaqar.openstack.common.strutils.rst zaqar.openstack.common.timeutils.rst zaqar.storage.base.rst zaqar.storage.errors.rst zaqar.storage.mongodb.catalogue.rst zaqar.storage.mongodb.claims.rst zaqar.storage.mongodb.controllers.rst zaqar.storage.mongodb.driver.rst zaqar.storage.mongodb.flavors.rst zaqar.storage.mongodb.messages.rst zaqar.storage.mongodb.options.rst zaqar.storage.mongodb.pools.rst zaqar.storage.mongodb.queues.rst zaqar.storage.mongodb.utils.rst zaqar.storage.pipeline.rst zaqar.storage.pooling.rst zaqar.storage.redis.claims.rst zaqar.storage.redis.controllers.rst zaqar.storage.redis.driver.rst zaqar.storage.redis.messages.rst zaqar.storage.redis.models.rst zaqar.storage.redis.options.rst zaqar.storage.redis.queues.rst zaqar.storage.redis.scripting.rst zaqar.storage.redis.utils.rst zaqar.storage.sqlalchemy.catalogue.rst zaqar.storage.sqlalchemy.claims.rst zaqar.storage.sqlalchemy.controllers.rst zaqar.storage.sqlalchemy.driver.rst zaqar.storage.sqlalchemy.messages.rst zaqar.storage.sqlalchemy.options.rst zaqar.storage.sqlalchemy.pools.rst zaqar.storage.sqlalchemy.queues.rst zaqar.storage.sqlalchemy.tables.rst zaqar.storage.sqlalchemy.utils.rst zaqar.storage.utils.rst zaqar.transport.auth.rst zaqar.transport.base.rst zaqar.transport.utils.rst zaqar.transport.validation.rst zaqar.transport.wsgi.app.rst zaqar.transport.wsgi.driver.rst zaqar.transport.wsgi.errors.rst zaqar.transport.wsgi.utils.rst zaqar.transport.wsgi.v1_0.claims.rst zaqar.transport.wsgi.v1_0.health.rst zaqar.transport.wsgi.v1_0.homedoc.rst zaqar.transport.wsgi.v1_0.messages.rst zaqar.transport.wsgi.v1_0.metadata.rst zaqar.transport.wsgi.v1_0.pools.rst zaqar.transport.wsgi.v1_0.queues.rst zaqar.transport.wsgi.v1_0.stats.rst zaqar.transport.wsgi.v1_1.claims.rst zaqar.transport.wsgi.v1_1.flavors.rst zaqar.transport.wsgi.v1_1.health.rst zaqar.transport.wsgi.v1_1.homedoc.rst zaqar.transport.wsgi.v1_1.messages.rst zaqar.transport.wsgi.v1_1.ping.rst zaqar.transport.wsgi.v1_1.pools.rst zaqar.transport.wsgi.v1_1.queues.rst zaqar.transport.wsgi.v1_1.stats.rst zaqar.version.rst,0,97
openstack%2Ftelemetry-specs~master~I05ae593238c82f62cf9da532e27ea727da32fe72,openstack/telemetry-specs,master,I05ae593238c82f62cf9da532e27ea727da32fe72,Add spec for Ceph object storage metering support,MERGED,2014-12-02 12:58:55.000000000,2014-12-15 12:41:47.000000000,2014-12-15 12:41:45.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 11224}]","[{'number': 1, 'created': '2014-12-02 12:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/21fe209815f0f665369c7fe472c015c68603294c', 'message': 'Add spec for Ceph object storage metering support\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}, {'number': 2, 'created': '2014-12-02 17:16:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/dac1dd9b361a813f13738b4fd6a33dacdf57f61e', 'message': 'Add spec for Ceph object storage metering support\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}, {'number': 3, 'created': '2014-12-03 06:30:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/9371110fed4a57592d2c6ff81cf9d1f57767f2ec', 'message': 'Add spec for Ceph object storage metering support\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}, {'number': 4, 'created': '2014-12-03 09:20:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/fff9e7c0123c60e2f707a44e0cafd420eeddc63b', 'message': 'Add spec for Ceph object storage metering support\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/ceph-ceilometer-integration\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}, {'number': 5, 'created': '2014-12-05 12:11:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/cc6017299f79bf36cee0a54f965bb6666f5fa4cb', 'message': 'Add spec for Ceph object storage metering support\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/ceph-ceilometer-integration\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}, {'number': 6, 'created': '2014-12-11 07:42:10.000000000', 'files': ['specs/kilo/ceilometer_ceph_integration.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/808d2b052de9deed183ccddc8eff446463dc3fed', 'message': 'Add spec for Ceph object storage metering support\n\nhttps://blueprints.launchpad.net/ceilometer/+spec/ceph-ceilometer-integration\n\nChange-Id: I05ae593238c82f62cf9da532e27ea727da32fe72\n'}]",36,138349,808d2b052de9deed183ccddc8eff446463dc3fed,34,6,6,11224,,,0,"Add spec for Ceph object storage metering support

https://blueprints.launchpad.net/ceilometer/+spec/ceph-ceilometer-integration

Change-Id: I05ae593238c82f62cf9da532e27ea727da32fe72
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/49/138349/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ceilometer_ceph_integration.rst'],1,21fe209815f0f665369c7fe472c015c68603294c,bp/s,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================== Ceph object storage meters ========================== This spec proposes to add ceph object storage metering to Ceilometer by polling mechanism, using the ceph radosgw (rados gateway) APIs, when the ceph is used as object storage back-end, instead of swift. Problem description =================== Currently, ceph object storage meters are not supported in ceilometer. When the ceph object storage used instead of swift object storage, metering support not there with ceilometer. Ceph object storage provide REST APIs to get the meters like object/container list, object/container size, etc. A polling machanisum is required, in Ceilometer, to get the meter details from the ceph object storage. This polling method could be similar to swift polling machanisum. Proposed change =============== Add a new poller classes for ceph object storage to get object storage meter information into samples, using existing ``storage.objects`` implementations as a model with swift object storage. These poller include objects and containers of the ceph object storage. The ceph object storage poller names have the following pattern, * ceph.storage.objects * ceph.storage.objects.size * ceph.storage.objects.containers * ceph.storage.containers.objects * ceph.storage.containers.objects.size * ceph.storage.api.request For this implementation we will call the ceph object storage (radosgw) APIs. Alternatives ------------ None. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Pipeline impact --------------- None. Other end user impact --------------------- None. Performance/Scalability Impacts ------------------------------- None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: swamireddy Ongoing maintainer: swamireddy Work Items ---------- * Configuration setup (ie setup.cfg) updated based on the object storage to get the metering information. - If swift used, use swift collectors to get the metering information - If ceph used, use ceph collectors to get the metering information * Implement the ceph object storage (radosgw) APIs calls for appropriately for each metering item. * Test coverage for the above poller classes and sample validation. Future lifecycle ================ In the future new types of metering items are expected from the ceph object storage to account for the statistics data. These will need to be handled separately. Dependencies ============ Ceph - radosgw REST APIs support required to do this. If ceph API is not supported, we may need to implement it in ceph. Testing ======= Unit and integration Tests will be added to cover the necessary poller classes and validate samples generated. Documentation Impact ==================== The added metrics will need to be documented in the `measurements section`_. .. _measurements section: http://docs.openstack.org/developer/ceilometer/measurements.html References ========== None ",,150,0
openstack%2Fopenstack-ansible~master~I35874b717efd60531781849ae973cc9176a6d77a,openstack/openstack-ansible,master,I35874b717efd60531781849ae973cc9176a6d77a,Set cloudserver-aio.sh to make use of os-ansible-aio-check.sh,MERGED,2014-12-11 11:42:55.000000000,2014-12-15 12:28:40.000000000,2014-12-15 12:28:38.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7307}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-12-11 11:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4637522add2e3da1c2404abf706c81cc2e536e26', 'message': 'Set cloudserver-aio.sh to make use of os-ansible-aio-check.sh\n\nThe cloudserver all in one server build will now use exactly the same\nbuild script as is used in the OpenStack CI gating process.\n\nChange-Id: I35874b717efd60531781849ae973cc9176a6d77a\nCloses-Bug: #1401495\n'}, {'number': 2, 'created': '2014-12-11 12:35:58.000000000', 'files': ['scripts/cloudserver-aio.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cb17a9906e61f352ac3c422ebdd4d2827999a750', 'message': 'Set cloudserver-aio.sh to make use of os-ansible-aio-check.sh\n\nThe cloudserver all in one server build will now use exactly the same\nbuild script as is used in the OpenStack CI gating process.\n\nChange-Id: I35874b717efd60531781849ae973cc9176a6d77a\nCloses-Bug: #1401495\n'}]",2,141024,cb17a9906e61f352ac3c422ebdd4d2827999a750,23,7,2,6816,,,0,"Set cloudserver-aio.sh to make use of os-ansible-aio-check.sh

The cloudserver all in one server build will now use exactly the same
build script as is used in the OpenStack CI gating process.

Change-Id: I35874b717efd60531781849ae973cc9176a6d77a
Closes-Bug: #1401495
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/24/141024/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/cloudserver-aio.sh'],1,4637522add2e3da1c2404abf706c81cc2e536e26,bug/1401495, # install git so that we can fetch the repo apt-get update && apt-get install -y git # fetch the repo git clone -b ${REPO_BRANCH} ${REPO_URL} os-ansible-deployment/ # run the same aio build script that is used in the OpenStack CI pipeline ./os-ansible-deployment/scripts/os-ansible-aio-check.sh,"FROZEN_REPO_URL=${FROZEN_REPO_URL:-""http://mirror.rackspace.com/rackspaceprivatecloud""} MAX_RETRIES=${MAX_RETRIES:-5} apt-get update apt-get install -y python-dev \ python2.7 \ build-essential \ curl \ git-core \ ipython \ tmux \ vim \ vlan \ bridge-utils \ lvm2 \ linux-image-extra-$(uname -r) function key_create(){ ssh-keygen -t rsa -f /root/.ssh/id_rsa -N '' } # Used to retry process that may fail due to random issues. function successerator() { set +e RETRY=0 # Set the initial return value to failure false while [ $? -ne 0 -a ${RETRY} -lt ${MAX_RETRIES} ];do RETRY=$((${RETRY}+1)) $@ done if [ ${RETRY} -eq ${MAX_RETRIES} ];then echo ""Hit maximum number of retries, giving up..."" exit 1 fi set -e } function install_bits() { successerator ansible-playbook -e @/etc/rpc_deploy/user_variables.yml \ playbooks/$@ } if [ ! -d ""/opt"" ];then mkdir /opt fi if [ ! ""$(swapon -s | grep -v Filename)"" ];then cat > /opt/swap.sh <<EOF #!/usr/bin/env bash if [ ! ""\$(swapon -s | grep -v Filename)"" ];then SWAPFILE=""/tmp/SwapFile"" if [ -f ""\${SWAPFILE}"" ];then swapoff -a rm \${SWAPFILE} fi dd if=/dev/zero of=\${SWAPFILE} bs=1M count=512 mkswap \${SWAPFILE} swapon \${SWAPFILE} fi EOF chmod +x /opt/swap.sh /opt/swap.sh fi if [ -f ""/opt/swap.sh"" ];then if [ ! -f ""/etc/rc.local"" ];then touch /etc/rc.local fi if [ ""$(grep 'exit 0' /etc/rc.local)"" ];then sed -i '/exit\ 0/ s/^/#\ /' /etc/rc.local fi if [ ! ""$(grep 'swap.sh' /etc/rc.local)"" ];then echo ""/opt/swap.sh"" | tee -a /etc/rc.local fi chmod +x /etc/rc.local fi # Make the system key used for bootstrapping self if [ ! -d /root/.ssh ];then mkdir -p /root/.ssh chmod 700 /root/.ssh fi pushd /root/.ssh/ if [ ! -f ""id_rsa"" ];then key_create fi if [ ! -f ""id_rsa.pub"" ];then rm ""id_rsa"" key_create fi KEYENTRY=$(cat id_rsa.pub) if [ ! ""$(grep \""$KEYENTRY\"" authorized_keys)"" ];then echo ""$KEYENTRY"" | tee -a authorized_keys fi popd CINDER=""/opt/cinder.img"" if [ ! ""$(losetup -a | grep /opt/cinder.img)"" ];then LOOP=$(losetup -f) dd if=/dev/zero of=${CINDER} bs=1 count=0 seek=1000G losetup ${LOOP} ${CINDER} pvcreate ${LOOP} vgcreate cinder-volumes ${LOOP} pvscan fi # Get the source if [ -d ""/opt/ansible-lxc-rpc"" ];then rm -rf ""/opt/ansible-lxc-rpc"" fi git clone ""${REPO_URL}"" ""/opt/ansible-lxc-rpc"" pushd /opt/ansible-lxc-rpc git checkout ""${REPO_BRANCH}"" # Copy the base etc files if [ -d ""/etc/rpc_deploy"" ];then rm -rf ""/etc/rpc_deploy"" fi cp -R /opt/ansible-lxc-rpc/etc/rpc_deploy /etc/ # Install pip curl ${FROZEN_REPO_URL}/downloads/get-pip.py | python # Install requirements pip install -r /opt/ansible-lxc-rpc/requirements.txt # Generate the passwords /opt/ansible-lxc-rpc/scripts/pw-token-gen.py --file /etc/rpc_deploy/user_variables.yml popd cat > /etc/rpc_deploy/user_variables.yml <<EOF --- rpc_repo_url: ${FROZEN_REPO_URL} required_kernel: 3.13.0-30-generic ## Rackspace Cloud Details rackspace_cloud_auth_url: https://identity.api.rackspacecloud.com/v2.0 rackspace_cloud_tenant_id: SomeTenantID rackspace_cloud_username: SomeUserName rackspace_cloud_password: SomeUsersPassword rackspace_cloud_api_key: SomeAPIKey ## Rabbit Options rabbitmq_password: secrete rabbitmq_cookie_token: secrete ## Tokens memcached_encryption_key: secrete ## Container default user container_openstack_password: secrete ## Galera Options mysql_root_password: secrete mysql_debian_sys_maint_password: secrete ## Keystone Options keystone_container_mysql_password: secrete keystone_auth_admin_token: secrete keystone_auth_admin_password: secrete keystone_service_password: secrete ## Cinder Options cinder_container_mysql_password: secrete cinder_service_password: secrete cinder_v2_service_password: secrete # Set default_store to ""swift"" if using Cloud Files or swift backend glance_default_store: file glance_container_mysql_password: secrete glance_service_password: secrete glance_swift_store_auth_address: ""{{ rackspace_cloud_auth_url }}"" glance_swift_store_user: ""{{ rackspace_cloud_tenant_id }}:{{ rackspace_cloud_username }}"" glance_swift_store_key: ""{{ rackspace_cloud_password }}"" glance_swift_store_container: SomeContainerName glance_swift_store_region: SomeRegion glance_swift_store_endpoint_type: internalURL glance_notification_driver: noop ## Heat Options heat_stack_domain_admin_password: secrete heat_container_mysql_password: secrete ### THE HEAT AUTH KEY NEEDS TO BE 32 CHARACTERS LONG ## heat_auth_encryption_key: 12345678901234567890123456789012 ### THE HEAT AUTH KEY NEEDS TO BE 32 CHARACTERS LONG ## heat_service_password: secrete heat_cfn_service_password: secrete ## Horizon Options horizon_container_mysql_password: secrete ## MaaS Options maas_auth_method: password maas_auth_url: ""{{ rackspace_cloud_auth_url }}"" maas_username: ""{{ rackspace_cloud_username }}"" maas_api_key: ""{{ rackspace_cloud_api_key }}"" maas_auth_token: some_token maas_api_url: https://monitoring.api.rackspacecloud.com/v1.0/{{ rackspace_cloud_tenant_id }} maas_notification_plan: npManaged # By default we will create an agent token for each entity, however if you'd # prefer to use the same agent token for all entities then specify it here #maas_agent_token: some_token maas_target_alias: public0_v4 maas_scheme: https # Override scheme for specific service remote monitor by specifying here: E.g. # maas_nova_scheme: http maas_keystone_user: maas maas_keystone_password: secrete # Check this number of times before registering state change maas_alarm_local_consecutive_count: 3 maas_alarm_remote_consecutive_count: 1 # Timeout must be less than period maas_check_period: 60 maas_check_timeout: 30 maas_monitoring_zones: - mzdfw - mziad - mzord - mzlon - mzhkg ## Neutron Options neutron_container_mysql_password: secrete neutron_service_password: secrete ## Nova Options nova_virt_type: qemu nova_container_mysql_password: secrete nova_metadata_proxy_secret: secrete nova_ec2_service_password: secrete nova_service_password: secrete nova_v3_service_password: secrete nova_s3_service_password: secrete ## RPC Support rpc_support_holland_password: secrete ## Kibana Options kibana_password: secrete EOF cat > /etc/rpc_deploy/rpc_user_config.yml <<EOF --- # This is the md5 of the environment file environment_version: $(md5sum /etc/rpc_deploy/rpc_environment.yml | awk '{print $1}') # User defined CIDR used for containers cidr_networks: # Cidr used in the Management network container: 172.29.236.0/22 # Cidr used in the Service network snet: 172.29.248.0/22 # Cidr used in the VM network tunnel: 172.29.240.0/22 # Cidr used in the Storage network storage: 172.29.244.0/22 used_ips: - 172.29.236.1,172.29.236.50 - 172.29.244.1,172.29.244.50 global_overrides: rpc_repo_url: ${FROZEN_REPO_URL} # Internal Management vip address internal_lb_vip_address: 172.29.236.100 # External DMZ VIP address external_lb_vip_address: 10.200.200.146 # Bridged interface to use with tunnel type networks tunnel_bridge: ""br-vxlan"" # Bridged interface to build containers with management_bridge: ""br-mgmt"" # Define your Add on container networks. provider_networks: - network: group_binds: - all_containers - hosts type: ""raw"" container_bridge: ""br-mgmt"" container_interface: ""eth1"" ip_from_q: ""container"" - network: group_binds: - glance_api - cinder_api - cinder_volume - nova_compute type: ""raw"" container_bridge: ""br-storage"" container_interface: ""eth2"" ip_from_q: ""storage"" - network: group_binds: - glance_api - nova_compute - neutron_linuxbridge_agent type: ""raw"" container_bridge: ""br-snet"" container_interface: ""eth3"" ip_from_q: ""snet"" - network: group_binds: - neutron_linuxbridge_agent container_bridge: ""br-vxlan"" container_interface: ""eth10"" ip_from_q: ""tunnel"" type: ""vxlan"" range: ""1:1000"" net_name: ""vxlan"" - network: group_binds: - neutron_linuxbridge_agent container_bridge: ""br-vlan"" container_interface: ""eth11"" type: ""flat"" net_name: ""vlan"" - network: group_binds: - neutron_linuxbridge_agent container_bridge: ""br-vlan"" container_interface: ""eth11"" type: ""vlan"" range: ""1:1"" net_name: ""vlan"" # Name of load balancer lb_name: lb_name_in_core # User defined Infrastructure Hosts, this should be a required group infra_hosts: aio1: ip: 172.29.236.100 # User defined Compute Hosts, this should be a required group compute_hosts: aio1: ip: 172.29.236.100 # User defined Storage Hosts, this should be a required group storage_hosts: aio1: ip: 172.29.236.100 container_vars: cinder_backends: limit_container_types: cinder_volume lvm: volume_group: cinder-volumes volume_driver: cinder.volume.drivers.lvm.LVMISCSIDriver volume_backend_name: LVM_iSCSI # User defined Logging Hosts, this should be a required group log_hosts: aio1: ip: 172.29.236.100 # User defined Networking Hosts, this should be a required group network_hosts: aio1: ip: 172.29.236.100 haproxy_hosts: aio1: ip: 172.29.236.100 EOF cat > /etc/network/interfaces.d/aio-bridges.cfg <<EOF ## Required network bridges; br-vlan, br-vxlan, br-mgmt. auto br-mgmt iface br-mgmt inet static bridge_stp off bridge_waitport 0 bridge_fd 0 # Notice the bridge port is the vlan tagged interface bridge_ports none address 172.29.236.100 netmask 255.255.252.0 auto br-vxlan iface br-vxlan inet static bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports none address 172.29.240.100 netmask 255.255.252.0 auto br-vlan iface br-vlan inet manual bridge_stp off bridge_waitport 0 bridge_fd 0 # Notice this bridge port is an Untagged host interface bridge_ports none auto br-storage iface br-storage inet static bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports none address 172.29.244.100 netmask 255.255.252.0 auto br-snet iface br-snet inet static bridge_stp off bridge_waitport 0 bridge_fd 0 bridge_ports none # Notice there is NO physical interface in this bridge! address 172.29.248.100 netmask 255.255.252.0 EOF # Ensure the network source is in place if [ ! ""$(grep -Rni '^source\ /etc/network/interfaces.d/\*.cfg' /etc/network/interfaces)"" ]; then echo ""source /etc/network/interfaces.d/*.cfg"" | tee -a /etc/network/interfaces fi # Bring up the new interfaces for i in br-snet br-storage br-vlan br-vxlan br-mgmt; do /sbin/ifup $i || true done # Export the home directory just in case it's not set export HOME=""/root"" pushd /opt/ansible-lxc-rpc/rpc_deployment # Install all host bits install_bits setup/host-setup.yml # Install haproxy for dev purposes only install_bits infrastructure/haproxy-install.yml # Install all of the infra bits install_bits infrastructure/infrastructure-setup.yml # install all of the Openstack Bits install_bits openstack/keystone-all.yml install_bits openstack/glance-all.yml install_bits openstack/heat-all.yml install_bits openstack/nova-all.yml install_bits openstack/neutron-all.yml install_bits openstack/cinder-all.yml install_bits openstack/horizon-all.yml install_bits openstack/utility-all.yml install_bits openstack/rpc-support-all.yml # Stop rsyslog container(s) for i in $(lxc-ls | grep ""rsyslog""); do lxc-stop -k -n $i; lxc-start -d -n $i done # Reconfigure Rsyslog install_bits infrastructure/rsyslog-config.yml popd if ! modprobe vxlan; then MINIMUM_KERNEL_VERSION=$(awk '/required_kernel/ {print $2}' /opt/ansible-lxc-rpc/rpc_deployment/inventory/group_vars/all.yml) apt-get install -y linux-headers-${MINIMUM_KERNEL_VERSION} \ linux-image-${MINIMUM_KERNEL_VERSION} \ linux-image-extra-${MINIMUM_KERNEL_VERSION} rm /etc/update-motd.d/* cat > /etc/update-motd.d/00-rpc-notice<< EOF #!/usr/bin/env bash echo """" echo ""############ RPC DEPLOYMENT #############"" echo ""A new kernel was installed on this system. you will"" echo ""need to re-bootstrap Galera to get the cluster operataional."" echo ""from the /opt/ansible-lxc-rpc/rpc_deployment directory execute:"" echo """" echo ""ansible-playbook -e @/etc/rpc_deploy/user_variables.yml playbooks/infrastructure/galera-startup.yml"" EOF chmod +x /etc/update-motd.d/00-rpc-notice shutdown -r now fi",6,451
openstack%2Fironic~master~I47e73b8f59bc8afd91e9cafaa792a537dd214238,openstack/ironic,master,I47e73b8f59bc8afd91e9cafaa792a537dd214238,Updated from global requirements,MERGED,2014-12-12 22:15:02.000000000,2014-12-15 12:27:48.000000000,2014-12-15 12:27:47.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-12 22:15:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic/commit/3beaa5fc7497ed49d5de0b6286b730a82ee9d227', 'message': 'Updated from global requirements\n\nChange-Id: I47e73b8f59bc8afd91e9cafaa792a537dd214238\n'}]",0,141507,3beaa5fc7497ed49d5de0b6286b730a82ee9d227,10,4,1,11131,,,0,"Updated from global requirements

Change-Id: I47e73b8f59bc8afd91e9cafaa792a537dd214238
",git fetch https://review.opendev.org/openstack/ironic refs/changes/07/141507/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3beaa5fc7497ed49d5de0b6286b730a82ee9d227,openstack/requirements,python-glanceclient>=0.15.0,python-glanceclient>=0.14.0,1,1
openstack%2Fceilometer~master~If377ac49bf75c0698f4af6be021e8354240f4e42,openstack/ceilometer,master,If377ac49bf75c0698f4af6be021e8354240f4e42,Fix docs to suit merged compute/central agents concept,MERGED,2014-10-06 11:17:55.000000000,2014-12-15 12:27:40.000000000,2014-12-15 12:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7336}, {'_account_id': 8871}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-06 11:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a8dff6e4930d0cb239c558a53c30a5503673e228', 'message': 'Fix docs to suit merged compute/central agents concept\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 2, 'created': '2014-10-09 10:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3b28041389127ee66815f4365f740a7c74ecf01b', 'message': 'Fix docs to suit merged compute/central agents concept\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 3, 'created': '2014-11-07 13:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/73cf9ff368d8d4cf5bc09ebe78908716b3560ea9', 'message': 'Fix docs to suit merged compute/central agents concept\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 4, 'created': '2014-12-02 10:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/51ec98396d5d4189e1d5afc281ea9b2c66ee9800', 'message': 'Fix docs to suit merged compute/central agents concept\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42'}, {'number': 5, 'created': '2014-12-02 10:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/824a6aba33fb17bf2308154f4ef0dec10abf8329', 'message': 'Fix docs to suit merged compute/central agents concept\n\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42'}, {'number': 6, 'created': '2014-12-11 12:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/754d0aa9c51370369af8c463098c9292ea066676', 'message': 'Fix docs to suit merged compute/central agents concept\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 7, 'created': '2014-12-12 10:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6def52d6322d116c21af28293bbbdcfca1cf5f19', 'message': 'Fix docs to suit merged compute/central agents concept\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 8, 'created': '2014-12-12 10:19:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/81e56ab0ac193d229a368bf34f0b2cc794998cea', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42'}, {'number': 9, 'created': '2014-12-12 13:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9b9be6fd704fd42ac5d34e4caf424b517025bba1', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 10, 'created': '2014-12-12 15:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cc54098be8b288bf5ebf8d7077f726f206e787f2', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 11, 'created': '2014-12-12 18:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a54b245db45e48db91f6a451d1b90c395c7a3317', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 12, 'created': '2014-12-12 19:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5f6ffda7c846c2097332939bc2ff139dc5331d0c', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}, {'number': 13, 'created': '2014-12-15 10:12:53.000000000', 'files': ['doc/source/contributing/plugins.rst', 'doc/source/architecture.rst', 'doc/source/glossary.rst', 'doc/source/install/development.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/05158adafc0fa9df1d7d7e55396650e88fb4582a', 'message': 'Fix docs to suit merged compute/central agents concept\n\nDocImpact: Fix agents-related docs to describe polling agent\nRelated-Blueprint: merge-compute-central-agents\n\nChange-Id: If377ac49bf75c0698f4af6be021e8354240f4e42\n'}]",34,126262,05158adafc0fa9df1d7d7e55396650e88fb4582a,45,7,13,3012,,,0,"Fix docs to suit merged compute/central agents concept

DocImpact: Fix agents-related docs to describe polling agent
Related-Blueprint: merge-compute-central-agents

Change-Id: If377ac49bf75c0698f4af6be021e8354240f4e42
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/62/126262/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributing/plugins.rst', 'doc/source/architecture.rst', 'doc/source/glossary.rst', 'doc/source/install/development.rst']",4,a8dff6e4930d0cb239c558a53c30a5503673e228,merge-compute-and-central-agents,"Ceilometer has several daemons. The basic are: :term:`polling agent` running either on the Nova compute node(s) or :term:`polling agent` running on the central management node(s), :term:`collector` and :term:`notification agent` running on the cloud's management node(s)... note:: In fact, previously Ceilometer had separated compute and central agents, and their support is implemented in devstack_ right now, not one agent variant. This means that right now Ceilometer is broken in the devstack_. # It is needed to implement Devstack ceilometer-apolling support first enable_service ceilometer-apolling ceilometer-anotification ceilometer-collector","Ceilometer has several daemons. The basic are: :term:`compute agent` runs on the Nova compute node(s) while the :term:`central agent`, :term:`collector` and :term:`notification agent` run on the cloud's management node(s). enable_service ceilometer-acompute ceilometer-acentral ceilometer-anotification ceilometer-collector",35,31
openstack%2Fceilometer~master~I0e8c38ba624d0f9c88582a8b2d7180e808d262a7,openstack/ceilometer,master,I0e8c38ba624d0f9c88582a8b2d7180e808d262a7,Merge Central and Compute agents to *polling agent*,MERGED,2014-09-29 12:00:53.000000000,2014-12-15 12:27:31.000000000,2014-12-15 12:27:30.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-09-29 12:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8021e252472e1bd2fca08a8420f41525bcd566d2', 'message': ""==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* fix docs\n* fix tests (they're failing now due to the import issues and\n  other ones :D)\n* separate to several changes to improve readability\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n""}, {'number': 2, 'created': '2014-09-30 09:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3e107420469d46cf66a22ac00cff5e8a70196695', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* fix docs\n* separate to several changes to improve readability\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 3, 'created': '2014-09-30 11:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c2272002cdb76379c858dddee1db7ecec1d16ddd', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* fix docs\n* separate to several changes to improve readability\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 4, 'created': '2014-10-06 11:17:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4f03a9f3a9afda9a420dfeac0f1ec560b63b96aa', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* separate to several changes to improve readability\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 5, 'created': '2014-10-09 10:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/c8bb933b4e7d271ea222f65ba445c169aff71204', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 6, 'created': '2014-11-07 13:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ce5cb969d2e434f9bd3597064b8a3a9318bf506a', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 7, 'created': '2014-11-26 14:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6111a7e2e031086106fb6faf8b02f8e276b01212', 'message': '==POC== Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 8, 'created': '2014-11-26 15:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9ff0802f0dbe498cc322e486a25d8bba8a74332a', 'message': 'Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 9, 'created': '2014-11-26 15:34:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8a8139a6777b303a713ae433c17fd3f0360b5120', 'message': 'Merge Central and Compute agents to *polling agent*\n\nAs POC compute local_instances discovery has added to the base\ncompute pollster class.\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 10, 'created': '2014-11-27 13:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0929a90937ee2fec1d1adce35efa026cfab7b663', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 11, 'created': '2014-11-28 09:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d1bb2ee439268cd97d173d4944044f94db0763d7', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 12, 'created': '2014-12-02 10:05:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a78044d2b411f2a2f550b9d7bf1510b2e40e7904', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7'}, {'number': 13, 'created': '2014-12-04 16:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e1949cd82b545e902961e378e0998b232bd4a100', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* add pollster-list cmd option and its usage\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 14, 'created': '2014-12-04 17:22:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/06500006a1e267831ed3daffac3230ba6b229afd', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 15, 'created': '2014-12-05 16:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/22c0567782a64486906854679a511c8db5bc30cb', 'message': 'Merge Central and Compute agents to *polling agent*\n\n=== TO DO ===\n* test on the lab in all the variants (now tested for all-in-one, and\n  two agents running on one VM in the central group with ZK)\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 16, 'created': '2014-12-09 11:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4168c467339935a5d070e2185eab6b9d262b9a3d', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 17, 'created': '2014-12-09 16:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4ae84e88188a9cc5540a6b08a3458e758471f6a5', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 18, 'created': '2014-12-10 11:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7ecddbd0b3f8234cf2760dc5a0a02b49a2ada550', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 19, 'created': '2014-12-11 12:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/bde98b63a360901aacc6021f14b9881cdd277bda', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 20, 'created': '2014-12-12 10:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/adfda96d3534c19975a9cc6c8b22fbf151cfa48f', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 21, 'created': '2014-12-12 13:26:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4d0ddf04d128f730744351c78c411500cbc3485e', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 22, 'created': '2014-12-12 15:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b9f17ff0adbb050ff0977c7250e467defc43ba41', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 23, 'created': '2014-12-12 18:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e26e9a755121f24f1d7700af1b5013c610356bb3', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 24, 'created': '2014-12-12 19:11:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1d2ae3a6593dc30098c513ec89618a2ebab52da4', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}, {'number': 25, 'created': '2014-12-15 10:12:53.000000000', 'files': ['ceilometer/compute/pollsters/memory.py', 'ceilometer/tests/compute/pollsters/base.py', 'ceilometer/tests/compute/pollsters/test_instance.py', 'ceilometer/compute/pollsters/disk.py', 'ceilometer/opts.py', 'ceilometer/tests/compute/pollsters/test_cpu.py', 'ceilometer/agent/base.py', 'ceilometer/agent/manager.py', 'ceilometer/tests/agent/test_manager.py', 'ceilometer/tests/compute/pollsters/test_diskio.py', 'ceilometer/tests/compute/pollsters/test_location_metadata.py', 'ceilometer/compute/manager.py', 'ceilometer/compute/plugin.py', 'ceilometer/tests/ipmi/test_manager.py', 'ceilometer/compute/pollsters/cpu.py', 'ceilometer/compute/pollsters/instance.py', 'ceilometer/cmd/agent_central.py', 'ceilometer/tests/compute/test_manager.py', 'ceilometer/tests/compute/pollsters/test_memory.py', 'ceilometer/compute/pollsters/__init__.py', 'ceilometer/cmd/agent_compute.py', 'ceilometer/tests/agent/agentbase.py', 'ceilometer/tests/compute/pollsters/test_net.py', 'ceilometer/cmd/polling.py', 'setup.cfg', 'ceilometer/compute/pollsters/net.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/9fdcae9ea943a690b1eaf2d08ef63f710436f749', 'message': 'Merge Central and Compute agents to *polling agent*\n\nImplements-Blueprint: merge-compute-central-agents\n\nChange-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7\n'}]",37,124719,9fdcae9ea943a690b1eaf2d08ef63f710436f749,103,7,25,3012,,,0,"Merge Central and Compute agents to *polling agent*

Implements-Blueprint: merge-compute-central-agents

Change-Id: I0e8c38ba624d0f9c88582a8b2d7180e808d262a7
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/19/124719/23 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/compute/pollsters/memory.py', 'ceilometer/ipmi/notifications/ironic.py', 'ceilometer/agent/plugin_base.py', 'ceilometer/central/plugin.py', 'ceilometer/compute/pollsters/disk.py', 'ceilometer/hardware/plugin.py', 'ceilometer/profiler/notifications.py', 'ceilometer/image/glance.py', 'ceilometer/volume/notifications.py', 'ceilometer/network/services/base.py', 'ceilometer/ipmi/manager.py', 'ceilometer/agent/__init__.py', 'ceilometer/identity/notifications.py', 'ceilometer/agent/base.py', 'ceilometer/agent/manager.py', 'ceilometer/agent/discoveries/tenant.py', 'ceilometer/hardware/discovery.py', 'ceilometer/network/notifications.py', 'ceilometer/image/notifications.py', 'ceilometer/compute/manager.py', 'ceilometer/network/services/discovery.py', 'ceilometer/network/floatingip.py', 'ceilometer/compute/discovery.py', 'ceilometer/data_processing/notifications.py', 'ceilometer/energy/kwapi.py', 'ceilometer/compute/notifications/__init__.py', 'ceilometer/compute/plugin.py', 'ceilometer/network/statistics/__init__.py', 'ceilometer/compute/pollsters/cpu.py', 'ceilometer/compute/pollsters/instance.py', 'ceilometer/cmd/agent_central.py', 'ceilometer/cmd/polling_agent.py', 'ceilometer/middleware.py', 'ceilometer/agent/discoveries/__init__.py', 'ceilometer/agent/discoveries/endpoint.py', 'ceilometer/compute/pollsters/__init__.py', 'ceilometer/orchestration/notifications.py', 'ceilometer/objectstore/swift.py', 'setup.cfg', 'ceilometer/compute/pollsters/net.py']",40,8021e252472e1bd2fca08a8420f41525bcd566d2,merge-compute-and-central-agents,from ceilometer.compute import pollstersclass _Base(pollsters.BaseComputePollster):,from ceilometer.compute import pluginclass _Base(plugin.ComputePollster):,229,297
openstack%2Ftripleo-image-elements~master~Ia9a8cc09cde8f1d578b9aba9862f840b3a045874,openstack/tripleo-image-elements,master,Ia9a8cc09cde8f1d578b9aba9862f840b3a045874,Force install of mariadb.i686 1:5.5.39-1.fc20,ABANDONED,2014-12-12 17:06:17.000000000,2014-12-15 12:25:06.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-12-12 17:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/022c9c4cbd05c12dc4833293f7ee084f4b82f18d', 'message': 'Force install of mariadb.i686 1:5.5.39-1.fc20\n\nA Fedora update to this package is causing pip to fail to build\nthe mysql extension.\n\nPushing this to gerrit so we can see if it works and maybe pulled into\nCI, a better fix should be found for tripleo-image-elements.\n\nRelated-Bug: #1401957\nChange-Id: Ia9a8cc09cde8f1d578b9aba9862f840b3a045874\n'}, {'number': 2, 'created': '2014-12-13 01:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/36c6dcb4aa6c8786be6ee34e9c5e12c58250bce2', 'message': 'Force install of mariadb.i686 1:5.5.39-1.fc20\n\nA Fedora update to this package is causing pip to fail to build\nthe mysql extension.\n\nPushing this to gerrit so we can see if it works and maybe pulled into\nCI, a better fix should be found for tripleo-image-elements.\n\nRelated-Bug: #1401957\nChange-Id: Ia9a8cc09cde8f1d578b9aba9862f840b3a045874\n'}, {'number': 3, 'created': '2014-12-13 16:57:40.000000000', 'files': ['elements/mysql-dev/install.d/03-mysql-dev', 'elements/mariadb-dev/install.d/03-mariadb-dev', 'elements/mariadb-dev/install.d/package-installs-mariadb-dev'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/ad347a7cd7e034c10995f0131382c27734f66929', 'message': 'Force install of mariadb.i686 1:5.5.39-1.fc20\n\nA Fedora update to this package is causing pip to fail to build\nthe mysql extension.\n\nPushing this to gerrit so we can see if it works and maybe pulled into\nCI, a better fix should be found for tripleo-image-elements.\n\nRelated-Bug: #1401957\nChange-Id: Ia9a8cc09cde8f1d578b9aba9862f840b3a045874\n'}]",0,141429,ad347a7cd7e034c10995f0131382c27734f66929,14,3,3,1926,,,0,"Force install of mariadb.i686 1:5.5.39-1.fc20

A Fedora update to this package is causing pip to fail to build
the mysql extension.

Pushing this to gerrit so we can see if it works and maybe pulled into
CI, a better fix should be found for tripleo-image-elements.

Related-Bug: #1401957
Change-Id: Ia9a8cc09cde8f1d578b9aba9862f840b3a045874
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/29/141429/2 && git format-patch -1 --stdout FETCH_HEAD,['elements/mysql-dev/install.d/03-mysql-dev'],1,022c9c4cbd05c12dc4833293f7ee084f4b82f18d,141429,"if [ ""$DISTRO_NAME"" = ""fedora"" ] ; then # Bug #1401957 yum install -y --nogpg https://kojipkgs.fedoraproject.org//packages/mariadb/5.5.39/1.fc20/i686/mariadb-5.5.39-1.fc20.i686.rpm https://kojipkgs.fedoraproject.org//packages/mariadb/5.5.39/1.fc20/i686/mariadb-devel-5.5.39-1.fc20.i686.rpm https://kojipkgs.fedoraproject.org//packages/mariadb/5.5.39/1.fc20/i686/mariadb-libs-5.5.39-1.fc20.i686.rpm else install-packages -m mysql-dev mysql_dev_package fi",install-packages -m mysql-dev mysql_dev_package,6,1
openstack%2Fceilometer~master~If5f151ab7d30c9711929f6dcade553fdca09ab67,openstack/ceilometer,master,If5f151ab7d30c9711929f6dcade553fdca09ab67,Move central agent code to the polling agent module,MERGED,2014-10-09 10:14:32.000000000,2014-12-15 12:09:52.000000000,2014-12-15 12:09:51.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7049}, {'_account_id': 7336}, {'_account_id': 7478}, {'_account_id': 8871}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-09 10:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/cfd297b4ed56403d2bba1d2656ba7a85d782839f', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 2, 'created': '2014-11-07 13:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/16b9a054bd4542c84989625b596bf7d1871c35ff', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 3, 'created': '2014-11-26 14:58:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5c6e43ee9fee9fe8c161ac7acb2e85316d70d38e', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 4, 'created': '2014-11-28 09:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/7fd43d121405a21fd52dace1f86ba6776a4868f5', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 5, 'created': '2014-12-02 10:04:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/dbffbf8427c0c3b32f17797677d66b8a56ab5a5f', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67""}, {'number': 6, 'created': '2014-12-04 16:16:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d009f10883a4e7ad692fcaad529651646ca58a8d', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 7, 'created': '2014-12-05 16:45:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/5be73a4060530b875cdda94b97fe61dad447bd9e', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 8, 'created': '2014-12-09 11:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d23eeb5af61f15690a71589676916f0465581ae0', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 9, 'created': '2014-12-09 16:01:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/11fc4526ed53e2c5452d3cf1e1836544fb0b2f72', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 10, 'created': '2014-12-11 12:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/0468840acebff0fe7c71363950ebde0fd099fa33', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 11, 'created': '2014-12-12 10:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/33b599af930ea60174682fc33d3fc4ba25594e0e', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 12, 'created': '2014-12-12 15:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ecbe2b4fd866f4b702a5add3a89310b3eabb29ca', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}, {'number': 13, 'created': '2014-12-12 18:11:20.000000000', 'files': ['ceilometer/ipmi/notifications/ironic.py', 'ceilometer/agent/plugin_base.py', 'ceilometer/agent/discovery/endpoint.py', 'ceilometer/central/plugin.py', 'ceilometer/hardware/plugin.py', 'ceilometer/profiler/notifications.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/opts.py', 'ceilometer/volume/notifications.py', 'ceilometer/agent/discovery/__init__.py', 'ceilometer/ipmi/manager.py', 'ceilometer/ipmi/pollsters/node.py', 'ceilometer/agent/manager.py', 'ceilometer/tests/agent/__init__.py', 'ceilometer/network/notifications.py', 'ceilometer/image/notifications.py', 'ceilometer/network/floatingip.py', 'ceilometer/compute/discovery.py', 'ceilometer/data_processing/notifications.py', 'ceilometer/tests/ipmi/test_manager.py', 'ceilometer/middleware.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/orchestration/notifications.py', 'ceilometer/tests/network/services/test_fwaas.py', 'setup.cfg', 'ceilometer/tests/agent/test_plugin.py', 'ceilometer/tests/hardware/pollsters/base.py', 'ceilometer/tests/agent/test_discovery.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/network/services/test_vpnaas.py', 'ceilometer/image/glance.py', 'ceilometer/network/services/base.py', 'ceilometer/agent/__init__.py', 'ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/identity/notifications.py', 'ceilometer/agent/base.py', 'ceilometer/hardware/discovery.py', 'ceilometer/tests/agent/test_manager.py', 'ceilometer/compute/manager.py', 'ceilometer/network/services/discovery.py', 'ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/energy/kwapi.py', 'ceilometer/compute/notifications/__init__.py', 'ceilometer/compute/plugin.py', 'ceilometer/network/statistics/__init__.py', 'ceilometer/agent/discovery/tenant.py', 'ceilometer/cmd/agent_central.py', 'ceilometer/tests/agent/agentbase.py', 'ceilometer/objectstore/swift.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/68df2bb9dc311f0492906f2502d963ecebd3d339', 'message': ""Move central agent code to the polling agent module\n\nThat's the preparation for further compute and central agents\nmerge\n\nPartially-Implements-Blueprint: merge-compute-central-agents\n\nChange-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67\n""}]",4,127186,68df2bb9dc311f0492906f2502d963ecebd3d339,56,12,13,3012,,,0,"Move central agent code to the polling agent module

That's the preparation for further compute and central agents
merge

Partially-Implements-Blueprint: merge-compute-central-agents

Change-Id: If5f151ab7d30c9711929f6dcade553fdca09ab67
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/86/127186/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/ipmi/notifications/ironic.py', 'ceilometer/agent/plugin_base.py', 'ceilometer/central/plugin.py', 'ceilometer/hardware/plugin.py', 'ceilometer/profiler/notifications.py', 'ceilometer/tests/objectstore/test_swift.py', 'ceilometer/volume/notifications.py', 'ceilometer/ipmi/manager.py', 'ceilometer/ipmi/pollsters/node.py', 'ceilometer/agent/manager.py', 'ceilometer/tests/agent/__init__.py', 'ceilometer/network/notifications.py', 'ceilometer/image/notifications.py', 'ceilometer/network/floatingip.py', 'ceilometer/compute/discovery.py', 'ceilometer/data_processing/notifications.py', 'ceilometer/tests/ipmi/test_manager.py', 'ceilometer/middleware.py', 'ceilometer/tests/network/test_floatingip.py', 'ceilometer/agent/discoveries/endpoint.py', 'ceilometer/orchestration/notifications.py', 'ceilometer/tests/network/services/test_fwaas.py', 'setup.cfg', 'ceilometer/tests/agent/test_plugin.py', 'ceilometer/tests/hardware/pollsters/base.py', 'ceilometer/tests/agent/test_discovery.py', 'ceilometer/tests/image/test_glance.py', 'ceilometer/tests/network/services/test_vpnaas.py', 'ceilometer/image/glance.py', 'ceilometer/network/services/base.py', 'ceilometer/agent/__init__.py', 'ceilometer/ipmi/pollsters/sensor.py', 'ceilometer/identity/notifications.py', 'ceilometer/agent/base.py', 'ceilometer/agent/discoveries/tenant.py', 'ceilometer/hardware/discovery.py', 'ceilometer/tests/agent/test_manager.py', 'ceilometer/compute/manager.py', 'ceilometer/network/services/discovery.py', 'ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/tests/energy/test_kwapi.py', 'ceilometer/energy/kwapi.py', 'ceilometer/compute/notifications/__init__.py', 'ceilometer/compute/plugin.py', 'ceilometer/network/statistics/__init__.py', 'ceilometer/cmd/agent_central.py', 'ceilometer/tests/agentbase.py', 'ceilometer/agent/discoveries/__init__.py', 'ceilometer/tests/agent/agentbase.py', 'ceilometer/objectstore/swift.py']",50,cfd297b4ed56403d2bba1d2656ba7a85d782839f,merge-compute-and-central-agents,from ceilometer.agent import plugin_baseclass _Base(plugin_base.PollsterBase):,from ceilometer.central import pluginclass _Base(plugin.CentralPollster):,946,204
openstack%2Ffuel-docs~master~I25c03c6f7fd1e82c81c069e6bb2636260128a1ad,openstack/fuel-docs,master,I25c03c6f7fd1e82c81c069e6bb2636260128a1ad,Update Create Environment screenshot in wizard,ABANDONED,2014-12-15 08:32:36.000000000,2014-12-15 11:58:55.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-15 08:32:36.000000000', 'files': ['_images/user_screen_shots/name_environ.png', 'pages/user-guide/create-environment/1500-name-distro.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/9adfefc429ea011f4e48f474f2186a7af3d46cc3', 'message': 'Update Create Environment screenshot in wizard\n\nChange-Id: I25c03c6f7fd1e82c81c069e6bb2636260128a1ad\n'}]",0,141740,9adfefc429ea011f4e48f474f2186a7af3d46cc3,5,2,1,13082,,,0,"Update Create Environment screenshot in wizard

Change-Id: I25c03c6f7fd1e82c81c069e6bb2636260128a1ad
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/40/141740/1 && git format-patch -1 --stdout FETCH_HEAD,"['_images/user_screen_shots/name_environ.png', 'pages/user-guide/create-environment/1500-name-distro.rst']",2,9adfefc429ea011f4e48f474f2186a7af3d46cc3,create-env," Juno on Ubuntu 12.04.4 (2014.2-6.0) Juno on CentOS 6.5 (2014.2-6.0)it is formed by concatenating the Juno Release numberIn this case, the ""2014.2"" string corresponds to the Juno release version; the ""6.0"" string is the Mirantis OpenStack release number."," Icehouse on Ubuntu 12.04.4 (2014.1.1-5.1) Icehouse on CentOS 6.5 (2014.1.1-5.1)it is formed by concatenating the IceHouse Release numberIn this case, the ""2014.1.1"" string corresponds to the Icehouse release version; the ""5.1"" string is the Mirantis OpenStack release number.",5,5
openstack%2Fmistral~master~Id0cbd64774f732664f31dc76524dba1e04df380f,openstack/mistral,master,Id0cbd64774f732664f31dc76524dba1e04df380f,Refactor for-each,MERGED,2014-12-09 13:38:39.000000000,2014-12-15 11:37:46.000000000,2014-12-12 10:51:43.000000000,"[{'_account_id': 3}, {'_account_id': 7700}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-09 13:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/5276c9a5b161c0377848687895e2f7e5754a24f7', 'message': 'Refactor for-each\n\n * Create separated module for for-each\n\nChange-Id: Id0cbd64774f732664f31dc76524dba1e04df380f\n'}, {'number': 2, 'created': '2014-12-11 10:28:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/78ec3078510fd9ca744ca00087bf3653f6bb542c', 'message': 'Refactor for-each\n\n * Create separated module for for-each\n\nChange-Id: Id0cbd64774f732664f31dc76524dba1e04df380f\n'}, {'number': 3, 'created': '2014-12-11 11:36:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/mistral/commit/8d8db960a35e92c048b91e9f80f27db211a0db43', 'message': 'Refactor for-each\n\n * Create separated module for for-each\n\nChange-Id: Id0cbd64774f732664f31dc76524dba1e04df380f\n'}, {'number': 4, 'created': '2014-12-11 15:07:00.000000000', 'files': ['mistral/engine1/commands.py', 'mistral/workflow/base.py', 'mistral/utils/for_each_utils.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/f60158254d65731a67fd34239583d34289a41c45', 'message': 'Refactor for-each\n\n * Create separated module for for-each\n\nChange-Id: Id0cbd64774f732664f31dc76524dba1e04df380f\n'}]",16,140327,f60158254d65731a67fd34239583d34289a41c45,23,5,4,7700,,,0,"Refactor for-each

 * Create separated module for for-each

Change-Id: Id0cbd64774f732664f31dc76524dba1e04df380f
",git fetch https://review.opendev.org/openstack/mistral refs/changes/27/140327/4 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/engine1/commands.py', 'mistral/workflow/base.py', 'mistral/utils/for_each_utils.py']",3,5276c9a5b161c0377848687895e2f7e5754a24f7,bp/mistral-for-each-parallelism,"# Copyright 2014 - Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. import copy from mistral import expressions as expr def get_for_each_output(task_db, task_spec, raw_result): t_name = task_db.name # Calc output for for-each (only list form is used). out_key = (task_spec.get_publish().keys()[0] if task_spec.get_publish() else None) # TODO(nmakhotkin): Simplify calculating task output. e_data = raw_result.error output = expr.evaluate_recursively( task_spec.get_publish(), raw_result.data or {} ) if not task_db.output: task_db.output = {} task_output = copy.copy(task_db.output) if out_key: if out_key in task_output: task_output[out_key].append( output.get(out_key) or e_data ) else: task_output[out_key] = [output.get(out_key) or e_data] # Add same result to task output under key 'task'. task_output['task'] = { t_name: task_output[out_key] } else: if 'task' not in task_output: task_output.update({'task': {t_name: [output or e_data]}}) else: task_output['task'][t_name].append(output or e_data) return task_output def calc_for_each_input(action_input): # In case of for-each iterate over action_input and send # each part of data to executor. # Calculate action input collection for separating input. action_input_collection = [] for key, value in action_input.items(): for index, item in enumerate(value): iter_context = {key: item} if index >= len(action_input_collection): action_input_collection.append(iter_context) else: action_input_collection[index].update(iter_context) return action_input_collection",,81,54
openstack%2Frally~master~Iccd085a8e67b204d4f9a985d5628128f4299ff83,openstack/rally,master,Iccd085a8e67b204d4f9a985d5628128f4299ff83,Changing default new user password,MERGED,2014-11-26 06:47:18.000000000,2014-12-15 11:26:18.000000000,2014-12-15 11:26:17.000000000,"[{'_account_id': 3}, {'_account_id': 4428}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-11-26 06:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b5f365171cd08e7c58ba8b6270f79366b81b10b2', 'message': 'Changing default new user password\n\nDue to some security reasons, this patch changes default user assignment\nfrom ""same as name"" to uuid.\n\nChange-Id: Iccd085a8e67b204d4f9a985d5628128f4299ff83\n'}, {'number': 2, 'created': '2014-12-11 23:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6b2d4de968c632b4b755390a5ad5697f9f2ddfe0', 'message': 'Changing default new user password\n\nDue to some security reasons, this patch changes default user assignment\nfrom ""same as name"" to uuid.\n\nChange-Id: Iccd085a8e67b204d4f9a985d5628128f4299ff83\n'}, {'number': 3, 'created': '2014-12-12 00:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8ac778a9741df70353c5f0802fa48b065994ea1d', 'message': 'Changing default new user password\n\nDue to some security reasons, this patch changes default user assignment\nfrom ""same as name"" to uuid.\n\nChange-Id: Iccd085a8e67b204d4f9a985d5628128f4299ff83\n'}, {'number': 4, 'created': '2014-12-15 04:00:27.000000000', 'files': ['tests/unit/benchmark/scenarios/keystone/test_utils.py', 'rally/benchmark/scenarios/keystone/utils.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/049837c7f149fdfe0ccc9fc0d5be4fcf58d96b69', 'message': 'Changing default new user password\n\nDue to some security reasons, this patch changes default user assignment\nfrom ""same as name"" to uuid.\n\nAlso, named parameter ""password"" is removed from method signature.\nIf there is a need for a new user to be created with preselected\nthat can be done thru kwargs by seting value with the ""password"" key.\n\nChange-Id: Iccd085a8e67b204d4f9a985d5628128f4299ff83\n'}]",14,137289,049837c7f149fdfe0ccc9fc0d5be4fcf58d96b69,25,6,4,13606,,,0,"Changing default new user password

Due to some security reasons, this patch changes default user assignment
from ""same as name"" to uuid.

Also, named parameter ""password"" is removed from method signature.
If there is a need for a new user to be created with preselected
that can be done thru kwargs by seting value with the ""password"" key.

Change-Id: Iccd085a8e67b204d4f9a985d5628128f4299ff83
",git fetch https://review.opendev.org/openstack/rally refs/changes/89/137289/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/benchmark/scenarios/keystone/test_utils.py', 'rally/benchmark/scenarios/keystone/utils.py']",2,b5f365171cd08e7c58ba8b6270f79366b81b10b2,randomize_password,import uuid password = password or str(uuid.uuid4()), password = password or name,4,2
openstack%2Frally~master~I8e1fbab22c2da109bbc442f040fe259e5d22a62a,openstack/rally,master,I8e1fbab22c2da109bbc442f040fe259e5d22a62a,Configure gate-rally-dsvm-verify,MERGED,2014-12-04 23:20:02.000000000,2014-12-15 11:19:08.000000000,2014-12-15 11:19:07.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 10644}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-04 23:20:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/37f8c7fae6b0e32bb3b250dd6641808cdd48df9c', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 2, 'created': '2014-12-04 23:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/bf85dc3fdadffbe81c268c366d2a687c5141d84f', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 3, 'created': '2014-12-04 23:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/41179aca47aa0edfe5b7ca3656099932db2451da', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 4, 'created': '2014-12-05 00:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5b64af1d14c66514cffe4b17b3207b6df629b08a', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 5, 'created': '2014-12-05 09:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9d553decc8493fcee5009f0dfe01b48319f5cf23', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 6, 'created': '2014-12-05 10:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ed54b256c35471cd63e8a76c4abdee23a252ed2e', 'message': 'WIP: configure rally_verify_job\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 7, 'created': '2014-12-05 10:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c1a9a85eb9e029f8c7feb0a753a7b08a3d4d4c65', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 8, 'created': '2014-12-05 11:17:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f1a9421a5e9d3f87a05728c171da4da8907d1cf9', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 9, 'created': '2014-12-05 11:38:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1edd9bbb82e6b321bfc659952a6e74dc206a9935', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 10, 'created': '2014-12-05 12:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2373a00ef0ce48b22b0aed5b64690cbbdaf69318', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 11, 'created': '2014-12-05 15:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b8f8281a272ec54cbc17d01f93b33e1698e3499b', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 12, 'created': '2014-12-05 17:18:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/946b851aa213423ade02011607b4bec1b4f36162', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 13, 'created': '2014-12-06 11:30:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f571486c993ed34ff1427dc24ff172dbea1944e7', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 14, 'created': '2014-12-06 12:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9bc566066e67a569e718add89d8e0dc1f6e385db', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 15, 'created': '2014-12-06 12:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9d0fcf8b291acba0aa437875a0788cfa3890d17d', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 16, 'created': '2014-12-06 16:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0ec84c89624d23e3a9b0ba46b24284c8c75bd915', 'message': 'WIP: configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 17, 'created': '2014-12-07 22:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7a3cb01b5d7b20b167eaa1d80d760e4c33cea58b', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 18, 'created': '2014-12-07 22:28:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9136fc776a1ead386e29e4b7b0177f651ebcd2ae', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 19, 'created': '2014-12-08 11:01:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ec7260101c10d6ae7295f975a2d2d265b7207522', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 20, 'created': '2014-12-08 11:02:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b7eef9440076a06dc56f295cf04b1a193e833ef2', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 21, 'created': '2014-12-08 11:52:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/96dbd2c4506ff665b8de8d7af65d240ee775ef97', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 22, 'created': '2014-12-08 13:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d54dfbd7ad41410ae3100e637e6ef4f68261c58d', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 23, 'created': '2014-12-08 13:36:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/198c52263fe02dc5dd4cae131cf1f63dcbdd5631', 'message': 'Configure gate-rally-dsvm-verify\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 24, 'created': '2014-12-08 14:42:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/dac21a031bc1d5a59080822741edf93acf58f869', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept argument to render html-pages\n- Fixed logging debig-messages in tempest verifier(found bug during testing\n  this job)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] http://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 25, 'created': '2014-12-08 15:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2021e9e9d7dd9bd9e402be335f42ada3afaf59a9', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept argument to render html-pages\n- Fixed logging debug-messages in tempest verifier(found bug during testing\n  this job)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] http://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 26, 'created': '2014-12-08 16:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/87b31c51885eee7de2b63b8a1f61fed4c75cf156', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept argument to render html-pages\n- Fixed logging debug-messages in tempest verifier(found bug during testing\n  this job)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] http://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 27, 'created': '2014-12-08 19:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/73b589f9f915640868bf9798fda369eb1d94ac21', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept argument to render html-pages\n- Fixed logging debug-messages in tempest verifier(found bug during testing\n  this job)\n- Fixed check of debug mode is turned on(Also, added hacking rule for it)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] http://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 28, 'created': '2014-12-08 22:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/de137cea383a357b183f3b633bd2d6efab3e356a', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept argument to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 29, 'created': '2014-12-08 22:46:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4762a30ae38c2f6e1574c326859115567aa22db5', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 30, 'created': '2014-12-09 12:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b53449f3a9f81ae338fca485800062d78ea2e7df', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches: add launch of rally task for Tempest\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 31, 'created': '2014-12-11 20:58:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4da95f1643eaa05ad366c7d92409ec6d117e0f32', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches:\n- add launch of rally task for Tempest\n- add launch of random test set\n- add check for successful tests\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 32, 'created': '2014-12-11 20:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2cd97684496f2825d799c49eaa576c5dd0a4eca', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches:\n- add launch of rally task for Tempest\n- add launch of random test set\n- add check for successful tests\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 33, 'created': '2014-12-11 22:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1b370695b81d01a9bb2b9cff2d0d814fd574e277', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches:\n- add launch of rally task for Tempest\n- add launch of random test set\n- add check for successful tests\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}, {'number': 34, 'created': '2014-12-11 23:28:33.000000000', 'files': ['rally/ui/utils.py', 'tests/hacking/checks.py', 'rally/aas/rest/app.py', 'tests/unit/test_hacking.py', 'rally/utils.py', 'tests/ci/rally-verify.sh', 'rally/broker.py', 'rally/verification/verifiers/tempest/tempest.py', 'rally/orchestrator/api.py', 'rally/osclients.py', 'doc/samples/plugins/context/context_plugin.py', 'tests/functional/test_cli_verify.py', 'rally/log.py', 'rally/benchmark/context/cleanup/manager.py', 'rally/benchmark/runners/base.py', 'tests/ci/rally-gate/index_verify.mako', 'rally/cmd/commands/task.py', 'rally/verification/verifiers/tempest/subunit2json.py', 'rally/cmd/cliutils.py', 'tests/hacking/README.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/6c5e07e31c63385e6152ec5cb5229a45c803659f', 'message': 'Configure gate-rally-dsvm-verify\n\nRecently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].\nThis job implied functional testing integration Rally with Tempest[2].\n\nThis patch adds tests/ci/rally-verify.sh script, which is used by new job.\n\nrally-verify.sh does:\n- tempest installation\n- run ""rally verify start"" twice and print results\n- compare results of two verifications\n- list verifications\n- generate html page based on results\n\nTo implement gate-rally-dsvm-verify some changes were requered to\nexisting Rally code:\n- Added ability for rally/ui/utils.py to accept arguments to render html-pages\n- Fixed logging debug-messages in tempest verifier\n- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)\n\nTODO for future patches:\n- add launch of rally task for Tempest\n- add launch of random test set\n- add check for successful tests\n\n[1] https://review.openstack.org/#/c/137232\n[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler\n\nCloses-Bug: #1400465\nCloses-Bug: #1400518\n\nChange-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a\n'}]",44,139262,6c5e07e31c63385e6152ec5cb5229a45c803659f,94,8,34,9545,,,0,"Configure gate-rally-dsvm-verify

Recently, we added new job ""gate-rally-dsvm-verify"" for Rally[1].
This job implied functional testing integration Rally with Tempest[2].

This patch adds tests/ci/rally-verify.sh script, which is used by new job.

rally-verify.sh does:
- tempest installation
- run ""rally verify start"" twice and print results
- compare results of two verifications
- list verifications
- generate html page based on results

To implement gate-rally-dsvm-verify some changes were requered to
existing Rally code:
- Added ability for rally/ui/utils.py to accept arguments to render html-pages
- Fixed logging debug-messages in tempest verifier
- Fixed check ""is debug mode turned on or not""(also, added hacking rule for it)

TODO for future patches:
- add launch of rally task for Tempest
- add launch of random test set
- add check for successful tests

[1] https://review.openstack.org/#/c/137232
[2] https://www.mirantis.com/blog/rally-openstack-tempest-testing-made-simpler

Closes-Bug: #1400465
Closes-Bug: #1400518

Change-Id: I8e1fbab22c2da109bbc442f040fe259e5d22a62a
",git fetch https://review.opendev.org/openstack/rally refs/changes/62/139262/21 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ci/rally-verify.sh', 'tests/functional/test_cli_verify.py']",2,37f8c7fae6b0e32bb3b250dd6641808cdd48df9c,verify_job,""""""" DON'T ADD TESTS FOR ""rally verify"" HERE. Tests of Rally verification is implemented in separate job. Please look at tests/ci/rally-verify.sh for more details. """"""","import json import unittest from tests.functional import utils class VerifyTestCase(unittest.TestCase): def setUp(self): super(VerifyTestCase, self).setUp() self.rally = utils.Rally() def _verify_start_and_get_results_in_json(self, set_name): self.rally(""verify start %s"" % set_name) results = json.loads(self.rally(""verify results --json"")) failed_tests = results[""failures""] * 100.0 / results[""tests""] if failed_tests >= 50: self.fail(""Number of failed tests more than 50%."") show_output = self.rally(""verify show"") total_raw = show_output.split(""\n"").pop(5)[1:-1].replace("" "", """") total = total_raw.split('|') self.assertEqual(set_name, total[2]) self.assertEqual(results[""tests""], int(total[3])) self.assertEqual(results[""failures""], int(total[4])) self.assertEqual(""finished"", total[6]) def test_image_set(self): self._verify_start_and_get_results_in_json(""image"")",68,31
openstack%2Frally~master~I654ad4317b2d061dd899f5fdfb028cda50af9b8b,openstack/rally,master,I654ad4317b2d061dd899f5fdfb028cda50af9b8b,100% coverage in functional tests,MERGED,2014-12-01 17:50:05.000000000,2014-12-15 11:19:00.000000000,2014-12-15 11:18:59.000000000,"[{'_account_id': 3}, {'_account_id': 7369}, {'_account_id': 8507}, {'_account_id': 10475}, {'_account_id': 12395}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-01 17:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5e32fe2cedb1afa901bb2345f51d474ac6f0d986', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 2, 'created': '2014-12-01 17:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cf328ca26da1a463a3663fa79e96b11c4ab6578c', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 3, 'created': '2014-12-02 17:04:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1cb5236d88047b5357f61a05ec96300955372fee', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 4, 'created': '2014-12-02 17:10:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d9e5bf76f9bb74362ffc0b7965db72529a08a530', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 5, 'created': '2014-12-03 12:50:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/baf63fb9a222dfee152c5dfeb21463d42c65cd44', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 6, 'created': '2014-12-03 12:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/068d604952a6e784d4b0908951b6add268537b73', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 7, 'created': '2014-12-03 15:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d823111907e196917c037628157df9e9090913bf', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 8, 'created': '2014-12-04 14:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/823543539f6fd6e676f0c45c73d10a344cdcd7d9', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 9, 'created': '2014-12-04 17:11:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a4d3cc686c298097da0d1bc9b83b7cb666d3be6f', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 10, 'created': '2014-12-05 11:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c2c9e7e77ab495bd53da4dac48a90e932f60bf54', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 11, 'created': '2014-12-05 13:49:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e2379e63a9ef5caf0785ce00886301f4e4916214', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 12, 'created': '2014-12-05 13:50:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/2ec31f2f4b28f16f4b070c5bc9491109855eda98', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 13, 'created': '2014-12-05 15:55:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0c2b087c4242df71007bf5fca0abdfd2a117af76', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 14, 'created': '2014-12-05 17:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/805438eee4ef109eac01584cddfe0eeae3df23e4', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 15, 'created': '2014-12-06 14:40:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/483b3515adb5ef8e6883fe275a5b452c54570a8e', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 16, 'created': '2014-12-07 00:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/37c4a8e4ca12af10fda0501f1dbbe294ad122782', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 17, 'created': '2014-12-07 00:37:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cdb7cb95da45c6ac27cf8ef949c375a279c1fcb0', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 18, 'created': '2014-12-07 14:53:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/73ef90ea03a90bc377ad6fec497bc15cc73d4df4', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 19, 'created': '2014-12-07 22:04:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e4b5bd9904ebf08a5fadf2a6c7b11af2982a83b2', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 20, 'created': '2014-12-07 22:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f9fec9b928cdd9dbe044395b2a30369463211556', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 21, 'created': '2014-12-08 12:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/16c9ee8c6e48a7ceda8c958e1ab5c879fdc9819f', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 22, 'created': '2014-12-08 12:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/51d378c9a10d9b9a6ed67217791ef30743242aa2', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 23, 'created': '2014-12-08 16:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ed8547f4e983f7a1919bceabcce847312ac6d2ea', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 24, 'created': '2014-12-08 21:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d46bf3a72c4dcaee84a9e0b4313de0337bd14649', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 25, 'created': '2014-12-08 22:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a0780617b2bfb1803d3c32c9bbbca4b4f819afb8', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 26, 'created': '2014-12-09 16:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4193d359a1298c45bfaefeb066a4897f38de6f4a', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 27, 'created': '2014-12-11 19:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/fd70ece2b78578ff2f4581f1b9fa9c1c8c4cb977', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 28, 'created': '2014-12-11 19:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/460a624ee62633cd9c2d91d6a4ed8cd232fa36e1', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 29, 'created': '2014-12-12 13:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/00071f2176eb9f9ddaa20006e36c079c877dc224', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 30, 'created': '2014-12-12 14:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/334e1d7b46a3d05dddb06a75d7aa16cf4540f4e2', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 31, 'created': '2014-12-12 14:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ce421b3427bf247b9a8fe8dbdb5c4a830232c3f6', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 32, 'created': '2014-12-12 15:30:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1cdeb80cbaed2627bc5d4ed1450a9d2691eda7b9', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 33, 'created': '2014-12-12 15:38:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/67cf672e169d84f86fdf1d3c52cb6b70fc3524e3', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 34, 'created': '2014-12-12 16:24:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1f16e85256d5e62da95b93e235bc289238636500', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}, {'number': 35, 'created': '2014-12-13 09:16:48.000000000', 'files': ['tests/functional/test_cli_show.py', 'tests/functional/test_cli_task.py', 'tests/functional/test_cli_use.py', 'tests/functional/test_cli_deployment.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/b836fe428f42bb0f17f0f69bd50184707f7d69f7', 'message': '100% coverage in functional tests\n\nIn Rally, we have functional tests that run different CLI\ncommands and check that the CLI output contains all the expected\ndata.\n\nWe need to ensure that every single subcommand of “rally task”,\n“rally deployment” etc. (for example, “rally task start”, “rally\ntask report”) is covered in these functional test with all possible\nparameters usage (e.g. the “--deployment” parameter in “rally task\nstart --deployment <name>” didn’t get tested, which has lead to\nerrors recently).\n\nChange-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b\n'}]",35,138134,b836fe428f42bb0f17f0f69bd50184707f7d69f7,103,6,35,12395,,,0,"100% coverage in functional tests

In Rally, we have functional tests that run different CLI
commands and check that the CLI output contains all the expected
data.

We need to ensure that every single subcommand of “rally task”,
“rally deployment” etc. (for example, “rally task start”, “rally
task report”) is covered in these functional test with all possible
parameters usage (e.g. the “--deployment” parameter in “rally task
start --deployment <name>” didn’t get tested, which has lead to
errors recently).

Change-Id: I654ad4317b2d061dd899f5fdfb028cda50af9b8b
",git fetch https://review.opendev.org/openstack/rally refs/changes/34/138134/33 && git format-patch -1 --stdout FETCH_HEAD,"['.idea/inspectionProfiles/Project_Default.xml', '.idea/inspectionProfiles/profiles_settings.xml', 'tests/functional/test_cli_use.py', 'tests/functional/test_cli_deployment.py']",4,5e32fe2cedb1afa901bb2345f51d474ac6f0d986,functional_tests," def test_recreate(self): with mock.patch.dict(""os.environ"", utils.TEST_ENV): self.rally(""deployment create --name t_create_env --fromenv"") self.rally(""deployment recreate --name t_create_env"") self.assertIn(""t_create_env"", self.rally(""deployment list""))",,48,0
openstack%2Fheat~master~Id113a4c7182723179f61ee22009348af796db53f,openstack/heat,master,Id113a4c7182723179f61ee22009348af796db53f,Remove resource_by_refid() from OS::Heat::HARestarter,ABANDONED,2014-11-26 19:00:45.000000000,2014-12-15 11:11:27.000000000,,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-26 19:00:45.000000000', 'files': ['heat/tests/test_restarter.py', 'heat/engine/resources/instance.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/87fcb4f9794bff9a8bef68a1034f3a75ff16bca3', 'message': 'Remove resource_by_refid() from OS::Heat::HARestarter\n\nRemove self.stack.resource_by_refid() as a preparatory step for\nconvergence.\n\nChange-Id: Id113a4c7182723179f61ee22009348af796db53f\n'}]",0,137446,87fcb4f9794bff9a8bef68a1034f3a75ff16bca3,6,4,1,13323,,,0,"Remove resource_by_refid() from OS::Heat::HARestarter

Remove self.stack.resource_by_refid() as a preparatory step for
convergence.

Change-Id: Id113a4c7182723179f61ee22009348af796db53f
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/137446/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_restarter.py', 'heat/engine/resources/instance.py']",2,87fcb4f9794bff9a8bef68a1034f3a75ff16bca3,rm-resource_by_refid," resources = self.heat().resources.list(self.stack.id) victim = None for res in resources: if res.physical_resource_id == target_id: victim = res {'name': self.name, 'victim': victim.resource_name}) self.stack.restart_resource(victim.resource_name)"," victim = self.stack.resource_by_refid(target_id) {'name': self.name, 'victim': victim.name}) self.stack.restart_resource(victim.name)",24,4
openstack%2Fmurano-dashboard~master~I5d5f9544694a6f398ccdaf957241e86214bb75d8,openstack/murano-dashboard,master,I5d5f9544694a6f398ccdaf957241e86214bb75d8,Fixed selenium tests,MERGED,2014-12-13 18:31:59.000000000,2014-12-15 10:49:40.000000000,2014-12-15 10:49:39.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-13 18:31:59.000000000', 'files': ['muranodashboard/tests/functional/sanity_check.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/6a15520f72afe516ad2c1286f1d3d76e2bc9b496', 'message': ""Fixed selenium tests\n\nCommit a0edef60 in Horizon replaced glyph icons with font-awesome.\nThis awesome change update funtional tests in accordance with new\nelements' paths.\n\nChange-Id: I5d5f9544694a6f398ccdaf957241e86214bb75d8\n""}]",0,141570,6a15520f72afe516ad2c1286f1d3d76e2bc9b496,12,6,1,7600,,,0,"Fixed selenium tests

Commit a0edef60 in Horizon replaced glyph icons with font-awesome.
This awesome change update funtional tests in accordance with new
elements' paths.

Change-Id: I5d5f9544694a6f398ccdaf957241e86214bb75d8
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/70/141570/1 && git format-patch -1 --stdout FETCH_HEAD,['muranodashboard/tests/functional/sanity_check.py'],1,6a15520f72afe516ad2c1286f1d3d76e2bc9b496,, 'span.fa-plus') 'span.fa-plus') 'span.fa-plus') self.driver.find_element_by_css_selector('span.fa-plus').click(), 'span.glyphicon-plus') 'span.glyphicon-plus') 'span.glyphicon-plus') self.driver.find_element_by_css_selector('span.glyphicon-plus').click(),4,4
openstack%2Ftricircle~master~I392f96e2b47e19dc1c959994c02ab7d445da2e37,openstack/tricircle,master,I392f96e2b47e19dc1c959994c02ab7d445da2e37,modify l2-proxy to get token when it was expired,MERGED,2014-12-15 09:23:48.000000000,2014-12-15 10:45:02.000000000,2014-12-15 10:45:02.000000000,"[{'_account_id': 3}, {'_account_id': 9778}]","[{'number': 1, 'created': '2014-12-15 09:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tricircle/commit/a448074d5e5d88d980391bba9419dc15e24a9b34', 'message': 'modify l2-proxy to get token when it was expired\n\nChange-Id: I392f96e2b47e19dc1c959994c02ab7d445da2e37\n'}, {'number': 2, 'created': '2014-12-15 10:43:53.000000000', 'files': ['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/c3d4f220007754d1f481f55f5b46236a1fad7fd9', 'message': 'modify l2-proxy to get token when it was expired\n\nChange-Id: I392f96e2b47e19dc1c959994c02ab7d445da2e37\n'}]",0,141750,c3d4f220007754d1f481f55f5b46236a1fad7fd9,8,2,2,9778,,,0,"modify l2-proxy to get token when it was expired

Change-Id: I392f96e2b47e19dc1c959994c02ab7d445da2e37
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/50/141750/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronproxy/l2proxy/neutron/plugins/l2_proxy/agent/l2_proxy.py'],1,a448074d5e5d88d980391bba9419dc15e24a9b34,,"from neutronclient.common import exceptions from neutron.openstack.common import excutils cascaded_neutron_client = None portResponse = None if(not QueryPortsInfoInterface.cascaded_neutron_client): QueryPortsInfoInterface.cascaded_neutron_client = self._get_cascaded_neutron_client() try: portResponse = QueryPortsInfoInterface.cascaded_neutron_client.get('/ports', params=filters) LOG.debug(_('list ports, filters:%s, since_time:%s, limit=%s, marker=%s,' 'Response:%s'), str(filters), str(since_time), str(pagination_limit), str(pagination_marker), str(portResponse)) except exceptions.Unauthorized: QueryPortsInfoInterface.cascaded_neutron_client = self._get_cascaded_neutron_client() return self._list_ports(since_time, pagination_limit, pagination_marker) except Exception as e: with excutils.save_and_reraise_exception(): LOG.error(_('ERR: list ports failed!')) # TODO(ethuleau): Change ARP responder so it's not dependent on th"," neutronClient = self._get_cascaded_neutron_client() portResponse = neutronClient.get('/ports', params=filters) LOG.debug(_('list ports, filters:%s, since_time:%s, limit=%s, marker=%s,' 'Response:%s'), str(filters), str(since_time), str(pagination_limit), str(pagination_marker), str(portResponse)) if(not portResponse or (portResponse and ('ports' not in portResponse.keys()))): LOG.error(_(""ERR: list ports failed, Response: %s.""), str(portResponse)) # TODO(ethuleau): Change ARP responder so it's not dependent on the # ML2 l2 population mechanism driver. self.enable_distributed_routing = enable_distributed_routing self.arp_responder_enabled = arp_responder and self.l2_pop self.agent_state = { 'binary': 'neutron-openvswitch-agent', 'host': cfg.CONF.host, 'topic': q_const.L2_AGENT_TOPIC, 'configurations': {'bridge_mappings': bridge_mappings, 'tunnel_types': self.tunnel_types, 'tunneling_ip': local_ip, 'l2_population': self.l2_pop, 'arp_responder_enabled': self.arp_responder_enabled, 'enable_distributed_routing': self.enable_distributed_routing}, 'agent_type': q_const.AGENT_TYPE_OVS, 'start_flag': True} self.query_ports_info_inter = QueryPortsInfoInterface() self.cascaded_port_info = {} self.cascaded_host_map = {} self.first_scan_flag = True # Keep track of int_br's device count for use by _report_state() self.int_br_device_count = 0 self.int_br = ovs_lib.OVSBridge(integ_br, self.root_helper) self.setup_integration_br() # Stores port update notifications for processing in main rpc loop self.updated_ports = set() self.setup_rpc() self.bridge_mappings = bridge_mappings self.setup_physical_bridges(self.bridge_mappings) self.local_vlan_map = {} self.tun_br_ofports = {p_const.TYPE_GRE: {}, p_const.TYPE_VXLAN: {}} self.polling_interval = polling_interval self.minimize_polling = minimize_polling self.ovsdb_monitor_respawn_interval = ovsdb_monitor_respawn_interval if tunnel_types: self.enable_tunneling = True else: self.enable_tunneling = False self.local_ip = local_ip self.tunnel_count = 0 self.vxlan_udp_port = cfg.CONF.AGENT.vxlan_udp_port self.dont_fragment = cfg.CONF.AGENT.dont_fragment self.tun_br = None self.patch_int_ofport = constants.OFPORT_INVALID self.patch_tun_ofport = constants.OFPORT_INVALID if self.enable_tunneling: # The patch_int_ofport and patch_tun_ofport are updated # here inside the call to setup_tunnel_br self.setup_tunnel_br(tun_br) self.dvr_agent = ovs_dvr_neutron_agent.OVSDVRNeutronAgent( self.context, self.plugin_rpc, self.int_br, self.tun_br, self.patch_int_ofport, self.patch_tun_ofport, cfg.CONF.host, self.enable_tunneling, self.enable_distributed_routing) # self.dvr_agent.setup_dvr_flows_on_integ_tun_br() # Collect additional bridges to monitor self.ancillary_brs = self.setup_ancillary_bridges(integ_br, tun_br) # Security group agent support self.sg_agent = OVSSecurityGroupAgent(self.context, self.plugin_rpc, root_helper) # Initialize iteration counter self.iter_num = 0 self.run_daemon_loop = True def _report_state(self): # How many devices are likely used by a VM self.agent_state.get('configurations')['devices'] = ( self.int_br_device_count) try: self.state_rpc.report_state(self.context, self.agent_state, self.use_call) self.use_call = False self.agent_state.pop('start_flag', None) except Exception: LOG.exception(_(""Failed reporting state!"")) def setup_rpc(self): self.agent_id = 'ovs-agent-%s' % cfg.CONF.host self.topic = topics.AGENT self.plugin_rpc = OVSPluginApi(topics.PLUGIN) self.state_rpc = agent_rpc.PluginReportStateAPI(topics.PLUGIN) # RPC network init self.context = context.get_admin_context_without_session() # Handle updates from service self.endpoints = [self] # Define the listening consumers for the agent consumers = [[topics.PORT, topics.UPDATE], [topics.NETWORK, topics.DELETE], [constants.TUNNEL, topics.UPDATE], [topics.SECURITY_GROUP, topics.UPDATE], [topics.DVR, topics.UPDATE]] if self.l2_pop: consumers.append([topics.L2POPULATION, topics.UPDATE, cfg.CONF.host]) self.connection = agent_rpc.create_consumers(self.endpoints, self.topic, consumers) report_interval = cfg.CONF.AGENT.report_interval if report_interval: heartbeat = loopingcall.FixedIntervalLoopingCall( self._report_state) heartbeat.start(interval=report_interval) def get_net_uuid(self, vif_id): for network_id, vlan_mapping in self.local_vlan_map.iteritems(): if vif_id in vlan_mapping.vif_ports: return network_id def network_delete(self, context, **kwargs): LOG.debug(_(""network_delete received"")) network_id = kwargs.get('network_id') LOG.debug(_(""Delete %s""), network_id) # The network may not be defined on this agent lvm = self.local_vlan_map.get(network_id) if lvm: self.reclaim_local_vlan(network_id) else: LOG.debug(_(""Network %s not used on agent.""), network_id) def port_update(self, context, **kwargs): port = kwargs.get('port') # Put the port identifier in the updated_ports set. # Even if full port details might be provided to this call, # they are not used since there is no guarantee the notifications # are processed in the same order as the relevant API requests self.updated_ports.add(port['id']) LOG.debug(_(""port_update message processed for port %s""), port['id']) def tunnel_update(self, context, **kwargs): LOG.debug(_(""tunnel_update received"")) if not self.enable_tunneling: return tunnel_ip = kwargs.get('tunnel_ip') tunnel_id = kwargs.get('tunnel_id', self.get_ip_in_hex(tunnel_ip)) if not tunnel_id: return tunnel_type = kwargs.get('tunnel_type') if not tunnel_type: LOG.error(_(""No tunnel_type specified, cannot create tunnels"")) return if tunnel_type not in self.tunnel_types: LOG.error(_(""tunnel_type %s not supported by agent""), tunnel_type) return if tunnel_ip == self.local_ip: return tun_name = '%s-%s' % (tunnel_type, tunnel_id) if not self.l2_pop: self._setup_tunnel_port(self.tun_br, tun_name, tunnel_ip, tunnel_type) def _create_port(self, context, network_id, binding_profile, port_name, mac_address, ips): if(not network_id): LOG.error(_(""No network id is specified, cannot create port"")) return keystone_auth_url = cfg.CONF.AGENT.keystone_auth_url kwargs = {'auth_token': None, 'username': cfg.CONF.AGENT.neutron_user_name, 'password': cfg.CONF.AGENT.neutron_password, 'aws_creds': None, 'tenant': cfg.CONF.AGENT.neutron_tenant_name, # 'tenant_id':'e8f280855dbe42a189eebb0f3ecb94bb', #context.values['tenant'], 'auth_url': keystone_auth_url, 'roles': context.roles, 'is_admin': context.is_admin, 'region_name': cfg.CONF.AGENT.os_region_name} reqCon = neutron_proxy_context.RequestContext(**kwargs) openStackClients = clients.OpenStackClients(reqCon) neutronClient = openStackClients.neutron() req_props = {'network_id': network_id, 'name': port_name, 'admin_state_up': True, 'fixed_ips': [{'ip_address': ip} for ip in ips], 'mac_address': mac_address, 'binding:profile': binding_profile, 'device_owner': 'compute:' } bodyResponse = neutronClient.create_port({'port': req_props}) LOG.debug(_('create port, Response:%s'), str(bodyResponse)) return bodyResponse def _destroy_port(self, context, port_id): if(not port_id): LOG.error(_(""No port id is specified, cannot destroy port"")) return keystone_auth_url = cfg.CONF.AGENT.keystone_auth_url kwargs = {'auth_token': None, 'username': cfg.CONF.AGENT.neutron_user_name, 'password': cfg.CONF.AGENT.neutron_password, 'aws_creds': None, 'tenant': cfg.CONF.AGENT.neutron_tenant_name, # 'tenant_id':'e8f280855dbe42a189eebb0f3ecb94bb', #context.values['tenant'], 'auth_url': keystone_auth_url, 'roles': context.roles, 'is_admin': context.is_admin, 'region_name': cfg.CONF.AGENT.os_region_name} reqCon = neutron_proxy_context.RequestContext(**kwargs) openStackClients = clients.OpenStackClients(reqCon) neutronClient = openStackClients.neutron() bodyResponse = neutronClient.delete_port(port_id) LOG.debug(_('destroy port, Response:%s'), str(bodyResponse)) return bodyResponse def fdb_add(self, context, fdb_entries): LOG.debug(""fdb_add received"") for lvm, agent_ports in self.get_agent_ports(fdb_entries, self.local_vlan_map): cascaded_net_id = lvm.cascaded_net_id if not cascaded_net_id: continue agent_ports.pop(self.local_ip, None) if len(agent_ports): for agent_ip, ports in agent_ports.items(): binding_profile = {""port_key"": ""remote_port"", ""host_ip"": agent_ip} port_name = 'remote_port' mac_ip_map = {} for port in ports: if(port == q_const.FLOODING_ENTRY): continue if(const.DEVICE_OWNER_DVR_INTERFACE in port[1]): return ips = mac_ip_map.get(port[0]) if(ips): ips += port[2] mac_ip_map[port[0]] = ips else: mac_ip_map[port[0]] = [port[2]] for mac_address, ips in mac_ip_map.items(): if(lvm.remote_ports.get(mac_address) or lvm.vif_ports.get(mac_address)): continue port_ret = self._create_port(context, cascaded_net_id, binding_profile, port_name, mac_address, ips) if(not port_ret or (port_ret and (not port_ret.get('port')))): LOG.debug(_(""remote port created failed, "" ""binding_profile:%s, mac_address:%s""), str(binding_profile), mac_address) return port_id = port_ret['port'].get('id', None) if not port_id: LOG.debug(_(""remote port created failed, "" ""port_name%s, mac_address:%s""), port_name, mac_address) return remote_port = RemotePort(port_id, port_name, mac_address, binding_profile, ips) lvm.remote_ports[mac_address] = remote_port def fdb_remove(self, context, fdb_entries): LOG.debug(""fdb_remove received"") for lvm, agent_ports in self.get_agent_ports(fdb_entries, self.local_vlan_map): agent_ports.pop(self.local_ip, None) if len(agent_ports): for agent_ip, ports in agent_ports.items(): for port in ports: local_p = lvm.vif_ports.pop(port[0], None) if(local_p and local_p.port_id): self.cascaded_port_info.pop(local_p.port_id, None) continue remote_p = lvm.remote_ports.pop(port[0], None) if not remote_p: continue self._destroy_port(context, remote_p.port_id) def add_fdb_flow(self, br, port_info, remote_ip, lvm, ofport): if port_info == q_const.FLOODING_ENTRY: lvm.tun_ofports.add(ofport) ofports = ','.join(lvm.tun_ofports) br.mod_flow(table=constants.FLOOD_TO_TUN, dl_vlan=lvm.vlan, actions=""strip_vlan,set_tunnel:%s,output:%s"" % (lvm.segmentation_id, ofports)) else: self.setup_entry_for_arp_reply(br, 'add', lvm.vlan, port_info[0], port_info[1]) br.add_flow(table=constants.UCAST_TO_TUN, priority=2, dl_vlan=lvm.vlan, dl_dst=port_info[0], actions=""strip_vlan,set_tunnel:%s,output:%s"" % (lvm.segmentation_id, ofport)) def del_fdb_flow(self, br, port_info, remote_ip, lvm, ofport): if port_info == q_const.FLOODING_ENTRY: lvm.tun_ofports.remove(ofport) if len(lvm.tun_ofports) > 0: ofports = ','.join(lvm.tun_ofports) br.mod_flow(table=constants.FLOOD_TO_TUN, dl_vlan=lvm.vlan, actions=""strip_vlan,set_tunnel:%s,output:%s"" % (lvm.segmentation_id, ofports)) else: # This local vlan doesn't require any more tunnelling br.delete_flows(table=constants.FLOOD_TO_TUN, dl_vlan=lvm.vlan) else: self.setup_entry_for_arp_reply(br, 'remove', lvm.vlan, port_info[0], port_info[1]) br.delete_flows(table=constants.UCAST_TO_TUN, dl_vlan=lvm.vlan, dl_dst=port_info[0]) def _fdb_chg_ip(self, context, fdb_entries): LOG.debug(""update chg_ip received"") with self.tun_br.deferred() as deferred_br: self.fdb_chg_ip_tun(context, deferred_br, fdb_entries, self.local_ip, self.local_vlan_map) def setup_entry_for_arp_reply(self, br, action, local_vid, mac_address, ip_address): '''Set the ARP respond entry. When the l2 population mechanism driver and OVS supports to edit ARP fields, a table (ARP_RESPONDER) to resolve ARP locally is added to the tunnel bridge. ''' if not self.arp_responder_enabled: return mac = netaddr.EUI(mac_address, dialect=netaddr.mac_unix) ip = netaddr.IPAddress(ip_address) if action == 'add': actions = constants.ARP_RESPONDER_ACTIONS % {'mac': mac, 'ip': ip} br.add_flow(table=constants.ARP_RESPONDER, priority=1, proto='arp', dl_vlan=local_vid, nw_dst='%s' % ip, actions=actions) elif action == 'remove': br.delete_flows(table=constants.ARP_RESPONDER, proto='arp', dl_vlan=local_vid, nw_dst='%s' % ip) else: LOG.warning(_('Action %s not supported'), action) def provision_local_vlan(self, net_uuid, network_type, physical_network, segmentation_id, cascaded_net_id): '''Provisions a local VLAN. :param net_uuid: the uuid of the network associated with this vlan. :param network_type: the network type ('gre', 'vxlan', 'vlan', 'flat', 'local') :param physical_network: the physical network for 'vlan' or 'flat' :param segmentation_id: the VID for 'vlan' or tunnel ID for 'tunnel' ''' # On a restart or crash of OVS, the network associated with this VLAN # will already be assigned, so check for that here before assigning a # new one. lvm = self.local_vlan_map.get(net_uuid) if lvm: lvid = lvm.vlan else: if not self.available_local_vlans: LOG.error(_(""No local VLAN available for net-id=%s""), net_uuid) return lvid = self.available_local_vlans.pop() self.local_vlan_map[net_uuid] = LocalVLANMapping( network_type, physical_network, segmentation_id, cascaded_net_id) LOG.info(_(""Assigning %(vlan_id)s as local vlan for "" ""net-id=%(net_uuid)s""), {'vlan_id': lvid, 'net_uuid': net_uuid}) def reclaim_local_vlan(self, net_uuid): '''Reclaim a local VLAN. :param net_uuid: the network uuid associated with this vlan. :param lvm: a LocalVLANMapping object that tracks (vlan, lsw_id, vif_ids) mapping. ''' lvm = self.local_vlan_map.pop(net_uuid, None) if lvm is None: LOG.debug(_(""Network %s not used on agent.""), net_uuid) return LOG.info(_(""Reclaiming vlan = %(vlan_id)s from net-id = %(net_uuid)s""), {'vlan_id': lvm.vlan, 'net_uuid': net_uuid}) if lvm.network_type in constants.TUNNEL_NETWORK_TYPES: if self.enable_tunneling: self.tun_br.delete_flows( table=constants.TUN_TABLE[lvm.network_type], tun_id=lvm.segmentation_id) self.tun_br.delete_flows(dl_vlan=lvm.vlan) if self.l2_pop: # Try to remove tunnel ports if not used by other networks for ofport in lvm.tun_ofports: self.cleanup_tunnel_port(self.tun_br, ofport, lvm.network_type) elif lvm.network_type == p_const.TYPE_FLAT: if lvm.physical_network in self.phys_brs: # outbound br = self.phys_brs[lvm.physical_network] br.delete_flows(in_port=self.phys_ofports[lvm. physical_network], dl_vlan=lvm.vlan) # inbound br = self.int_br br.delete_flows(in_port=self.int_ofports[lvm.physical_network], dl_vlan=0xffff) elif lvm.network_type == p_const.TYPE_VLAN: if lvm.physical_network in self.phys_brs: # outbound br = self.phys_brs[lvm.physical_network] br.delete_flows(in_port=self.phys_ofports[lvm. physical_network], dl_vlan=lvm.vlan) # inbound br = self.int_br br.delete_flows(in_port=self.int_ofports[lvm.physical_network], dl_vlan=lvm.segmentation_id) elif lvm.network_type == p_const.TYPE_LOCAL: # no flows needed for local networks pass else: LOG.error(_(""Cannot reclaim unknown network type "" ""%(network_type)s for net-id=%(net_uuid)s""), {'network_type': lvm.network_type, 'net_uuid': net_uuid}) self.available_local_vlans.add(lvm.vlan) def port_bound(self, port, net_uuid, network_type, physical_network, segmentation_id, fixed_ips, device_owner, cascaded_port_info, ovs_restarted): '''Bind port to net_uuid/lsw_id and install flow for inbound traffic to vm. :param port: a ovslib.VifPort object. :param net_uuid: the net_uuid this port is to be associated with. :param network_type: the network type ('gre', 'vlan', 'flat', 'local') :param physical_network: the physical network for 'vlan' or 'flat' :param segmentation_id: the VID for 'vlan' or tunnel ID for 'tunnel' :param fixed_ips: the ip addresses assigned to this port :param device_owner: the string indicative of owner of this port :param ovs_restarted: indicates if this is called for an OVS restart. ''' if net_uuid not in self.local_vlan_map or ovs_restarted: self.provision_local_vlan(net_uuid, network_type, physical_network, segmentation_id, cascaded_port_info['network_id']) lvm = self.local_vlan_map[net_uuid] lvm.vif_ports[cascaded_port_info['mac_address']] = \ LocalPort(port, cascaded_port_info['id'], cascaded_port_info['mac_address']) def port_unbound(self, vif_id, net_uuid=None): '''Unbind port. Removes corresponding local vlan mapping object if this is its last VIF. :param vif_id: the id of the vif :param net_uuid: the net_uuid this port is associated with. ''' if net_uuid is None: net_uuid = self.get_net_uuid(vif_id) if not self.local_vlan_map.get(net_uuid): LOG.info(_('port_unbound(): net_uuid %s not in local_vlan_map'), net_uuid) return lvm = self.local_vlan_map[net_uuid] # if vif_id in lvm.vif_ports: # vif_port = lvm.vif_ports[vif_id] # self.dvr_agent.unbind_port_from_dvr(vif_port, # local_vlan_id=lvm.vlan) lvm.vif_ports.pop(vif_id, None) if not lvm.vif_ports: self.reclaim_local_vlan(net_uuid) def port_dead(self, port): '''Once a port has no binding, put it on the ""dead vlan"". :param port: a ovs_lib.VifPort object. ''' # Don't kill a port if it's already dead cur_tag = self.int_br.db_get_val(""Port"", port.port_name, ""tag"") if cur_tag != DEAD_VLAN_TAG: self.int_br.set_db_attribute(""Port"", port.port_name, ""tag"", DEAD_VLAN_TAG) self.int_br.add_flow(priority=2, in_port=port.ofport, actions=""drop"") def setup_integration_br(self): '''Setup the integration bridge. Create patch ports and remove all existing flows. :param bridge_name: the name of the integration bridge. :returns: the integration bridge ''' # Ensure the integration bridge is created. # ovs_lib.OVSBridge.create() will run # ovs-vsctl -- --may-exist add-br BRIDGE_NAME # which does nothing if bridge already exists. self.int_br.create() self.int_br.set_secure_mode() self.int_br.delete_port(cfg.CONF.OVS.int_peer_patch_port) self.int_br.remove_all_flows() # switch all traffic using L2 learning self.int_br.add_flow(priority=1, actions=""normal"") # Add a canary flow to int_br to track OVS restarts self.int_br.add_flow(table=constants.CANARY_TABLE, priority=0, actions=""drop"") def setup_ancillary_bridges(self, integ_br, tun_br): '''Setup ancillary bridges - for example br-ex.''' ovs_bridges = set(ovs_lib.get_bridges(self.root_helper)) # Remove all known bridges ovs_bridges.remove(integ_br) if self.enable_tunneling: ovs_bridges.remove(tun_br) br_names = [self.phys_brs[physical_network].br_name for physical_network in self.phys_brs] ovs_bridges.difference_update(br_names) # Filter list of bridges to those that have external # bridge-id's configured br_names = [] for bridge in ovs_bridges: id = ovs_lib.get_bridge_external_bridge_id(self.root_helper, bridge) if id != bridge: br_names.append(bridge) ovs_bridges.difference_update(br_names) ancillary_bridges = [] for bridge in ovs_bridges: br = ovs_lib.OVSBridge(bridge, self.root_helper) LOG.info(_('Adding %s to list of bridges.'), bridge) ancillary_bridges.append(br) return ancillary_bridges def setup_tunnel_br(self, tun_br_name=None): '''Setup the tunnel bridge. Creates tunnel bridge, and links it to the integration bridge using a patch port. :param tun_br_name: the name of the tunnel bridge. ''' if not self.tun_br: self.tun_br = ovs_lib.OVSBridge(tun_br_name, self.root_helper) self.tun_br.reset_bridge() self.patch_tun_ofport = self.int_br.add_patch_port( cfg.CONF.OVS.int_peer_patch_port, cfg.CONF.OVS.tun_peer_patch_port) self.patch_int_ofport = self.tun_br.add_patch_port( cfg.CONF.OVS.tun_peer_patch_port, cfg.CONF.OVS.int_peer_patch_port) if int(self.patch_tun_ofport) < 0 or int(self.patch_int_ofport) < 0: LOG.error(_(""Failed to create OVS patch port. Cannot have "" ""tunneling enabled on this agent, since this version "" ""of OVS does not support tunnels or patch ports. "" ""Agent terminated!"")) exit(1) self.tun_br.remove_all_flows() # Table 0 (default) will sort incoming traffic depending on in_port self.tun_br.add_flow(priority=1, in_port=self.patch_int_ofport, actions=""resubmit(,%s)"" % constants.PATCH_LV_TO_TUN) self.tun_br.add_flow(priority=0, actions=""drop"") if self.arp_responder_enabled: # ARP broadcast-ed request go to the local ARP_RESPONDER table to # be locally resolved self.tun_br.add_flow(table=constants.PATCH_LV_TO_TUN, priority=1, proto='arp', dl_dst=""ff:ff:ff:ff:ff:ff"", actions=(""resubmit(,%s)"" % constants.ARP_RESPONDER)) # PATCH_LV_TO_TUN table will handle packets coming from patch_int # unicasts go to table UCAST_TO_TUN where remote addresses are learnt self.tun_br.add_flow(table=constants.PATCH_LV_TO_TUN, priority=0, dl_dst=""00:00:00:00:00:00/01:00:00:00:00:00"", actions=""resubmit(,%s)"" % constants.UCAST_TO_TUN) # Broadcasts/multicasts go to table FLOOD_TO_TUN that handles flooding self.tun_br.add_flow(table=constants.PATCH_LV_TO_TUN, priority=0, dl_dst=""01:00:00:00:00:00/01:00:00:00:00:00"", actions=""resubmit(,%s)"" % constants.FLOOD_TO_TUN) # Tables [tunnel_type]_TUN_TO_LV will set lvid depending on tun_id # for each tunnel type, and resubmit to table LEARN_FROM_TUN where # remote mac addresses will be learnt for tunnel_type in constants.TUNNEL_NETWORK_TYPES: self.tun_br.add_flow(table=constants.TUN_TABLE[tunnel_type], priority=0, actions=""drop"") # LEARN_FROM_TUN table will have a single flow using a learn action to # dynamically set-up flows in UCAST_TO_TUN corresponding to remote mac # addresses (assumes that lvid has already been set by a previous flow) learned_flow = (""table=%s,"" ""priority=1,"" ""hard_timeout=300,"" ""NXM_OF_VLAN_TCI[0..11],"" ""NXM_OF_ETH_DST[]=NXM_OF_ETH_SRC[],"" ""load:0->NXM_OF_VLAN_TCI[],"" ""load:NXM_NX_TUN_ID[]->NXM_NX_TUN_ID[],"" ""output:NXM_OF_IN_PORT[]"" % constants.UCAST_TO_TUN) # Once remote mac addresses are learnt, output packet to patch_int self.tun_br.add_flow(table=constants.LEARN_FROM_TUN, priority=1, actions=""learn(%s),output:%s"" % (learned_flow, self.patch_int_ofport)) # Egress unicast will be handled in table UCAST_TO_TUN, where remote # mac addresses will be learned. For now, just add a default flow that # will resubmit unknown unicasts to table FLOOD_TO_TUN to treat them # as broadcasts/multicasts self.tun_br.add_flow(table=constants.UCAST_TO_TUN, priority=0, actions=""resubmit(,%s)"" % constants.FLOOD_TO_TUN) if self.arp_responder_enabled: # If none of the ARP entries correspond to the requested IP, the # broadcast-ed packet is resubmitted to the flooding table self.tun_br.add_flow(table=constants.ARP_RESPONDER, priority=0, actions=""resubmit(,%s)"" % constants.FLOOD_TO_TUN) # FLOOD_TO_TUN will handle flooding in tunnels based on lvid, # for now, add a default drop action self.tun_br.add_flow(table=constants.FLOOD_TO_TUN, priority=0, actions=""drop"") def get_peer_name(self, prefix, name): """"""Construct a peer name based on the prefix and name. The peer name can not exceed the maximum length allowed for a linux device. Longer names are hashed to help ensure uniqueness. """""" if len(prefix + name) <= q_const.DEVICE_NAME_MAX_LEN: return prefix + name # We can't just truncate because bridges may be distinguished # by an ident at the end. A hash over the name should be unique. # Leave part of the bridge name on for easier identification hashlen = 6 namelen = q_const.DEVICE_NAME_MAX_LEN - len(prefix) - hashlen new_name = ('%(prefix)s%(truncated)s%(hash)s' % {'prefix': prefix, 'truncated': name[0:namelen], 'hash': hashlib.sha1(name).hexdigest()[0:hashlen]}) LOG.warning(_(""Creating an interface named %(name)s exceeds the "" ""%(limit)d character limitation. It was shortened to "" ""%(new_name)s to fit.""), {'name': name, 'limit': q_const.DEVICE_NAME_MAX_LEN, 'new_name': new_name}) return new_name def setup_physical_bridges(self, bridge_mappings): '''Setup the physical network bridges. Creates physical network bridges and links them to the integration bridge using veths. :param bridge_mappings: map physical network names to bridge names. ''' self.phys_brs = {} self.int_ofports = {} self.phys_ofports = {} ip_wrapper = ip_lib.IPWrapper(self.root_helper) ovs_bridges = ovs_lib.get_bridges(self.root_helper) for physical_network, bridge in bridge_mappings.iteritems(): LOG.info(_(""Mapping physical network %(physical_network)s to "" ""bridge %(bridge)s""), {'physical_network': physical_network, 'bridge': bridge}) # setup physical bridge if bridge not in ovs_bridges: LOG.error(_(""Bridge %(bridge)s for physical network "" ""%(physical_network)s does not exist. Agent "" ""terminated!""), {'physical_network': physical_network, 'bridge': bridge}) sys.exit(1) br = ovs_lib.OVSBridge(bridge, self.root_helper) br.remove_all_flows() br.add_flow(priority=1, actions=""normal"") self.phys_brs[physical_network] = br # interconnect physical and integration bridges using veth/patchs int_if_name = self.get_peer_name(constants.PEER_INTEGRATION_PREFIX, bridge) phys_if_name = self.get_peer_name(constants.PEER_PHYSICAL_PREFIX, bridge) self.int_br.delete_port(int_if_name) br.delete_port(phys_if_name) if self.use_veth_interconnection: if ip_lib.device_exists(int_if_name, self.root_helper): ip_lib.IPDevice(int_if_name, self.root_helper).link.delete() # Give udev a chance to process its rules here, to avoid # race conditions between commands launched by udev rules # and the subsequent call to ip_wrapper.add_veth utils.execute(['/sbin/udevadm', 'settle', '--timeout=10']) int_veth, phys_veth = ip_wrapper.add_veth(int_if_name, phys_if_name) int_ofport = self.int_br.add_port(int_veth) phys_ofport = br.add_port(phys_veth) else: # Create patch ports without associating them in order to block # untranslated traffic before association int_ofport = self.int_br.add_patch_port( int_if_name, constants.NONEXISTENT_PEER) phys_ofport = br.add_patch_port( phys_if_name, constants.NONEXISTENT_PEER) self.int_ofports[physical_network] = int_ofport self.phys_ofports[physical_network] = phys_ofport # block all untranslated traffic between bridges self.int_br.add_flow(priority=2, in_port=int_ofport, actions=""drop"") br.add_flow(priority=2, in_port=phys_ofport, actions=""drop"") if self.use_veth_interconnection: # enable veth to pass traffic int_veth.link.set_up() phys_veth.link.set_up() if self.veth_mtu: # set up mtu size for veth interfaces int_veth.link.set_mtu(self.veth_mtu) phys_veth.link.set_mtu(self.veth_mtu) else: # associate patch ports to pass traffic self.int_br.set_db_attribute('Interface', int_if_name, 'options:peer', phys_if_name) br.set_db_attribute('Interface', phys_if_name, 'options:peer', int_if_name) def get_port_id_from_profile(self, profile): return profile.get('cascading_port_id') def analysis_ports_info(self, ports_info): cur_ports = set() for port in ports_info: profile = port['binding:profile'] cascading_port_id = self.get_port_id_from_profile(profile) if(not cascading_port_id): continue self.cascaded_port_info[cascading_port_id] = port cur_ports.add(cascading_port_id) return cur_ports def scan_ports(self, registered_ports, updated_ports=None): if(self.first_scan_flag == True): ports_info = self.query_ports_info_inter.get_update_net_port_info() self.first_scan_flag = False else: pre_time = time.time() - self.polling_interval - 1 since_time = time.strftime(""%Y-%m-%d %H:%M:%S"", time.gmtime(pre_time)) ports_info = self.query_ports_info_inter.get_update_port_info_since( since_time) added_or_updated_ports = self.analysis_ports_info(ports_info) cur_ports = set(self.cascaded_port_info.keys()) | added_or_updated_ports self.int_br_device_count = len(cur_ports) port_info = {'current': cur_ports} if updated_ports is None: updated_ports = set() #updated_ports.update(self.check_changed_vlans(registered_ports)) if updated_ports: # Some updated ports might have been removed in the # meanwhile, and therefore should not be processed. # In this case the updated port won't be found among # current ports. updated_ports &= cur_ports if updated_ports: port_info['updated'] = updated_ports # FIXME(salv-orlando): It's not really necessary to return early # if nothing has changed. if cur_ports == registered_ports: # No added or removed ports to set, just return here return port_info port_info['added'] = cur_ports - registered_ports # Remove all the known ports not found on the integration bridge port_info['removed'] = registered_ports - cur_ports return port_info def check_changed_vlans(self, registered_ports): """"""Return ports which have lost their vlan tag. The returned value is a set of port ids of the ports concerned by a vlan tag loss. """""" port_tags = self.int_br.get_port_tag_dict() changed_ports = set() for lvm in self.local_vlan_map.values(): for port in registered_ports: if ( port in lvm.vif_ports and lvm.vif_ports[port].port_name in port_tags and port_tags[lvm.vif_ports[port].port_name] != lvm.vlan ): LOG.info( _(""Port '%(port_name)s' has lost "" ""its vlan tag '%(vlan_tag)d'!""), {'port_name': lvm.vif_ports[port].port_name, 'vlan_tag': lvm.vlan} ) changed_ports.add(port) return changed_ports def update_ancillary_ports(self, registered_ports): ports = set() for bridge in self.ancillary_brs: ports |= bridge.get_vif_port_set() if ports == registered_ports: return added = ports - registered_ports removed = registered_ports - ports return {'current': ports, 'added': added, 'removed': removed} def treat_vif_port(self, vif_port, port_id, network_id, network_type, physical_network, segmentation_id, admin_state_up, fixed_ips, device_owner, cascaded_port_info, ovs_restarted): # When this function is called for a port, the port should have # an OVS ofport configured, as only these ports were considered # for being treated. If that does not happen, it is a potential # error condition of which operators should be aware if admin_state_up: self.port_bound(vif_port, network_id, network_type, physical_network, segmentation_id, fixed_ips, device_owner, cascaded_port_info, ovs_restarted) else: self.port_dead(vif_port) def _setup_tunnel_port(self, br, port_name, remote_ip, tunnel_type): ofport = br.add_tunnel_port(port_name, remote_ip, self.local_ip, tunnel_type, self.vxlan_udp_port, self.dont_fragment) ofport_int = -1 try: ofport_int = int(ofport) except (TypeError, ValueError): LOG.exception(_(""ofport should have a value that can be "" ""interpreted as an integer"")) if ofport_int < 0: LOG.error(_(""Failed to set-up %(type)s tunnel port to %(ip)s""), {'type': tunnel_type, 'ip': remote_ip}) return 0 self.tun_br_ofports[tunnel_type][remote_ip] = ofport # Add flow in default table to resubmit to the right # tunnelling table (lvid will be set in the latter) br.add_flow(priority=1, in_port=ofport, actions=""resubmit(,%s)"" % constants.TUN_TABLE[tunnel_type]) ofports = ','.join(self.tun_br_ofports[tunnel_type].values()) if ofports and not self.l2_pop: # Update flooding flows to include the new tunnel for network_id, vlan_mapping in self.local_vlan_map.iteritems(): if vlan_mapping.network_type == tunnel_type: br.mod_flow(table=constants.FLOOD_TO_TUN, dl_vlan=vlan_mapping.vlan, actions=""strip_vlan,set_tunnel:%s,output:%s"" % (vlan_mapping.segmentation_id, ofports)) return ofport def setup_tunnel_port(self, br, remote_ip, network_type): remote_ip_hex = self.get_ip_in_hex(remote_ip) if not remote_ip_hex: return 0 port_name = '%s-%s' % (network_type, remote_ip_hex) ofport = self._setup_tunnel_port(br, port_name, remote_ip, network_type) return ofport def cleanup_tunnel_port(self, br, tun_ofport, tunnel_type): # Check if this tunnel port is still used for lvm in self.local_vlan_map.values(): if tun_ofport in lvm.tun_ofports: break # If not, remove it else: for remote_ip, ofport in self.tun_br_ofports[tunnel_type].items(): if ofport == tun_ofport: port_name = '%s-%s' % (tunnel_type, self.get_ip_in_hex(remote_ip)) br.delete_port(port_name) br.delete_flows(in_port=ofport) self.tun_br_ofports[tunnel_type].pop(remote_ip, None) def compare_port_info(self, details, cascaded_port_info): if details is None or cascaded_port_info is None: return False details_ips_set = set([ip['ip_address'] for ip in details['fixed_ips']]) cascaded_ips_set = set([ip['ip_address'] for ip in cascaded_port_info['fixed_ips']]) return details_ips_set == cascaded_ips_set def get_cascading_neutron_client(self): context = n_context.get_admin_context_without_session() keystone_auth_url = cfg.CONF.AGENT.cascading_auth_url kwargs = {'auth_token': None, 'username': cfg.CONF.AGENT.cascading_user_name, 'password': cfg.CONF.AGENT.cascading_password, 'aws_creds': None, 'tenant': cfg.CONF.AGENT.cascading_tenant_name, # 'tenant_id':'e8f280855dbe42a189eebb0f3ecb94bb', #context.values['tenant'], 'auth_url': keystone_auth_url, 'roles': context.roles, 'is_admin': context.is_admin, 'region_name': cfg.CONF.AGENT.cascading_os_region_name} reqCon = neutron_proxy_context.RequestContext(**kwargs) openStackClients = clients.OpenStackClients(reqCon) neutronClient = openStackClients.neutron() return neutronClient def update_cascading_port_profile(self, cascaded_host_ip, cascaded_port_info, details): if(not cascaded_host_ip): return profile = {'host_ip': cascaded_host_ip, 'cascaded_net_id': { details['network_id']: {}}, 'cascaded_subnet_id': {}} net_map = profile['cascaded_net_id'][details['network_id']] net_map[cfg.CONF.host] = cascaded_port_info['network_id'] subnet_map = profile['cascaded_subnet_id'] for fi_ing in details['fixed_ips']: for fi_ed in cascaded_port_info['fixed_ips']: if (fi_ed['ip_address'] == fi_ing['ip_address']): subnet_map[fi_ing['subnet_id']] = {} subnet_map[fi_ing['subnet_id']][cfg.CONF.host] = \ fi_ed['subnet_id'] break neutron_client = self.get_cascading_neutron_client() req_props = {""binding:profile"": profile} port_ret = neutron_client.update_port(details['port_id'], {'port': req_props}) LOG.debug(_('update compute port, Response:%s'), str(port_ret)) def get_cascaded_neutron_client(self): context = n_context.get_admin_context_without_session() keystone_auth_url = cfg.CONF.AGENT.keystone_auth_url kwargs = {'auth_token': None, 'username': cfg.CONF.AGENT.neutron_user_name, 'password': cfg.CONF.AGENT.neutron_password, 'aws_creds': None, 'tenant': cfg.CONF.AGENT.neutron_tenant_name, # 'tenant_id':'e8f280855dbe42a189eebb0f3ecb94bb', #context.values['tenant'], 'auth_url': keystone_auth_url, 'roles': context.roles, 'is_admin': context.is_admin, 'region_name': cfg.CONF.AGENT.os_region_name} reqCon = neutron_proxy_context.RequestContext(**kwargs) openStackClients = clients.OpenStackClients(reqCon) neutronClient = openStackClients.neutron() return neutronClient def get_cascaded_host_ip(self, ed_host_id): host_ip = self.cascaded_host_map.get(ed_host_id) if(host_ip): return host_ip neutron_client = self.get_cascaded_neutron_client() agent_ret = neutron_client.list_agents(host=ed_host_id, agent_type='Open vSwitch agent') if(not agent_ret or (agent_ret and (not agent_ret.get('agents')))): LOG.debug(_(""get agent failed, host_id:%s""), ed_host_id) return agent_config = agent_ret['agents'][0].get('configurations', None) # json.loads(agent_config) configuration = agent_config host_ip = configuration.get('tunneling_ip') if(host_ip): self.cascaded_host_map[ed_host_id] = host_ip return host_ip def treat_devices_added_or_updated(self, devices, ovs_restarted): skipped_devices = [] try: devices_details_list = self.plugin_rpc.get_devices_details_list( self.context, devices, self.agent_id, cfg.CONF.host) except Exception as e: raise DeviceListRetrievalError(devices=devices, error=e) for details in devices_details_list: device = details['device'] LOG.debug(""Processing port: %s"", device) if 'port_id' in details: cascaded_port_info = self.cascaded_port_info.get(device) if(not self.compare_port_info(details, cascaded_port_info)): LOG.info(_(""Port %(device)s can not updated. "" ""Because port info in cascading and cascaded layer"" ""are different, Details: %(details)s""), {'device': device, 'details': details}) skipped_devices.add(device) return skipped_devices LOG.info(_(""Port %(device)s updated. Details: %(details)s""), {'device': device, 'details': details}) self.treat_vif_port(device, details['port_id'], details['network_id'], details['network_type'], details['physical_network'], details['segmentation_id'], details['admin_state_up'], details['fixed_ips'], details['device_owner'], cascaded_port_info, ovs_restarted) # update cascading port, modify binding:profile to add host_ip # and cascaded net_id/cascaded_subnet_id if('compute' in details['device_owner']): ed_host_id = cascaded_port_info['binding:host_id'] cascaded_host_ip = self.get_cascaded_host_ip(ed_host_id) self.update_cascading_port_profile(cascaded_host_ip, cascaded_port_info, details) # update plugin about port status # FIXME(salv-orlando): Failures while updating device status # must be handled appropriately. Otherwise this might prevent # neutron server from sending network-vif-* events to the nova # API server, thus possibly preventing instance spawn. if details.get('admin_state_up'): LOG.debug(_(""Setting status for %s to UP""), device) self.plugin_rpc.update_device_up( self.context, device, self.agent_id, cfg.CONF.host) else: LOG.debug(_(""Setting status for %s to DOWN""), device) self.plugin_rpc.update_device_down( self.context, device, self.agent_id, cfg.CONF.host) LOG.info(_(""Configuration for device %s completed.""), device) # else: # LOG.warn(_(""Device %s not defined on plugin""), device) # if (port and port.ofport != -1): # self.port_dead(port) return skipped_devices def treat_ancillary_devices_added(self, devices): try: devices_details_list = self.plugin_rpc.get_devices_details_list( self.context, devices, self.agent_id, cfg.CONF.host) except Exception as e: raise DeviceListRetrievalError(devices=devices, error=e) for details in devices_details_list: device = details['device'] LOG.info(_(""Ancillary Port %s added""), device) # update plugin about port status self.plugin_rpc.update_device_up(self.context, device, self.agent_id, cfg.CONF.host) def treat_devices_removed(self, devices): resync = False self.sg_agent.remove_devices_filter(devices) for device in devices: LOG.info(_(""Attachment %s removed""), device) try: self.plugin_rpc.update_device_down(self.context, device, self.agent_id, cfg.CONF.host) except Exception as e: LOG.debug(_(""port_removed failed for %(device)s: %(e)s""), {'device': device, 'e': e}) resync = True continue self.port_unbound(device) return resync def treat_ancillary_devices_removed(self, devices): resync = False for device in devices: LOG.info(_(""Attachment %s removed""), device) try: details = self.plugin_rpc.update_device_down(self.context, device, self.agent_id, cfg.CONF.host) except Exception as e: LOG.debug(_(""port_removed failed for %(device)s: %(e)s""), {'device': device, 'e': e}) resync = True continue if details['exists']: LOG.info(_(""Port %s updated.""), device) # Nothing to do regarding local networking else: LOG.debug(_(""Device %s not defined on plugin""), device) return resync def process_network_ports(self, port_info, ovs_restarted): resync_a = False resync_b = False # TODO(salv-orlando): consider a solution for ensuring notifications # are processed exactly in the same order in which they were # received. This is tricky because there are two notification # sources: the neutron server, and the ovs db monitor process # If there is an exception while processing security groups ports # will not be wired anyway, and a resync will be triggered # TODO(salv-orlando): Optimize avoiding applying filters unnecessarily # (eg: when there are no IP address changes) self.sg_agent.setup_port_filters(port_info.get('added', set()), port_info.get('updated', set())) # VIF wiring needs to be performed always for 'new' devices. # For updated ports, re-wiring is not needed in most cases, but needs # to be performed anyway when the admin state of a device is changed. # A device might be both in the 'added' and 'updated' # list at the same time; avoid processing it twice. devices_added_updated = (port_info.get('added', set()) | port_info.get('updated', set())) if devices_added_updated: start = time.time() try: skipped_devices = self.treat_devices_added_or_updated( devices_added_updated, ovs_restarted) LOG.debug(_(""process_network_ports - iteration:%(iter_num)d -"" ""treat_devices_added_or_updated completed. "" ""Skipped %(num_skipped)d devices of "" ""%(num_current)d devices currently available. "" ""Time elapsed: %(elapsed).3f""), {'iter_num': self.iter_num, 'num_skipped': len(skipped_devices), 'num_current': len(port_info['current']), 'elapsed': time.time() - start}) # Update the list of current ports storing only those which # have been actually processed. port_info['current'] = (port_info['current'] - set(skipped_devices)) except DeviceListRetrievalError: # Need to resync as there was an error with server # communication. LOG.exception(_(""process_network_ports - iteration:%d - "" ""failure while retrieving port details "" ""from server""), self.iter_num) resync_a = True if 'removed' in port_info: start = time.time() resync_b = self.treat_devices_removed(port_info['removed']) LOG.debug(_(""process_network_ports - iteration:%(iter_num)d -"" ""treat_devices_removed completed in %(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) # If one of the above operations fails => resync with plugin return (resync_a | resync_b) def process_ancillary_network_ports(self, port_info): resync_a = False resync_b = False if 'added' in port_info: start = time.time() try: self.treat_ancillary_devices_added(port_info['added']) LOG.debug(_(""process_ancillary_network_ports - iteration: "" ""%(iter_num)d - treat_ancillary_devices_added "" ""completed in %(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) except DeviceListRetrievalError: # Need to resync as there was an error with server # communication. LOG.exception(_(""process_ancillary_network_ports - "" ""iteration:%d - failure while retrieving "" ""port details from server""), self.iter_num) resync_a = True if 'removed' in port_info: start = time.time() resync_b = self.treat_ancillary_devices_removed( port_info['removed']) LOG.debug(_(""process_ancillary_network_ports - iteration: "" ""%(iter_num)d - treat_ancillary_devices_removed "" ""completed in %(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) # If one of the above operations fails => resync with plugin return (resync_a | resync_b) def get_ip_in_hex(self, ip_address): try: return '%08x' % netaddr.IPAddress(ip_address, version=4) except Exception: LOG.warn(_(""Unable to create tunnel port. Invalid remote IP: %s""), ip_address) return def tunnel_sync(self): try: for tunnel_type in self.tunnel_types: details = self.plugin_rpc.tunnel_sync(self.context, self.local_ip, tunnel_type) if not self.l2_pop: tunnels = details['tunnels'] for tunnel in tunnels: if self.local_ip != tunnel['ip_address']: tunnel_id = tunnel.get('id') # Unlike the OVS plugin, ML2 doesn't return an id # key. So use ip_address to form port name instead. # Port name must be <=15 chars, so use shorter hex. remote_ip = tunnel['ip_address'] remote_ip_hex = self.get_ip_in_hex(remote_ip) if not tunnel_id and not remote_ip_hex: continue tun_name = '%s-%s' % (tunnel_type, tunnel_id or remote_ip_hex) self._setup_tunnel_port(self.tun_br, tun_name, tunnel['ip_address'], tunnel_type) except Exception as e: LOG.debug(_(""Unable to sync tunnel IP %(local_ip)s: %(e)s""), {'local_ip': self.local_ip, 'e': e}) return True return False def _agent_has_updates(self, polling_manager): return (polling_manager.is_polling_required or self.updated_ports or self.sg_agent.firewall_refresh_needed()) def _port_info_has_changes(self, port_info): return (port_info.get('added') or port_info.get('removed') or port_info.get('updated')) def check_ovs_restart(self): # Check for the canary flow canary_flow = self.int_br.dump_flows_for_table(constants.CANARY_TABLE) return not canary_flow def rpc_loop(self, polling_manager=None): if not polling_manager: polling_manager = polling.AlwaysPoll() sync = True ports = set() updated_ports_copy = set() ancillary_ports = set() tunnel_sync = True ovs_restarted = False while self.run_daemon_loop: start = time.time() port_stats = {'regular': {'added': 0, 'updated': 0, 'removed': 0}, 'ancillary': {'added': 0, 'removed': 0}} LOG.debug(_(""Agent rpc_loop - iteration:%d started""), self.iter_num) if sync: LOG.info(_(""Agent out of sync with plugin!"")) ports.clear() ancillary_ports.clear() sync = False polling_manager.force_polling() #ovs_restarted = self.check_ovs_restart() if ovs_restarted: self.setup_integration_br() self.setup_physical_bridges(self.bridge_mappings) if self.enable_tunneling: self.setup_tunnel_br() tunnel_sync = True self.dvr_agent.reset_ovs_parameters(self.int_br, self.tun_br, self.patch_int_ofport, self.patch_tun_ofport) self.dvr_agent.setup_dvr_flows_on_integ_tun_br() # Notify the plugin of tunnel IP if self.enable_tunneling and tunnel_sync: LOG.info(_(""Agent tunnel out of sync with plugin!"")) try: tunnel_sync = self.tunnel_sync() except Exception: LOG.exception(_(""Error while synchronizing tunnels"")) tunnel_sync = True # if self._agent_has_updates(polling_manager) or ovs_restarted: if True: try: LOG.debug(_(""Agent rpc_loop - iteration:%(iter_num)d - "" ""starting polling. Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) # Save updated ports dict to perform rollback in # case resync would be needed, and then clear # self.updated_ports. As the greenthread should not yield # between these two statements, this will be thread-safe updated_ports_copy = self.updated_ports self.updated_ports = set() reg_ports = (set() if ovs_restarted else ports) #import pdb;pdb.set_trace() port_info = self.scan_ports(reg_ports, updated_ports_copy) LOG.debug(_(""Agent rpc_loop - iteration:%(iter_num)d - "" ""port information retrieved. "" ""Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) # Secure and wire/unwire VIFs and update their status # on Neutron server if (self._port_info_has_changes(port_info) or self.sg_agent.firewall_refresh_needed() or ovs_restarted): LOG.debug(_(""Starting to process devices in:%s""), port_info) # If treat devices fails - must resync with plugin sync = self.process_network_ports(port_info, ovs_restarted) LOG.debug(_(""Agent rpc_loop - iteration:%(iter_num)d -"" ""ports processed. Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) port_stats['regular']['added'] = ( len(port_info.get('added', []))) port_stats['regular']['updated'] = ( len(port_info.get('updated', []))) port_stats['regular']['removed'] = ( len(port_info.get('removed', []))) ports = port_info['current'] # Treat ancillary devices if they exist if self.ancillary_brs: port_info = self.update_ancillary_ports( ancillary_ports) LOG.debug(_(""Agent rpc_loop - iteration:%(iter_num)d -"" ""ancillary port info retrieved. "" ""Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) if port_info: rc = self.process_ancillary_network_ports( port_info) LOG.debug(_(""Agent rpc_loop - iteration:"" ""%(iter_num)d - ancillary ports "" ""processed. Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'elapsed': time.time() - start}) ancillary_ports = port_info['current'] port_stats['ancillary']['added'] = ( len(port_info.get('added', []))) port_stats['ancillary']['removed'] = ( len(port_info.get('removed', []))) sync = sync | rc polling_manager.polling_completed() except Exception: LOG.exception(_(""Error while processing VIF ports"")) # Put the ports back in self.updated_port self.updated_ports |= updated_ports_copy sync = True # sleep till end of polling interval elapsed = (time.time() - start) LOG.debug(_(""Agent rpc_loop - iteration:%(iter_num)d "" ""completed. Processed ports statistics: "" ""%(port_stats)s. Elapsed:%(elapsed).3f""), {'iter_num': self.iter_num, 'port_stats': port_stats, 'elapsed': elapsed}) if (elapsed < self.polling_interval): time.sleep(self.polling_interval - elapsed) else: LOG.debug(_(""Loop iteration exceeded interval "" ""(%(polling_interval)s vs. %(elapsed)s)!""), {'polling_interval': self.polling_interval, 'elapsed': elapsed}) self.iter_num = self.iter_num + 1 def daemon_loop(self): with polling.get_polling_manager( self.minimize_polling, self.root_helper, self.ovsdb_monitor_respawn_interval) as pm: self.rpc_loop(polling_manager=pm) def _handle_sigterm(self, signum, frame): LOG.debug(""Agent caught SIGTERM, quitting daemon loop."") self.run_daemon_loop = False def create_agent_config_map(config): """"""Create a map of agent config parameters. :param config: an instance of cfg.CONF :returns: a map of agent configuration parameters """""" try: bridge_mappings = q_utils.parse_mappings(config.OVS.bridge_mappings) except ValueError as e: raise ValueError(_(""Parsing bridge_mappings failed: %s."") % e) kwargs = dict( integ_br=config.OVS.integration_bridge, tun_br=config.OVS.tunnel_bridge, local_ip=config.OVS.local_ip, bridge_mappings=bridge_mappings, root_helper=config.AGENT.root_helper, polling_interval=config.AGENT.polling_interval, minimize_polling=config.AGENT.minimize_polling, tunnel_types=config.AGENT.tunnel_types, veth_mtu=config.AGENT.veth_mtu, enable_distributed_routing=config.AGENT.enable_distributed_routing, l2_population=config.AGENT.l2_population, arp_responder=config.AGENT.arp_responder, use_veth_interconnection=config.OVS.use_veth_interconnection, ) # If enable_tunneling is TRUE, set tunnel_type to default to GRE if config.OVS.enable_tunneling and not kwargs['tunnel_types']: kwargs['tunnel_types'] = [p_const.TYPE_GRE] # Verify the tunnel_types specified are valid for tun in kwargs['tunnel_types']: if tun not in constants.TUNNEL_NETWORK_TYPES: msg = _('Invalid tunnel type specified: %s'), tun raise ValueError(msg) if not kwargs['local_ip']: msg = _('Tunneling cannot be enabled without a valid local_ip.') raise ValueError(msg) return kwargs def main(): cfg.CONF.register_opts(ip_lib.OPTS) common_config.init(sys.argv[1:]) common_config.setup_logging() q_utils.log_opt_values(LOG) try: agent_config = create_agent_config_map(cfg.CONF) except ValueError as e: LOG.error(_('%s Agent terminated!'), e) sys.exit(1) is_xen_compute_host = 'rootwrap-xen-dom0' in agent_config['root_helper'] if is_xen_compute_host: # Force ip_lib to always use the root helper to ensure that ip # commands target xen dom0 rather than domU. cfg.CONF.set_default('ip_lib_force_root', True) agent = OVSNeutronAgent(**agent_config) signal.signal(signal.SIGTERM, agent._handle_sigterm) # Start everything. LOG.info(_(""Agent initialized successfully, now running... "")) agent.daemon_loop() if __name__ == ""__main__"": main() ",20,1525
openstack%2Fsahara-extra~master~Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50,openstack/sahara-extra,master,Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50,Add main function wrapper for edp.java.adapt_for_oozie config,MERGED,2014-12-05 05:50:05.000000000,2014-12-15 10:35:00.000000000,2014-12-15 10:35:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-05 05:50:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/5eb81e9fda94730843e54120573b53e6586cce80', 'message': 'Add main function wrapper for edp.java.adapt_for_oozie config\n\nChange-Id: Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50\nImplements: blueprint edp-improve-compatibility\n'}, {'number': 2, 'created': '2014-12-05 06:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/109ea00689280fa089521adba963584bdaee7a33', 'message': 'Add main function wrapper for edp.java.adapt_for_oozie config\n\nChange-Id: Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50\nImplements: blueprint edp-improve-compatibility\n'}, {'number': 3, 'created': '2014-12-09 08:18:48.000000000', 'files': ['edp-adapt-for-oozie/src/main/java/org/openstack/sahara/edp/MainWrapper.java', 'README.rst', 'edp-adapt-for-oozie/README.rst', 'edp-adapt-for-oozie/pom.xml'], 'web_link': 'https://opendev.org/openstack/sahara-extra/commit/6f063eda988b7166de49891ce2c334e25ddaf01b', 'message': 'Add main function wrapper for edp.java.adapt_for_oozie config\n\nChange-Id: Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50\nImplements: blueprint edp-improve-compatibility\n'}]",0,139522,6f063eda988b7166de49891ce2c334e25ddaf01b,13,4,3,11059,,,0,"Add main function wrapper for edp.java.adapt_for_oozie config

Change-Id: Ic9c9a01e3ff071b07e9b179327a4ddb106a4cf50
Implements: blueprint edp-improve-compatibility
",git fetch https://review.opendev.org/openstack/sahara-extra refs/changes/22/139522/1 && git format-patch -1 --stdout FETCH_HEAD,"['edp-adapt-for-oozie/src/main/java/org/openstack/sahara/edp/MainWrapper.java', 'edp-adapt-for-oozie/pom.xml']",2,5eb81e9fda94730843e54120573b53e6586cce80,bp/edp-improve-compatibility,"<?xml version=""1.0"" encoding=""UTF-8""?> <!-- Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. See accompanying LICENSE file. --> <project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd""> <modelVersion>4.0.0</modelVersion> <groupId>org.openstack.sahara.edp</groupId> <artifactId>edp-main-wrapper</artifactId> <version>1.0.0-SNAPSHOT</version> <name>EDP Java Action Main Wrapper for oozie</name> <packaging>jar</packaging> <properties> <file.encoding>UTF-8</file.encoding> <downloadSources>true</downloadSources> <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding> </properties> <build> <plugins> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-compiler-plugin</artifactId> <configuration> <source>1.6</source> <target>1.6</target> </configuration> </plugin> <plugin> <groupId>org.apache.maven.plugins</groupId> <artifactId>maven-checkstyle-plugin</artifactId> <configuration> <configLocation>file://${basedir}/../hadoop-swiftfs/checkstyle.xml</configLocation> <failOnViolation>false</failOnViolation> <format>xml</format> <format>html</format> </configuration> </plugin> </plugins> </build> </project> ",,146,0
openstack%2Ffuel-library~stable%2F5.1~Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,openstack/fuel-library,stable/5.1,Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,Fix killing of Rabbit beam process for OCF scripts,MERGED,2014-12-12 13:04:43.000000000,2014-12-15 10:32:36.000000000,2014-12-15 10:32:35.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-12 13:04:43.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/01da95166bf7d5322fa206346f0ef6e05c7f4338', 'message': ""Fix killing of Rabbit beam process for OCF scripts\n\nW/o this patch, 'killall beam' commands kill all instances\nof rabbitmq including the one for Murano.\n\nThe solution is to use kill_rmq_and_remove_pid()\nprocedure to kill it by pidfile instead.\n\nCloses-bug: #1400670\n\nChange-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,141362,01da95166bf7d5322fa206346f0ef6e05c7f4338,9,3,1,6926,,,0,"Fix killing of Rabbit beam process for OCF scripts

W/o this patch, 'killall beam' commands kill all instances
of rabbitmq including the one for Murano.

The solution is to use kill_rmq_and_remove_pid()
procedure to kill it by pidfile instead.

Closes-bug: #1400670

Change-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/62/141362/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,01da95166bf7d5322fa206346f0ef6e05c7f4338,," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server can't be started while many tries. Beam will be killed."" kill_rmq_and_remove_pid"," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command."" ocf_run killall beam ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. beam will be killed."" ocf_run killall -9 beam ocf_log err ""${LH} RMQ-server can't be started while many tries. beam will be killed."" ocf_run killall -9 beam",6,6
openstack%2Fhorizon~master~I0ae1cb2da9693f5d2904cd96d475519b753a589d,openstack/horizon,master,I0ae1cb2da9693f5d2904cd96d475519b753a589d,Documenting create_stubs decorator for tests,MERGED,2014-12-03 18:06:30.000000000,2014-12-15 10:24:57.000000000,2014-12-15 10:24:56.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 7634}, {'_account_id': 9317}, {'_account_id': 9981}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-12-03 18:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4621ac7ac969f95842ebaa56016cfdac965a2cf7', 'message': 'Documenting create_stubs decorator for tests\n\nCloses-Bug: #1398912\nChange-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d\n'}, {'number': 2, 'created': '2014-12-04 00:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e6e93f1ff1ed646d5368a7c485b190af494f33e', 'message': 'Documenting create_stubs decorator for tests\n\nCloses-Bug: #1398912\nChange-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d\n'}, {'number': 3, 'created': '2014-12-10 21:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/32f1abc1ecad36f301d363ad5ed3acafe7be93d0', 'message': 'Documenting create_stubs decorator for tests\n\nCloses-Bug: #1398912\nChange-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d\n'}, {'number': 4, 'created': '2014-12-12 17:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1fe24eb5dc511e18a6c4c32d73c0a025b80e3cad', 'message': 'Documenting create_stubs decorator for tests\n\nCloses-Bug: #1398912\nChange-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d\n'}, {'number': 5, 'created': '2014-12-12 17:44:34.000000000', 'files': ['openstack_dashboard/test/helpers.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/48093c7a4cb0b7f11b91037a7617a287c7172422', 'message': 'Documenting create_stubs decorator for tests\n\nCloses-Bug: #1398912\nChange-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d\n'}]",9,138806,48093c7a4cb0b7f11b91037a7617a287c7172422,27,8,5,5623,,,0,"Documenting create_stubs decorator for tests

Closes-Bug: #1398912
Change-Id: I0ae1cb2da9693f5d2904cd96d475519b753a589d
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/138806/3 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/test/helpers.py'],1,4621ac7ac969f95842ebaa56016cfdac965a2cf7,bug-1398912," """"""decorator for settings up multiple stubs at once via mox :param stubs_to_create: is a dictionary where: The keys are python paths to the module containing the methods to mock. For example: api.nova The values are either a tuple of list of methods to mock in the module indicated by the key. For example: ('server_list',) -or- ('flavor_list', 'server_list',) Additionally, multiple modules can be mocked at once: { api.nova: ('flavor_list', ""server_list'), api.glance: ('image_list_detailed',), } """""" ",,24,0
openstack%2Fhorizon~master~Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8,openstack/horizon,master,Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8,Update project list in the header bar.,MERGED,2014-11-26 14:45:46.000000000,2014-12-15 10:24:04.000000000,2014-12-15 10:24:03.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 8040}, {'_account_id': 8533}, {'_account_id': 11096}, {'_account_id': 12355}, {'_account_id': 13325}, {'_account_id': 14124}, {'_account_id': 14151}]","[{'number': 1, 'created': '2014-11-26 14:45:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f8c687effa5a350108d10bd3741bf46e687d2529', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 2, 'created': '2014-11-27 11:24:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e2f0de7bc59591fc8fff403318f046d06393424f', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 3, 'created': '2014-11-27 15:53:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b6fcda9332ae0f0a10a5d630dba6dcb710eea15b', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 4, 'created': '2014-11-27 21:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a8c8d159fd5def98e6f3a4c1b2d9294d3ec2bdb5', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 5, 'created': '2014-12-03 21:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cedb8806b71393082c9d46505044ed0d352dcf73', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 6, 'created': '2014-12-08 08:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/106978957a1a55357c85e67deaf3e28b0cf807fe', 'message': 'Update project list in the header bar if project members were changed\n\nAdd function for clean cache of projects(for project \ncache is invalidated). Now, in the header bar, show only\nactive projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 7, 'created': '2014-12-08 09:27:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2aedf4af39cebae636f37c01364d9c8ff2f5ae95', 'message': 'Update project list in the header bar if project members were changed\n\nAdd function for clean cache of projects(for project\ncache is invalidated). Now, in the header bar, show only\nactive projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 8, 'created': '2014-12-08 09:30:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/51e97ad65950f7342e5e1f1bf7f7af50ba1b2ac6', 'message': 'Update project list in the header bar,\nif project members were changed.\n\nAdd function for clean cache of projects(for project\ncache is invalidated). Now, in the header bar, show only\nactive projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 9, 'created': '2014-12-08 09:37:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/411f0347d392de2763bdf00a0aa54ebbc2d21efe', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects, after project \nmembers were changed(for project cache is invalidated).\nNow, in the header bar, show only active projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 10, 'created': '2014-12-09 10:20:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ffc2b967e299823d2b0c1dfb40fa006f1db466e9', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects, after project\nmembers were changed(for project cache is invalidated).\nNow, in the header bar, show only active projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 11, 'created': '2014-12-09 10:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b0dd0c215025f635b76f4d0d1ff346e0ff605a73', 'message': 'Update project list in the header bar.\n\nAdd function for clean cache of projects, after project\nmembers were changed(for project cache is invalidated).\nNow, in the header bar, show only active projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}, {'number': 12, 'created': '2014-12-11 16:25:18.000000000', 'files': ['openstack_dashboard/dashboards/identity/projects/tables.py', 'openstack_dashboard/context_processors.py', 'openstack_dashboard/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a47c9846234843884e2d7455265237ff23c09d89', 'message': 'Update project list in the header bar.\n\nUse function for clean cache (from openstack_auth), after project\nmembers were changed(for project cache is invalidated).\nNow, in the header bar, show only active projects.\n\nChange-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8\nCloses-Bug: #1393659\n'}]",29,137369,a47c9846234843884e2d7455265237ff23c09d89,63,11,12,12355,,,0,"Update project list in the header bar.

Use function for clean cache (from openstack_auth), after project
members were changed(for project cache is invalidated).
Now, in the header bar, show only active projects.

Change-Id: Ia2561b591b4f3de29a14aaa4b666b16fc1d4cec8
Closes-Bug: #1393659
",git fetch https://review.opendev.org/openstack/horizon refs/changes/69/137369/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/projects/views.py', 'openstack_dashboard/api/keystone.py']",2,f8c687effa5a350108d10bd3741bf46e687d2529,bug/1393659,def project_cache_clean(token): auth_utils.remove_project_cache(token) ,,5,0
openstack%2Fhorizon~master~Ibb33241efdf2990004de431f1268fb3e3a2d6781,openstack/horizon,master,Ibb33241efdf2990004de431f1268fb3e3a2d6781,Added tests for Node Group Templates' create and copy workflows,MERGED,2014-12-12 14:25:11.000000000,2014-12-15 10:23:54.000000000,2014-12-15 10:23:52.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 6914}, {'_account_id': 10791}, {'_account_id': 12355}]","[{'number': 1, 'created': '2014-12-12 14:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8245435ecf4ad130143d84c99585985744b141af', 'message': ""Added tests for Node Group Templates' create and copy\nworkflows\n\ntest_copy has been adapted from cluster_templates and\nonly checks for the ng name\n\nCloses-Bug: #1382377\n\nChange-Id: Ibb33241efdf2990004de431f1268fb3e3a2d6781\n""}, {'number': 2, 'created': '2014-12-13 19:17:48.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/tests.py', 'openstack_dashboard/test/test_data/sahara_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4cbe19d2ddd469e0607a46e3e8cdf58761ae1e30', 'message': ""Added tests for Node Group Templates' create and copy workflows\n\ntest_copy has been adapted from cluster_templates and\nonly checks for the ng name\n\nCloses-Bug: #1382377\n\nChange-Id: Ibb33241efdf2990004de431f1268fb3e3a2d6781\n""}]",1,141384,4cbe19d2ddd469e0607a46e3e8cdf58761ae1e30,16,5,2,10791,,,0,"Added tests for Node Group Templates' create and copy workflows

test_copy has been adapted from cluster_templates and
only checks for the ng name

Closes-Bug: #1382377

Change-Id: Ibb33241efdf2990004de431f1268fb3e3a2d6781
",git fetch https://review.opendev.org/openstack/horizon refs/changes/84/141384/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/data_processing/nodegroup_templates/tests.py', 'openstack_dashboard/test/test_data/sahara_data.py']",2,8245435ecf4ad130143d84c99585985744b141af,1382377," ""availability_zone"": None, ""auto_security_group"": True, ""security_groups"": [],",,103,0
openstack%2Fopenstack-doc-tools~master~Iaf03108bb3e91eb3431dd660afb22d31c2498613,openstack/openstack-doc-tools,master,Iaf03108bb3e91eb3431dd660afb22d31c2498613,Update RELEASE_NOTES,MERGED,2014-12-15 09:19:54.000000000,2014-12-15 09:28:39.000000000,2014-12-15 09:28:38.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 09:19:54.000000000', 'files': ['RELEASE_NOTES.rst'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/e01d46abd010e723546d40fbec88470d4e8aab94', 'message': 'Update RELEASE_NOTES\n\nUpdate with changes since 0.20 to prepare for a 0.21 release.\n\nChange-Id: Iaf03108bb3e91eb3431dd660afb22d31c2498613\n'}]",0,141748,e01d46abd010e723546d40fbec88470d4e8aab94,6,2,1,6547,,,0,"Update RELEASE_NOTES

Update with changes since 0.20 to prepare for a 0.21 release.

Change-Id: Iaf03108bb3e91eb3431dd660afb22d31c2498613
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/48/141748/1 && git format-patch -1 --stdout FETCH_HEAD,['RELEASE_NOTES.rst'],1,e01d46abd010e723546d40fbec88470d4e8aab94,RELEASE-NOTES,"0.21 ---- * ``openstack-doc-test``: New option ``--url-exception`` to ignore URLs in link check. Use jsoncheck in tests for more better tests and output. * ``openstack-auto-commands``: Update list of supported commands to include ironic, sahara * ``openstack-dn2osdbk``: Various fixes. ",,10,0
openstack%2Ftripleo-image-elements~master~I89be1374407d75f09aad08ca4981c4b855b3c0c9,openstack/tripleo-image-elements,master,I89be1374407d75f09aad08ca4981c4b855b3c0c9,Add pass-through support for tempest element,MERGED,2014-12-08 23:21:44.000000000,2014-12-15 09:27:20.000000000,2014-12-15 09:27:19.000000000,"[{'_account_id': 3}, {'_account_id': 8449}, {'_account_id': 8688}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-12-08 23:21:44.000000000', 'files': ['elements/tempest/os-apply-config/opt/stack/tempest/etc/tempest.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/471bbaa46fb12bb24b01aca667e37689c6035169', 'message': 'Add pass-through support for tempest element\n\nIntroduce support for pass-through on tempest.conf.\n\nChange-Id: I89be1374407d75f09aad08ca4981c4b855b3c0c9\n'}]",0,140177,471bbaa46fb12bb24b01aca667e37689c6035169,11,4,1,1921,,,0,"Add pass-through support for tempest element

Introduce support for pass-through on tempest.conf.

Change-Id: I89be1374407d75f09aad08ca4981c4b855b3c0c9
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/77/140177/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/tempest/os-apply-config/opt/stack/tempest/etc/tempest.conf'],1,471bbaa46fb12bb24b01aca667e37689c6035169,tempest_passthrough,"# Pass-through enabled configuration file, suitable for use with # the existing bin/run-tempest script. {{#tempest}} {{#config}} [{{{section}}}] {{#values}} {{#comment}} # {{{.}}} {{/comment}} {{#option}} {{{option}}}={{{value}}} {{/option}} {{/values}} {{/config}} {{/tempest}} ",,17,0
openstack%2Fopenstack-doc-tools~master~I96ef56fef7dac98f344296d1217586326740b46e,openstack/openstack-doc-tools,master,I96ef56fef7dac98f344296d1217586326740b46e,Change config changes generator script,MERGED,2014-12-12 15:04:39.000000000,2014-12-15 09:20:47.000000000,2014-12-15 09:20:46.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2014-12-12 15:04:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/772d64f900b1798da7c7c49758e5fdae0e44464e', 'message': 'Change config changes generator script\n\nChange diff_branches.py to generate the config-changes file with an\nxml:id that always contains the release name instead of the name of\nthe new branch. This way it can be avoided that the id changes, when\nstable branch is cut close to the end of a release cycle.\n\nChange-Id: I96ef56fef7dac98f344296d1217586326740b46e\n'}, {'number': 2, 'created': '2014-12-12 15:12:45.000000000', 'files': ['autogenerate_config_docs/diff_branches.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/5177dfe361955567f1ff85b327f84f7d593c7a6d', 'message': 'Change config changes generator script\n\nChange diff_branches.py to generate the config-changes file with an\nxml:id that always contains the release name instead of the name of\nthe new branch. This way it can be avoided that the id changes, when\nstable branch is cut close to the end of a release cycle.\n\nChange-Id: I96ef56fef7dac98f344296d1217586326740b46e\n'}]",0,141394,5177dfe361955567f1ff85b327f84f7d593c7a6d,8,3,2,9562,,,0,"Change config changes generator script

Change diff_branches.py to generate the config-changes file with an
xml:id that always contains the release name instead of the name of
the new branch. This way it can be avoided that the id changes, when
stable branch is cut close to the end of a release cycle.

Change-Id: I96ef56fef7dac98f344296d1217586326740b46e
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/94/141394/1 && git format-patch -1 --stdout FETCH_HEAD,['autogenerate_config_docs/diff_branches.py'],1,772d64f900b1798da7c7c49758e5fdae0e44464e,diff-branches-xml-id-fix," release = release_from_branch(new_branch) id = ""%(project)s-conf-changes-%(release)s"" % {'project': project, 'release': release.lower()} {'release': release,"," id = ""%(project)s-conf-changes-%(branch)s"" % {'project': project, 'branch': new_branch} {'release': release_from_branch(new_branch),",4,3
openstack%2Fdevstack~master~I17603b4f0cc9e2512e84290e3c3b41f17f5d8e5b,openstack/devstack,master,I17603b4f0cc9e2512e84290e3c3b41f17f5d8e5b,Test.,ABANDONED,2014-12-15 08:19:36.000000000,2014-12-15 09:09:04.000000000,,"[{'_account_id': 2861}, {'_account_id': 10068}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-15 08:19:36.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/af8fb7addc4319bad72dbb645dea8c07c17e1f06', 'message': 'Test.\n\nChange-Id: I17603b4f0cc9e2512e84290e3c3b41f17f5d8e5b\n'}]",0,141739,af8fb7addc4319bad72dbb645dea8c07c17e1f06,5,3,1,14332,,,0,"Test.

Change-Id: I17603b4f0cc9e2512e84290e3c3b41f17f5d8e5b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/39/141739/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,af8fb7addc4319bad72dbb645dea8c07c17e1f06,test,,,1,0
openstack%2Ftricircle~master~I6069d733dc4781598e1874bc2d24195d0e5f2a86,openstack/tricircle,master,I6069d733dc4781598e1874bc2d24195d0e5f2a86,cache the sync nova client,MERGED,2014-12-15 08:58:52.000000000,2014-12-15 08:59:22.000000000,2014-12-15 08:59:22.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-15 08:58:52.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/68ab7c12d42d16845728642a976f60c0d2e7daba', 'message': 'cache the sync nova client\n\nTo avoid too many token-requests from the sync instance state function\nwe cache the sync_nova_client.\n\nChange-Id: I6069d733dc4781598e1874bc2d24195d0e5f2a86\n'}]",0,141747,68ab7c12d42d16845728642a976f60c0d2e7daba,6,2,1,9684,,,0,"cache the sync nova client

To avoid too many token-requests from the sync instance state function
we cache the sync_nova_client.

Change-Id: I6069d733dc4781598e1874bc2d24195d0e5f2a86
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/47/141747/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,68ab7c12d42d16845728642a976f60c0d2e7daba,,"from novaclient.exceptions import Unauthorized as Client_Unauthorized sync_nova_client = None if not self.sync_nova_client: self.sync_nova_client = openstack_clients.nova() # cascaded_nova_cli = openstack_clients.nova() try: servers = self.sync_nova_client.servers.list( search_opts=search_opts_args, limit=self.QUERY_PER_PAGE_LIMIT, marker=marker) except Client_Unauthorized: self.sync_nova_client = openstack_clients.nova() LOG.debug(_('the token is timed out in sync_nova_client,' 'fetch a new token form keystone.')) continue"," cascaded_nova_cli = openstack_clients.nova() servers = cascaded_nova_cli.servers.list( search_opts=search_opts_args, limit=self.QUERY_PER_PAGE_LIMIT, marker=marker)",15,5
openstack%2Ftripleo-image-elements~master~Icb62e6768c4d7785474b8430a02967e02c834405,openstack/tripleo-image-elements,master,Icb62e6768c4d7785474b8430a02967e02c834405,Allow setting extra config for stunnel ports,ABANDONED,2014-10-31 12:28:15.000000000,2014-12-15 08:45:32.000000000,,"[{'_account_id': 3}, {'_account_id': 1865}, {'_account_id': 1882}, {'_account_id': 8688}, {'_account_id': 10035}, {'_account_id': 10373}, {'_account_id': 11650}]","[{'number': 1, 'created': '2014-10-31 12:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/5a906d1713fa05aa0114eb32c6430c4d09a231c6', 'message': ""Allow setting the client mode for stunnel\n\nAdd config option to stunnel to allow setting it in client mode for\nservices. This mode defaults to 'no', when set to 'yes' this allows\noutgoing and incoming connections through stunnel rather than just\nincoming.\n\nChange-Id: Icb62e6768c4d7785474b8430a02967e02c834405\n""}, {'number': 2, 'created': '2014-10-31 13:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/9661d4feba57f562fdc4f051600ba1cc7d7cddb0', 'message': ""Allow setting extra config for stunnel ports\n\nAdd config option to stunnel to allow setting abitary extra\nconfiguration for each stunnel port. This will allow easy extension to\nstunnel usage for different situations. Example would be enabling client\nmode or setting certificates per service.\n\n    stunnel:\n      cert: {get_input: ssl_certificate}\n      key: {get_input: ssl_key}\n      ports:\n       - name: 'nova-ec2'\n         accept: 8773\n         connect: 8773\n         config:\n            - key: 'client'\n              value: 'yes'\n       - name: 'mysql'\n         accept: 3306\n         connect: 3306\n         config:\n            - key: 'cert'\n              value: {get_param: mysql_cert}\n\nChange-Id: Icb62e6768c4d7785474b8430a02967e02c834405\n""}, {'number': 3, 'created': '2014-10-31 13:24:36.000000000', 'files': ['elements/openstack-ssl/os-apply-config/etc/stunnel/from-heat.conf'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/a3632959f12e60be1ea5afbad5bb38594317da6b', 'message': ""Allow setting extra config for stunnel ports\n\nAdd config option to stunnel to allow setting arbitrary extra\nconfiguration for each stunnel port. This will allow easy extension to\nstunnel usage for different situations. For example enabling client mode\nor setting certificates per service.\n\n    stunnel:\n      cert: {get_input: ssl_certificate}\n      key: {get_input: ssl_key}\n      ports:\n       - name: 'nova-ec2'\n         accept: 8773\n         connect: 8773\n         config:\n            - key: 'client'\n              value: 'yes'\n       - name: 'mysql'\n         accept: 3306\n         connect: 3306\n         config:\n            - key: 'cert'\n              value: {get_param: mysql_cert}\n\nChange-Id: Icb62e6768c4d7785474b8430a02967e02c834405\n""}]",6,132227,a3632959f12e60be1ea5afbad5bb38594317da6b,16,7,3,11650,,,0,"Allow setting extra config for stunnel ports

Add config option to stunnel to allow setting arbitrary extra
configuration for each stunnel port. This will allow easy extension to
stunnel usage for different situations. For example enabling client mode
or setting certificates per service.

    stunnel:
      cert: {get_input: ssl_certificate}
      key: {get_input: ssl_key}
      ports:
       - name: 'nova-ec2'
         accept: 8773
         connect: 8773
         config:
            - key: 'client'
              value: 'yes'
       - name: 'mysql'
         accept: 3306
         connect: 3306
         config:
            - key: 'cert'
              value: {get_param: mysql_cert}

Change-Id: Icb62e6768c4d7785474b8430a02967e02c834405
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/27/132227/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/openstack-ssl/os-apply-config/etc/stunnel/from-heat.conf'],1,5a906d1713fa05aa0114eb32c6430c4d09a231c6,stunnel-extend,{{#client_mode}} client = {{.}} {{/client_mode}},,3,0
openstack%2Fheat~master~Icb3c4d423031456b8b24a84e97e310df077d9990,openstack/heat,master,Icb3c4d423031456b8b24a84e97e310df077d9990,Remove run_tests.sh,MERGED,2014-12-10 18:02:53.000000000,2014-12-15 08:40:45.000000000,2014-12-14 23:25:01.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 8246}, {'_account_id': 8537}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 11956}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-10 18:02:53.000000000', 'files': ['run_tests.sh', 'tools/with_venv.sh', 'tools/install_venv_common.py', 'tools/install_venv.py', 'MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/heat/commit/8516d12d604a14398994e7b860e939da91d1aeb7', 'message': 'Remove run_tests.sh\n\nThis tool is deprecated in favor of tox for a long time already.\nMoreover, currently it is broken as it tries to run\nour in-tree integration tests as well.\n\nSo instead of fixing it, just finally remove it.\n\nChange-Id: Icb3c4d423031456b8b24a84e97e310df077d9990\n'}]",0,140791,8516d12d604a14398994e7b860e939da91d1aeb7,19,9,1,9542,,,0,"Remove run_tests.sh

This tool is deprecated in favor of tox for a long time already.
Moreover, currently it is broken as it tries to run
our in-tree integration tests as well.

So instead of fixing it, just finally remove it.

Change-Id: Icb3c4d423031456b8b24a84e97e310df077d9990
",git fetch https://review.opendev.org/openstack/heat refs/changes/91/140791/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tools/with_venv.sh', 'tools/install_venv_common.py', 'tools/install_venv.py', 'MANIFEST.in']",5,8516d12d604a14398994e7b860e939da91d1aeb7,run_tests,include babel.cfg install.sh tox.ini uninstall.sh,include babel.cfg install.sh run_tests.sh tox.ini uninstall.sh,1,376
openstack%2Ffuel-main~master~I2b8fa6adde4cfc06b97f0bbba537be7afef393d4,openstack/fuel-main,master,I2b8fa6adde4cfc06b97f0bbba537be7afef393d4,Add test on node deletion from old cluster after upgrade,MERGED,2014-12-03 15:37:23.000000000,2014-12-15 08:38:48.000000000,2014-12-10 19:58:29.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-03 15:37:23.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c4df7e067ed8a2804b2cd30327f231efeb71ef9d', 'message': 'Add test on node deletion from old cluster\nafter upgrade\n\nChange-Id: I2b8fa6adde4cfc06b97f0bbba537be7afef393d4\nCloses-Bug: #1396571\n'}]",3,138762,c4df7e067ed8a2804b2cd30327f231efeb71ef9d,13,7,1,10136,,,0,"Add test on node deletion from old cluster
after upgrade

Change-Id: I2b8fa6adde4cfc06b97f0bbba537be7afef393d4
Closes-Bug: #1396571
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/62/138762/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,c4df7e067ed8a2804b2cd30327f231efeb71ef9d,addUpgradeTest,"from devops.helpers.helpers import wait @test(groups=[""upgrade_simple_delete_node""]) @log_snapshot_on_error def upgrade_simple_delete_node(self): """"""Upgrade simple deployed cluster with ceph and delete node from old cluster Scenario: 1. Revert snapshot with simple ceph env 2. Run upgrade on master 3. Check that upgrade was successful 4. Delete one compute+ceph node 5. Re-deploy cluster 6. Run OSTF """""" if not self.env.get_virtual_environment().has_snapshot( 'ceph_multinode_compact'): raise SkipTest() self.env.revert_snapshot(""ceph_multinode_compact"") cluster_id = self.fuel_web.get_last_created_cluster() checkers.upload_tarball(self.env.get_admin_remote(), hlp_data.TARBALL_PATH, '/var') checkers.check_tarball_exists(self.env.get_admin_remote(), os.path.basename(hlp_data. TARBALL_PATH), '/var') checkers.untar(self.env.get_admin_remote(), os.path.basename(hlp_data. TARBALL_PATH), '/var') checkers.run_script(self.env.get_admin_remote(), '/var', 'upgrade.sh', password= hlp_data.KEYSTONE_CREDS['password']) checkers.wait_upgrade_is_done(self.env.get_admin_remote(), 3000, phrase='*** UPGRADE DONE SUCCESSFULLY') checkers.check_upgraded_containers(self.env.get_admin_remote(), hlp_data.UPGRADE_FUEL_FROM, hlp_data.UPGRADE_FUEL_TO) self.fuel_web.assert_nodes_in_ready_state(cluster_id) self.fuel_web.assert_fuel_version(hlp_data.UPGRADE_FUEL_TO) self.fuel_web.assert_nailgun_upgrade_migration() nailgun_nodes = self.fuel_web.update_nodes( cluster_id, {'slave-03': ['compute', 'ceph-osd']}, False, True) task = self.fuel_web.deploy_cluster(cluster_id) self.fuel_web.assert_task_success(task) nodes = filter(lambda x: x[""pending_deletion""] is True, nailgun_nodes) wait( lambda: self.fuel_web.is_node_discovered(nodes[0]), timeout=10 * 60 ) self.fuel_web.run_ostf(cluster_id=cluster_id, should_fail=1) self.env.make_snapshot(""upgrade_simple_delete_node"") ",,55,0
openstack%2Fneutron~master~I6281886f3334100a18952578250c8154a0ed15a9,openstack/neutron,master,I6281886f3334100a18952578250c8154a0ed15a9,Remove broad exception catch from periodic_sync_routers_task,MERGED,2014-10-28 17:32:52.000000000,2014-12-15 07:34:50.000000000,2014-12-15 06:10:42.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 5950}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9093}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-28 17:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9638554b04f0a6486fd6a869d24c04ad14434acd', 'message': 'WIP Remove broad exception catch from _periodic_sync_routers_task\n\nJust a quick WIP to collect comments that started here [1]\n\n[1] https://review.openstack.org/#/c/130021/3/neutron/agent/l3_agent.py\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 2, 'created': '2014-11-12 13:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d43593ecc0adc476702ea95a640683e70a4786c', 'message': 'WIP Remove broad exception catch from _periodic_sync_routers_task\n\nJust a quick WIP to collect comments that started here [1]\n\n[1] https://review.openstack.org/#/c/130021/3/neutron/agent/l3_agent.py\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 3, 'created': '2014-11-12 16:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b39a81d3d4ade43c6677e509be27c9ef690ac5d4', 'message': 'WIP Remove broad exception catch from _periodic_sync_routers_task\n\nJust a quick WIP to collect comments that started here [1]\n\n[1] https://review.openstack.org/#/c/130021/3/neutron/agent/l3_agent.py\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 4, 'created': '2014-11-12 19:27:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e874fb9c067949da8da91685198fddc88348d6f1', 'message': 'WIP Remove broad exception catch from _periodic_sync_routers_task\n\nJust a quick WIP to collect comments that started here [1]\n\n[1] https://review.openstack.org/#/c/130021/3/neutron/agent/l3_agent.py\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 5, 'created': '2014-11-14 15:14:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/934e4b102becc1e85004ea910ba896e2d285c315', 'message': 'Remove broad exception catch from periodic_sync_routers_task\n\nAlthough this change removes a broad exception from\nperiodic_sync_routers_task (neutron.agent.l3_agent), the\nimplementation still ensures if an exception --caught or uncaught --\nprevents a call to the method to disable the fullsync, then the next\ncall to the method will perform a fullsync again.\n\nAuthor:         Cedric Brandily <zzelle@gmail.com>\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 6, 'created': '2014-11-21 00:16:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/71d5062cf2f71438878cb405295baeea1730e12a', 'message': 'Remove broad exception catch from periodic_sync_routers_task\n\nAlthough this change removes a broad exception from\nperiodic_sync_routers_task (neutron.agent.l3_agent), the\nimplementation still ensures if an exception --caught or uncaught --\nprevents a call to the method to disable the fullsync, then the next\ncall to the method will perform a fullsync again.\n\nAuthor:         Cedric Brandily <zzelle@gmail.com>\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 7, 'created': '2014-11-25 01:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc35a11d24d2f53c59c68531cd832ae7de1f9658', 'message': 'Remove broad exception catch from periodic_sync_routers_task\n\nAlthough this change removes a broad exception from\nperiodic_sync_routers_task (neutron.agent.l3_agent), the\nimplementation still ensures if an exception --caught or uncaught --\nprevents a call to the method to disable the fullsync, then the next\ncall to the method will perform a fullsync again.\n\nAuthor:         Cedric Brandily <zzelle@gmail.com>\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}, {'number': 8, 'created': '2014-12-11 15:37:32.000000000', 'files': ['neutron/agent/l3/agent.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/45340e5e7ddb1b1ba98d8bcf1153769b98ca0084', 'message': 'Remove broad exception catch from periodic_sync_routers_task\n\nAlthough this change removes a broad exception from\nperiodic_sync_routers_task (neutron.agent.l3_agent), the\nimplementation still ensures if an exception --caught or uncaught --\nprevents a call to the method to disable the fullsync, then the next\ncall to the method will perform a fullsync again.\n\nAuthor:         Cedric Brandily <zzelle@gmail.com>\nCo-Authored-By: Carl Baldwin <carl.baldwin@hp.com>\n\nChange-Id: I6281886f3334100a18952578250c8154a0ed15a9\n'}]",13,131510,45340e5e7ddb1b1ba98d8bcf1153769b98ca0084,174,35,8,7448,,,0,"Remove broad exception catch from periodic_sync_routers_task

Although this change removes a broad exception from
periodic_sync_routers_task (neutron.agent.l3_agent), the
implementation still ensures if an exception --caught or uncaught --
prevents a call to the method to disable the fullsync, then the next
call to the method will perform a fullsync again.

Author:         Cedric Brandily <zzelle@gmail.com>
Co-Authored-By: Carl Baldwin <carl.baldwin@hp.com>

Change-Id: I6281886f3334100a18952578250c8154a0ed15a9
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/131510/3 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,9638554b04f0a6486fd6a869d24c04ad14434acd,bp/restructure-l3-agent, self.fullsync = True," self.fullsync = True except Exception: LOG.exception(_LE(""Failed synchronizing routers"")) self.fullsync = True",1,4
openstack%2Ftaskflow~master~If61c8c1669d7c0d66e2daab5fd773b8c7756f202,openstack/taskflow,master,If61c8c1669d7c0d66e2daab5fd773b8c7756f202,Replace autobind with a notifier module helper function,MERGED,2014-12-15 03:07:15.000000000,2014-12-15 06:59:41.000000000,2014-12-15 06:59:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-15 03:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/821079f4018d7bd68cd0582b8e633280cbebb60b', 'message': 'Replace autobind with a notifier module helper function\n\nInstead of having the executor method provide a bind and\nunbind function just have the notifier module provide this,\nwhich allows those who were using the task autobind to use\nthis helper as well as the execution code itself.\n\nChange-Id: If61c8c1669d7c0d66e2daab5fd773b8c7756f202\n'}, {'number': 2, 'created': '2014-12-15 05:47:05.000000000', 'files': ['taskflow/types/notifier.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e9ecdc745d22470039228645838a2e4c1f3e1ba9', 'message': 'Replace autobind with a notifier module helper function\n\nInstead of having the executor method provide a bind and\nunbind function just have the notifier module provide this,\nwhich allows those who were using the task autobind to use\nthis helper as well as the execution code itself.\n\nChange-Id: If61c8c1669d7c0d66e2daab5fd773b8c7756f202\n'}]",0,141695,e9ecdc745d22470039228645838a2e4c1f3e1ba9,8,2,2,1297,,,0,"Replace autobind with a notifier module helper function

Instead of having the executor method provide a bind and
unbind function just have the notifier module provide this,
which allows those who were using the task autobind to use
this helper as well as the execution code itself.

Change-Id: If61c8c1669d7c0d66e2daab5fd773b8c7756f202
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/95/141695/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/types/notifier.py', 'taskflow/engines/action_engine/executor.py']",2,821079f4018d7bd68cd0582b8e633280cbebb60b,,"from taskflow.types import notifierdef _execute_task(task, arguments, progress_callback=None): with notifier.register_deregister(task.notifier, task_atom.EVENT_UPDATE_PROGRESS, progress_callback): with notifier.register_deregister(task.notifier, task_atom.EVENT_UPDATE_PROGRESS, progress_callback):","import contextlib@contextlib.contextmanager def _autobind(task, progress_callback=None): bound = False if progress_callback is not None: task.notifier.register(task_atom.EVENT_UPDATE_PROGRESS, progress_callback) bound = True try: yield finally: if bound: task.notifier.deregister(task_atom.EVENT_UPDATE_PROGRESS, progress_callback) def _execute_task(task, arguments, progress_callback=None): with _autobind(task, progress_callback=progress_callback): with _autobind(task, progress_callback=progress_callback):",30,18
openstack%2Fha-guide~master~Ib10bc7b21ddd3b95669d1d2c8c8496343015fae4,openstack/ha-guide,master,Ib10bc7b21ddd3b95669d1d2c8c8496343015fae4,Updated from openstack-manuals,MERGED,2014-12-15 06:43:33.000000000,2014-12-15 06:57:20.000000000,2014-12-15 06:57:19.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 06:43:33.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/4fe18673d1a8ccacc274f6843e0d8d4983066a67', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ib10bc7b21ddd3b95669d1d2c8c8496343015fae4\n'}]",0,141730,4fe18673d1a8ccacc274f6843e0d8d4983066a67,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ib10bc7b21ddd3b95669d1d2c8c8496343015fae4
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/30/141730/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,4fe18673d1a8ccacc274f6843e0d8d4983066a67,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-15 00:16+0000\n"" ""PO-Revision-Date: 2014-12-15 01:50+0000\n""msgstr ""認証局。暗号において、電子証明書を発行するエンティティー。電子証明書は、証明書の発行先の名前により公開鍵の所有者を証明する。これにより、他の信頼される機関が証明書を信頼できるようになる。また、証明された公開鍵に対応する秘密鍵による表明を信頼できるようになる。この信頼関係のモデルにおいて、CA は証明書の発行先と証明書を信頼している機関の両方に対する信頼された第三者機関である。CA は、多くの公開鍵基盤 (PKI) スキームの特徴である。""msgstr ""cloud-init 同様のゲスト初期化機能を提供する Windows プロジェクト。""msgstr ""サーバーの再起動時に有効なままになる Compute の RabbitMQ メッセージ交換。""msgstr ""ホストの起動時にネットワークを自動的に設定する方式。Networking と Compute により提供される。""msgstr ""別々のルーティングテーブルとインターフェースを持つ単一のホストにおいて、独立した仮想ネットワークインターフェースを提供する Linux カーネル機能。物理ネットワーク環境における仮想ルーティングおよびフォワーディング (VRF) サービスと似ている。""msgstr ""ルーター通知デーモン。仮想マシンインスタンスにルーティングサービスを提供するために、Compute の VLAN マネージャーと FlatDHCP マネージャーにより使用される。""msgstr ""自動的にカタログに登録するために、Compute などのサービスを有効化する、Identity の機能。""msgstr ""Identity と安全に通信するために Compute により使用される、管理者により定義されたトークン。""msgstr ""複数の仮想マシンを使用して、物理ネットワーク上にオーバーレイされる、スイッチング、ルーティング、負荷分散、セキュリティなどのネットワーク機能の仮想化に関する一般的な用語。""","""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-12 04:50+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",11,11
openstack%2Foperations-guide~master~I143673001b57fbbbfbb0f488a9fe8b01d7702ad2,openstack/operations-guide,master,I143673001b57fbbbfbb0f488a9fe8b01d7702ad2,Updated from openstack-manuals,MERGED,2014-12-15 06:43:38.000000000,2014-12-15 06:55:44.000000000,2014-12-15 06:55:43.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 06:43:38.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/9eebccdadf7bd074ec12297001d2bbe2ab959845', 'message': 'Updated from openstack-manuals\n\nChange-Id: I143673001b57fbbbfbb0f488a9fe8b01d7702ad2\n'}]",0,141731,9eebccdadf7bd074ec12297001d2bbe2ab959845,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I143673001b57fbbbfbb0f488a9fe8b01d7702ad2
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/31/141731/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,9eebccdadf7bd074ec12297001d2bbe2ab959845,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-15 00:16+0000\n"" ""PO-Revision-Date: 2014-12-15 01:50+0000\n""msgstr ""認証局。暗号において、電子証明書を発行するエンティティー。電子証明書は、証明書の発行先の名前により公開鍵の所有者を証明する。これにより、他の信頼される機関が証明書を信頼できるようになる。また、証明された公開鍵に対応する秘密鍵による表明を信頼できるようになる。この信頼関係のモデルにおいて、CA は証明書の発行先と証明書を信頼している機関の両方に対する信頼された第三者機関である。CA は、多くの公開鍵基盤 (PKI) スキームの特徴である。""msgstr ""cloud-init 同様のゲスト初期化機能を提供する Windows プロジェクト。""msgstr ""サーバーの再起動時に有効なままになる Compute の RabbitMQ メッセージ交換。""msgstr ""ホストの起動時にネットワークを自動的に設定する方式。Networking と Compute により提供される。""msgstr ""別々のルーティングテーブルとインターフェースを持つ単一のホストにおいて、独立した仮想ネットワークインターフェースを提供する Linux カーネル機能。物理ネットワーク環境における仮想ルーティングおよびフォワーディング (VRF) サービスと似ている。""msgstr ""ルーター通知デーモン。仮想マシンインスタンスにルーティングサービスを提供するために、Compute の VLAN マネージャーと FlatDHCP マネージャーにより使用される。""msgstr ""自動的にカタログに登録するために、Compute などのサービスを有効化する、Identity の機能。""msgstr ""Identity と安全に通信するために Compute により使用される、管理者により定義されたトークン。""msgstr ""複数の仮想マシンを使用して、物理ネットワーク上にオーバーレイされる、スイッチング、ルーティング、負荷分散、セキュリティなどのネットワーク機能の仮想化に関する一般的な用語。""","""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-12 04:50+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",11,11
openstack%2Fsecurity-doc~master~I0d9b30a7dea05001e08eecb39fc7a63b3786469f,openstack/security-doc,master,I0d9b30a7dea05001e08eecb39fc7a63b3786469f,Updated from openstack-manuals,MERGED,2014-12-15 06:43:41.000000000,2014-12-15 06:55:17.000000000,2014-12-15 06:55:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 06:43:41.000000000', 'files': ['glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/07ba70d86628c6a19e8da911419c217425d7700c', 'message': 'Updated from openstack-manuals\n\nChange-Id: I0d9b30a7dea05001e08eecb39fc7a63b3786469f\n'}]",0,141732,07ba70d86628c6a19e8da911419c217425d7700c,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I0d9b30a7dea05001e08eecb39fc7a63b3786469f
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/32/141732/1 && git format-patch -1 --stdout FETCH_HEAD,['glossary/locale/ja.po'],1,07ba70d86628c6a19e8da911419c217425d7700c,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-15 00:16+0000\n"" ""PO-Revision-Date: 2014-12-15 01:50+0000\n""msgstr ""認証局。暗号において、電子証明書を発行するエンティティー。電子証明書は、証明書の発行先の名前により公開鍵の所有者を証明する。これにより、他の信頼される機関が証明書を信頼できるようになる。また、証明された公開鍵に対応する秘密鍵による表明を信頼できるようになる。この信頼関係のモデルにおいて、CA は証明書の発行先と証明書を信頼している機関の両方に対する信頼された第三者機関である。CA は、多くの公開鍵基盤 (PKI) スキームの特徴である。""msgstr ""cloud-init 同様のゲスト初期化機能を提供する Windows プロジェクト。""msgstr ""サーバーの再起動時に有効なままになる Compute の RabbitMQ メッセージ交換。""msgstr ""ホストの起動時にネットワークを自動的に設定する方式。Networking と Compute により提供される。""msgstr ""別々のルーティングテーブルとインターフェースを持つ単一のホストにおいて、独立した仮想ネットワークインターフェースを提供する Linux カーネル機能。物理ネットワーク環境における仮想ルーティングおよびフォワーディング (VRF) サービスと似ている。""msgstr ""ルーター通知デーモン。仮想マシンインスタンスにルーティングサービスを提供するために、Compute の VLAN マネージャーと FlatDHCP マネージャーにより使用される。""msgstr ""自動的にカタログに登録するために、Compute などのサービスを有効化する、Identity の機能。""msgstr ""Identity と安全に通信するために Compute により使用される、管理者により定義されたトークン。""msgstr ""複数の仮想マシンを使用して、物理ネットワーク上にオーバーレイされる、スイッチング、ルーティング、負荷分散、セキュリティなどのネットワーク機能の仮想化に関する一般的な用語。""","""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-12 04:50+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",11,11
openstack%2Ftripleo-image-elements~master~If3300a6b1ef1c633fc339f884e9dab0d82bc0720,openstack/tripleo-image-elements,master,If3300a6b1ef1c633fc339f884e9dab0d82bc0720,Pin setuptools to <8.0,MERGED,2014-12-14 18:40:06.000000000,2014-12-15 06:46:30.000000000,2014-12-15 06:46:29.000000000,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 9369}]","[{'number': 1, 'created': '2014-12-14 18:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/f387630d7307ecd424d8a506f90d810ea7a9ae0d', 'message': 'Pin setuptools to <8.0\n\nSetuptools 8.0 changed the way it parses version strings and many of our\nopenstack packages break when using it. Pinning this for now until our\npackages are fixed.\n\nChange-Id: If3300a6b1ef1c633fc339f884e9dab0d82bc0720\n'}, {'number': 2, 'created': '2014-12-14 18:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/536fcc6b08aa437cc889a750d14ef496a6033700', 'message': 'Pin setuptools to <8.0\n\nSetuptools 8.0 changed the way it parses version strings and many of our\nopenstack packages break when using it. Pinning this for now until our\npackages are fixed.\n\nCloses-Bug: #1402305\n\nChange-Id: If3300a6b1ef1c633fc339f884e9dab0d82bc0720\n'}, {'number': 3, 'created': '2014-12-14 18:52:50.000000000', 'files': ['elements/pip-and-virtualenv/install.d/get-pip-py-source-install/01-install-pip', 'elements/heat-cfntools/install.d/05-heat-cfntools', 'elements/openstack-clients/bin/install-openstack-client', 'elements/os-svc-install/bin/os-svc-install'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/01694b1547ac3cf70854015c11ad39d72ece39c8', 'message': 'Pin setuptools to <8.0\n\nSetuptools 8.0 changed the way it parses version strings and many of our\nopenstack packages break when using it. Pinning this for now until our\npackages are fixed.\n\nCloses-Bug: #1402305\n\nChange-Id: If3300a6b1ef1c633fc339f884e9dab0d82bc0720\n'}]",0,141659,01694b1547ac3cf70854015c11ad39d72ece39c8,12,3,3,10035,,,0,"Pin setuptools to <8.0

Setuptools 8.0 changed the way it parses version strings and many of our
openstack packages break when using it. Pinning this for now until our
packages are fixed.

Closes-Bug: #1402305

Change-Id: If3300a6b1ef1c633fc339f884e9dab0d82bc0720
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/59/141659/2 && git format-patch -1 --stdout FETCH_HEAD,"['elements/pip-and-virtualenv/install.d/get-pip-py-source-install/01-install-pip', 'elements/heat-cfntools/install.d/05-heat-cfntools', 'elements/openstack-clients/bin/install-openstack-client', 'elements/os-svc-install/bin/os-svc-install']",4,f387630d7307ecd424d8a506f90d810ea7a9ae0d,fix/setuptools-pin," pip install -U 'setuptools>=1.0,<8.0'", pip install -U 'setuptools>=1.0',4,4
openstack%2Fopenstack-manuals~master~I149c2b1db33982f209acd6f7526689c07737c13e,openstack/openstack-manuals,master,I149c2b1db33982f209acd6f7526689c07737c13e,Imported Translations from Transifex,MERGED,2014-12-15 06:11:46.000000000,2014-12-15 06:41:21.000000000,2014-12-15 06:41:20.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-15 06:11:46.000000000', 'files': ['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/glossary/locale/ko_KR.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/glossary/locale/ja.po', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/25578bdedb47f0f00462e3c179fc16bd81088b3d', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I149c2b1db33982f209acd6f7526689c07737c13e\n'}]",0,141725,25578bdedb47f0f00462e3c179fc16bd81088b3d,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I149c2b1db33982f209acd6f7526689c07737c13e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/25/141725/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/glossary/locale/ko_KR.po', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/fr.po']",10,25578bdedb47f0f00462e3c179fc16bd81088b3d,transifex/translations,"""POT-Creation-Date: 2014-12-15 00:16+0000\n"" ""PO-Revision-Date: 2014-12-15 00:30+0000\n""#: ./doc/common/section_dashboard_access.xml195(guilabel) msgid ""Stacks"" msgstr ""Stacks"" ","""POT-Creation-Date: 2014-12-14 01:11+0000\n"" ""PO-Revision-Date: 2014-12-14 01:20+0000\n""#: ./doc/common/section_dashboard_access.xml195(guilabel)",294,224
openstack%2Fswift~master~Ib5c1bb632404573a7d8b9e2bfff9c02f47ab7446,openstack/swift,master,Ib5c1bb632404573a7d8b9e2bfff9c02f47ab7446,AUTHORS and CHANGELOG update for 2.2.1 release,MERGED,2014-12-15 04:23:55.000000000,2014-12-15 06:11:20.000000000,2014-12-15 06:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 7233}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-15 04:23:55.000000000', 'files': ['CHANGELOG', '.mailmap', 'AUTHORS'], 'web_link': 'https://opendev.org/openstack/swift/commit/c23a66f66d3a9bf64276607cd01ca9ab466077f1', 'message': 'AUTHORS and CHANGELOG update for 2.2.1 release\n\nChange-Id: Ib5c1bb632404573a7d8b9e2bfff9c02f47ab7446\n'}]",0,141705,c23a66f66d3a9bf64276607cd01ca9ab466077f1,8,4,1,330,,,0,"AUTHORS and CHANGELOG update for 2.2.1 release

Change-Id: Ib5c1bb632404573a7d8b9e2bfff9c02f47ab7446
",git fetch https://review.opendev.org/openstack/swift refs/changes/05/141705/1 && git format-patch -1 --stdout FETCH_HEAD,"['CHANGELOG', '.mailmap', 'AUTHORS']",3,c23a66f66d3a9bf64276607cd01ca9ab466077f1,221,Cedric Dos Santos (cedric.dos.sant@gmail.com)Hisashi Osanai (osanai.hisashi@jp.fujitsu.com)Shilla Saebi (shilla.saebi@gmail.com),,51,0
openstack%2Fneutron~stable%2Ficehouse~I7e72da61ccf4c1a3ccc48feb0fdf3d165cdda388,openstack/neutron,stable/icehouse,I7e72da61ccf4c1a3ccc48feb0fdf3d165cdda388,Notifier: Catch NotFound error from nova,MERGED,2014-12-11 21:50:30.000000000,2014-12-15 06:11:09.000000000,2014-12-15 06:11:08.000000000,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9846}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 21:50:30.000000000', 'files': ['neutron/notifiers/nova.py', 'neutron/tests/unit/notifiers/test_notifiers_nova.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/088b755e621cf9d38f3e41f71256a22ded26a9d6', 'message': ""Notifier: Catch NotFound error from nova\n\nIf neutron sends a single event to nova and the server_uuid isn't found\nin nova. The python-novaclient will raise a 404 error. This patch ensures\nwe explicitly catch that exception and use LOG.warning instead of LOG.exception\nas this is not an error and can happen when deleting an instance if neutron\ndetects that the port_status goes down before the port is deleted because\nnova first unplugs the vif and then deletes it from neutron.\n\nCloses-bug: #1309187\n(cherry picked from commit c049583e80d9b2234557a11b77d843549f1efa65)\n\nConflicts:\n\tneutron/notifiers/nova.py\n\nChange-Id: I7e72da61ccf4c1a3ccc48feb0fdf3d165cdda388\n""}]",0,141180,088b755e621cf9d38f3e41f71256a22ded26a9d6,17,14,1,8005,,,0,"Notifier: Catch NotFound error from nova

If neutron sends a single event to nova and the server_uuid isn't found
in nova. The python-novaclient will raise a 404 error. This patch ensures
we explicitly catch that exception and use LOG.warning instead of LOG.exception
as this is not an error and can happen when deleting an instance if neutron
detects that the port_status goes down before the port is deleted because
nova first unplugs the vif and then deletes it from neutron.

Closes-bug: #1309187
(cherry picked from commit c049583e80d9b2234557a11b77d843549f1efa65)

Conflicts:
	neutron/notifiers/nova.py

Change-Id: I7e72da61ccf4c1a3ccc48feb0fdf3d165cdda388
",git fetch https://review.opendev.org/openstack/neutron refs/changes/80/141180/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/notifiers/nova.py', 'neutron/tests/unit/notifiers/test_notifiers_nova.py']",2,088b755e621cf9d38f3e41f71256a22ded26a9d6,bug/1309187,"from novaclient import exceptions as nova_exceptions def test_nova_send_event_rasies_404(self): with mock.patch.object( self.nova_notifier.nclient.server_external_events, 'create') as nclient_create: nclient_create.side_effect = nova_exceptions.NotFound self.nova_notifier.send_events() ",,12,0
openstack%2Fneutron~master~Ie62af970b3b7f225de453e56c01abc4b12af8f5e,openstack/neutron,master,Ie62af970b3b7f225de453e56c01abc4b12af8f5e,Migrate to oslo.context,MERGED,2014-12-11 19:54:44.000000000,2014-12-15 06:10:57.000000000,2014-12-15 06:10:55.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 2592}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 8911}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 19:54:44.000000000', 'files': ['requirements.txt', 'neutron/tests/unit/ml2/drivers/brocade/test_brocade_l3_plugin.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'openstack-common.conf', 'neutron/context.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/openstack/common/context.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/089e60a68b313c1f7077f010964ac27141425517', 'message': ""Migrate to oslo.context\n\nThat's just a matter of adding requirements.txt entry, fixing imports,\nand dropping the corresponding oslo-incubator module from the tree.\n\nWhile at it, made all imports to import the module into 'oslo_context' and\nnot just 'context', so that we don't override the module locally in\nmultiple methods that receive their context arguments with the same\nname, making the library inaccessible from inside those methods.\n\nChange-Id: Ie62af970b3b7f225de453e56c01abc4b12af8f5e\nCloses-Bug: #1401054\n""}]",0,141144,089e60a68b313c1f7077f010964ac27141425517,53,29,1,9656,,,0,"Migrate to oslo.context

That's just a matter of adding requirements.txt entry, fixing imports,
and dropping the corresponding oslo-incubator module from the tree.

While at it, made all imports to import the module into 'oslo_context' and
not just 'context', so that we don't override the module locally in
multiple methods that receive their context arguments with the same
name, making the library inaccessible from inside those methods.

Change-Id: Ie62af970b3b7f225de453e56c01abc4b12af8f5e
Closes-Bug: #1401054
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/141144/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'neutron/tests/unit/ml2/drivers/brocade/test_brocade_l3_plugin.py', 'neutron/plugins/brocade/NeutronPlugin.py', 'neutron/tests/unit/mlnx/test_rpcapi.py', 'neutron/tests/unit/test_agent_rpc.py', 'neutron/tests/unit/brocade/test_brocade_vlan.py', 'neutron/tests/unit/ml2/test_rpcapi.py', 'openstack-common.conf', 'neutron/context.py', 'neutron/tests/unit/hyperv/test_hyperv_rpcapi.py', 'neutron/openstack/common/context.py']",11,089e60a68b313c1f7077f010964ac27141425517,bug/1401054,,"# vim: tabstop=4 shiftwidth=4 softtabstop=4 # Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Simple class that stores security context information in the web request. Projects should subclass this class if they wish to enhance the request context or provide additional information in their specific WSGI pipeline. """""" import itertools from neutron.openstack.common import uuidutils def generate_request_id(): return 'req-%s' % uuidutils.generate_uuid() class RequestContext(object): """"""Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """""" def __init__(self, auth_token=None, user=None, tenant=None, is_admin=False, read_only=False, show_deleted=False, request_id=None): self.auth_token = auth_token self.user = user self.tenant = tenant self.is_admin = is_admin self.read_only = read_only self.show_deleted = show_deleted if not request_id: request_id = generate_request_id() self.request_id = request_id def to_dict(self): return {'user': self.user, 'tenant': self.tenant, 'is_admin': self.is_admin, 'read_only': self.read_only, 'show_deleted': self.show_deleted, 'auth_token': self.auth_token, 'request_id': self.request_id} def get_admin_context(show_deleted=""no""): context = RequestContext(None, tenant=None, is_admin=True, show_deleted=show_deleted) return context def get_context_from_function_and_args(function, args, kwargs): """"""Find an arg of type RequestContext and return it. This is useful in a couple of decorators where we don't know much about the function we're wrapping. """""" for arg in itertools.chain(kwargs.values(), args): if isinstance(arg, RequestContext): return arg return None ",25,105
openstack%2Fneutron~master~Ia1e6d3a3cba30c94a1faa157d1d83da7beb523c4,openstack/neutron,master,Ia1e6d3a3cba30c94a1faa157d1d83da7beb523c4,Strip square brackets from IPv6 addresses,MERGED,2014-12-02 12:46:15.000000000,2014-12-15 06:10:30.000000000,2014-12-15 06:10:29.000000000,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 2592}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7183}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10257}, {'_account_id': 10692}, {'_account_id': 11061}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-02 12:46:15.000000000', 'files': ['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ada6fa4f235b5ce729ab3923f1d42a14e014c9a7', 'message': 'Strip square brackets from IPv6 addresses\n\nWhen releasing old DHCP leases, square brackets around IPv6 addresses\nshould be stripped while reading dnsmasq hosts file.\n\nChange-Id: Ia1e6d3a3cba30c94a1faa157d1d83da7beb523c4\nCloses-bug: #1398380\n'}]",2,138344,ada6fa4f235b5ce729ab3923f1d42a14e014c9a7,43,29,1,11061,,,0,"Strip square brackets from IPv6 addresses

When releasing old DHCP leases, square brackets around IPv6 addresses
should be stripped while reading dnsmasq hosts file.

Change-Id: Ia1e6d3a3cba30c94a1faa157d1d83da7beb523c4
Closes-bug: #1398380
",git fetch https://review.opendev.org/openstack/neutron refs/changes/44/138344/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/linux/dhcp.py', 'neutron/tests/unit/test_linux_dhcp.py']",2,ada6fa4f235b5ce729ab3923f1d42a14e014c9a7,bug/1398380," lines = [""00:00:80:aa:bb:cc,inst-name,192.168.0.1"", ""00:00:80:aa:bb:cc,inst-name,[fdca:3ba5:a17a::1]""] self.assertEqual(set([(""192.168.0.1"", ""00:00:80:aa:bb:cc""), (""fdca:3ba5:a17a::1"", ""00:00:80:aa:bb:cc"")]), leases)"," lines = [""00:00:80:aa:bb:cc,inst-name,192.168.0.1""] self.assertEqual(set([(""192.168.0.1"", ""00:00:80:aa:bb:cc"")]), leases)",6,3
openstack%2Fneutron~master~Ia7b57c6fc092514d9fbe4e71f580a4b189dc68b0,openstack/neutron,master,Ia7b57c6fc092514d9fbe4e71f580a4b189dc68b0,Switch to using subunit-trace from tempest-lib,MERGED,2014-12-10 18:22:41.000000000,2014-12-15 06:10:16.000000000,2014-12-15 06:10:14.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-10 18:22:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/04c8c905a0e7e2e303f2a2671b7928dd6c1b3b99', 'message': 'Switch to using subunit-trace from tempest-lib\n\nThis commit removes the local copy of subunit-trace and instead uses\nthe version packaged with tempest-lib.\n\nChange-Id: Ia7b57c6fc092514d9fbe4e71f580a4b189dc68b0\n'}, {'number': 2, 'created': '2014-12-10 23:36:40.000000000', 'files': ['tools/subunit-trace.py', 'test-requirements.txt', 'tools/pretty_tox.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/65b8daffd1915ff2dbef4461763065ebe441a6f8', 'message': 'Switch to using subunit-trace from tempest-lib\n\nThis commit removes the local copy of subunit-trace and instead uses\nthe version packaged with tempest-lib.\n\nChange-Id: Ia7b57c6fc092514d9fbe4e71f580a4b189dc68b0\n'}]",0,140796,65b8daffd1915ff2dbef4461763065ebe441a6f8,40,19,2,5196,,,0,"Switch to using subunit-trace from tempest-lib

This commit removes the local copy of subunit-trace and instead uses
the version packaged with tempest-lib.

Change-Id: Ia7b57c6fc092514d9fbe4e71f580a4b189dc68b0
",git fetch https://review.opendev.org/openstack/neutron refs/changes/96/140796/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/subunit-trace.py', 'test-requirements.txt', 'tools/pretty_tox.sh']",3,04c8c905a0e7e2e303f2a2671b7928dd6c1b3b99,,"status=$(exec 4>&1 >&3; ( python -m neutron.openstack.common.lockutils python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS""; echo $? >&4 ) | $(subunit-trace -f) && exit $status","status=$(exec 4>&1 >&3; ( python -m neutron.openstack.common.lockutils python setup.py testr --slowest --testr-args=""--subunit $TESTRARGS""; echo $? >&4 ) | $(dirname $0)/subunit-trace.py -f) && exit $status",2,308
openstack%2Fpython-neutronclient~master~I550edc355f008d94d6c0b834494d693137c29111,openstack/python-neutronclient,master,I550edc355f008d94d6c0b834494d693137c29111,Use discovery fixture,MERGED,2014-10-31 11:12:39.000000000,2014-12-15 06:09:59.000000000,2014-12-15 06:09:58.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 5950}, {'_account_id': 6854}, {'_account_id': 7191}]","[{'number': 1, 'created': '2014-10-31 11:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8c23a46831becad476e5921a2fe9f19ff8444b8e', 'message': 'Use discovery fixture\n\nUse the provided fixtures rather than copying code out of\nkeystoneclient.\n\nChange-Id: I550edc355f008d94d6c0b834494d693137c29111\n'}, {'number': 2, 'created': '2014-11-21 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7c1ee113557819776f3e74ab097f0755b4d07c54', 'message': 'Use discovery fixture\n\nUse the provided fixtures rather than copying code out of\nkeystoneclient.\n\nChange-Id: I550edc355f008d94d6c0b834494d693137c29111\n'}, {'number': 3, 'created': '2014-12-02 04:06:33.000000000', 'files': ['neutronclient/tests/unit/test_shell.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c5d8557fbee5f035e22ebb4bf4869f0503af6315', 'message': 'Use discovery fixture\n\nUse the provided fixtures rather than copying code out of\nkeystoneclient.\n\nChange-Id: I550edc355f008d94d6c0b834494d693137c29111\n'}]",0,132212,c5d8557fbee5f035e22ebb4bf4869f0503af6315,19,7,3,7191,,,0,"Use discovery fixture

Use the provided fixtures rather than copying code out of
keystoneclient.

Change-Id: I550edc355f008d94d6c0b834494d693137c29111
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/12/132212/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_shell.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/tests/unit/test_auth.py']",3,8c23a46831becad476e5921a2fe9f19ff8444b8e,test2,"BASE_URL = ""http://keystone.example.com:5000/"" _v2 = fixture.V2Discovery(V2_URL) _v3 = fixture.V3Discovery(V3_URL) V3_VERSION_LIST = jsonutils.dumps({'versions': {'values': [_v2, _v3]}}) V2_VERSION_ENTRY = {'version': _v2} V3_VERSION_ENTRY = {'version': _v3} json=v2_token) json=V3_VERSION_ENTRY)","BASE_HOST = 'http://keystone.example.com' BASE_URL = ""%s:5000/"" % BASE_HOST UPDATED = '2013-03-06T00:00:00Z' # FIXME (bklei): A future release of keystoneclient will support # a discovery fixture which can replace these constants and clean # this up.V2_DESCRIBED_BY_HTML = {'href': 'http://docs.openstack.org/api/' 'openstack-identity-service/2.0/content/', 'rel': 'describedby', 'type': 'text/html'} V2_DESCRIBED_BY_PDF = {'href': 'http://docs.openstack.org/api/openstack-ident' 'ity-service/2.0/identity-dev-guide-2.0.pdf', 'rel': 'describedby', 'type': 'application/pdf'} V2_VERSION = {'id': 'v2.0', 'links': [{'href': V2_URL, 'rel': 'self'}, V2_DESCRIBED_BY_HTML, V2_DESCRIBED_BY_PDF], 'status': 'stable', 'updated': UPDATED} V3_MEDIA_TYPES = [{'base': 'application/json', 'type': 'application/vnd.openstack.identity-v3+json'}, {'base': 'application/xml', 'type': 'application/vnd.openstack.identity-v3+xml'}] V3_VERSION = {'id': 'v3.0', 'links': [{'href': V3_URL, 'rel': 'self'}], 'media-types': V3_MEDIA_TYPES, 'status': 'stable', 'updated': UPDATED} def _create_version_entry(version): return jsonutils.dumps({'version': version}) def _create_version_list(versions): return jsonutils.dumps({'versions': {'values': versions}}) V3_VERSION_LIST = _create_version_list([V3_VERSION, V2_VERSION]) V3_VERSION_ENTRY = _create_version_entry(V3_VERSION) V2_VERSION_ENTRY = _create_version_entry(V2_VERSION) text=json.dumps(v2_token)) text=V3_VERSION_ENTRY)",14,50
openstack%2Fpython-neutronclient~master~If726b1365cb7659a9db011bdcb37252563f84ef4,openstack/python-neutronclient,master,If726b1365cb7659a9db011bdcb37252563f84ef4,Cleanup copy and pasted token,MERGED,2014-10-31 11:12:39.000000000,2014-12-15 06:07:02.000000000,2014-12-15 06:07:00.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 5950}, {'_account_id': 6854}, {'_account_id': 7191}, {'_account_id': 7293}]","[{'number': 1, 'created': '2014-10-31 11:12:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/562bda82404026225a530fc449318bb04730d424', 'message': 'Cleanup copy and pasted token\n\nCorrectly use fixtures instead.\n\nChange-Id: If726b1365cb7659a9db011bdcb37252563f84ef4\n'}, {'number': 2, 'created': '2014-11-21 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/8da915d26395199f7aa9b5ec14bca8e4e08aaa3f', 'message': 'Cleanup copy and pasted token\n\nCorrectly use fixtures instead.\n\nChange-Id: If726b1365cb7659a9db011bdcb37252563f84ef4\n'}, {'number': 3, 'created': '2014-12-02 04:06:33.000000000', 'files': ['neutronclient/tests/unit/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/497bb55f66ec0621a7fc81664b8a19ce4cde766a', 'message': 'Cleanup copy and pasted token\n\nCorrectly use fixtures instead.\n\nChange-Id: If726b1365cb7659a9db011bdcb37252563f84ef4\n'}]",0,132211,497bb55f66ec0621a7fc81664b8a19ce4cde766a,20,8,3,7191,,,0,"Cleanup copy and pasted token

Correctly use fixtures instead.

Change-Id: If726b1365cb7659a9db011bdcb37252563f84ef4
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/11/132211/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/tests/unit/test_auth.py'],1,562bda82404026225a530fc449318bb04730d424,test2,"from keystoneclient import fixtureKS_TOKEN_RESULT = fixture.V2Token() KS_TOKEN_RESULT.set_scope() _s = KS_TOKEN_RESULT.add_service('network', 'Neutron Service') _s.add_endpoint(ENDPOINT_URL, region=REGION) v2_token = fixture.V2Token(token_id=TOKENID) v3_token = fixture.V3Token() token_id = uuid.uuid4().hex token=token_id, expected = {'auth_token': token_id, token_id = uuid.uuid4().hex self.client.auth_token = token_id headers=mox.ContainsKeyValue('X-Auth-Token', token_id) headers=mox.ContainsKeyValue('X-Auth-Token', KS_TOKEN_RESULT.token_id) token_id = uuid.uuid4().hex self.client.auth_token = token_id headers=mox.ContainsKeyValue('X-Auth-Token', token_id) token_id = uuid.uuid4().hex self.client.auth_token = token_id mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) headers=mox.ContainsKeyValue('X-Auth-Token', token_id) token_id = uuid.uuid4().hex self.client.auth_token = token_id headers=mox.ContainsKeyValue('X-Auth-Token', token_id) token_id = uuid.uuid4().hex self.client.auth_token = token_id mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) token_id = uuid.uuid4().hex self.client.auth_token = token_id mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % token_id), 'GET', headers=mox.IsA(dict) headers=mox.ContainsKeyValue('X-Auth-Token', KS_TOKEN_RESULT.token_id)","from keystoneclient.fixture import v2 as ks_v2_fixture from keystoneclient.fixture import v3 as ks_v3_fixtureTOKEN = 'tokentoken'KS_TOKEN_RESULT = { 'access': { 'token': {'id': TOKEN, 'expires': '2012-08-11T07:49:01Z', 'tenant': {'id': str(uuid.uuid1())}}, 'user': {'id': str(uuid.uuid1())}, 'serviceCatalog': [ {'endpoints_links': [], 'endpoints': [{'adminURL': ENDPOINT_URL, 'internalURL': ENDPOINT_URL, 'publicURL': ENDPOINT_URL, 'region': REGION}], 'type': 'network', 'name': 'Neutron Service'} ] } } v2_token = ks_v2_fixture.Token(token_id=TOKENID) v3_token = ks_v3_fixture.Token() token=TOKEN, expected = {'auth_token': TOKEN, self.client.auth_token = TOKEN headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN) headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN) self.client.auth_token = TOKEN headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN) self.client.auth_token = TOKEN mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % TOKEN), 'GET', headers=mox.IsA(dict) headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN) self.client.auth_token = TOKEN headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN) self.client.auth_token = TOKEN mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % TOKEN), 'GET', headers=mox.IsA(dict) self.client.auth_token = TOKEN mox.StrContains(AUTH_URL + '/tokens/%s/endpoints' % TOKEN), 'GET', headers=mox.IsA(dict) headers=mox.ContainsKeyValue('X-Auth-Token', TOKEN)",37,42
openstack%2Fneutron~master~I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5,openstack/neutron,master,I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5,run_tests.sh OS X script fixes,MERGED,2014-07-11 02:45:49.000000000,2014-12-15 06:02:39.000000000,2014-12-15 06:02:38.000000000,"[{'_account_id': 3}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8788}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-07-11 02:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/768ff57443200ebd0f45f3dced83422292888dfb', 'message': 'Fix mac script error with grep, error if OS_TEST_DIR is empty for all platforms\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 2, 'created': '2014-07-11 02:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/64acf07a1a62dff02f3bc47e1436590f66292d4d', 'message': 'Fix mac script error with grep and error if OS_TEST_PATH is empty for all platforms\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 3, 'created': '2014-07-11 02:47:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bebf1cd1779d7103c6d6f81452f4f59afcc86f3', 'message': 'run_tests.sh script fixes, OS X grep error, empty OS_TEST_PATH bug\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 4, 'created': '2014-07-11 02:48:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/381868f179fe385dce35e17421bbcc9fa65a722a', 'message': 'run_tests.sh script fixes\nOS X grep error, empty OS_TEST_PATH bug\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 5, 'created': '2014-07-24 16:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/54dbb9b43389038bc503771c3b2e0544923fed9c', 'message': 'run_tests.sh script fixes\nOS X grep error, empty OS_TEST_PATH bug\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 6, 'created': '2014-11-12 15:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1d964d0a588741d77be0621d54200b46284bdec3', 'message': 'run_tests.sh script fixes\nOS X grep error, empty OS_TEST_PATH bug\n\nCloses-Bug: 1391858\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 7, 'created': '2014-11-15 15:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf2057c6f1ae538d721c3d33df09f247572c2d66', 'message': 'run_tests.sh script fixes\nOS X grep error, empty OS_TEST_PATH bug\n\nCloses-Bug: 1391858\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n'}, {'number': 8, 'created': '2014-11-21 00:57:45.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5a438746580f5f626ddaf743905a91292cb3aa71', 'message': ""run_tests.sh OS X script fixes\n\nOn OS X, '*' is not a valid grep modified for '[^[:space:]:]', nor is it\nnecessary when the lines being checked against must be prefixed with\nneutron.tests.\nAlso, dirname was being called with an empty var, without quoting, resulting\nin usage errors.\n\nCloses-Bug: 1391858\n\nChange-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5\n""}]",17,106237,5a438746580f5f626ddaf743905a91292cb3aa71,228,34,8,10980,,,0,"run_tests.sh OS X script fixes

On OS X, '*' is not a valid grep modified for '[^[:space:]:]', nor is it
necessary when the lines being checked against must be prefixed with
neutron.tests.
Also, dirname was being called with an empty var, without quoting, resulting
in usage errors.

Closes-Bug: 1391858

Change-Id: I34ab0625a00809f68b7a44cb3a175a57ba0bd6d5
",git fetch https://review.opendev.org/openstack/neutron refs/changes/37/106237/8 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,768ff57443200ebd0f45f3dced83422292888dfb,bug/1391858," OS_TEST_PATH=`echo $testrargs|grep -o 'neutron\.tests[^[:space:]:]\+'|tr . /` elif [ -d ""$(dirname \""$OS_TEST_PATH\"")"" ]; then wrapper=""OS_TEST_PATH=$(dirname \""$OS_TEST_PATH\"") $wrapper"""," OS_TEST_PATH=`echo $testrargs|grep -o 'neutron\.tests[^[:space:]:]*\+'|tr . /` elif [ -d ""$(dirname $OS_TEST_PATH)"" ]; then wrapper=""OS_TEST_PATH=$(dirname $OS_TEST_PATH) $wrapper""",3,3
openstack%2Fneutron~master~Ib120bf09d24dccc0b09fae906dae05c69efe734a,openstack/neutron,master,Ib120bf09d24dccc0b09fae906dae05c69efe734a,Don't restore stopped mock that is initialized in setUp(),MERGED,2014-12-04 10:58:16.000000000,2014-12-15 06:02:26.000000000,2014-12-15 06:02:24.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-04 10:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/3d157de3dcd419e59467225b8bb8628df5eebb9a', 'message': ""Don't restore stopped mock that is initialized in setUp()\n\nSince this mock will be reinitialized for consequent test cases when\ncalling setUp(), it's not needed to restart it in the case.\n\nChange-Id: Ib120bf09d24dccc0b09fae906dae05c69efe734a\n""}, {'number': 2, 'created': '2014-12-04 12:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/571de48bc747bec616737c17c6d771ce3e63fad2', 'message': ""Don't restore stopped mock that is initialized in setUp()\n\nSince this mock will be reinitialized for consequent test cases when\ncalling setUp(), it's not needed to restart it in the case.\n\nChange-Id: Ib120bf09d24dccc0b09fae906dae05c69efe734a\n""}, {'number': 3, 'created': '2014-12-12 15:36:01.000000000', 'files': ['neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d21fa9bfc845221f5b62e4221008c20ade7cbf88', 'message': ""Don't restore stopped mock that is initialized in setUp()\n\nSince this mock will be reinitialized for consequent test cases when\ncalling setUp(), it's not needed to restart it in the case.\n\nChange-Id: Ib120bf09d24dccc0b09fae906dae05c69efe734a\n""}]",1,139011,d21fa9bfc845221f5b62e4221008c20ade7cbf88,74,30,3,9656,,,0,"Don't restore stopped mock that is initialized in setUp()

Since this mock will be reinitialized for consequent test cases when
calling setUp(), it's not needed to restart it in the case.

Change-Id: Ib120bf09d24dccc0b09fae906dae05c69efe734a
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/139011/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_l3_agent.py'],1,3d157de3dcd419e59467225b8bb8628df5eebb9a,dont-unmock," with mock.patch(ip_class_path) as ip_mock: self.agent._spawn_metadata_proxy(ri.router_id, ri.ns_name) ip_mock.assert_has_calls([ mock.call('sudo', ri.ns_name), mock.call().netns.execute([ 'neutron-ns-metadata-proxy', mock.ANY, mock.ANY, '--router_id=%s' % router_id, mock.ANY, '--metadata_port=%s' % metadata_port, '--debug', '--log-file=neutron-ns-metadata-proxy-%s.log' % router_id ], addl_env=None) ])"," try: with mock.patch(ip_class_path) as ip_mock: self.agent._spawn_metadata_proxy(ri.router_id, ri.ns_name) ip_mock.assert_has_calls([ mock.call('sudo', ri.ns_name), mock.call().netns.execute([ 'neutron-ns-metadata-proxy', mock.ANY, mock.ANY, '--router_id=%s' % router_id, mock.ANY, '--metadata_port=%s' % metadata_port, '--debug', '--log-file=neutron-ns-metadata-proxy-%s.log' % router_id ], addl_env=None) ]) finally: self.external_process_p.start()",16,19
openstack%2Fpython-neutronclient~master~I79577bd70a796543b9dea53b4839512eb8944d7c,openstack/python-neutronclient,master,I79577bd70a796543b9dea53b4839512eb8944d7c,Router create distributed accepts lower case,MERGED,2014-09-12 20:21:54.000000000,2014-12-15 06:00:47.000000000,2014-12-15 06:00:45.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 4395}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 8655}, {'_account_id': 8873}, {'_account_id': 9361}, {'_account_id': 12737}]","[{'number': 1, 'created': '2014-09-12 20:21:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/46d2941ce0b29eff0400cd4279fd6d2ce4ab76e6', 'message': 'Router create distributed accepts lower case\n\nNeutron router-create optional argument distributed\ndoes not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}, {'number': 2, 'created': '2014-09-15 07:13:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c1717a5c223517e1e731e3feffeeb1dba46b61cf', 'message': 'Router create distributed accepts lower case\n\nNeutron router-create optional argument distributed\ndoes not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}, {'number': 3, 'created': '2014-09-16 10:52:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f35c80abf978567205733e0758870b8a66170b64', 'message': 'Router create distributed accepts lower case\n\nNeutron router-create optional argument distributed\ndoes not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}, {'number': 4, 'created': '2014-09-16 11:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e31ce73df24822644c1183f75a8a91709d0de70f', 'message': 'Router create distributed/ha accepts lower case\n\nNeutron router-create optional argument ""distributed""\nand ""ha"" do not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}, {'number': 5, 'created': '2014-12-03 02:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f376c9917a800c7fc2f5ed9b6319972d8a17cd3a', 'message': 'Router create distributed accepts lower case\n\nNeutron router-create optional argument distributed\ndoes not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}, {'number': 6, 'created': '2014-12-04 21:28:50.000000000', 'files': ['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_router.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/66612c9de835bd080a9f43d91aa65e5e8639fd26', 'message': 'Router create distributed accepts lower case\n\nNeutron router-create optional argument distributed\ndoes not accept ""true/false"" anymore.\nIt only accepts value with Camel case ""True/False"".\n\nThis patch will allow the users to provide both\nTrue/true or False/false.\n\nChange-Id: I79577bd70a796543b9dea53b4839512eb8944d7c\nCloses-bug: #1368934\n'}]",24,121219,66612c9de835bd080a9f43d91aa65e5e8639fd26,58,11,6,7016,,,0,"Router create distributed accepts lower case

Neutron router-create optional argument distributed
does not accept ""true/false"" anymore.
It only accepts value with Camel case ""True/False"".

This patch will allow the users to provide both
True/true or False/false.

Change-Id: I79577bd70a796543b9dea53b4839512eb8944d7c
Closes-bug: #1368934
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/19/121219/5 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_router.py']",2,46d2941ce0b29eff0400cd4279fd6d2ce4ab76e6,bug/1368934," def _process_create_router_distributed(self, test_distributed): distributed = test_distributed def test_create_router_distributed_True(self): """"""Create router: --distributed=True."""""" self._process_create_router_distributed('True') def test_create_router_distributed_False(self): """"""Create router: --distributed=False."""""" self._process_create_router_distributed('False') def test_create_router_distributed_true(self): """"""Create router: --distributed=true."""""" self._process_create_router_distributed('true') def test_create_router_distributed_false(self): """"""Create router: --distributed=false."""""" self._process_create_router_distributed('false') ", def test_create_router_distributed(self): distributed = 'True',19,3
openstack%2Fcongress~master~Ic6aa11d1f85982fd6452c7efa8e83ae81de15c87,openstack/congress,master,Ic6aa11d1f85982fd6452c7efa8e83ae81de15c87,Enable H404,MERGED,2014-12-14 10:47:57.000000000,2014-12-15 05:13:51.000000000,2014-12-15 05:13:50.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-14 10:47:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/congress/commit/01d17ed1540a050c2f1eedcbbdd15af3440b25b1', 'message': 'Enable H404\n\nChange-Id: Ic6aa11d1f85982fd6452c7efa8e83ae81de15c87\nCloses-Bug: #1398556\n'}]",0,141633,01d17ed1540a050c2f1eedcbbdd15af3440b25b1,7,3,1,7770,,,0,"Enable H404

Change-Id: Ic6aa11d1f85982fd6452c7efa8e83ae81de15c87
Closes-Bug: #1398556
",git fetch https://review.opendev.org/openstack/congress refs/changes/33/141633/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,01d17ed1540a050c2f1eedcbbdd15af3440b25b1,bug/1398556,"ignore = E128,E129,E251,F402,F811,F812,H237,H305,H401,H405,H904,H231,H302","# H404 multi line docstring should start with a summaryignore = E128,E129,E251,F402,F811,F812,H237,H305,H401,H404,H405,H904,H231,H302",1,2
openstack%2Fcongress~master~Ib2f65f043b183edd2e553a51807276eafb94bb4b,openstack/congress,master,Ib2f65f043b183edd2e553a51807276eafb94bb4b,Skip the sdist phase,MERGED,2014-12-14 10:55:23.000000000,2014-12-15 05:10:52.000000000,2014-12-15 05:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-14 10:55:23.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/congress/commit/fd345b5f94259f8d43318a5b55245baccdb5c18b', 'message': 'Skip the sdist phase\n\nSpeeds up tox runs\n\nChange-Id: Ib2f65f043b183edd2e553a51807276eafb94bb4b\n'}]",0,141634,fd345b5f94259f8d43318a5b55245baccdb5c18b,7,3,1,7770,,,0,"Skip the sdist phase

Speeds up tox runs

Change-Id: Ib2f65f043b183edd2e553a51807276eafb94bb4b
",git fetch https://review.opendev.org/openstack/congress refs/changes/34/141634/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,fd345b5f94259f8d43318a5b55245baccdb5c18b,,skipsdist = True,,1,0
openstack%2Ftricircle~master~Ib39eb92dc68e8cacfb5588a2b04226723249bbf5,openstack/tricircle,master,Ib39eb92dc68e8cacfb5588a2b04226723249bbf5,modify remarks and logs for cinder proxy,MERGED,2014-12-15 04:37:18.000000000,2014-12-15 04:38:54.000000000,2014-12-15 04:38:54.000000000,"[{'_account_id': 3}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-15 04:37:18.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/7f649fc7ade2a59c89fa25936013f5508991715d', 'message': 'modify remarks and logs for cinder proxy\n\nChange-Id: Ib39eb92dc68e8cacfb5588a2b04226723249bbf5\n'}]",0,141707,7f649fc7ade2a59c89fa25936013f5508991715d,6,2,1,13924,,,0,"modify remarks and logs for cinder proxy

Change-Id: Ib39eb92dc68e8cacfb5588a2b04226723249bbf5
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/07/141707/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,7f649fc7ade2a59c89fa25936013f5508991715d,," help='pagination limit query for volumes between' 'cascading and cascaded openstack'), LOG.debug(_('cascade info: pagination volumes query.' 'marker: %s, vols: %s'), marker, vols) LOG.debug(_('cascade info: marker: %s'), marker) 'volumes: %s'), volumes)"," help='pagination limit query for volume between cascading' 'and cascaded volume'), LOG.debug(_('cascade info, pagination volumes query.marker' '%s, vols:%s'), marker, vols) LOG.debug(_('cascade info, marker: %s'), marker) 'volumes:%s'), volumes)",6,6
openstack%2Ftricircle~master~Icefca593dfd76a5173a717b5f8ec2f5155484a33,openstack/tricircle,master,Icefca593dfd76a5173a717b5f8ec2f5155484a33,remove terminate_connection while detach_volume for novaproxy,MERGED,2014-12-15 04:23:42.000000000,2014-12-15 04:25:39.000000000,2014-12-15 04:25:39.000000000,"[{'_account_id': 3}, {'_account_id': 10068}, {'_account_id': 13924}]","[{'number': 1, 'created': '2014-12-15 04:23:42.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/fa7b3018439e7958a251aaedea4df473d7233127', 'message': 'remove terminate_connection while detach_volume for novaproxy\n\nChange-Id: Icefca593dfd76a5173a717b5f8ec2f5155484a33\n'}]",0,141704,fa7b3018439e7958a251aaedea4df473d7233127,7,3,1,13924,,,0,"remove terminate_connection while detach_volume for novaproxy

Change-Id: Icefca593dfd76a5173a717b5f8ec2f5155484a33
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/04/141704/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,fa7b3018439e7958a251aaedea4df473d7233127,,," #self.volume_api.terminate_connection(context, volume_id, connector)",0,1
openstack%2Fkeystone~master~I5e00a9fea3430198098e9debe715e574349feae9,openstack/keystone,master,I5e00a9fea3430198098e9debe715e574349feae9,Adds a dependency on jsd,ABANDONED,2014-07-29 15:46:21.000000000,2014-12-15 04:05:41.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-07-29 15:46:21.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/keystone/commit/f44832e24b2d1c5b012eb2706ab76faa446c75a5', 'message': 'Adds a dependency on jsd\n\nChange-Id: I5e00a9fea3430198098e9debe715e574349feae9\n'}]",0,110337,f44832e24b2d1c5b012eb2706ab76faa446c75a5,8,3,1,7725,,,0,"Adds a dependency on jsd

Change-Id: I5e00a9fea3430198098e9debe715e574349feae9
",git fetch https://review.opendev.org/openstack/keystone refs/changes/37/110337/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,f44832e24b2d1c5b012eb2706ab76faa446c75a5,bp/api-validation,jsd,,2,0
openstack%2Fkeystone~master~Iee72c3bc243d818920f084dd63b95eb91e6d318d,openstack/keystone,master,Iee72c3bc243d818920f084dd63b95eb91e6d318d,Convert projects from embeded JSON to jsd schemas,ABANDONED,2014-07-29 15:46:21.000000000,2014-12-15 04:05:10.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-07-29 15:46:21.000000000', 'files': ['keystone/assignment/controllers.py', 'keystone/common/validation/__init__.py', 'keystone/tests/test_validation.py', 'keystone/common/validation/parameter_types.py', 'keystone/assignment/schema.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2b158972b5462ff38e8ec4933d7e5c7d3915ad83', 'message': 'Convert projects from embeded JSON to jsd schemas\n\nChange-Id: Iee72c3bc243d818920f084dd63b95eb91e6d318d\n'}]",1,110339,2b158972b5462ff38e8ec4933d7e5c7d3915ad83,10,4,1,7725,,,0,"Convert projects from embeded JSON to jsd schemas

Change-Id: Iee72c3bc243d818920f084dd63b95eb91e6d318d
",git fetch https://review.opendev.org/openstack/keystone refs/changes/39/110339/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/assignment/controllers.py', 'keystone/common/validation/__init__.py', 'keystone/tests/test_validation.py', 'keystone/common/validation/parameter_types.py', 'keystone/assignment/schema.py']",5,2b158972b5462ff38e8ec4933d7e5c7d3915ad83,bp/api-validation,import jsd class ProjectSchema(jsd.Object): # required domain_id = parameter_types.IdString(required=True) name = parameter_types.Name(required=True) # optional description = parameter_types.Description() enabled = parameter_types.Boolean() ," project_create = { 'type': 'object', 'properties': { 'description': parameter_types.description, 'domain_id': parameter_types.required_id_string, 'enabled': parameter_types.boolean, 'name': parameter_types.name }, # NOTE(lbragstad): A project name is the only parameter required for # project creation according to the Identity V3 API. We should think # about using the maxProperties validator here, and in update. 'required': ['name', 'domain_id'], 'additionalProperties': True } project_update = { 'type': 'object', 'properties': { 'description': parameter_types.description, 'domain_id': parameter_types.required_id_string, 'enabled': parameter_types.boolean, 'name': parameter_types.name }, # NOTE(lbragstad) Make sure at least one property is being updated 'minProperties': 1, 'additionalProperties': True }",96,64
openstack%2Fkeystone~master~I9a00113b6c0a6d16d194ca2462f6a599cef33b15,openstack/keystone,master,I9a00113b6c0a6d16d194ca2462f6a599cef33b15,Initial attempt at lazy configs - ugly,ABANDONED,2014-07-29 15:46:21.000000000,2014-12-15 04:04:53.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7725}]","[{'number': 1, 'created': '2014-07-29 15:46:21.000000000', 'files': ['keystone/common/validation/__init__.py', 'keystone/common/validation/parameter_types.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d22da35263c6c6b1819d1c74c9ea047f7d3785b8', 'message': 'Initial attempt at lazy configs - ugly\n\nChange-Id: I9a00113b6c0a6d16d194ca2462f6a599cef33b15\n'}]",0,110340,d22da35263c6c6b1819d1c74c9ea047f7d3785b8,8,3,1,7725,,,0,"Initial attempt at lazy configs - ugly

Change-Id: I9a00113b6c0a6d16d194ca2462f6a599cef33b15
",git fetch https://review.opendev.org/openstack/keystone refs/changes/40/110340/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/common/validation/__init__.py', 'keystone/common/validation/parameter_types.py']",2,d22da35263c6c6b1819d1c74c9ea047f7d3785b8,bp/api-validation, @property def pattern(self): # NOTE(dstanek): this is a property so that it can be evaluated # lazily. This can't be executed at import time because the # config options wouldn't have been setup. return CONF.validation.id_string_regex, #pattern = CONF.validation.id_string_regex pattern = '^[a-zA-Z0-9-]+$',10,5
openstack%2Fkeystone~master~Id9dae825608b0727e9076e3fcf234d8cf89f5ca2,openstack/keystone,master,Id9dae825608b0727e9076e3fcf234d8cf89f5ca2,WIP: Middleware tests now run under Python3,ABANDONED,2014-06-12 14:09:29.000000000,2014-12-15 04:02:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 7725}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-06-12 14:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/5dffd4218d31cc6d4249c7602ed73ce3df7f2784', 'message': 'Middleware tests now run under Python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 2, 'created': '2014-06-16 16:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e7590359c6bf7fdb42e91151eca089ee647e91c2', 'message': 'Middleware tests now run under Python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 3, 'created': '2014-06-18 19:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/36aa49c68f532d5235f5163c57b2356e7cb09f08', 'message': 'Middleware tests now run under Python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 4, 'created': '2014-06-25 20:10:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6c614c6e5466aa27b36dc496fc0bca0c61399a0d', 'message': 'Middleware tests now run under Python3\n\nbp python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 5, 'created': '2014-06-26 18:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/60c85036deae7ec5bbe395e129f3818c10e2d344', 'message': 'Middleware tests now run under Python3\n\nbp python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 6, 'created': '2014-10-01 16:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f8ace8017b6d48c013344cc9261b38313128cfaf', 'message': 'Middleware tests now run under Python3\n\nbp python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 7, 'created': '2014-10-23 15:47:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/11e7c12de132a9277a8660f8b147e6bc6bec10d5', 'message': 'Middleware tests now run under Python3\n\nbp python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}, {'number': 8, 'created': '2014-11-21 16:31:45.000000000', 'files': ['keystone/middleware/core.py', 'keystone/tests/test_middleware.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone/commit/cf3cebff67c55d8ad1cece227474ff4d91e69380', 'message': 'WIP: Middleware tests now run under Python3\n\nbp python3\n\nChange-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2\n'}]",0,99669,cf3cebff67c55d8ad1cece227474ff4d91e69380,31,4,8,7725,,,0,"WIP: Middleware tests now run under Python3

bp python3

Change-Id: Id9dae825608b0727e9076e3fcf234d8cf89f5ca2
",git fetch https://review.opendev.org/openstack/keystone refs/changes/69/99669/8 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/middleware/core.py', 'keystone/tests/test_middleware.py', 'keystone/common/serializer.py', 'tox.ini']",4,5dffd4218d31cc6d4249c7602ed73ce3df7f2784,bp/removed-as-of-kilo, keystone/tests/test_middleware.py \,,18,15
openstack%2Fneutron~master~Ifda70a2656a38ddf506e8f4d98e52b40e225e529,openstack/neutron,master,Ifda70a2656a38ddf506e8f4d98e52b40e225e529,Imported Translations from Transifex,MERGED,2014-12-13 06:07:51.000000000,2014-12-15 03:54:13.000000000,2014-12-15 03:54:11.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-13 06:07:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b081fd8721c1c6c4eed23922c2221cadd0e1b0f9', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifda70a2656a38ddf506e8f4d98e52b40e225e529\n'}, {'number': 2, 'created': '2014-12-14 06:06:15.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5da5ae60ef46ef393b3d5a6434813df1533641f4', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ifda70a2656a38ddf506e8f4d98e52b40e225e529\n'}]",0,141539,5da5ae60ef46ef393b3d5a6434813df1533641f4,43,19,2,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ifda70a2656a38ddf506e8f4d98e52b40e225e529
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/141539/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-info.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",10,b081fd8721c1c6c4eed23922c2221cadd0e1b0f9,transifex/translations,"""POT-Creation-Date: 2014-12-13 06:07+0000\n"" ""PO-Revision-Date: 2014-12-13 00:03+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1734#: neutron/agent/l3/agent.py:1636#: neutron/db/l3_dvrscheduler_db.py:307 msgid ""SNAT already bound to a service node."" msgstr """" ","""POT-Creation-Date: 2014-12-12 06:07+0000\n"" ""PO-Revision-Date: 2014-12-10 22:16+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1720#: neutron/agent/l3/agent.py:1622",80,40
openstack%2Fkeystone~master~Ia1dfd887e23b0055fdc260473be367fbcd6c7662,openstack/keystone,master,Ia1dfd887e23b0055fdc260473be367fbcd6c7662,Remove database setup duplication,MERGED,2014-10-07 21:32:22.000000000,2014-12-15 03:39:03.000000000,2014-12-15 03:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 6460}, {'_account_id': 6486}, {'_account_id': 7725}, {'_account_id': 8978}, {'_account_id': 9142}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-07 21:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/080405ef7b7188bb48af2a36c323e7e544acb794', 'message': 'Remove database setup duplication\n\nThe Database fixture was being used twice. This removes is from the\ntest_v3.RestfulTestCase class in favor of keeping the setup in the\nrest.RestfulTestCase class. To do this the rest.RestfulTestCase class\nneeded a method to define extensions.\n\nimplements bp tests-on-rdbmses\nChange-Id: Ia1dfd887e23b0055fdc260473be367fbcd6c7662\n'}, {'number': 2, 'created': '2014-10-08 16:18:16.000000000', 'files': ['keystone/tests/rest.py', 'keystone/tests/test_v3.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5c2d4b51ff1aaaea4bdb6b271b95b741a14942c5', 'message': 'Remove database setup duplication\n\nThe Database fixture was being used twice. This removes is from the\ntest_v3.RestfulTestCase class in favor of keeping the setup in the\nrest.RestfulTestCase class. To do this the rest.RestfulTestCase class\nneeded a method to define extensions.\n\nimplements bp tests-on-rdbmses\nChange-Id: Ia1dfd887e23b0055fdc260473be367fbcd6c7662\n'}]",2,126734,5c2d4b51ff1aaaea4bdb6b271b95b741a14942c5,19,10,2,7725,,,0,"Remove database setup duplication

The Database fixture was being used twice. This removes is from the
test_v3.RestfulTestCase class in favor of keeping the setup in the
rest.RestfulTestCase class. To do this the rest.RestfulTestCase class
needed a method to define extensions.

implements bp tests-on-rdbmses
Change-Id: Ia1dfd887e23b0055fdc260473be367fbcd6c7662
",git fetch https://review.opendev.org/openstack/keystone refs/changes/34/126734/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/rest.py', 'keystone/tests/test_v3.py']",2,080405ef7b7188bb48af2a36c323e7e544acb794,bp/tests-on-rdbmses,, self.useFixture(database.Database(self.get_extensions())) ,4,3
openstack%2Fneutron~master~Ifce3b1337d653721a57a5bc0199e155b0e49e36b,openstack/neutron,master,Ifce3b1337d653721a57a5bc0199e155b0e49e36b,"when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.",ABANDONED,2014-12-13 06:08:05.000000000,2014-12-15 03:29:17.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-13 06:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9f6e5bc03e9f65dc9b4d7662e87c75c432a7b14b', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\n\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b\n""}, {'number': 2, 'created': '2014-12-15 02:16:32.000000000', 'files': ['neutron/services/firewall/agents/l3reference/firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/31e29dc8334d97bb3135ea8e2099bfa7dd4b0269', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\n\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b\n""}]",2,141540,31e29dc8334d97bb3135ea8e2099bfa7dd4b0269,31,21,2,14203,,,0,"when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.

   step:
   1. Create network and router in A and B tenant.
   2. Create a firewall in A tenant.
   3. Restart vpn and l3 agent serivce.
   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn

Then I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.

Closes-Bug: #1398267
Change-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/141540/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/services/firewall/agents/l3reference/firewall_l3_agent.py'],1,9f6e5bc03e9f65dc9b4d7662e87c75c432a7b14b,bug/1398267," ##1398267 if fw['tenant_id'] == ri.router['tenant_id']: self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)"," self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)",6,4
openstack%2Ftricircle~master~I17ea74b804bf71958df70eb2885a8656757719df,openstack/tricircle,master,I17ea74b804bf71958df70eb2885a8656757719df,get rid off terminate_connection for nova_proxy while detach volume,MERGED,2014-12-15 03:23:55.000000000,2014-12-15 03:26:08.000000000,2014-12-15 03:26:08.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-15 03:23:55.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/bfd2c1159527e95c0c4635ecea1042c86b922305', 'message': 'get rid off terminate_connection for nova_proxy while detach volume\n\nChange-Id: I17ea74b804bf71958df70eb2885a8656757719df\n'}]",0,141696,bfd2c1159527e95c0c4635ecea1042c86b922305,6,2,1,9684,,,0,"get rid off terminate_connection for nova_proxy while detach volume

Change-Id: I17ea74b804bf71958df70eb2885a8656757719df
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/96/141696/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,bfd2c1159527e95c0c4635ecea1042c86b922305,," #self.volume_api.terminate_connection(context, volume_id, connector)"," self.volume_api.terminate_connection(context, volume_id, connector)",1,1
openstack%2Fhorizon~master~I7d1d7749117805a928bca4146b6f8bbfe3d2e2ec,openstack/horizon,master,I7d1d7749117805a928bca4146b6f8bbfe3d2e2ec,Imported Translations from Transifex,MERGED,2014-12-13 06:06:18.000000000,2014-12-15 03:13:37.000000000,2014-12-15 03:13:36.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-13 06:06:18.000000000', 'files': ['openstack_dashboard/locale/de/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/85b7779c3d56f970e0034ffd1020e92c5789cc72', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I7d1d7749117805a928bca4146b6f8bbfe3d2e2ec\n'}]",0,141538,85b7779c3d56f970e0034ffd1020e92c5789cc72,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I7d1d7749117805a928bca4146b6f8bbfe3d2e2ec
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/141538/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/locale/de/LC_MESSAGES/django.po'],1,85b7779c3d56f970e0034ffd1020e92c5789cc72,transifex/translations,"""PO-Revision-Date: 2014-12-12 16:01+0000\n"" ""Last-Translator: Ettore Atalan <atalanttore@googlemail.com>\n""msgstr ""Netzwerkdetails""msgstr ""%(conf_name)s: %(conf_val)s""msgstr ""Subnetzdetails""msgstr ""Portdetails""msgstr ""Ressourcendetails: %s""msgstr ""Ressourcendetails""","""PO-Revision-Date: 2014-12-12 03:41+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",8,8
openstack%2Fneutron~stable%2Ficehouse~I5f62b663e9898b80ef79b79f090ca7ae47cc4c06,openstack/neutron,stable/icehouse,I5f62b663e9898b80ef79b79f090ca7ae47cc4c06,"when delete the lb vip, the tap device not be deleted",ABANDONED,2014-12-05 06:18:49.000000000,2014-12-15 02:18:04.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10068}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 12040}, {'_account_id': 14203}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-05 06:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b48c7bde42c7d644afde842abca953de4f335651', 'message': 'when delete the lb vip, the tap device not be deleted\n\nWhen I delete the lb vip which is ERROR status, the lbaas namespace tap device not be delete.\nso when I add a new vip used the same ip address, then It can not be accessed. Because the ip\naddress confilict.\n\nChange-Id: I5f62b663e9898b80ef79b79f090ca7ae47cc4c06\nCloses-Bug: #1399114\n'}, {'number': 2, 'created': '2014-12-12 09:29:55.000000000', 'files': ['neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0781701017c0ec918a5f9b70bc8ea8ec405007a0', 'message': 'when delete the lb vip, the tap device not be deleted\n\nWhen I delete the lb vip which is ERROR status, the lbaas namespace tap device not be delete.\nso when I add a new vip used the same ip address, then It can not be accessed. Because the ip\naddress confilict.\n\nChange-Id: I5f62b663e9898b80ef79b79f090ca7ae47cc4c06\nCloses-Bug: #1399114\n'}]",0,139533,0781701017c0ec918a5f9b70bc8ea8ec405007a0,29,16,2,14203,,,0,"when delete the lb vip, the tap device not be deleted

When I delete the lb vip which is ERROR status, the lbaas namespace tap device not be delete.
so when I add a new vip used the same ip address, then It can not be accessed. Because the ip
address confilict.

Change-Id: I5f62b663e9898b80ef79b79f090ca7ae47cc4c06
Closes-Bug: #1399114
",git fetch https://review.opendev.org/openstack/neutron refs/changes/33/139533/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_attributes.py', 'neutron/api/v2/attributes.py', 'neutron/services/loadbalancer/drivers/haproxy/namespace_driver.py']",3,b48c7bde42c7d644afde842abca953de4f335651,bug/1399114," def undeploy_instance(self, pool_id, port_id = None): if port_id: self.undeploy_instance(vip['pool_id'],vip['port_id'])"," def undeploy_instance(self, pool_id): if pool_id in self.pool_to_port_id: self.undeploy_instance(vip['pool_id'])",75,26
openstack%2Fneutron~stable%2Ficehouse~Ifce3b1337d653721a57a5bc0199e155b0e49e36b,openstack/neutron,stable/icehouse,Ifce3b1337d653721a57a5bc0199e155b0e49e36b,"when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.",ABANDONED,2014-12-05 06:36:12.000000000,2014-12-15 02:17:48.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 7249}, {'_account_id': 7787}, {'_account_id': 9656}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9846}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 12040}, {'_account_id': 14101}, {'_account_id': 14203}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-05 06:36:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/43d3775bf59032b8f82a98a79772aed081767e8c', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\n\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nChange-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b\nCloses-Bug: #1398267\n""}, {'number': 2, 'created': '2014-12-12 09:16:12.000000000', 'files': ['neutron/services/firewall/agents/l3reference/firewall_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f03deddeb04334c47948f14346b7e8476d05613d', 'message': ""when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.\n\n   step:\n   1. Create network and router in A and B tenant.\n   2. Create a firewall in A tenant.\n   3. Restart vpn and l3 agent serivce.\n   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn\n\nThen I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.\n\nCloses-Bug: #1398267\nChange-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b\n""}]",1,139540,f03deddeb04334c47948f14346b7e8476d05613d,29,17,2,14203,,,0,"when restart the vpn and l3 agent, the firewall rule apply to all tenants' router.

   step:
   1. Create network and router in A and B tenant.
   2. Create a firewall in A tenant.
   3. Restart vpn and l3 agent serivce.
   4. ip netns exec qrouter-B_router_uuid iptables -L -t filter -vn

Then I find the firewall rule in chain neutron-l3-agent-FORWARD and neutron-vpn-agen-FORWARD.

Closes-Bug: #1398267
Change-Id: Ifce3b1337d653721a57a5bc0199e155b0e49e36b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/40/139540/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_attributes.py', 'neutron/api/v2/attributes.py', 'neutron/services/firewall/agents/l3reference/firewall_l3_agent.py']",3,43d3775bf59032b8f82a98a79772aed081767e8c,bug/1398267," if fw['tenant_id'] == ri.router['tenant_id']: self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)"," self._invoke_driver_for_sync_from_plugin( ctx, router_info_list, fw)",77,27
openstack%2Fkeystone~master~Ia2aaf3453ac7833d78ed1137659ce25902f6fc11,openstack/keystone,master,Ia2aaf3453ac7833d78ed1137659ce25902f6fc11,Fixes indentation in contrib/federation/utils.py,ABANDONED,2014-12-12 14:24:49.000000000,2014-12-15 01:53:43.000000000,,"[{'_account_id': 3}, {'_account_id': 8866}, {'_account_id': 8978}, {'_account_id': 9101}, {'_account_id': 9142}, {'_account_id': 11022}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-12 14:24:49.000000000', 'files': ['keystone/contrib/federation/utils.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ea6a5e72cf7b86bf6bb2d36f673c833b1b24b7fc', 'message': 'Fixes indentation in contrib/federation/utils.py\n\nThis code was indented one level too many.\n\nChange-Id: Ia2aaf3453ac7833d78ed1137659ce25902f6fc11\n'}]",0,141383,ea6a5e72cf7b86bf6bb2d36f673c833b1b24b7fc,10,7,1,13140,,,0,"Fixes indentation in contrib/federation/utils.py

This code was indented one level too many.

Change-Id: Ia2aaf3453ac7833d78ed1137659ce25902f6fc11
",git fetch https://review.opendev.org/openstack/keystone refs/changes/83/141383/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/contrib/federation/utils.py'],1,ea6a5e72cf7b86bf6bb2d36f673c833b1b24b7fc,mappings," v = jsonschema.Draft4Validator(MAPPING_SCHEMA) messages = '' for error in sorted(v.iter_errors(ref), key=str): messages = messages + error.message + ""\n"" if messages: raise exception.ValidationError(messages)"," v = jsonschema.Draft4Validator(MAPPING_SCHEMA) messages = '' for error in sorted(v.iter_errors(ref), key=str): messages = messages + error.message + ""\n"" if messages: raise exception.ValidationError(messages)",6,6
openstack%2Fnova~master~Ib2765006d59122b409915dfb8c77af90abf04d59,openstack/nova,master,Ib2765006d59122b409915dfb8c77af90abf04d59,Updated from global requirements,MERGED,2014-12-12 22:19:13.000000000,2014-12-15 01:01:14.000000000,2014-12-15 01:01:12.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 22:19:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3547aa14acd478ee3ddac80e932bc681efc3d99e', 'message': 'Updated from global requirements\n\nChange-Id: Ib2765006d59122b409915dfb8c77af90abf04d59\n'}, {'number': 2, 'created': '2014-12-12 22:28:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/ebbb56e297fd09a3e0b027cf888e727964973978', 'message': 'Updated from global requirements\n\nChange-Id: Ib2765006d59122b409915dfb8c77af90abf04d59\n'}]",0,141508,ebbb56e297fd09a3e0b027cf888e727964973978,12,6,2,11131,,,0,"Updated from global requirements

Change-Id: Ib2765006d59122b409915dfb8c77af90abf04d59
",git fetch https://review.opendev.org/openstack/nova refs/changes/08/141508/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3547aa14acd478ee3ddac80e932bc681efc3d99e,openstack/requirements,python-glanceclient>=0.15.0,python-glanceclient>=0.14.0,1,1
openstack%2Foslo-incubator~master~Idf12a6b8f83799e6a0b3c22b2e222fb035203911,openstack/oslo-incubator,master,Idf12a6b8f83799e6a0b3c22b2e222fb035203911,Fix for SetuptoolsVersion object does not support indexing,ABANDONED,2014-12-14 16:05:56.000000000,2014-12-15 00:47:13.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 7687}, {'_account_id': 7770}]","[{'number': 1, 'created': '2014-12-14 16:05:56.000000000', 'files': ['openstack/common/versionutils.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/4074051de37634e6578f1762361efe6cf8d4aabb', 'message': 'Fix for SetuptoolsVersion object does not support indexing\n\nSetuptools 8 was released to PyPI yesterday, it returns a\nVersion object when parse_version is called. Earlier we used\nto get a tuple of strings. Fortunately the Version object\nhas an iterator as well. So adding a list() will support both\ncases\n\nChange-Id: Idf12a6b8f83799e6a0b3c22b2e222fb035203911\n'}]",0,141653,4074051de37634e6578f1762361efe6cf8d4aabb,12,6,1,5638,,,0,"Fix for SetuptoolsVersion object does not support indexing

Setuptools 8 was released to PyPI yesterday, it returns a
Version object when parse_version is called. Earlier we used
to get a tuple of strings. Fortunately the Version object
has an iterator as well. So adding a list() will support both
cases

Change-Id: Idf12a6b8f83799e6a0b3c22b2e222fb035203911
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/53/141653/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/common/versionutils.py'],1,4074051de37634e6578f1762361efe6cf8d4aabb,, requested_parts = list(pkg_resources.parse_version(requested_version)) current_parts = list(pkg_resources.parse_version(current_version)), requested_parts = pkg_resources.parse_version(requested_version) current_parts = pkg_resources.parse_version(current_version),2,2
openstack%2Fnova~master~I9bc6bc4a0d3084ef3c8c864ab9fad17a55ea65c5,openstack/nova,master,I9bc6bc4a0d3084ef3c8c864ab9fad17a55ea65c5,Fix for SetuptoolsVersion object does not support indexing,ABANDONED,2014-12-14 16:07:32.000000000,2014-12-15 00:46:59.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7687}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-14 16:07:32.000000000', 'files': ['nova/openstack/common/versionutils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/737c405d0eeeaa7699324a06d9392aae82c507ca', 'message': 'Fix for SetuptoolsVersion object does not support indexing\n\nSetuptools 8 was released to PyPI yesterday, it returns a\nVersion object when parse_version is called. Earlier we used\nto get a tuple of strings. Fortunately the Version object\nhas an iterator as well. So adding a list() will support both\ncases\n\nDepends-On: Idf12a6b8f83799e6a0b3c22b2e222fb035203911\nChange-Id: I9bc6bc4a0d3084ef3c8c864ab9fad17a55ea65c5\n'}]",0,141654,737c405d0eeeaa7699324a06d9392aae82c507ca,9,7,1,5638,,,0,"Fix for SetuptoolsVersion object does not support indexing

Setuptools 8 was released to PyPI yesterday, it returns a
Version object when parse_version is called. Earlier we used
to get a tuple of strings. Fortunately the Version object
has an iterator as well. So adding a list() will support both
cases

Depends-On: Idf12a6b8f83799e6a0b3c22b2e222fb035203911
Change-Id: I9bc6bc4a0d3084ef3c8c864ab9fad17a55ea65c5
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/141654/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/openstack/common/versionutils.py'],1,737c405d0eeeaa7699324a06d9392aae82c507ca,, requested_parts = list(pkg_resources.parse_version(requested_version)) current_parts = list(pkg_resources.parse_version(current_version)), requested_parts = pkg_resources.parse_version(requested_version) current_parts = pkg_resources.parse_version(current_version),2,2
openstack%2Fopenstack-manuals~master~Id5359e4dd3ca22c7cd82beb8839247f637b679b2,openstack/openstack-manuals,master,Id5359e4dd3ca22c7cd82beb8839247f637b679b2,fix typo in section_environment,MERGED,2014-12-14 13:00:42.000000000,2014-12-15 00:12:19.000000000,2014-12-15 00:12:18.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-14 13:00:42.000000000', 'files': ['doc/user-guide/hot/section_environment.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bc93bb5ffe61c4312fe0bbd48ecbf60ebd5e81c4', 'message': 'fix typo in section_environment\n\nthe word ""wilcards"" should be ""wildcards""\n\nChange-Id: Id5359e4dd3ca22c7cd82beb8839247f637b679b2\n'}]",0,141639,bc93bb5ffe61c4312fe0bbd48ecbf60ebd5e81c4,7,3,1,11530,,,0,"fix typo in section_environment

the word ""wilcards"" should be ""wildcards""

Change-Id: Id5359e4dd3ca22c7cd82beb8839247f637b679b2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/141639/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/hot/section_environment.xml'],1,bc93bb5ffe61c4312fe0bbd48ecbf60ebd5e81c4,typo_in_section_environment, <para>You can use wildcards to map multiple resources:</para>, <para>You can use wilcards to map multiple resources:</para>,1,1
openstack%2Fopenstack-manuals~master~Ieede0bad2b6c7a9c6c0cb4983424222390196863,openstack/openstack-manuals,master,Ieede0bad2b6c7a9c6c0cb4983424222390196863,fix typo in section_sdk_nova.xml,MERGED,2014-12-14 12:43:30.000000000,2014-12-15 00:11:54.000000000,2014-12-15 00:11:53.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-14 12:43:30.000000000', 'files': ['doc/user-guide/section_sdk_nova.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ec63492a2b19b4d747137acc001e093866402133', 'message': 'fix typo in section_sdk_nova.xml\n\nwhen using nova_client.servers.list, miss parentheses\n\nChange-Id: Ieede0bad2b6c7a9c6c0cb4983424222390196863\n'}]",0,141638,ec63492a2b19b4d747137acc001e093866402133,7,3,1,11530,,,0,"fix typo in section_sdk_nova.xml

when using nova_client.servers.list, miss parentheses

Change-Id: Ieede0bad2b6c7a9c6c0cb4983424222390196863
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/38/141638/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/user-guide/section_sdk_nova.xml'],1,ec63492a2b19b4d747137acc001e093866402133,typo_in_sdk_compute_api,print(nova_client.servers.list())</programlisting>,print(nova_client.servers.list)</programlisting>,1,1
openstack%2Fopenstack-manuals~master~Iee95c7d735f7441941bf9e39dde99e432b7b281d,openstack/openstack-manuals,master,Iee95c7d735f7441941bf9e39dde99e432b7b281d,"misusing the word ""Containers"" in Orchestration tab",MERGED,2014-12-14 13:22:15.000000000,2014-12-15 00:11:20.000000000,2014-12-15 00:11:19.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-14 13:22:15.000000000', 'files': ['doc/common/section_dashboard_access.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/887c5c505f2f90097f017a3b63da48b638bbc326', 'message': 'misusing the word ""Containers"" in Orchestration tab\n\nthe word ""Containers"" should be the word ""Stacks""\n\nChange-Id: Iee95c7d735f7441941bf9e39dde99e432b7b281d\n'}]",0,141640,887c5c505f2f90097f017a3b63da48b638bbc326,7,3,1,11530,,,0,"misusing the word ""Containers"" in Orchestration tab

the word ""Containers"" should be the word ""Stacks""

Change-Id: Iee95c7d735f7441941bf9e39dde99e432b7b281d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/40/141640/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/section_dashboard_access.xml'],1,887c5c505f2f90097f017a3b63da48b638bbc326,misusing_container_in_Orchestration_tab, <td><para><guilabel>Stacks</guilabel></para></td>, <td><para><guilabel>Containers</guilabel></para></td>,1,1
openstack%2Fpbr~master~If325b220b3eaa546c0339d1152c09b74fa45b9ad,openstack/pbr,master,If325b220b3eaa546c0339d1152c09b74fa45b9ad,Merge tag '0.10.1' into HEAD,MERGED,2014-12-14 02:41:52.000000000,2014-12-14 23:43:45.000000000,2014-12-14 23:43:44.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2014-12-14 02:41:52.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/1f5c9f71f99944ecf6e120efdb677f44fbe3b654', 'message': ""Merge tag '0.10.1' into HEAD\n\nRelease 0.10.1 for PEP 440/setuptools 8 fix\n\nChange-Id: If325b220b3eaa546c0339d1152c09b74fa45b9ad\n""}]",0,141612,1f5c9f71f99944ecf6e120efdb677f44fbe3b654,7,3,1,5263,,,0,"Merge tag '0.10.1' into HEAD

Release 0.10.1 for PEP 440/setuptools 8 fix

Change-Id: If325b220b3eaa546c0339d1152c09b74fa45b9ad
",git fetch https://review.opendev.org/openstack/pbr refs/changes/12/141612/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,1f5c9f71f99944ecf6e120efdb677f44fbe3b654,merge/release-tag,,"<<<<<<< HEAD (49ff27 Workflow documentation is now in infra-manual)======= if pre_version: try: return _run_git_command( ['describe', '--exact-match'], git_dir, throw_on_error=True).replace('-', '.') except Exception: sha = _run_git_command( ['log', '-n1', '--pretty=format:%h'], git_dir) return ""%s.dev%s+g%s"" % (pre_version, _get_revno(git_dir), sha) else: return _run_git_command( ['describe', '--always'], git_dir).replace('-', '.').replace('.g', '+g') >>>>>>> BRANCH (1c89d1 Prefix git suffixes with + instead of .)",0,16
openstack%2Fheat~master~I07484d01161ee573dcb1a7908784d5caee9bbe58,openstack/heat,master,I07484d01161ee573dcb1a7908784d5caee9bbe58,Fix suspend/resume error in RemoteStack,MERGED,2014-12-12 12:58:01.000000000,2014-12-14 23:24:53.000000000,2014-12-14 23:24:52.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-12 12:58:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d4a29b9397d7245704fdadc1c3c034649c3c950e', 'message': 'Fix suspend/resume error in RemoteStack\n\nCurrent implementation of suspend and resume are incorrectly\nimplemented.  This patch fixes the calls to heatclient.\n\nCloses-Bug: 1401876\nChange-Id: I07484d01161ee573dcb1a7908784d5caee9bbe58\n'}, {'number': 2, 'created': '2014-12-12 13:08:54.000000000', 'files': ['heat/engine/resources/remote_stack.py', 'heat/tests/test_remote_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ce81186858031ad893d4025c157f04d025c78343', 'message': 'Fix suspend/resume error in RemoteStack\n\nCurrent implementation of suspend and resume are incorrectly\nimplemented. This patch fixes the calls to heatclient.\n\nCloses-Bug: 1401876\nChange-Id: I07484d01161ee573dcb1a7908784d5caee9bbe58\n'}]",2,141358,ce81186858031ad893d4025c157f04d025c78343,12,5,2,8246,,,0,"Fix suspend/resume error in RemoteStack

Current implementation of suspend and resume are incorrectly
implemented. This patch fixes the calls to heatclient.

Closes-Bug: 1401876
Change-Id: I07484d01161ee573dcb1a7908784d5caee9bbe58
",git fetch https://review.opendev.org/openstack/heat refs/changes/58/141358/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/remote_stack.py', 'heat/tests/test_remote_stack.py']",2,d4a29b9397d7245704fdadc1c3c034649c3c950e,bug/1401876, self.heat.actions.resume = mock.MagicMock() self.heat.actions.resume.assert_called_with(stack_id=rsrc.resource_id) self.heat.actions.resume = mock.MagicMock() self.heat.actions.resume.assert_called_with(stack_id=rsrc.resource_id) self.heat.actions.suspend = mock.MagicMock() self.heat.actions.suspend.assert_called_with(stack_id=rsrc.resource_id) self.heat.actions.suspend = mock.MagicMock() # assert suspend was not called self.heat.actions.suspend.assert_has_calls([]) self.heat.actions.suspend = mock.MagicMock() # assert suspend was not called self.heat.actions.suspend.assert_has_calls([]), self.heat.stacks.resume = mock.MagicMock() self.heat.stacks.resume.assert_called_with(stack_id=rsrc.resource_id) self.heat.stacks.resume = mock.MagicMock() self.heat.stacks.resume.assert_called_with(stack_id=rsrc.resource_id) self.heat.stacks.suspend = mock.MagicMock() self.heat.stacks.suspend.assert_called_with(stack_id=rsrc.resource_id) self.heat.stacks.suspend = mock.MagicMock() self.heat.stacks.suspend.assert_called_with(stack_id=rsrc.resource_id),14,10
openstack%2Fheat~master~Ia035083519dad2faa0f3ff6647553508f70a2608,openstack/heat,master,Ia035083519dad2faa0f3ff6647553508f70a2608,Take admin password for server rebuild,MERGED,2014-11-28 08:43:11.000000000,2014-12-14 23:24:01.000000000,2014-12-14 23:23:59.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 7256}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-28 08:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cb6e24fbf44faa59beb5682cd4f437fd155a9fc6', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 2, 'created': '2014-12-02 01:53:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a95744b4c3f273b06409fcdd063e8268ff6321a4', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 3, 'created': '2014-12-04 01:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8a3b9492d372aa68521053798bcfd5cd1fc979f3', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 4, 'created': '2014-12-08 10:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/55292858bda0b41e85db2c0e5ee7a68de1b2b1b6', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 5, 'created': '2014-12-10 03:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/45026cc370f52c61219b8527cb9dcac979afb734', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 6, 'created': '2014-12-11 02:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed8f455fd452256634a629601ac9a2c63807c158', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}, {'number': 7, 'created': '2014-12-12 06:36:52.000000000', 'files': ['heat/engine/resources/server.py', 'heat/engine/clients/os/nova.py', 'heat/tests/test_server.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/80f5193750a869487089c69bd4b85ead3b45205b', 'message': 'Take admin password for server rebuild\n\nTake admin password when rebuild a server.\n\nChange-Id: Ia035083519dad2faa0f3ff6647553508f70a2608\nCloses-Bug: #1397220\n'}]",1,137746,80f5193750a869487089c69bd4b85ead3b45205b,35,10,7,8289,,,0,"Take admin password for server rebuild

Take admin password when rebuild a server.

Change-Id: Ia035083519dad2faa0f3ff6647553508f70a2608
Closes-Bug: #1397220
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/137746/5 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/server.py', 'heat/engine/clients/os/nova.py', 'heat/tests/test_server.py']",3,cb6e24fbf44faa59beb5682cd4f437fd155a9fc6,bug/1397220," def _test_server_update_image_rebuild(self, status, policy='REBUILD', password=None): if password: update_template['Properties']['admin_pass'] = password return_server, 744, password=password, preserve_ephemeral=False) return_server, 744, password=password, preserve_ephemeral=True) def test_server_update_image_rebuild_with_new_password(self): # Normally we will see 'REBUILD' first and then 'ACTIVE"". self._test_server_update_image_rebuild(password='new_admin_password', status=('REBUILD', 'ACTIVE')) "," def _test_server_update_image_rebuild(self, status, policy='REBUILD'): return_server, 744, password=None, preserve_ephemeral=False) return_server, 744, password=None, preserve_ephemeral=True)",25,6
openstack%2Fopenstack-manuals~master~Ic95411e5afa97aaef990fd12dbabc59c88f38183,openstack/openstack-manuals,master,Ic95411e5afa97aaef990fd12dbabc59c88f38183,"Removal of passive voice from chap 1, arch guide",MERGED,2014-12-11 07:18:25.000000000,2014-12-14 22:50:39.000000000,2014-12-14 22:50:38.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 9162}, {'_account_id': 10607}]","[{'number': 1, 'created': '2014-12-11 07:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2a8bf037ce2a370682da7e895d8c40381dfefce8', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 2, 'created': '2014-12-11 22:54:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2c66da0c60d1111d53817bad3e92ed41dd5e5039', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 3, 'created': '2014-12-12 00:18:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/eaf454efbabe1d755cd9d0c2f857ab24be1de77c', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 4, 'created': '2014-12-12 00:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3fcf0f62459d3123f53ff1d1463b5f483dfa0b86', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 5, 'created': '2014-12-12 00:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9e9074cfec839167469ec8a9ceac6d18a8fb2400', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 6, 'created': '2014-12-14 03:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/73b43d89f67821829b15daf6177d94d0cf5fde25', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 7, 'created': '2014-12-14 08:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/c42a013d2a414479889ad1e05db541c806960649', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 8, 'created': '2014-12-14 20:56:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/733d4d823fd02916a35758ba81a081a95ddd5d66', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}, {'number': 9, 'created': '2014-12-14 21:01:11.000000000', 'files': ['doc/arch-design/generalpurpose/section_architecture_general_purpose.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b02d4f1fd0e01e1333488a3969a5058b8992eedc', 'message': 'Removal of passive voice from chap 1, arch guide\n\nRemoval of passive voice from section_architecture\n\nChange-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183\nPartial-bug: #1400550\n'}]",28,140945,b02d4f1fd0e01e1333488a3969a5058b8992eedc,30,4,9,10607,,,0,"Removal of passive voice from chap 1, arch guide

Removal of passive voice from section_architecture

Change-Id: Ic95411e5afa97aaef990fd12dbabc59c88f38183
Partial-bug: #1400550
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/45/140945/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/generalpurpose/section_architecture_general_purpose.xml'],1,2a8bf037ce2a370682da7e895d8c40381dfefce8,asettle/bug1400550," <para>Selecting hardware for a general purpose OpenStack cloud should reflect a cloud with no pre-defined usage model. General purpose clouds are designed to run a wide variety of applications with varying resource usage requirements. These applications include any of the following:</para> <itemizedlist> <listitem> <para> RAM-intensive </para> </listitem> <listitem> <para> CPU-intensive </para> </listitem> <listitem> <para> Storage-intensive </para> </listitem> </itemizedlist> <para>Choosing hardware for a general purpose OpenStack cloud must provide balanced access to all major resources.</para> <para>Certain hardware form factors may better suit a general purpose OpenStack cloud due to the requirement for equal (or nearly equal) balance of resources. Server hardware must provide the following:</para> <itemizedlist> <listitem> <para> Equal (or nearly equal) balance of compute capacity (RAM and CPU) </para> </listitem> <listitem> <para> Network capacity (number and speed of links) </para> </listitem> <listitem> <para> Storage capacity (gigabytes or terabytes as well as Input/Output Operations Per Second (<glossterm>IOPS</glossterm>) </para> </listitem> <listitem> <para> </para> </listitem> </itemizedlist> dimensions.</para><!--This is a list and I don't know why this is a list, what is this list referring to? Above? --> <para>The best form factor for server hardware must flow from user requirements, technical hardware:</para> <para>The selection of form factors or architectures affects the selection of server hardware. For example, if the design is a scale-out storage architecture, then the server hardware selection will require careful consideration when matching the requirements set to the commerical solution.</para> <para>Ensure that the selected server hardware architecture.</para> <para>Storage hardware architecture is largely determined by the selected storage architecture. The selection of storage architecture, as well as the corresponding storage hardware, is determined by evaluating possible solutions against the critical factors, the user requirements, technical considerations, and operational considerations. Factors that need to be overall system cost. For an organization that is concerned advisable, although it comes with a higher price <para>Scalability, along with expandability, is a major may be difficult to predict the final intended size of the implementation as there are no established usage patterns for a general purpose cloud. It may become necessary to expand the initial deployment in order to accommodate growth and user demand.</para> <para>Expandability is a major architecture factor for cloud. This metric is related to, but different, from scalability, which is a measure of the solution's performance as it expands. For example, the storage architecture for a cloud that is intended for a development platform may not have the same expandability and scalability purpose OpenStack cloud. For example, it is possible to populate storage in either the compute hosts similar to a grid computing solution, or into hosts dedicated to providing block storage exclusively. When deploying storage in the compute hosts appropriate hardware, that can support both the storage and compute services on the same hardware, will be required.</para> determine what scale-out solution should be used. Determining if a single, highly expandable and highly vertical, scalable, centralized storage array should be included in the design. Once an approach has been determined, the storage hardware needs to be selected based on this criteria.</para> the appropriate hardware has been selected. OpenStack Object Storage will use it for object storage.</para> the architecture. storage architecture that includes DAS, it <para>General purpose OpenStack cloud has multiple options. The key factors that will have an influence <para>Hardware resources selected for the resource nodes should be capable of supporting ample storage for the cloud services. Defining the initial requirements and ensuring the design can support adding capacity is important. Hardware nodes selected for object storage should be capable of support a large number of inexpensive disks with no reliance on RAID controller cards. Hardware nodes selected for block storage should be capable of supporting high speed storage solutions and RAID controller cards to provide performance and redundancy to storage at a hardware level. Selecting hardware RAID controllers that automatically repair damaged arrays will assist with the replacement and repair of degraded or destroyed storage devices.</para> <para>Disks selected for object storage services do not need to be fast performing disks. We recommend that object storage nodes take advantage of the best cost per terabyte available for storage. Contrastingly, disks chosen for block storage sevices should take advantage of performance boosting features that may entail the use of SSDs or flash storage to provide high performance block storage pools. Storage performance of ephemeral disks used for instances should also be taken into consideration. If compute pools are expected to have a high utilization of ephemeral storage, or requires very high performance, it would be advantageous to deploy similar hardware solutions to block storage.</para> <para>Selecting network architecture determines which network hardware will be used. Networking software is determined by the selected networking hardware. For example, selecting networking hardware that only supports Gigabit Ethernet (GbE) will impact the overall design. Similarly, deciding to use 10 Gigabit Ethernet (10 GbE) will have a number of impacts on various areas of the overall design.</para> <para>There are more subtle design impacts that need to be considered. The selection of certain networking hardware (and the networking software) affects the management tools that can be used. There are requisite port count. A higher port density is preferred, as it leaves more rack space for compute or storage components that may be required by the design. This can also lead into network speed, for example: 1 GbE, 10 GbE, or 40 GbE (or even 100 GbE). the hardware will need to support this configuration.</para> <para>Ensure that the physical data network hardware.</para> <note> <para> This may be an issue for spine switches in a leaf and spine fabric, or end of row (EoR) switches. </para> </note> require network connectivity. In some <para>The network design should solution within the network architecture to <para>Selecting an operating system (OS) and hypervisor have a significant impact on the overall design. Selecting a particular operating system and hypervisor can directly affect server hardware selection, and topology, support the selected operating system and hypervisor combination. Also ensuring that the networking hardware selection and topology will work with the chosen operating system and hypervisor combination. For example, if the design uses Link Aggregation cost due to support contracts. Business or application requirements may dictate a specific or commercially supported hypervisor.</para> hypervisor, staff should have the appropriate <para>Ensure that the design can accommodate regular periodic installations of application security patches while maintaining required workloads. The <para>Determine which features of OpenStack are required. This impacts the selection of the OS-hypervisor combination. Certain features are only available with specific OSs or <para>The ability for the selected OS-hypervisor combination to interoperate with other OS-hyervisors, including other software solutions, should be taken into consideration. Operational troubleshooting tools for one OS-hypervisor combination may differ from the tools used for another OS-hypervisor <para>Selecting which OpenStack components are included in the overall design have a significant impact. Certain components will be consistent throughout each design (Compute, Image Service, for example), there are services that may not be required (Orchestration).</para> <para>Excluding certain OpenStack components can limit or constrain the functionality of other components. For example, if the architecture includes Orchestration but excludes Telemetry, then the design will not be able to take advantage of Orchestrations' auto scaling functionality. It is important to research the component interdependencies in conjunction with the technicalrequirements before deciding on the final architecture.</para> <section xml:id=""supplemental-components""> <!--This feels like it requires more content, otherwise it seems fairly invalid --> software packages that can be useful when managing OpenStack components. Some examples include:</para> <itemizedlist> <listitem> <para> Software to provide load balancing </para> </listitem> <listitem> <para> Network redundancy protocols </para> </listitem> <listitem> <para> Routing daemons </para> </listitem> </itemizedlist> <para>Some of these software packages are described infrastructure components need to be highly available. If <para>Selected supplemental software solution impacts and requirements. The impact of including (or not sub-categories includes a number of various options. Logs are best stored in a centralized location to ease of use when performing analytics against the data. Log data analytics engines can also provide automation and issue notification by providing a mechanism to <para>If these software packages are required, the (CPU, RAM, storage, and network bandwidth). Some other potential <para>OpenStack components often require access information. Selecting an appropriate back-end database that satisfies the availability and fault tolerance services supports connecting to a database that is supported recommend that the database, which provides back-end service within a general purpose cloud, be made highly accomplish that goal.</para> Compute-focused workloads are higher demanding on CPU and memory resources with lower priority given to storage and network performance. object or block storage services. For guidance on designing for this","%openstack; <para>For each of these areas, the selection of hardware for a general purpose OpenStack cloud must reflect the fact that a the cloud has no pre-defined usage model. This means that there will be a wide variety of applications running on this cloud that will have varying resource usage requirements. Some applications will be RAM-intensive, some applications will be CPU-intensive, while others will be storage-intensive. Therefore, choosing hardware for a general purpose OpenStack cloud must provide balanced access to all major resources.</para> <para>Certain hardware form factors may be better suited for use in a general purpose OpenStack cloud because of the need for an equal or nearly equal balance of resources. Server hardware for a general purpose OpenStack architecture design must provide an equal or nearly equal balance of compute capacity (RAM and CPU), network capacity (number and speed of links), and storage capacity (gigabytes or terabytes as well as Input/Output Operations Per Second (<glossterm>IOPS</glossterm>).</para> dimensions: </para> <para>Given the wide selection of hardware and general user requirements, the best form factor for the server hardware must flow out of the user requirements, technical hardware: </para> <para>The selection of certain form factors or architectures will affect the selection of server hardware. For example, if the design calls for a scale-out storage architecture (such as leveraging Ceph, Gluster, or a similar commercial solution), then the server hardware selection will need to be carefully considered to match the requirements set by the commercial solution. Ensure that the selected server hardware architecture. This is especially true if the architecture uses InfiniBand or another less commonly used networking protocol.</para> <para>The selection of storage hardware is largely determined by the proposed storage architecture. Factors that need to be overall system cost that should be factored into the design decision. For an organization that is concerned advisable, although it is comes with a higher price <term>Performance</term> <listitem> <para>Storage performance, measured by observing the latency of storage I-O requests, is not a critical factor for a general purpose OpenStack cloud as overall systems performance is not a design priority.</para> </listitem> </varlistentry> <varlistentry> <para>The term ""scalability"" refers to how well the storage solution performs as it expands up to its maximum designed size. A solution that continues to perform well at maximum expansion is considered scalable. A storage solution that performs well in small configurations but has degrading performance as it expands was not designed to be not scalable. Scalability, along with expandability, is a major might be difficult to predict the final intended size of the implementation because there are no established usage patterns for a general purpose cloud. Therefore, it may become necessary to expand the initial deployment in order to accommodate growth and user demand. The ability of the storage solution to continue to perform well as it expands is important.</para> <para>This refers to the overall ability of the solution to grow. A storage solution that expands to 50&nbsp;PB is considered more expandable than a solution that only scales to 10&nbsp;PB. This metric is related to, but different, from scalability, which is a measure of the solution's performance as it expands. Expandability is a major architecture factor for cloud. For example, the storage architecture for a cloud that is intended for a development platform may not have the same expandability and scalability <para>Storage hardware architecture is largely determined by the selected storage architecture. The selection of storage architecture, as well as the corresponding storage hardware, is determined by evaluating possible solutions against the critical factors, the user requirements, technical considerations, and operational considerations. A combination of all the factors and considerations will determine which approach will be best.</para> purpose OpenStack cloud. In this scenario, it is possible to populate storage in either the compute hosts similar to a grid computing solution or into hosts dedicated to providing block storage exclusively. When deploying storage in the compute hosts, appropriate hardware which can support both the storage and compute services on the same hardware will be required. This approach is referred to as a grid computing architecture because there is a grid of modules that have both compute and storage in a single box.</para> determine if Ceph, Gluster, or a similar scale-out solution should be used. It can then be further determined if a single, highly expandable and highly vertical, scalable, centralized storage array should be included in the design. Once the approach has been determined, the storage hardware needs to be chosen based on this criteria. If a centralized storage array fits the requirements best, then the array vendor will determine the hardware. For cost reasons it may be decided to build an open source storage array using solutions such as OpenFiler, Nexenta Open Source, or BackBlaze Open Source.</para> the appropriate hardware has been selected. Some examples include InfiniBand, FDDI and Fibre Channel. OpenStack Object Storage will use it for object storage. All of these usage models are affected by the selection of particular storage architecture and the corresponding storage hardware to support that architecture.</para> the architecture. For example, instances can be stored in a number of options. OpenStack Block Storage is a good location for instances because it is persistent block storage, however, OpenStack Object Storage can be used if storage latency is less of a concern. The same argument applies to the appropriate image storage location. storage architecture that includes DAS, naturally that <para>General purpose OpenStack cloud has multiple options. As a result, there is no single decision that will apply to all implementations. The key factors that will have an influence <para>Hardware resources selected for the resource nodes should be capable of supporting enough storage for the cloud services that will use them. It is important to clearly define the initial requirements and ensure that the design can support adding capacity as resources are used in the cloud, as workloads are relatively unknown. Hardware nodes selected for object storage should be capable of supporting a large number of inexpensive disks and should not have any reliance on RAID controller cards. Hardware nodes selected for block storage should be capable of supporting higher speed storage solutions and RAID controller cards to provide performance and redundancy to storage at the hardware level. Selecting hardware RAID controllers that can automatically repair damaged arrays will further assist with replacing and repairing degraded or destroyed storage devices within the cloud.</para> <para>Disks selected for the object storage service do not need to be fast performing disks. We recommend that object storage nodes take advantage of the best cost per terabyte available for storage at the time of acquisition and avoid enterprise class drives. In contrast, disks chosen for the block storage service should take advantage of performance boosting features and may entail the use of SSDs or flash storage to provide for high performing block storage pools. Storage performance of ephemeral disks used for instances should also be taken into consideration. If compute pools are expected to have a high utilization of ephemeral storage or requires very high performance, it would be advantageous to deploy similar hardware solutions to block storage in order to increase the storage performance.</para> <para>As is the case with storage architecture, selecting a network architecture often determines which network hardware will be used. The networking software in use is determined by the selected networking hardware. Some design impacts are obvious, for example, selecting networking hardware that only supports Gigabit Ethernet (GbE) will naturally have an impact on many different areas of the overall design. Similarly, deciding to use 10 Gigabit Ethernet (10&nbsp;GbE) has a number of impacts on various areas of the overall design.</para> <para>As an example, selecting Cisco networking hardware implies that the architecture will be using Cisco networking software like IOS or NX-OS. Conversely, selecting Arista networking hardware means the network devices will use the Arista networking software called Extensible Operating System (EOS). In addition, there are more subtle design impacts that need to be considered. The selection of certain networking hardware (and therefore the networking software) could affect the management tools that can be used. There are requisite port count. A switch that can provide 48 10&nbsp;GbE ports in 1U has a much higher port density than a switch that provides 24 10&nbsp;GbE ports in 2U. A higher port density is preferred, as it leaves more rack space for compute or storage components that may be required by the design. This can also lead into network speed, for example: 1&nbsp;GbE, 10&nbsp;GbE, or 40&nbsp;GbE (or even 100&nbsp;GbE). the hardware will need to support this configuration. User requirements will determine if a completely redundant network infrastructure is required.</para> <para>Make sure that the physical data network hardware. This is not an issue for top of rack (ToR) switches, but may be an issue for spine switches in a leaf and spine fabric, or end of row (EoR) switches.</para> require some form of network connectivity. In some <para>The chosen network design should solutions within the network architecture to <para> The selection of operating system (OS) and hypervisor has a tremendous impact on the overall design. Selecting a particular operating system and hypervisor can also directly affect server hardware selection and topology support the selected operating system and hypervisor combination. Finally, it is important to ensure that the networking hardware selection and topology will work with the chosen operating system and hypervisor combination. For example, if the design uses Link Aggregation cost due to support contracts. On the other hand, business or application requirements may dictate a specific or commercially supported hypervisor.</para> hypervisor, the staff should have the appropriate <para>Ensure that the design can accommodate the regular periodic installation of application security patches while maintaining the required workloads. The <para>Determine which features of OpenStack are required. This will often determine the selection of the OS-hypervisor combination. Certain features are only available with specific OSs or <para>Consideration should be given to the ability of the selected OS-hypervisor combination to interoperate or co-exist with other OS-hypervisors as well as other software solutions in the overall design (if required). Operational troubleshooting tools for one OS-hypervisor combination may differ from the tools used for another OS-hypervisor <para>The selection of which OpenStack components are included has a significant impact on the overall design. While there are certain components that will always be present, (Compute and Image Service, for example) there are other services that may not be required. As an example, a certain design might not need <glossterm>Orchestration</glossterm>. Omitting Orchestration would not have a significant impact on the overall design of a cloud; however, if the architecture uses a replacement for OpenStack Object Storage for its storage component, it could potentially have significant impacts on the rest of the design.</para> <para>The exclusion of certain OpenStack components might also limit or constrain the functionality of other components. If the architecture includes Orchestration but excludes Telemetry, then the design will not be able to take advantage of Orchestrations' auto scaling functionality (which relies on information from Telemetry). It is important to research the component interdependencies in conjunction with the technical requirements before deciding what components need to be included and what components can be dropped from the final architecture.</para> <section xml:id=""supplemental-components""> software packages that might be useful to manage the OpenStack components themselves. Some examples include software to provide load balancing, network redundancy protocols, and routing daemons. Some of these software packages are described infrastructure components will need to be highly available. If <para>The selected supplemental software solution impacts and requirements. Therefore, the impact of including (or not sub-categories includes a number of various options. For example, in the logging sub-category one might consider Logstash, Splunk, instanceware Log Insight, or some other log aggregation-consolidation tool. Logs should be stored in a centralized location to make it easier to perform analytics against the data. Log data analytics engines can also provide automation and issue notification by providing a mechanism to <para>If any of these software packages are required, then the (CPU, RAM, storage, and network bandwidth for a log aggregation solution, for example). Some other potential <para>A large majority of the OpenStack components require access information. Selection of an appropriate back-end database that will satisfy the availability and fault tolerance services supports connecting to any database that is supported recommend that the database which provides back-end service within a general purpose cloud be made highly accomplish that goal. Some of the more common software solutions used include Galera, MariaDB and MySQL with multi-master replication.</para> Compute-focused workloads are generally those that would place a higher demand on CPU and memory resources with lower priority given to storage and network performance, other than what is required to support the intended compute workloads. object or block storage services that require specialized consideration and planning. For guidance on designing for this",228,274
openstack%2Fpython-heatclient~master~Ic44073880b7e65b6530a7314a5a2d65eb4aadb09,openstack/python-heatclient,master,Ic44073880b7e65b6530a7314a5a2d65eb4aadb09,Add transtlation markers for error messages,MERGED,2014-12-01 17:01:51.000000000,2014-12-14 22:48:28.000000000,2014-12-14 22:48:28.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-01 17:01:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/69db76dce34dc52eac19c10dbea8b6d2cf2f8516', 'message': 'Add transtlation markers for error messages\n\nChange-Id: Ic44073880b7e65b6530a7314a5a2d65eb4aadb09\nPartial-Bug: #1269930\n'}, {'number': 2, 'created': '2014-12-03 10:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dbe234a3c04e622e90df65e1a8b0c2aeb02ce780', 'message': 'Add transtlation markers for error messages\n\nChange-Id: Ic44073880b7e65b6530a7314a5a2d65eb4aadb09\nPartial-Bug: #1269930\n'}, {'number': 3, 'created': '2014-12-03 14:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/a354cca66ed2239efd7ee81fb428cef15949d8e8', 'message': 'Add transtlation markers for error messages\n\nChange-Id: Ic44073880b7e65b6530a7314a5a2d65eb4aadb09\nPartial-Bug: #1269930\n'}, {'number': 4, 'created': '2014-12-10 10:32:21.000000000', 'files': ['heatclient/common/http.py', 'heatclient/openstack/common/apiclient/exceptions.py', 'heatclient/common/environment_format.py', 'heatclient/exc.py', 'heatclient/shell.py', 'heatclient/common/template_utils.py', 'heatclient/common/utils.py', 'heatclient/v1/shell.py', 'heatclient/common/template_format.py', 'heatclient/openstack/common/apiclient/fake_client.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6ff27ccabf0580d57f48e607b21535f5475ff3fe', 'message': 'Add transtlation markers for error messages\n\nChange-Id: Ic44073880b7e65b6530a7314a5a2d65eb4aadb09\nPartial-Bug: #1269930\n'}]",0,138123,6ff27ccabf0580d57f48e607b21535f5475ff3fe,16,4,4,13323,,,0,"Add transtlation markers for error messages

Change-Id: Ic44073880b7e65b6530a7314a5a2d65eb4aadb09
Partial-Bug: #1269930
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/23/138123/4 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/openstack/common/cliutils.py', 'heatclient/common/http.py', 'heatclient/openstack/common/apiclient/client.py', 'heatclient/common/environment_format.py', 'heatclient/common/template_utils.py', 'heatclient/common/utils.py', 'heatclient/openstack/common/apiclient/base.py', 'heatclient/v1/shell.py', 'heatclient/openstack/common/apiclient/fake_client.py', 'heatclient/openstack/common/apiclient/exceptions.py', 'heatclient/exc.py', 'heatclient/openstack/common/importutils.py', 'heatclient/shell.py', 'heatclient/common/template_format.py', 'heatclient/openstack/common/strutils.py']",15,69db76dce34dc52eac19c10dbea8b6d2cf2f8516,bug/1269930,"from heatclient.i18n import _ raise TypeError(_(""%s can't be decoded"") % type(text)) raise TypeError(_(""%s can't be encoded"") % type(text))","from heatclient.openstack.common.gettextutils import _ raise TypeError(""%s can't be decoded"" % type(text)) raise TypeError(""%s can't be encoded"" % type(text))",165,130
openstack%2Ftraining-guides~master~I0f99ed49f11bf2231b1e33d5a2af7408aa8389c7,openstack/training-guides,master,I0f99ed49f11bf2231b1e33d5a2af7408aa8389c7,Imported Translations from Transifex,MERGED,2014-12-14 06:00:17.000000000,2014-12-14 22:48:14.000000000,2014-12-14 22:48:14.000000000,"[{'_account_id': 3}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-12-14 06:00:17.000000000', 'files': ['doc/training-guides/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/90cf4fd0ea25649c062e739caf49b4d1c5e3a583', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I0f99ed49f11bf2231b1e33d5a2af7408aa8389c7\n'}]",0,141623,90cf4fd0ea25649c062e739caf49b4d1c5e3a583,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I0f99ed49f11bf2231b1e33d5a2af7408aa8389c7
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/23/141623/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/locale/ja.po'],1,90cf4fd0ea25649c062e739caf49b4d1c5e3a583,transifex/translations,"""POT-Creation-Date: 2014-12-08 10:05+0000\n"" ""PO-Revision-Date: 2014-12-13 11:10+0000\n""msgstr ""ブリッジ/NAT -- DHCP -- これらのスクリプトは、Pre-Install.sh 実行後にインターネット接続なしで実行すべきです。Templates/* は、カスタムネットワーク向けに必要な IP アドレスに変更すべきです。""msgstr ""テスト環境やサンドボックスのために VirtualBox に OpenStack を導入する場合、または、一般的なハードウェアで OpenStack を単に試したい場合、以下の方法が慣習となっています。""msgstr ""第 2 世代 Core i5/i7 プロセッサーを使用している場合、VMware により提供される仮想マシン内で VT 技術を利用できます。お使いの OpenStack ノード (実際は仮想マシン) が、KVM-OK になることを意味します。以降の設定は、UI とその他少しの違いを除き、同じになります。""msgstr ""ホストオンリーネットワークの追加オプションが右側にあります。""msgstr ""VirtualBox の仮想マシンにインストールされたオペレーティングシステム。この仮想マシンはホスト OS と独立しています。一般的に<glossterm baseform=\""guest OS\"">ゲスト OS</glossterm> やゲストと呼ばれます。""msgstr ""この文脈では、とくにサーバーを指します。各 OpenStack サーバーはノードです。""","""POT-Creation-Date: 2014-12-07 18:31+0000\n"" ""PO-Revision-Date: 2014-12-08 01:01+0000\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",8,8
openstack%2Ftraining-guides~master~I4a689f8e906a3a3a26863f00f741c1dab7c3d849,openstack/training-guides,master,I4a689f8e906a3a3a26863f00f741c1dab7c3d849,Updated from openstack-manuals,MERGED,2014-12-11 20:55:59.000000000,2014-12-14 22:48:07.000000000,2014-12-14 22:48:07.000000000,"[{'_account_id': 3}, {'_account_id': 11889}]","[{'number': 1, 'created': '2014-12-11 20:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/731ebd145d971a03399ad6ee5a3adda3b23fe134', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4a689f8e906a3a3a26863f00f741c1dab7c3d849\n'}, {'number': 2, 'created': '2014-12-12 08:09:58.000000000', 'files': ['doc/glossary/locale/ja.po', 'doc/training-guides/openstack.ent'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/1f06a6b6bc0e6a0f48058d18490c18bcc95075b7', 'message': 'Updated from openstack-manuals\n\nChange-Id: I4a689f8e906a3a3a26863f00f741c1dab7c3d849\n'}]",0,141160,1f06a6b6bc0e6a0f48058d18490c18bcc95075b7,10,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: I4a689f8e906a3a3a26863f00f741c1dab7c3d849
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/60/141160/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/training-guides/openstack.ent'],1,731ebd145d971a03399ad6ee5a3adda3b23fe134,openstack/openstack-manuals,"<!-- Useful for describing APIs in the User Guide --> <!ENTITY COPY '<command xmlns=""http://docbook.org/ns/docbook"">COPY</command>'> <!ENTITY GET '<command xmlns=""http://docbook.org/ns/docbook"">GET</command>'> <!ENTITY HEAD '<command xmlns=""http://docbook.org/ns/docbook"">HEAD</command>'> <!ENTITY PUT '<command xmlns=""http://docbook.org/ns/docbook"">PUT</command>'> <!ENTITY POST '<command xmlns=""http://docbook.org/ns/docbook"">POST</command>'> <!ENTITY DELETE '<command xmlns=""http://docbook.org/ns/docbook"">DELETE</command>'> ",,8,0
openstack%2Fpython-heatclient~master~I20a487952b8c4e4cc74a69e731e84672daff22e4,openstack/python-heatclient,master,I20a487952b8c4e4cc74a69e731e84672daff22e4,Add transtlation markers for help messages,MERGED,2014-12-01 14:49:12.000000000,2014-12-14 22:42:24.000000000,2014-12-14 22:42:24.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 12606}]","[{'number': 1, 'created': '2014-12-01 14:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/655c6b981a85bf64a9cdf9ca0c3b158fd2a55b7f', 'message': 'Add transtlation markers for help messages\n\nChange-Id: I20a487952b8c4e4cc74a69e731e84672daff22e4\nPartial-Bug: #1269930\n'}, {'number': 2, 'created': '2014-12-03 10:55:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/6748ef44b3668ebe1bdec767fcc8c88327dca4a5', 'message': 'Add transtlation markers for help messages\n\nChange-Id: I20a487952b8c4e4cc74a69e731e84672daff22e4\nPartial-Bug: #1269930\n'}, {'number': 3, 'created': '2014-12-03 14:17:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/0f6a44894dce3b681c018f45017b6cac33d37170', 'message': 'Add transtlation markers for help messages\n\nChange-Id: I20a487952b8c4e4cc74a69e731e84672daff22e4\nPartial-Bug: #1269930\n'}, {'number': 4, 'created': '2014-12-10 10:32:21.000000000', 'files': ['heatclient/shell.py', 'heatclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/4916c64f7fc126cbcce05055569d4ff7efb37e3a', 'message': 'Add transtlation markers for help messages\n\nChange-Id: I20a487952b8c4e4cc74a69e731e84672daff22e4\nPartial-Bug: #1269930\n'}]",0,138081,4916c64f7fc126cbcce05055569d4ff7efb37e3a,16,4,4,13323,,,0,"Add transtlation markers for help messages

Change-Id: I20a487952b8c4e4cc74a69e731e84672daff22e4
Partial-Bug: #1269930
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/81/138081/1 && git format-patch -1 --stdout FETCH_HEAD,"['heatclient/shell.py', 'heatclient/v1/shell.py']",2,655c6b981a85bf64a9cdf9ca0c3b158fd2a55b7f,bug/1269930,"from heatclient.i18n import _ help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL of template.')) help=_('URL to retrieve template object (e.g. from swift).')) help=_('Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.')) help=_('Stack creation timeout in minutes.')) help=_('Enable rollback on create/update failure.')) help=_('Parameter values used to create the stack. ' 'separated by a semicolon.'), help=_('Name of the stack to create.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL of template.')) help=_('URL to retrieve template object (e.g. from swift).')) help=_('Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.')) help=_('Stack creation timeout in minutes.')) help=_('Enable rollback on create/update failure.')) help=_('Parameter values used to create the stack. ' 'separated by a semicolon.'), help=_('Name of the stack to create.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.')) help=_('Stack creation timeout in minutes.')) help=_('Path to adopt stack data file.')) help=_('Enable rollback on create/update failure.')) help=_('Parameter values used to create the stack. ' 'separated by a semicolon.'), help=_('Name of the stack to adopt.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL of template.')) help=_('URL to retrieve template object (e.g. from swift)')) help=_('Stack creation timeout in minutes. This is only used during' 'validation in preview.')) help=_('Enable rollback on failure. This option is not used during' 'preview and exists only for symmetry with stack-create.')) help=_('Parameter values used to preview the stack. ' 'separated by semicolon.'), help=_('Name of the stack to preview.')) help=_('Name or ID of stack(s) to delete.')) help=_('Name or ID of stack(s) to delete.')) help=_('file to output abandon result. ' ' output into <FILE>.')) help=_('Name or ID of stack to abandon.')) help=_('Name or ID of stack to suspend.'))@utils.arg('id', metavar='<NAME or ID>', help=_('Name or ID of stack to resume.')) help=_('Name or ID of stack to check.')) help=_('Name or ID of stack to describe.')) help=_('Name or ID of stack to describe.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL of template.')) help=_('URL to retrieve template object (e.g. from swift).')) help=_('Stack update timeout in minutes.')) help=_('DEPRECATED! Use --rollback argument instead. ' 'of existing stack.')) help=_('Set rollback on update failure. ' 'Default is to use the value of existing stack to be updated.') help=_('Parameter values used to create the stack. ' 'separated by a semicolon.'), help=_('Re-use the set of parameters of the current stack. ' 'the existing values.')) help=_('Remove the parameters from the set of parameters of ' 'current stack for the stack-update. The default value in the ' 'template will be used. This can be specified multiple times.'), help=_('Name or ID of stack to update.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL of template.')) help=_('URL to retrieve template object (e.g. from swift).')) help=_('Stack update timeout in minutes.')) help=_('DEPRECATED! Use --rollback argument instead. ' 'of existing stack.')) help=_('Set rollback on update failure. ' 'Default is to use the value of existing stack to be updated.') help=_('Parameter values used to create the stack. ' 'separated by a semicolon.'), help=_('Re-use the set of parameters of the current stack. ' 'the existing values.')) help=_('Remove the parameters from the set of parameters of ' 'current stack for the stack-update. The default value in the ' 'template will be used. This can be specified multiple times.'), help=_('Name or ID of stack to update.')) help=_('Name or ID of stack to cancel update for.')) help=_('Include soft-deleted stacks in the stack listing.')) help=_('Include nested stacks in the stack listing.')) help=_('Filter parameters to apply on returned stacks. ' 'separated by a semicolon.'), help=_('Limit the number of stacks returned.')) help=_('Only return stacks that appear after the given stack ID.')) help=_('Display stacks from all tenants. Operation only authorized ' 'for users who match the policy in heat\'s policy.json.')) help=_('Display stack owner information. This is automatically ' 'enabled when using --global-tenant.')) help=_('Name or ID of stack to query.')) help=_('Name or ID of stack to query.')) help=_('Name of an output to display.')) help=_('Resource type to get the details for.')) help=_('Resource type to generate a template for.')) help=_(""The template output format, one of: %s."") % ', '.join(utils.supported_formats.keys())) help=_('Name or ID of stack to get the template for.')) help=_('Name or ID of stack to get the template for.')) help=_('URL of template.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL to retrieve template object (e.g. from swift).')) help=_('URL of template.')) help=_('Path to the template.')) help=_('Path to the environment, it can be specified ' 'multiple times.'), help=_('URL to retrieve template object (e.g. from swift).')) help=_('Name or ID of stack to show the resources for.')) help=_('Depth of nested stacks from which to display resources.')) help=_('Name or ID of stack to show the resource for.')) help=_('Name of the resource to show the details for.')) help=_('Name or ID of stack to show the resource for.')) help=_('Name of the resource to show the details for.')) help=_('Resource type to generate a template for.')) help=_(""The template output format, one of: %s."") % ', '.join(utils.supported_formats.keys())) help=_('Name or ID of stack to show the resource metadata for.')) help=_('Name of the resource to show the metadata for.')) help=_('Name or ID of stack the resource belongs to.')) help=_('Name of the resource to signal.')) help=_('JSON Data to send to the signal handler.')) help=_('File containing JSON data to send to the signal handler.')) help=_('Name or ID of stack to show the events for.')) help=_('Name of the resource to filter events by.')) help=_('Filter parameters to apply on returned events. ' 'separated by a semicolon.'), help=_('Limit the number of events returned.')) help=_('Only return events that appear after the given event ID.')) help=_('Name or ID of stack to show the events for.')) help=_('Name of the resource the event belongs to.')) help=_('ID of event to display details for.')) help=_('Name or ID of stack to show the events for.')) help=_('Name of the resource the event belongs to.')) help=_('ID of event to display details for.')) help=_('Name or ID of stack to snapshot.')) help=_('If specified, the name given to the snapshot.')) help=_('Name or ID of the stack containing the snapshot.')) help=_('The ID of the snapshot to show.')) help=_('Name or ID of the stack containing the snapshot.')) help=_('The ID of the snapshot to delete.')) help=_('Name or ID of the stack containing the snapshot.')) help=_('The ID of the snapshot to restore.')) help=_('Name or ID of the stack containing the snapshots.'))"," help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL of template.') help='URL to retrieve template object (e.g. from swift).') help='Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.') help='Stack creation timeout in minutes.') help='Enable rollback on create/update failure.') help='Parameter values used to create the stack. ' 'separated by a semicolon.', help='Name of the stack to create.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL of template.') help='URL to retrieve template object (e.g. from swift).') help='Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.') help='Stack creation timeout in minutes.') help='Enable rollback on create/update failure.') help='Parameter values used to create the stack. ' 'separated by a semicolon.', help='Name of the stack to create.') help='Path to the environment, it can be specified multiple times.', help='Stack creation timeout in minutes.' ' DEPRECATED use --timeout instead.') help='Stack creation timeout in minutes.') help='Path to adopt stack data file.') help='Enable rollback on create/update failure.') help='Parameter values used to create the stack. ' 'separated by a semicolon.', help='Name of the stack to adopt.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL of template.') help='URL to retrieve template object (e.g. from swift)') help='Stack creation timeout in minutes. This is only used during' 'validation in preview.') help='Enable rollback on failure. This option is not used during' 'preview and exists only for symmetry with stack-create.') help='Parameter values used to preview the stack. ' 'separated by semicolon.', help='Name of the stack to preview.') help='Name or ID of stack(s) to delete.') help='Name or ID of stack(s) to delete.') help='file to output abandon result. ' ' output into <FILE>.') help='Name or ID of stack to abandon.') help='Name or ID of stack to suspend.')@utils.arg('id', metavar='<NAME or ID>', help='Name or ID of stack to resume.') help='Name or ID of stack to check.') help='Name or ID of stack to describe.') help='Name or ID of stack to describe.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL of template.') help='URL to retrieve template object (e.g. from swift).') help='Stack update timeout in minutes.') help='DEPRECATED! Use --rollback argument instead. ' 'of existing stack.') help='Set rollback on update failure. ' 'Default is to use the value of existing stack to be updated.' help='Parameter values used to create the stack. ' 'separated by a semicolon.', help='Re-use the set of parameters of the current stack. ' 'the existing values.') help='Remove the parameters from the set of parameters of current ' 'stack for the stack-update. The default value in the template ' 'will be used. This can be specified multiple times.', help='Name or ID of stack to update.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL of template.') help='URL to retrieve template object (e.g. from swift).') help='Stack update timeout in minutes.') help='DEPRECATED! Use --rollback argument instead. ' 'of existing stack.') help='Set rollback on update failure. ' 'Default is to use the value of existing stack to be updated.' help='Parameter values used to create the stack. ' 'separated by a semicolon.', help='Re-use the set of parameters of the current stack. ' 'the existing values.') help='Remove the parameters from the set of parameters of current ' 'stack for the stack-update. The default value in the template ' 'will be used. This can be specified multiple times.', help='Name or ID of stack to update.') help='Name or ID of stack to cancel update for.') help='Include soft-deleted stacks in the stack listing.') help='Include nested stacks in the stack listing.') help='Filter parameters to apply on returned stacks. ' 'separated by a semicolon.', help='Limit the number of stacks returned.') help='Only return stacks that appear after the given stack ID.') help='Display stacks from all tenants. Operation only authorized ' 'for users who match the policy in heat\'s policy.json.') help='Display stack owner information. This is automatically ' 'enabled when using --global-tenant.') help='Name or ID of stack to query.') help='Name or ID of stack to query.') help='Name of an output to display.') help='Resource type to get the details for.') help='Resource type to generate a template for.') help=""The template output format, one of: %s."" % ', '.join(utils.supported_formats.keys())) help='Name or ID of stack to get the template for.') help='Name or ID of stack to get the template for.') help='URL of template.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL to retrieve template object (e.g. from swift).') help='URL of template.') help='Path to the template.') help='Path to the environment, it can be specified multiple times.', help='URL to retrieve template object (e.g. from swift).') help='Name or ID of stack to show the resources for.') help='Depth of nested stacks from which to display resources.') help='Name or ID of stack to show the resource for.') help='Name of the resource to show the details for.') help='Name or ID of stack to show the resource for.') help='Name of the resource to show the details for.') help='Resource type to generate a template for.') help=""The template output format, one of: %s."" % ', '.join(utils.supported_formats.keys())) help='Name or ID of stack to show the resource metadata for.') help='Name of the resource to show the metadata for.') help='Name or ID of stack the resource belongs to.') help='Name of the resource to signal.') help='JSON Data to send to the signal handler.') help='File containing JSON data to send to the signal handler.') help='Name or ID of stack to show the events for.') help='Name of the resource to filter events by.') help='Filter parameters to apply on returned events. ' 'separated by a semicolon.', help='Limit the number of events returned.') help='Only return events that appear after the given event ID.') help='Name or ID of stack to show the events for.') help='Name of the resource the event belongs to.') help='ID of event to display details for.') help='Name or ID of stack to show the events for.') help='Name of the resource the event belongs to.') help='ID of event to display details for.') help='Name or ID of stack to snapshot.') help='If specified, the name given to the snapshot.') help='Name or ID of the stack containing the snapshot.') help='The ID of the snapshot to show.') help='Name or ID of the stack containing the snapshot.') help='The ID of the snapshot to delete.') help='Name or ID of the stack containing the snapshot.') help='The ID of the snapshot to restore.') help='Name or ID of the stack containing the snapshots.')",219,208
openstack%2Fpuppet-tempest~stable%2Fjuno~Iac7c8aa23c97be3857843a17a755cc2e2574952a,openstack/puppet-tempest,stable/juno,Iac7c8aa23c97be3857843a17a755cc2e2574952a,Allow to activate Ceilometer tests,MERGED,2014-12-13 23:46:48.000000000,2014-12-14 22:11:43.000000000,2014-12-14 22:11:43.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 8482}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-13 23:46:48.000000000', 'files': ['manifests/init.pp', 'spec/classes/tempest_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/8631ec5df1c050bc4c3f1cba983e5aadd1c0e4d5', 'message': 'Allow to activate Ceilometer tests\n\nEnable ceilometer parameter to test Telemetry tests in Tempest.\n\nChange-Id: Iac7c8aa23c97be3857843a17a755cc2e2574952a\n(cherry picked from commit beb7add18570713e71e8186403bda44f200d7bcb)\n'}]",0,141587,8631ec5df1c050bc4c3f1cba983e5aadd1c0e4d5,7,6,1,3153,,,0,"Allow to activate Ceilometer tests

Enable ceilometer parameter to test Telemetry tests in Tempest.

Change-Id: Iac7c8aa23c97be3857843a17a755cc2e2574952a
(cherry picked from commit beb7add18570713e71e8186403bda44f200d7bcb)
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/87/141587/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/tempest_spec.rb']",2,8631ec5df1c050bc4c3f1cba983e5aadd1c0e4d5,, should contain_tempest_config('service_available/ceilometer').with(:value => false),,3,0
openstack%2Fmagnum~master~Iee16111fc86aef83603251aedf6d58f6da78fc92,openstack/magnum,master,Iee16111fc86aef83603251aedf6d58f6da78fc92,Migrate to oslo.context,MERGED,2014-12-14 11:08:40.000000000,2014-12-14 21:05:59.000000000,2014-12-14 21:05:58.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-14 11:08:40.000000000', 'files': ['requirements.txt', 'magnum/common/context.py', 'magnum/objects/base.py', 'openstack-common.conf', 'magnum/openstack/common/context.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/92e3ebee208500e4db5c3aebf0d24c8619b6d8a9', 'message': 'Migrate to oslo.context\n\nRemove deprecated oslo incubator code\n\nChange-Id: Iee16111fc86aef83603251aedf6d58f6da78fc92\n'}]",0,141635,92e3ebee208500e4db5c3aebf0d24c8619b6d8a9,7,3,1,7770,,,0,"Migrate to oslo.context

Remove deprecated oslo incubator code

Change-Id: Iee16111fc86aef83603251aedf6d58f6da78fc92
",git fetch https://review.opendev.org/openstack/magnum refs/changes/35/141635/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'magnum/common/context.py', 'magnum/objects/base.py', 'openstack-common.conf', 'magnum/openstack/common/context.py']",5,92e3ebee208500e4db5c3aebf0d24c8619b6d8a9,,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Simple class that stores security context information in the web request. Projects should subclass this class if they wish to enhance the request context or provide additional information in their specific WSGI pipeline. """""" import itertools import uuid def generate_request_id(): return b'req-' + str(uuid.uuid4()).encode('ascii') class RequestContext(object): """"""Helper class to represent useful information about a request context. Stores information about the security context under which the user accesses the system, as well as additional request information. """""" user_idt_format = '{user} {tenant} {domain} {user_domain} {p_domain}' def __init__(self, auth_token=None, user=None, tenant=None, domain=None, user_domain=None, project_domain=None, is_admin=False, read_only=False, show_deleted=False, request_id=None, instance_uuid=None): self.auth_token = auth_token self.user = user self.tenant = tenant self.domain = domain self.user_domain = user_domain self.project_domain = project_domain self.is_admin = is_admin self.read_only = read_only self.show_deleted = show_deleted self.instance_uuid = instance_uuid if not request_id: request_id = generate_request_id() self.request_id = request_id def to_dict(self): user_idt = ( self.user_idt_format.format(user=self.user or '-', tenant=self.tenant or '-', domain=self.domain or '-', user_domain=self.user_domain or '-', p_domain=self.project_domain or '-')) return {'user': self.user, 'tenant': self.tenant, 'domain': self.domain, 'user_domain': self.user_domain, 'project_domain': self.project_domain, 'is_admin': self.is_admin, 'read_only': self.read_only, 'show_deleted': self.show_deleted, 'auth_token': self.auth_token, 'request_id': self.request_id, 'instance_uuid': self.instance_uuid, 'user_identity': user_idt} @classmethod def from_dict(cls, ctx): return cls( auth_token=ctx.get(""auth_token""), user=ctx.get(""user""), tenant=ctx.get(""tenant""), domain=ctx.get(""domain""), user_domain=ctx.get(""user_domain""), project_domain=ctx.get(""project_domain""), is_admin=ctx.get(""is_admin"", False), read_only=ctx.get(""read_only"", False), show_deleted=ctx.get(""show_deleted"", False), request_id=ctx.get(""request_id""), instance_uuid=ctx.get(""instance_uuid"")) def get_admin_context(show_deleted=False): context = RequestContext(None, tenant=None, is_admin=True, show_deleted=show_deleted) return context def get_context_from_function_and_args(function, args, kwargs): """"""Find an arg of type RequestContext and return it. This is useful in a couple of decorators where we don't know much about the function we're wrapping. """""" for arg in itertools.chain(kwargs.values(), args): if isinstance(arg, RequestContext): return arg return None def is_user_context(context): """"""Indicates if the request context is a normal user."""""" if not context or context.is_admin: return False return context.user_id and context.project_id ",3,125
openstack%2Fneutron-vpnaas~master~Ib1039ea1ff9480ca57f9cb0c917469d0d2ad28b8,openstack/neutron-vpnaas,master,Ib1039ea1ff9480ca57f9cb0c917469d0d2ad28b8,tests: initialize admin context after super().setUp call,MERGED,2014-12-12 15:31:16.000000000,2014-12-14 19:22:14.000000000,2014-12-14 19:22:14.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 6951}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 15:31:16.000000000', 'files': ['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpnaas_driver_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/5253ceb9a5e0643c98ac66e9d3fd6368ca035f6c', 'message': 'tests: initialize admin context after super().setUp call\n\nNew policy code requires that CONF is already initialized when policy\nchecks are invoked. It means that no Neutron context objects should be\ncreated before BaseTestCase.setUp() is called that will set\nconfiguration, among other things.\n\nIdeally, we would just make sure that all test cases invoke\nsuper().setUp() as the very first line of any subclass setUp() methods.\nBut since some of test cases require prior setup (like mocking extension\nmanager) before proceeding to base class, we end up with magically\nshuffling context instantiations to occur below super() calls.\n\nChange-Id: Ib1039ea1ff9480ca57f9cb0c917469d0d2ad28b8\nCloses-Bug: #1400301\n'}]",0,141405,5253ceb9a5e0643c98ac66e9d3fd6368ca035f6c,15,5,1,9656,,,0,"tests: initialize admin context after super().setUp call

New policy code requires that CONF is already initialized when policy
checks are invoked. It means that no Neutron context objects should be
created before BaseTestCase.setUp() is called that will set
configuration, among other things.

Ideally, we would just make sure that all test cases invoke
super().setUp() as the very first line of any subclass setUp() methods.
But since some of test cases require prior setup (like mocking extension
manager) before proceeding to base class, we end up with magically
shuffling context instantiations to occur below super() calls.

Change-Id: Ib1039ea1ff9480ca57f9cb0c917469d0d2ad28b8
Closes-Bug: #1400301
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/05/141405/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_vpnaas/tests.skip/unit/services/vpn/test_vpnaas_driver_plugin.py'],1,5253ceb9a5e0643c98ac66e9d3fd6368ca035f6c,bug/1400301, self.adminContext = context.get_admin_context(), self.adminContext = context.get_admin_context(),1,1
openstack-attic%2Fnetconn-api~master~Ie9bcba99d1f217fb56dd9156c5012cfbe7a646a2,openstack-attic/netconn-api,master,Ie9bcba99d1f217fb56dd9156c5012cfbe7a646a2,Indicates frozen nature in README,MERGED,2014-12-11 23:25:04.000000000,2014-12-14 17:55:02.000000000,2014-12-14 17:55:01.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 10705}]","[{'number': 1, 'created': '2014-12-11 23:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/4691ae5b1abd8431665e1cd08f6acb8c92e8932b', 'message': 'Indicates frozen nature in README\n\nChange-Id: Ie9bcba99d1f217fb56dd9156c5012cfbe7a646a2\n'}, {'number': 2, 'created': '2014-12-12 18:14:29.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/0c620bccc3254bc7d18db34d4e1c21d1fa1d0ada', 'message': 'Indicates frozen nature in README\n\nChange-Id: Ie9bcba99d1f217fb56dd9156c5012cfbe7a646a2\n'}]",0,141212,0c620bccc3254bc7d18db34d4e1c21d1fa1d0ada,10,4,2,964,,,0,"Indicates frozen nature in README

Change-Id: Ie9bcba99d1f217fb56dd9156c5012cfbe7a646a2
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/12/141212/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4691ae5b1abd8431665e1cd08f6acb8c92e8932b,freeze,This repository is now frozen-in-time and will not accept new patches. It was the original holder for API information for the OpenStack Network,This repository contains the RESTful API information for the OpenStack Network,3,1
openstack%2Fneutron~master~I12825bc071033109bdcb93c89daa32012a8babb6,openstack/neutron,master,I12825bc071033109bdcb93c89daa32012a8babb6,Do not restart vpn processes for every router update,ABANDONED,2014-11-24 18:44:31.000000000,2014-12-14 17:24:57.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1206}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 6659}, {'_account_id': 6788}, {'_account_id': 7141}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10294}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-11-24 18:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ecd58bb33eac02008f19638aa09642136efb808', 'message': 'Do not restart vpn processes for every router update\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n'}, {'number': 2, 'created': '2014-11-27 12:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/704a5dbae364625a416a3388057c652fbd9457ff', 'message': 'Do not restart vpn processes for every router update\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n'}, {'number': 3, 'created': '2014-11-27 12:37:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b8f008380616b86dcfc4fe77238fe3eaf836196d', 'message': 'Do not restart vpn processes for every router update\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n'}, {'number': 4, 'created': '2014-12-02 14:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6668b7fea6ed827feba36ee5b0e4dca38c64d2b2', 'message': 'Do not restart vpn processes for every router update\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n'}, {'number': 5, 'created': '2014-12-03 17:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a2df54f9e783b89675a1aeddd6ed4cbc818a600', 'message': 'Do not restart vpn processes for every router update\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n'}, {'number': 6, 'created': '2014-12-05 02:28:28.000000000', 'files': ['neutron/services/vpn/device_drivers/ipsec.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/07d1c80ff4e07a72490c1cdc1b005c0d68d9635d', 'message': ""Do not restart vpn processes for every router update\n\nPresently all the vpn processes are restarted when any\nrouter is updated, even if the updated router do not\nhost any vpn services. 'device_drivers.ipsec.sync()'\nupdates all the vpn services which results in stopping\nand then starting of the vpn processes.\n\nThis patch addresses the issue by\n1. Passing router id information to the vpnservice_updated\n2. (Re)starting the vpn process only if the\n      - the vpn service is newly added or\n      - the agent has been restarted before the sync or\n      - the sync has the router id of the vpn service\n\nChange-Id: I12825bc071033109bdcb93c89daa32012a8babb6\nCloses-bug: #1393589\n""}]",27,136858,07d1c80ff4e07a72490c1cdc1b005c0d68d9635d,120,27,6,10237,,,0,"Do not restart vpn processes for every router update

Presently all the vpn processes are restarted when any
router is updated, even if the updated router do not
host any vpn services. 'device_drivers.ipsec.sync()'
updates all the vpn services which results in stopping
and then starting of the vpn processes.

This patch addresses the issue by
1. Passing router id information to the vpnservice_updated
2. (Re)starting the vpn process only if the
      - the vpn service is newly added or
      - the agent has been restarted before the sync or
      - the sync has the router id of the vpn service

Change-Id: I12825bc071033109bdcb93c89daa32012a8babb6
Closes-bug: #1393589
",git fetch https://review.opendev.org/openstack/neutron refs/changes/58/136858/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/vpn/device_drivers/ipsec.py', 'neutron/tests/unit/services/vpn/service_drivers/test_cisco_ipsec.py', 'neutron/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron/services/vpn/service_drivers/__init__.py', 'neutron/tests/unit/services/vpn/service_drivers/test_ipsec.py']",5,9ecd58bb33eac02008f19638aa09642136efb808,bug/1393589," self.service_plugin = mock.Mock() self.service_plugin.get_l3_agents_hosting_routers.return_value = ( [l3_agent]) self.service_plugin._get_vpnservice.return_value = { self.driver = ipsec_driver.IPsecVPNDriver(self.service_plugin) def _test_update(self, func, args, additional_info=None): rpc_mock.assert_called_once_with(ctxt, 'vpnservice_updated', **additional_info) fake_vpn_conn = FAKE_VPN_CONNECTION fake_vpnservice = self.service_plugin._get_vpnservice( mock.ANY, fake_vpn_conn['vpnservice_id']) [fake_vpn_conn], {'routers': [{'id': fake_vpnservice['router_id']}]}) fake_vpn_conn = FAKE_VPN_CONNECTION fake_vpn_service = self.service_plugin._get_vpnservice( mock.ANY, fake_vpn_conn['vpnservice_id']) [FAKE_VPN_CONNECTION, fake_vpn_conn], {'routers': [{'id': fake_vpn_service['router_id']}]}) fake_vpn_conn = FAKE_VPN_CONNECTION fake_vpn_service = self.service_plugin._get_vpnservice( mock.ANY, fake_vpn_conn['vpnservice_id']) [fake_vpn_conn], {'routers': [{'id': fake_vpn_service['router_id']}]}) fake_vpn_service = FAKE_VPN_SERVICE [FAKE_VPN_SERVICE, fake_vpn_service], {'routers': [{'id': fake_vpn_service['router_id']}]}) fake_vpn_service = FAKE_VPN_SERVICE [fake_vpn_service], {'routers': [{'id': fake_vpn_service['router_id']}]})"," service_plugin = mock.Mock() service_plugin.get_l3_agents_hosting_routers.return_value = [l3_agent] service_plugin._get_vpnservice.return_value = { self.driver = ipsec_driver.IPsecVPNDriver(service_plugin) def _test_update(self, func, args): rpc_mock.assert_called_once_with(ctxt, 'vpnservice_updated') [FAKE_VPN_CONNECTION]) [FAKE_VPN_CONNECTION, FAKE_VPN_CONNECTION]) [FAKE_VPN_CONNECTION]) [FAKE_VPN_SERVICE, FAKE_VPN_SERVICE]) [FAKE_VPN_SERVICE])",246,76
openstack%2Fceilometer~master~I92e4309f53fc1c7e9a952dff5366592d9ca50174,openstack/ceilometer,master,I92e4309f53fc1c7e9a952dff5366592d9ca50174,[Errno -9] Address family for hostname not supported,ABANDONED,2014-06-01 17:52:11.000000000,2014-12-14 15:32:09.000000000,,"[{'_account_id': 3}, {'_account_id': 6676}, {'_account_id': 8871}, {'_account_id': 13900}]","[{'number': 1, 'created': '2014-06-01 17:52:11.000000000', 'files': ['ceilometer/service.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/22b6ba8d7890f69b1b76c1f7141b05d2e628878d', 'message': '[Errno -9] Address family for hostname not supported\n\nFixed bug #1325399\n\nChange-Id: I92e4309f53fc1c7e9a952dff5366592d9ca50174\n'}]",1,97114,22b6ba8d7890f69b1b76c1f7141b05d2e628878d,7,4,1,9536,,,0,"[Errno -9] Address family for hostname not supported

Fixed bug #1325399

Change-Id: I92e4309f53fc1c7e9a952dff5366592d9ca50174
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/14/97114/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/service.py'],1,22b6ba8d7890f69b1b76c1f7141b05d2e628878d,bug/1325399," 'http://127.0.0.1:5000/v2.0'),"," 'http://localhost:5000/v2.0'),",1,1
openstack%2Ftripleo-image-elements~master~I8184bd2897e0dfd48ce50e7b5bcec9e59d5b62fd,openstack/tripleo-image-elements,master,I8184bd2897e0dfd48ce50e7b5bcec9e59d5b62fd,Create a devpi element,ABANDONED,2014-08-08 02:17:11.000000000,2014-12-14 10:24:59.000000000,,"[{'_account_id': 3}, {'_account_id': 9369}, {'_account_id': 9453}]","[{'number': 1, 'created': '2014-08-08 02:17:11.000000000', 'files': ['elements/devpi/element-deps', 'elements/devpi/README.md', 'elements/devpi/install.d/50-devpi'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/af5a3561dc843ad105f8699b21d89d267eaec5c5', 'message': ""Create a devpi element\n\nThis element is intended as a replacement for the pypi-mirror element\n\nRather than installing pypi-mirror and populating its cache, this\nelement installs devpi, starts a server running, configures the\nenvironment to use the server, and then installs the global\nrequirements into a venv in order to populate devpi's cache\n\nChange-Id: I8184bd2897e0dfd48ce50e7b5bcec9e59d5b62fd\n""}]",6,112748,af5a3561dc843ad105f8699b21d89d267eaec5c5,7,3,1,9453,,,0,"Create a devpi element

This element is intended as a replacement for the pypi-mirror element

Rather than installing pypi-mirror and populating its cache, this
element installs devpi, starts a server running, configures the
environment to use the server, and then installs the global
requirements into a venv in order to populate devpi's cache

Change-Id: I8184bd2897e0dfd48ce50e7b5bcec9e59d5b62fd
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/48/112748/1 && git format-patch -1 --stdout FETCH_HEAD,"['elements/devpi/element-deps', 'elements/devpi/README.md', 'elements/devpi/install.d/50-devpi']",3,af5a3561dc843ad105f8699b21d89d267eaec5c5,devpi-server,"#!/bin/bash # Copyright 2014 Hewlett-Packard Development Company, L.P. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. set -eux install-packages libyaml-dev pkg-config python-dev build-essential libmysqlclient-dev \ libffi-dev libpq-dev libxslt-dev libsqlite3-dev libldap2-dev libsasl2-dev mkdir -p /opt/stack/venvs virtualenv /opt/stack/venvs/devpi devpi/opt/stack/venvs/devpi/bin/pip install -U devpi ln -sf /opt/stack/venvs/devpi/bin/devpi-server /usr/local/bin/devpi-server useradd devpi --system -d /var/run/devpi -s /bin/false mkdir -p /var/cache devpi chown -R devpi.devpi /var/cache/devpi chmod a+rx /var/cache/devpi devpi-server --server-dir /var/cache/devpi --port 4040 --gen-config devpi-server --server-dir /var/cache/devpi --port 4040 --start devpi use --set-cfg http://localhost:4040/root/pypi cd $(mktemp -d) virtualenv . source bin/activate devpi use --set-cfg http://localhost:4040/root/pypi pip install -r https://git.openstack.org/cgit/openstack/requirements/plain/global-requirements.txt ",,44,0
openstack%2Fneutron~master~Ie09287113c1cff8ad774fbc88cbc84650baa6b0e,openstack/neutron,master,Ie09287113c1cff8ad774fbc88cbc84650baa6b0e,Remove unused dependencies,MERGED,2014-12-13 15:37:50.000000000,2014-12-14 10:14:08.000000000,2014-12-14 10:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7770}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10237}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-13 15:37:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c51bc1c2f3146ff63fdaf4adc8871bd4e5f2b3a7', 'message': 'Remove unused dependencies\n\n- anyjson is a dependency for oslo.serialization\n- argparse is in std lib\n\nChange-Id: Ie09287113c1cff8ad774fbc88cbc84650baa6b0e\n'}]",0,141561,c51bc1c2f3146ff63fdaf4adc8871bd4e5f2b3a7,46,27,1,7770,,,0,"Remove unused dependencies

- anyjson is a dependency for oslo.serialization
- argparse is in std lib

Change-Id: Ie09287113c1cff8ad774fbc88cbc84650baa6b0e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/141561/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c51bc1c2f3146ff63fdaf4adc8871bd4e5f2b3a7,,,anyjson>=0.3.3 argparse,0,2
openstack%2Frequirements~master~I88ed6d4912b506cf9c2b0803ebaa95095f3e18c4,openstack/requirements,master,I88ed6d4912b506cf9c2b0803ebaa95095f3e18c4,Remove dependencies which are not needed,ABANDONED,2014-12-14 09:49:32.000000000,2014-12-14 10:10:13.000000000,,[],"[{'number': 1, 'created': '2014-12-14 09:49:32.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5052f584ad47ea36d9d59faabb12d34aab5fff74', 'message': 'Remove dependencies which are not needed\n\n- anyjason is a dependency for oslo.serialization\n- argparse is in the std lib\n\nChange-Id: I88ed6d4912b506cf9c2b0803ebaa95095f3e18c4\n'}]",0,141631,5052f584ad47ea36d9d59faabb12d34aab5fff74,2,0,1,7770,,,0,"Remove dependencies which are not needed

- anyjason is a dependency for oslo.serialization
- argparse is in the std lib

Change-Id: I88ed6d4912b506cf9c2b0803ebaa95095f3e18c4
",git fetch https://review.opendev.org/openstack/requirements refs/changes/31/141631/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,5052f584ad47ea36d9d59faabb12d34aab5fff74,,,anyjson>=0.3.3 argparse,0,2
openstack%2Fopenstack-manuals~master~I4ed480cdec46d623115f0d5a5c496ef604e8071f,openstack/openstack-manuals,master,I4ed480cdec46d623115f0d5a5c496ef604e8071f,Imported Translations from Transifex,MERGED,2014-12-14 06:11:10.000000000,2014-12-14 07:39:34.000000000,2014-12-14 07:39:33.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-14 06:11:10.000000000', 'files': ['doc/install-guide/locale/install-guide.pot', 'doc/user-guide/locale/ja.po', 'doc/install-guide/locale/pt_BR.po', 'doc/networking-guide/locale/networking-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e99c99c717b0ee69160fbf1d22a4e64bec93c0ea', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I4ed480cdec46d623115f0d5a5c496ef604e8071f\n'}]",0,141624,e99c99c717b0ee69160fbf1d22a4e64bec93c0ea,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I4ed480cdec46d623115f0d5a5c496ef604e8071f
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/24/141624/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/install-guide/locale/install-guide.pot', 'doc/install-guide/locale/pt_BR.po', 'doc/user-guide/locale/ja.po', 'doc/networking-guide/locale/networking-guide.pot', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/common/locale/fr.po']",10,e99c99c717b0ee69160fbf1d22a4e64bec93c0ea,transifex/translations,"""POT-Creation-Date: 2014-12-14 01:11+0000\n"" ""PO-Revision-Date: 2014-12-14 01:20+0000\n""#: ./doc/common/tables/ceilometer-conf-changes.xml25(td)#: ./doc/common/tables/ceilometer-conf-changes.xml29(td)#: ./doc/common/tables/ceilometer-conf-changes.xml33(td)#: ./doc/common/tables/ceilometer-conf-changes.xml49(td)#: ./doc/common/tables/ceilometer-conf-changes.xml37(td)#: ./doc/common/tables/ceilometer-conf-changes.xml41(td)#: ./doc/common/tables/ceilometer-conf-changes.xml45(td)msgid ""New, updated and deprecated options in Kilo for Telemetry""msgid ""[DEFAULT] policy_dirs = ['policy.d']""#: ./doc/common/tables/ceilometer-api.xml34(td) msgid """" ""(MultiStrOpt) Directories where policy configuration files are stored. They "" ""can be relative to any directory in the search path defined by the "" ""config_dir option, or absolute paths. The file defined by policy_file must "" ""exist for these directories to be searched.""msgid ""[alarm] evaluation_service = default""#: ./doc/common/tables/ceilometer-alarm.xml26(td) msgid """" ""(StrOpt) Driver to use for alarm evaluation service. DEPRECATED: "" ""\""singleton\"" and \""partitioned\"" alarm evaluator services will be removed "" ""in Kilo in favour of the default alarm evaluation service using tooz for "" ""partitioning.""msgid ""[database] db2nosql_resource_id_maxlen = 512""msgid ""[database] event_connection = None""msgid ""[database] mongodb_replica_set =""msgid ""[dispatcher_http] cadf_only = False""msgid ""[dispatcher_http] target =""msgid ""[dispatcher_http] timeout = 5""#: ./doc/common/tables/nova-conf-changes.xml300(td) msgid ""[vmware] host_port = 443""#: ./doc/common/tables/nova-upgrade_levels.xml29(td) msgid ""(StrOpt) Set a version cap for messages sent to local cells services"" msgstr """" #: ./doc/common/tables/ceilometer-api.xml22(td) msgid ""(StrOpt) Configuration file for WSGI definition of API."" msgstr """" #: ./doc/common/tables/ceilometer-api.xml61(td) msgid """" ""(BoolOpt) Toggle Pecan Debug Middleware. Defaults to global debug value."" msgstr """" #: ./doc/common/tables/ceilometer-exchange.xml38(td) msgid ""(StrOpt) Exchange name for Ironic notifications."" msgstr """" #: ./doc/common/tables/ceilometer-exchange.xml42(td) msgid ""(StrOpt) Exchange name for Keystone notifications."" msgstr """" #: ./doc/common/tables/cinder-common.xml38(td) #: ./doc/common/tables/nova-api.xml30(td) msgid ""(BoolOpt) Services to be added to the available pool on create"" msgstr """" #: ./doc/common/tables/ceilometer-alarm.xml38(td) msgid ""(IntOpt) Maximum number of alarms defined for a project."" msgstr """" #: ./doc/common/tables/ceilometer-alarm.xml54(td) msgid ""(IntOpt) Number of retries for REST notifier"" msgstr """" #: ./doc/common/tables/ceilometer-alarm.xml62(td) msgid ""(IntOpt) Maximum number of alarms defined for a user."" msgstr """" #: ./doc/common/tables/nova-conf-changes.xml84(td) msgid ""[database] use_tpool = False"" msgstr """" #: ./doc/common/tables/ceilometer-rpc.xml57(td) msgid """" ""(MultiStrOpt) Messaging URLs to listen for notifications. Example: "" ""transport://user:pass@host1:port[,hostN:portN]/virtual_host "" ""(DEFAULT/transport_url is used if empty)"" msgstr """" #: ./doc/common/tables/ceilometer-rpc.xml71(td) msgid ""(StrOpt) The driver that ceilometer uses for metering notifications."" msgstr """" #: ./doc/common/tables/ceilometer-rpc.xml75(td) msgid ""(StrOpt) The topic that ceilometer uses for metering notifications."" msgstr """" #: ./doc/common/tables/nova-network.xml166(td) msgid ""(StrOpt) The full class name of the network API class to use"" msgstr """" #: ./doc/common/tables/ceilometer-debug.xml26(td) msgid ""(BoolOpt) Allow novaclient's debug log output."" msgstr """" #: ./doc/common/tables/ceilometer-tripleo.xml22(td) msgid ""(StrOpt) SNMPd user name of all nodes running in the cloud."" msgstr """" #: ./doc/common/tables/ceilometer-service_types.xml22(td) msgid ""(StrOpt) Glance service type."" msgstr """" #: ./doc/common/tables/ceilometer-service_types.xml26(td) msgid ""(StrOpt) Kwapi service type."" msgstr """" #: ./doc/common/tables/ceilometer-service_types.xml30(td) msgid ""(StrOpt) Neutron service type."" msgstr """" #: ./doc/common/tables/ceilometer-service_types.xml34(td) msgid ""(StrOpt) Nova service type."" msgstr """" #: ./doc/common/tables/ceilometer-service_types.xml38(td) msgid ""(StrOpt) Swift service type."" msgstr """" #: ./doc/common/tables/nova-logging.xml34(td) msgid ""(BoolOpt) Make exception message format errors fatal"" msgstr """" #: ./doc/common/tables/nova-api.xml42(td) msgid ""(StrOpt) Template string to be used to generate instance names"" msgstr """" #: ./doc/common/tables/ceilometer-ipmi.xml22(td) msgid """" ""(IntOpt) Number of retries upon Intel Node Manager initialization failure"" msgstr """" #: ./doc/common/tables/ceilometer-glance.xml22(td) msgid """" ""(IntOpt) Number of items to request in each paginated Glance API request "" ""(parameter used by glancecelient). If this is less than or equal to 0, page "" ""size is not specified (default value in glanceclient is used)."" msgstr """" ","""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-11 19:34+0000\n""#: ./doc/common/tables/ceilometer-conf-changes.xml137(td)#: ./doc/common/tables/ceilometer-conf-changes.xml141(td)#: ./doc/common/tables/ceilometer-conf-changes.xml145(td)#: ./doc/common/tables/ceilometer-conf-changes.xml149(td)#: ./doc/common/tables/ceilometer-conf-changes.xml153(td)#: ./doc/common/tables/ceilometer-conf-changes.xml161(td)#: ./doc/common/tables/ceilometer-conf-changes.xml165(td)#: ./doc/common/tables/ceilometer-conf-changes.xml169(td)#: ./doc/common/tables/ceilometer-conf-changes.xml173(td)#: ./doc/common/tables/ceilometer-conf-changes.xml197(td)#: ./doc/common/tables/ceilometer-conf-changes.xml201(td)#: ./doc/common/tables/ceilometer-conf-changes.xml205(td)#: ./doc/common/tables/ceilometer-conf-changes.xml89(td)#: ./doc/common/tables/ceilometer-conf-changes.xml69(td)#: ./doc/common/tables/ceilometer-conf-changes.xml49(td)#: ./doc/common/tables/ceilometer-conf-changes.xml53(td)#: ./doc/common/tables/ceilometer-conf-changes.xml77(td)#: ./doc/common/tables/ceilometer-conf-changes.xml117(td)#: ./doc/common/tables/ceilometer-conf-changes.xml125(td)#: ./doc/common/tables/ceilometer-conf-changes.xml129(td)#: ./doc/common/tables/ceilometer-conf-changes.xml177(td)#: ./doc/common/tables/ceilometer-conf-changes.xml261(td)#: ./doc/common/tables/ceilometer-conf-changes.xml73(td)#: ./doc/common/tables/ceilometer-conf-changes.xml65(td)#: ./doc/common/tables/ceilometer-conf-changes.xml37(td)#: ./doc/common/tables/ceilometer-conf-changes.xml68(td)#: ./doc/common/tables/ceilometer-conf-changes.xml72(td)#: ./doc/common/tables/ceilometer-conf-changes.xml88(td)#: ./doc/common/tables/ceilometer-conf-changes.xml140(td)#: ./doc/common/tables/ceilometer-conf-changes.xml144(td)#: ./doc/common/tables/ceilometer-conf-changes.xml148(td)#: ./doc/common/tables/ceilometer-conf-changes.xml152(td)#: ./doc/common/tables/ceilometer-conf-changes.xml160(td)#: ./doc/common/tables/ceilometer-conf-changes.xml164(td)#: ./doc/common/tables/ceilometer-conf-changes.xml168(td)#: ./doc/common/tables/ceilometer-conf-changes.xml172(td)#: ./doc/common/tables/ceilometer-conf-changes.xml196(td)#: ./doc/common/tables/ceilometer-conf-changes.xml200(td)#: ./doc/common/tables/ceilometer-conf-changes.xml204(td)#: ./doc/common/tables/ceilometer-conf-changes.xml265(caption)#: ./doc/common/tables/ceilometer-conf-changes.xml271(td)#: ./doc/common/tables/ceilometer-conf-changes.xml272(td)#: ./doc/common/tables/ceilometer-conf-changes.xml273(td)#: ./doc/common/tables/ceilometer-conf-changes.xml277(td)#: ./doc/common/tables/ceilometer-conf-changes.xml289(td) #: ./doc/common/tables/ceilometer-conf-changes.xml294(td)#: ./doc/common/tables/ceilometer-conf-changes.xml282(td)#: ./doc/common/tables/ceilometer-conf-changes.xml284(td)#: ./doc/common/tables/ceilometer-conf-changes.xml287(td)#: ./doc/common/tables/ceilometer-conf-changes.xml292(td)#: ./doc/common/tables/ceilometer-conf-changes.xml297(td)#: ./doc/common/tables/ceilometer-conf-changes.xml298(td)#: ./doc/common/tables/ceilometer-conf-changes.xml299(td)#: ./doc/common/tables/ceilometer-conf-changes.xml303(caption)#: ./doc/common/tables/ceilometer-conf-changes.xml308(td)#: ./doc/common/tables/ceilometer-conf-changes.xml309(td)#: ./doc/common/tables/ceilometer-conf-changes.xml313(td)#: ./doc/common/tables/ceilometer-conf-changes.xml314(td)#: ./doc/common/tables/ceilometer-conf-changes.xml278(td)#: ./doc/common/tables/ceilometer-conf-changes.xml279(td)#: ./doc/common/tables/ceilometer-conf-changes.xml85(td)msgid ""New, updated and deprecated options in Juno for Telemetry""msgid ""[DEFAULT] api_paste_config = api_paste.ini""#: ./doc/common/tables/ceilometer-api.xml22(td) msgid ""(StrOpt) Configuration file for WSGI definition of API.""msgid ""[DEFAULT] enable_new_services = True""#: ./doc/common/tables/cinder-common.xml38(td) #: ./doc/common/tables/nova-api.xml30(td) msgid ""(BoolOpt) Services to be added to the available pool on create""msgid ""[DEFAULT] fatal_exception_format_errors = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml25(td) #: ./doc/common/tables/nova-logging.xml34(td) msgid ""(BoolOpt) Make exception message format errors fatal""msgid ""[DEFAULT] glance_page_size = 0"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml29(td) #: ./doc/common/tables/ceilometer-glance.xml22(td) msgid """" ""(IntOpt) Number of items to request in each paginated Glance API request "" ""(parameter used by glancecelient). If this is less than or equal to 0, page "" ""size is not specified (default value in glanceclient is used).""msgid ""[DEFAULT] instance_name_template = instance-%08x"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml33(td) #: ./doc/common/tables/nova-api.xml42(td) msgid ""(StrOpt) Template string to be used to generate instance names""msgid ""[DEFAULT] instance_usage_audit_period = month""msgid ""[DEFAULT] ironic_exchange = ironic"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml41(td) #: ./doc/common/tables/ceilometer-exchange.xml38(td) msgid ""(StrOpt) Exchange name for Ironic notifications.""msgid ""[DEFAULT] keystone_control_exchange = keystone"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml45(td) #: ./doc/common/tables/ceilometer-exchange.xml42(td) msgid ""(StrOpt) Exchange name for Keystone notifications.""msgid ""[DEFAULT] monkey_patch = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml52(td) msgid """" ""[DEFAULT] monkey_patch_modules = "" ""nova.api.ec2.cloud:nova.notifications.notify_decorator, "" ""nova.compute.api:nova.notifications.notify_decorator"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml56(td) msgid ""[DEFAULT] network_api_class = nova.network.api.API"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml57(td) #: ./doc/common/tables/nova-network.xml166(td) msgid ""(StrOpt) The full class name of the network API class to use"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml60(td) msgid ""[DEFAULT] nova_http_log_debug = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml61(td) #: ./doc/common/tables/ceilometer-debug.xml26(td) msgid ""(BoolOpt) Allow novaclient's debug log output."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml64(td) msgid ""[DEFAULT] password_length = 12"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml76(td) msgid ""[DEFAULT] rootwrap_config = /etc/ceilometer/rootwrap.conf"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml80(td) msgid ""[DEFAULT] sahara_control_exchange = sahara"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml81(td) msgid ""(StrOpt) Exchange name for Data Processing notifications"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml84(td) msgid ""[DEFAULT] snapshot_name_template = snapshot-%s"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml92(td) msgid ""[DEFAULT] trove_control_exchange = trove"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml93(td) msgid ""(StrOpt) Exchange name for DBaaS notifications"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml96(td) msgid ""[alarm] project_alarm_quota = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml97(td) #: ./doc/common/tables/ceilometer-alarm.xml38(td) msgid ""(IntOpt) Maximum number of alarms defined for a project."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml100(td) msgid ""[alarm] rest_notifier_max_retries = 0"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml101(td) #: ./doc/common/tables/ceilometer-alarm.xml54(td) msgid ""(IntOpt) Number of retries for REST notifier"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml104(td) msgid ""[alarm] user_alarm_quota = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml105(td) #: ./doc/common/tables/ceilometer-alarm.xml62(td) msgid ""(IntOpt) Maximum number of alarms defined for a user."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml108(td) msgid ""[api] enable_reverse_dns_lookup = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml109(td) msgid """" ""(BoolOpt) Set it to False if your environment does not need or have dns "" ""server, otherwise it will delay the response from api."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml112(td) msgid ""[api] pecan_debug = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml113(td) #: ./doc/common/tables/ceilometer-api.xml61(td) msgid """" ""(BoolOpt) Toggle Pecan Debug Middleware. Defaults to global debug value."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml116(td) msgid ""[central] partitioning_group_prefix = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml120(td) msgid ""[collector] requeue_sample_on_dispatcher_error = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml121(td) msgid """" ""(BoolOpt) Requeue the sample on the collector sample queue when the "" ""collector fails to dispatch it. This is only valid if the sample come from "" ""the notifier publisher"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml124(td) msgid ""[compute] workload_partitioning = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml128(td) msgid ""[coordination] backend_url = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml132(td) msgid ""[coordination] heartbeat = 1.0"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml133(td) msgid """" ""(FloatOpt) Number of seconds between heartbeats for distributed coordination"" "" (float)"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml136(td) msgid ""[database] alarm_connection = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml156(td) msgid ""[database] metering_connection = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml157(td) msgid """" ""(StrOpt) The connection string used to connect to the meteting database. (if"" "" unset, connection is used)"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml176(td) #: ./doc/common/tables/nova-conf-changes.xml84(td) msgid ""[database] use_tpool = False"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml180(td) msgid ""[hardware] readonly_user_name = ro_snmp_user"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml181(td) #: ./doc/common/tables/ceilometer-tripleo.xml22(td) msgid ""(StrOpt) SNMPd user name of all nodes running in the cloud."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml184(td) msgid ""[hardware] readonly_user_password = password"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml185(td) msgid ""(StrOpt) SNMPd password of all the nodes running in the cloud"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml188(td) msgid ""[hardware] url_scheme = snmp://"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml189(td) msgid ""(StrOpt) URL scheme to use for hardware nodes"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml192(td) msgid ""[ipmi] node_manager_init_retry = 3"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml193(td) #: ./doc/common/tables/ceilometer-ipmi.xml22(td) msgid """" ""(IntOpt) Number of retries upon Intel Node Manager initialization failure"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml208(td) msgid ""[notification] messaging_urls = []"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml209(td) #: ./doc/common/tables/ceilometer-rpc.xml57(td) msgid """" ""(MultiStrOpt) Messaging URLs to listen for notifications. Example: "" ""transport://user:pass@host1:port[,hostN:portN]/virtual_host "" ""(DEFAULT/transport_url is used if empty)"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml212(td) msgid ""[publisher_notifier] metering_driver = messagingv2"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml213(td) #: ./doc/common/tables/ceilometer-rpc.xml71(td) msgid ""(StrOpt) The driver that ceilometer uses for metering notifications."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml216(td) msgid ""[publisher_notifier] metering_topic = metering"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml217(td) #: ./doc/common/tables/ceilometer-rpc.xml75(td) msgid ""(StrOpt) The topic that ceilometer uses for metering notifications."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml220(td) msgid ""[service_types] glance = image"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml221(td) #: ./doc/common/tables/ceilometer-service_types.xml22(td) msgid ""(StrOpt) Glance service type."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml224(td) msgid ""[service_types] kwapi = energy"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml225(td) #: ./doc/common/tables/ceilometer-service_types.xml26(td) msgid ""(StrOpt) Kwapi service type."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml228(td) msgid ""[service_types] neutron = network"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml229(td) #: ./doc/common/tables/ceilometer-service_types.xml30(td) msgid ""(StrOpt) Neutron service type."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml232(td) msgid ""[service_types] nova = compute"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml233(td) #: ./doc/common/tables/ceilometer-service_types.xml34(td) msgid ""(StrOpt) Nova service type."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml236(td) msgid ""[service_types] swift = object-store"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml237(td) #: ./doc/common/tables/ceilometer-service_types.xml38(td) msgid ""(StrOpt) Swift service type."" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml240(td) msgid ""[upgrade_levels] cells = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml241(td) #: ./doc/common/tables/nova-upgrade_levels.xml29(td) msgid ""(StrOpt) Set a version cap for messages sent to local cells services"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml244(td) msgid ""[vmware] wsdl_location = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml245(td) msgid """" ""(StrOpt) Optional vim service WSDL location e.g "" ""http://&lt;server&gt;/vimService.wsdl. Optional over-ride to default "" ""location for bug work-arounds"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml248(td) msgid ""[xenapi] connection_password = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml249(td) msgid ""(StrOpt) Password for connection to XenServer/Xen Cloud Platform"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml252(td) msgid ""[xenapi] connection_url = None"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml253(td) msgid ""(StrOpt) URL for connection to XenServer/Xen Cloud Platform"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml256(td) msgid ""[xenapi] connection_username = root"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml257(td) msgid ""(StrOpt) Username for connection to XenServer/Xen Cloud Platform"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml260(td) msgid ""[xenapi] login_timeout = 10"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml283(td) msgid ""ceilometer.openstack.common.rpc.matchmaker.MatchMakerLocalhost"" msgstr """" #: ./doc/common/tables/ceilometer-conf-changes.xml288(td) msgid """" ""sqlite:////usr/lib/python/site-"" ""packages/ceilometer/ceilometer/openstack/common/db/$sqlite_db""#: ./doc/common/tables/ceilometer-api.xml34(td) msgid """" ""(MultiStrOpt) Directories where policy configuration files are stored. They "" ""can be relative to any directory in the search path defined by the "" ""config_dir option, or absolute paths. The file defined by policy_file must "" ""exist for these directories to be searched."" msgstr """" #: ./doc/common/tables/ceilometer-alarm.xml26(td) msgid """" ""(StrOpt) Driver to use for alarm evaluation service. DEPRECATED: "" ""\""singleton\"" and \""partitioned\"" alarm evaluator services will be removed "" ""in Kilo in favour of the default alarm evaluation service using tooz for "" ""partitioning."" msgstr """" #: ./doc/common/tables/nova-conf-changes.xml300(td) msgid ""[vmware] host_port = 443"" msgstr """" ",9687,1455
openstack%2Fdevstack~stable%2Fjuno~Id252581f180045e265d7163bc236ce2c76d40da8,openstack/devstack,stable/juno,Id252581f180045e265d7163bc236ce2c76d40da8,Hard code juno service extension lists,MERGED,2014-12-08 17:22:10.000000000,2014-12-14 06:46:32.000000000,2014-12-14 06:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 970}, {'_account_id': 5196}, {'_account_id': 10016}]","[{'number': 1, 'created': '2014-12-08 17:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/33f2a3bce26c5a2f79d24ed55f83104e8161dea4', 'message': ""Hard code juno service extension lists\n\nThis commit adds the hard coded service extension lists for juno\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the juno\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: Id252581f180045e265d7163bc236ce2c76d40da8\n""}, {'number': 2, 'created': '2014-12-08 19:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/175ccd3eda49854343aa2f7cbef4f970d154d1c2', 'message': ""Hard code juno service extension lists\n\nThis commit adds the hard coded service extension lists for juno\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the juno\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: Id252581f180045e265d7163bc236ce2c76d40da8\n""}, {'number': 3, 'created': '2014-12-08 21:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3440bcd3081db8fe4152c36ed31d2bd1e7054453', 'message': ""Hard code juno service extension lists\n\nThis commit adds the hard coded service extension lists for juno\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the juno\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: Id252581f180045e265d7163bc236ce2c76d40da8\n""}, {'number': 4, 'created': '2014-12-08 21:59:43.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3710f94b956118840f8cd7f0eea741e83944329a', 'message': ""Hard code juno service extension lists\n\nThis commit adds the hard coded service extension lists for juno\nin the tempest config files. To enable gating with tempest master on\nall supported branches the extension list has to be explicit on stable\nbranches to ensure we don't attempt to run tests for new extensions on\nstable branch services. This commit adds these lists for the juno\nbranch.\n\nImplements blueprint branchless-tempest-extensions\n\nChange-Id: Id252581f180045e265d7163bc236ce2c76d40da8\n""}]",0,140090,3710f94b956118840f8cd7f0eea741e83944329a,25,6,4,5196,,,0,"Hard code juno service extension lists

This commit adds the hard coded service extension lists for juno
in the tempest config files. To enable gating with tempest master on
all supported branches the extension list has to be explicit on stable
branches to ensure we don't attempt to run tests for new extensions on
stable branch services. This commit adds these lists for the juno
branch.

Implements blueprint branchless-tempest-extensions

Change-Id: Id252581f180045e265d7163bc236ce2c76d40da8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/90/140090/4 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,33f2a3bce26c5a2f79d24ed55f83104e8161dea4,bp/branchless-tempest-extensions," iniset $TEMPEST_CONFIG compute-feature-enabled api_extensions ${COMPUTE_API_EXTENSIONS:-""AdminActions, Agents, Aggregates, AssistedVolumeSnapshots, AttachInterfaces, AvailabilityZone, BareMetalExtStatus, BareMetalNodes, BlockDeviceMappingV2Boot, CellCapacities, Cells, Certificates, Cloudpipe, CloudpipeUpdate, ConfigDrive, ConsoleAuthTokens, ConsoleOutput, Consoles, Createserverext, DeferredDelete, DiskConfig, Evacuate, ExtendedAvailabilityZone, ExtendedEvacuateFindHost, ExtendedFloatingIps, ExtendedHypervisors, ExtendedIps, ExtendedIpsMac, ExtendedNetworks, ExtendedQuotas, ExtendedRescueWithImage, ExtendedServerAttributes, ExtendedServices, ExtendedServicesDelete, ExtendedStatus, ExtendedVIFNet, ExtendedVolumes, FixedIPs, FlavorAccess, FlavorDisabled, FlavorExtraData, FlavorExtraSpecs, FlavorManage, FlavorRxtx, FlavorSwap, FloatingIpDns, FloatingIpPools, FloatingIps, FloatingIpsBulk, Fping, HideServerAddresses, Hosts, HypervisorStatus, Hypervisors, ImageSize, InstanceActions, Keypairs, Migrations, Multinic, MultipleCreate, NetworkAssociationSupport, Networks, OSInstanceUsageAuditLog, OSTenantNetworks, PreserveEphemeralOnRebuild, QuotaClasses, Quotas, Rescue, SchedulerHints, SecurityGroupDefaultRules, SecurityGroups, ServerDiagnostics, ServerExternalEvents, ServerGroupQuotas, ServerGroups, ServerListMultiStatus, ServerPassword, ServerStartStop, ServerUsage, Services, Shelve, SimpleTenantUsage, UsedLimits, UsedLimitsForAdmin, UserData, UserQuotas, VirtualInterfaces, VolumeAttachmentUpdate, Volumes""} iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ${NETWORK_API_EXTENSIONS:-""agent, allowed-address-pairs, binding, dhcp_agent_scheduler, dvr, ext-gw-mode, external-net, extra_dhcp_opt, extraroute, fwaas, l3-ha, l3_agent_scheduler, lbaas, lbaas_agent_scheduler, metering, multi-provider, provider, quotas, router, security-group, service-type, vpnaas""} iniset $TEMPEST_CONFIG object-storage-feature-enabled discoverable_apis ${OBJECT_STORAGE_API_EXTENSIONS:-""account_quotas, bulk_delete, bulk_upload, container_quotas, container_sync, crossdomain, formpost, keystoneauth, ratelimit, slo, staticweb, tempauth, tempurl""} iniset $TEMPEST_CONFIG volume-feature-enabled api_extensions ${VOLUME_API_EXTENSIONS:-""AdminActions, AvailabilityZones, Backups, Cgsnapshots, Consistencygroups, CreateVolumeExtension, ExtendedServices, ExtendedSnapshotAttributes, Hosts, Qos_specs_manage, QuotaClasses, Quotas, SchedulerHints, Scheduler_stats, Services, SnapshotActions, TypesExtraSpecs, TypesManage, UsedLimits, VolumeActions, VolumeEncryptionMetadata, VolumeHostAttribute, VolumeImageMetadata, VolumeManage, VolumeMigStatusAttribute, VolumeReplication, VolumeTenantAttribute, VolumeTransfer, VolumeTypeEncryption, VolumeUnmanage""}"," iniset $TEMPEST_CONFIG compute-feature-enabled api_extensions ${COMPUTE_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG network-feature-enabled api_extensions ${NETWORK_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG object-storage-feature-enabled discoverable_apis ${OBJECT_STORAGE_API_EXTENSIONS:-""all""} iniset $TEMPEST_CONFIG volume-feature-enabled api_extensions ${VOLUME_API_EXTENSIONS:-""all""}",4,4
openstack%2Fcinder~master~I8c184bf1684c8592a36f749cdcb5493f6b65e52b,openstack/cinder,master,I8c184bf1684c8592a36f749cdcb5493f6b65e52b,Fix use of invalid variable in tgt exists check,MERGED,2014-12-03 17:47:35.000000000,2014-12-14 05:25:01.000000000,2014-12-14 05:24:59.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10504}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12780}]","[{'number': 1, 'created': '2014-12-03 17:47:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/dcdafa6cc72ffd712a7df8874e1883d69364c4b4', 'message': 'Fix use of invalid variable in tgt exists check\n\nI added a check for tgt already exists here:\nhttps://review.openstack.org/#/c/138173/\n\nBut, that was wrong, the err value is never going to be\nset because of the exception.  This should have inspected\nthe exception object and checked against it.\n\nSo this patch makes it do what it was supposed to do.\n\nChange-Id: I8c184bf1684c8592a36f749cdcb5493f6b65e52b\n'}, {'number': 2, 'created': '2014-12-12 05:36:03.000000000', 'files': ['cinder/brick/iscsi/iscsi.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/22abe9081543bde315f39438e56eb7ce8c30c223', 'message': 'Fix use of invalid variable in tgt exists check\n\nI added a check for tgt already exists here:\nhttps://review.openstack.org/#/c/138173/\n\nBut, that was wrong, the err value is never going to be\nset because of the exception.  This should have inspected\nthe exception object and checked against it.\n\nSo this patch makes it do what it was supposed to do.\n\nChange-Id: I8c184bf1684c8592a36f749cdcb5493f6b65e52b\n'}]",1,138802,22abe9081543bde315f39438e56eb7ce8c30c223,25,14,2,2243,,,0,"Fix use of invalid variable in tgt exists check

I added a check for tgt already exists here:
https://review.openstack.org/#/c/138173/

But, that was wrong, the err value is never going to be
set because of the exception.  This should have inspected
the exception object and checked against it.

So this patch makes it do what it was supposed to do.

Change-Id: I8c184bf1684c8592a36f749cdcb5493f6b65e52b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/02/138802/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/brick/iscsi/iscsi.py'],1,dcdafa6cc72ffd712a7df8874e1883d69364c4b4,fix_invalid_var_usage," if ""target already exists"" in e.stderr:"," if ""target already exists"" in err:",1,1
openstack%2Fneutron~master~Ic0a968a400268af1f66c91e4c39e7d3acf492ef3,openstack/neutron,master,Ic0a968a400268af1f66c91e4c39e7d3acf492ef3,Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel,MERGED,2014-12-11 14:16:49.000000000,2014-12-14 05:18:58.000000000,2014-12-14 05:18:56.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7743}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 14:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d572e6381db3530e5c0c78d05d34855dbbdc4aba', 'message': 'Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel\n\nCurrently in unit test neutron.tests.unit.openvswitch.test_ovs_tunnel,\nthere\'re 3 test_daemon_loop test cases. And in each of them, there\'s\na 2 seconds wait according to ""polling_interval"". It\'s unnecessary,\nbut introduces extra 6 seconds cost for these unit test. That makes\nthem to be top 3 slowest tests in test_ovs_tunnel. Time cost {2.094s,\n2.093s, 2.085s}, total 6.272s. With this patch, time cost reduces to\n{0.022s, 0.090s, 0.023s}, total 0.135s. Tested on the same dev-box.\n\nChange-Id: Ic0a968a400268af1f66c91e4c39e7d3acf492ef3\n'}, {'number': 2, 'created': '2014-12-11 14:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/871e40c73096a9d01ba1eb9c2eda1bd35d45dce9', 'message': 'Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel\n\nCurrently in unit test neutron.tests.unit.openvswitch.test_ovs_tunnel,\nthere\'re 3 test_daemon_loop test cases. And in each of them, there\'s\na 2 seconds wait according to ""polling_interval"". It\'s unnecessary,\nbut introduces extra 6 seconds cost for these unit test. That makes\nthem to be top 3 slowest tests in test_ovs_tunnel. Time cost {2.094s,\n2.093s, 2.085s}, total 6.272s. With this patch, time cost reduces to\n{0.022s, 0.090s, 0.023s}, total 0.135s. Tested on the same dev-box.\nCloses-bug: #1401457\n\nChange-Id: Ic0a968a400268af1f66c91e4c39e7d3acf492ef3\n'}, {'number': 3, 'created': '2014-12-12 01:44:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2a40aed34e9f4c6b86160d3e893e9c0a45a8d89d', 'message': 'Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel\n\nUnnecessary wait in ovs tunnel UT introduces extra 6 seconds time cost, and makes 3 test_daemon_loop cases the slowest tests. Mock up time.sleep to reduce UT time, from around 6.272s to 0.135s.\n\nCloses-bug: #1401457\n\nChange-Id: Ic0a968a400268af1f66c91e4c39e7d3acf492ef3\n'}, {'number': 4, 'created': '2014-12-12 01:45:36.000000000', 'files': ['neutron/tests/unit/openvswitch/test_ovs_tunnel.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5b0aa48ec1502b3522ff19eada74855d98ec25de', 'message': 'Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel\n\nUnnecessary wait in ovs tunnel UT introduces extra 6 seconds time cost,\nand makes 3 test_daemon_loop cases the slowest tests. Mock up time.sleep\nto reduce UT time, from around 6.272s to 0.135s.\n\nCloses-bug: #1401457\n\nChange-Id: Ic0a968a400268af1f66c91e4c39e7d3acf492ef3\n'}]",2,141057,5b0aa48ec1502b3522ff19eada74855d98ec25de,96,24,4,7743,,,0,"Mock up time.sleep to avoid unnecessary wait in test_ovs_tunnel

Unnecessary wait in ovs tunnel UT introduces extra 6 seconds time cost,
and makes 3 test_daemon_loop cases the slowest tests. Mock up time.sleep
to reduce UT time, from around 6.272s to 0.135s.

Closes-bug: #1401457

Change-Id: Ic0a968a400268af1f66c91e4c39e7d3acf492ef3
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/141057/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/openvswitch/test_ovs_tunnel.py'],1,d572e6381db3530e5c0c78d05d34855dbbdc4aba,bug/1401457,"import time 'tunnel_sync'), mock.patch.object(time, 'sleep') ) as (log_exception, scan_ports, process_network_ports, ts, time_sleep):"," 'tunnel_sync') ) as (log_exception, scan_ports, process_network_ports, ts):",5,2
openstack%2Fmurano~stable%2Fjuno~I852f1f3dd1051c7b40afaa2575a4335b0f3c3104,openstack/murano,stable/juno,I852f1f3dd1051c7b40afaa2575a4335b0f3c3104,Environment in delete failed state was in progress forever,MERGED,2014-11-10 18:44:07.000000000,2014-12-14 05:09:47.000000000,2014-12-14 05:09:46.000000000,"[{'_account_id': 3}, {'_account_id': 979}, {'_account_id': 7225}, {'_account_id': 7227}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-10 18:44:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f5bee8e53f26eed5ea012df898dfe1bf053ee8f2', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever.\n\nAlso there were 2 duplicate SessionStates enums in the code with\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration\n\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nCloses-Bug: #1386068\n""}, {'number': 2, 'created': '2014-11-18 13:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/7e0c541b41fe9bba6c954ac97ca0adb0ec6e4e32', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever.\n\nAlso there were 2 duplicate SessionStates enums in the code with\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration.\n\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}, {'number': 3, 'created': '2014-11-19 14:27:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/4365716d4bf47c1898628e6fe77805cdb8b5f8de', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever.\n\nAlso there were 2 duplicate SessionStates enums in the code with\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration.\n\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}, {'number': 4, 'created': '2014-11-21 16:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/83558a2b3231979d53c142f7390c5d31bc90e7ab', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever.\n\nAlso there were 2 duplicate SessionStates enums in the code\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration.\n\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}, {'number': 5, 'created': '2014-11-26 15:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/785086e0a72533c3fdbf90c1dc26a7ef1b84159c', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever.\n\nAlso there were 2 duplicate SessionStates enums in the code\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration\n\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}, {'number': 6, 'created': '2014-12-12 12:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bd75d01df6d25eed064389476654bce25e584091', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever\n\nAlso there were 2 duplicate SessionStates enums in the code\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration\n\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}, {'number': 7, 'created': '2014-12-12 18:40:36.000000000', 'files': ['murano/services/state.py', 'murano/utils.py', 'murano/db/services/environments.py', 'murano/db/services/sessions.py', 'murano/services/actions.py', 'murano/api/v1/actions.py', 'murano/common/server.py', 'murano/db/services/actions.py', 'murano/services/states.py', 'murano/api/v1/sessions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/bbfa9cbfdaf837b3aec11bf7c00b8bc15a766ce0', 'message': ""Environment in delete failed state was in progress forever\n\nDeletion sessions were in 'deploying' state instead of 'deleting'.\nBecause of this such sessions could not be found by RPC result\nprocessing code and remained in 'deploying' status causing UI\nto display progress bar forever\n\nAlso there were 2 duplicate SessionStates enums in the code\nand the second copy was outdated and didn't contained DELETING\nstatus as well as other new session statuses. Because buggy code\nwas using that outdated enum it was necessary to merge both enums\ninto single declaration\n\nCloses-Bug: #1386068\nCherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\nChange-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104\n""}]",3,133539,bbfa9cbfdaf837b3aec11bf7c00b8bc15a766ce0,42,6,7,7226,,,0,"Environment in delete failed state was in progress forever

Deletion sessions were in 'deploying' state instead of 'deleting'.
Because of this such sessions could not be found by RPC result
processing code and remained in 'deploying' status causing UI
to display progress bar forever

Also there were 2 duplicate SessionStates enums in the code
and the second copy was outdated and didn't contained DELETING
status as well as other new session statuses. Because buggy code
was using that outdated enum it was necessary to merge both enums
into single declaration

Closes-Bug: #1386068
Cherry-pick: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104
Change-Id: I852f1f3dd1051c7b40afaa2575a4335b0f3c3104
",git fetch https://review.opendev.org/openstack/murano refs/changes/39/133539/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/services/state.py', 'murano/utils.py', 'murano/db/services/environments.py', 'murano/db/services/sessions.py', 'murano/services/actions.py', 'murano/api/v1/actions.py', 'murano/common/server.py', 'murano/db/services/actions.py', 'murano/services/states.py', 'murano/api/v1/sessions.py']",10,f5bee8e53f26eed5ea012df898dfe1bf053ee8f2,,"from murano.services import states if env_status in (states.EnvironmentStatus.DEPLOYING, states.EnvironmentStatus.DELETING): if session.state == states.SessionState.DEPLOYING: if session.state != states.SessionState.OPENED:"," if env_status in (envs.EnvironmentStatus.DEPLOYING, envs.EnvironmentStatus.DELETING): if session.state == sessions.SessionState.DEPLOYING: if session.state != sessions.SessionState.OPENED:",79,85
openstack%2Ftaskflow~master~Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6,openstack/taskflow,master,Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6,Use the notifier type in the task class/module directly,MERGED,2014-12-13 02:26:56.000000000,2014-12-14 04:43:24.000000000,2014-12-14 04:43:23.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-13 02:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ec1f02abd0dc675649d5d7a7c9ee7c9a0a93bb86', 'message': 'Use the notifier type in task module directly\n\nInstead of having code that is somewhat like the notifier\ncode we already have, but is duplicated in the task class\njust move the code that was in the task class (and doing\nsimilar actions) to instead now use a notifier that is\ndirectly contained in the task base class for internal task\ntriggering of internal task events.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 2, 'created': '2014-12-13 02:51:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cd60e418e70951dce8e3984b7410a349f4e891a3', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 3, 'created': '2014-12-13 03:17:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/61c0ad5d68aced967f38030bfdd5241aff6e4e03', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 4, 'created': '2014-12-13 03:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/c33782397969cb6ee800921d394b04b946716a38', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 5, 'created': '2014-12-13 04:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/581d90d854260749201fb1b64cd9ecce4c2187b6', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 6, 'created': '2014-12-13 04:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/eccb30ae62b3e4fd04f12d7cfb6b6dcc1711ded6', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 7, 'created': '2014-12-13 05:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/37faefc3879d86b906bbac246ab87724cab119ba', 'message': 'Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since its likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n'}, {'number': 8, 'created': '2014-12-13 05:59:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9155f75f98a87017407f7eceba3cf3b45f3c2264', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 9, 'created': '2014-12-13 07:44:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e3920580601f7666e3db8eae1f5fa31439e61dc3', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 10, 'created': '2014-12-13 07:48:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1327231fb46033e3d58f6617a2fc6785a6dd8cbf', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 11, 'created': '2014-12-13 21:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b208c2d97ee20d480c33092a66176f7d284809ee', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 12, 'created': '2014-12-14 02:07:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/79f8cbba3ef11e750fba4d901e63295f34888f2b', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 13, 'created': '2014-12-14 02:09:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/35a770453b0b7bb3b190d48f6ccc2a2a4b8dc97d', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 14, 'created': '2014-12-14 02:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/094e5f0fa1d48befdcade5694ffb8d5073e85aa9', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}, {'number': 15, 'created': '2014-12-14 03:09:05.000000000', 'files': ['taskflow/engines/worker_based/server.py', 'doc/source/workers.rst', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/engines/action_engine/actions/task.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/types/notifier.py', 'taskflow/engines/action_engine/executor.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/task.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/tests/unit/test_progress.py', 'taskflow/tests/unit/test_notifier.py', 'taskflow/tests/unit/test_task.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/tests/unit/worker_based/test_endpoint.py', 'taskflow/tests/unit/worker_based/test_server.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1f4dd72e6e859f3820de5e68ece2d09c15a18b70', 'message': ""Use the notifier type in the task class/module directly\n\nInstead of having code that is some what like the notifier\ncode we already have, but is duplicated and is slightly different\nin the task class just move the code that was in the task class (and\ndoing similar actions) to instead now use a notifier that is directly\ncontained in the task base class for internal task triggering of\ninternal task events.\n\nBreaking change: alters the capabilities of the task to process\nnotifications itself, most actions now must go through the task\nnotifier property and instead use that (update_progress still exists\nas a common utility method, since it's likely the most common type\nof notification that will be used).\n\nRemoves the following methods from task base class (as they are\nno longer needed with a notifier attribute):\n\n- trigger (replaced with notifier.notify)\n- autobind (removed, not replaced, can be created by the user\n            of taskflow in a simple manner, without requiring\n            functionality in taskflow)\n- bind (replaced with notifier.register)\n- unbind (replaced with notifier.unregister)\n- listeners_iter (replaced with notifier.listeners_iter)\n\nDue to this change we can now also correctly proxy back events from\nremote tasks to the engine for correct proxying back to the original\ntask.\n\nFixes bug 1370766\n\nChange-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6\n""}]",0,141534,1f4dd72e6e859f3820de5e68ece2d09c15a18b70,31,2,15,1297,,,0,"Use the notifier type in the task class/module directly

Instead of having code that is some what like the notifier
code we already have, but is duplicated and is slightly different
in the task class just move the code that was in the task class (and
doing similar actions) to instead now use a notifier that is directly
contained in the task base class for internal task triggering of
internal task events.

Breaking change: alters the capabilities of the task to process
notifications itself, most actions now must go through the task
notifier property and instead use that (update_progress still exists
as a common utility method, since it's likely the most common type
of notification that will be used).

Removes the following methods from task base class (as they are
no longer needed with a notifier attribute):

- trigger (replaced with notifier.notify)
- autobind (removed, not replaced, can be created by the user
            of taskflow in a simple manner, without requiring
            functionality in taskflow)
- bind (replaced with notifier.register)
- unbind (replaced with notifier.unregister)
- listeners_iter (replaced with notifier.listeners_iter)

Due to this change we can now also correctly proxy back events from
remote tasks to the engine for correct proxying back to the original
task.

Fixes bug 1370766

Change-Id: Ic9dfef516d72e6e32e71dda30a1cb3522c9e0be6
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/34/141534/1 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/server.py', 'taskflow/tests/unit/worker_based/test_protocol.py', 'taskflow/engines/action_engine/actions/task.py', 'taskflow/tests/unit/worker_based/test_executor.py', 'taskflow/tests/unit/worker_based/test_message_pump.py', 'taskflow/types/notifier.py', 'taskflow/engines/action_engine/executor.py', 'taskflow/engines/worker_based/executor.py', 'taskflow/task.py', 'taskflow/engines/worker_based/endpoint.py', 'taskflow/tests/unit/test_progress.py', 'taskflow/tests/unit/test_task.py', 'taskflow/engines/worker_based/protocol.py', 'taskflow/tests/unit/worker_based/test_endpoint.py', 'taskflow/tests/unit/worker_based/test_server.py']",15,ec1f02abd0dc675649d5d7a7c9ee7c9a0a93bb86,bug/1370766,"from taskflow import task as task_atom bundle = server.Server._parse_request(**request) task_cls, task_name, action, task_args = bundle self.assertEqual((task_cls, task_name, action, task_args), (self.task.name, self.task.name, self.task_action, dict(arguments=self.task_args))) bundle = server.Server._parse_request(**request) task_cls, task_name, action, task_args = bundle self.assertEqual((task_cls, task_name, action, task_args), (self.task.name, self.task.name, 'revert', dict(arguments=self.task_args, bundle = server.Server._parse_request(**request) task_cls, task_name, action, task_args = bundle self.assertEqual((task_cls, task_name, action, task_args), (self.task.name, self.task.name, 'revert', dict(arguments=self.task_args, bundle = server.Server._parse_request(**request) task_cls, task_name, action, task_args = bundle (task_cls, task_name, action, task_args), (self.task.name, self.task.name, 'revert', dict(arguments=self.task_args, mock.call.Response(pr.EVENT, details={'progress': 0.0}, event_type=task_atom.EVENT_UPDATE_PROGRESS), mock.call.Response(pr.EVENT, details={'progress': 1.0}, event_type=task_atom.EVENT_UPDATE_PROGRESS), self.assertEqual(master_mock_calls, self.master_mock.mock_calls)"," task_cls, action, task_args = server.Server._parse_request(**request) self.assertEqual((task_cls, action, task_args), (self.task.name, self.task_action, dict(task_name=self.task.name, arguments=self.task_args))) task_cls, action, task_args = server.Server._parse_request(**request) self.assertEqual((task_cls, action, task_args), (self.task.name, 'revert', dict(task_name=self.task.name, arguments=self.task_args, task_cls, action, task_args = server.Server._parse_request(**request) self.assertEqual((task_cls, action, task_args), (self.task.name, 'revert', dict(task_name=self.task.name, arguments=self.task_args, task_cls, action, task_args = server.Server._parse_request(**request) (task_cls, action, task_args), (self.task.name, 'revert', dict(task_name=self.task.name, arguments=self.task_args, mock.call.Response(pr.PROGRESS, progress=0.0, event_data={}), mock.call.Response(pr.PROGRESS, progress=1.0, event_data={}), self.assertEqual(self.master_mock.mock_calls, master_mock_calls)",376,359
openstack%2Fkeystone~master~I13ce159cbe9739d4bf5d321fc4bd069245f32734,openstack/keystone,master,I13ce159cbe9739d4bf5d321fc4bd069245f32734,HEAD responses should return same status as GET,MERGED,2014-07-02 00:01:21.000000000,2014-12-14 04:29:53.000000000,2014-07-10 20:27:38.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 220}, {'_account_id': 1091}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 9098}, {'_account_id': 9142}, {'_account_id': 9751}]","[{'number': 1, 'created': '2014-07-02 00:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/cead14f9d86771959595d4ade9c8d74bdc4b7ac5', 'message': 'HEAD responses should return same status as GET\n\nAccording to the HTTP spec, a HEAD request should return the same\nstatus and headers as the GET request (including content-type and\ncontent-length). The HEAD request simply strips out the body and\nreturns no body. Any case where HEAD routing returned a different\nstatus code than GET, now returns the same status and headers.\n\nAny case where HEAD was supported where GET was not supported now\nsupports both GET and HEAD.\n\nThe wsgi.render_response code now handles HEAD appropriately and\nwill maintain headers while enforcing no body data is returned.\n\nThe bulk of this change is to support the same behavior between\ndeploying Keystone under eventlet and under HTTPD + mod_wsgi. In\nthe case of deploying under HTTPD + mod_wsgi, there are cases\nwhere mod_wsgi will turn a HEAD request into a GET request to\nensure that the proper response is rendered. With these changes\nall HEAD responses will respond in the same manner under either\neventlet or mod_wsgi.\n\nChange-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734\nCloses-Bug: #1334368\n'}, {'number': 2, 'created': '2014-07-03 15:50:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/0e58106636b84ed843bd594c559ed88739375174', 'message': 'HEAD responses should return same status as GET\n\nAccording to the HTTP spec, a HEAD request should return the same\nstatus and headers as the GET request (including content-type and\ncontent-length). The HEAD request simply strips out the body and\nreturns no body. Any case where HEAD routing returned a different\nstatus code than GET, now returns the same status and headers.\n\nAny case where HEAD was supported where GET was not supported now\nsupports both GET and HEAD.\n\nThe wsgi.render_response code now handles HEAD appropriately and\nwill maintain headers while enforcing no body data is returned.\n\nThe bulk of this change is to support the same behavior between\ndeploying Keystone under eventlet and under HTTPD + mod_wsgi. In\nthe case of deploying under HTTPD + mod_wsgi, there are cases\nwhere mod_wsgi will turn a HEAD request into a GET request to\nensure that the proper response is rendered. With these changes\nall HEAD responses will respond in the same manner under either\neventlet or mod_wsgi.\n\nChange-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734\nCloses-Bug: #1334368\n'}, {'number': 3, 'created': '2014-07-03 19:59:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/b5f297c54a3b5f39a7e7d82108e743492912d320', 'message': 'HEAD responses should return same status as GET\n\nAccording to the HTTP spec, a HEAD request should return the same\nstatus and headers as the GET request (including content-type and\ncontent-length). The HEAD request simply strips out the body and\nreturns no body. Any case where HEAD routing returned a different\nstatus code than GET, now returns the same status and headers.\n\nAny case where HEAD was supported where GET was not supported now\nsupports both GET and HEAD.\n\nThe wsgi.render_response code now handles HEAD appropriately and\nwill maintain headers while enforcing no body data is returned.\n\nThe bulk of this change is to support the same behavior between\ndeploying Keystone under eventlet and under HTTPD + mod_wsgi. In\nthe case of deploying under HTTPD + mod_wsgi, there are cases\nwhere mod_wsgi will turn a HEAD request into a GET request to\nensure that the proper response is rendered. With these changes\nall HEAD responses will respond in the same manner under either\neventlet or mod_wsgi.\n\nChange-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734\nCloses-Bug: #1334368\n'}, {'number': 4, 'created': '2014-07-03 21:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e0f57c30ec05f11b6ef658a7a66b8d2864c3c5cc', 'message': 'HEAD responses should return same status as GET\n\nAccording to the HTTP spec, a HEAD request should return the same\nstatus and headers as the GET request (including content-type and\ncontent-length). The HEAD request simply strips out the body and\nreturns no body. Any case where HEAD routing returned a different\nstatus code than GET, now returns the same status and headers.\n\nAny case where HEAD was supported where GET was not supported now\nsupports both GET and HEAD.\n\nThe wsgi.render_response code now handles HEAD appropriately and\nwill maintain headers while enforcing no body data is returned.\n\nThe bulk of this change is to support the same behavior between\ndeploying Keystone under eventlet and under HTTPD + mod_wsgi. In\nthe case of deploying under HTTPD + mod_wsgi, there are cases\nwhere mod_wsgi will turn a HEAD request into a GET request to\nensure that the proper response is rendered. With these changes\nall HEAD responses will respond in the same manner under either\neventlet or mod_wsgi.\n\nChange-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734\nCloses-Bug: #1334368\n'}, {'number': 5, 'created': '2014-07-09 05:38:05.000000000', 'files': ['keystone/contrib/endpoint_filter/routers.py', 'keystone/auth/controllers.py', 'keystone/tests/test_wsgi.py', 'keystone/auth/routers.py', 'keystone/token/routers.py', 'keystone/tests/test_v3_auth.py', 'keystone/common/wsgi.py', 'keystone/identity/routers.py', 'keystone/tests/test_v3.py', 'keystone/token/controllers.py', 'keystone/tests/test_content_types.py', 'keystone/assignment/routers.py', 'keystone/trust/routers.py', 'keystone/tests/test_v3_identity.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/82101a36d348ad0c3de10f455878828f4263ffe2', 'message': 'HEAD responses should return same status as GET\n\nAccording to the HTTP spec, a HEAD request should return the same\nstatus and headers as the GET request (including content-type and\ncontent-length). The HEAD request simply strips out the body and\nreturns no body. Any case where HEAD routing returned a different\nstatus code than GET, now returns the same status and headers.\n\nAny case where HEAD was supported where GET was not supported now\nsupports both GET and HEAD.\n\nThe wsgi.render_response code now handles HEAD appropriately and\nwill maintain headers while enforcing no body data is returned.\n\nThe bulk of this change is to support the same behavior between\ndeploying Keystone under eventlet and under HTTPD + mod_wsgi. In\nthe case of deploying under HTTPD + mod_wsgi, there are cases\nwhere mod_wsgi will turn a HEAD request into a GET request to\nensure that the proper response is rendered. With these changes\nall HEAD responses will respond in the same manner under either\neventlet or mod_wsgi.\n\nChange-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734\nCloses-Bug: #1334368\n'}]",40,104026,82101a36d348ad0c3de10f455878828f4263ffe2,49,16,5,2903,,,0,"HEAD responses should return same status as GET

According to the HTTP spec, a HEAD request should return the same
status and headers as the GET request (including content-type and
content-length). The HEAD request simply strips out the body and
returns no body. Any case where HEAD routing returned a different
status code than GET, now returns the same status and headers.

Any case where HEAD was supported where GET was not supported now
supports both GET and HEAD.

The wsgi.render_response code now handles HEAD appropriately and
will maintain headers while enforcing no body data is returned.

The bulk of this change is to support the same behavior between
deploying Keystone under eventlet and under HTTPD + mod_wsgi. In
the case of deploying under HTTPD + mod_wsgi, there are cases
where mod_wsgi will turn a HEAD request into a GET request to
ensure that the proper response is rendered. With these changes
all HEAD responses will respond in the same manner under either
eventlet or mod_wsgi.

Change-Id: I13ce159cbe9739d4bf5d321fc4bd069245f32734
Closes-Bug: #1334368
",git fetch https://review.opendev.org/openstack/keystone refs/changes/26/104026/5 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/contrib/endpoint_filter/routers.py', 'keystone/auth/controllers.py', 'keystone/tests/test_wsgi.py', 'keystone/common/router.py', 'keystone/auth/routers.py', 'keystone/contrib/admin_crud/core.py', 'keystone/token/routers.py', 'keystone/tests/test_associate_project_endpoint_extension.py', 'keystone/tests/test_v3_auth.py', 'keystone/common/wsgi.py', 'keystone/identity/routers.py', 'keystone/tests/test_v3.py', 'keystone/token/controllers.py', 'keystone/tests/test_content_types.py', 'keystone/assignment/routers.py', 'keystone/trust/routers.py', 'keystone/contrib/ec2/routers.py', 'keystone/tests/test_v3_identity.py', 'keystone/contrib/stats/core.py']",19,cead14f9d86771959595d4ade9c8d74bdc4b7ac5,bug/1334368," conditions=dict(method=['GET', 'HEAD']))", conditions=dict(method=['GET'])),126,87
openstack%2Fmurano~master~Ib83d58459ebceee9576115b346bedcd510729f33,openstack/murano,master,Ib83d58459ebceee9576115b346bedcd510729f33,test ci,ABANDONED,2014-12-14 03:50:12.000000000,2014-12-14 04:26:51.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-14 03:50:12.000000000', 'files': ['test.ci'], 'web_link': 'https://opendev.org/openstack/murano/commit/1152b582c8e8d2f9162cf035e0ea5c2357839296', 'message': 'test ci\n\nChange-Id: Ib83d58459ebceee9576115b346bedcd510729f33\n'}]",0,141617,1152b582c8e8d2f9162cf035e0ea5c2357839296,5,2,1,7600,,,0,"test ci

Change-Id: Ib83d58459ebceee9576115b346bedcd510729f33
",git fetch https://review.opendev.org/openstack/murano refs/changes/17/141617/1 && git format-patch -1 --stdout FETCH_HEAD,['test.ci'],1,1152b582c8e8d2f9162cf035e0ea5c2357839296,,hello ,,1,0
openstack%2Fmurano-dashboard~master~I89b77605f83b7398d6f29cc2935d8ba0328c4311,openstack/murano-dashboard,master,I89b77605f83b7398d6f29cc2935d8ba0328c4311,test ci,ABANDONED,2014-12-14 03:44:34.000000000,2014-12-14 04:26:44.000000000,,"[{'_account_id': 3}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-14 03:44:34.000000000', 'files': ['test.ci'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/db3c0443a4465ebb08dc95ecd1161c2787f327c6', 'message': 'test ci\n\nChange-Id: I89b77605f83b7398d6f29cc2935d8ba0328c4311\n'}]",0,141616,db3c0443a4465ebb08dc95ecd1161c2787f327c6,10,3,1,7600,,,0,"test ci

Change-Id: I89b77605f83b7398d6f29cc2935d8ba0328c4311
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/16/141616/1 && git format-patch -1 --stdout FETCH_HEAD,['test.ci'],1,db3c0443a4465ebb08dc95ecd1161c2787f327c6,,hello ,,1,0
openstack%2Ftricircle~master~Icc881edfac618afb58bfaec4ce37c3d2252cd384,openstack/tricircle,master,Icc881edfac618afb58bfaec4ce37c3d2252cd384,Cinder proxy paging,MERGED,2014-12-14 03:38:47.000000000,2014-12-14 03:39:39.000000000,2014-12-14 03:39:39.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-14 03:38:47.000000000', 'files': ['cinderproxy/cinder/volume/cinder_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/cfafc8d47ab96e0f814e167ea1f5be461b43c068', 'message': 'Cinder proxy paging\n\ncinder proxy paging\n\nChange-Id: Icc881edfac618afb58bfaec4ce37c3d2252cd384\n'}]",0,141615,cfafc8d47ab96e0f814e167ea1f5be461b43c068,6,2,1,9684,,,0,"Cinder proxy paging

cinder proxy paging

Change-Id: Icc881edfac618afb58bfaec4ce37c3d2252cd384
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/15/141615/1 && git format-patch -1 --stdout FETCH_HEAD,['cinderproxy/cinder/volume/cinder_proxy.py'],1,cfafc8d47ab96e0f814e167ea1f5be461b43c068,," cfg.IntOpt('pagination_limit', default=50, help='pagination limit query for volume between cascading' 'and cascaded volume'), page_limit = CONF.pagination_limit LOG.debug(_('cascade info, pagination_limit: %s'), page_limit) marker = None volumes = [] while True: search_opt = {'all_tenants': True, 'sort_key': 'updated_at', 'sort_dir': 'desc', 'marker': marker, 'limit': page_limit, } vols = cinderClient.volumes.list(search_opts=search_opt) LOG.debug(_('cascade info, pagination volumes query.marker' '%s, vols:%s'), marker, vols) if (vols): volumes.extend(vols) marker = vols[-1]._info['id'] LOG.debug(_('cascade info, marker: %s'), marker) continue else: break"," search_opt = {'all_tenants': True, 'sort_key': 'updated_at', 'sort_dir': 'desc', 'limit': '50', } volumes = cinderClient.volumes.list(search_opts=search_opt)",25,6
openstack%2Ftaskflow~master~I8369dbb61f73a60932d9e15c8b4d06db249ea38e,openstack/taskflow,master,I8369dbb61f73a60932d9e15c8b4d06db249ea38e,Use a tiny clamp helper to clamp the 'on_progress' value,MERGED,2014-12-13 07:04:55.000000000,2014-12-14 03:06:15.000000000,2014-12-14 03:06:15.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-13 07:04:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/4dfc2436e8f0e85737285541a223b480e682c70d', 'message': 'Use a tiny clamp helper to clamp the on_progress value\n\nAdd a misc clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n'}, {'number': 2, 'created': '2014-12-13 07:44:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/aeed068fbf29796f0e422f6cbc0776003679f3e5', 'message': 'Use a tiny clamp helper to clamp the on_progress value\n\nAdd a misc clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n'}, {'number': 3, 'created': '2014-12-13 07:48:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/9edfac901bbba792c0b2e2a833f7092f19357e61', 'message': 'Use a tiny clamp helper to clamp the on_progress value\n\nAdd a misc clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n'}, {'number': 4, 'created': '2014-12-13 07:54:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/8b8196bf8232c9cd453c1fe74c7d689315470396', 'message': 'Use a tiny clamp helper to clamp the on_progress value\n\nAdd a misc.clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n'}, {'number': 5, 'created': '2014-12-13 21:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/35768c6bcbaaeaf99a4a55cd30c569b32c0c948e', 'message': 'Use a tiny clamp helper to clamp the on_progress value\n\nAdd a misc.clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n'}, {'number': 6, 'created': '2014-12-14 01:13:08.000000000', 'files': ['taskflow/task.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/cdfd8ece61c3340a3de73005ea7b44d0383223fd', 'message': ""Use a tiny clamp helper to clamp the 'on_progress' value\n\nAdd a misc.clamp function that will clamp a value to a given\nrange (it can also call a callback if clamping occurs). Use it\nto clamp the progress value that was previously clamped with\na set of customized logic that can now be replaced with a more\ngeneralized logic that can be shared.\n\nChange-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e\n""}]",0,141546,cdfd8ece61c3340a3de73005ea7b44d0383223fd,15,2,6,1297,,,0,"Use a tiny clamp helper to clamp the 'on_progress' value

Add a misc.clamp function that will clamp a value to a given
range (it can also call a callback if clamping occurs). Use it
to clamp the progress value that was previously clamped with
a set of customized logic that can now be replaced with a more
generalized logic that can be shared.

Change-Id: I8369dbb61f73a60932d9e15c8b4d06db249ea38e
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/46/141546/5 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/tests/unit/test_utils.py', 'taskflow/utils/misc.py']",3,4dfc2436e8f0e85737285541a223b480e682c70d,,"def clamp(value, minimum, maximum, on_clamped=None): """"""Clamps a value to ensure its >= minimum and <= maximum."""""" if minimum > maximum: raise ValueError(""Provided minimum '%s' must be less than or equal to"" "" the provided maximum '%s'"" % (minimum, maximum)) if value > maximum: value = maximum if on_clamped is not None: on_clamped() if value < minimum: value = minimum if on_clamped is not None: on_clamped() return value ",,53,7
openstack%2Fneutron~master~Ia4e6659b8b59732d88cd603b0e6c630fad37aae5,openstack/neutron,master,Ia4e6659b8b59732d88cd603b0e6c630fad37aae5,Enforce log hints,MERGED,2014-12-07 21:00:39.000000000,2014-12-14 02:58:35.000000000,2014-12-14 02:58:34.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 11822}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-07 21:00:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c97f76adafcccb0555ab8d1fe294a03bf5dcf97d', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}, {'number': 2, 'created': '2014-12-07 21:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a01a89d9387df6dca537aed1f05d4d3088a436dd', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}, {'number': 3, 'created': '2014-12-07 22:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff4faa94144f2191531aa1376bbc4393d6945d11', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}, {'number': 4, 'created': '2014-12-07 22:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/43302a04a1b5ba93fa31d898e3e8e08cbcd59048', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}, {'number': 5, 'created': '2014-12-08 15:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/68efb7d776c56ad76d9e2c8b425fc59c631fa4e8', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}, {'number': 6, 'created': '2014-12-08 18:59:48.000000000', 'files': ['neutron/tests/unit/test_hacking.py', 'neutron/wsgi.py', 'neutron/quota.py', 'neutron/auth.py', 'neutron/service.py', 'neutron/manager.py', 'neutron/hacking/checks.py', 'neutron/context.py', 'neutron/policy.py', 'neutron/tests/unit/nec/stub_ofc_driver.py', 'neutron/tests/unit/bigswitch/fake_server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/32ef5da4882ab583c2bd7cd04e052b67f11faf92', 'message': 'Enforce log hints\n\nThis change enforces log hints use and removes debug level log\ntranslation, modifications are validated through a hacking rule\nand the change respects logging guidelines.\n\nChange-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5\nCloses-bug: #1320867\n'}]",1,139881,32ef5da4882ab583c2bd7cd04e052b67f11faf92,148,34,6,8124,,,0,"Enforce log hints

This change enforces log hints use and removes debug level log
translation, modifications are validated through a hacking rule
and the change respects logging guidelines.

Change-Id: Ia4e6659b8b59732d88cd603b0e6c630fad37aae5
Closes-bug: #1320867
",git fetch https://review.opendev.org/openstack/neutron refs/changes/81/139881/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/wsgi.py', 'neutron/auth.py', 'neutron/quota.py', 'neutron/service.py', 'neutron/manager.py', 'neutron/hacking/checks.py', 'neutron/context.py', 'neutron/policy.py', 'neutron/tests/unit/nec/stub_ofc_driver.py', 'neutron/tests/unit/bigswitch/fake_server.py']",10,c97f76adafcccb0555ab8d1fe294a03bf5dcf97d,bug/1320867," LOG.debug(""Request: action=%(action)s, uri=%(uri)r, "" ""body=%(body)s, headers=%(headers)s"","," LOG.debug(_(""Request: action=%(action)s, uri=%(uri)r, "" ""body=%(body)s, headers=%(headers)s""),",73,122
openstack%2Fpbr~feature%2F0.10~I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,openstack/pbr,feature/0.10,I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,Prefix git suffixes with + instead of .,MERGED,2014-12-14 00:20:57.000000000,2014-12-14 02:25:39.000000000,2014-12-14 02:25:38.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 10035}]","[{'number': 1, 'created': '2014-12-14 00:20:57.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/1c89d18b6beecade6b7c9007b324e8cf0f486e22', 'message': ""Prefix git suffixes with + instead of .\n\nsetuptools 8.0 enforces the accepted version of PEP440, which means\nthat 1.2.3.g123456 is now sorted before 1.0. Forget for a second that\nunder no obvious human inspection this makes sense, it is now the law of\nthe land and we must comply.\n\nI swear to god I'm going to start coding in Go.\n\nChange-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551\n(cherry picked from commit fafd6c4db07789b2d378fdb5ceda89115d2abe30)\n""}]",1,141606,1c89d18b6beecade6b7c9007b324e8cf0f486e22,8,4,1,5263,,,0,"Prefix git suffixes with + instead of .

setuptools 8.0 enforces the accepted version of PEP440, which means
that 1.2.3.g123456 is now sorted before 1.0. Forget for a second that
under no obvious human inspection this makes sense, it is now the law of
the land and we must comply.

I swear to god I'm going to start coding in Go.

Change-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551
(cherry picked from commit fafd6c4db07789b2d378fdb5ceda89115d2abe30)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/06/141606/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,1c89d18b6beecade6b7c9007b324e8cf0f486e22,setuptools-8," return ""%s.dev%s+g%s"" % (pre_version, _get_revno(git_dir), sha) ['describe', '--always'], git_dir).replace('-', '.').replace('.g', '+g')"," return ""%s.dev%s.g%s"" % (pre_version, _get_revno(git_dir), sha) ['describe', '--always'], git_dir).replace('-', '.')",3,2
openstack%2Fpbr~feature%2F0.10~I1758a7afa1cab572590112567e0cac2920d94506,openstack/pbr,feature/0.10,I1758a7afa1cab572590112567e0cac2920d94506,Make a PEP440-ish version for non-tagged repos,ABANDONED,2014-12-14 00:20:57.000000000,2014-12-14 01:22:12.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-12-14 00:20:57.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/c9dd9361fdcd63e43e01b8624acc57a4c9a775c7', 'message': 'Make a PEP440-ish version for non-tagged repos\n\nIf a repo has no tags, it produces a git short-sha, which can be\nconfusing.\n\nChange-Id: I1758a7afa1cab572590112567e0cac2920d94506\n(cherry picked from commit bab6479532fd9eb76acdda3bbfaa3ccae835eab7)\n'}]",0,141607,c9dd9361fdcd63e43e01b8624acc57a4c9a775c7,4,3,1,5263,,,0,"Make a PEP440-ish version for non-tagged repos

If a repo has no tags, it produces a git short-sha, which can be
confusing.

Change-Id: I1758a7afa1cab572590112567e0cac2920d94506
(cherry picked from commit bab6479532fd9eb76acdda3bbfaa3ccae835eab7)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/07/141607/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,c9dd9361fdcd63e43e01b8624acc57a4c9a775c7,setuptools-8," raw_version = _run_git_command( if '.' not in raw_version: raw_version = ""0.0.0.%s+g%s"" % ( _get_revno(git_dir), raw_version) return raw_version", return _run_git_command(,5,1
openstack%2Ftempest~master~Ia7383114c17e4d901c81b8e7b6b2822a7ec4f908,openstack/tempest,master,Ia7383114c17e4d901c81b8e7b6b2822a7ec4f908,Skip IPv6 scenarios for baremetal,MERGED,2014-12-12 18:39:35.000000000,2014-12-14 01:11:44.000000000,2014-12-14 01:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 18:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/553af7b28eb476235f44348ab36757d56f6b8ff8', 'message': 'Skip IPv6 scenarios for baremetal\n\nThese tests attempt to create two isolated tenant networks and\nboot servers on each.  Baremetal relies on flat networking that\ndoes not support network isolation, so these tests should be skipped\nin that case.\n\nChange-Id: Ia7383114c17e4d901c81b8e7b6b2822a7ec4f908\n'}, {'number': 2, 'created': '2014-12-12 19:08:18.000000000', 'files': ['tempest/scenario/test_network_v6.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ab6106ddaa5b58a423277fcdfc57ad85c31f39ce', 'message': 'Skip IPv6 scenarios for baremetal\n\nThese tests attempt to create two isolated tenant networks and\nboot servers on each.  Baremetal relies on flat networking that\ndoes not support network isolation, so these tests should be skipped\nin that case.\n\nChange-Id: Ia7383114c17e4d901c81b8e7b6b2822a7ec4f908\n'}]",0,141456,ab6106ddaa5b58a423277fcdfc57ad85c31f39ce,13,4,2,1420,,,0,"Skip IPv6 scenarios for baremetal

These tests attempt to create two isolated tenant networks and
boot servers on each.  Baremetal relies on flat networking that
does not support network isolation, so these tests should be skipped
in that case.

Change-Id: Ia7383114c17e4d901c81b8e7b6b2822a7ec4f908
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/141456/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_v6.py'],1,553af7b28eb476235f44348ab36757d56f6b8ff8,clean_enabled, if CONF.baremetal.driver_enabled: msg = ('Baremetal does not currently support network isolation') cls.enabled = False raise cls.skipException(msg) ,,5,0
openstack%2Fopenstack-manuals~master~I1f1860435c4068174bd899edb9866c824e6dd51e,openstack/openstack-manuals,master,I1f1860435c4068174bd899edb9866c824e6dd51e,Telemetry config changes update,MERGED,2014-12-12 12:36:54.000000000,2014-12-14 01:05:57.000000000,2014-12-14 01:05:56.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6772}, {'_account_id': 9562}]","[{'number': 1, 'created': '2014-12-12 12:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d0d3eb34066bf43c89081288980b35454255e026', 'message': 'Telemetry config changes update\n\nUpdate the ceilometer-conf-changes.xml file to contain the new config\nchanges that were introduced in the Kilo release so far.\n\nChange-Id: I1f1860435c4068174bd899edb9866c824e6dd51e\n'}, {'number': 2, 'created': '2014-12-12 15:08:01.000000000', 'files': ['doc/common/tables/ceilometer-conf-changes.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/491f990973257d8c7203fccafd078ed4ee2212c8', 'message': 'Telemetry config changes update\n\nUpdate the ceilometer-conf-changes.xml file to contain the new config\nchanges that were introduced in the Kilo release so far.\n\nChange-Id: I1f1860435c4068174bd899edb9866c824e6dd51e\n'}]",0,141351,491f990973257d8c7203fccafd078ed4ee2212c8,11,4,2,9562,,,0,"Telemetry config changes update

Update the ceilometer-conf-changes.xml file to contain the new config
changes that were introduced in the Kilo release so far.

Change-Id: I1f1860435c4068174bd899edb9866c824e6dd51e
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/51/141351/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/common/tables/ceilometer-conf-changes.xml'],1,d0d3eb34066bf43c89081288980b35454255e026,ceilo-conf-change-update,"<section xmlns=""http://docbook.org/ns/docbook"" version=""5.0"" xml:id=""ceilometer-conf-changes-master""> <title>New, updated and deprecated options in Kilo for Telemetry</title> <td>[DEFAULT] policy_dirs = ['policy.d']</td> <td>(MultiStrOpt) Directories where policy configuration files are stored. They can be relative to any directory in the search path defined by the config_dir option, or absolute paths. The file defined by policy_file must exist for these directories to be searched.</td> <td>[alarm] evaluation_service = default</td> <td>(StrOpt) Driver to use for alarm evaluation service. DEPRECATED: ""singleton"" and ""partitioned"" alarm evaluator services will be removed in Kilo in favour of the default alarm evaluation service using tooz for partitioning.</td> <td>[database] db2nosql_resource_id_maxlen = 512</td> <td>(IntOpt) The max length of resources id in DB2 nosql, the value should be larger than len(hostname) * 2 as compute node's resource id is &lt;hostname&gt;_&lt;nodename&gt;.</td> <td>[database] event_connection = None</td> <td>(StrOpt) The connection string used to connect to the event database. (if unset, connection is used)</td> <td>[database] mongodb_replica_set = </td> <td>(StrOpt) The name of the replica set which is used to connect to MongoDB database. If it is set, MongoReplicaSetClient will be used instead of MongoClient.</td> <td>[dispatcher_http] cadf_only = False</td> <td>(BoolOpt) The flag which indicates if only cadf message should be posted. If false, all meters will be posted.</td> <td>[dispatcher_http] target = </td> <td>(StrOpt) The target where the http request will be sent to. If this is not set, no data will be posted. For example: target = http://hostname:1234/path</td> <td>[dispatcher_http] timeout = 5</td> <td>(IntOpt) The max time in second to wait for a request to timeout.</td> <td>[vmware] host_port = 443</td> <td>(IntOpt) Port of the VMware Vsphere host.</td>","<section xmlns=""http://docbook.org/ns/docbook"" version=""5.0"" xml:id=""ceilometer-conf-changes-juno""> <title>New, updated and deprecated options in Juno for Telemetry</title> <td>[DEFAULT] api_paste_config = api_paste.ini</td> <td>(StrOpt) Configuration file for WSGI definition of API.</td> <td>[DEFAULT] enable_new_services = True</td> <td>(BoolOpt) Services to be added to the available pool on create</td> <td>[DEFAULT] fatal_exception_format_errors = False</td> <td>(BoolOpt) Make exception message format errors fatal</td> <td>[DEFAULT] glance_page_size = 0</td> <td>(IntOpt) Number of items to request in each paginated Glance API request (parameter used by glancecelient). If this is less than or equal to 0, page size is not specified (default value in glanceclient is used).</td> <td>[DEFAULT] instance_name_template = instance-%08x</td> <td>(StrOpt) Template string to be used to generate instance names</td> <td>[DEFAULT] instance_usage_audit_period = month</td> <td>(StrOpt) Time period to generate instance usages for. Time period must be hour, day, month or year</td> <td>[DEFAULT] ironic_exchange = ironic</td> <td>(StrOpt) Exchange name for Ironic notifications.</td> <td>[DEFAULT] keystone_control_exchange = keystone</td> <td>(StrOpt) Exchange name for Keystone notifications.</td> <td>[DEFAULT] monkey_patch = False</td> <td>(BoolOpt) Whether to log monkey patching</td> </tr> <tr> <td>[DEFAULT] monkey_patch_modules = nova.api.ec2.cloud:nova.notifications.notify_decorator, nova.compute.api:nova.notifications.notify_decorator</td> <td>(ListOpt) List of modules/decorators to monkey patch</td> </tr> <tr> <td>[DEFAULT] network_api_class = nova.network.api.API</td> <td>(StrOpt) The full class name of the network API class to use</td> </tr> <tr> <td>[DEFAULT] nova_http_log_debug = False</td> <td>(BoolOpt) Allow novaclient's debug log output.</td> </tr> <tr> <td>[DEFAULT] password_length = 12</td> <td>(IntOpt) Length of generated instance admin passwords</td> </tr> <tr> <td>[DEFAULT] qpid_receiver_capacity = 1</td> <td>(IntOpt) The number of prefetched messages held by receiver.</td> </tr> <tr> <td>[DEFAULT] rabbit_login_method = AMQPLAIN</td> <td>(StrOpt) the RabbitMQ login method</td> </tr> <tr> <td>[DEFAULT] rootwrap_config = /etc/ceilometer/rootwrap.conf</td> <td>(StrOpt) Path to the rootwrap configuration file touse for running commands as root</td> </tr> <tr> <td>[DEFAULT] sahara_control_exchange = sahara</td> <td>(StrOpt) Exchange name for Data Processing notifications</td> </tr> <tr> <td>[DEFAULT] snapshot_name_template = snapshot-%s</td> <td>(StrOpt) Template string to be used to generate snapshot names</td> </tr> <tr> <td>[DEFAULT] transport_url = None</td> <td>(StrOpt) A URL representing the messaging driver to use and its full configuration. If not set, we fall back to the rpc_backend option and driver specific configuration.</td> </tr> <tr> <td>[DEFAULT] trove_control_exchange = trove</td> <td>(StrOpt) Exchange name for DBaaS notifications</td> </tr> <tr> <td>[alarm] project_alarm_quota = None</td> <td>(IntOpt) Maximum number of alarms defined for a project.</td> </tr> <tr> <td>[alarm] rest_notifier_max_retries = 0</td> <td>(IntOpt) Number of retries for REST notifier</td> </tr> <tr> <td>[alarm] user_alarm_quota = None</td> <td>(IntOpt) Maximum number of alarms defined for a user.</td> </tr> <tr> <td>[api] enable_reverse_dns_lookup = False</td> <td>(BoolOpt) Set it to False if your environment does not need or have dns server, otherwise it will delay the response from api.</td> </tr> <tr> <td>[api] pecan_debug = False</td> <td>(BoolOpt) Toggle Pecan Debug Middleware. Defaults to global debug value.</td> </tr> <tr> <td>[central] partitioning_group_prefix = None</td> <td>(StrOpt) Work-load partitioning group prefix. Use only if you want to run multiple central agents with different config files. For each sub-group of the central agent pool with the same partitioning_group_prefix a disjoint subset of pollsters should be loaded.</td> </tr> <tr> <td>[collector] requeue_sample_on_dispatcher_error = False</td> <td>(BoolOpt) Requeue the sample on the collector sample queue when the collector fails to dispatch it. This is only valid if the sample come from the notifier publisher</td> </tr> <tr> <td>[compute] workload_partitioning = False</td> <td>(BoolOpt) Enable work-load partitioning, allowing multiple compute agents to be run simultaneously.</td> </tr> <tr> <td>[coordination] backend_url = None</td> <td>(StrOpt) The backend URL to use for distributed coordination. If left empty, per-deployment central agent and per-host compute agent won't do workload partitioning and will only function correctly if a single instance of that service is running.</td> </tr> <tr> <td>[coordination] heartbeat = 1.0</td> <td>(FloatOpt) Number of seconds between heartbeats for distributed coordination (float)</td> </tr> <tr> <td>[database] alarm_connection = None</td> <td>(StrOpt) The connection string used to connect to the alarm database. (if unset, connection is used)</td> </tr> <tr> <td>[database] db_inc_retry_interval = True</td> <td>(BoolOpt) If True, increases the interval between database connection retries up to db_max_retry_interval.</td> </tr> <tr> <td>[database] db_max_retries = 20</td> <td>(IntOpt) Maximum database connection retries before error is raised. Set to -1 to specify an infinite retry count.</td> </tr> <tr> <td>[database] db_max_retry_interval = 10</td> <td>(IntOpt) If db_inc_retry_interval is set, the maximum seconds between database connection retries.</td> </tr> <tr> <td>[database] db_retry_interval = 1</td> <td>(IntOpt) Seconds between database connection retries.</td> </tr> <tr> <td>[database] metering_connection = None</td> <td>(StrOpt) The connection string used to connect to the meteting database. (if unset, connection is used)</td> </tr> <tr> <td>[database] mysql_sql_mode = TRADITIONAL</td> <td>(StrOpt) The SQL mode to be used for MySQL sessions. This option, including the default, overrides any server-set SQL mode. To use whatever SQL mode is set by the server configuration, set this to no value. Example: mysql_sql_mode=</td> </tr> <tr> <td>[database] sqlite_db = oslo.sqlite</td> <td>(StrOpt) The file name to use with SQLite.</td> </tr> <tr> <td>[database] sqlite_synchronous = True</td> <td>(BoolOpt) If True, SQLite uses synchronous mode.</td> </tr> <tr> <td>[database] use_db_reconnect = False</td> <td>(BoolOpt) Enable the experimental use of database reconnect on connection lost.</td> </tr> <tr> <td>[database] use_tpool = False</td> <td>(BoolOpt) Enable the experimental use of thread pooling for all DB API calls</td> </tr> <tr> <td>[hardware] readonly_user_name = ro_snmp_user</td> <td>(StrOpt) SNMPd user name of all nodes running in the cloud.</td> </tr> <tr> <td>[hardware] readonly_user_password = password</td> <td>(StrOpt) SNMPd password of all the nodes running in the cloud</td> </tr> <tr> <td>[hardware] url_scheme = snmp://</td> <td>(StrOpt) URL scheme to use for hardware nodes</td> </tr> <tr> <td>[ipmi] node_manager_init_retry = 3</td> <td>(IntOpt) Number of retries upon Intel Node Manager initialization failure</td> </tr> <tr> <td>[keystone_authtoken] check_revocations_for_cached = False</td> <td>(BoolOpt) If true, the revocation list will be checked for cached tokens. This requires that PKI tokens are configured on the Keystone server.</td> </tr> <tr> <td>[keystone_authtoken] hash_algorithms = md5</td> <td>(ListOpt) Hash algorithms to use for hashing PKI tokens. This may be a single algorithm or multiple. The algorithms are those supported by Python standard hashlib.new(). The hashes will be tried in the order given, so put the preferred one first for performance. The result of the first hash will be stored in the cache. This will typically be set to multiple values only while migrating from a less secure algorithm to a more secure one. Once all the old tokens are expired this option should be set to a single value for better performance.</td> </tr> <tr> <td>[keystone_authtoken] identity_uri = None</td> <td>(StrOpt) Complete admin Identity API endpoint. This should specify the unversioned root endpoint e.g. https://localhost:35357/</td> </tr> <tr> <td>[notification] messaging_urls = []</td> <td>(MultiStrOpt) Messaging URLs to listen for notifications. Example: transport://user:pass@host1:port[,hostN:portN]/virtual_host (DEFAULT/transport_url is used if empty)</td> </tr> <tr> <td>[publisher_notifier] metering_driver = messagingv2</td> <td>(StrOpt) The driver that ceilometer uses for metering notifications.</td> </tr> <tr> <td>[publisher_notifier] metering_topic = metering</td> <td>(StrOpt) The topic that ceilometer uses for metering notifications.</td> </tr> <tr> <td>[service_types] glance = image</td> <td>(StrOpt) Glance service type.</td> </tr> <tr> <td>[service_types] kwapi = energy</td> <td>(StrOpt) Kwapi service type.</td> </tr> <tr> <td>[service_types] neutron = network</td> <td>(StrOpt) Neutron service type.</td> </tr> <tr> <td>[service_types] nova = compute</td> <td>(StrOpt) Nova service type.</td> </tr> <tr> <td>[service_types] swift = object-store</td> <td>(StrOpt) Swift service type.</td> </tr> <tr> <td>[upgrade_levels] cells = None</td> <td>(StrOpt) Set a version cap for messages sent to local cells services</td> </tr> <tr> <td>[vmware] wsdl_location = None</td> <td>(StrOpt) Optional vim service WSDL location e.g http://&lt;server&gt;/vimService.wsdl. Optional over-ride to default location for bug work-arounds</td> </tr> <tr> <td>[xenapi] connection_password = None</td> <td>(StrOpt) Password for connection to XenServer/Xen Cloud Platform</td> </tr> <tr> <td>[xenapi] connection_url = None</td> <td>(StrOpt) URL for connection to XenServer/Xen Cloud Platform</td> </tr> <tr> <td>[xenapi] connection_username = root</td> <td>(StrOpt) Username for connection to XenServer/Xen Cloud Platform</td> </tr> <tr> <td>[xenapi] login_timeout = 10</td> <td>(IntOpt) Timeout in seconds for XenAPI login.</td> </tr> </table> <table> <caption>New default values</caption> <col width=""33%""/> <col width=""33%""/> <col width=""33%""/> <thead> <tr> <td>Option</td> <td>Previous default value</td> <td>New default value</td> </tr> </thead> <tr> <td>[DEFAULT] default_log_levels</td> <td>amqp=WARN, amqplib=WARN, boto=WARN, qpid=WARN, sqlalchemy=WARN, suds=INFO, iso8601=WARN, requests.packages.urllib3.connectionpool=WARN</td> <td>amqp=WARN, amqplib=WARN, boto=WARN, qpid=WARN, sqlalchemy=WARN, suds=INFO, oslo.messaging=INFO, iso8601=WARN, requests.packages.urllib3.connectionpool=WARN, urllib3.connectionpool=WARN, websocket=WARN, keystonemiddleware=WARN, routes.middleware=WARN, stevedore=WARN</td> </tr> <tr> <td>[DEFAULT] rpc_zmq_matchmaker</td> <td>ceilometer.openstack.common.rpc.matchmaker.MatchMakerLocalhost</td> <td>oslo.messaging._drivers.matchmaker.MatchMakerLocalhost</td> </tr> <tr> <td>[database] connection</td> <td>sqlite:////usr/lib/python/site-packages/ceilometer/ceilometer/openstack/common/db/$sqlite_db</td> <td>None</td> </tr> <tr> <td>[database] slave_connection</td> <td></td> <td>None</td> </tr> <tr> <td>[keystone_authtoken] revocation_cache_time</td> <td>300</td> <td>10</td> </tr> </table> <table> <caption>Deprecated options</caption> <col width=""50%""/> <col width=""50%""/> <thead> <tr> <td>Deprecated option</td> <td>New Option</td> </tr> </thead> <tr> <td>[rpc_notifier2] topics</td> <td>[DEFAULT] notification_topics</td>",20,285
openstack%2Fopenstack-manuals~master~I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3,openstack/openstack-manuals,master,I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3,Adds serialized response formats to End User Guide,MERGED,2014-12-05 22:50:39.000000000,2014-12-14 01:05:50.000000000,2014-12-14 01:05:49.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 10068}, {'_account_id': 10705}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-05 22:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1a76c7bb31317b28eec49ead631e214cf700c353', 'message': 'Adds serialized response formats to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nto be added to the End User Guide. Also included linked\nenvironment variables topic.\n\nChange-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3\nPartial-bug: 1392382\n'}, {'number': 2, 'created': '2014-12-10 19:14:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1c63481c2f53213d826dcf07c84048b42fe5d5f6', 'message': 'Adds serialized response formats to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nto be added to the End User Guide. Also included linked\nenvironment variables topic.\n\nChange-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3\nPartial-bug: 1392382\n'}, {'number': 3, 'created': '2014-12-11 16:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/05fc55210a580dffacb72cf65988f979d9870fa8', 'message': 'Adds serialized response formats to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nto be added to the End User Guide. Also included linked\nenvironment variables topic.\n\nChange-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3\nPartial-bug: 1392382\n'}, {'number': 4, 'created': '2014-12-11 21:40:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4a0fef18547e1fdc75ec10ce2f35a8569fb459ff', 'message': 'Adds serialized response formats to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nto be added to the End User Guide. Also included linked\nenvironment variables topic.\n\nChange-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3\nPartial-bug: 1392382\n'}, {'number': 5, 'created': '2014-12-12 16:14:45.000000000', 'files': ['doc/user-guide/section_object-api-env-vars.xml', 'doc/user-guide/section_object-api-response-formats.xml', 'doc/user-guide/section_cli_swift_howto.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1b49fe3f2c1678462cae363c077ae8353518230c', 'message': 'Adds serialized response formats to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nto be added to the End User Guide. Also included linked\nenvironment variables topic.\n\nChange-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3\nPartial-bug: 1392382\n'}]",4,139746,1b49fe3f2c1678462cae363c077ae8353518230c,25,7,5,12454,,,0,"Adds serialized response formats to End User Guide

With the moving of the Object Storage API content from a
long-form dev guide to a specification, some topics needed
to be added to the End User Guide. Also included linked
environment variables topic.

Change-Id: I6b8cee64e0bb7ea8ba7291aea31b4b7853f214a3
Partial-bug: 1392382
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/46/139746/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/section_object-api-env-vars.xml', 'doc/user-guide/section_object-api-response-formats.xml', 'doc/user-guide/section_cli_swift_howto.xml']",3,1a76c7bb31317b28eec49ead631e214cf700c353,bug/1392382," <xi:include href=""section_object-api-env-vars.xml""/> <xi:include href=""section_object-api-response-formats.xml""/>",,176,0
openstack%2Fopenstack-manuals~master~I1b9568c4765fb5820e24045dbfcd5e834f1894e0,openstack/openstack-manuals,master,I1b9568c4765fb5820e24045dbfcd5e834f1894e0,Clarify Installation Guide sections for compute node installation,MERGED,2014-12-12 19:14:31.000000000,2014-12-14 01:05:41.000000000,2014-12-14 01:05:40.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}, {'_account_id': 6772}, {'_account_id': 9515}]","[{'number': 1, 'created': '2014-12-12 19:14:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/06c8547e62c1cfe0747a3b0ad89e72b6c9702c8f', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to install a compute node.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 2, 'created': '2014-12-12 21:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ca86bad47a0e704d8bcae35af1d364e84f7d02ca', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to install a compute node.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 3, 'created': '2014-12-12 21:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d810b5fe1828a96044dd04b88be320c705906055', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to getting OpenStack packages as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 4, 'created': '2014-12-12 22:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9daafb1624da28c6b5bb307e2481d2b687cab384', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to performing basic config steps as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 5, 'created': '2014-12-12 22:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cf65ed9d668794cb75d31deaf7da61a6a2f9e029', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to performing basic config steps as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 6, 'created': '2014-12-12 23:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a9e65b24298529352ae44c3777f6368fc31ea61b', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to performing basic config steps as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}, {'number': 7, 'created': '2014-12-12 23:55:58.000000000', 'files': ['doc/install-guide/section_nova-compute-install.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e821eda3cf36dc5b20eedc11df437d50bdba04ad', 'message': 'Clarify Installation Guide sections for compute node installation\n\nAdd note to compute guide installation section to clarify what\nsections are needed to only install additional compute nodes.\nInclude links to performing basic config steps as well as using\neither OpenStack Networking or nova-network.\n\nChange-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0\nbackport: juno\nCloses-Bug: 1372492\n'}]",6,141470,e821eda3cf36dc5b20eedc11df437d50bdba04ad,21,5,7,13384,,,0,"Clarify Installation Guide sections for compute node installation

Add note to compute guide installation section to clarify what
sections are needed to only install additional compute nodes.
Include links to performing basic config steps as well as using
either OpenStack Networking or nova-network.

Change-Id: I1b9568c4765fb5820e24045dbfcd5e834f1894e0
backport: juno
Closes-Bug: 1372492
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/70/141470/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/section_nova-compute-install.xml'],1,06c8547e62c1cfe0747a3b0ad89e72b6c9702c8f,bug/1372492," <note> <para>This procedure assumes that you are following the instructions in all the sections of the Installation Guide step-by-step. For installation of future additional compute nodes, you only need to perform the steps provided in <link linkend=""section_basics-packages"">OpenStack packages</link>, this section, and the <link linkend=""section_neutron-compute-node"">OpenStack Networking compute node</link> sections.</para> </note>",,9,0
openstack%2Ftempest~master~I368f9e08cba6372010b9fed47f7730160e9d60b1,openstack/tempest,master,I368f9e08cba6372010b9fed47f7730160e9d60b1,Remove use of 'cls.enabled = False',MERGED,2014-12-12 19:08:18.000000000,2014-12-14 00:58:22.000000000,2014-12-14 00:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 19:08:18.000000000', 'files': ['tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/scenario/test_network_advanced_server_ops.py', 'tempest/scenario/test_load_balancer_basic.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/721f80d90dd470b4be3eeddfa45dce3a01a59d97', 'message': ""Remove use of 'cls.enabled = False'\n\nVarious network scenario tests have been setting this attribute\nwhen raising skip exceptions.  It appears to no longer be used for\nanything and can be removed.\n\nChange-Id: I368f9e08cba6372010b9fed47f7730160e9d60b1\n""}]",0,141467,721f80d90dd470b4be3eeddfa45dce3a01a59d97,12,4,1,1420,,,0,"Remove use of 'cls.enabled = False'

Various network scenario tests have been setting this attribute
when raising skip exceptions.  It appears to no longer be used for
anything and can be removed.

Change-Id: I368f9e08cba6372010b9fed47f7730160e9d60b1
",git fetch https://review.opendev.org/openstack/tempest refs/changes/67/141467/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/scenario/test_network_basic_ops.py', 'tempest/scenario/test_network_v6.py', 'tempest/scenario/test_network_advanced_server_ops.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/scenario/test_load_balancer_basic.py']",5,721f80d90dd470b4be3eeddfa45dce3a01a59d97,clean_enabled,, cls.enabled = False cls.enabled = False,1,8
openstack%2Fironic~master~I2987898e656b2451d3eacd0d5e9bc7fa35723ad5,openstack/ironic,master,I2987898e656b2451d3eacd0d5e9bc7fa35723ad5,Get rid of set_failed_state duplication,MERGED,2014-12-12 15:38:36.000000000,2014-12-14 00:22:55.000000000,2014-12-14 00:22:53.000000000,"[{'_account_id': 3}, {'_account_id': 8106}, {'_account_id': 10239}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-12 15:38:36.000000000', 'files': ['ironic/drivers/modules/agent.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_agent.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/80670140b19e1d5daf9c7aebd4c90771667d8e66', 'message': 'Get rid of set_failed_state duplication\n\ndrivers.modules.agent and drivers.modules.iscsi_deploy contain\n_set_failed_state and set_failed_state functions respectively, which\nare almost identical. This change moves this functionality to\ndrivers.modules.deploy_utils.\n\nChange-Id: I2987898e656b2451d3eacd0d5e9bc7fa35723ad5\n'}]",0,141408,80670140b19e1d5daf9c7aebd4c90771667d8e66,10,4,1,12356,,,0,"Get rid of set_failed_state duplication

drivers.modules.agent and drivers.modules.iscsi_deploy contain
_set_failed_state and set_failed_state functions respectively, which
are almost identical. This change moves this functionality to
drivers.modules.deploy_utils.

Change-Id: I2987898e656b2451d3eacd0d5e9bc7fa35723ad5
",git fetch https://review.opendev.org/openstack/ironic refs/changes/08/141408/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/agent.py', 'ironic/drivers/modules/deploy_utils.py', 'ironic/drivers/modules/iscsi_deploy.py', 'ironic/drivers/modules/ilo/deploy.py', 'ironic/drivers/modules/pxe.py', 'ironic/tests/drivers/test_agent.py']",6,80670140b19e1d5daf9c7aebd4c90771667d8e66,set-failed-state-refactor,"from ironic.drivers.modules import deploy_utils @mock.patch.object(deploy_utils, 'set_failed_state')"," @mock.patch.object(agent, '_set_failed_state')",40,65
openstack%2Fpbr~stable%2F0.10~I1758a7afa1cab572590112567e0cac2920d94506,openstack/pbr,stable/0.10,I1758a7afa1cab572590112567e0cac2920d94506,Make a PEP440-ish version for non-tagged repos,ABANDONED,2014-12-14 00:06:01.000000000,2014-12-14 00:16:27.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}]","[{'number': 1, 'created': '2014-12-14 00:06:01.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/eff3a989ad1788a8428333f43fb04967a80bbfe8', 'message': 'Make a PEP440-ish version for non-tagged repos\n\nIf a repo has no tags, it produces a git short-sha, which can be\nconfusing.\n\nChange-Id: I1758a7afa1cab572590112567e0cac2920d94506\n(cherry picked from commit bab6479532fd9eb76acdda3bbfaa3ccae835eab7)\n'}]",0,141592,eff3a989ad1788a8428333f43fb04967a80bbfe8,4,3,1,5263,,,0,"Make a PEP440-ish version for non-tagged repos

If a repo has no tags, it produces a git short-sha, which can be
confusing.

Change-Id: I1758a7afa1cab572590112567e0cac2920d94506
(cherry picked from commit bab6479532fd9eb76acdda3bbfaa3ccae835eab7)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/92/141592/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,eff3a989ad1788a8428333f43fb04967a80bbfe8,setuptools-8," raw_version = _run_git_command( if '.' not in raw_version: raw_version = ""0.0.0.%s+g%s"" % ( _get_revno(git_dir), raw_version) return raw_version", return _run_git_command(,5,1
openstack%2Fpbr~stable%2F0.10~I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,openstack/pbr,stable/0.10,I2a5072d73e19ce77fa29ba5d8aa6e9649859a551,Prefix git suffixes with + instead of .,ABANDONED,2014-12-14 00:06:01.000000000,2014-12-14 00:16:14.000000000,,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 7687}]","[{'number': 1, 'created': '2014-12-14 00:06:01.000000000', 'files': ['pbr/packaging.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/985c4dec74581351e936aafa69aaa33416920a51', 'message': ""Prefix git suffixes with + instead of .\n\nsetuptools 8.0 enforces the accepted version of PEP440, which means\nthat 1.2.3.g123456 is now sorted before 1.0. Forget for a second that\nunder no obvious human inspection this makes sense, it is now the law of\nthe land and we must comply.\n\nI swear to god I'm going to start coding in Go.\n\nChange-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551\n(cherry picked from commit fafd6c4db07789b2d378fdb5ceda89115d2abe30)\n""}]",0,141591,985c4dec74581351e936aafa69aaa33416920a51,5,4,1,5263,,,0,"Prefix git suffixes with + instead of .

setuptools 8.0 enforces the accepted version of PEP440, which means
that 1.2.3.g123456 is now sorted before 1.0. Forget for a second that
under no obvious human inspection this makes sense, it is now the law of
the land and we must comply.

I swear to god I'm going to start coding in Go.

Change-Id: I2a5072d73e19ce77fa29ba5d8aa6e9649859a551
(cherry picked from commit fafd6c4db07789b2d378fdb5ceda89115d2abe30)
",git fetch https://review.opendev.org/openstack/pbr refs/changes/91/141591/1 && git format-patch -1 --stdout FETCH_HEAD,['pbr/packaging.py'],1,985c4dec74581351e936aafa69aaa33416920a51,setuptools-8," return ""%s.dev%s+g%s"" % (pre_version, _get_revno(git_dir), sha) ['describe', '--always'], git_dir).replace('-', '.').replace('.g', '+g')"," return ""%s.dev%s.g%s"" % (pre_version, _get_revno(git_dir), sha) ['describe', '--always'], git_dir).replace('-', '.')",3,2
openstack%2Frequirements~stable%2Fjuno~I9b556aeacbe4b7d66e61d46d7ae23ae9ff28e1fa,openstack/requirements,stable/juno,I9b556aeacbe4b7d66e61d46d7ae23ae9ff28e1fa,Consistently use comma to mean AND to match the PEP 440 behavior,MERGED,2014-12-13 21:46:00.000000000,2014-12-14 00:09:35.000000000,2014-12-14 00:09:34.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 7680}]","[{'number': 1, 'created': '2014-12-13 21:46:00.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4bbac4c9bc5bcba6962921369ce7721d2a544aa4', 'message': ""Consistently use comma to mean AND to match the PEP 440 behavior\n\nThis includes a series of != in order to ensure that we don't install\nversions that we were previously attempting to exclude.\n\nChange-Id: I9b556aeacbe4b7d66e61d46d7ae23ae9ff28e1fa\n""}]",0,141584,4bbac4c9bc5bcba6962921369ce7721d2a544aa4,11,4,1,7687,,,0,"Consistently use comma to mean AND to match the PEP 440 behavior

This includes a series of != in order to ensure that we don't install
versions that we were previously attempting to exclude.

Change-Id: I9b556aeacbe4b7d66e61d46d7ae23ae9ff28e1fa
",git fetch https://review.opendev.org/openstack/requirements refs/changes/84/141584/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4bbac4c9bc5bcba6962921369ce7721d2a544aa4,fix-sqlalchemy,"SQLAlchemy>=0.8.4,<=0.9.99,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,!=0.9.4,!=0.9.5,!=0.9.6","# The SQLA requirement looks weird, but it's here for a reason. The # version of pip shipped with distros will treat 0.9b* as < 0.8 if it's # anytime uploaded to PyPI, so the ""clear"" version of this requirement # is potentially broken. The fix for this isn't until pip 1.4.1, which # is way more current than what most distros have. SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,6
openstack%2Fmurano-dashboard~master~Id17ff0f47fc239b756a5ff7832250b822761264d,openstack/murano-dashboard,master,Id17ff0f47fc239b756a5ff7832250b822761264d,Removed statistics panel,ABANDONED,2014-12-13 17:34:52.000000000,2014-12-14 00:05:18.000000000,,"[{'_account_id': 3}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-13 17:34:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/11b4ca8bbe2ce7361afc96fcb19193a8c824c8e5', 'message': 'Removed statistics panel\n\nChange-Id: Id17ff0f47fc239b756a5ff7832250b822761264d\n'}, {'number': 2, 'created': '2014-12-13 18:09:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/cf548881235fe62c53d6b2350521c7ff2d8fc38a', 'message': 'Removed statistics panel\n\nChange-Id: Id17ff0f47fc239b756a5ff7832250b822761264d\n'}, {'number': 3, 'created': '2014-12-13 23:43:08.000000000', 'files': ['muranodashboard/tests/functional/sanity_check.py', 'muranodashboard/templates/stats/_billing_stats.html', 'muranodashboard/stats/panel.py', 'muranodashboard/templates/stats/_page_header.html', 'muranodashboard/templates/stats/_srv_instance.html', 'muranodashboard/stats/tabs.py', 'muranodashboard/stats/views.py', 'muranodashboard/templates/stats/index.html', 'muranodashboard/templates/stats/_eng_srv.html', 'muranodashboard/static/muranodashboard/css/catalog.css', 'muranodashboard/dashboard.py', 'muranodashboard/templates/stats/_billing_entry.html', 'muranodashboard/stats/__init__.py', 'muranodashboard/templates/stats/_api_srv.html', 'muranodashboard/stats/models.py', 'muranodashboard/stats/urls.py', 'muranodashboard/templates/stats/_app_stats.html', 'muranodashboard/templates/stats/_billing.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/7edcf325ec208c246fc276bfba8f68c47d7bfc65', 'message': 'Removed statistics panel\n\nChange-Id: Id17ff0f47fc239b756a5ff7832250b822761264d\n'}]",0,141568,7edcf325ec208c246fc276bfba8f68c47d7bfc65,19,3,3,7600,,,0,"Removed statistics panel

Change-Id: Id17ff0f47fc239b756a5ff7832250b822761264d
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/68/141568/2 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templates/stats/_billing_stats.html', 'muranodashboard/stats/panel.py', 'muranodashboard/templates/stats/_page_header.html', 'muranodashboard/templates/stats/_srv_instance.html', 'muranodashboard/stats/tabs.py', 'muranodashboard/stats/views.py', 'muranodashboard/templates/stats/index.html', 'muranodashboard/templates/stats/_eng_srv.html', 'muranodashboard/static/muranodashboard/css/catalog.css', 'muranodashboard/dashboard.py', 'muranodashboard/templates/stats/_billing_entry.html', 'muranodashboard/stats/__init__.py', 'muranodashboard/templates/stats/_api_srv.html', 'muranodashboard/stats/models.py', 'muranodashboard/stats/urls.py', 'muranodashboard/templates/stats/_app_stats.html', 'muranodashboard/templates/stats/_billing.html']",17,11b4ca8bbe2ce7361afc96fcb19193a8c824c8e5,remove-stats,,"{% load i18n sizeformat %} {% if stats %} <div class=""panel-group {{ offset }}"" id=""{{ grp_id }}""> {% for env in stats %} {% with parent=grp_id env=env t=""stats/_billing_stats.html"" %} {% include t %} {% endwith %} {% endfor %} </div> {% else %} <div class=""alert alert-block alert-info fade in""> <p>{% trans ""No recent activity to report at this time."" %}</p> </div> {% endif %} ",1,346
openstack%2Fpuppet-keystone~master~Id21623619c65c5ff1970b43b2d6a3857410a1fd7,openstack/puppet-keystone,master,Id21623619c65c5ff1970b43b2d6a3857410a1fd7,service_identity: add user/role ordering,MERGED,2014-12-05 20:03:34.000000000,2014-12-13 23:47:24.000000000,2014-12-12 10:51:34.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 8482}, {'_account_id': 9060}, {'_account_id': 9410}, {'_account_id': 9500}]","[{'number': 1, 'created': '2014-12-05 20:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/9a57a31917d237d61e104ba91048ddfd854bb600', 'message': 'service_identity: add user/role ordering\n\nIf configure_user_role and configure_user are True, we may want to\nensure the user is created before role assignment.\n\nChange-Id: Id21623619c65c5ff1970b43b2d6a3857410a1fd7\n'}, {'number': 2, 'created': '2014-12-07 15:18:00.000000000', 'files': ['manifests/resource/service_identity.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/46673d3c793d84e03a766fc1e51f53a52ae8bd8e', 'message': 'service_identity: add user/role ordering\n\nIf configure_user_role and configure_user are True, we may want to\nensure the user is created before role assignment.\n\nChange-Id: Id21623619c65c5ff1970b43b2d6a3857410a1fd7\n'}]",0,139724,46673d3c793d84e03a766fc1e51f53a52ae8bd8e,14,9,2,3153,,,0,"service_identity: add user/role ordering

If configure_user_role and configure_user are True, we may want to
ensure the user is created before role assignment.

Change-Id: Id21623619c65c5ff1970b43b2d6a3857410a1fd7
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/24/139724/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/resource/service_identity.pp'],1,9a57a31917d237d61e104ba91048ddfd854bb600,resource-order," if $configure_user { Keystone_user[""$auth_name""] -> Keystone_user_role[""${auth_name}@${tenant}""] }",,3,0
openstack%2Fpuppet-tempest~master~Iac7c8aa23c97be3857843a17a755cc2e2574952a,openstack/puppet-tempest,master,Iac7c8aa23c97be3857843a17a755cc2e2574952a,Allow to activate Ceilometer tests,MERGED,2014-12-09 01:26:18.000000000,2014-12-13 23:46:48.000000000,2014-12-12 10:52:35.000000000,"[{'_account_id': 3}, {'_account_id': 1918}, {'_account_id': 7155}, {'_account_id': 7156}, {'_account_id': 7616}, {'_account_id': 9410}]","[{'number': 1, 'created': '2014-12-09 01:26:18.000000000', 'files': ['manifests/init.pp', 'spec/classes/tempest_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/beb7add18570713e71e8186403bda44f200d7bcb', 'message': 'Allow to activate Ceilometer tests\n\nEnable ceilometer parameter to test Telemetry tests in Tempest.\n\nChange-Id: Iac7c8aa23c97be3857843a17a755cc2e2574952a\n'}]",0,140198,beb7add18570713e71e8186403bda44f200d7bcb,9,6,1,3153,,,0,"Allow to activate Ceilometer tests

Enable ceilometer parameter to test Telemetry tests in Tempest.

Change-Id: Iac7c8aa23c97be3857843a17a755cc2e2574952a
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/98/140198/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/init.pp', 'spec/classes/tempest_spec.rb']",2,beb7add18570713e71e8186403bda44f200d7bcb,enable-ceilo, should contain_tempest_config('service_available/ceilometer').with(:value => false),,3,0
openstack%2Ffreezer~master~I561ae49c9f2065fe5d97e1dc12ed41626e195a7e,openstack/freezer,master,I561ae49c9f2065fe5d97e1dc12ed41626e195a7e,Fixed bug in setup.py and remove test auth file in mysql test,MERGED,2014-12-13 15:18:09.000000000,2014-12-13 23:36:07.000000000,2014-12-13 23:36:07.000000000,"[{'_account_id': 3}, {'_account_id': 6780}, {'_account_id': 12211}, {'_account_id': 14028}, {'_account_id': 14159}]","[{'number': 1, 'created': '2014-12-13 15:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/05e8edc70ac335612847c95fcd39feaa34219d0e', 'message': 'Fixed bug in setup.py and remove test auth file in mysql test\n\nChange-Id: I561ae49c9f2065fe5d97e1dc12ed41626e195a7e\n'}, {'number': 2, 'created': '2014-12-13 15:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/cdf18ff99059cf9b8b0e5cd838a5d8d54f8c4bf1', 'message': 'Fixed bug in setup.py and remove test auth file in mysql test\n\nBUG: https://bugs.launchpad.net/freezer/+bug/1402218\n\nChange-Id: I561ae49c9f2065fe5d97e1dc12ed41626e195a7e\n'}, {'number': 3, 'created': '2014-12-13 16:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/5b7bcc03c38f997f27cc6694c46d570bda54505c', 'message': 'Fixed bug in setup.py and remove test auth file in mysql test\n\nBUG: https://bugs.launchpad.net/freezer/+bug/1402218\n\nChange-Id: I561ae49c9f2065fe5d97e1dc12ed41626e195a7e\n'}, {'number': 4, 'created': '2014-12-13 17:39:35.000000000', 'files': ['tests/test_backup.py', 'setup.py'], 'web_link': 'https://opendev.org/openstack/freezer/commit/0f725a008370dba3fc72061d2f5fc35fa63a5316', 'message': 'Fixed bug in setup.py and remove test auth file in mysql test\n\nBUG: https://bugs.launchpad.net/freezer/+bug/1402218\n\nChange-Id: I561ae49c9f2065fe5d97e1dc12ed41626e195a7e\n'}]",0,141558,0f725a008370dba3fc72061d2f5fc35fa63a5316,13,5,4,11151,,,0,"Fixed bug in setup.py and remove test auth file in mysql test

BUG: https://bugs.launchpad.net/freezer/+bug/1402218

Change-Id: I561ae49c9f2065fe5d97e1dc12ed41626e195a7e
",git fetch https://review.opendev.org/openstack/freezer refs/changes/58/141558/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_backup.py', 'setup.py']",2,05e8edc70ac335612847c95fcd39feaa34219d0e,, import sys,,2,1
openstack%2Fdevstack~master~I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6,openstack/devstack,master,I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6,Pin version of setuptools,MERGED,2014-12-13 20:19:50.000000000,2014-12-13 23:26:32.000000000,2014-12-13 23:26:31.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 6547}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-13 20:19:50.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3b782d304ec2073a6406c37b9e1a76c8aecfc9a3', 'message': ""Pin version of setuptools\n\nLatest release of setuptool 8.0 made several versions used in\nrequirements.txt of OpenStack projects invalid. Instances:\n* SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99 in oslo.db 1.2.0\n* python-neutronclient 2.3.9.40.g9ed73c0 in openstackclient\n\nCap '<8.0' is set as a temporary fix until a better solution\ncomes up.\n\nChange-Id: I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6\n""}]",0,141578,3b782d304ec2073a6406c37b9e1a76c8aecfc9a3,14,6,1,7600,,,0,"Pin version of setuptools

Latest release of setuptool 8.0 made several versions used in
requirements.txt of OpenStack projects invalid. Instances:
* SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99 in oslo.db 1.2.0
* python-neutronclient 2.3.9.40.g9ed73c0 in openstackclient

Cap '<8.0' is set as a temporary fix until a better solution
comes up.

Change-Id: I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6
",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/141578/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,3b782d304ec2073a6406c37b9e1a76c8aecfc9a3,fix-the-world,"pip_install -U ""setuptools<8.0""",pip_install -U setuptools,1,1
openstack%2Fcinder~master~Iaf39ea31bcbd31a90b621b6f33b6aa799f425744,openstack/cinder,master,Iaf39ea31bcbd31a90b621b6f33b6aa799f425744,Remove an unused variable in volume/manager.py,MERGED,2014-12-12 02:52:27.000000000,2014-12-13 23:16:23.000000000,2014-12-12 06:57:33.000000000,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12369}]","[{'number': 1, 'created': '2014-12-12 02:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/80b9707a236ea0df7cc5b0696b6359346986c1ed', 'message': 'Remove an unused code in volume/manager.py\n\nRemove an unused code in manager.py.\n\nChange-Id: Iaf39ea31bcbd31a90b621b6f33b6aa799f425744\n'}, {'number': 2, 'created': '2014-12-12 04:49:00.000000000', 'files': ['cinder/volume/manager.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/6ef5043363913f685234cabcacc802a7c0284963', 'message': ""Remove an unused variable in volume/manager.py\n\nThe 'old_reservations' variable defined in a exception handling block in 'retype' method is never used, this change removes it.\n\nChange-Id: Iaf39ea31bcbd31a90b621b6f33b6aa799f425744\n""}]",0,141253,6ef5043363913f685234cabcacc802a7c0284963,17,8,2,8289,,,0,"Remove an unused variable in volume/manager.py

The 'old_reservations' variable defined in a exception handling block in 'retype' method is never used, this change removes it.

Change-Id: Iaf39ea31bcbd31a90b621b6f33b6aa799f425744
",git fetch https://review.opendev.org/openstack/cinder refs/changes/53/141253/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/manager.py'],1,80b9707a236ea0df7cc5b0696b6359346986c1ed,rm-an-unused-code,, old_reservations = None,0,1
openstack%2Fdevstack~stable%2Fjuno~I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6,openstack/devstack,stable/juno,I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6,Pin version of setuptools,MERGED,2014-12-13 20:47:29.000000000,2014-12-13 22:41:13.000000000,2014-12-13 21:59:36.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 6547}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-13 20:47:29.000000000', 'files': ['tools/install_pip.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a571e4abe8f5d9f31f743557f24472e24337b6bb', 'message': ""Pin version of setuptools\n\nLatest release of setuptool 8.0 made several versions used in\nrequirements.txt of OpenStack projects invalid. Instances:\n* SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99 in oslo.db 1.2.0\n* python-neutronclient 2.3.9.40.g9ed73c0 in openstackclient\n\nCap '<8.0' is set as a temporary fix until a better solution\ncomes up.\n\nChange-Id: I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6\n(cherry picked from commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3)\n""}]",0,141581,a571e4abe8f5d9f31f743557f24472e24337b6bb,10,7,1,4146,,,0,"Pin version of setuptools

Latest release of setuptool 8.0 made several versions used in
requirements.txt of OpenStack projects invalid. Instances:
* SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99 in oslo.db 1.2.0
* python-neutronclient 2.3.9.40.g9ed73c0 in openstackclient

Cap '<8.0' is set as a temporary fix until a better solution
comes up.

Change-Id: I4cfe2e4c86474ec9bf69a3c2007c0277288ea2b6
(cherry picked from commit 3b782d304ec2073a6406c37b9e1a76c8aecfc9a3)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/81/141581/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/install_pip.sh'],1,a571e4abe8f5d9f31f743557f24472e24337b6bb,,"pip_install -U ""setuptools<8.0""",pip_install -U setuptools,1,1
openstack%2Fdevstack~stable%2Ficehouse~Iae98d9d7e97b81955cafe1b88022133e6902e551,openstack/devstack,stable/icehouse,Iae98d9d7e97b81955cafe1b88022133e6902e551,Install setuptools<8.0,MERGED,2014-12-13 20:52:25.000000000,2014-12-13 22:15:33.000000000,2014-12-13 22:15:32.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-13 20:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/effcce9d219976a2f8579f2456a93fa19e5c78c8', 'message': 'Install setuptools<8.0\n\nNew setuptools (>=8.0) breaks with versions used in older versions of\nthings. Specifically .gshortsha1 source identifiers do not parse and are\nsorted as coming before all other versions. Using <8.0 at least unwedges\nus then we can work on backporting changes to use newer pbr which will\nuse +gshortsha1 which sorts properly.\n\nChange-Id: Iae98d9d7e97b81955cafe1b88022133e6902e551\n'}, {'number': 2, 'created': '2014-12-13 20:57:42.000000000', 'files': ['lib/infra'], 'web_link': 'https://opendev.org/openstack/devstack/commit/55a6f3ae675c692bd241c3e815c8862b577081ae', 'message': 'Install setuptools<8.0\n\nNew setuptools (>=8.0) breaks with versions used in older versions of\nthings. Specifically .gshortsha1 source identifiers do not parse and are\nsorted as coming before all other versions. Using <8.0 at least unwedges\nus then we can work on backporting changes to use newer pbr which will\nuse +gshortsha1 which sorts properly.\n\nChange-Id: Iae98d9d7e97b81955cafe1b88022133e6902e551\n'}]",0,141582,55a6f3ae675c692bd241c3e815c8862b577081ae,8,3,2,4146,,,0,"Install setuptools<8.0

New setuptools (>=8.0) breaks with versions used in older versions of
things. Specifically .gshortsha1 source identifiers do not parse and are
sorted as coming before all other versions. Using <8.0 at least unwedges
us then we can work on backporting changes to use newer pbr which will
use +gshortsha1 which sorts properly.

Change-Id: Iae98d9d7e97b81955cafe1b88022133e6902e551
",git fetch https://review.opendev.org/openstack/devstack refs/changes/82/141582/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/infra'],1,effcce9d219976a2f8579f2456a93fa19e5c78c8,fix-icehouse-setuptools, pip_install -U setuptools<8.0 pip_install -U setuptools<8.0, pip_install -U setuptools pip_install -U setuptools,2,2
openstack%2Ffuel-main~stable%2F5.0~I21ae585c1ce50300834ed29517bb7f1ba72ef4e3,openstack/fuel-main,stable/5.0,I21ae585c1ce50300834ed29517bb7f1ba72ef4e3,Updating mirror URIs,MERGED,2014-12-13 18:42:24.000000000,2014-12-13 21:53:58.000000000,2014-12-13 21:53:58.000000000,"[{'_account_id': 3}, {'_account_id': 406}, {'_account_id': 8777}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9582}]","[{'number': 1, 'created': '2014-12-13 18:42:24.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f0a97edbddb05839a1f3702e626e5019a3889eeb', 'message': 'Updating mirror URIs\n\nChange-Id: I21ae585c1ce50300834ed29517bb7f1ba72ef4e3\n(cherry picked from commit 5579585121f8445e061bde9a8bd48fb7e53714cd)\n'}]",4,141572,f0a97edbddb05839a1f3702e626e5019a3889eeb,14,6,1,8777,,,0,"Updating mirror URIs

Change-Id: I21ae585c1ce50300834ed29517bb7f1ba72ef4e3
(cherry picked from commit 5579585121f8445e061bde9a8bd48fb7e53714cd)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/72/141572/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,f0a97edbddb05839a1f3702e626e5019a3889eeb,,"ifeq ($(USE_MIRROR),us)ifeq ($(USE_MIRROR),ext) YUM_REPOS?=proprietary MIRROR_BASE?=http://mirror.fuel-infra.org/fwm/$(PRODUCT_VERSION) MIRROR_CENTOS?=$(MIRROR_BASE)/centos MIRROR_UBUNTU?=$(MIRROR_BASE)/ubuntu MIRROR_DOCKER?=$(MIRROR_BASE)/docker endifMIRROR_BASE?=http://osci-mirror-srt.srt.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://osci-mirror-msk.msk.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://osci-mirror-kha.kha.mirantis.net/fwm/$(PRODUCT_VERSION)","ifeq ($(USE_MIRROR),ext)MIRROR_BASE?=http://fuel-mirror.srt.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://fuel-mirror.msk.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://fuel-mirror.kha.mirantis.net/fwm/$(PRODUCT_VERSION)",11,4
openstack%2Fneutron~master~Ifbb345fcefe074f5958458f055a21f67ad3c75dc,openstack/neutron,master,Ifbb345fcefe074f5958458f055a21f67ad3c75dc,Remove runtests.sh from Neutron,ABANDONED,2014-12-08 20:22:04.000000000,2014-12-13 21:27:41.000000000,,"[{'_account_id': 3}, {'_account_id': 1131}, {'_account_id': 1561}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-08 20:22:04.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b55938c09820ea53d5416b32a73f1437b9369d73', 'message': ""Remove runtests.sh from Neutron\n\nAn alternate version of this bugfix exists that fixes the syntax error,\nbut there doesn't seem to be a lot of interest in this script.  Let's see\nif we can just get rid of it.\n\nChange-Id: Ifbb345fcefe074f5958458f055a21f67ad3c75dc\n""}]",2,140139,b55938c09820ea53d5416b32a73f1437b9369d73,32,30,1,10980,,,0,"Remove runtests.sh from Neutron

An alternate version of this bugfix exists that fixes the syntax error,
but there doesn't seem to be a lot of interest in this script.  Let's see
if we can just get rid of it.

Change-Id: Ifbb345fcefe074f5958458f055a21f67ad3c75dc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/140139/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,b55938c09820ea53d5416b32a73f1437b9369d73,bug/1391858,,"#!/bin/bash set -eu function usage { echo ""Usage: $0 [OPTION]..."" echo ""Run Neutron's test suite(s)"" echo """" echo "" -V, --virtual-env Always use virtualenv. Install automatically if not present"" echo "" -N, --no-virtual-env Don't use virtualenv. Run tests in local environment"" echo "" -s, --no-site-packages Isolate the virtualenv from the global Python environment"" echo "" -r, --recreate-db Recreate the test database (deprecated, as this is now the default)."" echo "" -n, --no-recreate-db Don't recreate the test database."" echo "" -f, --force Force a clean re-build of the virtual environment. Useful when dependencies have been added."" echo "" -u, --update Update the virtual environment with any newer package versions"" echo "" -p, --pep8 Just run PEP8 and HACKING compliance check"" echo "" -8, --pep8-only-changed [<basecommit>]"" echo "" Just run PEP8 and HACKING compliance check on files changed since HEAD~1 (or <basecommit>)"" echo "" -P, --no-pep8 Don't run static code checks"" echo "" -c, --coverage Generate coverage report"" echo "" -d, --debug Run tests with testtools instead of testr. This allows you to use the debugger."" echo "" -h, --help Print this usage message"" echo "" --virtual-env-path <path> Location of the virtualenv directory"" echo "" Default: \$(pwd)"" echo "" --virtual-env-name <name> Name of the virtualenv directory"" echo "" Default: .venv"" echo "" --tools-path <dir> Location of the tools directory"" echo "" Default: \$(pwd)"" echo """" echo ""Note: with no options specified, the script will try to run the tests in a virtual environment,"" echo "" If no virtualenv is found, the script will ask if you would like to create one. If you "" echo "" prefer to run tests NOT in a virtual environment, simply pass the -N option."" exit } function process_options { i=1 while [ $i -le $# ]; do case ""${!i}"" in -h|--help) usage;; -V|--virtual-env) always_venv=1; never_venv=0;; -N|--no-virtual-env) always_venv=0; never_venv=1;; -s|--no-site-packages) no_site_packages=1;; -r|--recreate-db) recreate_db=1;; -n|--no-recreate-db) recreate_db=0;; -f|--force) force=1;; -u|--update) update=1;; -p|--pep8) just_pep8=1;; -8|--pep8-only-changed) just_pep8_changed=1;; -P|--no-pep8) no_pep8=1;; -c|--coverage) coverage=1;; -d|--debug) debug=1;; --virtual-env-path) (( i++ )) venv_path=${!i} ;; --virtual-env-name) (( i++ )) venv_dir=${!i} ;; --tools-path) (( i++ )) tools_path=${!i} ;; -*) testopts=""$testopts ${!i}"";; *) testargs=""$testargs ${!i}"" esac (( i++ )) done } tool_path=${tools_path:-$(pwd)} venv_path=${venv_path:-$(pwd)} venv_dir=${venv_name:-.venv} with_venv=tools/with_venv.sh always_venv=0 never_venv=0 force=0 no_site_packages=0 installvenvopts= testargs= testopts= wrapper="""" just_pep8=0 just_pep8_changed=0 no_pep8=0 coverage=0 debug=0 recreate_db=1 update=0 LANG=en_US.UTF-8 LANGUAGE=en_US:en LC_ALL=C process_options $@ # Make our paths available to other scripts we call export venv_path export venv_dir export venv_name export tools_dir export venv=${venv_path}/${venv_dir} if [ $no_site_packages -eq 1 ]; then installvenvopts=""--no-site-packages"" fi function run_tests { # Cleanup *pyc ${wrapper} find . -type f -name ""*.pyc"" -delete if [ $debug -eq 1 ]; then if [ ""$testopts"" = """" ] && [ ""$testargs"" = """" ]; then # Default to running all tests if specific test is not # provided. testargs=""discover ./neutron/tests"" fi ${wrapper} python -m testtools.run $testopts $testargs # Short circuit because all of the testr and coverage stuff # below does not make sense when running testtools.run for # debugging purposes. return $? fi if [ $coverage -eq 1 ]; then TESTRTESTS=""$TESTRTESTS --coverage"" else TESTRTESTS=""$TESTRTESTS --slowest"" fi # Just run the test suites in current environment set +e testargs=`echo ""$testargs"" | sed -e's/^\s*\(.*\)\s*$/\1/'` TESTRTESTS=""$TESTRTESTS --testr-args='--subunit $testopts $testargs'"" OS_TEST_PATH=`echo $testargs|grep -o 'neutron\.tests[^[:space:]:]*\+'|tr . /` if [ -d ""$OS_TEST_PATH"" ]; then wrapper=""OS_TEST_PATH=$OS_TEST_PATH $wrapper"" elif [ -d ""$(dirname $OS_TEST_PATH)"" ]; then wrapper=""OS_TEST_PATH=$(dirname $OS_TEST_PATH) $wrapper"" fi echo ""Running \`${wrapper} $TESTRTESTS\`"" bash -c ""${wrapper} $TESTRTESTS | ${wrapper} subunit2pyunit"" RESULT=$? set -e copy_subunit_log if [ $coverage -eq 1 ]; then echo ""Generating coverage report in covhtml/"" # Don't compute coverage for common code, which is tested elsewhere ${wrapper} coverage combine ${wrapper} coverage html --include='neutron/*' --omit='neutron/openstack/common/*' -d covhtml -i fi return $RESULT } function copy_subunit_log { LOGNAME=`cat .testrepository/next-stream` LOGNAME=$(($LOGNAME - 1)) LOGNAME="".testrepository/${LOGNAME}"" cp $LOGNAME subunit.log } function warn_on_flake8_without_venv { if [ $never_venv -eq 1 ]; then echo ""**WARNING**:"" echo ""Running flake8 without virtual env may miss OpenStack HACKING detection"" fi } function run_pep8 { echo ""Running flake8 ..."" warn_on_flake8_without_venv ${wrapper} flake8 } function run_pep8_changed { # NOTE(gilliard) We want use flake8 to check the entirety of every file that has # a change in it. Unfortunately the --filenames argument to flake8 only accepts # file *names* and there are no files named (eg) ""nova/compute/manager.py"". The # --diff argument behaves surprisingly as well, because although you feed it a # diff, it actually checks the file on disk anyway. local target=${testargs:-HEAD~1} local files=$(git diff --name-only $target | tr '\n' ' ') echo ""Running flake8 on ${files}"" warn_on_flake8_without_venv diff -u --from-file /dev/null ${files} | ${wrapper} flake8 --diff } TESTRTESTS=""python -m neutron.openstack.common.lockutils python setup.py testr"" if [ $never_venv -eq 0 ] then # Remove the virtual environment if --force used if [ $force -eq 1 ]; then echo ""Cleaning virtualenv..."" rm -rf ${venv} fi if [ $update -eq 1 ]; then echo ""Updating virtualenv..."" python tools/install_venv.py $installvenvopts fi if [ -e ${venv} ]; then wrapper=""${with_venv}"" else if [ $always_venv -eq 1 ]; then # Automatically install the virtualenv python tools/install_venv.py $installvenvopts wrapper=""${with_venv}"" else echo -e ""No virtual environment found...create one? (Y/n) \c"" read use_ve if [ ""x$use_ve"" = ""xY"" -o ""x$use_ve"" = ""x"" -o ""x$use_ve"" = ""xy"" ]; then # Install the virtualenv and run the test suite in it python tools/install_venv.py $installvenvopts wrapper=${with_venv} fi fi fi fi # Delete old coverage data from previous runs if [ $coverage -eq 1 ]; then ${wrapper} coverage erase fi if [ $just_pep8 -eq 1 ]; then run_pep8 exit fi if [ $just_pep8_changed -eq 1 ]; then run_pep8_changed exit fi if [ $recreate_db -eq 1 ]; then rm -f tests.sqlite fi run_tests # NOTE(sirp): we only want to run pep8 when we're running the full-test suite, # not when we're running tests individually. To handle this, we need to # distinguish between options (testopts), which begin with a '-', and # arguments (testargs). if [ -z ""$testargs"" ]; then if [ $no_pep8 -eq 0 ]; then run_pep8 fi fi ",0,255
openstack%2Fneutron~master~I131db0639bc46d332ed48faa2bbe68a214264062,openstack/neutron,master,I131db0639bc46d332ed48faa2bbe68a214264062,radvd: pass -m syslog to avoid thread lock for radvd 2.0+,MERGED,2014-12-03 11:59:21.000000000,2014-12-13 20:06:36.000000000,2014-12-13 07:46:22.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-03 11:59:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/497b5b79cbeae2122b4dc9697ff220bd470abdad', 'message': ""radvd: pass -m syslog to avoid thread lock for radvd 2.0+\n\nSince radvd 2.0, the daemon does not use daemon_fork() function from\nlibdaemon, but instead calls Linux daemon() function directly. It also\npasses (1, 1) arguments when logging method (-m) is either stderr (the\ndefault) or stderr_syslog. The second argument's value = 1 means that\nstderr is not closed and left there for (some) log messages.\n\nFor neutron, it means that corresponding execute() call that spawns\nradvd and expects the invoked process to close stderr does not ever get\ncompleted. The current thread that spawned radvd is locked waiting for\nradvd to exit, which does not ever occur unless the process crashes or\nreceives a signal.\n\nSince L3 agent gives exclusive access to updates queue for each router\nto one of processing threads only, it means that the thread that got to\nserve a radvd-powered subnet will not proceed and not update any new\nports or other changes to the router anymore.\n\nPassing -m syslog makes radvd 2.0+ close stderr and return to execute()\ncaller, proceeding with router update processing. The same arguments\nshould work for old (pre 2.0) versions of radvd too, so passing them\nunconditionally.\n\nWe could instead use -m logfile and pass appropriate -l <logfile>\nargument to radvd to make it log to a log file located in router's\nnamespace storage path. Though that would be not in line with what\ndnsmasq processes currently do for dhcp agent, where we log all messages\nto syslog, so sticking to syslog for radvd for consistency.\n\nChange-Id: I131db0639bc46d332ed48faa2bbe68a214264062\nCloses-Bug: #1398779\n""}, {'number': 2, 'created': '2014-12-03 14:17:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0e590c2cccff34c715716da033c4d0327b73cc87', 'message': ""radvd: pass -m syslog to avoid thread lock for radvd 2.0+\n\nSince radvd 2.0, the daemon does not use daemon_fork() function from\nlibdaemon, but instead calls Linux daemon() function directly. It also\npasses (1, 1) arguments when logging method (-m) is either stderr (the\ndefault) or stderr_syslog. The second argument's value = 1 means that\nstderr is not closed and left there for (some) log messages.\n\nFor neutron, it means that corresponding execute() call that spawns\nradvd and expects the invoked process to close stderr does not ever get\ncompleted. The current thread that spawned radvd is locked waiting for\nradvd to exit, which does not ever occur unless the process crashes or\nreceives a signal.\n\nSince L3 agent gives exclusive access to updates queue for each router\nto one of processing threads only, it means that the thread that got to\nserve a radvd-powered subnet will not proceed and not update any new\nports or other changes to the router anymore.\n\nPassing -m syslog makes radvd 2.0+ close stderr and return to execute()\ncaller, proceeding with router update processing. The same arguments\nshould work for old (pre 2.0) versions of radvd too, so passing them\nunconditionally.\n\nWe could instead use -m logfile and pass appropriate -l <logfile>\nargument to radvd to make it log to a log file located in router's\nnamespace storage path. Though that would be not in line with what\ndnsmasq processes currently do for dhcp agent, where we log all messages\nto syslog, so sticking to syslog for radvd for consistency.\n\nChange-Id: I131db0639bc46d332ed48faa2bbe68a214264062\nCloses-Bug: #1398779\n""}, {'number': 3, 'created': '2014-12-04 10:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/219cbf803432c4d98a2ba127416d0e7ad3d5454e', 'message': ""radvd: pass -m syslog to avoid thread lock for radvd 2.0+\n\nSince radvd 2.0, the daemon does not use daemon_fork() function from\nlibdaemon, but instead calls Linux daemon() function directly. It also\npasses (1, 1) arguments when logging method (-m) is either stderr (the\ndefault) or stderr_syslog. The second argument's value = 1 means that\nstderr is not closed and left there for (some) log messages.\n\nFor neutron, it means that corresponding execute() call that spawns\nradvd and expects the invoked process to close stderr does not ever get\ncompleted. The current thread that spawned radvd is locked waiting for\nradvd to exit, which does not ever occur unless the process crashes or\nreceives a signal.\n\nSince L3 agent gives exclusive access to updates queue for each router\nto one of processing threads only, it means that the thread that got to\nserve a radvd-powered subnet will not proceed and not update any new\nports or other changes to the router anymore.\n\nPassing -m syslog makes radvd 2.0+ close stderr and return to execute()\ncaller, proceeding with router update processing. The same arguments\nshould work for old (pre 2.0) versions of radvd too, so passing them\nunconditionally.\n\nWe could instead use -m logfile and pass appropriate -l <logfile>\nargument to radvd to make it log to a log file located in router's\nnamespace storage path. Though that would be not in line with what\ndnsmasq processes currently do for dhcp agent, where we log all messages\nto syslog, so sticking to syslog for radvd for consistency.\n\nChange-Id: I131db0639bc46d332ed48faa2bbe68a214264062\nCloses-Bug: #1398779\n""}, {'number': 4, 'created': '2014-12-04 12:38:08.000000000', 'files': ['neutron/agent/linux/ra.py', 'neutron/tests/unit/test_l3_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/72d41174765540bb7672b545c336fb7aaad075e8', 'message': ""radvd: pass -m syslog to avoid thread lock for radvd 2.0+\n\nSince radvd 2.0, the daemon does not use daemon_fork() function from\nlibdaemon, but instead calls Linux daemon() function directly. It also\npasses (1, 1) arguments when logging method (-m) is either stderr (the\ndefault) or stderr_syslog. The second argument's value = 1 means that\nstderr is not closed and left there for (some) log messages.\n\nFor neutron, it means that corresponding execute() call that spawns\nradvd and expects the invoked process to close stderr does not ever get\ncompleted. The current thread that spawned radvd is locked waiting for\nradvd to exit, which does not ever occur unless the process crashes or\nreceives a signal.\n\nSince L3 agent gives exclusive access to updates queue for each router\nto one of processing threads only, it means that the thread that got to\nserve a radvd-powered subnet will not proceed and not update any new\nports or other changes to the router anymore.\n\nPassing -m syslog makes radvd 2.0+ close stderr and return to execute()\ncaller, proceeding with router update processing. The same arguments\nshould work for old (pre 2.0) versions of radvd too, so passing them\nunconditionally.\n\nWe could instead use -m logfile and pass appropriate -l <logfile>\nargument to radvd to make it log to a log file located in router's\nnamespace storage path. Though that would be not in line with what\ndnsmasq processes currently do for dhcp agent, where we log all messages\nto syslog, so sticking to syslog for radvd for consistency.\n\nChange-Id: I131db0639bc46d332ed48faa2bbe68a214264062\nCloses-Bug: #1398779\n""}]",10,138688,72d41174765540bb7672b545c336fb7aaad075e8,104,32,4,9656,,,0,"radvd: pass -m syslog to avoid thread lock for radvd 2.0+

Since radvd 2.0, the daemon does not use daemon_fork() function from
libdaemon, but instead calls Linux daemon() function directly. It also
passes (1, 1) arguments when logging method (-m) is either stderr (the
default) or stderr_syslog. The second argument's value = 1 means that
stderr is not closed and left there for (some) log messages.

For neutron, it means that corresponding execute() call that spawns
radvd and expects the invoked process to close stderr does not ever get
completed. The current thread that spawned radvd is locked waiting for
radvd to exit, which does not ever occur unless the process crashes or
receives a signal.

Since L3 agent gives exclusive access to updates queue for each router
to one of processing threads only, it means that the thread that got to
serve a radvd-powered subnet will not proceed and not update any new
ports or other changes to the router anymore.

Passing -m syslog makes radvd 2.0+ close stderr and return to execute()
caller, proceeding with router update processing. The same arguments
should work for old (pre 2.0) versions of radvd too, so passing them
unconditionally.

We could instead use -m logfile and pass appropriate -l <logfile>
argument to radvd to make it log to a log file located in router's
namespace storage path. Though that would be not in line with what
dnsmasq processes currently do for dhcp agent, where we log all messages
to syslog, so sticking to syslog for radvd for consistency.

Change-Id: I131db0639bc46d332ed48faa2bbe68a214264062
Closes-Bug: #1398779
",git fetch https://review.opendev.org/openstack/neutron refs/changes/88/138688/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ra.py'],1,497b5b79cbeae2122b4dc9697ff220bd470abdad,radvd," # we should not use -m stderr (the default) or -m stderr_syslog # since in that case radvd 2.0+ will not close stderr and exit # and hence block execution of the current thread '-p', '%s' % pid_file, '-m', 'syslog']"," '-p', '%s' % pid_file]",5,1
openstack%2Fcinder~master~I62f446786360c61288a788be29d1daa6e409c7b1,openstack/cinder,master,I62f446786360c61288a788be29d1daa6e409c7b1,Report better capacity info for a limitless 3par cpg,MERGED,2014-12-10 02:09:58.000000000,2014-12-13 19:56:39.000000000,2014-12-11 05:20:29.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 11880}, {'_account_id': 11903}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 14242}]","[{'number': 1, 'created': '2014-12-10 02:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/30573ad5b7baaff6c826b570fb7d1e80127701ec', 'message': 'Fix to report better free_capacity for a limitless 3par cpg\n\nThis change has the following improvement:\n\n1. Uses getCPGAvailableSpace from hp3parclient to report\nfree_capapcity for a limitless cpg.\n\n2. TBD for total_capacity for limitless cpg\n\nCloses-Bug #1398651\nChange-Id: I62f446786360c61288a788be29d1daa6e409c7b1\n'}, {'number': 2, 'created': '2014-12-10 02:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5bc7d136dc0484140cfd481855c512a7a6ff9cb2', 'message': 'Report better capacity info for a limitless 3par cpg\n\nThis change has the following improvement:\n\n1. Uses getCPGAvailableSpace from hp3parclient to report\nfree_capapcity for a limitless cpg.\n\n2. TBD for total_capacity for limitless cpg\n\nCloses-Bug #1398651\nChange-Id: I62f446786360c61288a788be29d1daa6e409c7b1\n'}, {'number': 3, 'created': '2014-12-11 01:17:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/1013e9bf2ae8a206cdee846d27970869e7acf1a3', 'message': ""Report better capacity info for a limitless 3par cpg\n\nThis change has the following improvement:\n\n1. Uses getCPGAvailableSpace from hp3parclient to report\nfree_capapcity for a limitless cpg.\n\n2. Uses cpg's SDUsage.usedMiB + UsrUsage.usedMiB + free_capacity\nto calculate the total_capacity for a limitless cpg. This is the\nbest we can do for a limitless cpg.\n\nCloses-Bug: #1398651\nChange-Id: I62f446786360c61288a788be29d1daa6e409c7b1\n""}, {'number': 4, 'created': '2014-12-11 01:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5d313e5caf302d567d21bd5a15a7cd4abafba1d4', 'message': ""Report better capacity info for a limitless 3par cpg\n\nThis change has the following improvement:\n\n1. Uses getCPGAvailableSpace from hp3parclient to report\nfree_capapcity for a limitless cpg.\n\n2. Uses cpg's SDUsage.usedMiB + UsrUsage.usedMiB + free_capacity\nto calculate the total_capacity for a limitless cpg. This is the\nbest we can do for a limitless cpg.\n\nCloses-Bug: #1398651\nChange-Id: I62f446786360c61288a788be29d1daa6e409c7b1\n""}, {'number': 5, 'created': '2014-12-11 01:38:15.000000000', 'files': ['cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/92888e514b37c3ce3c0502e66e183a40da1b4249', 'message': ""Report better capacity info for a limitless 3par cpg\n\nThis change has the following improvement:\n\n1. Uses getCPGAvailableSpace from hp3parclient to report\nfree_capapcity for a limitless cpg.\n\n2. Uses cpg's SDUsage.usedMiB + UsrUsage.usedMiB + free_capacity\nto calculate the total_capacity for a limitless cpg. This is the\nbest we can do for a limitless cpg.\n\nCloses-Bug: #1398651\nChange-Id: I62f446786360c61288a788be29d1daa6e409c7b1\n""}]",6,140553,92888e514b37c3ce3c0502e66e183a40da1b4249,27,11,5,11880,,,0,"Report better capacity info for a limitless 3par cpg

This change has the following improvement:

1. Uses getCPGAvailableSpace from hp3parclient to report
free_capapcity for a limitless cpg.

2. Uses cpg's SDUsage.usedMiB + UsrUsage.usedMiB + free_capacity
to calculate the total_capacity for a limitless cpg. This is the
best we can do for a limitless cpg.

Closes-Bug: #1398651
Change-Id: I62f446786360c61288a788be29d1daa6e409c7b1
",git fetch https://review.opendev.org/openstack/cinder refs/changes/53/140553/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_hp3par.py', 'cinder/volume/drivers/san/hp/hp_3par_common.py']",2,30573ad5b7baaff6c826b570fb7d1e80127701ec,bug/1398651," 2.0.29 - Report limitless cpg's stats better bug #1398651 VERSION = ""2.0.29"" # cpg usable free space cpg_avail_space = \ self.client.getCPGAvailableSpace(cpg_name) free_capacity = cpg_avail_space['usableFreeMiB'] * const"," VERSION = ""2.0.28"" free_capacity = info['freeCapacityMiB'] * const",32,9
openstack%2Fmurano-dashboard~master~I548ef3f761c4ac78a9cb5671b2952a8b603f2a7b,openstack/murano-dashboard,master,I548ef3f761c4ac78a9cb5671b2952a8b603f2a7b,DO NOT LOOK AT ME,ABANDONED,2014-12-13 18:02:28.000000000,2014-12-13 19:43:31.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-13 18:02:28.000000000', 'files': ['test.ci'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/053980211bdb3c26b990fa0de8c297cbd3b459ea', 'message': 'DO NOT LOOK AT ME\n\nChange-Id: I548ef3f761c4ac78a9cb5671b2952a8b603f2a7b\n'}]",0,141569,053980211bdb3c26b990fa0de8c297cbd3b459ea,5,2,1,7600,,,0,"DO NOT LOOK AT ME

Change-Id: I548ef3f761c4ac78a9cb5671b2952a8b603f2a7b
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/69/141569/1 && git format-patch -1 --stdout FETCH_HEAD,['test.ci'],1,053980211bdb3c26b990fa0de8c297cbd3b459ea,testci,hello ,,1,0
openstack%2Fceilometer~master~I7bc511408e457b3f64bfa340118ef1712343aabd,openstack/ceilometer,master,I7bc511408e457b3f64bfa340118ef1712343aabd,[WIP] Update constraints for SQLAlchemy,ABANDONED,2014-12-13 19:07:00.000000000,2014-12-13 19:27:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-13 19:07:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/a0c109c204db421605ebb1ed5c8bcdb32644aac8', 'message': '[WIP] Update constraints for SQLAlchemy\n\nChange-Id: I7bc511408e457b3f64bfa340118ef1712343aabd\n'}]",0,141574,a0c109c204db421605ebb1ed5c8bcdb32644aac8,3,1,1,7600,,,0,"[WIP] Update constraints for SQLAlchemy

Change-Id: I7bc511408e457b3f64bfa340118ef1712343aabd
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/74/141574/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a0c109c204db421605ebb1ed5c8bcdb32644aac8,,"SQLAlchemy>=0.9.7,<=0.9.99","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fcongress~master~Idf6f105c857c2d1db2ece15168d4885a35f81340,openstack/congress,master,Idf6f105c857c2d1db2ece15168d4885a35f81340,Remove code to run scripts directly,MERGED,2014-12-13 13:37:18.000000000,2014-12-13 18:48:40.000000000,2014-12-13 18:48:40.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-13 13:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/d44eb2b547f52c1b71cfe7c3ef97e25bc02cb46b', 'message': 'Remove code to run scripts directly\n\nChange-Id: Idf6f105c857c2d1db2ece15168d4885a35f81340\nCloses-Bug: #1399509\n'}, {'number': 2, 'created': '2014-12-13 13:41:40.000000000', 'files': ['congress/api/webservice.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/tests/datasources/test_ceilometer_driver.py', 'congress/tests/datasources/test_nova_driver.py', 'congress/api/application.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/datasource_driver.py', 'congress/datasources/cinder_driver.py', 'congress/datasources/keystone_driver.py', 'congress/tests/datasources/plexxi_fakes.py', 'congress/policy/builtin/congressbuiltin.py', 'congress/datasources/benchmark_driver.py', 'congress/datasources/nova_driver.py', 'congress/tests/datasources/test_swift_driver.py', 'congress/tests/datasources/test_keystone_driver.py', 'congress/datasources/swift_driver.py', 'congress/tests/helper.py', 'congress/tests/datasources/test_neutron_driver.py', 'congress/tests/datasources/test_plexxi_driver.py', 'congress/tests/datasources/test_cinder_driver.py', 'congress/tests/datasources/test_glancev2_driver.py', 'congress/datasources/glancev2_driver.py', 'congress/tests/datasources/test_driver.py', 'congress/datasources/plexxi_driver.py', 'congress/dse/d6cage.py', 'congress/datasources/ceilometer_driver.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/fd3f1c83d087d80d7cdc566d375843ac586b2672', 'message': 'Remove code to run scripts directly\n\nChange-Id: Idf6f105c857c2d1db2ece15168d4885a35f81340\nCloses-Bug: #1399509\n'}]",0,141551,fd3f1c83d087d80d7cdc566d375843ac586b2672,8,4,2,7770,,,0,"Remove code to run scripts directly

Change-Id: Idf6f105c857c2d1db2ece15168d4885a35f81340
Closes-Bug: #1399509
",git fetch https://review.opendev.org/openstack/congress refs/changes/51/141551/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/api/webservice.py', 'congress/tests/datasources/test_datasource_driver.py', 'congress/tests/datasources/test_ceilometer_driver.py', 'congress/tests/datasources/test_nova_driver.py', 'congress/api/application.py', 'congress/datasources/neutron_driver.py', 'congress/datasources/datasource_driver.py', 'congress/datasources/cinder_driver.py', 'congress/datasources/keystone_driver.py', 'congress/tests/datasources/plexxi_fakes.py', 'congress/policy/builtin/congressbuiltin.py', 'congress/datasources/benchmark_driver.py', 'congress/datasources/nova_driver.py', 'congress/tests/datasources/test_swift_driver.py', 'congress/tests/datasources/test_keystone_driver.py', 'congress/datasources/swift_driver.py', 'congress/tests/helper.py', 'congress/tests/datasources/test_neutron_driver.py', 'congress/tests/datasources/test_plexxi_driver.py', 'congress/tests/datasources/test_cinder_driver.py', 'congress/tests/datasources/test_glancev2_driver.py', 'congress/datasources/glancev2_driver.py', 'congress/tests/datasources/test_driver.py', 'congress/datasources/plexxi_driver.py', 'congress/dse/d6cage.py', 'congress/datasources/ceilometer_driver.py']",26,d44eb2b547f52c1b71cfe7c3ef97e25bc02cb46b,bug/1399509,,"#!/usr/bin/env python def main(): driver = CeilometerDriver() print(""Last updated: %s"" % driver.get_last_updated_time()) print(""Starting Ceilometer Sync Service"") print(""Tuple Names : "" + str(driver.get_tuple_names())) print(""Tuple Metadata - : "" + str(CeilometerDriver.get_schema())) # sync with the ceilometer service driver.update_from_datasource() print(""Meters: %s"" % driver.get_all(driver.METERS)) print(""Alarms: %s"" % driver.get_all(driver.ALARMS)) print(""Events: %s"" % driver.get_all(driver.EVENTS)) print(""Last updated: %s"" % driver.get_last_updated_time()) print(""Sync completed"") print(""-----------------------------------------"") if __name__ == '__main__': try: main() except SystemExit: # Let system.exit() calls complete normally raise except Exception: raise",0,228
openstack%2Fcongress~master~I6cba0375047a5aad5cd3c76532c9bb76e3388250,openstack/congress,master,I6cba0375047a5aad5cd3c76532c9bb76e3388250,Migrate to oslo.middleware,MERGED,2014-12-13 14:04:09.000000000,2014-12-13 18:45:50.000000000,2014-12-13 18:45:49.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 7770}, {'_account_id': 8215}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-13 14:04:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/c11396c6774dbb19448a6e8f181f145d76da9c01', 'message': 'Migrate to oslo.middleware\n\nThe incubator library has graduated and will be removed soon\n\nChange-Id: I6cba0375047a5aad5cd3c76532c9bb76e3388250\nCloses-Bug: #1398639\n'}, {'number': 2, 'created': '2014-12-13 14:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/bcde0c6be312b225c2bdc6bbb6eebf1d3b3c6373', 'message': 'Migrate to oslo.middleware\n\nThe incubator library has graduated and will be removed soon\n\nChange-Id: I6cba0375047a5aad5cd3c76532c9bb76e3388250\nCloses-Bug: #1398639\n'}, {'number': 3, 'created': '2014-12-13 15:14:34.000000000', 'files': ['congress/openstack/common/middleware/__init__.py', 'etc/api-paste.ini', 'requirements.txt', 'congress/openstack/common/middleware/base.py', 'congress/openstack/common/middleware/request_id.py', 'congress/openstack/common/middleware/correlation_id.py', 'congress/tests/test_auth.py', 'congress/auth.py', 'congress/openstack/common/middleware/sizelimit.py', 'congress/openstack/common/middleware/catch_errors.py', 'congress/openstack/common/middleware/debug.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/1eea4579b9997f8b316e4354a0c75361878704b7', 'message': 'Migrate to oslo.middleware\n\nThe incubator library has graduated and will be removed soon\n\nChange-Id: I6cba0375047a5aad5cd3c76532c9bb76e3388250\nCloses-Bug: #1398639\n'}]",0,141552,1eea4579b9997f8b316e4354a0c75361878704b7,14,5,3,7770,,,0,"Migrate to oslo.middleware

The incubator library has graduated and will be removed soon

Change-Id: I6cba0375047a5aad5cd3c76532c9bb76e3388250
Closes-Bug: #1398639
",git fetch https://review.opendev.org/openstack/congress refs/changes/52/141552/2 && git format-patch -1 --stdout FETCH_HEAD,"['congress/openstack/common/middleware/__init__.py', 'etc/api-paste.ini', 'requirements.txt', 'congress/openstack/common/middleware/base.py', 'congress/openstack/common/middleware/request_id.py', 'congress/openstack/common/middleware/correlation_id.py', 'congress/tests/test_auth.py', 'congress/auth.py', 'congress/openstack/common/middleware/sizelimit.py', 'congress/openstack/common/middleware/catch_errors.py', 'congress/openstack/common/middleware/debug.py']",11,c11396c6774dbb19448a6e8f181f145d76da9c01,bug/1398639,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Debug middleware"""""" from __future__ import print_function import sys import six import webob.dec from congress.openstack.common.middleware import base from congress.openstack.common import versionutils @versionutils.deprecated(as_of=versionutils.deprecated.JUNO, in_favor_of='oslo.middleware.Debug') class Debug(base.Middleware): """"""Helper class that returns debug information. Can be inserted into any WSGI application chain to get information about the request and response. """""" @webob.dec.wsgify def __call__(self, req): print((""*"" * 40) + "" REQUEST ENVIRON"") for key, value in req.environ.items(): print(key, ""="", value) print() resp = req.get_response(self.application) print((""*"" * 40) + "" RESPONSE HEADERS"") for (key, value) in six.iteritems(resp.headers): print(key, ""="", value) print() resp.app_iter = self.print_generator(resp.app_iter) return resp @staticmethod def print_generator(app_iter): """"""Prints the contents of a wrapper string iterator when iterated."""""" print((""*"" * 40) + "" BODY"") for part in app_iter: sys.stdout.write(part) sys.stdout.flush() yield part print() ",4,328
openstack%2Ffuel-main~master~I21ae585c1ce50300834ed29517bb7f1ba72ef4e3,openstack/fuel-main,master,I21ae585c1ce50300834ed29517bb7f1ba72ef4e3,Updating mirror URIs,MERGED,2014-09-24 11:45:22.000000000,2014-12-13 18:42:24.000000000,2014-09-25 22:11:06.000000000,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9582}, {'_account_id': 9977}, {'_account_id': 11110}, {'_account_id': 12817}]","[{'number': 1, 'created': '2014-09-24 11:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1aa2ec199538c4852aea9a6bc0effb8a591178e1', 'message': 'Updating mirror URIs\n\nChange-Id: I21ae585c1ce50300834ed29517bb7f1ba72ef4e3\n'}, {'number': 2, 'created': '2014-09-25 21:07:23.000000000', 'files': ['config.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5579585121f8445e061bde9a8bd48fb7e53714cd', 'message': 'Updating mirror URIs\n\nChange-Id: I21ae585c1ce50300834ed29517bb7f1ba72ef4e3\n'}]",0,123707,5579585121f8445e061bde9a8bd48fb7e53714cd,32,8,2,8965,,,0,"Updating mirror URIs

Change-Id: I21ae585c1ce50300834ed29517bb7f1ba72ef4e3
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/07/123707/1 && git format-patch -1 --stdout FETCH_HEAD,['config.mk'],1,1aa2ec199538c4852aea9a6bc0effb8a591178e1,,"ifeq ($(USE_MIRROR),us)ifeq ($(USE_MIRROR),ext) YUM_REPOS?=proprietary MIRROR_BASE?=http://mirror.fuel-infra.org/fwm/$(PRODUCT_VERSION) MIRROR_CENTOS?=$(MIRROR_BASE)/centos MIRROR_UBUNTU?=$(MIRROR_BASE)/ubuntu MIRROR_DOCKER?=$(MIRROR_BASE)/docker endifMIRROR_BASE?=http://osci-mirror-srt.srt.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://osci-mirror-msk.msk.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://osci-mirror-kha.kha.mirantis.net/fwm/$(PRODUCT_VERSION)","ifeq ($(USE_MIRROR),ext)MIRROR_BASE?=http://fuel-mirror.srt.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://fuel-mirror.msk.mirantis.net/fwm/$(PRODUCT_VERSION)MIRROR_BASE?=http://fuel-mirror.kha.mirantis.net/fwm/$(PRODUCT_VERSION)",11,4
openstack%2Fopenstack-manuals~master~Ib59d4a1fb9cf68cd4d7f188f8ad1d2aeeb50eb14,openstack/openstack-manuals,master,Ib59d4a1fb9cf68cd4d7f188f8ad1d2aeeb50eb14,Updated ch_advanced.xml,MERGED,2014-12-12 23:58:21.000000000,2014-12-13 18:30:43.000000000,2014-12-13 18:30:42.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 7751}, {'_account_id': 9515}, {'_account_id': 10068}]","[{'number': 1, 'created': '2014-12-12 23:58:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a893ebe7acf9c762daa87b451765a00f72b9c353', 'message': 'Updated ch_advanced.xml\nCloses-Bug 140208\n\nChange-Id: Ib59d4a1fb9cf68cd4d7f188f8ad1d2aeeb50eb14\n'}, {'number': 2, 'created': '2014-12-13 08:44:49.000000000', 'files': ['doc/networking-guide/ch_advanced.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/23d3fb50d7a68b09b5a1e6fb8befb6693ea2a1ca', 'message': 'Updated ch_advanced.xml\n\nCloses-Bug: #140208\n\nChange-Id: Ib59d4a1fb9cf68cd4d7f188f8ad1d2aeeb50eb14\n'}]",1,141527,23d3fb50d7a68b09b5a1e6fb8befb6693ea2a1ca,13,6,2,13411,,,0,"Updated ch_advanced.xml

Closes-Bug: #140208

Change-Id: Ib59d4a1fb9cf68cd4d7f188f8ad1d2aeeb50eb14
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/27/141527/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/networking-guide/ch_advanced.xml'],1,a893ebe7acf9c762daa87b451765a00f72b9c353,bug/140208," The following topics describe advanced configuration options for various system components. For example, configuration options where the default works but that the user wants to customize options. After installing from packages, <varname>$NEUTRON_CONF_DIR</varname> is <filename>/etc/neutron</filename>."," This section describes advanced configuration options for various system components. For example, configuration options where the default works but that the user wants to customize options. After installing from packages, <varname>$NEUTRON_CONF_DIR</varname> is <filename>/etc/neutron</filename>.",1,1
openstack%2Fkolla~master~I99465069bb3c37e7bf17c6d7a8f3559f87bf7140,openstack/kolla,master,I99465069bb3c37e7bf17c6d7a8f3559f87bf7140,Fixed Neutron Service Proxy and Simplified Naming,MERGED,2014-11-12 14:12:24.000000000,2014-12-13 18:21:29.000000000,2014-12-13 18:21:28.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6924}, {'_account_id': 10419}, {'_account_id': 11822}]","[{'number': 1, 'created': '2014-11-12 14:12:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ee70ae2576648d9c6bd0227c925e0a1ac399f2ce', 'message': 'Fixed Neutron Service Proxy and Simplified Naming\n\nPreviously, the k8s neutron-server service was using a selector\nfor the neutron pod that did not exist. The selector name defined\nin the service yaml was more appropriate than the label (neutron)\ndefined in the pod yaml, so the label was updated in the pod\nyaml.\n\nAdditionally, the naming convention for the neutron pod was\nchanged from neutron-controller to neutron-server to more\ncorrectly depict the pods functionality.\n\nChange-Id: I99465069bb3c37e7bf17c6d7a8f3559f87bf7140\n'}, {'number': 2, 'created': '2014-11-13 19:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1c36fac77db2314993cce54e4c23dffbffc6eb1f', 'message': 'Fixed Neutron Service Proxy and Simplified Naming\n\nPreviously, the k8s neutron-server service was using a selector\nfor the neutron pod that did not exist. The selector name defined\nin the service yaml was more appropriate than the label (neutron)\ndefined in the pod yaml, so the label was updated in the pod\nyaml.\n\nAdditionally, the naming convention for the neutron pod was\nchanged from neutron-controller to neutron-server to more\ncorrectly depict the pods functionality.\n\nChange-Id: I99465069bb3c37e7bf17c6d7a8f3559f87bf7140\n'}, {'number': 3, 'created': '2014-12-12 22:54:13.000000000', 'files': ['tools/start-all-pods'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9aadaef82e9d2de260a7a3e3651b77a790515fcc', 'message': 'Fixed Neutron Service Proxy and Simplified Naming\n\nPreviously, the k8s neutron-server service was using a selector\nfor the neutron pod that did not exist. The selector name defined\nin the service yaml was more appropriate than the label (neutron)\ndefined in the pod yaml, so the label was updated in the pod\nyaml.\n\nAdditionally, the naming convention for the neutron pod was\nchanged from neutron-controller to neutron-server to more\ncorrectly depict the pods functionality.\n\nChange-Id: I99465069bb3c37e7bf17c6d7a8f3559f87bf7140\n'}]",0,133965,9aadaef82e9d2de260a7a3e3651b77a790515fcc,15,5,3,6836,,,0,"Fixed Neutron Service Proxy and Simplified Naming

Previously, the k8s neutron-server service was using a selector
for the neutron pod that did not exist. The selector name defined
in the service yaml was more appropriate than the label (neutron)
defined in the pod yaml, so the label was updated in the pod
yaml.

Additionally, the naming convention for the neutron pod was
changed from neutron-controller to neutron-server to more
correctly depict the pods functionality.

Change-Id: I99465069bb3c37e7bf17c6d7a8f3559f87bf7140
",git fetch https://review.opendev.org/openstack/kolla refs/changes/65/133965/2 && git format-patch -1 --stdout FETCH_HEAD,['k8s/pod/neutron-server-pod.yaml'],1,ee70ae2576648d9c6bd0227c925e0a1ac399f2ce,neutron_kube_svc_fix, id: neutron-server-1id: neutron-server labels: name: neutron-server, id: neutron-controller-1id: neutron-controller labels: name: neutron,3,3
openstack%2Fneutron~master~I74f469219a5d693bda6c12f2b6a035638fd47485,openstack/neutron,master,I74f469219a5d693bda6c12f2b6a035638fd47485,WIP: Sync HA routers states to server when L3 agent starts,ABANDONED,2014-10-13 16:56:58.000000000,2014-12-13 18:14:53.000000000,,"[{'_account_id': 3}, {'_account_id': 2035}, {'_account_id': 5170}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-13 16:56:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4de3c52b10415b7444b8ff01d782315446466bb8', 'message': 'Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed during state transitions. The L3 agent should\nreport all L3 HA routers states when it boots up.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nCloses-Bug: #1365453\n'}, {'number': 2, 'created': '2014-10-13 17:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/450c171baf744fdacad86791291261a1699372a0', 'message': 'Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed during state transitions. The L3 agent should\nreport all L3 HA routers states when it boots up.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nCloses-Bug: #1365453\n'}, {'number': 3, 'created': '2014-11-19 15:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d93aa25224a6f32e679fa9872fc03a834d0281be', 'message': 'Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed during state transitions. The L3 agent should\nreport all L3 HA routers states when it boots up.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nPartially-Implements: blueprint report-ha-router-master\nCloses-Bug: #1365453\n'}, {'number': 4, 'created': '2014-12-07 15:27:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7b79daa1c66be8ec232677c323bbef8116d0b639', 'message': ""WIP: Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed while state transitions were happening.\nThe L3 agent should report all L3 HA routers states when\nit starts.\n\nTo-Do:\n* Implement this patch\n* Write a new patch that adds a timestamp per HA state transition,\n  and introduce the 'fault' state to the DB. Currently the DB and\n  API only support 'active' and 'standby'.\n\nneutron l3-agent-list-hosting-router router\nShould show one of three states, as well as the timestamp of the\nlast transition, as per the spec.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nPartially-Implements: blueprint report-ha-router-master\nCloses-Bug: #1365453\n""}, {'number': 5, 'created': '2014-12-07 18:37:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/707949dc82359172ae6d293450e2e6ae43c164bd', 'message': ""WIP: Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed while state transitions were happening.\nThe L3 agent should report all L3 HA routers states when\nit starts.\n\nTo-Do:\n* Implement this patch\n* Write a new patch that adds a timestamp per HA state transition,\n  and introduce the 'fault' state to the DB. Currently the DB and\n  API only support 'active' and 'standby'.\n\nneutron l3-agent-list-hosting-router router\nShould show one of three states, as well as the timestamp of the\nlast transition, as per the spec.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nPartially-Implements: blueprint report-ha-router-master\nCloses-Bug: #1365453\n""}, {'number': 6, 'created': '2014-12-07 21:46:52.000000000', 'files': ['neutron/agent/l3_agent.py', 'neutron/agent/l3_ha_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/91bab7687a1494e428026ed6bc143ced4073c499', 'message': ""WIP: Sync HA routers states to server when L3 agent starts\n\nState change notifications might be lost if the L3 agent\ncrashed while state transitions were happening.\nThe L3 agent should report all L3 HA routers states when\nit starts.\n\nTo-Do:\n* Implement this patch\n* Write a new patch that adds a timestamp per HA state transition,\n  and introduce the 'fault' state to the DB. Currently the DB and\n  API only support 'active' and 'standby'.\n\nneutron l3-agent-list-hosting-router router\nShould show one of three states, as well as the timestamp of the\nlast transition, as per the spec.\n\nChange-Id: I74f469219a5d693bda6c12f2b6a035638fd47485\nPartially-Implements: blueprint report-ha-router-master\n""}]",0,128014,91bab7687a1494e428026ed6bc143ced4073c499,119,27,6,8873,,,0,"WIP: Sync HA routers states to server when L3 agent starts

State change notifications might be lost if the L3 agent
crashed while state transitions were happening.
The L3 agent should report all L3 HA routers states when
it starts.

To-Do:
* Implement this patch
* Write a new patch that adds a timestamp per HA state transition,
  and introduce the 'fault' state to the DB. Currently the DB and
  API only support 'active' and 'standby'.

neutron l3-agent-list-hosting-router router
Should show one of three states, as well as the timestamp of the
last transition, as per the spec.

Change-Id: I74f469219a5d693bda6c12f2b6a035638fd47485
Partially-Implements: blueprint report-ha-router-master
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/128014/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3_agent.py', 'neutron/agent/l3_ha_agent.py']",2,4de3c52b10415b7444b8ff01d782315446466bb8,bp/report-ha-router-master," def sync_ha_states(self, routers): # TODO(amuller): Read HA state from disk, update server via RPC pass ",,5,0
openstack%2Fneutron-vpnaas~master~I80fa00ec4e229fb3cb6ea009fd4d825055f56954,openstack/neutron-vpnaas,master,I80fa00ec4e229fb3cb6ea009fd4d825055f56954,Update test code to import neutron_vpnaas.services,ABANDONED,2014-12-13 14:14:35.000000000,2014-12-13 17:54:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 9656}, {'_account_id': 10237}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-13 14:14:35.000000000', 'files': ['neutron_vpnaas/tests.skip/unit/db/vpn/test_db_vpnaas.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/service_drivers/test_cisco_ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/8bdfd406d178491a35457239e7b0ea19bc5bf3f3', 'message': ""Update test code to import neutron_vpnaas.services\n\nSome vpn test code still refers to neutron.services\ninstead of neutron_vpnaas.services because of which\nthe test cases are failing.\n\nThis patch fixes the issue by changing to 'neutron_vpnaas_services'\nin  the test code.\n\nChange-Id: I80fa00ec4e229fb3cb6ea009fd4d825055f56954\nCloses-bug: #1402197\n""}]",0,141553,8bdfd406d178491a35457239e7b0ea19bc5bf3f3,5,5,1,10237,,,0,"Update test code to import neutron_vpnaas.services

Some vpn test code still refers to neutron.services
instead of neutron_vpnaas.services because of which
the test cases are failing.

This patch fixes the issue by changing to 'neutron_vpnaas_services'
in  the test code.

Change-Id: I80fa00ec4e229fb3cb6ea009fd4d825055f56954
Closes-bug: #1402197
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/53/141553/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests.skip/unit/db/vpn/test_db_vpnaas.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/service_drivers/test_ipsec.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/test_vpn_agent.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/device_drivers/test_ipsec.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/test_vpnaas_driver_plugin.py', 'neutron_vpnaas/tests.skip/unit/services/vpn/service_drivers/test_cisco_ipsec.py']",6,8bdfd406d178491a35457239e7b0ea19bc5bf3f3,bug/1402197,CISCO_IPSEC_SERVICE_DRIVER = ('neutron_vpnaas.services.vpn.service_drivers.',CISCO_IPSEC_SERVICE_DRIVER = ('neutron.services.vpn.service_drivers.',10,10
openstack%2Ftaskflow~master~I17d4f02241c90a49fc4334cfd1f2fffd03d58927,openstack/taskflow,master,I17d4f02241c90a49fc4334cfd1f2fffd03d58927,Just assign a empty collection instead of copy/clear,MERGED,2014-12-09 23:52:59.000000000,2014-12-13 16:35:30.000000000,2014-12-10 07:05:25.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 7787}]","[{'number': 1, 'created': '2014-12-09 23:52:59.000000000', 'files': ['taskflow/task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b275c51a6fcf85d69af4e1ae7ee3d3918db8850b', 'message': ""Just assign a empty collection instead of copy/clear\n\nInstead of copying the '_events_listeners' then clear\nthem to get a clean copy just set the copies '_events_listeners'\nto a new collection in the first place.\n\nChange-Id: I17d4f02241c90a49fc4334cfd1f2fffd03d58927\n""}]",0,140530,b275c51a6fcf85d69af4e1ae7ee3d3918db8850b,10,3,1,1297,,,0,"Just assign a empty collection instead of copy/clear

Instead of copying the '_events_listeners' then clear
them to get a clean copy just set the copies '_events_listeners'
to a new collection in the first place.

Change-Id: I17d4f02241c90a49fc4334cfd1f2fffd03d58927
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/30/140530/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/task.py'],1,b275c51a6fcf85d69af4e1ae7ee3d3918db8850b,, c._events_listeners = collections.defaultdict(list), c._events_listeners = c._events_listeners.copy() c._events_listeners.clear(),1,2
openstack%2Fswift~stable%2Fjuno~Iab607b03b7f011e87b799d1f9af7ab3b4ff30019,openstack/swift,stable/juno,Iab607b03b7f011e87b799d1f9af7ab3b4ff30019,Clean up empty account and container partitions directories.,MERGED,2014-12-04 23:08:05.000000000,2014-12-13 16:21:06.000000000,2014-12-13 08:51:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 330}, {'_account_id': 1420}, {'_account_id': 1955}, {'_account_id': 2622}, {'_account_id': 2903}, {'_account_id': 7848}, {'_account_id': 9656}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-04 23:08:05.000000000', 'files': ['test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/70e35c6084ddb62a6124cdd5ba35f29748dfd746', 'message': 'Clean up empty account and container partitions directories.\n\nBecause we iterate over these directories on a replication run,\nand they are not (previously) cleaned up, the time to start the\nreplication increases incrementally for each stale directory\nlying around.  Thousands of directories across dozens of disks\non a single machine can make for non-trivial startup times.\n\nPlus it just seems like good housekeeping.\nCloses-Bug: #1396152\n\nChange-Id: Iab607b03b7f011e87b799d1f9af7ab3b4ff30019\n'}]",0,139255,70e35c6084ddb62a6124cdd5ba35f29748dfd746,15,10,1,330,,,0,"Clean up empty account and container partitions directories.

Because we iterate over these directories on a replication run,
and they are not (previously) cleaned up, the time to start the
replication increases incrementally for each stale directory
lying around.  Thousands of directories across dozens of disks
on a single machine can make for non-trivial startup times.

Plus it just seems like good housekeeping.
Closes-Bug: #1396152

Change-Id: Iab607b03b7f011e87b799d1f9af7ab3b4ff30019
",git fetch https://review.opendev.org/openstack/swift refs/changes/55/139255/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/test_db_replicator.py', 'swift/common/db_replicator.py']",2,70e35c6084ddb62a6124cdd5ba35f29748dfd746,bp, if not suffixes: os.rmdir(part_dir),,31,5
openstack%2Fdevstack~master~Ic15d2ad6d3616bfde4838873d0c79664b009ef1f,openstack/devstack,master,Ic15d2ad6d3616bfde4838873d0c79664b009ef1f,Change Cinder Cert script to run all Volume tests,MERGED,2014-12-10 04:50:35.000000000,2014-12-13 16:07:33.000000000,2014-12-13 16:07:31.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 04:50:35.000000000', 'files': ['driver_certs/cinder_driver_cert.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/19d22bd19a1802cae3eab2c194cb7c0dd7d3c47c', 'message': 'Change Cinder Cert script to run all Volume tests\n\nThe Cinder Cert script currently only runs the Tempest\ntests tagged with volume.api, should be all Volume tests\nto make sure we get things like attach and other commands\nfully tested.\n\nChange-Id: Ic15d2ad6d3616bfde4838873d0c79664b009ef1f\n'}]",0,140570,19d22bd19a1802cae3eab2c194cb7c0dd7d3c47c,8,4,1,2243,,,0,"Change Cinder Cert script to run all Volume tests

The Cinder Cert script currently only runs the Tempest
tests tagged with volume.api, should be all Volume tests
to make sure we get things like attach and other commands
fully tested.

Change-Id: Ic15d2ad6d3616bfde4838873d0c79664b009ef1f
",git fetch https://review.opendev.org/openstack/devstack refs/changes/70/140570/1 && git format-patch -1 --stdout FETCH_HEAD,['driver_certs/cinder_driver_cert.sh'],1,19d22bd19a1802cae3eab2c194cb7c0dd7d3c47c,update_cinder_cert_to_include_all_volume_tests,"log_message ""Run the actual tempest volume tests (./tools/pretty_tox.sh volume)..."", True","log_message ""Run the actual tempest volume tests (./tools/pretty_tox.sh api.volume)..."", True",1,1
openstack%2Fnetworking-odl~master~I3d05450221f09da4427d9822e03772bc7ef641cf,openstack/networking-odl,master,I3d05450221f09da4427d9822e03772bc7ef641cf,Initial commit for networking-odl,ABANDONED,2014-12-09 00:58:32.000000000,2014-12-13 15:59:17.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 8788}, {'_account_id': 9656}, {'_account_id': 11692}, {'_account_id': 11952}]","[{'number': 1, 'created': '2014-12-09 00:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/8e09a32f89cb49e321fade3321c60c712aae9614', 'message': 'Initial commit for networking-odl\n\nThis commit collapses all the work done by myself, Dave Tucker, and\nFlavio Fernandes.\n\nChange-Id: I3d05450221f09da4427d9822e03772bc7ef641cf\nCo-Authored-By: Dave Tucker <dave@dtucker.co.uk>\nCo-Authored-By: Flavio Fernandes <ffernand@redhat.com>\n'}, {'number': 2, 'created': '2014-12-10 20:48:26.000000000', 'files': ['odldrivers/fwaas/__init__.py', 'tools/subunit-trace.py', '.gitignore', '.pylintrc', 'odldrivers/common/auth.py', 'odldrivers/ml2/__init__.py', 'test-requirements.txt', 'README.rst', 'etc/neutron/plugins/opendaylight/odl_rest.ini', 'setup.py', 'odldrivers/fwaas/driver.py', 'odldrivers/common/config.py', 'requirements.txt', 'odldrivers/ml2/README.rst', 'odldrivers/common/client.py', 'odldrivers/tests/__init__.py', 'odldrivers/l3/__init__.py', 'odldrivers/common/__init__.py', 'MANIFEST.in', 'odldrivers/tests/unit/__init__.py', '.testr.conf', 'odldrivers/lbaas/__init__.py', 'odldrivers/__init__.py', 'odl_neutron_drivers.sublime-project', 'odldrivers/common/utils.py', 'odldrivers/lbaas/driver.py', 'setup.cfg', 'odldrivers/ml2/mech_driver.py', 'tox.ini', 'odldrivers/common/exceptions.py', 'odldrivers/l3/l3_odl.py', 'odldrivers/tests/unit/test_mechanism_odl.py', 'tools/pretty_tox.sh', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/af7039ea4e42df545106cb93ec6f2aa0460313eb', 'message': 'Initial commit for networking-odl\n\nThis commit helps the ODL driver comply with the plugin decomposition\nwork being done in Neutron during Kilo [1]. This is the second part,\nthere is a corresponding Neutron change which will thin the in-tree\ndriver as well.\n\nThis commit collapses all the work done by myself, Dave Tucker,\nCédric Ollivier, Flavio Fernandes.\n\n[1] https://review.openstack.org/#/c/134680/\n\nChange-Id: I3d05450221f09da4427d9822e03772bc7ef641cf\nCo-Authored-By: Dave Tucker <dave@dtucker.co.uk>\nCo-Authored-By: Flavio Fernandes <ffernand@redhat.com>\n'}]",6,140191,af7039ea4e42df545106cb93ec6f2aa0460313eb,22,8,2,105,,,0,"Initial commit for networking-odl

This commit helps the ODL driver comply with the plugin decomposition
work being done in Neutron during Kilo [1]. This is the second part,
there is a corresponding Neutron change which will thin the in-tree
driver as well.

This commit collapses all the work done by myself, Dave Tucker,
Cédric Ollivier, Flavio Fernandes.

[1] https://review.openstack.org/#/c/134680/

Change-Id: I3d05450221f09da4427d9822e03772bc7ef641cf
Co-Authored-By: Dave Tucker <dave@dtucker.co.uk>
Co-Authored-By: Flavio Fernandes <ffernand@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/91/140191/2 && git format-patch -1 --stdout FETCH_HEAD,"['odldrivers/fwaas/__init__.py', 'tools/subunit-trace.py', '.gitignore', '.pylintrc', 'odldrivers/common/auth.py', 'odldrivers/ml2/__init__.py', 'test-requirements.txt', 'README.rst', 'etc/neutron/plugins/opendaylight/odl_rest.ini', 'puppet/hiera.yaml', 'puppet/hieradata/hosts.json', 'setup.py', 'K', 'odldrivers/fwaas/driver.py', 'odldrivers/common/config.py', 'puppet/templates/control.local.conf.erb', 'requirements.txt', 'odldrivers/ml2/README.rst', 'odldrivers/common/client.py', 'odldrivers/tests/__init__.py', 'Vagrantfile', 'odldrivers/l3/__init__.py', 'odldrivers/common/__init__.py', 'LICENSE', 'puppet/scripts/bootstrap.sh', 'puppet/manifests/mininet.pp', 'MANIFEST.in', 'puppet/manifests/devstack-compute.pp', 'odldrivers/tests/unit/__init__.py', 'puppet/manifests/base.pp', 'puppet/templates/compute.local.conf.erb', 'puppet/manifests/devstack-control.pp', '.testr.conf', 'puppet/templates/hosts.erb', 'odldrivers/lbaas/__init__.py', 'odldrivers/__init__.py', 'odl_neutron_drivers.sublime-project', 'odldrivers/common/utils.py', 'odldrivers/lbaas/driver.py', 'setup.cfg', 'odldrivers/ml2/mech_driver.py', 'tox.ini', 'odldrivers/common/exceptions.py', 'odldrivers/l3/l3_odl.py', 'odldrivers/tests/unit/test_mechanism_odl.py', 'tools/pretty_tox.sh', 'HACKING.rst']",47,8e09a32f89cb49e321fade3321c60c712aae9614,,,,2464,0
openstack%2Frally~master~I93eb390a9beeff50fdf58b2190ea8ce74609cd3e,openstack/rally,master,I93eb390a9beeff50fdf58b2190ea8ce74609cd3e,Updated from global requirements,MERGED,2014-12-12 22:22:49.000000000,2014-12-13 14:29:12.000000000,2014-12-13 14:29:11.000000000,"[{'_account_id': 3}, {'_account_id': 8507}, {'_account_id': 14135}]","[{'number': 1, 'created': '2014-12-12 22:22:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/rally/commit/879b1ab12efe548fd8c2d56809e5b24e65ed22ab', 'message': 'Updated from global requirements\n\nChange-Id: I93eb390a9beeff50fdf58b2190ea8ce74609cd3e\n'}]",0,141512,879b1ab12efe548fd8c2d56809e5b24e65ed22ab,15,3,1,11131,,,0,"Updated from global requirements

Change-Id: I93eb390a9beeff50fdf58b2190ea8ce74609cd3e
",git fetch https://review.opendev.org/openstack/rally refs/changes/12/141512/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,879b1ab12efe548fd8c2d56809e5b24e65ed22ab,openstack/requirements,python-glanceclient>=0.15.0,python-glanceclient>=0.14.0,1,1
openstack%2Fmurano~master~I9632078c587cd79f3f03edce3a1895a23aa84e56,openstack/murano,master,I9632078c587cd79f3f03edce3a1895a23aa84e56,DO NOT LOOK AT ME,ABANDONED,2014-12-12 19:18:48.000000000,2014-12-13 11:33:23.000000000,,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-12 19:18:48.000000000', 'files': ['test.ci'], 'web_link': 'https://opendev.org/openstack/murano/commit/077317cac7d4867ea90d211f85a9fe6c8c103272', 'message': 'DO NOT LOOK AT ME\n\nChange-Id: I9632078c587cd79f3f03edce3a1895a23aa84e56\n'}]",0,141471,077317cac7d4867ea90d211f85a9fe6c8c103272,11,3,1,7600,,,0,"DO NOT LOOK AT ME

Change-Id: I9632078c587cd79f3f03edce3a1895a23aa84e56
",git fetch https://review.opendev.org/openstack/murano refs/changes/71/141471/1 && git format-patch -1 --stdout FETCH_HEAD,['test.ci'],1,077317cac7d4867ea90d211f85a9fe6c8c103272,testci,hello ci ,,1,0
openstack%2Fneutron~stable%2Fjuno~Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc,openstack/neutron,stable/juno,Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc,BSN: Optimistic locking strategy for consistency,MERGED,2014-11-21 09:35:10.000000000,2014-12-13 08:51:19.000000000,2014-12-13 08:51:17.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 1955}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 10119}, {'_account_id': 10153}, {'_account_id': 10980}, {'_account_id': 12040}]","[{'number': 1, 'created': '2014-11-21 09:35:10.000000000', 'files': ['neutron/tests/unit/bigswitch/test_agent_scheduler.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/bigswitch/test_servermanager.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/bigswitch/test_security_groups.py', 'neutron/tests/unit/bigswitch/test_ssl.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/db/consistency_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/615e2d6399ca443a27ca3476d326faa2ae7a3fa2', 'message': ""BSN: Optimistic locking strategy for consistency\n\nSummary:\n  Adds an optimistic locking strategy for the Big Switch\n  server manager so multiple Neutron servers wanting to\n  communicate with the backend do not receive the consistency\n  hash for use simultaneously.\n\n  The bsn-rest-call semaphore is removed because serialization\n  is now provided by the new locking scheme.\n\n  A new DB engine is added because the consistency hashes\n  need a life-cycle with rollbacks and other DB operations\n  than cannot impact or be impacted by database operations\n  happening on the regular Neutron objects.\n\n  Unit tests are included for each of the new branches\n  introduced.\n\nProblem Statement:\n  Requests to the Big Switch controllers must contain the\n  consistency hash value received from the previous update.\n  Otherwise, an inconsistency error will be triggered which\n  will force a synchronization. Essentially, a new backend\n  call must be prevented from reading from the consistency\n  hash table in the DB until the previous call has updated\n  the table with the hash from the server response.\n\n  This can be addressed by a semaphore around the rest_call\n  function for the single server use case and by a table lock\n  on the consistency table for multiple Neutron servers.\n  However, both solutions are inadequate because a single\n  Neutron server does not scale and a table lock is not\n  supported by common SQL HA deployments (e.g. Galera).\n\n  This issue was previously addressed by deploying servers\n  in an active-standby configuration. However, that only\n  prevented the problem for HTTP API calls. All Neutron\n  servers would respond to RPC messages, some of which would\n  result in a port update and possible backend call which\n  would trigger a conflict if it happened at the same time\n  as a backend call from another server. These unnecessary\n  syncs are unsustainable as the topology increases beyond\n  ~3k VMs.\n\n  Any solution needs to be back-portable to Icehouse so new\n  database tables, new requirements, etc. are all out of the\n  question.\n\nSolution:\n  This patch stores the lock for the consistency hash as a part\n  of the DB record. The guaruntees the database offers around\n  atomic insertion and constrained atomic updates offer the\n  primitives necessary to ensure that only one process/thread\n  can lock the record at once.\n\n  The read_for_update method is modified to not return the hash\n  in the database until an identifier is inserted into the\n  current record or added as a new record. By using an UPDATE\n  query with a WHERE clause restricting to the current state,\n  only one of many concurrent callers to the DB will successfully\n  update the rows. If a caller sees that it didn't update any\n  rows, it will start the process over of trying to get the\n  lock.\n\n  If a caller observes that the same ID has the lock for\n  more than 60 seconds, it will assume the holder has\n  died and will attempt to take the lock. This is also done\n  in a concurrency-safe UPDATE call since there may be many\n  other callers may attempt to do the same thing. If it\n  fails and the lock was taken by someone else, the process\n  will start over.\n\n  Some pseudo-code resembling the logic:\n    read_current_lock\n    if no_record:\n      insert_lock\n      sleep_and_retry if constraint_violation else return\n    if current_is_locked and not timer_exceeded:\n      sleep_and_retry\n    if update_record_with_lock:\n      return\n    else:\n      sleep_and_retry\n\nConflicts:\n\tneutron/tests/unit/bigswitch/test_servermanager.py\n\nCloses-Bug: #1374261\nChange-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc\n(cherry picked from commit cdaa502f899d4c90c5e40ccd745f1d92bfd1127b)\n""}]",0,136275,615e2d6399ca443a27ca3476d326faa2ae7a3fa2,25,17,1,7787,,,0,"BSN: Optimistic locking strategy for consistency

Summary:
  Adds an optimistic locking strategy for the Big Switch
  server manager so multiple Neutron servers wanting to
  communicate with the backend do not receive the consistency
  hash for use simultaneously.

  The bsn-rest-call semaphore is removed because serialization
  is now provided by the new locking scheme.

  A new DB engine is added because the consistency hashes
  need a life-cycle with rollbacks and other DB operations
  than cannot impact or be impacted by database operations
  happening on the regular Neutron objects.

  Unit tests are included for each of the new branches
  introduced.

Problem Statement:
  Requests to the Big Switch controllers must contain the
  consistency hash value received from the previous update.
  Otherwise, an inconsistency error will be triggered which
  will force a synchronization. Essentially, a new backend
  call must be prevented from reading from the consistency
  hash table in the DB until the previous call has updated
  the table with the hash from the server response.

  This can be addressed by a semaphore around the rest_call
  function for the single server use case and by a table lock
  on the consistency table for multiple Neutron servers.
  However, both solutions are inadequate because a single
  Neutron server does not scale and a table lock is not
  supported by common SQL HA deployments (e.g. Galera).

  This issue was previously addressed by deploying servers
  in an active-standby configuration. However, that only
  prevented the problem for HTTP API calls. All Neutron
  servers would respond to RPC messages, some of which would
  result in a port update and possible backend call which
  would trigger a conflict if it happened at the same time
  as a backend call from another server. These unnecessary
  syncs are unsustainable as the topology increases beyond
  ~3k VMs.

  Any solution needs to be back-portable to Icehouse so new
  database tables, new requirements, etc. are all out of the
  question.

Solution:
  This patch stores the lock for the consistency hash as a part
  of the DB record. The guaruntees the database offers around
  atomic insertion and constrained atomic updates offer the
  primitives necessary to ensure that only one process/thread
  can lock the record at once.

  The read_for_update method is modified to not return the hash
  in the database until an identifier is inserted into the
  current record or added as a new record. By using an UPDATE
  query with a WHERE clause restricting to the current state,
  only one of many concurrent callers to the DB will successfully
  update the rows. If a caller sees that it didn't update any
  rows, it will start the process over of trying to get the
  lock.

  If a caller observes that the same ID has the lock for
  more than 60 seconds, it will assume the holder has
  died and will attempt to take the lock. This is also done
  in a concurrency-safe UPDATE call since there may be many
  other callers may attempt to do the same thing. If it
  fails and the lock was taken by someone else, the process
  will start over.

  Some pseudo-code resembling the logic:
    read_current_lock
    if no_record:
      insert_lock
      sleep_and_retry if constraint_violation else return
    if current_is_locked and not timer_exceeded:
      sleep_and_retry
    if update_record_with_lock:
      return
    else:
      sleep_and_retry

Conflicts:
	neutron/tests/unit/bigswitch/test_servermanager.py

Closes-Bug: #1374261
Change-Id: Ifa5a7c9749952bc2785a9bf3fed69ad55bf21acc
(cherry picked from commit cdaa502f899d4c90c5e40ccd745f1d92bfd1127b)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/75/136275/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/bigswitch/test_agent_scheduler.py', 'neutron/tests/unit/bigswitch/test_base.py', 'neutron/tests/unit/bigswitch/test_router_db.py', 'neutron/tests/unit/bigswitch/test_restproxy_plugin.py', 'neutron/tests/unit/bigswitch/test_servermanager.py', 'neutron/tests/unit/bigswitch/test_security_groups.py', 'neutron/tests/unit/bigswitch/test_ssl.py', 'neutron/plugins/bigswitch/servermanager.py', 'neutron/plugins/bigswitch/db/consistency_db.py']",9,615e2d6399ca443a27ca3476d326faa2ae7a3fa2,,"import random import re import string import time from oslo.config import cfg from oslo.db import exception as db_exc from oslo.db.sqlalchemy import sessionfrom neutron.openstack.common.gettextutils import _LI, _LW# Maximum time in seconds to wait for a single record lock to be released # NOTE: The total time waiting may exceed this if there are multiple servers # waiting for the same lock MAX_LOCK_WAIT_TIME = 15 def setup_db(): '''Helper to register models for unit tests''' if HashHandler._FACADE is None: HashHandler._FACADE = session.EngineFacade.from_config( cfg.CONF, sqlite_fk=True) ConsistencyHash.metadata.create_all( HashHandler._FACADE.get_engine()) def clear_db(): '''Helper to unregister models and clear engine in unit tests''' if not HashHandler._FACADE: return ConsistencyHash.metadata.drop_all(HashHandler._FACADE.get_engine()) HashHandler._FACADE = None This class needs an SQL engine completely independent of the main neutron connection so rollbacks from consistency hash operations don't affect the parent sessions. ''' _FACADE = None def __init__(self, hash_id='1'): if HashHandler._FACADE is None: HashHandler._FACADE = session.EngineFacade.from_config( cfg.CONF, sqlite_fk=True) self.hash_id = hash_id self.session = HashHandler._FACADE.get_session(autocommit=True, expire_on_commit=False) self.random_lock_id = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10)) self.lock_marker = 'LOCKED_BY[%s]' % self.random_lock_id def _get_current_record(self): if res: self.session.refresh(res) # make sure latest is loaded from db return res def _insert_empty_hash_with_lock(self): # try to insert a new hash, return False on conflict try: with self.session.begin(subtransactions=True): res = ConsistencyHash(hash_id=self.hash_id, hash=self.lock_marker) self.session.add(res) return True except db_exc.DBDuplicateEntry: # another server created a new record at the same time return False def _optimistic_update_hash_record(self, old_record, new_hash): # Optimistic update strategy. Returns True if successful, else False. query = sa.update(ConsistencyHash.__table__).values(hash=new_hash) query = query.where(ConsistencyHash.hash_id == old_record.hash_id) query = query.where(ConsistencyHash.hash == old_record.hash) with self._FACADE.get_engine().begin() as conn: result = conn.execute(query) # We need to check update row count in case another server is # doing this at the same time. Only one will succeed, the other will # not update any rows. return result.rowcount != 0 def _get_lock_owner(self, record): matches = re.findall(""^LOCKED_BY\[(\w+)\]"", record) if not matches: return None return matches[0] def read_for_update(self): # An optimistic locking strategy with a timeout to avoid using a # consistency hash while another server is using it. This will # not return until a lock is acquired either normally or by stealing # it after an individual ID holds it for greater than # MAX_LOCK_WAIT_TIME. lock_wait_start = None last_lock_owner = None while True: res = self._get_current_record() if not res: # no current entry. try to insert to grab lock if not self._insert_empty_hash_with_lock(): # A failed insert after missing current record means # a concurrent insert occured. Start process over to # find the new record. LOG.debug(""Concurrent record inserted. Retrying."") time.sleep(0.25) continue # The empty hash was successfully inserted with our lock return '' current_lock_owner = self._get_lock_owner(res.hash) if not current_lock_owner: # no current lock. attempt to lock new = self.lock_marker + res.hash if not self._optimistic_update_hash_record(res, new): # someone else beat us to it. restart process to wait # for new lock ID to be removed LOG.debug( ""Failed to acquire lock. Restarting lock wait. "" ""Previous hash: %(prev)s. Attempted update: %(new)s"" % {'prev': res.hash, 'new': new}) time.sleep(0.25) continue # successfully got the lock return res.hash LOG.debug(""This request's lock ID is %(this)s. "" ""DB lock held by %(that)s"" % {'this': self.random_lock_id, 'that': current_lock_owner}) if current_lock_owner == self.random_lock_id: # no change needed, we already have the table lock due to # previous read_for_update call. # return hash with lock tag stripped off for use in a header return res.hash.replace(self.lock_marker, '') if current_lock_owner != last_lock_owner: # The owner changed since the last iteration, but it # wasn't to us. Reset the counter. Log if not # first iteration. if lock_wait_start: LOG.debug(""Lock owner changed from %(old)s to %(new)s "" ""while waiting to acquire it."", {'old': last_lock_owner, 'new': current_lock_owner}) lock_wait_start = time.time() last_lock_owner = current_lock_owner if time.time() - lock_wait_start > MAX_LOCK_WAIT_TIME: # the lock has been held too long, steal it LOG.warning(_LW(""Gave up waiting for consistency DB "" ""lock, trying to take it. "" ""Current hash is: %s""), res.hash) new_db_value = res.hash.replace(current_lock_owner, self.random_lock_id) if self._optimistic_update_hash_record(res, new_db_value): return res.hash.replace(new_db_value, '') LOG.info(_LI(""Failed to take lock. Another process updated "" ""the DB first."")) def clear_lock(self): LOG.debug(""Clearing hash record lock of id %s"" % self.random_lock_id) with self.session.begin(subtransactions=True): res = (self.session.query(ConsistencyHash). filter_by(hash_id=self.hash_id).first()) if not res: LOG.warning(_LW(""Hash record already gone, no lock to clear."")) return if not res.hash.startswith(self.lock_marker): # if these are frequent the server is too slow LOG.warning(_LW(""Another server already removed the lock. %s""), res.hash) return res.hash = res.hash.replace(self.lock_marker, '') res = (self.session.query(ConsistencyHash). filter_by(hash_id=self.hash_id).first()) if res: res.hash = hash","from neutron.db import api as db ''' def __init__(self, context=None, hash_id='1'): self.hash_id = hash_id self.session = db.get_session() if not context else context.session self.hash_db_obj = None def read_for_update(self): # REVISIT(kevinbenton): locking here with the DB is prone to deadlocks # in various multi-REST-call scenarios (router intfs, flips, etc). # Since it doesn't work in Galera deployments anyway, another sync # mechanism will have to be introduced to prevent inefficient double # syncs in HA deployments. if not res: return '' self.hash_db_obj = res return res.hash if self.hash_db_obj is not None: self.hash_db_obj.hash = hash",318,23
openstack%2Fopenstack-manuals~master~Ibdfe4579221b6d545d9b4577534af0626d019799,openstack/openstack-manuals,master,Ibdfe4579221b6d545d9b4577534af0626d019799,Imported Translations from Transifex,MERGED,2014-12-13 06:14:22.000000000,2014-12-13 08:39:56.000000000,2014-12-13 08:39:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-13 06:14:22.000000000', 'files': ['doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d6de488636a9c912325086351414786ab4a05073', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ibdfe4579221b6d545d9b4577534af0626d019799\n'}]",0,141543,d6de488636a9c912325086351414786ab4a05073,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ibdfe4579221b6d545d9b4577534af0626d019799
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/141543/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/locale/admin-guide-cloud.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot']",4,d6de488636a9c912325086351414786ab4a05073,transifex/translations,"""POT-Creation-Date: 2014-12-13 06:13+0000\n""#: ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:222(title) ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:248(title) ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:273(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1852(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1877(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1903(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1960(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1994(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2035(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2085(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2102(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2126(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2151(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2177(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2217(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2260(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2304(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2321(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2351(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2436(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2460(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2492(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2745(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2762(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2779(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2804(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2828(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2873(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2890(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2907(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2953(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2982(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3011(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3036(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3104(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3151(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3168(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3185(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3202(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3252(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3279(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3364(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3381(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3439(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3457(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3494(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3530(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3564(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3581(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3598(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3647(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3664(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3692(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3717(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3745(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3770(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3795(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3823(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3841(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3897(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3930(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3949(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4002(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4019(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4043(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4105(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4139(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4173(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4190(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4215(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4234(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4278(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4303(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4320(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4348(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4372(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4530(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4548(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4593(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4610(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4643(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4705(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4722(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4748(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4772(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4797(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4829(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5028(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5047(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5099(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5116(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5133(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5162(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5379(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5540(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5579(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5671(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5689(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5714(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5739(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5765(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5782(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5799(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5828(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5864(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5881(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5898(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5915(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5932(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5949(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5966(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6008(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6058(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6107(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6132(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6150(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6192(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6242(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6315(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6332(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6365(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6390(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6407(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6431(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6448(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6484(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6534(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6551(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6568(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6599(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6681(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6698(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6715(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6732(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6749(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6766(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6783(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6867(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6907(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6978(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6995(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7037(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7057(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7103(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7127(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7144(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7161(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7185(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7218(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7244(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1676(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1783(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1836(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1879(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1948(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2035(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2101(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2197(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2285(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2341(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2447(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2501(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2542(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2596(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2641(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2734(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2793(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2869(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2990(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3068(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3107(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3245(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3294(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3348(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3510(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3628(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3683(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3731(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3786(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3832(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3892(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3953(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3990(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4107(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4168(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4252(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4339(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4397(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4643(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4763(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4818(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4873(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4927(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4972(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5023(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5077(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5240(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5278(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5405(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5459(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5502(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5580(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5697(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5750(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5884(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6002(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6059(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6116(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6169(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6214(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6325(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6442(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6495(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6537(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6598(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6718(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6788(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6906(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6963(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7033(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7186(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7304(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7369(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7509(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7569(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7685(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7753(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7808(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7847(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7958(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8012(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8130(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8217(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8270(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8312(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8357(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8444(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8736(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8792(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8861(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8946(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9031(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9324(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9392(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9429(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9467(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9520(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9568(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9697(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9756(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9843(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9896(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9938(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9991(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10117(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10218(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10347(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10405(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10460(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10601(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10745(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10862(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10923(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11055(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11159(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11277(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11332(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11391(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11495(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11613(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11668(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11721(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11799(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11916(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11970(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:629(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:646(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:663(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:689(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:744(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:777(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:794(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:819(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:848(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:873(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:898(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:943(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:978(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:995(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1025(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1057(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1129(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1149(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1237(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1329(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1411(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1432(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1548(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:276(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:340(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:454(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:519(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:602(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:640(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:588(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:662(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:726(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:743(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:784(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:801(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:820(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:930(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:947(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:964(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:981(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1072(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1136(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1173(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1200(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1237(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1262(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1287(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1315(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1349(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1368(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1448(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1519(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1547(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:346(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:387(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:432(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:491(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:588(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:620(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:672(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:719(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:758(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:790(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:858(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:917(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1009(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1061(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1102(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1157(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1185(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1286(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1351(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1419(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1461(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1521(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1580(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1666(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1767(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1817(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1876(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1935(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1976(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2159(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2223(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2266(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2370(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2398(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2434(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2470(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2509(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2537(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2603(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2642(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2678(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2728(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2840(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2900(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2974(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3045(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3076(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3112(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3154(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3241(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3283(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3344(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3402(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3474(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3555(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3714(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3761(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3808(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3836(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3883(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3930(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3962(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3998(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4062(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4118(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4174(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4207(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4254(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4282(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4318(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4377(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4564(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4722(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4753(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4830(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4858(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4914(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4966(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5002(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5041(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5071(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5131(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5161(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5217(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5257(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5357(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5385(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5413(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5441(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5469(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5510(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5555(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5613(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5653(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5706(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5755(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5802(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5849(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5882(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5958(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6026(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6066(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6153(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6191(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6300(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6392(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6448(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6480(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6517(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6573(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6610(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6647(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:609(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:767(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:813(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:985(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1021(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1081(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1100(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1148(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1165(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1270(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1298(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1323(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1349(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1397(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1445(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1482(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1510(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1547(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1573(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1645(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1662(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1679(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1699(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1736(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1762(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1798(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1823(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1841(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1886(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1923(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1969(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2013(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2038(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2056(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2094(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2146(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2172(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2204(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2229(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2271(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:676(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:826(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:843(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:892(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:909(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:926(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1164(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1374(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1587(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1765(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:884(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:928(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:952(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:981(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1005(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1096(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1117(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1174(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1198(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1222(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1254(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1323(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1357(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1374(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1399(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1437(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1462(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1487(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1516(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1541(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1558(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1575(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1616(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1633(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1654(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1706(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1723(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1740(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1760(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1812(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1836(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1863(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1899(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1930(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1966(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2016(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2041(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2061(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2109(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2170(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2204(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2222(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2248(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2285(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2315(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2332(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2357(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2385(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2409(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2426(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2443(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2460(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2504(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2583(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2627(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2644(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2661(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2693(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2721(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2739(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2775(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2827(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2846(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2891(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2940(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2967(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3085(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3105(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3162(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3186(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3210(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3242(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3354(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3448(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3482(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3499(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3524(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3562(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3588(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3613(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3642(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3668(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3685(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3702(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3743(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3760(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3781(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3833(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3850(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3867(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3887(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3939(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3963(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3989(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4025(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4042(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4059(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4090(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4126(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4162(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4212(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4237(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4256(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4304(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4364(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4398(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4416(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4442(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4479(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4509(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4526(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4551(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4579(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4603(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4620(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4637(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4694(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4714(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:885(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:930(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:975(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1017(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1045(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1063(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1108(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1125(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1169(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1186(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1214(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1269(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1286(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1303(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1320(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1345(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1377(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1416(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1441(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1460(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1514(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1635(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1679(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1704(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1728(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1745(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1763(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1792(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1809(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1833(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1893(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1926(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1951(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1984(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2001(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2026(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2067(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2092(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2117(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2134(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2151(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2168(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2193(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2217(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2234(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2251(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2270(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2325(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2377(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2414(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2458(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2475(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2519(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2555(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2595(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:216(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:256(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:328(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:364(title)#: ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:282(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1827(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1977(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2279(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2395(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2503(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2728(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2839(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2856(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2934(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2964(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2993(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3071(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3124(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3227(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3323(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3414(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3476(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3505(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3547(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3623(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3728(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3806(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3852(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3879(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3960(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3985(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4079(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4122(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4245(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4331(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4394(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4567(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4672(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4840(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5058(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5081(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5173(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5298(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5315(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5340(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5390(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5551(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5598(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5810(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5847(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6291(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6467(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6509(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6579(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6610(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6800(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6835(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6918(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7020(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7068(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1687(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1716(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1794(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1847(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1898(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1959(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1988(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2046(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2120(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2208(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2237(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2296(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2352(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2399(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2458(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2512(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2553(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2615(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2660(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2688(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2745(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2804(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2880(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2910(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3001(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3079(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3126(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3172(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3264(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3305(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3359(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3395(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3521(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3551(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3639(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3694(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3742(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3797(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3852(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3903(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3964(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4001(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4031(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4118(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4179(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4263(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4292(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4350(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4408(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4497(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4685(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4774(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4829(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4884(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4946(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4991(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5034(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5097(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5132(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5251(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5298(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5328(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5416(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5470(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5513(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5591(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5621(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5708(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5761(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5793(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5895(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5925(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6013(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6070(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6127(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6180(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6225(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6336(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6366(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6453(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6548(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6609(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6639(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6737(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6799(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6829(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6917(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6974(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7044(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7197(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7227(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7315(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7380(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7520(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7580(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7610(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7704(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7764(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7819(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7866(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7912(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7969(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8023(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8052(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8141(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8228(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8281(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8323(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8368(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8397(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8455(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8517(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8631(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8660(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8747(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8803(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8872(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8957(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8985(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9042(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9085(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9122(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9150(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9193(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9335(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9403(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9440(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9486(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9542(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9590(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9708(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9767(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9854(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9907(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9949(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10002(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10032(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10128(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10229(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10261(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10358(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10416(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10471(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10517(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10756(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10786(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10873(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10934(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11066(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11170(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11200(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11288(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11343(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11402(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11536(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11624(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11679(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11741(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11810(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11840(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11927(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11981(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:700(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:830(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:917(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:954(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1006(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1036(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1068(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1160(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1255(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1340(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1443(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1566(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:296(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:362(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:465(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:539(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:621(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:660(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:562(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:606(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:673(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:847(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:867(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1001(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1083(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1156(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1219(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1298(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1395(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1414(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1466(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1530(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:365(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:398(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:443(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:463(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:510(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:543(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:599(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:631(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:683(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:702(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:738(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:769(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:841(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:869(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:889(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:952(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:972(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1028(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1072(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1113(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1168(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1196(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1218(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1297(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1318(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1362(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1390(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1430(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1472(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1552(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1591(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1611(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1677(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1778(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1797(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1828(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1848(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1887(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1907(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1946(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1987(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2170(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2190(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2234(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2277(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2381(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2417(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2453(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2489(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2520(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2548(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2567(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2586(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2622(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2653(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2689(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2708(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2739(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2767(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2811(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2851(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2911(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2931(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2985(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3056(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3095(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3131(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3165(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3260(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3294(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3355(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3374(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3413(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3485(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3505(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3566(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3725(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3772(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3819(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3847(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3866(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3894(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3941(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3973(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4009(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4029(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4073(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4129(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4185(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4218(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4265(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4301(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4337(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4388(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4543(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4575(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4617(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4733(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4764(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4841(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4869(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4925(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4985(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5021(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5052(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5082(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5142(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5172(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5228(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5268(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5368(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5396(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5424(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5452(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5480(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5521(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5566(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5585(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5624(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5664(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5717(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5736(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5766(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5813(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5832(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5860(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5893(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5969(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5989(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6037(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6077(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6164(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6202(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6311(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6340(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6403(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6459(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6491(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6528(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6548(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6584(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6621(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6658(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:441(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:633(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:778(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:824(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1004(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1046(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1112(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1176(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1205(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1281(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1369(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1408(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1456(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1493(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1521(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1590(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1611(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1710(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1773(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1868(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1905(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1942(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1980(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2075(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2113(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2254(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:530(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:687(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:854(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:873(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:937(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:970(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1175(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1385(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1568(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1611(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1631(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1670(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1708(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1746(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1788(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1872(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1908(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1962(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1980(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:637(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:654(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:686(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:719(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:736(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:769(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:804(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:861(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:893(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:918(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:959(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:992(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1025(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1050(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1077(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1127(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1144(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1168(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1200(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1228(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1293(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1317(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1335(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1384(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1416(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1441(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1458(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1491(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1531(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:895(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:963(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1016(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1137(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1274(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1418(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1498(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1665(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1771(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1882(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1911(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1949(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1991(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2072(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2128(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2267(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2296(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2368(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2523(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2594(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2704(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2750(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2793(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2857(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2903(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2923(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2979(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3125(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3262(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3374(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3543(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3624(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3792(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3898(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4008(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4070(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4109(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4145(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4187(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4267(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4322(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4461(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4490(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4562(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4733(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:904(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:949(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:992(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1028(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1090(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1142(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1233(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1357(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1397(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1479(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1533(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1654(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1774(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1857(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2281(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2352(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2396(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2441(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2502(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2538(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2574(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2614(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:236(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:311(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:339(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:375(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:392(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:418(title)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:633(para) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4102(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:61(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:606(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1438(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:347(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:310(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:134(para) ./doc/cli-reference/generated/ch_cli_keystone_commands.xml:338(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:275(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:380(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1635(para) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:52(para) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:144(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:324(para) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:58(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:148(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:289(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:394(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:622(para) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:603(para) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:202(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1684(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:492(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:291(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:473(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1692(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:500(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:299(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1700(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:560(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:359(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:481(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1708(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:576(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:375(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:489(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:451(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1716(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:568(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:367(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:337(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:459(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1724(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:584(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:383(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:505(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1732(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:592(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:391(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:345(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:151(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:534(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:531(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:333(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:784(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:170(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:524(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:521(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:323(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:774(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:214(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:544(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:541(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:343(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:794(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:222(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:552(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:549(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:351(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:802(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:438(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:237(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:448(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:348(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:247(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:456(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:255(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:466(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:356(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:265(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:474(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:273(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:484(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:364(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:283(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:508(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:505(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:307(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:441(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:516(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:513(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:315(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:449(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:600(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:399(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:353(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:475(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:608(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:407(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:361(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:616(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:415(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:369(para)#: ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:340(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:164(para)msgid ""The <placeholder-1/> client is the command-line interface (CLI) for the OpenStack Image Service API and its extensions. This chapter documents <placeholder-2/> version <literal>0.15.0</literal>.""#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:53(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:438(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1097(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:69(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1162(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:77(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:630(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1202(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:85(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:764(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1267(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:93(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:810(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:101(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:982(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:109(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1018(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:117(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1043(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:125(para) msgid ""Prints all of the commands and options to stdout so that the"" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:143(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:156(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:172(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:182(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:190(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:198(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:207(para) msgid ""Defaults to <code>env[OS_IMAGE_URL]</code>. If the provided image url contains a a version number and `--os-image-api- version` is omitted the version of the URL will be picked as the image api version to use.""#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:218(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:226(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:424(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:426(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:445(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:453(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:828(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:461(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:469(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:836(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:478(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:845(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:487(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:854(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:495(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:504(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:870(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:513(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:879(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:522(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:888(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:534(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:544(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:553(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:919(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:563(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:929(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:571(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:937(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:579(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:945(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1116(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1373(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:588(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:705(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:782(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:964(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:596(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:972(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1135(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1432(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:604(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:613(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:621(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:637(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:645(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:653(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:663(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:673(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:681(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:689(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1241(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:697(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1209(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:713(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:721(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:729(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:738(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:752(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:761(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:771(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:790(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1285(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1723(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1872(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1909(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2079(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:798(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:817(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:862(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:900(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:910(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:954(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:980(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:989(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:997(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1008(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1016(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1025(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2233(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1033(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2241(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1041(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1050(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1058(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1068(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1069(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1076(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1078(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1085(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1093(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1104(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1361(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1559(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1748(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2158(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1125(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1180(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1143(title) msgid ""glance image-delete (v2)"" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1145(para) msgid ""Delete specified image."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1152(para) msgid ""ID of image to delete."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1160(title) msgid ""glance image-download (v2)"" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1169(para) msgid ""ID of image to download."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1189(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1197(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1217(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1225(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1233(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1249(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1257(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1265(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1274(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1293(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1295(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1302(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1310(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1335(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1318(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1320(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1327(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1343(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1346(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1353(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1382(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1391(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1394(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1401(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1412(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1422(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1440(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1442(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1449(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1460(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1468(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1533(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1477(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1479(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1486(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1497(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1505(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1507(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1514(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1525(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1542(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1544(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1551(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1568(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1570(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1577(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1585(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1587(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1594(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1604(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1608(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1615(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1623(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1631(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1640(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1642(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1649(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1666(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1683(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1827(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2042(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2150(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2176(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1657(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1659(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1674(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1676(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1691(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1695(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1703(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1714(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1731(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1733(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1740(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1757(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1759(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1766(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1777(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1785(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1954(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1793(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1795(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1802(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1845(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1890(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1927(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1810(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1853(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1898(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1935(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1818(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1820(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1835(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1838(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1861(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2025(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2068(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2106(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1880(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1883(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1917(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1920(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1946(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1962(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1966(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1973(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1984(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1992(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2125(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2000(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2133(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2008(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2010(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2017(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2060(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2098(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2033(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2035(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2050(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2053(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2087(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2091(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2117(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2141(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2143(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2167(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2169(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2184(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2192(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2194(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2199(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2201(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2208(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2216(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2224(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2226(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2249(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2251(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2258(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2266(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2268(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2275(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2283(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2291(para)","""POT-Creation-Date: 2014-12-12 06:11+0000\n""#: ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:222(title) ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:248(title) ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:273(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1852(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1877(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1903(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1960(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1994(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2035(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2085(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2102(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2126(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2151(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2177(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2217(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2260(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2304(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2321(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2351(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2436(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2460(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2492(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2745(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2762(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2779(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2804(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2828(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2873(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2890(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2907(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2953(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2982(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3011(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3036(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3104(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3151(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3168(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3185(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3202(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3252(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3279(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3364(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3381(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3439(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3457(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3494(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3530(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3564(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3581(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3598(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3647(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3664(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3692(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3717(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3745(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3770(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3795(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3823(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3841(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3897(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3930(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3949(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4002(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4019(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4043(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4060(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4105(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4139(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4173(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4190(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4215(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4234(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4278(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4303(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4320(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4348(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4372(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4530(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4548(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4593(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4610(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4643(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4705(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4722(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4748(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4772(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4797(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4829(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5028(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5047(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5099(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5116(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5133(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5162(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5379(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5540(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5579(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5671(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5689(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5714(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5739(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5765(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5782(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5799(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5828(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5864(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5881(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5898(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5915(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5932(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5949(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5966(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6008(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6058(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6107(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6132(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6150(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6192(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6242(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6315(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6332(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6365(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6390(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6407(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6431(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6448(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6484(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6534(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6551(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6568(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6599(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6681(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6698(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6715(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6732(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6749(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6766(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6783(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6867(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6907(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6978(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6995(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7037(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7057(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7103(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7127(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7144(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7161(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7185(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7218(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7244(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1676(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1783(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1836(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1879(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1948(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2035(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2101(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2197(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2285(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2341(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2447(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2501(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2542(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2596(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2641(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2734(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2793(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2869(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2990(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3068(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3107(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3245(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3294(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3348(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3510(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3628(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3683(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3731(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3786(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3832(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3892(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3953(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3990(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4107(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4168(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4252(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4339(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4397(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4643(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4763(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4818(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4873(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4927(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4972(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5023(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5077(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5240(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5278(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5405(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5459(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5502(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5580(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5697(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5750(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5884(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6002(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6059(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6116(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6169(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6214(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6325(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6442(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6495(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6537(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6598(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6718(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6788(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6906(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6963(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7033(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7186(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7304(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7369(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7509(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7569(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7685(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7753(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7808(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7847(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7958(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8012(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8130(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8217(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8270(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8312(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8357(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8444(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8736(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8792(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8861(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8946(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9031(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9324(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9392(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9429(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9467(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9520(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9568(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9697(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9756(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9843(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9896(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9938(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9991(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10117(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10218(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10347(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10405(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10460(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10601(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10745(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10862(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10923(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11055(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11159(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11277(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11332(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11391(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11495(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11613(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11668(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11721(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11799(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11916(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11970(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:629(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:646(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:663(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:689(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:744(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:777(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:794(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:819(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:848(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:873(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:898(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:943(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:978(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:995(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1025(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1057(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1129(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1149(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1237(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1329(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1411(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1432(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1548(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:276(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:340(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:454(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:519(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:602(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:640(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:588(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:662(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:726(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:743(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:784(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:801(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:820(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:930(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:947(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:964(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:981(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1072(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1136(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1173(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1200(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1237(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1262(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1287(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1315(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1349(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1368(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1448(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1519(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1547(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:346(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:387(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:432(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:491(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:588(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:620(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:672(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:719(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:758(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:790(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:858(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:917(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1009(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1061(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1102(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1157(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1185(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1286(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1351(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1419(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1461(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1521(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1580(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1666(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1767(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1817(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1876(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1935(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1976(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2159(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2223(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2266(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2370(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2398(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2434(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2470(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2509(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2537(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2603(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2642(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2678(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2728(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2840(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2900(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2974(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3045(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3076(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3112(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3154(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3241(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3283(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3344(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3402(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3474(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3555(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3714(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3761(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3808(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3836(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3883(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3930(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3962(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3998(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4062(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4118(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4174(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4207(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4254(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4282(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4318(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4377(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4564(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4722(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4753(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4830(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4858(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4914(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4966(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5002(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5041(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5071(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5131(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5161(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5217(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5257(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5357(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5385(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5413(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5441(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5469(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5510(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5555(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5613(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5653(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5706(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5755(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5802(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5849(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5882(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5958(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6026(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6066(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6153(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6191(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6300(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6392(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6448(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6480(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6517(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6573(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6610(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6647(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:612(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:770(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:816(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:988(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1024(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1084(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1101(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1131(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1148(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1244(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1272(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1297(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1323(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1371(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1419(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1456(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1484(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1521(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1547(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1619(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1636(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1653(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1673(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1710(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1736(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1772(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1797(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1815(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1860(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1897(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1943(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1987(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2012(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2030(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2068(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2120(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2146(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2178(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2203(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2245(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:676(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:826(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:843(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:892(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:909(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:926(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1164(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1374(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1587(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1765(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:884(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:928(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:952(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:981(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1005(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1096(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1117(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1174(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1198(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1222(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1254(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1323(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1357(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1374(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1399(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1437(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1462(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1487(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1516(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1541(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1558(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1575(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1616(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1633(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1654(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1706(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1723(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1740(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1760(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1812(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1836(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1863(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1899(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1930(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1966(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2016(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2041(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2061(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2109(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2170(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2204(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2222(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2248(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2285(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2315(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2332(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2357(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2385(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2409(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2426(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2443(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2460(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2504(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2583(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2627(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2644(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2661(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2693(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2721(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2739(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2775(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2827(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2846(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2891(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2940(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2967(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3085(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3105(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3162(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3186(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3210(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3242(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3354(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3448(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3482(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3499(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3524(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3562(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3588(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3613(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3642(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3668(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3685(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3702(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3743(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3760(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3781(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3833(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3850(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3867(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3887(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3939(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3963(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3989(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4025(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4042(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4059(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4090(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4126(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4162(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4212(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4237(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4256(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4304(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4364(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4398(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4416(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4442(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4479(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4509(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4526(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4551(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4579(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4603(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4620(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4637(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4694(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4714(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:885(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:930(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:975(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1017(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1045(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1063(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1108(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1125(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1169(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1186(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1214(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1269(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1286(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1303(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1320(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1345(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1377(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1416(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1441(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1460(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1514(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1635(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1679(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1704(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1728(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1745(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1763(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1792(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1809(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1833(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1893(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1926(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1951(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1984(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2001(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2026(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2067(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2092(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2117(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2134(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2151(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2168(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2193(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2217(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2234(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2251(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2270(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2325(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2377(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2414(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2458(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2475(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2519(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2555(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2595(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:216(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:256(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:328(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:364(title)#: ./doc/cli-reference/ch_cli_neutron-debug_commands.xml:282(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1827(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1977(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2279(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2395(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2503(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2728(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2839(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2856(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2934(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2964(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:2993(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3071(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3124(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3227(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3323(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3414(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3476(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3505(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3547(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3623(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3728(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3806(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3852(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3879(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3960(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:3985(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4079(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4122(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4245(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4331(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4394(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4567(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4672(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4840(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5058(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5081(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5173(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5298(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5315(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5340(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5390(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5551(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5598(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5810(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:5847(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6291(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6467(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6509(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6579(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6610(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6800(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6835(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:6918(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7020(title) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:7068(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1687(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1716(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1794(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1847(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1898(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1959(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:1988(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2046(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2120(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2208(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2237(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2296(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2352(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2399(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2458(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2512(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2553(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2615(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2660(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2688(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2745(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2804(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2880(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:2910(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3001(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3079(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3126(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3172(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3264(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3305(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3359(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3395(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3521(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3551(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3639(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3694(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3742(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3797(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3852(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3903(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:3964(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4001(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4031(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4118(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4179(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4263(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4292(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4350(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4408(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4497(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4654(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4685(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4774(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4829(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4884(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4946(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:4991(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5034(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5097(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5132(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5251(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5298(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5328(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5416(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5470(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5513(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5591(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5621(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5708(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5761(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5793(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5895(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:5925(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6013(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6070(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6127(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6180(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6225(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6336(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6366(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6453(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6548(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6609(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6639(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6737(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6799(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6829(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6917(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:6974(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7044(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7197(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7227(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7315(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7380(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7520(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7580(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7610(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7704(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7764(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7819(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7866(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7912(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:7969(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8023(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8052(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8141(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8228(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8281(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8323(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8368(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8397(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8455(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8517(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8631(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8660(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8747(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8803(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8872(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8957(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:8985(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9042(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9085(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9122(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9150(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9193(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9335(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9403(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9440(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9486(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9542(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9590(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9708(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9767(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9854(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9907(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:9949(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10002(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10032(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10128(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10229(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10261(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10358(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10416(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10471(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10517(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10620(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10756(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10786(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10873(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:10934(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11066(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11170(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11200(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11288(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11343(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11402(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11506(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11536(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11624(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11679(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11741(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11810(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11840(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11927(title) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:11981(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:700(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:830(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:917(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:954(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1006(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1036(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1068(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1160(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1255(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1340(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1443(title) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:1566(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:296(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:362(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:465(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:539(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:621(title) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:660(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:562(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:606(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:673(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:847(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:867(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1001(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1083(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1156(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1219(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1298(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1395(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1414(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1466(title) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:1530(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:365(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:398(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:443(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:463(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:510(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:543(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:599(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:631(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:683(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:702(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:738(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:769(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:841(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:869(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:889(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:952(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:972(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1028(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1072(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1113(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1168(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1196(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1218(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1297(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1318(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1362(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1390(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1430(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1472(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1532(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1552(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1591(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1611(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1677(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1778(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1797(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1828(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1848(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1887(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1907(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1946(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:1987(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2170(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2190(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2234(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2277(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2381(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2417(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2453(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2489(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2520(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2548(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2567(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2586(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2622(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2653(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2689(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2708(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2739(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2767(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2811(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2851(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2911(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2931(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:2985(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3056(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3095(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3131(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3165(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3260(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3294(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3355(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3374(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3413(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3485(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3505(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3566(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3725(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3772(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3819(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3847(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3866(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3894(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3941(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:3973(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4009(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4029(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4073(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4129(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4185(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4218(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4265(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4301(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4337(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4388(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4543(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4575(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4617(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4733(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4764(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4841(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4869(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4925(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:4985(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5021(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5052(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5082(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5142(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5172(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5228(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5268(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5368(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5396(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5424(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5452(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5480(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5521(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5566(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5585(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5624(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5664(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5717(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5736(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5766(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5813(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5832(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5860(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5893(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5969(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:5989(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6037(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6077(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6164(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6202(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6311(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6340(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6403(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6459(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6491(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6528(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6548(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6584(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6621(title) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:6658(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:444(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:636(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:781(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:827(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1007(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1049(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1113(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1159(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1187(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1255(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1343(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1382(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1430(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1467(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1495(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1564(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1585(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1684(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1747(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1842(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1879(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1916(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1954(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2049(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2087(title) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2228(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:530(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:687(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:854(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:873(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:937(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:970(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1175(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1385(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1568(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1611(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1631(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1670(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1708(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1746(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1788(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1872(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1908(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1962(title) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:1980(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:637(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:654(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:686(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:719(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:736(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:769(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:804(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:861(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:893(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:918(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:959(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:992(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1025(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1050(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1077(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1127(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1144(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1168(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1200(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1228(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1293(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1317(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1335(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1384(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1416(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1441(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1458(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1491(title) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:1531(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:895(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:963(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1016(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1137(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1274(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1418(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1498(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1665(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1771(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1882(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1911(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1949(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:1991(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2072(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2128(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2267(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2296(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2368(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2523(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2594(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2704(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2750(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2793(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2857(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2903(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2923(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:2979(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3125(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3262(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3374(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3543(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3624(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3792(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:3898(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4008(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4070(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4109(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4145(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4187(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4267(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4322(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4461(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4490(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4562(title) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:4733(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:904(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:949(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:992(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1028(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1090(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1142(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1233(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1357(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1397(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1479(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1533(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1654(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1774(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:1857(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2281(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2352(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2396(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2441(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2502(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2538(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2574(title) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:2614(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:236(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:311(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:339(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:375(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:392(title) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:418(title)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:633(para) ./doc/cli-reference/generated/ch_cli_nova_commands.xml:4102(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:61(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:609(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1438(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:347(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:310(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:125(para) ./doc/cli-reference/generated/ch_cli_keystone_commands.xml:338(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:275(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:380(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1635(para) ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:52(para) ./doc/cli-reference/generated/ch_cli_swift_commands.xml:144(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:324(para) ./doc/cli-reference/generated/ch_cli_openstack_commands.xml:58(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:139(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:289(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:394(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:622(para) ./doc/cli-reference/generated/ch_cli_trove_commands.xml:603(para) ./doc/cli-reference/generated/ch_cli_trove-manage_commands.xml:202(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1684(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:492(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:294(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:473(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1692(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:500(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:302(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1700(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:560(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:362(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:481(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1708(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:576(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:378(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:489(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:451(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1716(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:568(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:370(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:337(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:459(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1724(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:584(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:386(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:505(para)#: ./doc/cli-reference/generated/ch_cli_nova_commands.xml:1732(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:592(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:394(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:345(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:151(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:534(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:531(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:336(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:784(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:170(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:524(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:521(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:326(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:774(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:214(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:544(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:541(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:346(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:794(para)#: ./doc/cli-reference/generated/ch_cli_neutron_commands.xml:222(para) ./doc/cli-reference/generated/ch_cli_heat_commands.xml:552(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:549(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:354(para) ./doc/cli-reference/generated/ch_cli_cinder_commands.xml:802(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:438(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:240(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:448(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:348(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:250(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:456(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:258(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:466(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:356(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:268(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:474(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:276(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:484(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:364(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:286(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:508(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:505(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:310(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:441(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:516(para) ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:513(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:318(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:449(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:600(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:402(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:353(para) ./doc/cli-reference/generated/ch_cli_sahara_commands.xml:475(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:608(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:410(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:361(para)#: ./doc/cli-reference/generated/ch_cli_heat_commands.xml:616(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:418(para) ./doc/cli-reference/generated/ch_cli_ceilometer_commands.xml:369(para)#: ./doc/cli-reference/generated/ch_cli_ironic_commands.xml:340(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:155(para)msgid ""The <placeholder-1/> client is the command-line interface (CLI) for the OpenStack Image Service API and its extensions. This chapter documents <placeholder-2/> version <literal>0.14.2</literal>.""#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:53(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:441(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1098(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:69(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1145(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:77(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:633(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1184(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:85(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:767(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1241(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:93(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:813(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:101(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:985(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:109(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1021(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:117(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1046(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:134(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:147(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:163(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:173(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:181(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:189(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:198(para) msgid ""Defaults to <code>env[OS_IMAGE_URL]</code>.""#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:206(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:214(para) msgid ""key to use for encrypting context data for performance profiling of operation. This key should be the value of HMAC key configured in osprofiler middleware in glance, it is specified in paste configuration file at /etc/glance/api-paste.ini and /etc/glance/registry-paste.ini. Without key the profiling will not be triggered even if osprofiler is enabled on server side."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:229(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:427(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:429(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:448(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:456(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:831(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:464(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:472(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:839(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:481(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:848(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:490(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:857(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:498(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:507(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:873(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:516(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:882(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:525(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:891(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:537(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:547(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:556(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:922(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:566(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:932(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:574(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:940(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:582(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:948(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1117(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1347(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:591(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:708(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:785(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:967(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:599(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:975(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1406(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:607(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:616(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:624(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:640(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:648(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:656(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:666(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:676(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:684(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:692(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:700(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1191(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:716(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:724(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:732(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:741(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:755(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:764(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:774(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:793(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1259(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1697(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1846(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1883(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2053(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:801(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:820(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:865(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:903(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:913(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:957(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:983(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:992(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1000(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1011(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1019(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1028(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2207(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1036(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2215(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1044(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1053(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1061(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1071(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1072(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1079(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1081(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1088(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1096(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1105(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1335(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1533(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1722(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2132(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1126(title) msgid ""glance image-delete (v2)"" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1128(para) msgid ""Delete specified image."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1135(para) msgid ""ID of image to delete."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1143(title) msgid ""glance image-download (v2)"" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1152(para) msgid ""ID of image to download."" msgstr """" #: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1163(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1172(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1180(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1199(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1207(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1215(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1223(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1231(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1239(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1248(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1267(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1269(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1276(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1284(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1309(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1292(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1294(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1301(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1317(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1320(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1327(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1356(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1365(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1368(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1375(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1386(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1396(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1414(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1416(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1423(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1434(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1442(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1507(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1451(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1453(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1460(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1471(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1479(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1481(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1488(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1499(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1516(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1518(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1525(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1542(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1544(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1551(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1559(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1561(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1568(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1578(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1582(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1589(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1597(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1605(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1614(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1616(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1623(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1640(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1657(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1801(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2016(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2124(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2150(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1631(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1633(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1648(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1650(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1665(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1669(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1677(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1688(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1705(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1707(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1714(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1731(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1733(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1740(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1751(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1759(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1928(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1767(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1769(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1776(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1819(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1864(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1901(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1784(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1827(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1872(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1909(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1792(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1794(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1809(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1812(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1835(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1999(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2042(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2080(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1854(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1857(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1891(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1894(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1920(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1936(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1940(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1947(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1958(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1966(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2099(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1974(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2107(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1982(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1984(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:1991(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2034(para) ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2072(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2007(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2009(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2024(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2027(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2061(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2065(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2091(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2115(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2117(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2141(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2143(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2158(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2166(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2168(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2173(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2175(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2182(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2190(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2198(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2200(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2223(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2225(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2232(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2240(title)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2242(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2249(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2257(para)#: ./doc/cli-reference/generated/ch_cli_glance_commands.xml:2265(para)",286,282
openstack%2Fneutron~master~I07afc0351a19e1c855a4659ffc0088674f4fdb6c,openstack/neutron,master,I07afc0351a19e1c855a4659ffc0088674f4fdb6c,Imported Translations from Transifex,MERGED,2014-12-08 06:07:27.000000000,2014-12-13 07:51:15.000000000,2014-12-10 10:01:51.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-08 06:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d006a8e5359848c8f9d96f04a89b766c41e8be92', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I07afc0351a19e1c855a4659ffc0088674f4fdb6c\n'}, {'number': 2, 'created': '2014-12-09 06:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/18bee4ee30bc80fe4043e0bccea462db58213226', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I07afc0351a19e1c855a4659ffc0088674f4fdb6c\n'}, {'number': 3, 'created': '2014-12-10 06:08:05.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bee8592b1bf661f0b247d804738c7202b37604c', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I07afc0351a19e1c855a4659ffc0088674f4fdb6c\n'}]",0,139914,6bee8592b1bf661f0b247d804738c7202b37604c,60,20,3,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I07afc0351a19e1c855a4659ffc0088674f4fdb6c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/14/139914/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",13,d006a8e5359848c8f9d96f04a89b766c41e8be92,transifex/translations,"""POT-Creation-Date: 2014-12-08 06:06+0000\n"" ""PO-Revision-Date: 2014-12-07 20:22+0000\n""#: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:267#: neutron/plugins/ibm/sdnve_api.py:76 #, python-format msgid ""The IP addr of available SDN-VE controllers: %s"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:79 #, python-format msgid ""The SDN-VE controller IP address: %s"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:235 msgid ""Bad resource for forming a list request"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:245 msgid ""Bad resource for forming a show request"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:255 msgid ""Bad resource for forming a create request"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:267 msgid ""Bad resource for forming a update request"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:278 msgid ""Bad resource for forming a delete request"" msgstr """" #: neutron/plugins/ibm/sdnve_api.py:306 #, python-format msgid ""Non matching tenant and network types: %(ttype)s %(ntype)s"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:31 msgid ""Fake SDNVE controller initialized"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:34 msgid ""Fake SDNVE controller: list"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:38 msgid ""Fake SDNVE controller: show"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:42 msgid ""Fake SDNVE controller: create"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:46 msgid ""Fake SDNVE controller: update"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:50 msgid ""Fake SDNVE controller: delete"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:54 msgid ""Fake SDNVE controller: get tenant by id"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:58 msgid ""Fake SDNVE controller: check and create tenant"" msgstr """" #: neutron/plugins/ibm/sdnve_api_fake.py:62 msgid ""Fake SDNVE controller: get controller"" msgstr """" #: neutron/plugins/ibm/sdnve_neutron_plugin.py:147 msgid ""Set a new controller if needed."" msgstr """" #: neutron/plugins/ibm/sdnve_neutron_plugin.py:153 #, python-format msgid ""Set the controller to a new controller: %s"" msgstr """" #: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:194 #, python-format msgid """" ""Mapping physical network %(physical_network)s to interface %(interface)s"" msgstr """" #: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:225 #, python-format msgid """" ""Loop iteration exceeded interval (%(polling_interval)s vs. %(elapsed)s)!"" msgstr """" ""L'iterazione loop supera l'intervallo (%(polling_interval)s vs. %(elapsed)s)!"" #: neutron/plugins/ibm/agent/sdnve_neutron_agent.py:239 #, python-format msgid ""Controller IPs: %s"" msgstr """" ","""POT-Creation-Date: 2014-12-07 06:07+0000\n"" ""PO-Revision-Date: 2014-12-05 22:51+0000\n""",1097,413
openstack%2Fnova~master~I520be6ff01ed82c7b1bf82e782cfdef65c920389,openstack/nova,master,I520be6ff01ed82c7b1bf82e782cfdef65c920389,Add monitoring on resume_instance,ABANDONED,2014-08-13 03:05:09.000000000,2014-12-13 07:39:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2750}, {'_account_id': 4690}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 6062}, {'_account_id': 8412}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 9847}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11531}]","[{'number': 1, 'created': '2014-08-13 03:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e1933a925224742c614385b2aab85c43d3c7b90', 'message': 'Add monitoring on resume_instance\n\nThe existing monitoring is only at the end of the resume_instance, I think\nwe should add monitoring on both begin and end, it isvery convenient to\ncheck problem.\n\nChange-Id: I520be6ff01ed82c7b1bf82e782cfdef65c920389\nFixes: bug #1356167\n'}, {'number': 2, 'created': '2014-08-28 08:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/813802ec24e3dcf64f74b25121cbbfa6efe7e954', 'message': 'Add monitoring on resume_instance\n\nThe existing monitoring is only at the end of the resume_instance, I think\nwe should add monitoring on both begin and end, it isvery convenient to\ncheck problem.\n\nChange-Id: I520be6ff01ed82c7b1bf82e782cfdef65c920389\nCloses-Bug: #1356167\n'}, {'number': 3, 'created': '2014-08-28 12:25:53.000000000', 'files': ['nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fb1318fc8a8ebac4b17d34cd66de1e70b6624843', 'message': 'Add monitoring on resume_instance\n\nThe existing monitoring is only at the end of the resume_instance, I think\nwe should add monitoring on both begin and end, it is very convenient to\ncheck problem.\n\nChange-Id: I520be6ff01ed82c7b1bf82e782cfdef65c920389\nCloses-Bug: #1356167\n'}]",2,113759,fb1318fc8a8ebac4b17d34cd66de1e70b6624843,40,16,3,11531,,,0,"Add monitoring on resume_instance

The existing monitoring is only at the end of the resume_instance, I think
we should add monitoring on both begin and end, it is very convenient to
check problem.

Change-Id: I520be6ff01ed82c7b1bf82e782cfdef65c920389
Closes-Bug: #1356167
",git fetch https://review.opendev.org/openstack/nova refs/changes/59/113759/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,2e1933a925224742c614385b2aab85c43d3c7b90,bug/1356167," self._notify_about_instance_usage(context, instance, 'resume.start') self._notify_about_instance_usage(context, instance, 'resume.end')"," self._notify_about_instance_usage(context, instance, 'resume')",2,1
openstack%2Ftaskflow~master~Ia67c924bc5896fbdc59bea25bf08fd87954905d0,openstack/taskflow,master,Ia67c924bc5896fbdc59bea25bf08fd87954905d0,Retain the existence of a 'EngineBase' until 0.7 or later,MERGED,2014-12-13 06:11:36.000000000,2014-12-13 07:32:41.000000000,2014-12-13 07:32:40.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-13 06:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f148ad282c304bb2158c9f4ddd98816ac9ae465e', 'message': ""Retain the existence of an engine base until 0.7 or later\n\nFor the recently renamed 'EngineBase' -> 'Engine' cleanup it\nwould be nice to also retain the 'EngineBase' old named class\nfor a deprecation cycle. To enable this use the newly made\ndeprecation function that allows for creating inheritable classes\nthat emit deprecation warnings.\n\nChange-Id: Ia67c924bc5896fbdc59bea25bf08fd87954905d0\n""}, {'number': 2, 'created': '2014-12-13 06:12:39.000000000', 'files': ['taskflow/engines/base.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/624d966e641a2a9f3fb22cb14bca94cb4dc7fcfa', 'message': ""Retain the existence of a 'EngineBase' until 0.7 or later\n\nFor the recently renamed 'EngineBase' -> 'Engine' cleanup it\nwould be nice to retain the 'EngineBase' old named class for a\ndeprecation cycle. To enable this use the newly made deprecation\nfunction that allows for creating inheritable classes that emit\ndeprecation warnings when constructed.\n\nChange-Id: Ia67c924bc5896fbdc59bea25bf08fd87954905d0\n""}]",0,141541,624d966e641a2a9f3fb22cb14bca94cb4dc7fcfa,7,2,2,1297,,,0,"Retain the existence of a 'EngineBase' until 0.7 or later

For the recently renamed 'EngineBase' -> 'Engine' cleanup it
would be nice to retain the 'EngineBase' old named class for a
deprecation cycle. To enable this use the newly made deprecation
function that allows for creating inheritable classes that emit
deprecation warnings when constructed.

Change-Id: Ia67c924bc5896fbdc59bea25bf08fd87954905d0
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/41/141541/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/base.py'],1,f148ad282c304bb2158c9f4ddd98816ac9ae465e,," # TODO(harlowja): remove in 0.7 or later... EngineBase = deprecation.moved_inheritable_class(Engine, 'EngineBase', __name__, version=""0.6"", removal_version=""?"")",,7,0
openstack%2Fcinder~master~Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef,openstack/cinder,master,Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef,VMware: Fix datastore selection with single host,MERGED,2014-12-10 12:04:25.000000000,2014-12-13 07:25:24.000000000,2014-12-11 05:19:58.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 10621}, {'_account_id': 11811}, {'_account_id': 12016}]","[{'number': 1, 'created': '2014-12-10 12:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/04bce185bc4ab4e33cf7bd7042b67eacb217d5a0', 'message': 'VMware: Fix datastore selection with single host\n\nUsing the new datastore selection logic with a single host fails with\nerror ""val instance has no attribute \'obj\'"". Currently this code path\nis never executed, but will be used by future bug fixes. This patch\nfixes the attribute error.\n\nCloses-Bug: #1401052\nChange-Id: Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef\n'}, {'number': 2, 'created': '2014-12-10 12:05:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/98039becfe166d4448fa966c160b4b22214f5ab5', 'message': 'VMware: Fix datastore selection with single host\n\nUsing the datastore selection logic with a single host fails with\nerror ""val instance has no attribute \'obj\'"". Currently this code path\nis never executed, but will be used by future bug fixes. This patch\nfixes the attribute error.\n\nCloses-Bug: #1401052\nChange-Id: Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef\n'}, {'number': 3, 'created': '2014-12-10 12:40:29.000000000', 'files': ['cinder/tests/test_vmware_datastore.py', 'cinder/volume/drivers/vmware/datastore.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/01b029e4d3afb181b43cce4b7f7c0185adb9eeac', 'message': ""VMware: Fix datastore selection with single host\n\nCurrently, the select_datastore method is called with an empty list of\nESX hosts. This causes the method to retrieve all the hosts in vCenter\nas candidates for selecting a datastore. The reference to a retrieved\nhost is stored in attribute 'obj'. Some of the future bug fixes will\nneed to invoke this method with reference to a single ESX host. Such\ninvocations will fail with attribute error: 'val instance has no\nattribute 'obj''. This patch fixes the attribute error.\n\nCloses-Bug: #1401052\nChange-Id: Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef\n""}]",0,140655,01b029e4d3afb181b43cce4b7f7c0185adb9eeac,15,8,3,9171,,,0,"VMware: Fix datastore selection with single host

Currently, the select_datastore method is called with an empty list of
ESX hosts. This causes the method to retrieve all the hosts in vCenter
as candidates for selecting a datastore. The reference to a retrieved
host is stored in attribute 'obj'. Some of the future bug fixes will
need to invoke this method with reference to a single ESX host. Such
invocations will fail with attribute error: 'val instance has no
attribute 'obj''. This patch fixes the attribute error.

Closes-Bug: #1401052
Change-Id: Ib4f48d2ebfbfa3a9ce6a402300d41351548932ef
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/140655/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/test_vmware_datastore.py', 'cinder/volume/drivers/vmware/datastore.py']",2,04bce185bc4ab4e33cf7bd7042b67eacb217d5a0,bug/1401052, for host in hosts: all_hosts.append(host.obj) for host_ref in hosts:, all_hosts.extend(hosts) for host in hosts: host_ref = host.obj,43,12
openstack%2Ftaskflow~master~I1f5cbcd29f1453d68e774f9f9f733eb873efc7cb,openstack/taskflow,master,I1f5cbcd29f1453d68e774f9f9f733eb873efc7cb,Remove the base postfix from the internal task executor,MERGED,2014-12-13 06:02:30.000000000,2014-12-13 07:00:09.000000000,2014-12-13 07:00:09.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-13 06:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3e4f1e0f0efedf5175a43a67c2f0d462c75a142d', 'message': ""Remove the base postfix from the internal task executor\n\nThere is no need to have a postfix of 'base' in the task\nexecutor as it is obvious by having a metaclass of abc.ABCMeta\nand the fact that it has no methods that the task executor base\nis a base class and should be used as such without a 'base'\npostfix to also signify the same information.\n\nChange-Id: I1f5cbcd29f1453d68e774f9f9f733eb873efc7cb\n""}, {'number': 2, 'created': '2014-12-13 06:05:30.000000000', 'files': ['taskflow/engines/worker_based/executor.py', 'taskflow/engines/action_engine/executor.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f5060ff41ea3fd2f9282c00a5a63f110918568b0', 'message': ""Remove the base postfix from the internal task executor\n\nThere is no need to have a postfix of 'base' in the task\nexecutor as it is obvious by having a metaclass of abc.ABCMeta\nand the fact that it has no methods that the task executor base\nis a base class and should be used as such without a 'base'\npostfix to also signify the same information.\n\nChange-Id: I1f5cbcd29f1453d68e774f9f9f733eb873efc7cb\n""}]",0,141537,f5060ff41ea3fd2f9282c00a5a63f110918568b0,7,2,2,1297,,,0,"Remove the base postfix from the internal task executor

There is no need to have a postfix of 'base' in the task
executor as it is obvious by having a metaclass of abc.ABCMeta
and the fact that it has no methods that the task executor base
is a base class and should be used as such without a 'base'
postfix to also signify the same information.

Change-Id: I1f5cbcd29f1453d68e774f9f9f733eb873efc7cb
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/37/141537/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/engines/worker_based/executor.py', 'taskflow/engines/action_engine/executor.py']",2,3e4f1e0f0efedf5175a43a67c2f0d462c75a142d,,class TaskExecutor(object):class SerialTaskExecutor(TaskExecutor):class ParallelTaskExecutor(TaskExecutor):,class TaskExecutorBase(object):class SerialTaskExecutor(TaskExecutorBase):class ParallelTaskExecutor(TaskExecutorBase):,4,4
openstack%2Fneutron~master~Ie8e4854c23aa3739b0df618db1b3944466d64bd2,openstack/neutron,master,Ie8e4854c23aa3739b0df618db1b3944466d64bd2,Separate wait_until to standalone function,MERGED,2014-09-30 16:15:39.000000000,2014-12-13 06:48:35.000000000,2014-12-13 04:32:32.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 1653}, {'_account_id': 2035}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 8645}, {'_account_id': 8655}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9656}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 12040}, {'_account_id': 12444}, {'_account_id': 12737}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-09-30 16:15:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69aa81f72a62d8305ab9a04779d237419787ac83', 'message': 'Separate wait_until to new Waiter class\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 2, 'created': '2014-09-30 16:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d152c02450f2148b3bb32e15c734e6f3f5d6797e', 'message': 'Separate wait_until to new Waiter class\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 3, 'created': '2014-09-30 17:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1e92f1bb1d4d0da94b98fcf6b14a2d7f3c4c97d1', 'message': 'Separate wait_until to new Waiter class\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 4, 'created': '2014-10-03 16:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/981834ff13b5763cdc57f111fdf4d867d736834b', 'message': 'Separate wait_until to new Waiter class\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 5, 'created': '2014-10-06 08:19:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ce1c2b6a4531cf4a880b41784055060690dd49b4', 'message': 'Separate wait_until to new Waiter class\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 6, 'created': '2014-11-10 16:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a164e26b6422c1ec359ff30a03c47ddd701910cf', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 7, 'created': '2014-11-10 16:32:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/80d4150dd07a668c12555fd50ef89f996a52a981', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 8, 'created': '2014-11-10 16:34:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/28f9b7d0beb62838eaa115c38c34ffc6ff9323ac', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 9, 'created': '2014-11-12 15:40:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0040197157daa0dbd4d3614358ce8e19576feee4', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 10, 'created': '2014-11-21 13:55:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dabbe1f020796321fc94650c0af9e08252797afc', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 11, 'created': '2014-11-21 14:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd52a44da5a195271aac5849554abe014a70638d', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 12, 'created': '2014-11-27 12:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56bb009904dadb8ff528603c37b0a015af6b7748', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 13, 'created': '2014-11-28 12:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2898f484054e23b40308fef7090ecc7f85e25bfb', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}, {'number': 14, 'created': '2014-12-12 12:16:23.000000000', 'files': ['neutron/tests/functional/agent/linux/base.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/functional/base.py', 'neutron/tests/functional/agent/linux/helpers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f1277a4036ac355c13a5b928e189ab2abf765402', 'message': 'Separate wait_until to standalone function\n\nIt makes wait_until more usable outside of unittest.TestCase classes.\nPart of this patch is renaming pinger module to helpers thus we can have\nhelpers module with useful utilities for testing.\n\nChange-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2\nRelated-Bug: 1243216\n'}]",44,125109,f1277a4036ac355c13a5b928e189ab2abf765402,260,41,14,8655,,,0,"Separate wait_until to standalone function

It makes wait_until more usable outside of unittest.TestCase classes.
Part of this patch is renaming pinger module to helpers thus we can have
helpers module with useful utilities for testing.

Change-Id: Ie8e4854c23aa3739b0df618db1b3944466d64bd2
Related-Bug: 1243216
",git fetch https://review.opendev.org/openstack/neutron refs/changes/09/125109/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/functional/agent/test_l3_agent.py', 'neutron/tests/functional/agent/linux/helpers.py']",2,69aa81f72a62d8305ab9a04779d237419787ac83,bug/1243216,"import eventlet class Waiter(object): def __init__(self, timeout=60, sleep=1): self.timeout = timeout self.sleep = sleep def wait_until(self, predicate, *args, **kwargs): with eventlet.timeout.Timeout(self.timeout): while not predicate(*args, **kwargs): eventlet.sleep(self.sleep_interval)",,17,2
openstack%2Ftaskflow~master~Iaeaeaf698c23d71720ef7b62c8781996829e192a,openstack/taskflow,master,Iaeaeaf698c23d71720ef7b62c8781996829e192a,Remove usage of listener base postfix,MERGED,2014-12-12 20:51:13.000000000,2014-12-13 05:09:56.000000000,2014-12-13 05:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-12 20:51:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d484fe213e1e73bf497fe1f774411409987412b1', 'message': ""Remove usage of listener base postfix\n\nThe base prefix added on to the listener classes is\nnot very useful and is already understood that these are\nbase classes by documentation or abc.ABCMeta usage so\nwe don't need to specifically name these classes bases\nto also show that they are a base class (useless duplicate\ninformation).\n\nSo in this change we deprecate the ListenerBase and the\nLoggingBase and rename these classes to more appropriate\nnames.\n\nChange-Id: Iaeaeaf698c23d71720ef7b62c8781996829e192a\n""}, {'number': 2, 'created': '2014-12-12 20:52:58.000000000', 'files': ['taskflow/listeners/timing.py', 'taskflow/listeners/claims.py', 'taskflow/listeners/logging.py', 'taskflow/listeners/base.py', 'taskflow/listeners/printing.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b4e4e214cb69a3f2b9d90c287dcc2dd521a7f425', 'message': ""Remove usage of listener base postfix\n\nThe base prefix added on to the listener classes is\nnot very useful and is already understood that these are\nbase classes by documentation or abc.ABCMeta usage so\nwe don't need to specifically name these classes bases\nto also show that they are a base class (useless duplicate\ninformation).\n\nSo in this change we deprecate the 'ListenerBase' and the\n'LoggingBase' and rename these classes to more appropriate\nnames.\n\nChange-Id: Iaeaeaf698c23d71720ef7b62c8781996829e192a\n""}]",0,141490,b4e4e214cb69a3f2b9d90c287dcc2dd521a7f425,7,2,2,1297,,,0,"Remove usage of listener base postfix

The base prefix added on to the listener classes is
not very useful and is already understood that these are
base classes by documentation or abc.ABCMeta usage so
we don't need to specifically name these classes bases
to also show that they are a base class (useless duplicate
information).

So in this change we deprecate the 'ListenerBase' and the
'LoggingBase' and rename these classes to more appropriate
names.

Change-Id: Iaeaeaf698c23d71720ef7b62c8781996829e192a
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/90/141490/2 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/listeners/timing.py', 'taskflow/listeners/claims.py', 'taskflow/listeners/logging.py', 'taskflow/listeners/base.py', 'taskflow/listeners/printing.py']",5,d484fe213e1e73bf497fe1f774411409987412b1,tweaked-listeners,"class PrintingListener(base.DumpingListener): def _dump(self, message, *args, **kwargs):","class PrintingListener(base.LoggingBase): def _log(self, message, *args, **kwargs):",48,26
openstack%2Ftaskflow~master~I8cd5b707125264f6b595d5b3ac327cfe16e7923c,openstack/taskflow,master,I8cd5b707125264f6b595d5b3ac327cfe16e7923c,Add a moved_inheritable_class deprecation helper,MERGED,2014-12-08 19:54:45.000000000,2014-12-13 05:09:37.000000000,2014-12-13 05:09:37.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-08 19:54:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3ed41e818ddbf577c513d542b5762f46168d4c48', 'message': 'Add a moved_inheritable_class deprecation helper\n\nFor cases where inheritance is still needed we should provide\na mechanism to provide this so that consuming users of the\nlibrary can still refer to the old location for a period of time\nso that there derived code does not fail due to the movement\nof the class that occurred.\n\nChange-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c\n'}, {'number': 2, 'created': '2014-12-08 23:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/14058caac8b5367ff1802011d9d667f9651f91fc', 'message': 'Add a moved_inheritable_class deprecation helper\n\nFor cases where inheritance is still needed we should provide\na mechanism to provide this so that consuming users of the\nlibrary can still refer to the old location for a period of time\nso that there derived code does not fail due to the movement\nof the class that occurred.\n\nChange-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c\n'}, {'number': 3, 'created': '2014-12-11 04:09:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/010f223b71d90d6d5ae1ffebadb83b0d7cb21413', 'message': 'Add a moved_inheritable_class deprecation helper\n\nFor cases where inheritance is still needed we should provide\na mechanism to provide this so that consuming users of the\nlibrary can still refer to the old location for a period of time\nso that there derived code does not fail due to the movement\nof the class that occurred.\n\nChange-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c\n'}, {'number': 4, 'created': '2014-12-11 21:02:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/5ee812d963a41c6f5e56bde1c7dd87a720ad817a', 'message': 'Add a moved_inheritable_class deprecation helper\n\nFor cases where inheritance is still needed we should provide\na mechanism to provide this so that consuming users of the\nlibrary can still refer to the old location for a period of time\nso that there derived code does not fail due to the movement\nof the class that occurred.\n\nChange-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c\n'}, {'number': 5, 'created': '2014-12-12 20:51:13.000000000', 'files': ['taskflow/utils/deprecation.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a440ec40a518f8ee25ba5a945847e5b4eefdb45c', 'message': 'Add a moved_inheritable_class deprecation helper\n\nFor cases where inheritance is still needed we should provide\na mechanism to provide this so that consuming users of the\nlibrary can still refer to the old location for a period of time\nso that there derived code does not fail due to the movement\nof the class that occurred.\n\nChange-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c\n'}]",0,140132,a440ec40a518f8ee25ba5a945847e5b4eefdb45c,19,2,5,1297,,,0,"Add a moved_inheritable_class deprecation helper

For cases where inheritance is still needed we should provide
a mechanism to provide this so that consuming users of the
library can still refer to the old location for a period of time
so that there derived code does not fail due to the movement
of the class that occurred.

Change-Id: I8cd5b707125264f6b595d5b3ac327cfe16e7923c
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/32/140132/5 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/utils/deprecation.py'],1,3ed41e818ddbf577c513d542b5762f46168d4c48,deprecation-patterns,"def moved_inheritable_class(new_class, old_class_name, old_module_name, message=None, version=None, removal_version=None): """"""Deprecates a class that was moved to another location. NOTE(harlowja): this creates a new-old type that can be used for a deprecation period that can be inherited from, the difference between this and the ``moved_class`` deprecation function is that the proxy from that function can not be inherited from (thus limiting its use for a more particular usecase where inheritance is not needed). This will emit warnings when the old locations class is initialized, telling where the new and improved location for the old class now is. """""" old_name = ""."".join((old_module_name, old_class_name)) new_name = reflection.get_class_name(new_class) prefix = _CLASS_MOVED_PREFIX_TPL % (old_name, new_name) out_message = _generate_moved_message(prefix, message=message, version=version, removal_version=removal_version) def decorator(f): @six.wraps(f) def wrapper(self, *args, **kwargs): deprecation(out_message, stacklevel=3) return f(self, *args, **kwargs) return wrapper old_class = type(old_class_name, (new_class,), {}) old_class.__module__ = old_module_name old_class.__init__ = decorator(old_class.__init__) return old_class ",,35,0
openstack%2Fneutron~master~I6174453eb1c41c398ecffbab59c45b0678637672,openstack/neutron,master,I6174453eb1c41c398ecffbab59c45b0678637672,Not nova but neutron,MERGED,2014-12-11 16:31:43.000000000,2014-12-13 04:52:16.000000000,2014-12-13 04:52:14.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8873}, {'_account_id': 9077}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10980}, {'_account_id': 11822}, {'_account_id': 14046}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 16:31:43.000000000', 'files': ['neutron/service.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6635e832d5d1d5114e8bb670b6e614de2d97a37f', 'message': 'Not nova but neutron\n\nThe docstring for topic is not correct.\n\nChange-Id: I6174453eb1c41c398ecffbab59c45b0678637672\n'}]",0,141091,6635e832d5d1d5114e8bb670b6e614de2d97a37f,47,25,1,7930,,,0,"Not nova but neutron

The docstring for topic is not correct.

Change-Id: I6174453eb1c41c398ecffbab59c45b0678637672
",git fetch https://review.opendev.org/openstack/neutron refs/changes/91/141091/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/service.py'],1,6635e832d5d1d5114e8bb670b6e614de2d97a37f,not-nova, :param topic: defaults to bin_name - 'neutron-' part, :param topic: defaults to bin_name - 'nova-' part,1,1
openstack%2Fneutron~master~I9f4b9e1f151281d4a467b3b90980a32529a78334,openstack/neutron,master,I9f4b9e1f151281d4a467b3b90980a32529a78334,Add lbaasv2 extension to Neutron for REST refactor,MERGED,2014-12-10 00:53:23.000000000,2014-12-13 04:16:57.000000000,2014-12-10 20:18:19.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 2592}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 12040}, {'_account_id': 14208}]","[{'number': 1, 'created': '2014-12-10 00:53:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/86f28dd5a370b31a85410903b3502d72cfac44a1', 'message': 'Add lbaasv2 extension to Neutron for REST refactor.\n\nChange-Id: I9f4b9e1f151281d4a467b3b90980a32529a78334\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}, {'number': 2, 'created': '2014-12-10 03:28:19.000000000', 'files': ['neutron/extensions/loadbalancerv2.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2b2f96bffacdf9ac837f67424bee8f67a0d35354', 'message': 'Add lbaasv2 extension to Neutron for REST refactor\n\nChange-Id: I9f4b9e1f151281d4a467b3b90980a32529a78334\nCo-Authored-By: Brandon Logan <brandon.logan@rackspace.com>\n'}]",2,140546,2b2f96bffacdf9ac837f67424bee8f67a0d35354,48,21,2,10980,,,0,"Add lbaasv2 extension to Neutron for REST refactor

Change-Id: I9f4b9e1f151281d4a467b3b90980a32529a78334
Co-Authored-By: Brandon Logan <brandon.logan@rackspace.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/46/140546/2 && git format-patch -1 --stdout FETCH_HEAD,['neutron/extensions/loadbalancerv2.py'],1,86f28dd5a370b31a85410903b3502d72cfac44a1,services-split-lb2-extension,"# Copyright 2014 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import abc from oslo.config import cfg import six from neutron.api import extensions from neutron.api.v2 import attributes as attr from neutron.api.v2 import base from neutron.api.v2 import resource_helper from neutron.common import exceptions as qexception from neutron import manager from neutron.plugins.common import constants from neutron.services import service_base # TODO(dougw) - stop hard-coding these constants when this extension moves # to the neutron-lbaas repo #from neutron.services.loadbalancer import constants as lb_const LB_METHOD_ROUND_ROBIN = 'ROUND_ROBIN' LB_METHOD_LEAST_CONNECTIONS = 'LEAST_CONNECTIONS' LB_METHOD_SOURCE_IP = 'SOURCE_IP' SUPPORTED_LB_ALGORITHMS = (LB_METHOD_LEAST_CONNECTIONS, LB_METHOD_ROUND_ROBIN, LB_METHOD_SOURCE_IP) PROTOCOL_TCP = 'TCP' PROTOCOL_HTTP = 'HTTP' PROTOCOL_HTTPS = 'HTTPS' SUPPORTED_PROTOCOLS = (PROTOCOL_TCP, PROTOCOL_HTTPS, PROTOCOL_HTTP) HEALTH_MONITOR_PING = 'PING' HEALTH_MONITOR_TCP = 'TCP' HEALTH_MONITOR_HTTP = 'HTTP' HEALTH_MONITOR_HTTPS = 'HTTPS' SUPPORTED_HEALTH_MONITOR_TYPES = (HEALTH_MONITOR_HTTP, HEALTH_MONITOR_HTTPS, HEALTH_MONITOR_PING, HEALTH_MONITOR_TCP) SESSION_PERSISTENCE_SOURCE_IP = 'SOURCE_IP' SESSION_PERSISTENCE_HTTP_COOKIE = 'HTTP_COOKIE' SESSION_PERSISTENCE_APP_COOKIE = 'APP_COOKIE' SUPPORTED_SP_TYPES = (SESSION_PERSISTENCE_SOURCE_IP, SESSION_PERSISTENCE_HTTP_COOKIE, SESSION_PERSISTENCE_APP_COOKIE) # Loadbalancer Exceptions # This exception is only for a workaround when having v1 and v2 lbaas extension # and plugins enabled class RequiredAttributeNotSpecified(qexception.BadRequest): message = _(""Required attribute %(attr_name)s not specified"") class EntityNotFound(qexception.NotFound): message = _(""%(name)s %(id)s could not be found"") class DelayOrTimeoutInvalid(qexception.BadRequest): message = _(""Delay must be greater than or equal to timeout"") class EntityInUse(qexception.InUse): message = _(""%(entity_using)s %(id)s is using this %(entity_in_use)s"") class LoadBalancerListenerProtocolPortExists(qexception.Conflict): message = _(""Load Balancer %(lb_id)s already has a listener with "" ""protocol_port of %(protocol_port)s"") class ListenerPoolProtocolMismatch(qexception.Conflict): message = _(""Listener protocol %(listener_proto)s and pool protocol "" ""%(pool_proto)s are not compatible."") class AttributeIDImmutable(qexception.NeutronException): message = _(""Cannot change %(attribute)s if one already exists"") class StateInvalid(qexception.NeutronException): message = _(""Invalid state %(state)s of loadbalancer resource %(id)s"") class MemberNotFoundForPool(qexception.NotFound): message = _(""Member %(member_id)s could not be found in pool %(pool_id)s"") class MemberExists(qexception.Conflict): message = _(""Member with address %(address)s and protocol_port %(port)s "" ""already present in pool %(pool)s"") class MemberAddressTypeSubnetTypeMismatch(qexception.NeutronException): message = _(""Member with address %(address)s and subnet %(subnet_id) "" "" have mismatched IP versions"") class DriverError(qexception.NeutronException): message = _(""An error happened in the driver"") class LBConfigurationUnsupported(qexception.NeutronException): message = _(""Load balancer %(load_balancer_id)s configuration is not"" ""supported by driver %(driver_name)s"") RESOURCE_ATTRIBUTE_MAP = { 'loadbalancers': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'vip_subnet_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, 'vip_address': {'allow_post': True, 'allow_put': False, 'default': attr.ATTR_NOT_SPECIFIED, 'validate': {'type:ip_address_or_none': None}, 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} }, 'listeners': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '', 'is_visible': True}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'loadbalancer_id': {'allow_post': True, 'allow_put': True, 'validate': {'type:uuid_or_none': None}, 'default': attr.ATTR_NOT_SPECIFIED, 'is_visible': True}, 'default_pool_id': {'allow_post': True, 'allow_put': True, 'validate': {'type:uuid_or_none': None}, 'default': attr.ATTR_NOT_SPECIFIED, 'is_visible': True}, 'connection_limit': {'allow_post': True, 'allow_put': True, 'default': -1, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'protocol': {'allow_post': True, 'allow_put': False, 'validate': {'type:values': SUPPORTED_PROTOCOLS}, 'is_visible': True}, 'protocol_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:range': [0, 65535]}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} }, 'pools': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'name': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'description': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'is_visible': True, 'default': ''}, 'healthmonitor_id': {'allow_post': True, 'allow_put': True, 'validate': {'type:string_or_none': None}, 'is_visible': True, 'default': attr.ATTR_NOT_SPECIFIED}, 'protocol': {'allow_post': True, 'allow_put': False, 'validate': {'type:values': SUPPORTED_PROTOCOLS}, 'is_visible': True}, 'lb_algorithm': {'allow_post': True, 'allow_put': True, 'validate': { 'type:values': SUPPORTED_LB_ALGORITHMS}, # TODO(brandon-logan) remove when old API is removed # because this is a required attribute) 'default': attr.ATTR_NOT_SPECIFIED, 'is_visible': True}, 'session_persistence': { 'allow_post': True, 'allow_put': True, 'convert_to': attr.convert_none_to_empty_dict, 'default': {}, 'validate': { 'type:dict_or_empty': { 'type': { 'type:values': SUPPORTED_SP_TYPES, 'required': True}, 'cookie_name': {'type:string': None, 'required': False}}}, 'is_visible': True}, 'members': {'allow_post': False, 'allow_put': False, 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} }, 'healthmonitors': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'type': {'allow_post': True, 'allow_put': False, 'validate': { 'type:values': SUPPORTED_HEALTH_MONITOR_TYPES}, 'is_visible': True}, 'delay': {'allow_post': True, 'allow_put': True, 'validate': {'type:non_negative': None}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'timeout': {'allow_post': True, 'allow_put': True, 'validate': {'type:non_negative': None}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'max_retries': {'allow_post': True, 'allow_put': True, 'validate': {'type:range': [1, 10]}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'http_method': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': 'GET', 'is_visible': True}, 'url_path': {'allow_post': True, 'allow_put': True, 'validate': {'type:string': None}, 'default': '/', 'is_visible': True}, 'expected_codes': { 'allow_post': True, 'allow_put': True, 'validate': { 'type:regex': '^(\d{3}(\s*,\s*\d{3})*)$|^(\d{3}-\d{3})$' }, 'default': '200', 'is_visible': True }, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True} } } SUB_RESOURCE_ATTRIBUTE_MAP = { 'members': { 'parent': {'collection_name': 'pools', 'member_name': 'pool'}, 'parameters': { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'address': {'allow_post': True, 'allow_put': False, 'validate': {'type:ip_address': None}, 'is_visible': True}, 'protocol_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:range': [0, 65535]}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'weight': {'allow_post': True, 'allow_put': True, 'default': 1, 'validate': {'type:range': [0, 256]}, 'convert_to': attr.convert_to_int, 'is_visible': True}, 'admin_state_up': {'allow_post': True, 'allow_put': True, 'default': True, 'convert_to': attr.convert_to_boolean, 'is_visible': True}, 'status': {'allow_post': False, 'allow_put': False, 'is_visible': True}, 'subnet_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, } } } lbaasv2_quota_opts = [ cfg.IntOpt('quota_loadbalancer', default=10, help=_('Number of LoadBalancers allowed per tenant. ' 'A negative value means unlimited.')), cfg.IntOpt('quota_listener', default=-1, help=_('Number of Loadbalancer Listeners allowed per tenant. ' 'A negative value means unlimited.')), cfg.IntOpt('quota_pool', default=10, help=_('Number of pools allowed per tenant. ' 'A negative value means unlimited.')), cfg.IntOpt('quota_member', default=-1, help=_('Number of pool members allowed per tenant. ' 'A negative value means unlimited.')), cfg.IntOpt('quota_healthmonitor', default=-1, help=_('Number of health monitors allowed per tenant. ' 'A negative value means unlimited.')) ] cfg.CONF.register_opts(lbaasv2_quota_opts, 'QUOTAS') class Loadbalancerv2(extensions.ExtensionDescriptor): @classmethod def get_name(cls): return ""LoadBalancing service v2"" @classmethod def get_alias(cls): return ""lbaasv2"" @classmethod def get_description(cls): return ""Extension for LoadBalancing service v2"" @classmethod def get_namespace(cls): return ""http://wiki.openstack.org/neutron/LBaaS/API_2.0"" @classmethod def get_updated(cls): return ""2014-06-18T10:00:00-00:00"" @classmethod def get_resources(cls): plural_mappings = resource_helper.build_plural_mappings( {}, RESOURCE_ATTRIBUTE_MAP) action_map = {'loadbalancer': {'stats': 'GET'}} plural_mappings['members'] = 'member' attr.PLURALS.update(plural_mappings) resources = resource_helper.build_resource_info( plural_mappings, RESOURCE_ATTRIBUTE_MAP, constants.LOADBALANCERV2, action_map=action_map, register_quota=True) plugin = manager.NeutronManager.get_service_plugins()[ constants.LOADBALANCERV2] for collection_name in SUB_RESOURCE_ATTRIBUTE_MAP: # Special handling needed for sub-resources with 'y' ending # (e.g. proxies -> proxy) resource_name = collection_name[:-1] parent = SUB_RESOURCE_ATTRIBUTE_MAP[collection_name].get('parent') params = SUB_RESOURCE_ATTRIBUTE_MAP[collection_name].get( 'parameters') controller = base.create_resource(collection_name, resource_name, plugin, params, allow_bulk=True, parent=parent, allow_pagination=True, allow_sorting=True) resource = extensions.ResourceExtension( collection_name, controller, parent, path_prefix=constants.COMMON_PREFIXES[ constants.LOADBALANCERV2], attr_map=params) resources.append(resource) return resources @classmethod def get_plugin_interface(cls): return LoadBalancerPluginBaseV2 def update_attributes_map(self, attributes, extension_attrs_map=None): super(Loadbalancerv2, self).update_attributes_map( attributes, extension_attrs_map=RESOURCE_ATTRIBUTE_MAP) def get_extended_resources(self, version): if version == ""2.0"": return RESOURCE_ATTRIBUTE_MAP else: return {} @six.add_metaclass(abc.ABCMeta) class LoadBalancerPluginBaseV2(service_base.ServicePluginBase): def get_plugin_name(self): return constants.LOADBALANCERV2 def get_plugin_type(self): return constants.LOADBALANCERV2 def get_plugin_description(self): return 'LoadBalancer service plugin v2' @abc.abstractmethod def get_loadbalancers(self, context, filters=None, fields=None): pass @abc.abstractmethod def get_loadbalancer(self, context, id, fields=None): pass @abc.abstractmethod def create_loadbalancer(self, context, loadbalancer): pass @abc.abstractmethod def update_loadbalancer(self, context, id, loadbalancer): pass @abc.abstractmethod def delete_loadbalancer(self, context, id): pass @abc.abstractmethod def create_listener(self, context, listener): pass @abc.abstractmethod def get_listener(self, context, id, fields=None): pass @abc.abstractmethod def get_listeners(self, context, filters=None, fields=None): pass @abc.abstractmethod def update_listener(self, context, id, listener): pass @abc.abstractmethod def delete_listener(self, context, id): pass @abc.abstractmethod def get_pools(self, context, filters=None, fields=None): pass @abc.abstractmethod def get_pool(self, context, id, fields=None): pass @abc.abstractmethod def create_pool(self, context, pool): pass @abc.abstractmethod def update_pool(self, context, id, pool): pass @abc.abstractmethod def delete_pool(self, context, id): pass @abc.abstractmethod def stats(self, context, loadbalancer_id): pass @abc.abstractmethod def get_pool_members(self, context, pool_id, filters=None, fields=None): pass @abc.abstractmethod def get_pool_member(self, context, id, pool_id, fields=None): pass @abc.abstractmethod def create_pool_member(self, context, member, pool_id): pass @abc.abstractmethod def update_pool_member(self, context, member, id, pool_id): pass @abc.abstractmethod def delete_pool_member(self, context, id, pool_id): pass @abc.abstractmethod def get_healthmonitors(self, context, filters=None, fields=None): pass @abc.abstractmethod def get_healthmonitor(self, context, id, fields=None): pass @abc.abstractmethod def create_healthmonitor(self, context, healthmonitor): pass @abc.abstractmethod def update_healthmonitor(self, context, id, healthmonitor): pass @abc.abstractmethod def delete_healthmonitor(self, context, id): pass @abc.abstractmethod def get_members(self, context, filters=None, fields=None): pass @abc.abstractmethod def get_member(self, context, id, fields=None): pass ",,566,0
openstack%2Fneutron~master~I18f00383ecae68436a9208f094a898849bfed8a2,openstack/neutron,master,I18f00383ecae68436a9208f094a898849bfed8a2,Imported Translations from Transifex,MERGED,2014-12-11 06:05:11.000000000,2014-12-13 03:21:21.000000000,2014-12-13 03:21:19.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-11 06:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/da746ccd300be0d37f9e5a398722af51f687b885', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I18f00383ecae68436a9208f094a898849bfed8a2\n'}, {'number': 2, 'created': '2014-12-12 06:08:16.000000000', 'files': ['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po'], 'web_link': 'https://opendev.org/openstack/neutron/commit/2770cd8a9b448ae894b13073cafea6e2ef923802', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I18f00383ecae68436a9208f094a898849bfed8a2\n'}]",0,140929,2770cd8a9b448ae894b13073cafea6e2ef923802,50,19,2,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I18f00383ecae68436a9208f094a898849bfed8a2
",git fetch https://review.opendev.org/openstack/neutron refs/changes/29/140929/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/locale/neutron-log-error.pot', 'neutron/locale/pt_BR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/ja/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/de/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_CN/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/es/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-warning.pot', 'neutron/locale/fr/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/neutron-log-info.pot', 'neutron/locale/neutron.pot', 'neutron/locale/ko_KR/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/zh_TW/LC_MESSAGES/neutron-log-info.po', 'neutron/locale/it/LC_MESSAGES/neutron-log-info.po']",13,da746ccd300be0d37f9e5a398722af51f687b885,transifex/translations,"""POT-Creation-Date: 2014-12-11 06:04+0000\n"" ""PO-Revision-Date: 2014-12-10 22:16+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3/agent.py:1713#: neutron/agent/l3/agent.py:1615 msgid ""L3 agent started"" msgstr ""Agent L3 avviato"" ","""POT-Creation-Date: 2014-12-10 06:07+0000\n"" ""PO-Revision-Date: 2014-12-10 00:24+0000\n""#: neutron/agent/dhcp_agent.py:602 neutron/agent/l3_agent.py:1999#: neutron/agent/l3_agent.py:1901 msgid ""L3 agent started"" msgstr ""Agent L3 avviato"" #: neutron/services/vpn/service_drivers/cisco_csr_db.py:226 #, python-format msgid """" ""Mapped connection %(conn_id)s to Tunnel%(tunnel_id)d using IKE policy ID "" ""%(ike_id)d and IPSec policy ID %(ipsec_id)d"" msgstr """" #: neutron/services/vpn/service_drivers/cisco_csr_db.py:238 #, python-format msgid ""Removed mapping for connection %s"" msgstr """" ",380,542
openstack%2Fneutron-lbaas~master~Ic5f0cca72d0af1053c840bae69a99ab5a173dafa,openstack/neutron-lbaas,master,Ic5f0cca72d0af1053c840bae69a99ab5a173dafa,Fake review to test tempest jobs,ABANDONED,2014-12-12 18:17:39.000000000,2014-12-13 03:16:25.000000000,,"[{'_account_id': 3}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 18:17:39.000000000', 'files': ['FOO'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/9cf31e5e82d12b5f55fa476074a74de5f301f483', 'message': 'Fake review to test tempest jobs\n\nChange-Id: Ic5f0cca72d0af1053c840bae69a99ab5a173dafa\n'}]",0,141451,9cf31e5e82d12b5f55fa476074a74de5f301f483,8,2,1,10980,,,0,"Fake review to test tempest jobs

Change-Id: Ic5f0cca72d0af1053c840bae69a99ab5a173dafa
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/51/141451/1 && git format-patch -1 --stdout FETCH_HEAD,['FOO'],1,9cf31e5e82d12b5f55fa476074a74de5f301f483,foo,,,0,0
openstack%2Fkeystone~master~Icc0a96cb705ce11f03342d4df1f12844f224c967,openstack/keystone,master,Icc0a96cb705ce11f03342d4df1f12844f224c967,Inherited role assignments to projects,MERGED,2014-12-02 21:40:10.000000000,2014-12-13 03:15:06.000000000,2014-12-13 03:15:04.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 792}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 2903}, {'_account_id': 5046}, {'_account_id': 5707}, {'_account_id': 6482}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 7725}, {'_account_id': 8871}, {'_account_id': 11022}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-12-02 21:40:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/29a8342e9c9ce656c4c472f671efa904c2d8ba40', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 2, 'created': '2014-12-02 21:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fd90990eb4dc471e40abbd9115717ac077de8335', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 3, 'created': '2014-12-03 14:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d059891db1c136d267c6719d328dd7e9ea2dcd3c', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 4, 'created': '2014-12-03 19:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/87686d893c9d49653296a471207005710f0046d2', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 5, 'created': '2014-12-03 19:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/6d63772666360c22e9f049c2e72c7fdc6964daf8', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 6, 'created': '2014-12-04 21:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/8d3224dae700971590c4eb961d0968418db9d235', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 7, 'created': '2014-12-05 14:18:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/da530b47bca537f494d70064d9ccf122ecc488f4', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 8, 'created': '2014-12-05 19:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/31862e66d0dd087886868c0974c70ad03f4caeb0', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 9, 'created': '2014-12-05 19:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2e941fd90e390af73737684434422534277b209b', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 10, 'created': '2014-12-09 13:54:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fdb257490cced6f4772bc3f4fda19a64a23d202c', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 11, 'created': '2014-12-10 14:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/79c26fa1e533d24191d87cd162d553cb1b73cdaf', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 12, 'created': '2014-12-11 17:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/dd7debcfcf9a294d0f82019dc19ea7c5496b265d', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 13, 'created': '2014-12-11 17:57:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/47866bf4a8c70a39daaec2b498ae4d6989928a4b', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}, {'number': 14, 'created': '2014-12-11 19:31:05.000000000', 'files': ['keystone/assignment/controllers.py', 'keystone/assignment/backends/sql.py', 'keystone/assignment/core.py', 'keystone/assignment/routers.py', 'keystone/tests/test_v3_assignment.py', 'keystone/tests/test_versions.py', 'keystone/tests/test_v3.py', 'keystone/tests/test_backend.py', 'keystone/assignment/backends/ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/ac5a118e1abe1fc0fd9f676f30436959c8cb1847', 'message': 'Inherited role assignments to projects\n\nAdding inherited role assignments to hierarchical projects.\n\nCo-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>\nCo-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>\nCo-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>\nCo-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>\nCo-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>\n\nChange-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967\nImplements: blueprint hierarchical-multitenancy\n'}]",64,138552,ac5a118e1abe1fc0fd9f676f30436959c8cb1847,64,15,14,11022,,,0,"Inherited role assignments to projects

Adding inherited role assignments to hierarchical projects.

Co-Authored-By: Andre Aranha <afaranha@lsd.ufcg.edu.br>
Co-Authored-By: Gabriel Assis Bezerra <gabrielb@lsd.ufcg.edu.br>
Co-Authored-By: Raildo Mascena de Sousa Filho <raildo@lsd.ufcg.edu.br>
Co-Authored-By: Rodrigo Duarte <rodrigods@lsd.ufcg.edu.br>
Co-Authored-By: Samuel de Medeiros Queiroz <samuel@lsd.ufcg.edu.br>

Change-Id: Icc0a96cb705ce11f03342d4df1f12844f224c967
Implements: blueprint hierarchical-multitenancy
",git fetch https://review.opendev.org/openstack/keystone refs/changes/52/138552/6 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/assignment/controllers.py', 'keystone/assignment/backends/sql.py', 'keystone/assignment/core.py', 'keystone/assignment/routers.py', 'keystone/tests/test_v3_assignment.py', 'keystone/tests/test_versions.py', 'keystone/tests/test_v3.py', 'keystone/tests/test_backend_ldap.py', 'keystone/assignment/backends/ldap.py']",9,29a8342e9c9ce656c4c472f671efa904c2d8ba40,bp/hierarchical-multitenancy,," if project_id and inherited_to_projects: msg = _('Inherited roles can only be assigned to domains') raise exception.Conflict(type='role grant', details=msg) ",433,63
openstack%2Fneutron~master~Ie68b26a48c1d0ed9cb8e584a7284c06688937cf9,openstack/neutron,master,Ie68b26a48c1d0ed9cb8e584a7284c06688937cf9,Reduce code duplication in test_linux_dhcp,MERGED,2014-12-08 10:45:21.000000000,2014-12-13 02:35:07.000000000,2014-12-13 02:35:05.000000000,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 6502}, {'_account_id': 7249}, {'_account_id': 7293}, {'_account_id': 8124}, {'_account_id': 8645}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 9970}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 11701}, {'_account_id': 12040}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-08 10:45:21.000000000', 'files': ['neutron/tests/unit/test_linux_dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/d1531b5e99a1b1d20c5b9ef7254b4ae812b44654', 'message': 'Reduce code duplication in test_linux_dhcp\n\nThis patch reduces duplication in test_output_opts_file_*()\n\nChange-Id: Ie68b26a48c1d0ed9cb8e584a7284c06688937cf9\nCloses-Bug: #1352870\n'}]",0,139966,d1531b5e99a1b1d20c5b9ef7254b4ae812b44654,38,31,1,7293,,,0,"Reduce code duplication in test_linux_dhcp

This patch reduces duplication in test_output_opts_file_*()

Change-Id: Ie68b26a48c1d0ed9cb8e584a7284c06688937cf9
Closes-Bug: #1352870
",git fetch https://review.opendev.org/openstack/neutron refs/changes/66/139966/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/test_linux_dhcp.py'],1,d1531b5e99a1b1d20c5b9ef7254b4ae812b44654,bug/1352870," def _test_output_opts_file(self, expected, network, ipm_retval=None): with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, network, version=dhcp.Dnsmasq.MINIMUM_VERSION) if ipm_retval: with mock.patch.object( dm, '_make_subnet_interface_ip_map') as ipm: ipm.return_value = ipm_retval dm._output_opts_file() self.assertTrue(ipm.called) else: dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) self._test_output_opts_file(expected, FakeDualNetwork()) expected = ('tag:tag0,option:dns-server,8.8.8.8\n' 'tag:tag0,option:router,192.168.0.1\n' 'tag:tag1,option6:dns-server,%s\n' 'tag:tag1,option6:domain-search,' 'openstacklocal').lstrip() % ('[' + fake_v6 + ']') self._test_output_opts_file(expected, FakeDualNetworkGatewayRoute()) expected = ('tag:tag0,option:router,192.168.0.1\n' 'tag:tag0,option:dns-server,192.168.0.5,' '192.168.0.6').lstrip() self._test_output_opts_file(expected, FakeV4MultipleAgentsWithoutDnsProvided()) expected = ('tag:tag0,option:dns-server,8.8.8.8\n' 'tag:tag0,option:router,192.168.0.1').lstrip() self._test_output_opts_file(expected, FakeV4MultipleAgentsWithDnsProvided()) self._test_output_opts_file(expected, FakeDualNetworkSingleDHCP()) expected = ( 'tag:tag0,option:classless-static-route,' '169.254.169.254/32,192.168.1.1\n' 'tag:tag0,249,169.254.169.254/32,192.168.1.1\n' 'tag:tag0,option:router').lstrip() ipm_retval = {FakeV4SubnetNoGateway.id: '192.168.1.1'} self._test_output_opts_file(expected, FakeV4NoGatewayNetwork(), ipm_retval=ipm_retval) ipm_retval = {FakeV4SubnetNoRouter.id: '192.168.1.2'} self._test_output_opts_file(expected, FakeV4NetworkNoRouter(), ipm_retval=ipm_retval) ipm_retval = {FakeV4Subnet.id: '192.168.0.1'} self._test_output_opts_file(expected, FakeV4NetworkDistRouter(), ipm_retval=ipm_retval) 'option:bootfile-name,pxelinux.0').lstrip() self._test_output_opts_file(expected, FakeV4NetworkPxe2Ports()) 'option:bootfile-name,pxelinux.0').lstrip() self._test_output_opts_file(expected, FakeV4NetworkPxe2Ports(""portsDiff"")) 'option:bootfile-name,pxelinux3.0').lstrip() self._test_output_opts_file(expected, FakeDualV4Pxe3Ports())"," with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeDualNetwork(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) expected = """""" tag:tag0,option:dns-server,8.8.8.8 tag:tag0,option:router,192.168.0.1 tag:tag1,option6:dns-server,%s tag:tag1,option6:domain-search,openstacklocal"""""".lstrip() % ( '[' + fake_v6 + ']') with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeDualNetworkGatewayRoute(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) expected = """""" tag:tag0,option:router,192.168.0.1 tag:tag0,option:dns-server,192.168.0.5,192.168.0.6"""""".lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4MultipleAgentsWithoutDnsProvided(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) expected = """""" tag:tag0,option:dns-server,8.8.8.8 tag:tag0,option:router,192.168.0.1"""""".lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4MultipleAgentsWithDnsProvided(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeDualNetworkSingleDHCP(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) expected = """""" tag:tag0,option:classless-static-route,169.254.169.254/32,192.168.1.1 tag:tag0,249,169.254.169.254/32,192.168.1.1 tag:tag0,option:router"""""".lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4NoGatewayNetwork(), version=dhcp.Dnsmasq.MINIMUM_VERSION) with mock.patch.object(dm, '_make_subnet_interface_ip_map') as ipm: ipm.return_value = {FakeV4SubnetNoGateway.id: '192.168.1.1'} dm._output_opts_file() self.assertTrue(ipm.called) self.safe.assert_called_once_with('/foo/opts', expected) with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4NetworkNoRouter(), version=dhcp.Dnsmasq.MINIMUM_VERSION) with mock.patch.object(dm, '_make_subnet_interface_ip_map') as ipm: ipm.return_value = {FakeV4SubnetNoRouter.id: '192.168.1.2'} dm._output_opts_file() self.assertTrue(ipm.called) self.safe.assert_called_once_with('/foo/opts', expected) with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4NetworkDistRouter(), version=dhcp.Dnsmasq.MINIMUM_VERSION) with mock.patch.object(dm, '_make_subnet_interface_ip_map') as ipm: ipm.return_value = {FakeV4Subnet.id: '192.168.0.1'} dm._output_opts_file() self.assertTrue(ipm.called) self.safe.assert_called_once_with('/foo/opts', expected) 'option:bootfile-name,pxelinux.0') expected = expected.lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' fp = FakeV4NetworkPxe2Ports() dm = dhcp.Dnsmasq(self.conf, fp, version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) 'option:bootfile-name,pxelinux.0') expected = expected.lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeV4NetworkPxe2Ports(""portsDiff""), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected) 'option:bootfile-name,pxelinux3.0') expected = expected.lstrip() with mock.patch.object(dhcp.Dnsmasq, 'get_conf_file_name') as conf_fn: conf_fn.return_value = '/foo/opts' dm = dhcp.Dnsmasq(self.conf, FakeDualV4Pxe3Ports(), version=dhcp.Dnsmasq.MINIMUM_VERSION) dm._output_opts_file() self.safe.assert_called_once_with('/foo/opts', expected)",55,111
openstack%2Fcongress~master~Ic49cb90b462fe37ba19a9431f7057eac55b41ada,openstack/congress,master,Ic49cb90b462fe37ba19a9431f7057eac55b41ada,Subclass from congress.tests.base.TestCase,MERGED,2014-12-11 23:45:38.000000000,2014-12-13 02:16:40.000000000,2014-12-13 01:36:06.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-11 23:45:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/75296017b4cdf78e9109029b1d5ef59caaf5b373', 'message': 'Subclass from congress.tests.base.TestCase\n\nPreviously, our tests were inconsistent in their superclass; some subclassed\nfrom congress.tests.base.TestCase, while others subclassed from\nunittest.TestCase.\n\nOur tests need to subclass from congress.tests.base.TestCase so that logging\ninfrastructure and other things are initialized.  This is why some tests would\nnot produce any log messages when the test failed.\n\nAll future tests should subclass from congress.tests.base.TestCase.\n\nChange-Id: Ic49cb90b462fe37ba19a9431f7057eac55b41ada\n'}, {'number': 2, 'created': '2014-12-12 21:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/417d5f7ec58ab531c133698f347dcb617105cc8c', 'message': 'Subclass from congress.tests.base.TestCase\n\nPreviously, our tests were inconsistent in their superclass; some subclassed\nfrom congress.tests.base.TestCase, while others subclassed from\nunittest.TestCase.\n\nOur tests need to subclass from congress.tests.base.TestCase so that logging\ninfrastructure and other things are initialized.  This is why some tests would\nnot produce any log messages when the test failed.\n\nAll future tests should subclass from congress.tests.base.TestCase.\n\nChange-Id: Ic49cb90b462fe37ba19a9431f7057eac55b41ada\n'}, {'number': 3, 'created': '2014-12-12 21:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/5ebf4ab70177f36d9e97a74d8ba1440f8759299e', 'message': 'Subclass from congress.tests.base.TestCase\n\nPreviously, our tests were inconsistent in their superclass; some subclassed\nfrom congress.tests.base.TestCase, while others subclassed from\nunittest.TestCase.\n\nOur tests need to subclass from congress.tests.base.TestCase so that logging\ninfrastructure and other things are initialized.  This is why some tests would\nnot produce any log messages when the test failed.\n\nAll future tests should subclass from congress.tests.base.TestCase.\n\nChange-Id: Ic49cb90b462fe37ba19a9431f7057eac55b41ada\n'}, {'number': 4, 'created': '2014-12-12 22:46:03.000000000', 'files': ['congress/tests/api/test_webservice.py', 'congress/tests/policy/test_unify.py', 'congress/tests/policy/brokentest_runtime.py', 'congress/tests/policy/test_nonrecur.py', 'congress/tests/policy/test_runtime.py', 'congress/tests/policy/test_ordered_set.py', 'congress/tests/dse/test_dse.py', 'congress/tests/policy/test_compiler.py', 'congress/tests/policy/builtin/test_builtin.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/89a3b617bf308f04d96ca06dbee4de95b343e95e', 'message': 'Subclass from congress.tests.base.TestCase\n\nPreviously, our tests were inconsistent in their superclass; some subclassed\nfrom congress.tests.base.TestCase, while others subclassed from\nunittest.TestCase.\n\nOur tests need to subclass from congress.tests.base.TestCase so that logging\ninfrastructure and other things are initialized.  This is why some tests would\nnot produce any log messages when the test failed.\n\nAll future tests should subclass from congress.tests.base.TestCase.\n\nThis change alters our use of assertRaises() since the congress.tests.base\nclass\'s implementation of assertRaises() does not support the ""with"" syntax.\n\nChange-Id: Ic49cb90b462fe37ba19a9431f7057eac55b41ada\n'}]",15,141216,89a3b617bf308f04d96ca06dbee4de95b343e95e,25,4,4,12875,,,0,"Subclass from congress.tests.base.TestCase

Previously, our tests were inconsistent in their superclass; some subclassed
from congress.tests.base.TestCase, while others subclassed from
unittest.TestCase.

Our tests need to subclass from congress.tests.base.TestCase so that logging
infrastructure and other things are initialized.  This is why some tests would
not produce any log messages when the test failed.

All future tests should subclass from congress.tests.base.TestCase.

This change alters our use of assertRaises() since the congress.tests.base
class's implementation of assertRaises() does not support the ""with"" syntax.

Change-Id: Ic49cb90b462fe37ba19a9431f7057eac55b41ada
",git fetch https://review.opendev.org/openstack/congress refs/changes/16/141216/4 && git format-patch -1 --stdout FETCH_HEAD,"['congress/tests/api/test_webservice.py', 'congress/tests/policy/test_unify.py', 'congress/tests/policy/brokentest_runtime.py', 'congress/tests/policy/test_nonrecur.py', 'congress/tests/policy/test_runtime.py', 'congress/tests/policy/test_ordered_set.py', 'congress/tests/dse/test_dse.py', 'congress/tests/policy/test_compiler.py', 'congress/tests/policy/builtin/test_builtin.py']",9,75296017b4cdf78e9109029b1d5ef59caaf5b373,,"import congress.tests.baseclass TestBuiltins(congress.tests.base.TestCase): super(TestBuiltins, self).setUp()class TestReorder(congress.tests.base.TestCase): def setUp(self): super(TestReorder, self).setUp() class TestTheories(congress.tests.base.TestCase): def setUp(self): super(TestTheories, self).setUp()", import unittest class TestBuiltins(unittest.TestCase):class TestReorder(unittest.TestCase):class TestTheories(unittest.TestCase): if __name__ == '__main__': unittest.main(),52,60
openstack%2Fneutron~master~Ib355f34917580b88bda3d550e33fc630a8e7120b,openstack/neutron,master,Ib355f34917580b88bda3d550e33fc630a8e7120b,Generate testr_results.html for neutron functional job,MERGED,2014-12-10 22:39:14.000000000,2014-12-13 02:14:41.000000000,2014-12-13 02:14:39.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10387}, {'_account_id': 10980}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-10 22:39:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bd8147cc923324fa8662ccd4ce310bd238124dff', 'message': 'Add subunit.log to functional test runs\n\nBy having this log file, we will be able to get a\nformatted output to feed to test-results.\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 2, 'created': '2014-12-11 00:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9ebdcab068424fbb94e0327d27e6f0a21412df16', 'message': 'Add subunit.log to functional test runs\n\nBy having this log file, we will be able to get a\nformatted output to feed to test-results.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 3, 'created': '2014-12-11 06:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ebc46c91b0790d4fe7d266ab51525c5f030b302b', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 4, 'created': '2014-12-11 06:46:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1a9f8aa9a2f6b944965de408c7fcda33a2c42a1b', 'message': 'Add subunit.log to functional test runs\n\nWIP: take 3\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 5, 'created': '2014-12-11 07:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bf1c460c355b7ca96c6655cf43557b0c5043825f', 'message': 'Add subunit.log to functional test runs\n\nWIP: take 5\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 6, 'created': '2014-12-11 07:37:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d0cffc30078500e71c38bb5e1c89d096e059293d', 'message': 'Add subunit.log to functional test runs\n\nWIP: take 6\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 7, 'created': '2014-12-11 08:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ddbcaa8de600c5f9014dd8040963e70aa0ef385', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 8, 'created': '2014-12-11 08:29:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fe3db53f218ce13c0e3c3a0083c48ffe659a28f5', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 9, 'created': '2014-12-11 08:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa78d9eaf60dafe343b0527cb4715dfca6504126', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 10, 'created': '2014-12-11 08:54:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7e7544d23d86011e82e496dd6560035182375f6', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 11, 'created': '2014-12-11 16:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a6865e7aa89ae4a85ea5efe2798eb27aa077192c', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 12, 'created': '2014-12-11 16:51:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55b4166970b83b3c82eb47bd2b3a967d8a5d26d2', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 13, 'created': '2014-12-11 17:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e297a64b84419110bfee09acd5abc6a56b520cfc', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 14, 'created': '2014-12-11 17:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b7ba15f4b8e8568ec7022607d4e92678546a6ce4', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 15, 'created': '2014-12-11 18:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e7f06e6deea003decc9ca60f8960967cc86ab793', 'message': 'Add subunit.log to functional test runs\n\nWIP\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 16, 'created': '2014-12-11 21:54:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/385c4974e351d3e7a5a03f14830a70acfbae24f2', 'message': 'Generated testr_results.html for neutron functional jobs\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 17, 'created': '2014-12-12 00:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f36cd53a87308d0a6f40da985a13393511a2a539', 'message': 'Generated testr_results.html for neutron functional jobs\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 18, 'created': '2014-12-12 01:13:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6af45217331d98705b00d1dccbdf0f671db2c366', 'message': 'Generated testr_results.html for neutron functional jobs\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 19, 'created': '2014-12-12 01:32:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/96744eab7693f906e7857fbc53ddc6ea5b54d879', 'message': 'Generate testr_results.html for neutron functional jobs\n\nTweak job post-hook script to generate testr results the\nsame way other jobs do, with a pretty html view that is\neasy to digest and navigate.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 20, 'created': '2014-12-12 18:41:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4ccd98b468212ca179aa7b8768eee01f818c2cb6', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 21, 'created': '2014-12-12 18:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6c5daabfae240487f7fd7d442a167f339a82e1ef', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\n** DO NOT MERGE YET **\nI want to check how the failure path is handled by the\npost hook\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 22, 'created': '2014-12-12 21:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/688fe47250649159822339b4fa85aa8ee646b791', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\n** DO NOT MERGE YET **\nI want to check how the failure path is handled by the\npost hook\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 23, 'created': '2014-12-12 21:26:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0c09890c9c54d2430618d4accab5a44ae9f8f72a', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 24, 'created': '2014-12-13 00:15:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/773541bbbb0426f4aedf6d437068df03b7460f7e', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}, {'number': 25, 'created': '2014-12-13 00:17:07.000000000', 'files': ['neutron/tests/functional/contrib/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/neutron/commit/622d872efc8e0317eaf6ade870f3f01a9cc64e90', 'message': 'Generate testr_results.html for neutron functional job\n\nTweak job post_test_hook script to generate testr results\nthe same way other jobs do, with a pretty html view that\nis easy to digest and navigate.\n\nCloses-bug: #1401340\n\nChange-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b\n'}]",5,140851,622d872efc8e0317eaf6ade870f3f01a9cc64e90,356,28,25,748,,,0,"Generate testr_results.html for neutron functional job

Tweak job post_test_hook script to generate testr results
the same way other jobs do, with a pretty html view that
is easy to digest and navigate.

Closes-bug: #1401340

Change-Id: Ib355f34917580b88bda3d550e33fc630a8e7120b
",git fetch https://review.opendev.org/openstack/neutron refs/changes/51/140851/25 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/contrib/post_test_hook.sh'],1,bd8147cc923324fa8662ccd4ce310bd238124dff,bug/1401340,"function copy_subunit_log { LOGNAME=`cat .testrepository/next-stream` LOGNAME=$(($LOGNAME - 1)) LOGNAME="".testrepository/${LOGNAME}"" cp $LOGNAME subunit.log } copy_subunit_log",,9,0
openstack%2Fpython-neutronclient~master~I98879cfe1bb1e7c085404aa73786a1eeaae1f40e,openstack/python-neutronclient,master,I98879cfe1bb1e7c085404aa73786a1eeaae1f40e,Add unit tests for agent related commands,MERGED,2014-12-02 10:00:51.000000000,2014-12-13 02:12:03.000000000,2014-12-13 02:12:03.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 7249}]","[{'number': 1, 'created': '2014-12-02 10:00:51.000000000', 'files': ['neutronclient/tests/unit/test_cli20_agents.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/89271b191e1a092d999e3eb9147e40894d8c9183', 'message': 'Add unit tests for agent related commands\n\nAdded unit tests to cover:\n    * agent show;\n    * agent delete.\n\nChange-Id: I98879cfe1bb1e7c085404aa73786a1eeaae1f40e\nCloses-Bug: #1206110\n'}]",0,138302,89271b191e1a092d999e3eb9147e40894d8c9183,8,4,1,7293,,,0,"Add unit tests for agent related commands

Added unit tests to cover:
    * agent show;
    * agent delete.

Change-Id: I98879cfe1bb1e7c085404aa73786a1eeaae1f40e
Closes-Bug: #1206110
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/02/138302/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/tests/unit/test_cli20_agents.py'],1,89271b191e1a092d999e3eb9147e40894d8c9183,bug/1206110," def test_show_agent(self): """"""Show agent: --field id --field binary myid."""""" resource = 'agent' cmd = agent.ShowAgent(test_cli20.MyApp(sys.stdout), None) args = ['--field', 'id', '--field', 'binary', self.test_id] self._test_show_resource(resource, cmd, self.test_id, args, ['id', 'binary']) def test_delete_agent(self): """"""Delete agent: myid."""""" resource = 'agent' cmd = agent.DeleteAgent(test_cli20.MyApp(sys.stdout), None) myid = 'myid' args = [myid] self._test_delete_resource(resource, cmd, myid, args)",,16,0
openstack%2Fpython-neutronclient~master~Ie9f30f30102bef6735dc9ed538eca9a1183c2780,openstack/python-neutronclient,master,Ie9f30f30102bef6735dc9ed538eca9a1183c2780,Make help for agent-update more verbose,MERGED,2014-11-20 11:24:47.000000000,2014-12-13 02:11:51.000000000,2014-12-13 02:11:50.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 5948}, {'_account_id': 5950}, {'_account_id': 6072}, {'_account_id': 7125}, {'_account_id': 7249}, {'_account_id': 7293}]","[{'number': 1, 'created': '2014-11-20 11:24:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/043032000ed6c0f7671d17d1f9b8cd8013226022', 'message': 'Make help for agent-update more verbose\n\nAmended the description of the command to reflect what it\nreally does.\nAdded two optional aguments:\n    * admin-state-down - sets admin state up to false\n    * description - provides the description for the agent\n\nChange-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780\nCloses-Bug: #1254241\n'}, {'number': 2, 'created': '2014-11-20 11:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/1ad7f49ce0f65519fab44673dd816aeb5ad784f2', 'message': 'Make help for agent-update more verbose\n\nAmended the description of the command to reflect what it\nreally does.\nAdded two optional aguments:\n    * admin-state-down - sets admin state up to false\n    * description - provides the description for the agent\n\nChange-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780\nCloses-Bug: #1254241\n'}, {'number': 3, 'created': '2014-11-24 07:55:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/bc83524ea3edf18fa678924f4c9b623b3971101a', 'message': 'Make help for agent-update more verbose\n\nAmended the description of the command to reflect what it\nreally does.\nAdded two optional aguments:\n    * admin-state-up - sets admin state up for the agent\n    * description - provides the description for the agent\n\nChange-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780\nCloses-Bug: #1254241\n'}, {'number': 4, 'created': '2014-11-28 14:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/54b932f75410f766ece9b8c42ee1da4a272d529f', 'message': 'Make help for agent-update more verbose\n\nAmended the description of the command to reflect what it\nreally does.\nAdded two optional aguments:\n    * admin-state-down - sets admin state up of the agent to false\n    * description - provides the description for the agent\n\nAdded a unit test.\n\nChange-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780\nCloses-Bug: #1254241\n'}, {'number': 5, 'created': '2014-12-02 10:00:51.000000000', 'files': ['neutronclient/neutron/v2_0/agent.py', 'neutronclient/tests/unit/test_cli20_agents.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/56892bb08abce93b352a773e001f5b950c4a7c85', 'message': 'Make help for agent-update more verbose\n\nAmended the description of the command to reflect what it\nreally does.\nAdded two optional aguments:\n    * admin-state-down - sets admin state up of the agent to false\n    * description - provides the description for the agent\n\nAdded a unit test.\n\nChange-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780\nCloses-Bug: #1254241\n'}]",2,135917,56892bb08abce93b352a773e001f5b950c4a7c85,39,8,5,7293,,,0,"Make help for agent-update more verbose

Amended the description of the command to reflect what it
really does.
Added two optional aguments:
    * admin-state-down - sets admin state up of the agent to false
    * description - provides the description for the agent

Added a unit test.

Change-Id: Ie9f30f30102bef6735dc9ed538eca9a1183c2780
Closes-Bug: #1254241
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/17/135917/1 && git format-patch -1 --stdout FETCH_HEAD,['neutronclient/neutron/v2_0/agent.py'],1,043032000ed6c0f7671d17d1f9b8cd8013226022,bug/1206110,"from neutronclient.i18n import _ """"""Updates the admin status and description for a specified agent."""""" def add_known_arguments(self, parser): parser.add_argument( '--admin-state-down', dest='admin_state', action='store_false', help=_('Set admin state up to false.')) parser.add_argument( '--description', help=_('Description for the agent.')) def args2body(self, parsed_args): body = { self.resource: { 'admin_state_up': parsed_args.admin_state, }, } neutronV20.update_dict(parsed_args, body[self.resource], ['description']) return body"," """"""Update a given agent.""""""",20,1
openstack%2Fpython-novaclient~master~I036587f355e42e362ac2b70fb6755cca81d30b75,openstack/python-novaclient,master,I036587f355e42e362ac2b70fb6755cca81d30b75,Reject non existent mock assert calls,MERGED,2014-12-12 14:11:54.000000000,2014-12-13 01:55:26.000000000,2014-12-13 01:55:24.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 9550}]","[{'number': 1, 'created': '2014-12-12 14:11:54.000000000', 'files': ['novaclient/tests/utils.py', 'novaclient/tests/v1_1/test_auth.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/ab2f1a742da217ff2de469267c4c4279ebddd4de', 'message': ""Reject non existent mock assert calls\n\nassert_called and assert_not_called are not asserting the state\nof the mock object but considered as mocked calls so mock\nwill never raise exception but always executed successfully\n\nThis change patches the Mock class during unit test\nto raise an exception if a function called on a mock object\nthat's name starts with 'assert' and does not one\nof the supported Mock assert calls.\n\nThis change also fix the unit test to call only the supported\nassert function on mock object.\n\nChange-Id: I036587f355e42e362ac2b70fb6755cca81d30b75\n""}]",0,141378,ab2f1a742da217ff2de469267c4c4279ebddd4de,9,5,1,9708,,,0,"Reject non existent mock assert calls

assert_called and assert_not_called are not asserting the state
of the mock object but considered as mocked calls so mock
will never raise exception but always executed successfully

This change patches the Mock class during unit test
to raise an exception if a function called on a mock object
that's name starts with 'assert' and does not one
of the supported Mock assert calls.

This change also fix the unit test to call only the supported
assert function on mock object.

Change-Id: I036587f355e42e362ac2b70fb6755cca81d30b75
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/78/141378/1 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/utils.py', 'novaclient/tests/v1_1/test_auth.py']",2,ab2f1a742da217ff2de469267c4c4279ebddd4de,mock_assert_called, self.assertTrue(m.called) self.assertTrue(mock_request.called) self.assertTrue(m.called), m.assert_called() mock_request.assert_called() m.assert_called(),27,3
openstack%2Fcongress-specs~master~I0ea5b275bf04b6ee1ae165bda73f7ac5b1949b05,openstack/congress-specs,master,I0ea5b275bf04b6ee1ae165bda73f7ac5b1949b05,Added vCenter_Driver spec document,MERGED,2014-12-05 19:59:35.000000000,2014-12-13 01:41:43.000000000,2014-12-13 01:41:41.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12669}, {'_account_id': 13593}]","[{'number': 1, 'created': '2014-12-05 19:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/a8ecfa48cf3d0cbbeddec11d5837d0336325db55', 'message': 'Added vCenter_Driver spec document\n\nChange-Id: I0ea5b275bf04b6ee1ae165bda73f7ac5b1949b05\n'}, {'number': 2, 'created': '2014-12-12 18:11:32.000000000', 'files': ['specs/kilo/vCenter_Driver.rst'], 'web_link': 'https://opendev.org/openstack/congress-specs/commit/ca14916675ffc9cca7cf1008ab2781859f8eab6d', 'message': 'Added vCenter_Driver spec document\n\nChange-Id: I0ea5b275bf04b6ee1ae165bda73f7ac5b1949b05\n'}]",5,139723,ca14916675ffc9cca7cf1008ab2781859f8eab6d,14,6,2,12669,,,0,"Added vCenter_Driver spec document

Change-Id: I0ea5b275bf04b6ee1ae165bda73f7ac5b1949b05
",git fetch https://review.opendev.org/openstack/congress-specs refs/changes/23/139723/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/vCenter_Driver.rst'],1,a8ecfa48cf3d0cbbeddec11d5837d0336325db55,bp/vcenter-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== vCenter Driver ========================================== https://blueprints.launchpad.net/congress/+spec/vcenter-driver This blueprint is to add a data source driver for vCenter, giving congress access to new information from an external datasource. Problem description =================== N/A Proposed change =============== Add a data source driver that integrates congress with vCenter Alternatives ------------ N/A Policy ------ This will use the congress language. vCenter:hosts(X) etc. Example - Creating a whitelist of all MAC addresses of hosts found in vCenter WhiteList(vnic_macs,pnic_macs) :- vCenter:hosts(host:vnic_mac_id,host:pnic_mac_id), vCenter:host.pnic_macs(host:pnic_mac_id,pnic_macs), vCenter:host.vnic_macs(host:vnic_mac_id,vnic_macs) Policy Actions -------------- Monitoring Hosts and Virtual Machines Data Sources ------------ vCenter Data model impact ----------------- N/A REST API impact --------------- N/A Security impact --------------- This will driver will require vCenter credentials to be input into congresses configuration, and will provide congress data by using those credentials. It will be important for those implementing this driver to be aware of what data is visible from congresses API. Notifications impact -------------------- N/A Other end user impact --------------------- N/A Performance Impact ------------------ Implementing this driver will add another data source for congress to parse data from, and since this driver pulls data from a non-openstack source this will generate additional traffic on the network. Other Deployer Impacts ---------------------- To use this driver a deployer will need to configure this driver in datasource.config. Developer Impact ---------------- N/A Implementation ============== Assignee(s) ----------- Primary assignee: Conner Ferguson Work Items ---------- N/A Dependencies ============ vconnector - Used for connecting to vCenter pyvmomi - Used for collecting data from vCenter Testing ======= TBD Documentation Impact ==================== Documentation can already be found at https://bitbucket.org/ConnerFerguson/vcenter-driver References ========== https://bitbucket.org/ConnerFerguson/vcenter-driver - Current code hosting https://github.com/vmware/pyvmomi - pyvmomi source code https://github.com/dnaeon/py-vconnector - vConnector source code ",,148,0
openstack%2Fneutron~master~Idd1324c653dcb15f5dacf2d897a7048bca22fc38,openstack/neutron,master,Idd1324c653dcb15f5dacf2d897a7048bca22fc38,Fix IPv6 RA security group rule for DVR,MERGED,2014-12-12 08:03:45.000000000,2014-12-13 01:39:12.000000000,2014-12-13 01:39:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6685}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-12 08:03:45.000000000', 'files': ['neutron/tests/unit/test_security_groups_rpc.py', 'neutron/db/securitygroups_rpc_base.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/deffbbfdfef57f740006215674a7aa54a5a1f5cc', 'message': ""Fix IPv6 RA security group rule for DVR\n\nCurrent IPv6 RA security group rule doesn't work for\nDVR because the code only allows RA from device_owner\nis network:router_interface. When DVR is enabled, the\nrouter interface is network:router_interface_distributed.\n\nThis fix fixes the RA rule to allow RA from DVR router\ninterface, so router advertisement from DVR RADVD can\npass to VM.\n\nCo-Authored-By: Baodong (Robert) Li <baoli@cisco.com>\n\nChange-Id: Idd1324c653dcb15f5dacf2d897a7048bca22fc38\nPartial-Bug: 1376325\n""}]",0,141297,deffbbfdfef57f740006215674a7aa54a5a1f5cc,46,23,1,7183,,,0,"Fix IPv6 RA security group rule for DVR

Current IPv6 RA security group rule doesn't work for
DVR because the code only allows RA from device_owner
is network:router_interface. When DVR is enabled, the
router interface is network:router_interface_distributed.

This fix fixes the RA rule to allow RA from DVR router
interface, so router advertisement from DVR RADVD can
pass to VM.

Co-Authored-By: Baodong (Robert) Li <baoli@cisco.com>

Change-Id: Idd1324c653dcb15f5dacf2d897a7048bca22fc38
Partial-Bug: 1376325
",git fetch https://review.opendev.org/openstack/neutron refs/changes/97/141297/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/securitygroups_rpc_base.py', 'neutron/tests/unit/test_security_groups_rpc.py']",2,deffbbfdfef57f740006215674a7aa54a5a1f5cc,bug/1376325," def test_security_group_ra_rules_for_devices_ipv6_dvr(self): fake_prefix = FAKE_PREFIX[const.IPv6] fake_gateway = FAKE_IP['IPv6_GLOBAL'] with self.network() as n: with contextlib.nested(self.subnet(n, gateway_ip=fake_gateway, cidr=fake_prefix, ip_version=6, ipv6_ra_mode=const.IPV6_SLAAC), self.security_group()) as (subnet_v6, sg1): sg1_id = sg1['security_group']['id'] rule1 = self._build_security_group_rule( sg1_id, 'ingress', const.PROTO_NAME_TCP, '22', '22', ethertype=const.IPv6) rules = { 'security_group_rules': [rule1['security_group_rule']]} self._make_security_group_rule(self.fmt, rules) # Create DVR router interface port gateway_res = self._make_port( self.fmt, n['network']['id'], fixed_ips=[{'subnet_id': subnet_v6['subnet']['id'], 'ip_address': fake_gateway}], device_owner=const.DEVICE_OWNER_DVR_INTERFACE) gateway_mac = gateway_res['port']['mac_address'] gateway_port_id = gateway_res['port']['id'] gateway_lla_ip = str(ipv6.get_ipv6_addr_by_EUI64( const.IPV6_LLA_PREFIX, gateway_mac)) ports_rest1 = self._make_port( self.fmt, n['network']['id'], fixed_ips=[{'subnet_id': subnet_v6['subnet']['id']}], security_groups=[sg1_id]) port_id1 = ports_rest1['port']['id'] self.rpc.devices = {port_id1: ports_rest1['port']} devices = [port_id1, 'no_exist_device'] ctx = context.get_admin_context() ports_rpc = self.rpc.security_group_rules_for_devices( ctx, devices=devices) port_rpc = ports_rpc[port_id1] expected = [{'direction': 'egress', 'ethertype': const.IPv4, 'security_group_id': sg1_id}, {'direction': 'egress', 'ethertype': const.IPv6, 'security_group_id': sg1_id}, {'direction': 'ingress', 'protocol': const.PROTO_NAME_TCP, 'ethertype': const.IPv6, 'port_range_max': 22, 'security_group_id': sg1_id, 'port_range_min': 22}, {'direction': 'ingress', 'protocol': const.PROTO_NAME_ICMP_V6, 'ethertype': const.IPv6, 'source_ip_prefix': gateway_lla_ip, 'source_port_range_min': const.ICMPV6_TYPE_RA}, ] self.assertEqual(port_rpc['security_group_rules'], expected) self._delete('ports', port_id1) # Note(xuhanp): remove gateway port's fixed_ips or gateway port # deletion will be prevented. data = {'port': {'fixed_ips': []}} req = self.new_update_request('ports', data, gateway_port_id) self.deserialize(self.fmt, req.get_response(self.api)) self._delete('ports', gateway_port_id) ",,75,2
openstack%2Fcongress~master~I03c4f723236c1b99759fa9d03f6296f4e49f98db,openstack/congress,master,I03c4f723236c1b99759fa9d03f6296f4e49f98db,Move antlr3 from the front to the back of sys.path,MERGED,2014-12-12 21:49:16.000000000,2014-12-13 01:34:45.000000000,2014-12-13 01:34:45.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 8215}, {'_account_id': 12875}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-12 21:49:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/4fa45df9cf6bc9fc4bf04fac9270b1d5d4670af0', 'message': 'Move antlr3 from the front to the back of sys.path\n\nChange-Id: I03c4f723236c1b99759fa9d03f6296f4e49f98db\n'}, {'number': 2, 'created': '2014-12-12 21:51:15.000000000', 'files': ['thirdparty/antlr3/__init__.py'], 'web_link': 'https://opendev.org/openstack/congress/commit/0e379c2efe9202f3240e6d825f634d451884d6b7', 'message': 'Move antlr3 from the front to the back of sys.path\n\nAdding antlr3 to the front of sys.path causes confusion for subsequent\nimports.  I ran into a problem where ""import extras"" imported something from\nthe antlr3 directory instead of site-packages.  Antlr3 should be at the back\nof the sys.path.\n\nChange-Id: I03c4f723236c1b99759fa9d03f6296f4e49f98db\n'}]",3,141500,0e379c2efe9202f3240e6d825f634d451884d6b7,14,5,2,12875,,,0,"Move antlr3 from the front to the back of sys.path

Adding antlr3 to the front of sys.path causes confusion for subsequent
imports.  I ran into a problem where ""import extras"" imported something from
the antlr3 directory instead of site-packages.  Antlr3 should be at the back
of the sys.path.

Change-Id: I03c4f723236c1b99759fa9d03f6296f4e49f98db
",git fetch https://review.opendev.org/openstack/congress refs/changes/00/141500/1 && git format-patch -1 --stdout FETCH_HEAD,['thirdparty/antlr3/__init__.py'],1,4fa45df9cf6bc9fc4bf04fac9270b1d5d4670af0,,sys.path.append(top_dir),"sys.path.insert(0, top_dir)",1,1
openstack%2Ffuel-docs~master~I1e484958f0f03ac3928dca095f16b4338b579bf7,openstack/fuel-docs,master,I1e484958f0f03ac3928dca095f16b4338b579bf7,VirtualBox: requires procps package on Windows/Cygwin,MERGED,2014-12-02 03:33:55.000000000,2014-12-13 01:34:01.000000000,2014-12-13 01:34:01.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9248}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 11827}]","[{'number': 1, 'created': '2014-12-02 03:33:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/c1b810ed4a9794310dc65d4696b56435f41a661f', 'message': 'VirtualBox: requires procps package on Windows/Cygwin\n\nAdd note that people running the VirtualBox version\nof MOS on Windows systems must first install the procps\npackage.\n\nThis fix is being applied to the 6.0 docs but it would\nbe nice to cherrypick it to 5.1.1 as well.\n\nChange-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7\nCloses-Bug:1380687\n'}, {'number': 2, 'created': '2014-12-03 01:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4a0143e61b5eb0e047806cc82e27bc85b13750b2', 'message': 'VirtualBox: requires procps package on Windows/Cygwin\n\nAdd procps to the list of Cygwin packages required\nto run the VirtualBox version of MOS on Windows systems.\n\nThis fix is being applied to the 6.0 docs but it would\nbe nice to cherrypick it to 5.1.1 as well.\n\nChange-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7\nCloses-Bug:1380687\n'}, {'number': 3, 'created': '2014-12-10 02:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/24036b05320135c51cbbc22057e05626f494b1b3', 'message': 'VirtualBox: requires procps package on Windows/Cygwin\n\nAdd procps to the list of Cygwin packages required\nto run the VirtualBox version of MOS on Windows systems.\n\nThis fix is being applied to the 6.0 docs but it would\nbe nice to cherrypick it to 5.1.1 as well.\n\nChange-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7\nCloses-Bug:1380687\n'}, {'number': 4, 'created': '2014-12-13 00:51:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/853e6f949f5baedefe5a023f40b74452c51bde37', 'message': 'VirtualBox: requires procps package on Windows/Cygwin\n\nAdd procps to the list of Cygwin packages required\nto run the VirtualBox version of MOS on Windows systems.\n\nThis fix is being applied to the 6.0 docs but it would\nbe nice to cherrypick it to 5.1.1 as well.\n\nChange-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7\nCloses-Bug:1380687\n'}, {'number': 5, 'created': '2014-12-13 01:28:37.000000000', 'files': ['pages/virtualbox/0300-install-virtualbox.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/58e887e80c44eaa8d55be1ee9621da6edffceeab', 'message': 'VirtualBox: requires procps package on Windows/Cygwin\n\nAdd procps to the list of Cygwin packages required\nto run the VirtualBox version of MOS on Windows systems.\n\nThis fix is being applied to the 6.0 docs but it would\nbe nice to cherrypick it to 5.1.1 as well.\n\nChange-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7\nCloses-Bug:1380687\n'}]",4,138238,58e887e80c44eaa8d55be1ee9621da6edffceeab,35,7,5,10014,,,0,"VirtualBox: requires procps package on Windows/Cygwin

Add procps to the list of Cygwin packages required
to run the VirtualBox version of MOS on Windows systems.

This fix is being applied to the 6.0 docs but it would
be nice to cherrypick it to 5.1.1 as well.

Change-Id: I1e484958f0f03ac3928dca095f16b4338b579bf7
Closes-Bug:1380687
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/38/138238/4 && git format-patch -1 --stdout FETCH_HEAD,['pages/virtualbox/0300-install-virtualbox.rst'],1,c1b810ed4a9794310dc65d4696b56435f41a661f,bug/1380687," You must also install the **procps** package, which includes the **top** and **free** commands; without this package, the *launch.sh* script fails with a message indicating that you are allocating negative memory. ",,6,0
openstack%2Fcongress~master~I446a5ace72727d1e1c8fecdc6e38ccd35d2fa599,openstack/congress,master,I446a5ace72727d1e1c8fecdc6e38ccd35d2fa599,Updated from global requirements,MERGED,2014-12-10 17:38:09.000000000,2014-12-13 01:31:23.000000000,2014-12-13 01:31:22.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-10 17:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/congress/commit/cacdcf7bac4d96388b85f26af814e8f32246be1f', 'message': 'Updated from global requirements\n\nChange-Id: I446a5ace72727d1e1c8fecdc6e38ccd35d2fa599\n'}, {'number': 2, 'created': '2014-12-12 22:22:39.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/congress/commit/cbe2070383ec22023456489069de4f72ff5152fa', 'message': 'Updated from global requirements\n\nChange-Id: I446a5ace72727d1e1c8fecdc6e38ccd35d2fa599\n'}]",0,140782,cbe2070383ec22023456489069de4f72ff5152fa,21,3,2,11131,,,0,"Updated from global requirements

Change-Id: I446a5ace72727d1e1c8fecdc6e38ccd35d2fa599
",git fetch https://review.opendev.org/openstack/congress refs/changes/82/140782/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,cacdcf7bac4d96388b85f26af814e8f32246be1f,openstack/requirements,"retrying>=1.2.3,!=1.3.0 # Apache-2.0","retrying>=1.2.2,!=1.3.0 # Apache-2.0",1,1
openstack%2Fmurano~master~Ia4082e69db3a5dcab3b5c7f79424012a8b259f05,openstack/murano,master,Ia4082e69db3a5dcab3b5c7f79424012a8b259f05,[WIP] debugging CI,ABANDONED,2014-12-12 23:34:55.000000000,2014-12-13 01:29:16.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-12 23:34:55.000000000', 'files': ['murano/tests/functional/engine/DummyTestApp/Classes/PrimaryController.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Get-DnsListeningIpAddress.ps1', 'murano/tests/functional/engine/DummyTestApp/manifest.yaml', 'murano/tests/functional/engine/DummyTestApp/UI/ui.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/JoinDomain.template', 'murano/tests/functional/engine/DummyTestApp/Resources/SetPassword.template', 'murano/tests/functional/engine/DummyTestApp/Classes/Dummy.yaml', 'murano/tests/functional/engine/base.py', 'murano/tests/functional/engine/DummyTestApp/Classes/Host.yaml', 'murano/tests/functional/engine/DummyTestApp/Classes/DomainHost.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Install-RolePrimaryDomainController.ps1', 'murano/tests/functional/engine/DummyTestApp/Resources/CreateSecondaryDC.template', 'murano/tests/functional/engine/DummyTestApp/logo2.png', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Set-LocalUserPassword.ps1', 'murano/tests/functional/engine/DummyTestApp/Classes/Controller.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/AskDnsIp.template', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/ImportCoreFunctions.ps1', 'murano/tests/functional/engine/DummyTestApp/Resources/CreatePrimaryDC.template', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Join-Domain.ps1', 'murano/tests/functional/engine/DummyTestApp/Classes/SecondaryController.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Install-RoleSecondaryDomainController.ps1'], 'web_link': 'https://opendev.org/openstack/murano/commit/24fdb0e0fb20999299155682bb78245133c85d66', 'message': '[WIP] debugging CI\n\nChange-Id: Ia4082e69db3a5dcab3b5c7f79424012a8b259f05\n'}]",0,141520,24fdb0e0fb20999299155682bb78245133c85d66,5,2,1,7600,,,0,"[WIP] debugging CI

Change-Id: Ia4082e69db3a5dcab3b5c7f79424012a8b259f05
",git fetch https://review.opendev.org/openstack/murano refs/changes/20/141520/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/tests/functional/engine/DummyTestApp/Classes/PrimaryController.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Get-DnsListeningIpAddress.ps1', 'murano/tests/functional/engine/DummyTestApp/manifest.yaml', 'murano/tests/functional/engine/DummyTestApp/UI/ui.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/JoinDomain.template', 'murano/tests/functional/engine/DummyTestApp/Resources/SetPassword.template', 'murano/tests/functional/engine/DummyTestApp/Classes/Dummy.yaml', 'murano/tests/functional/engine/base.py', 'murano/tests/functional/engine/DummyTestApp/Classes/Host.yaml', 'murano/tests/functional/engine/DummyTestApp/Classes/DomainHost.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Install-RolePrimaryDomainController.ps1', 'murano/tests/functional/engine/DummyTestApp/Resources/CreateSecondaryDC.template', 'murano/tests/functional/engine/DummyTestApp/logo2.png', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Set-LocalUserPassword.ps1', 'murano/tests/functional/engine/DummyTestApp/Classes/Controller.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/AskDnsIp.template', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/ImportCoreFunctions.ps1', 'murano/tests/functional/engine/DummyTestApp/Resources/CreatePrimaryDC.template', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Join-Domain.ps1', 'murano/tests/functional/engine/DummyTestApp/Classes/SecondaryController.yaml', 'murano/tests/functional/engine/DummyTestApp/Resources/scripts/Install-RoleSecondaryDomainController.ps1']",21,24fdb0e0fb20999299155682bb78245133c85d66,," trap { &$TrapHandler } Function Install-RoleSecondaryDomainController { <# .SYNOPSIS Install additional (secondary) domain controller. #> param ( [String] # Domain name to join to. $DomainName, [String] # Domain user who is allowed to join computer to domain. $UserName, [String] # User's password. $Password, [String] # Domain controller recovery mode password. $SafeModePassword ) begin { Show-InvocationInfo $MyInvocation } end { Show-InvocationInfo $MyInvocation -End } process { trap { &$TrapHandler } $Credential = New-Credential -UserName ""$DomainName\$UserName"" -Password $Password # Add required windows features Add-WindowsFeatureWrapper ` -Name ""DNS"",""AD-Domain-Services"",""RSAT-DFS-Mgmt-Con"" ` -IncludeManagementTools ` -NotifyRestart Write-Log ""Adding secondary domain controller ..."" $SMAP = ConvertTo-SecureString -String $SafeModePassword -AsPlainText -Force Install-ADDSDomainController ` -DomainName $DomainName ` -SafeModeAdministratorPassword $SMAP ` -Credential $Credential ` -NoRebootOnCompletion ` -Force ` -ErrorAction Stop | Out-Null Write-Log ""Waiting for restart ..."" # Stop-Execution -ExitCode 3010 -ExitString ""Computer must be restarted to finish domain controller promotion."" # Write-Log ""Restarting computer ..."" # Restart-Computer -Force } } ",,784,181
openstack%2Fpython-muranoclient~master~I52af65d954ea2ff46a012026190b21ab1bdf75d7,openstack/python-muranoclient,master,I52af65d954ea2ff46a012026190b21ab1bdf75d7,"Revert ""Add keystone v3 support to client""",MERGED,2014-12-13 00:32:45.000000000,2014-12-13 01:27:53.000000000,2014-12-13 01:27:52.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-12-13 00:32:45.000000000', 'files': ['muranoclient/shell.py', 'requirements.txt', 'muranoclient/tests/test_shell.py', 'test-requirements.txt', 'muranoclient/v1/client.py', 'muranoclient/v1/packages.py', 'muranoclient/common/http.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/7ee1c39dd6e863e027f4c7c693eb12a6f2cf8d12', 'message': 'Revert ""Add keystone v3 support to client""\n\nThis change broke package.create feature of python-muranoclient\n\nThis reverts commit 65f51420e559482224d69ce4bf30d02122f7c755.\n\nChange-Id: I52af65d954ea2ff46a012026190b21ab1bdf75d7\n'}]",0,141529,7ee1c39dd6e863e027f4c7c693eb12a6f2cf8d12,7,3,1,7225,,,0,"Revert ""Add keystone v3 support to client""

This change broke package.create feature of python-muranoclient

This reverts commit 65f51420e559482224d69ce4bf30d02122f7c755.

Change-Id: I52af65d954ea2ff46a012026190b21ab1bdf75d7
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/29/141529/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranoclient/shell.py', 'requirements.txt', 'muranoclient/tests/test_shell.py', 'muranoclient/v1/client.py', 'test-requirements.txt', 'muranoclient/v1/packages.py', 'muranoclient/common/http.py']",7,7ee1c39dd6e863e027f4c7c693eb12a6f2cf8d12,bp/support-keystone-v3,,"import keystoneclient.adapter as keystone_adapter class SessionClient(keystone_adapter.LegacyJsonAdapter): def request(self, url, method, **kwargs): raise_exc = kwargs.pop('raise_exc', True) resp, body = super(SessionClient, self).request(url, method, raise_exc=False, **kwargs) if raise_exc and resp.status_code >= 400: raise exc.from_response(resp) return resp, body def json_request(self, method, url, **kwargs): # Legacy adapter expects the payload in 'body', but # will pass it to the non-legacy adapter in the # 'json' spot so encoding happens later if 'data' in kwargs: if 'body' in kwargs: raise ValueError(""Can't provide both 'data' and "" ""'body' to a request"") kwargs['body'] = kwargs.pop('data') # The argument order is different, beware return self.request(url, method, **kwargs) def json_patch_request(self, url, method='PATCH', **kwargs): content_type = 'application/murano-packages-json-patch' return self.json_request( method, url, content_type=content_type, **kwargs) def raw_request(self, method, url, **kwargs): # A non-json request; instead of calling # super.request, need to call the grandparent # adapter.request raise_exc = kwargs.pop('raise_exc', True) if 'body' in kwargs: if 'data' in kwargs: raise ValueError(""Can't provide both 'data' and "" ""'body' to a request"") kwargs['data'] = kwargs.pop('body') resp = keystone_adapter.Adapter.request(self, url, method, raise_exc=False, **kwargs) body = resp.text if raise_exc and resp.status_code >= 400: raise exc.from_response(resp) return resp, body def _construct_http_client(*args, **kwargs): session = kwargs.pop('session', None) auth = kwargs.pop('auth', None) if session: service_type = kwargs.pop('service_type', None) endpoint_type = kwargs.pop('endpoint_type', None) region_name = kwargs.pop('region_name', None) service_name = kwargs.pop('service_name', None) return SessionClient(session=session, auth=auth, interface=endpoint_type, service_type=service_type, region_name=region_name, service_name=service_name, user_agent='python-muranoclient', **kwargs) else: return HTTPClient(*args, **kwargs)",161,304
openstack%2Fsolum~master~Id399faaa3df36902d142b6a1ec8ffacf87d2ee66,openstack/solum,master,Id399faaa3df36902d142b6a1ec8ffacf87d2ee66,Fix retry on public repos,MERGED,2014-11-21 00:10:01.000000000,2014-12-13 00:30:59.000000000,2014-12-13 00:30:57.000000000,"[{'_account_id': 3}, {'_account_id': 1375}, {'_account_id': 2506}, {'_account_id': 9095}, {'_account_id': 11324}]","[{'number': 1, 'created': '2014-11-21 00:10:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/93066a921ee2b0c1f1f58d95323bda2cf744b89d', 'message': 'Fix retry on public repos\n\nThis is because a recent change of Github API\n\nChange-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66\n'}, {'number': 2, 'created': '2014-12-01 23:50:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6553757bf7ceae3be4721f5851a6da57d94e4ab8', 'message': 'Fix retry on public repos\n\nGithub recently added auth requirement to its collaborator API.\nThis patch is for handling the change.\n\nChange-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66\n'}, {'number': 3, 'created': '2014-12-02 20:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/6992739e2f8ac4750783b9bb087a2e0572982ec1', 'message': 'Fix retry on public repos\n\nGithub recently added auth requirement to its collaborator API.\nThis patch is for handling the change.\n\nChange-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66\n'}, {'number': 4, 'created': '2014-12-02 21:11:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/solum/commit/b3bd42e0589eceb9d038061636004ba86d91e877', 'message': 'Fix retry on public repos\n\nGithub recently added auth requirement to its collaborator API.\nThis patch is for handling the change.\n\nChange-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66\n'}, {'number': 5, 'created': '2014-12-11 21:37:56.000000000', 'files': ['solum/common/exception.py', 'solum/api/controllers/v1/datamodel/plan.py', 'solum/worker/handlers/shell.py', 'solum/tests/api/controllers/v1/test_trigger.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/api/controllers/v1/trigger.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/1be2f0256e269f6ac6dde4b0f4a0fdbebf965503', 'message': 'Fix retry on public repos\n\nGithub recently added auth requirement to its collaborator API.\nThis patch is for handling the change.\n\nChange-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66\n'}]",0,136189,1be2f0256e269f6ac6dde4b0f4a0fdbebf965503,17,5,5,6662,,,0,"Fix retry on public repos

Github recently added auth requirement to its collaborator API.
This patch is for handling the change.

Change-Id: Id399faaa3df36902d142b6a1ec8ffacf87d2ee66
",git fetch https://review.opendev.org/openstack/solum refs/changes/89/136189/2 && git format-patch -1 --stdout FETCH_HEAD,"['solum/common/exception.py', 'solum/api/controllers/v1/datamodel/plan.py', 'solum/worker/handlers/shell.py', 'solum/tests/worker/handlers/test_shell.py', 'solum/tests/worker/handlers/test_shell_nobuild.py', 'solum/api/controllers/v1/trigger.py', 'solum/worker/handlers/shell_nobuild.py', 'solum/api/handlers/assembly_handler.py', 'solum/tests/api/handlers/test_assembly.py']",9,93066a921ee2b0c1f1f58d95323bda2cf744b89d,retry_github," 'repo_token': None, 'repo_token': None,"," 'status_token': None, 'status_token': None,",70,55
openstack%2Fnova-specs~master~I1e8ebb5b54eea4ee958d7ea335361203f6a867b4,openstack/nova-specs,master,I1e8ebb5b54eea4ee958d7ea335361203f6a867b4,Add support for shared volumes between guests,MERGED,2014-12-05 09:44:18.000000000,2014-12-13 00:06:04.000000000,2014-12-13 00:06:02.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2243}, {'_account_id': 2750}, {'_account_id': 4573}, {'_account_id': 5997}, {'_account_id': 9708}, {'_account_id': 10851}]","[{'number': 1, 'created': '2014-12-05 09:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/542d5da8a6c7d903f3cf69c6029336332802ef15', 'message': 'Add support for shared volumes between guests\n\nThis blueprint proposes a change to Nova to support\nattaching a cinder volume to more than one instance.\n\nChange-Id: I1e8ebb5b54eea4ee958d7ea335361203f6a867b4\nImplements: blueprint multi_attach_volume\n'}, {'number': 2, 'created': '2014-12-12 13:28:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ff467668b84a526ba682e40bed4e98d8e469d1b9', 'message': 'Add support for shared volumes between guests\n\nThis blueprint proposes a change to Nova to support\nattaching a cinder volume to more than one instance.\n\nChange-Id: I1e8ebb5b54eea4ee958d7ea335361203f6a867b4\nImplements: blueprint multi_attach_volume\n'}, {'number': 3, 'created': '2014-12-12 18:49:44.000000000', 'files': ['specs/kilo/approved/multi-attach-volume.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4de629d59d4444bbfc0c6257fec9dc96673c72a5', 'message': 'Add support for shared volumes between guests\n\nThis blueprint proposes a change to Nova to support\nattaching a cinder volume to more than one instance.\n\nChange-Id: I1e8ebb5b54eea4ee958d7ea335361203f6a867b4\nImplements: blueprint multi_attach_volume\n'}]",9,139580,4de629d59d4444bbfc0c6257fec9dc96673c72a5,28,11,3,10851,,,0,"Add support for shared volumes between guests

This blueprint proposes a change to Nova to support
attaching a cinder volume to more than one instance.

Change-Id: I1e8ebb5b54eea4ee958d7ea335361203f6a867b4
Implements: blueprint multi_attach_volume
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/80/139580/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/multi-attach-volume.rst'],1,542d5da8a6c7d903f3cf69c6029336332802ef15,bp/proposes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Support Cinder Volume Multi-attach ========================================== https://blueprints.launchpad.net/nova/+spec/multi-attach-volume Currently, Cinder only allows a volume to be attached to a single host or instance. There are times when a user may want to be able to attach the same volume to multiple instances. Problem description =================== Currently, Cinder only allows a volume to be attached to one instance and or host at a time. Nova makes an assumption in a number of places that assumes the limitation of a single volume to a single instance. * cinderclient only has volume as a parameter to the detach() call. This makes the assumption that a volume is only attached once. * nova assumes that if a volume is attached, it can't be attached again. see nova/volume/cinder.py: check_attach() Use Cases --------- Allow users to share volumes between multiple guests using either read-write or read-only attachments. Project Priority ---------------- - Proposed change =============== The Changes needed in Nova are related to attach time and detach time. At attach time, nova has to remove the assumption that it can only attach a volume if it's not 'in-use'. A Cinder volume can now be attached if it's 'available' and/or 'in-use'. Cinder will only allow a volume to be attached more than once if it's 'shareable' flag is set on the volume at create time. At detach time, nova needs to pass a new parameter to the cinderclient to tell cinder which specific attachment it's requesting cinder to detach. Since a volume can be attached to an instance and/or a host, a new attachment uuid is added at detach time. Passing only an instance uuid is insufficient. The attachment_id will be optional in the cinderclient. If it isn't passed in and there are multiple attachments, then cinder will fail because it won't know which attachment to detach. Alternatives ------------ The only alternative is for a user to clone a volume and attach the clone to the second instance. The downside to this is any changes to the original volume don't show up in the mounted clone. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- The command line will now allow you to call nova volume-attach for a volume to multiple instances. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Any time new code is added to Nova that requires a call to detach a volume, the developer must get the volume attachment uuid for the instance. This information is embedded in the cinder volume volume_attachments list. Implementation ============== Based on the work from Walter Boring and Charlie Zhou. Agreed with Walter to start the work again. Assignee(s) ----------- Primary assignee: Tobias Engelbert Work Items ---------- 1. Update the use of cinderclient to extract the new list of volume attachments when Nova fetches a volume. 2. Update all calls to cinderclient.detach() to include the attachment uuid. Dependencies ============ * This requires a new version of the python-cinderclient. The changes in the client include the new detach API. https://blueprints.launchpad.net/python-cinderclient/+spec/multi-attach-volume * This also requires a patch in cinder to support the ability to attach to multiple instances. https://blueprints.launchpad.net/cinder/+spec/multi-attach-volume Testing ======= We'll have to add new Tempest tests to support the new Cinder volume shareable flag. The new cinder shareable flag is what allows a volume to be attached more than once or not. Have to look into a tempest test for attaching the same volume to multiple instances. Documentation Impact ==================== We will have to update the docs to discuss the new ability to attach a volume to multiple instances if the cinder shareable flag is set on a volume. References ========== * This is the cinder wiki page that discusses the approach to multi-attach https://wiki.openstack.org/wiki/Cinder/blueprints/multi-attach-volume ",,163,0
openstack%2Fhorizon~master~If09072f0f4bef4047b14b9be474ddb1169158029,openstack/horizon,master,If09072f0f4bef4047b14b9be474ddb1169158029,Updated from global requirements,MERGED,2014-12-12 22:14:53.000000000,2014-12-13 00:02:14.000000000,2014-12-13 00:02:13.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 9576}, {'_account_id': 9981}]","[{'number': 1, 'created': '2014-12-12 22:14:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/horizon/commit/d685888a3f1a6c763c5334bf78d1d2044c7f1e87', 'message': 'Updated from global requirements\n\nChange-Id: If09072f0f4bef4047b14b9be474ddb1169158029\n'}]",0,141506,d685888a3f1a6c763c5334bf78d1d2044c7f1e87,8,4,1,11131,,,0,"Updated from global requirements

Change-Id: If09072f0f4bef4047b14b9be474ddb1169158029
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/141506/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,d685888a3f1a6c763c5334bf78d1d2044c7f1e87,openstack/requirements,python-glanceclient>=0.15.0,python-glanceclient>=0.14.0,1,1
openstack%2Fneutron~master~If242b04b372609f640f3ce88f4245c17a45bf69d,openstack/neutron,master,If242b04b372609f640f3ce88f4245c17a45bf69d,Catch duplicate errors scheduling SNAT service,MERGED,2014-10-16 09:15:06.000000000,2014-12-12 23:59:11.000000000,2014-12-12 23:59:09.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 6854}, {'_account_id': 7787}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10192}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10503}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-10-16 09:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9e94842412425df9330f9f5dbc001ef65399435d', 'message': 'Catch duplicate errors scheduling SNAT service\n\nCatch DBDuplicateEntry errors when scheduling SNAT to\na service node to prevent harmless tracebacks in the log.\nThese can occur if scheduling occurs concurrently,\nso they are safe to ignore.\n\nCloses-Bug: #1381958\nChange-Id: If242b04b372609f640f3ce88f4245c17a45bf69d\n'}, {'number': 2, 'created': '2014-12-05 22:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/70eb10e61da19d747375a1482191f72a9999c421', 'message': 'Catch duplicate errors scheduling SNAT service\n\nCatch DBDuplicateEntry errors when scheduling SNAT to\na service node to prevent harmless tracebacks in the log.\nThese can occur if scheduling occurs concurrently,\nso they are safe to ignore.\n\nCloses-Bug: #1381958\nChange-Id: If242b04b372609f640f3ce88f4245c17a45bf69d\n'}, {'number': 3, 'created': '2014-12-12 00:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee359846b5a6eb32bcffb9e412be7257a6a54c8f', 'message': 'Catch duplicate errors scheduling SNAT service\n\nCatch DBDuplicateEntry errors when scheduling SNAT to\na service node to prevent harmless tracebacks in the log.\nThese can occur if scheduling occurs concurrently,\nso they are safe to ignore.\n\nCloses-Bug: #1381958\nChange-Id: If242b04b372609f640f3ce88f4245c17a45bf69d\n'}, {'number': 4, 'created': '2014-12-12 01:06:09.000000000', 'files': ['neutron/db/l3_dvrscheduler_db.py', 'neutron/tests/unit/test_l3_schedulers.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/a93abbbfef7f0b88be0ad42048d52b658c29e1c4', 'message': 'Catch duplicate errors scheduling SNAT service\n\nCatch DBDuplicateEntry errors when scheduling SNAT to\na service node to prevent harmless tracebacks in the log.\nThese can occur if scheduling occurs concurrently,\nso they are safe to ignore.\n\nCloses-Bug: #1381958\nChange-Id: If242b04b372609f640f3ce88f4245c17a45bf69d\n'}]",4,128857,a93abbbfef7f0b88be0ad42048d52b658c29e1c4,101,32,4,7787,,,0,"Catch duplicate errors scheduling SNAT service

Catch DBDuplicateEntry errors when scheduling SNAT to
a service node to prevent harmless tracebacks in the log.
These can occur if scheduling occurs concurrently,
so they are safe to ignore.

Closes-Bug: #1381958
Change-Id: If242b04b372609f640f3ce88f4245c17a45bf69d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/57/128857/4 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_dvrscheduler_db.py'],1,9e94842412425df9330f9f5dbc001ef65399435d,bug/1381958,"from oslo.db import exception as db_excfrom neutron.openstack.common.gettextutils import _LI try: chosen_agent = self.bind_snat_servicenode( context, router_id, snat_candidates) except db_exc.DBDuplicateEntry: LOG.info(_LI(""SNAT already bound to a service node."")) return"," chosen_agent = self.bind_snat_servicenode( context, router_id, snat_candidates)",8,2
openstack%2Fhorizon~master~I6f29e673f7ecf0316e855a3c0c0176d3c081491c,openstack/horizon,master,I6f29e673f7ecf0316e855a3c0c0176d3c081491c,"Fixes the Order of ""launch"" buttons on jobs panel",MERGED,2014-12-10 15:29:33.000000000,2014-12-12 23:53:59.000000000,2014-12-12 23:53:57.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6914}, {'_account_id': 12355}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-12-10 15:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/597de8f771870ddd1fb8e0b88a665663cae509a4', 'message': 'Fixes the Order of ""launch"" buttons on jobs panel\n\nOn the data processing/jobs panel, the first ""launch"" button is ""Launch\non New Cluster"". This patch make the  ""Launch on Existing Cluster"" as\nthe first button. ""Launch on New Cluster"" is moved down on the list.\n\nAlso when ""Launch On Existing Cluster"" becomes the default option, the\n""down arrow"" to expand the action choices wraps down to the next line.\nSo added css to fix this issue.\n\nChange-Id: I6f29e673f7ecf0316e855a3c0c0176d3c081491c\nCloses-bug: #139036\n'}, {'number': 2, 'created': '2014-12-10 17:07:39.000000000', 'files': ['openstack_dashboard/dashboards/project/data_processing/jobs/tables.py', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/jobs.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/b5f53d679b41e2218112f2f62beb00b23f51a632', 'message': 'Fixes the Order of ""launch"" buttons on jobs panel\n\nOn the data processing/jobs panel, the first ""launch"" button is ""Launch\non New Cluster"". This patch make the  ""Launch on Existing Cluster"" as\nthe first button. ""Launch on New Cluster"" is moved down on the list.\n\nAlso when ""Launch On Existing Cluster"" becomes the default option, the\n""down arrow"" to expand the action choices wraps down to the next line.\nSo added css to fix this issue.\n\nChange-Id: I6f29e673f7ecf0316e855a3c0c0176d3c081491c\nCloses-bug: #1390362\n'}]",0,140734,b5f53d679b41e2218112f2f62beb00b23f51a632,12,5,2,11599,,,0,"Fixes the Order of ""launch"" buttons on jobs panel

On the data processing/jobs panel, the first ""launch"" button is ""Launch
on New Cluster"". This patch make the  ""Launch on Existing Cluster"" as
the first button. ""Launch on New Cluster"" is moved down on the list.

Also when ""Launch On Existing Cluster"" becomes the default option, the
""down arrow"" to expand the action choices wraps down to the next line.
So added css to fix this issue.

Change-Id: I6f29e673f7ecf0316e855a3c0c0176d3c081491c
Closes-bug: #1390362
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/140734/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/project/data_processing/jobs/tables.py', 'openstack_dashboard/dashboards/project/data_processing/jobs/templates/data_processing.jobs/jobs.html']",2,597de8f771870ddd1fb8e0b88a665663cae509a4,bugs/#139036_2data_processing, .actions_column { width: 210px !important; },,3,1
openstack%2Fdevstack~master~Idbbc43bf74ff5fff3d50f3494148454bb51e378f,openstack/devstack,master,Idbbc43bf74ff5fff3d50f3494148454bb51e378f,Poll resource tracker for ironic cpus as well as count,MERGED,2014-12-09 22:49:12.000000000,2014-12-12 23:52:50.000000000,2014-12-12 23:52:48.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1420}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 22:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7a7b3c62807783da49c9830ef6dfc88318543f3a', 'message': 'Poll resource tracker for ironic cpus as well as count\n\nWhen ironic nodes are enrolled, their resources are not available\nto the nova scheduler until after a round of ironic and nova periodic\ntasks have run  In addition to waiting for ironic nodes to show up in\nthe resource tracker, also wait for associated CPU resources.  In\nthe worst case, this means waiting for 3 total rounds of periodic\ntasks.\n\nChange-Id: Idbbc43bf74ff5fff3d50f3494148454bb51e378f\nCloses-bug: #1398128\n'}, {'number': 2, 'created': '2014-12-10 21:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/55db4df84449a08eaa9878ddba775a58e8b45217', 'message': 'Poll resource tracker for ironic cpus as well as count\n\nWhen ironic nodes are enrolled, their resources are not available\nto the nova scheduler until after a round of ironic and nova periodic\ntasks have run  In addition to waiting for ironic nodes to show up in\nthe resource tracker, also wait for associated CPU resources.  In\nthe worst case, this means waiting for 3 total rounds of periodic\ntasks.\n\nChange-Id: Idbbc43bf74ff5fff3d50f3494148454bb51e378f\nCloses-bug: #1398128\n'}, {'number': 3, 'created': '2014-12-11 01:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/82ebfc6ea61ae2529107a9f9e3e783c42207b316', 'message': 'Poll resource tracker for ironic cpus as well as count\n\nWhen ironic nodes are enrolled, their resources are not available\nto the nova scheduler until after a round of ironic and nova periodic\ntasks have run  In addition to waiting for ironic nodes to show up in\nthe resource tracker, also wait for associated CPU resources.  In\nthe worst case, this means waiting for 3 total rounds of periodic\ntasks.\n\nChange-Id: Idbbc43bf74ff5fff3d50f3494148454bb51e378f\nCloses-bug: #1398128\n'}, {'number': 4, 'created': '2014-12-11 20:43:04.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0c99e2f65b6e86236c0d29928c110628f1e32f3d', 'message': 'Poll resource tracker for ironic cpus as well as count\n\nWhen ironic nodes are enrolled, their resources are not available\nto the nova scheduler until after a round of ironic and nova periodic\ntasks have run  In addition to waiting for ironic nodes to show up in\nthe resource tracker, also wait for associated CPU resources.  In\nthe worst case, this means waiting for 3 total rounds of periodic\ntasks.\n\nChange-Id: Idbbc43bf74ff5fff3d50f3494148454bb51e378f\nCloses-bug: #1398128\n'}]",2,140512,0c99e2f65b6e86236c0d29928c110628f1e32f3d,26,8,4,1420,,,0,"Poll resource tracker for ironic cpus as well as count

When ironic nodes are enrolled, their resources are not available
to the nova scheduler until after a round of ironic and nova periodic
tasks have run  In addition to waiting for ironic nodes to show up in
the resource tracker, also wait for associated CPU resources.  In
the worst case, this means waiting for 3 total rounds of periodic
tasks.

Change-Id: Idbbc43bf74ff5fff3d50f3494148454bb51e378f
Closes-bug: #1398128
",git fetch https://review.opendev.org/openstack/devstack refs/changes/12/140512/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,7a7b3c62807783da49c9830ef6dfc88318543f3a,ir_poll_nova," # After nodes have been enrolled, we need to wait for both ironic and # nova's periodic tasks to populate the resource tracker with available # nodes and resources. Wait up to 2 minutes for a given resource before # timing out. local resource=$1 local expected_count=$2 echo_summary ""Waiting 2 minutes for Nova resource tracker to pick up $resource >= $expected_count"" if [ $(nova hypervisor-stats | grep "" $1 "" | get_field 2) -ge $expected_count ]; then local total_cpus=0 total_cpus=$((total_cpus+$ironic_node_cpu)) wait_for_nova_resources ""count"" $total_nodes wait_for_nova_resources ""vcpus"" $total_cpus"," # After nodes have been enrolled, we need to wait for n-cpu's periodic # task populate the resource tracker with available nodes. Wait for 2 # minutes before timing out. local expected_count=$1 echo_summary ""Waiting 2 minutes for Nova resource tracker to pick up $expected_count Ironic nodes"" if [ $(nova hypervisor-stats | grep "" count "" | get_field 2) -ge $expected_count ]; then wait_for_nova_resources $total_nodes",12,7
openstack%2Fzaqar~master~Iff42e3b775ed63661bc69fc1925242ff0e574e46,openstack/zaqar,master,Iff42e3b775ed63661bc69fc1925242ff0e574e46,Wrap abstract method with base methods,MERGED,2014-12-04 14:39:31.000000000,2014-12-12 23:30:28.000000000,2014-12-12 23:30:27.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2014-12-04 14:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/b98f0fd63591dc1f55648efafb1f00d56f2efe0a', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}, {'number': 2, 'created': '2014-12-09 09:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/5faa495c32218b4f9fc65f24d3274f857372544a', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}, {'number': 3, 'created': '2014-12-09 10:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cff05a1a973b5aaf80d6e3c9a122a262a07ef51a', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}, {'number': 4, 'created': '2014-12-09 12:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/8b4b1ae2dd0e936468670496fe4f11bd0100b1fb', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}, {'number': 5, 'created': '2014-12-11 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/03758703a6aea9a943401b2ee303c832ad4d132c', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}, {'number': 6, 'created': '2014-12-12 14:06:54.000000000', 'files': ['zaqar/storage/redis/queues.py', 'zaqar/tests/faulty_storage.py', 'zaqar/storage/sqlalchemy/queues.py', 'zaqar/storage/base.py', 'zaqar/storage/mongodb/queues.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/6ae5372629fd6f51725416477ad8505451d18b63', 'message': 'Wrap abstract method with base methods\n\nIn order to be able to move some validations and general checks, that are\ncurrently done in the transport, down to the storage layer, we need to\nwrap the methods being overloaded with other methods that are defined in\nthe base class. This will allow us to add logic before and after the\nactual method call if needed.\n\nThis is the first patch of a series of patches that will update all the\nstorage controllers.\n\nPartial-blueprint: expose-storage-capabilities\nChange-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46\n'}]",0,139073,6ae5372629fd6f51725416477ad8505451d18b63,19,4,6,6159,,,0,"Wrap abstract method with base methods

In order to be able to move some validations and general checks, that are
currently done in the transport, down to the storage layer, we need to
wrap the methods being overloaded with other methods that are defined in
the base class. This will allow us to add logic before and after the
actual method call if needed.

This is the first patch of a series of patches that will update all the
storage controllers.

Partial-blueprint: expose-storage-capabilities
Change-Id: Iff42e3b775ed63661bc69fc1925242ff0e574e46
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/73/139073/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/queues/storage/sqlalchemy/queues.py', 'zaqar/queues/storage/base.py', 'zaqar/tests/faulty_storage.py', 'zaqar/queues/storage/redis/queues.py', 'zaqar/queues/storage/utils.py', 'zaqar/queues/storage/mongodb/queues.py']",6,b98f0fd63591dc1f55648efafb1f00d56f2efe0a,bp/expose-storage-capabilities," def _get(self, name, project=None): def _list(self, project=None, marker=None, def _create(self, name, metadata=None, project=None): def _exists(self, name, project=None): @_exists.purges def _delete(self, name, project=None): def _stats(self, name, project=None):"," def get(self, name, project=None): def list(self, project=None, marker=None, def create(self, name, metadata=None, project=None): def exists(self, name, project=None): @exists.purges def delete(self, name, project=None): def stats(self, name, project=None):",70,55
openstack%2Ffuel-docs~master~I022dc1b09c97385ea375688ef0890d054d7f4f99,openstack/fuel-docs,master,I022dc1b09c97385ea375688ef0890d054d7f4f99,Clarify choice between qcow2 and raw for image storage,MERGED,2014-11-08 01:32:53.000000000,2014-12-12 23:18:45.000000000,2014-12-12 23:18:44.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 12866}, {'_account_id': 14046}]","[{'number': 1, 'created': '2014-11-08 01:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/4a370505a9ed980e6cdff12893d7afad866d46c1', 'message': 'Clarify choice between qcow2 and raw for image storage\n\nMore work is being done in https://review.openstack.org/#/c/125592/\n\nChange-Id: I022dc1b09c97385ea375688ef0890d054d7f4f99\nPartial-Bug: 1375899\n'}, {'number': 2, 'created': '2014-11-27 09:48:26.000000000', 'files': ['pages/terminology/allterms.rst', 'pages/user-guide/config-environment/settings/3400-qcow.rst', 'pages/terminology/q/qcow2.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/d674907c0eac78c5b9c38a3f6d567e84244ff9de', 'message': 'Clarify choice between qcow2 and raw for image storage\n\nMore work is being done in https://review.openstack.org/#/c/125592/\n\nChange-Id: I022dc1b09c97385ea375688ef0890d054d7f4f99\nPartial-Bug: 1375899\n'}]",5,133323,d674907c0eac78c5b9c38a3f6d567e84244ff9de,22,7,2,10014,,,0,"Clarify choice between qcow2 and raw for image storage

More work is being done in https://review.openstack.org/#/c/125592/

Change-Id: I022dc1b09c97385ea375688ef0890d054d7f4f99
Partial-Bug: 1375899
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/23/133323/1 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/allterms.rst', 'pages/user-guide/config-environment/settings/3400-qcow.rst', 'pages/terminology/q/qcow2.rst']",3,4a370505a9ed980e6cdff12893d7afad866d46c1,bug/1375899," .. _qcow2-term: qcow2 ----- qcow2 (QEMU Copy-on-Write) is one of the file formats Fuel supports for Glance image storage and ephemeral volumes. You can set the file format to use for images on the :ref:`qcow-format-ug` screen. - When using :ref:`Swift<swift-object-storage-term>` as the storage backend, qcow2 is the recommended format for storage images. It provides copy-on-write and snapshot functionality for Swift. - When using :ref:`Ceph<ceph-term>` as the storage backend for Cinder, you must disable qcow2 so that images are stored in raw format. Ceph includes its own mechanisms that provide copy-on-write capabilities and snapshots; if you use the qcow2 image format with Ceph, images must be converted to raw format in order to be cloned. ",,31,11
openstack%2Fdevstack~master~I6f22e0f86ae071d30bf69de9ed5dec6b28ebc92b,openstack/devstack,master,I6f22e0f86ae071d30bf69de9ed5dec6b28ebc92b,XenAPI: Simplify installed packages,MERGED,2014-12-10 10:35:00.000000000,2014-12-12 23:03:25.000000000,2014-12-12 23:03:24.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 5044}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 10:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/62e34da00f5159ba4256f8947d8bef1081540733', 'message': ""XenAPI: Simplify installed packages\n\nRemove duplicate packages.\npip is handled by devstack, so don't try and install it here.\n\nChange-Id: I6f22e0f86ae071d30bf69de9ed5dec6b28ebc92b\n""}, {'number': 2, 'created': '2014-12-12 13:14:57.000000000', 'files': ['lib/nova_plugins/hypervisor-xenserver', 'tools/xen/prepare_guest.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/be485221b321ebb418f3f5dd8d86e164797f07de', 'message': ""XenAPI: Simplify installed packages\n\nRemove duplicate packages.\npip is handled by devstack, so don't try and install it here.\n\nChange-Id: I6f22e0f86ae071d30bf69de9ed5dec6b28ebc92b\n""}]",1,140634,be485221b321ebb418f3f5dd8d86e164797f07de,13,6,2,6735,,,0,"XenAPI: Simplify installed packages

Remove duplicate packages.
pip is handled by devstack, so don't try and install it here.

Change-Id: I6f22e0f86ae071d30bf69de9ed5dec6b28ebc92b
",git fetch https://review.opendev.org/openstack/devstack refs/changes/34/140634/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/nova_plugins/hypervisor-xenserver', 'tools/xen/prepare_guest.sh']",2,62e34da00f5159ba4256f8947d8bef1081540733,,apt-get install -y git sudo python-netaddr coreutils,apt-get install -y curl wget ssh openssh-server python-pip git sudo python-netaddr apt-get install -y coreutils pip install xenapi,2,5
openstack%2Fdevstack~master~Ic79fd003aea2af7b258397ec2cdfd70c8568743c,openstack/devstack,master,Ic79fd003aea2af7b258397ec2cdfd70c8568743c,Generate an IPv6 address when PUBLIC_BRIDGE does not have one,MERGED,2014-12-09 19:26:39.000000000,2014-12-12 23:03:22.000000000,2014-12-12 23:03:21.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1131}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 9008}, {'_account_id': 9382}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 19:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a425959d3afbc9803e13f1c4579e33cf1aa798a0', 'message': 'Generate an IPv6 address when PUBLIC_BRIDGE does not have one\n\nCloses-Bug: #1400823\nChange-Id: Ic79fd003aea2af7b258397ec2cdfd70c8568743c\n'}, {'number': 2, 'created': '2014-12-09 20:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/328a63cb0a3a83b78bea53fb7872333ba61cd925', 'message': 'Generate an IPv6 address when PUBLIC_BRIDGE does not have one\n\nCloses-Bug: #1400823\nChange-Id: Ic79fd003aea2af7b258397ec2cdfd70c8568743c\n'}, {'number': 3, 'created': '2014-12-09 20:17:56.000000000', 'files': ['lib/neutron'], 'web_link': 'https://opendev.org/openstack/devstack/commit/fc094655080955f7bfcb628b544d131145830b67', 'message': 'Generate an IPv6 address when PUBLIC_BRIDGE does not have one\n\nCloses-Bug: #1400823\nChange-Id: Ic79fd003aea2af7b258397ec2cdfd70c8568743c\n'}]",2,140449,fc094655080955f7bfcb628b544d131145830b67,20,10,3,4656,,,0,"Generate an IPv6 address when PUBLIC_BRIDGE does not have one

Closes-Bug: #1400823
Change-Id: Ic79fd003aea2af7b258397ec2cdfd70c8568743c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/49/140449/3 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron'],1,a425959d3afbc9803e13f1c4579e33cf1aa798a0,bug/1400823," if ! ip -6 addr show dev $PUBLIC_BRIDGE | grep 'scope global'; then # Create an IPv6 ULA address for PUBLIC_BRIDGE if one is not present IPV6_BRIDGE_ULA=`uuidgen | sed s/-//g | cut -c 23- | sed -e ""s/\(..\)\(....\)\(....\)/\1:\2:\3/""` sudo ip -6 addr add fd$IPV6_BRIDGE_ULA::1 dev $PUBLIC_BRIDGE fi ",,6,0
openstack%2Fdevstack~master~I43a231c9611b4cc2e390b603aa3bfb49c915bdc5,openstack/devstack,master,I43a231c9611b4cc2e390b603aa3bfb49c915bdc5,Take an optional rabbit user name as input,MERGED,2014-12-11 20:50:15.000000000,2014-12-12 23:03:18.000000000,2014-12-12 23:03:16.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1082}, {'_account_id': 2750}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 20:50:15.000000000', 'files': ['lib/nova', 'lib/keystone', 'lib/rpc_backend', 'lib/trove', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d5b74c688febfafb69ddc3881d9936e0268daa4c', 'message': ""Take an optional rabbit user name as input\n\nNewer versions of rabbitmq (3.3 and later) do not allow the 'guest'\nuser to access on non-local interfaces.\n\n- Added a new config RABBIT_USERID which defaults to stackrabbit\n- Invoked config scripts using that variable\n\nAdopted from:\nhttps://review.openstack.org/#/c/107779/\n\nChange-Id: I43a231c9611b4cc2e390b603aa3bfb49c915bdc5\nCloses-Bug: #1343354\nCo-Authored-By: Scott Moser <smoser@ubuntu.com>\n""}]",0,141156,d5b74c688febfafb69ddc3881d9936e0268daa4c,8,7,1,7770,,,0,"Take an optional rabbit user name as input

Newer versions of rabbitmq (3.3 and later) do not allow the 'guest'
user to access on non-local interfaces.

- Added a new config RABBIT_USERID which defaults to stackrabbit
- Invoked config scripts using that variable

Adopted from:
https://review.openstack.org/#/c/107779/

Change-Id: I43a231c9611b4cc2e390b603aa3bfb49c915bdc5
Closes-Bug: #1343354
Co-Authored-By: Scott Moser <smoser@ubuntu.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/141156/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/nova', 'lib/keystone', 'lib/rpc_backend', 'lib/trove', 'stack.sh']",5,d5b74c688febfafb69ddc3881d9936e0268daa4c,bug/1343354, RABBIT_USERID=${RABBIT_USERID:-stackrabbit},,31,5
openstack%2Fkeystone~master~Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0,openstack/keystone,master,Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0,Cleanup eventlet use in tests,MERGED,2014-12-10 20:58:32.000000000,2014-12-12 23:02:21.000000000,2014-12-12 23:02:19.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 6486}, {'_account_id': 9142}]","[{'number': 1, 'created': '2014-12-10 20:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f6f56cbc789712cea0d007fbb47916408c7280b2', 'message': ""Cleanup to stop server in test_wsgi\n\nThe tests in test_wsgi should stop the server once the test is over,\notherwise it would continue running and potentially affect other\ntests.\n\nAlso, the setUp did environment.use_eventlet(), which has no effect\nsince this was already done in keystone.tests.core, and it's\nincorrect to put this in a test setUp since it would affect other\ntests.\n\nChange-Id: Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0\n""}, {'number': 2, 'created': '2014-12-10 21:21:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/16d4bc8b528b785ef0a7785ec2a4ded73d4db944', 'message': ""Cleanup eventlet use in tests\n\nThe tests in test_wsgi should stop the server once the test is over,\notherwise it would continue running and potentially affect other\ntests.\n\nAlso, there were a couple of tests that did\nenvironment.use_eventlet() in setUp, which has no effect since this\nwas already done in keystone.tests.core, and it's incorrect to put\nthis in a test setUp since it would affect other tests as it's an\napplication-wide library setting.\n\nChange-Id: Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0\n""}, {'number': 3, 'created': '2014-12-12 14:27:27.000000000', 'files': ['keystone/tests/test_auth.py', 'keystone/tests/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/20b272a7b47dd14eae106557462e6692c0a0bf41', 'message': ""Cleanup eventlet use in tests\n\nThe tests in test_wsgi should stop the server once the test is over,\notherwise it would continue running and potentially affect other\ntests.\n\nAlso, there were a couple of tests that did\nenvironment.use_eventlet() in setUp, which has no effect since this\nwas already done in keystone.tests.core, and it's incorrect to put\nthis in a test setUp since it would affect other tests as it's an\napplication-wide library setting.\n\nCloses-Bug: #1400565\nChange-Id: Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0\n""}]",0,140835,20b272a7b47dd14eae106557462e6692c0a0bf41,17,6,3,6486,,,0,"Cleanup eventlet use in tests

The tests in test_wsgi should stop the server once the test is over,
otherwise it would continue running and potentially affect other
tests.

Also, there were a couple of tests that did
environment.use_eventlet() in setUp, which has no effect since this
was already done in keystone.tests.core, and it's incorrect to put
this in a test setUp since it would affect other tests as it's an
application-wide library setting.

Closes-Bug: #1400565
Change-Id: Ibb00a1afa64cf46aaa0eafaca895bcf7a1f69eb0
",git fetch https://review.opendev.org/openstack/keystone refs/changes/35/140835/3 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/test_wsgi.py'],1,f6f56cbc789712cea0d007fbb47916408c7280b2,bug/1400565, self.addCleanup(server.stop) self.addCleanup(server.stop) self.addCleanup(server.stop), environment.use_eventlet(),3,1
openstack%2Fzaqar~master~I413b30b14ea605a7b3f22d6a51059a601af71e76,openstack/zaqar,master,I413b30b14ea605a7b3f22d6a51059a601af71e76,Split Control and Data planes of Storage layer,MERGED,2014-11-17 11:37:03.000000000,2014-12-12 22:59:47.000000000,2014-12-12 22:59:47.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6427}, {'_account_id': 13227}]","[{'number': 1, 'created': '2014-11-17 11:37:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ebf92a7342870cd358e0bd59616039c4e1a63ea8', 'message': 'Split Control and Data planes of Storage layer\n\nTask one - Create separate group options is in progress.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 2, 'created': '2014-11-17 17:04:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cb59f215a91a4e19d5e2ef94f9d1e5ad5fb52ca3', 'message': 'Split Control and Data planes of Storage layer\n\nTask one - Create separate group options is in progress.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 3, 'created': '2014-11-18 19:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/9a37bf885a6b66ee876f841b63e6b9e7928ad172', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 4, 'created': '2014-11-24 12:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0b940c5ff78a58d288f0bff744be9c2e9f99428e', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nAnd modified test cases.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 5, 'created': '2014-11-25 13:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/e6858797c0e4aaf9ade2ee4f456396ce93db7086', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nAnd modified test cases.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 6, 'created': '2014-11-26 11:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/d1bf3f33bd5b6de6f73a7abce192b0347a3fc604', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nAnd modified test cases.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 7, 'created': '2014-11-28 21:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/96d14038db617d818ea9cb08c5724536ff0c56b9', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nAnd modified test cases.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 8, 'created': '2014-11-28 21:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/315bbe8fa3f53bd520a37d1fd710799a7846c374', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nAnd modified test cases.\nFirst focusing only on Mongodb.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 9, 'created': '2014-12-08 13:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/3b388856193668dd7296771eed9f83b667c3155b', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nModified drivers modules and many test cases.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 10, 'created': '2014-12-09 21:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/eda136b046263a42eb61b6ba25b29c9b81953af2', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nModified drivers modules and many test cases.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}, {'number': 11, 'created': '2014-12-11 17:07:13.000000000', 'files': ['zaqar/storage/sqlalchemy/driver.py', 'zaqar/storage/redis/options.py', 'tests/etc/wsgi_mongodb_pooled.conf', 'tests/unit/queues/storage/test_impl_redis.py', 'zaqar/tests/queues/transport/wsgi/v1/test_messages.py', 'tests/unit/queues/storage/test_impl_mongodb.py', 'tests/etc/wsgi_mongodb.conf', 'zaqar/storage/mongodb/driver.py', 'zaqar/tests/queues/transport/wsgi/v1_1/test_messages.py', 'zaqar/storage/utils.py', 'tests/etc/wsgi_redis.conf', 'tests/etc/wsgi_redis_pooled.conf', 'zaqar/storage/sqlalchemy/options.py', 'zaqar/storage/mongodb/options.py', 'zaqar/storage/redis/driver.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/44ceb3d3923f7f7a915068027a818c1951410430', 'message': 'Split Control and Data planes of Storage layer\n\nTo split Data/Control planes first separate groups for options are created.\nAccordingly registered data and control plane options in the new group.\nModified drivers modules and many test cases.\n\nChange-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76\n'}]",7,134910,44ceb3d3923f7f7a915068027a818c1951410430,39,5,11,13227,,,0,"Split Control and Data planes of Storage layer

To split Data/Control planes first separate groups for options are created.
Accordingly registered data and control plane options in the new group.
Modified drivers modules and many test cases.

Change-Id: I413b30b14ea605a7b3f22d6a51059a601af71e76
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/10/134910/3 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/queues/storage/mongodb/options.py'],1,ebf92a7342870cd358e0bd59616039c4e1a63ea8,split-zaqar,"COMMON_OPTIONS = (MANAGEMENT_MONGODB_OPTIONS = COMMON_OPTIONS MESSAGE_MONGODB_OPTIONS = COMMON_OPTIONS + ( # options used only by message_storage cfg.IntOpt('partitions', default=2, help=('Number of databases across which to ' 'partition message data, in order to ' 'reduce writer lock %. DO NOT change ' 'this setting after initial deployment. ' 'It MUST remain static. Also, you ' 'should not need a large number of partitions ' 'to improve performance, esp. if deploying ' 'MongoDB on SSD storage.')), ) MANAGEMENT_MONGODB_GROUP = 'drivers:management_store:mongodb' MESSAGE_MONGODB_GROUP = 'drivers:message_store:mongodb' return [(MANAGEMENT_MONGODB_GROUP, MANAGEMENT_MONGODB_OPTIONS), (MESSAGE_MONGODB_GROUP, MESSAGE_MONGODB_OPTIONS)]","MONGODB_OPTIONS = ( cfg.IntOpt('partitions', default=2, help=('Number of databases across which to ' 'partition message data, in order to ' 'reduce writer lock %. DO NOT change ' 'this setting after initial deployment. ' 'It MUST remain static. Also, you ' 'should not need a large number of partitions ' 'to improve performance, esp. if deploying ' 'MongoDB on SSD storage.')), MONGODB_GROUP = 'drivers:storage:mongodb' return [(MONGODB_GROUP, MONGODB_OPTIONS)]",19,13
openstack%2Fzaqar~master~I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef,openstack/zaqar,master,I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef,Add capabilities property to the DataDriver,MERGED,2014-11-19 16:25:27.000000000,2014-12-12 22:59:27.000000000,2014-12-12 22:59:26.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6413}, {'_account_id': 6484}]","[{'number': 1, 'created': '2014-11-19 16:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/699e5bb703b4eb964c25f99df77135e72ca67ddc', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}, {'number': 2, 'created': '2014-12-01 14:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/f1151a307b85fa9f105c8b0df466925d77395b4d', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}, {'number': 3, 'created': '2014-12-03 14:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/dbdfdb8931be1b428ebee5679e856a798813755d', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}, {'number': 4, 'created': '2014-12-09 09:53:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/37458fb1c17bb42702003f2946b62fabc456205c', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}, {'number': 5, 'created': '2014-12-11 06:57:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar/commit/ef54a8fdec3afb24e9205df3bd9bc4a07b53644f', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}, {'number': 6, 'created': '2014-12-12 14:06:54.000000000', 'files': ['zaqar/storage/sqlalchemy/driver.py', 'requirements.txt', 'zaqar/storage/pipeline.py', 'zaqar/tests/faulty_storage.py', 'zaqar/storage/mongodb/driver.py', 'zaqar/storage/__init__.py', 'zaqar/storage/base.py', 'requirements-py3.txt', 'zaqar/storage/pooling.py', 'zaqar/storage/redis/driver.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/55624816bdcb446b881fb29abb5b99093f6bac86', 'message': 'Add capabilities property to the DataDriver\n\nThis patch adds the capabilities property to DataDrivers as a first step\nto support storage capabilities. For now, capabilities are static for\nstorage drivers, whereas they are calculated dynamically for pooled\ndrivers.\n\nFollow up patches will make drivers capabilities dynamic.\n\nChange-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef\nPartial-blueprint: expose-storage-capabilities\n'}]",8,135637,55624816bdcb446b881fb29abb5b99093f6bac86,29,4,6,6159,,,0,"Add capabilities property to the DataDriver

This patch adds the capabilities property to DataDrivers as a first step
to support storage capabilities. For now, capabilities are static for
storage drivers, whereas they are calculated dynamically for pooled
drivers.

Follow up patches will make drivers capabilities dynamic.

Change-Id: I29602ab5c8b3857caa3a5a6b1e9e37a5f88b2eef
Partial-blueprint: expose-storage-capabilities
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/37/135637/1 && git format-patch -1 --stdout FETCH_HEAD,"['zaqar/queues/storage/base.py', 'zaqar/queues/storage/mongodb/driver.py', 'zaqar/tests/faulty_storage.py', 'zaqar/queues/storage/pipeline.py', 'zaqar/queues/storage/sqlalchemy/driver.py', 'zaqar/queues/storage/pooling.py', 'zaqar/queues/storage/redis/driver.py']",7,699e5bb703b4eb964c25f99df77135e72ca67ddc,bp/expose-storage-capabilities," # NOTE(flaper87): Make this dynamic self._capabilities = ['fifo', 'high-throughput'] @property def capabilities(self): return self._capabilities ",,42,0
openstack%2Ftaskflow~master~I3482f122570cd984f3b4428cf56d0b1c17ef8e30,openstack/taskflow,master,I3482f122570cd984f3b4428cf56d0b1c17ef8e30,Add a helper callback class triggered on task events,ABANDONED,2014-12-10 21:13:00.000000000,2014-12-12 22:57:27.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-10 21:13:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/ef7b26180bf6efc9766c4392009b7e664ec89c69', 'message': 'Add a helper callback class triggered on task events\n\nInstead of retaining raw callbacks in the task event listeners\nretain a wrapper class that can provide useful properties and\nmethods that the task can then use to perform its callback actions\non.\n\nThis helps decouple the task base class from knowing about how to\ncall the callbacks with the right parameters and checking for equals\nand so-on, making the functionality simpler and more isolated.\n\nChange-Id: I3482f122570cd984f3b4428cf56d0b1c17ef8e30\n'}, {'number': 2, 'created': '2014-12-11 00:08:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/a2e0d7ca097896c7e5ddfb1b8e5e94c96c0de379', 'message': 'Add a helper callback class triggered on task events\n\nInstead of retaining raw callbacks in the task event listeners\nretain a wrapper class that can provide useful properties and\nmethods that the task can then use to perform its callback actions\non.\n\nThis helps decouple the task base class from knowing about how to\ncall the callbacks with the right parameters and checking for equals\nand so-on, making the functionality simpler and more isolated.\n\nChange-Id: I3482f122570cd984f3b4428cf56d0b1c17ef8e30\n'}, {'number': 3, 'created': '2014-12-11 02:44:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0363ec410c8088edb3b7371a8649c600ea046987', 'message': 'Add a helper callback class triggered on task events\n\nInstead of retaining raw callbacks in the task event listeners\nretain a wrapper class that can provide useful properties and\nmethods that the task can then use to perform its callback actions\non.\n\nThis helps decouple the task base class from knowing about how to\ncall the callbacks with the right parameters and checking for equals\nand so-on, making the functionality simpler and more isolated.\n\nChange-Id: I3482f122570cd984f3b4428cf56d0b1c17ef8e30\n'}, {'number': 4, 'created': '2014-12-11 06:39:38.000000000', 'files': ['taskflow/task.py', 'taskflow/tests/unit/test_task.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d05ccab9df60f86063f4ee2d5f655b0c91a59e47', 'message': 'Add a helper callback class triggered on task events\n\nInstead of retaining raw callbacks in the task event listeners\nretain a wrapper class that can provide useful properties and\nmethods that the task can then use to perform its callback actions\non.\n\nThis helps decouple the task base class from knowing about how to\ncall the callbacks with the right parameters and checking for equals\nand so-on, making the functionality simpler and more isolated.\n\nChange-Id: I3482f122570cd984f3b4428cf56d0b1c17ef8e30\n'}]",0,140838,d05ccab9df60f86063f4ee2d5f655b0c91a59e47,9,1,4,1297,,,0,"Add a helper callback class triggered on task events

Instead of retaining raw callbacks in the task event listeners
retain a wrapper class that can provide useful properties and
methods that the task can then use to perform its callback actions
on.

This helps decouple the task base class from knowing about how to
call the callbacks with the right parameters and checking for equals
and so-on, making the functionality simpler and more isolated.

Change-Id: I3482f122570cd984f3b4428cf56d0b1c17ef8e30
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/38/140838/4 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/task.py', 'taskflow/tests/unit/test_task.py']",2,ef7b26180bf6efc9766c4392009b7e664ec89c69,," mock.ANY, mock.ANY, task.EVENT_UPDATE_PROGRESS, exc_info=mock.ANY)","from taskflow.utils import reflection mock.ANY, reflection.get_callable_name(progress_callback), task.EVENT_UPDATE_PROGRESS, exc_info=mock.ANY)",45,21
openstack%2Fcongress~master~Iea2fb5ee5568318b92f0213657cb263d6f0f3140,openstack/congress,master,Iea2fb5ee5568318b92f0213657cb263d6f0f3140,Remove q-lbaas from readme as this is now part of a different repo,ABANDONED,2014-12-12 00:05:22.000000000,2014-12-12 22:56:40.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 13050}]","[{'number': 1, 'created': '2014-12-12 00:05:22.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/congress/commit/b35e41740767aa855e977ade4fb9b26969e72894', 'message': 'Remove q-lbaas from readme as this is now part of a different repo\n\nChange-Id: Iea2fb5ee5568318b92f0213657cb263d6f0f3140\n'}]",0,141223,b35e41740767aa855e977ade4fb9b26969e72894,7,3,1,4395,,,0,"Remove q-lbaas from readme as this is now part of a different repo

Change-Id: Iea2fb5ee5568318b92f0213657cb263d6f0f3140
",git fetch https://review.opendev.org/openstack/congress refs/changes/23/141223/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b35e41740767aa855e977ade4fb9b26969e72894,," ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,n-cauth,horizon,mysql,rabbit,sysstat,cinder,c-api,c-vol,c-sch,n-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,n-novnc,n-xvnc,q-lbaas,ceilometer-acompute,ceilometer-acentral,ceilometer-anotification,ceilometer-collector,ceilometer-alarm-evaluator,ceilometer-alarm-notifier,ceilometer-api,s-proxy,s-object,s-container,s-account"," ENABLED_SERVICES=g-api,g-reg,key,n-api,n-crt,n-obj,n-cpu,n-sch,n-cauth,horizon,mysql,rabbit,sysstat,cinder,c-api,c-vol,c-sch,n-cond,quantum,q-svc,q-agt,q-dhcp,q-l3,q-meta,q-lbaas,n-novnc,n-xvnc,q-lbaas,ceilometer-acompute,ceilometer-acentral,ceilometer-anotification,ceilometer-collector,ceilometer-alarm-evaluator,ceilometer-alarm-notifier,ceilometer-api,s-proxy,s-object,s-container,s-account",1,1
openstack%2Foctavia~master~I4839e2995869b6dc857052632701affbd9bfcc5e,openstack/octavia,master,I4839e2995869b6dc857052632701affbd9bfcc5e,Added pymysql as default DBAPI,MERGED,2014-12-12 22:07:34.000000000,2014-12-12 22:51:24.000000000,2014-12-12 22:51:24.000000000,"[{'_account_id': 3}, {'_account_id': 10850}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 22:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/94bcfd911d63bdb0c0e9d556a4eddc26d353d301', 'message': 'Added pymysql as default DBAPI\n\nChange-Id: I4839e2995869b6dc857052632701affbd9bfcc5e\n'}, {'number': 2, 'created': '2014-12-12 22:30:32.000000000', 'files': ['requirements.txt', 'octavia/db/migration/alembic.ini', 'etc/octavia.conf'], 'web_link': 'https://opendev.org/openstack/octavia/commit/6b511cc1139beb5dec034cd51344337c0adab783', 'message': 'Added pymysql as default DBAPI\n\npymysql does not require any system dependencies so it just\nrequires a pip install unlike MySQL-Python.\n\nChange-Id: I4839e2995869b6dc857052632701affbd9bfcc5e\n'}]",1,141502,6b511cc1139beb5dec034cd51344337c0adab783,10,3,2,6951,,,0,"Added pymysql as default DBAPI

pymysql does not require any system dependencies so it just
requires a pip install unlike MySQL-Python.

Change-Id: I4839e2995869b6dc857052632701affbd9bfcc5e
",git fetch https://review.opendev.org/openstack/octavia refs/changes/02/141502/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'octavia/db/migration/alembic.ini', 'etc/octavia.conf']",3,94bcfd911d63bdb0c0e9d556a4eddc26d353d301,,# connection = mysql+pymysql://root:pass@127.0.0.1:3306/octavia# connection = mysql+pymysql://,# connection = mysql://root:pass@127.0.0.1:3306/octavia# connection = sqlite://,4,3
openstack%2Fmagnum~master~Ia020802cd61a867da22c89beab1f231a2345ce78,openstack/magnum,master,Ia020802cd61a867da22c89beab1f231a2345ce78,Make docker and k8s backend handlers use proper input parameters,ABANDONED,2014-12-01 19:47:45.000000000,2014-12-12 22:51:10.000000000,,"[{'_account_id': 3}, {'_account_id': 6924}, {'_account_id': 7494}, {'_account_id': 7770}]","[{'number': 1, 'created': '2014-12-01 19:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4b2f833af27f1f138db57880fa94282032bfe51c', 'message': 'Make docker and k8s backend handlers use proper input parameters\n\npreviously the methods were not taking self or context.\n\nChange-Id: Ia020802cd61a867da22c89beab1f231a2345ce78\n'}, {'number': 2, 'created': '2014-12-01 22:46:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/24963ba452fc76e148b1ecef6058cefeebe27f0f', 'message': 'Make docker and k8s backend handlers use proper input parameters\n\npreviously the methods were not taking self or context.\n\nChange-Id: Ia020802cd61a867da22c89beab1f231a2345ce78\n'}, {'number': 3, 'created': '2014-12-02 02:40:42.000000000', 'files': ['magnum/backend/handlers/docker.py', 'magnum/backend/handlers/k8s.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/524a864e1bf7c7229014458a8615dbb67af83a73', 'message': 'Make docker and k8s backend handlers use proper input parameters\n\npreviously the methods were not taking self or context.\n\nChange-Id: Ia020802cd61a867da22c89beab1f231a2345ce78\n'}]",0,138162,524a864e1bf7c7229014458a8615dbb67af83a73,11,4,3,2834,,,0,"Make docker and k8s backend handlers use proper input parameters

previously the methods were not taking self or context.

Change-Id: Ia020802cd61a867da22c89beab1f231a2345ce78
",git fetch https://review.opendev.org/openstack/magnum refs/changes/62/138162/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/backend/handlers/docker.py', 'magnum/backend/handlers/k8s.py']",2,4b2f833af27f1f138db57880fa94282032bfe51c,," def service_create(self, context, id, name): LOG.debug(""service_create %s contents %s"" % (id, contents)) def service_list(self, context): def service_delete(self, context, id): LOG.debug(""service_delete %s"" % id) def service_show(self, context, id): LOG.debug(""service_show %s"" % id) def pod_create(self, context, id, contents): def pod_list(self, context, id) def pod_delete(self, context, id): LOG.debug(""pod_delete %s"" % id) def pod_show(self, context, id): LOG.debug(""pod_show %s"" % id)"," def service_create(uuid, contents): LOG.debug(""service_create %s contents %s"" % (uuid, contents)) def service_list(): def service_delete(uuid): LOG.debug(""service_delete %s"" % uuid) def service_show(uuid): LOG.debug(""service_show %s"" % uuid) def pod_create(uuid, contents): def pod_list(): def pod_delete(uuid): LOG.debug(""pod_delete %s"" % uuid) def pod_show(uuid): LOG.debug(""pod_show %s"" % uuid) return None # Container operations def container_create(uuid, contents): return None def container_list(): return None def container_delete(uuid): return None def container_show(uuid): return None def container_reboot(uuid): return None def container_stop(uuid): return None def container_start(uuid): return None def container_pause(uuid): return None def container_unpause(uuid): return None def container_logs(uuid): return None def container_execute(uuid):",34,97
openstack%2Fswift~master~If06149d13140148463004d426cb7ba4c5601404a,openstack/swift,master,If06149d13140148463004d426cb7ba4c5601404a,Add tests for metadata on 304 and 412 responses,MERGED,2014-12-12 20:08:49.000000000,2014-12-12 22:48:18.000000000,2014-12-12 22:48:17.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 13052}]","[{'number': 1, 'created': '2014-12-12 20:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1dbe942c87773d0602116ac432d27f5127a7e8b3', 'message': ""Add tests for metadata on 304 and 412 responses\n\nCommit 1f67eb74 added support for If-[None-]Match on DLOs and SLOs. It\nalso made the 304 and 412 responses have the Content-Type and\nX-Object-Meta-* headers from the object instead of just having the\nEtag.\n\nSomeone showed up in IRC today looking for this behavior, and was\nhappy to learn it's in newer Swift versions than the one they were\nrunning. If we've got clients depending on this, we should have some\nunit tests to make sure we don't accidentally take it out again.\n\nChange-Id: If06149d13140148463004d426cb7ba4c5601404a\n""}, {'number': 2, 'created': '2014-12-12 20:29:53.000000000', 'files': ['test/unit/obj/test_server.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/f48350865ec1666fd51bf161c339a90aee9ff7cd', 'message': ""Add tests for metadata on 304 and 412 responses\n\nCommit 1f67eb74 added support for If-[None-]Match on DLOs and SLOs. It\nalso made the 304 and 412 responses have the Content-Type and\nX-Object-Meta-* headers from the object instead of just having the\nEtag.\n\nSomeone showed up in IRC today looking for this behavior, and was\nhappy to learn it's in newer Swift versions than the one they were\nrunning. If we've got clients depending on this, we should have some\nunit tests to make sure we don't accidentally take it out again.\n\nChange-Id: If06149d13140148463004d426cb7ba4c5601404a\n""}]",0,141479,f48350865ec1666fd51bf161c339a90aee9ff7cd,9,3,2,2622,,,0,"Add tests for metadata on 304 and 412 responses

Commit 1f67eb74 added support for If-[None-]Match on DLOs and SLOs. It
also made the 304 and 412 responses have the Content-Type and
X-Object-Meta-* headers from the object instead of just having the
Etag.

Someone showed up in IRC today looking for this behavior, and was
happy to learn it's in newer Swift versions than the one they were
running. If we've got clients depending on this, we should have some
unit tests to make sure we don't accidentally take it out again.

Change-Id: If06149d13140148463004d426cb7ba4c5601404a
",git fetch https://review.opendev.org/openstack/swift refs/changes/79/141479/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/obj/test_server.py'],1,1dbe942c87773d0602116ac432d27f5127a7e8b3,304-metadata," 'X-Object-Meta-Soup': 'gazpacho', self.assertEquals(resp.headers['Content-Type'], 'application/octet-stream') self.assertEquals(resp.headers['X-Object-Meta-Soup'], 'gazpacho') 'X-Object-Meta-Burr': 'ito', self.assertEquals(resp.headers['Content-Type'], 'application/octet-stream') self.assertEquals(resp.headers['X-Object-Meta-Burr'], 'ito')",,8,0
openstack-attic%2Fcompute-api~master~I3e1844baf19ab4020d0187896b3a743ad7676b86,openstack-attic/compute-api,master,I3e1844baf19ab4020d0187896b3a743ad7676b86,Indicates frozen nature in README,MERGED,2014-12-11 23:19:07.000000000,2014-12-12 22:44:58.000000000,2014-12-12 22:44:58.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-11 23:19:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/1bbc4043430efccbedabad6e907b23bfebd52aad', 'message': 'Indicates frozen nature in README\n\nChange-Id: I3e1844baf19ab4020d0187896b3a743ad7676b86\n'}, {'number': 2, 'created': '2014-12-12 20:17:53.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/compute-api/commit/a49a75edb25a93e4273ddbaa329539da049fb336', 'message': 'Indicates frozen nature in README\n\nChange-Id: I3e1844baf19ab4020d0187896b3a743ad7676b86\n'}]",0,141207,a49a75edb25a93e4273ddbaa329539da049fb336,10,3,2,964,,,0,"Indicates frozen nature in README

Change-Id: I3e1844baf19ab4020d0187896b3a743ad7676b86
",git fetch https://review.opendev.org/openstack-attic/compute-api refs/changes/07/141207/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1bbc4043430efccbedabad6e907b23bfebd52aad,freeze,"This repository is now frozen-in-time and will not accept new patches. It was the original API information holder for the OpenStack Compute project, also known as Nova. The Nova project provides open source cloud management and orchestration services.","This repository contains the RESTful API information for the OpenStack Compute project, also known as Nova. The Nova project provides open source cloud management and orchestration services.",5,3
openstack-attic%2Fimage-api~master~I7eff614866cdfa44c89d9b073218292f1261af39,openstack-attic/image-api,master,I7eff614866cdfa44c89d9b073218292f1261af39,Indicates frozen state in README,MERGED,2014-12-11 23:21:29.000000000,2014-12-12 22:40:45.000000000,2014-12-12 22:40:44.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-11 23:21:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/19a0fd0ac3097aed3a50b12a22dce78103bff4c9', 'message': 'Indicates frozen state in README\n\nChange-Id: I7eff614866cdfa44c89d9b073218292f1261af39\n'}, {'number': 2, 'created': '2014-12-12 18:18:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/image-api/commit/8d2fd70ff42e22f3f6e6aa3f7dc13852c00f9239', 'message': 'Indicates frozen state in README\n\nChange-Id: I7eff614866cdfa44c89d9b073218292f1261af39\n'}]",0,141209,8d2fd70ff42e22f3f6e6aa3f7dc13852c00f9239,9,3,2,964,,,0,"Indicates frozen state in README

Change-Id: I7eff614866cdfa44c89d9b073218292f1261af39
",git fetch https://review.opendev.org/openstack-attic/image-api refs/changes/09/141209/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,19a0fd0ac3097aed3a50b12a22dce78103bff4c9,freeze,This repository is now frozen-in-time and will not accept new patches. It was the original holder for API information for the OpenStack,This repository contains the RESTful API information for the OpenStack,3,1
openstack-attic%2Fobject-api~master~If9c2e36b45cc3d72cd75242fd3b801c1284d6ea8,openstack-attic/object-api,master,If9c2e36b45cc3d72cd75242fd3b801c1284d6ea8,Indicate contents are frozen in README,MERGED,2014-12-11 23:22:24.000000000,2014-12-12 22:39:10.000000000,2014-12-12 22:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-11 23:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/ca4a632431f915ed57d1307f83d07afe095dd7ba', 'message': 'Indicate contents are frozen in README\n\nChange-Id: If9c2e36b45cc3d72cd75242fd3b801c1284d6ea8\n'}, {'number': 2, 'created': '2014-12-12 18:19:36.000000000', 'files': ['README.rst', 'v1/bk_os-objectstorage-devguide.xml'], 'web_link': 'https://opendev.org/openstack-attic/object-api/commit/9cc1e380d39245a73026f096b4698942402fb118', 'message': 'Indicate contents are frozen in README\n\nChange-Id: If9c2e36b45cc3d72cd75242fd3b801c1284d6ea8\n'}]",0,141210,9cc1e380d39245a73026f096b4698942402fb118,9,3,2,964,,,0,"Indicate contents are frozen in README

Change-Id: If9c2e36b45cc3d72cd75242fd3b801c1284d6ea8
",git fetch https://review.opendev.org/openstack-attic/object-api refs/changes/10/141210/2 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'v1/bk_os-objectstorage-devguide.xml']",2,ca4a632431f915ed57d1307f83d07afe095dd7ba,freeze," <!--<revhistory> </revhistory>--> <!--<xi:include href=""preface.xml""/>-->"," <revhistory> </revhistory> <xi:include href=""preface.xml""/>",6,4
openstack%2Fneutron~master~Ia5e26a5bd76a24cbd4b9b90351ba567ea13c4062,openstack/neutron,master,Ia5e26a5bd76a24cbd4b9b90351ba567ea13c4062,(WIP)Improve the performance of _modify_rules() in IptablesManager,ABANDONED,2014-12-03 17:18:35.000000000,2014-12-12 22:31:36.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6072}, {'_account_id': 7448}, {'_account_id': 8574}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10692}, {'_account_id': 12040}, {'_account_id': 13051}]","[{'number': 1, 'created': '2014-12-03 17:18:35.000000000', 'files': ['neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4e9c4368220ff4d72f62ad6208a2148372091bf', 'message': '(WIP)Improve the performance of _modify_rules() in IptablesManager\n\nImplement a new algorithm for _modify_rules(), which reduces the\ncomplexity from O(n^2) to O(nlogn). The new code does not change\nany behavior of _modify_rules(). A new unit test is also added\nfor _modify_rules().\n\nChange-Id: Ia5e26a5bd76a24cbd4b9b90351ba567ea13c4062\nCloses-Bug: 1352826\n'}]",0,138793,b4e9c4368220ff4d72f62ad6208a2148372091bf,20,19,1,6072,,,0,"(WIP)Improve the performance of _modify_rules() in IptablesManager

Implement a new algorithm for _modify_rules(), which reduces the
complexity from O(n^2) to O(nlogn). The new code does not change
any behavior of _modify_rules(). A new unit test is also added
for _modify_rules().

Change-Id: Ia5e26a5bd76a24cbd4b9b90351ba567ea13c4062
Closes-Bug: 1352826
",git fetch https://review.opendev.org/openstack/neutron refs/changes/93/138793/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/test_iptables_manager.py', 'neutron/agent/linux/iptables_manager.py']",2,b4e9c4368220ff4d72f62ad6208a2148372091bf,bug/1352826," LOG.debug(""ALL_LINES1: %s"", all_lines) LOG.debug(""ALL_LINES2: %s"", all_lines) table_header = current_lines[:2] table_footer = current_lines[-2:] rule_index = self._find_rules_index(current_lines) # Get sorted chain list from iptables-save output chain_lines = [(_strip_packets_bytes(s), s) for s in current_lines[2:rule_index]] chain_lines.sort(key=lambda e: e[0]) # Get sorted rule list from iptables-save output rule_lines = \ [(_strip_packets_bytes(s), s) for s in current_lines[rule_index:len(current_lines) - 2]] rule_lines.sort(key=lambda e: e[0]) all_chains = ['%s' % e for e in unwrapped_chains] + \ ['%s-%s' % (self.wrap_name, e) for e in chains] # Get sorted chain list from in-memory table my_chain = [(i, str(c).strip()) for i, c in enumerate(all_chains)] my_chain.sort(key=lambda e: e[1]) # Get sorted rule list from in-memory table my_rule = [(i, str(r).strip(), r.top) for i, r in enumerate(rules)] my_rule.sort(key=lambda e: e[1]) chain_output = [] # Merge the chains of in-memory table and iptables-save output while(len(my_chain) > 0 and len(chain_lines) > 0): # Skip the duplicated chains, remains the last occurrence. while (len(my_chain) > 1 and my_chain[0][1] == my_chain[1][1]): my_chain.pop(0) while (len(chain_lines) > 1 and chain_lines[0][0] == chain_lines[1][0]): chain_lines.pop(0) a = my_chain[0][1] b = chain_lines[0][0] if a < b: # The chain string which is in the in-memory table # is not in the iptables-save output. e = my_chain.pop(0) chain_output.append((e[0], ':' + e[1] + ' - [0:0]')) elif a > b: # The chain string which is in the iptables-save output # is not in the in-memory table. e = chain_lines.pop(0) #chain_output.append((-1, e[1])) else: # The chain string which is in the iptables-save output # is also in the iptables-save output. e = my_chain.pop(0) f = chain_lines.pop(0) chain_output.append((e[0], f[1])) # Append the rest entries of the in-memory table last_e = None for e in my_chain: if (last_e and last_e[1] == e[1]): chain_output.pop() chain_output.append((e[0], ':' + e[1] + ' - [0:0]')) last_e = e # Append the rest entries of the iptables-save output - ??? """""" last_e = None for e in chain_lines: if (last_e and last_e[0] == e[0]): chain_output.pop() chain_output.append((-1, e[1])) last_e = e """""" # Restore output to the original order. The chains in iptables-save # output but not in in-memory table will be placed in the first half. # The chains in in-memory table but not in iptables ouput will be # placed in the second half. chain_output.sort(key=lambda e: e[0]) rule_output = [] max_index = len(my_rule) while(len(my_rule) > 0 and len(rule_lines) > 0): # Skip the duplicated rule, and remain the last occurrence. while (len(my_rule) > 1 and my_rule[0][1] == my_rule[1][1]): my_rule.pop(0) while (len(rule_lines) > 1 and rule_lines[0][0] == rule_lines[1][0]): rule_lines.pop(0) a = my_rule[0][1] b = rule_lines[0][0] if a < b: # The rule string which is in the in-memory table # is not in the iptables-save output. e = my_rule.pop(0) if not e[2]: # rule.top is False rule_output.append((e[0], '[0:0] ' + e[1])) else: rule_output.append((e[0] - max_index - 1, '[0:0] ' + e[1])) elif a > b: # The rule string which is in the iptables-save output # is not in the in-memory table. e = rule_lines.pop(0) #rule_output.append((max_index, e[1])) else: # The rule string which is in the iptables-save output # is also in the iptables-save output. e = my_rule.pop(0) f = rule_lines.pop(0) if not e[2]: # rule.top is False rule_output.append((e[0], f[1])) else: rule_output.append((e[0] - max_index - 1, f[1])) # Append the rest rules in the in-memory table last_e = None for e in my_rule: if (last_e and last_e[1] == e[1]): rule_output.pop() rule_output.append((e[0], '[0:0] ' + e[1])) last_e = e # Append the rest rules in the iptables-save output """""" last_e = None for e in rule_lines: if (last_e and last_e[0] == e[0]): rule_output.pop() rule_output.append((max_index, e[1])) last_e = e """""" # Restore output to the original order. The rules in iptables-save # output but not in in-memory table will be placed in the second half. # The rules in in-memory table but not in iptables ouput will be # placed in the first half. rule_output.sort(key=lambda e: e[0]) remove_chains = table.remove_chains remove_rules = table.remove_rules # No duplicates in output now. We only need to filter out # anything in the ""remove"" list. output = \ table_header + \ [e[1] for e in chain_output if _weed_out_removes(e[1])] + \ [e[1] for e in rule_output if _weed_out_removes(e[1])] + \ table_footer return output"," remove_chains = table.remove_chains remove_rules = table.remove_rules # Fill old_filter with any chains or rules we might have added, # they could have a [packet:byte] count we want to preserve. # Fill new_filter with any chains or rules without our name in them. old_filter, new_filter = [], [] for line in current_lines: (old_filter if self.wrap_name in line else new_filter).append(line.strip()) rules_index = self._find_rules_index(new_filter) all_chains = [':%s' % name for name in unwrapped_chains] all_chains += [':%s-%s' % (self.wrap_name, name) for name in chains] # Iterate through all the chains, trying to find an existing # match. our_chains = [] for chain in all_chains: chain_str = str(chain).strip() old = self._find_last_entry(old_filter, chain_str) if not old: dup = self._find_last_entry(new_filter, chain_str) new_filter = [s for s in new_filter if chain_str not in s.strip()] # if no old or duplicates, use original chain if old or dup: chain_str = str(old or dup) else: # add-on the [packet:bytes] chain_str += ' - [0:0]' our_chains += [chain_str] # Iterate through all the rules, trying to find an existing # match. our_rules = [] bot_rules = [] for rule in rules: rule_str = str(rule).strip() # Further down, we weed out duplicates from the bottom of the # list, so here we remove the dupes ahead of time. old = self._find_last_entry(old_filter, rule_str) if not old: dup = self._find_last_entry(new_filter, rule_str) new_filter = [s for s in new_filter if rule_str not in s.strip()] # if no old or duplicates, use original rule if old or dup: rule_str = str(old or dup) # backup one index so we write the array correctly if not old: rules_index -= 1 else: # add-on the [packet:bytes] rule_str = '[0:0] ' + rule_str if rule.top: # rule.top == True means we want this rule to be at the top. our_rules += [rule_str] else: bot_rules += [rule_str] our_rules += bot_rules new_filter[rules_index:rules_index] = our_rules new_filter[rules_index:rules_index] = our_chains seen_chains = set() def _weed_out_duplicate_chains(line): # ignore [packet:byte] counts at end of lines if line.startswith(':'): line = _strip_packets_bytes(line) if line in seen_chains: return False else: seen_chains.add(line) # Leave it alone return True seen_rules = set() def _weed_out_duplicate_rules(line): if line.startswith('['): line = _strip_packets_bytes(line) if line in seen_rules: return False else: seen_rules.add(line) # Leave it alone return True # We filter duplicates. Go through the chains and rules, letting # the *last* occurrence take precedence since it could have a # non-zero [packet:byte] count we want to preserve. We also filter # out anything in the ""remove"" list. new_filter.reverse() new_filter = [line for line in new_filter if _weed_out_duplicate_chains(line) and _weed_out_duplicate_rules(line) and _weed_out_removes(line)] new_filter.reverse() return new_filter",223,103
openstack%2Fdevstack~master~I4a4430e451094d638704a2da1eb2de7f22f25b84,openstack/devstack,master,I4a4430e451094d638704a2da1eb2de7f22f25b84,Delete is_ironic function,MERGED,2014-12-12 07:44:42.000000000,2014-12-12 22:10:08.000000000,2014-12-12 22:10:06.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 7369}, {'_account_id': 8003}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 07:44:42.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/31f70b4016b9f65325d1f7d2d7fc594b4dc98c12', 'message': 'Delete is_ironic function\n\nThis function is not used in DevStack anymore.\n\nChange-Id: I4a4430e451094d638704a2da1eb2de7f22f25b84\n'}]",0,141292,31f70b4016b9f65325d1f7d2d7fc594b4dc98c12,9,6,1,1994,,,0,"Delete is_ironic function

This function is not used in DevStack anymore.

Change-Id: I4a4430e451094d638704a2da1eb2de7f22f25b84
",git fetch https://review.opendev.org/openstack/devstack refs/changes/92/141292/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,31f70b4016b9f65325d1f7d2d7fc594b4dc98c12,del_is_ironic,,function is_ironic { if ( is_service_enabled ir-cond && is_service_enabled ir-api ); then return 0 fi return 1 } ,0,7
openstack%2Fceilometer~master~I60d468a7d24e0a5bdb4c2f680af24397b4c0d77c,openstack/ceilometer,master,I60d468a7d24e0a5bdb4c2f680af24397b4c0d77c,Make LBaaS total_connections cumulative,MERGED,2014-12-11 02:08:10.000000000,2014-12-12 22:09:58.000000000,2014-12-12 22:09:58.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 8871}, {'_account_id': 11685}, {'_account_id': 13367}]","[{'number': 1, 'created': '2014-12-11 02:08:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/98bc452ad9eeb7491edfa798507ac3236be36474', 'message': 'Make LBaaS total_connections cumulative\n\nThe total_connections LBaaS data point is presently incorrectly\nlisted as a gauge. Since the total_connections data point will be an\never-increasing value (much the same as bytes_in and bytes_out are),\nthis commit corrects total_connections to also be cumulative.\n\nChange-Id: I60d468a7d24e0a5bdb4c2f680af24397b4c0d77c\n'}, {'number': 2, 'created': '2014-12-11 02:20:11.000000000', 'files': ['ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/network/services/lbaas.py', 'doc/source/measurements.rst'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/09d21e8e51e84eb6034b02349569211c6e640155', 'message': 'Make LBaaS total_connections cumulative\n\nThe total_connections LBaaS data point is presently incorrectly\nlisted as a gauge. Since the total_connections data point will be an\never-increasing value (much the same as bytes_in and bytes_out are),\nthis commit corrects total_connections to also be cumulative.\n\nChange-Id: I60d468a7d24e0a5bdb4c2f680af24397b4c0d77c\nCloses-Bug: #1401352\n'}]",0,140897,09d21e8e51e84eb6034b02349569211c6e640155,20,9,2,11685,,,0,"Make LBaaS total_connections cumulative

The total_connections LBaaS data point is presently incorrectly
listed as a gauge. Since the total_connections data point will be an
ever-increasing value (much the same as bytes_in and bytes_out are),
this commit corrects total_connections to also be cumulative.

Change-Id: I60d468a7d24e0a5bdb4c2f680af24397b4c0d77c
Closes-Bug: #1401352
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/97/140897/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/network/services/test_lbaas.py', 'ceilometer/network/services/lbaas.py', 'doc/source/measurements.rst']",3,98bc452ad9eeb7491edfa798507ac3236be36474,bug/1401352,network.services.lb.total.connections Cumulative connection pool ID pollster Total connections on a LB,network.services.lb.total.connections Gauge connection pool ID pollster Total connections on a LB,3,3
openstack%2Fceilometer~master~I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad,openstack/ceilometer,master,I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad,RBAC Support for Ceilometer API Implementation,MERGED,2014-08-20 17:26:43.000000000,2014-12-12 22:09:36.000000000,2014-12-12 22:09:34.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 7409}, {'_account_id': 7729}, {'_account_id': 9013}, {'_account_id': 10608}, {'_account_id': 10987}, {'_account_id': 11224}, {'_account_id': 11549}, {'_account_id': 11564}, {'_account_id': 11580}, {'_account_id': 12149}, {'_account_id': 12637}]","[{'number': 1, 'created': '2014-08-20 17:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e884bd554b49424d54b58dd88268bff73fdd68ce', 'message': 'Placeholder commit for WIP\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 2, 'created': '2014-08-20 21:42:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d5131eb144820a2223619bdf966992ea3409a0bf', 'message': 'Placeholder commit for WIP\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 3, 'created': '2014-09-11 01:51:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e9861f43eec38e8d7926628419d9dc10b25c5cf3', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 4, 'created': '2014-10-16 17:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/77050f342d322fe98be4172a5a09d2f05d7a3309', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 5, 'created': '2014-10-22 01:20:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/695abff03ea45cee5099df8659239af56123f0b7', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 6, 'created': '2014-10-23 03:45:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/8d5be24d8e2ea2d24ffdbf4b4b9af0d836f5cda7', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 7, 'created': '2014-10-25 04:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/4e046cdd098b0bb8f9da08f8bd388e9eedadb673', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 8, 'created': '2014-10-25 05:41:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/eb5d5a21f6e9921fb05c48b6cbc561f61c7710d6', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 9, 'created': '2014-11-13 15:27:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/237a4c7d40529eac2856970a4d0062f1dfaf2a91', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 10, 'created': '2014-11-19 08:31:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d50f1c550cc2709aeb2a083e25d1bc2c3eed8d14', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 11, 'created': '2014-11-19 23:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/375935315a63dc09e5e841838da759942a6fa1c3', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nThe implementation leverages the pecan secure decorator and\nthe oslo policy evaluation code.\n\nAlso a specific RBAC context is injected  to the pecan header\ndata to allow more refined and granular usage within the\ncontroller code if needed.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 12, 'created': '2014-11-19 23:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e92dc679c528c04683feae66970296be647709b4', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 13, 'created': '2014-11-20 00:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/fde42a19db337b124b99860757436e31e8bcedc7', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 14, 'created': '2014-11-26 16:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3a989bcc9c1c6081b0f4f2593fe38ff91efa1628', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 15, 'created': '2014-12-04 22:57:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e9d8b6df63772086db77e95ab20d99949fea5623', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 16, 'created': '2014-12-11 15:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/ff2287c183bc6a0dffca98c2564d8664918a96ab', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nDocImpact\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 17, 'created': '2014-12-11 16:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/1def1d55be2f920b95222612dd0b9a675988ecdf', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}, {'number': 18, 'created': '2014-12-12 17:04:07.000000000', 'files': ['etc/ceilometer/policy.json.sample', 'etc/ceilometer/policy.json', 'ceilometer/api/acl.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/api/rbac.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/be42f2035a087dac3923c6e365b8bb785eee998b', 'message': 'RBAC Support for Ceilometer API Implementation\n\nThis patch adds policy based Role Based Access Control\nto the Ceilometer V2 APIs.\n\nValidation/Enforcement of the policy is executed for the\ndifferent controllers and hence it is possible to\ngranularly control access.\n\nCo-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>\n\nChange-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad\n'}]",62,115717,be42f2035a087dac3923c6e365b8bb785eee998b,96,18,18,7409,,,0,"RBAC Support for Ceilometer API Implementation

This patch adds policy based Role Based Access Control
to the Ceilometer V2 APIs.

Validation/Enforcement of the policy is executed for the
different controllers and hence it is possible to
granularly control access.

Co-Authored-By: Fabio Giannetti <fabio.giannetti@hp.com>

Change-Id: I788b9b31c8cfba9f3caa19f1f6d465a3f81101ad
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/17/115717/5 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/common/rbac_validate.py', 'ceilometer/api/controllers/v2.py', 'ceilometer/common/__init__.py']",3,e884bd554b49424d54b58dd88268bff73fdd68ce,rbac_test,,,68,11
openstack%2Fnova~master~I42d85407f5a98c22607536446f2defec6a994cbc,openstack/nova,master,I42d85407f5a98c22607536446f2defec6a994cbc,Bump major version of Scheduler RPC API to 4.0,MERGED,2014-12-05 17:00:35.000000000,2014-12-12 22:09:11.000000000,2014-12-12 22:09:07.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6450}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-05 17:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ddece77ee94b771460bd91948d8eb058dd24a867', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nSince Juno, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc\n""}, {'number': 2, 'created': '2014-12-05 22:58:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e8eb59a45a6ab42159d133a223c920bc1496d47f', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nDuring Juno timeframe, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc""}, {'number': 3, 'created': '2014-12-05 22:58:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67e3fb34411af6080a3963028d21e9c127dbba27', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nDuring Juno timeframe, the below deprecated methods were removed from\nthe RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc""}, {'number': 4, 'created': '2014-12-08 16:49:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c37117ff862dc630cc26928e1ab7cddb5dbb571c', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nSince Juno, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc\n""}, {'number': 5, 'created': '2014-12-08 17:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/14d4e2590801edd6869efbe93b7036438cd81ccf', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nSince Juno, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc\n""}, {'number': 6, 'created': '2014-12-09 08:08:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1ccfe8b9a0b2e6d241ec9bd75b8cfb9b0ef27b49', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nSince Juno, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc\n""}, {'number': 7, 'created': '2014-12-10 18:02:26.000000000', 'files': ['nova/tests/unit/scheduler/test_chance_scheduler.py', 'nova/scheduler/manager.py', 'nova/scheduler/rpcapi.py', 'nova/scheduler/filter_scheduler.py', 'nova/scheduler/driver.py', 'nova/scheduler/chance.py', 'nova/tests/unit/scheduler/test_rpcapi.py', 'nova/tests/unit/scheduler/test_scheduler.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8466013fbed8b0ec7bb64c6eb183c9bb1b846665', 'message': ""Bump major version of Scheduler RPC API to 4.0\n\nSince Juno, the below deprecated methods were removed from the RPC client:\n - schedule_run_instance\n - prep_resize\n\nNow that we're in Kilo, we only need to care about changes in between 3.0 and\n4.0, and there is only one backwards compatibility to leave about flavors.\n\nNOTE : instance_uuids can now be removed from request_spec but it will be\ndone in a separate commit.\n\nPartially-Implements blueprint request-spec-object\n\nChange-Id: I42d85407f5a98c22607536446f2defec6a994cbc\n""}]",16,139684,8466013fbed8b0ec7bb64c6eb183c9bb1b846665,60,12,7,7166,,,0,"Bump major version of Scheduler RPC API to 4.0

Since Juno, the below deprecated methods were removed from the RPC client:
 - schedule_run_instance
 - prep_resize

Now that we're in Kilo, we only need to care about changes in between 3.0 and
4.0, and there is only one backwards compatibility to leave about flavors.

NOTE : instance_uuids can now be removed from request_spec but it will be
done in a separate commit.

Partially-Implements blueprint request-spec-object

Change-Id: I42d85407f5a98c22607536446f2defec6a994cbc
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/139684/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/manager.py', 'nova/scheduler/rpcapi.py', 'nova/tests/unit/scheduler/test_rpcapi.py', 'nova/tests/unit/scheduler/test_scheduler.py']",4,ddece77ee94b771460bd91948d8eb058dd24a867,bp/request-spec-object,,"from nova.compute import utils as compute_utils from nova.compute import vm_statesfrom nova import objectsfrom nova.tests.unit import fake_instance def test_run_instance_exception_puts_instance_in_error_state(self): fake_instance_uuid = 'fake-instance-id' inst = {""vm_state"": """", ""task_state"": """"} self._mox_schedule_method_helper('schedule_run_instance') self.mox.StubOutWithMock(compute_utils, 'add_instance_fault_from_exc') self.mox.StubOutWithMock(db, 'instance_update_and_get_original') request_spec = {'instance_properties': inst, 'instance_uuids': [fake_instance_uuid]} self.manager.driver.schedule_run_instance(self.context, request_spec, None, None, None, None, {}, False).AndRaise( exception.NoValidHost(reason="""")) old, new_ref = db.instance_update_and_get_original(self.context, fake_instance_uuid, {""vm_state"": vm_states.ERROR, ""task_state"": None}).AndReturn((inst, inst)) compute_utils.add_instance_fault_from_exc(self.context, new_ref, mox.IsA(exception.NoValidHost), mox.IgnoreArg()) self.mox.ReplayAll() self.manager.run_instance(self.context, request_spec, None, None, None, None, {}, False) def test_prep_resize_no_valid_host_back_in_active_state(self): fake_instance_uuid = 'fake-instance-id' fake_instance = {'uuid': fake_instance_uuid} inst = {""vm_state"": """", ""task_state"": """"} self._mox_schedule_method_helper('select_destinations') self.mox.StubOutWithMock(compute_utils, 'add_instance_fault_from_exc') self.mox.StubOutWithMock(db, 'instance_update_and_get_original') request_spec = {'instance_type': 'fake_type', 'instance_uuids': [fake_instance_uuid], 'instance_properties': {'uuid': fake_instance_uuid}} kwargs = { 'context': self.context, 'image': 'fake_image', 'request_spec': request_spec, 'filter_properties': 'fake_props', 'instance': fake_instance, 'instance_type': 'fake_type', 'reservations': list('fake_res'), } self.manager.driver.select_destinations( self.context, request_spec, 'fake_props').AndRaise( exception.NoValidHost(reason="""")) old_ref, new_ref = db.instance_update_and_get_original(self.context, fake_instance_uuid, {""vm_state"": vm_states.ACTIVE, ""task_state"": None}).AndReturn( (inst, inst)) compute_utils.add_instance_fault_from_exc(self.context, new_ref, mox.IsA(exception.NoValidHost), mox.IgnoreArg()) self.mox.ReplayAll() self.manager.prep_resize(**kwargs) def test_prep_resize_no_valid_host_back_in_shutoff_state(self): fake_instance_uuid = 'fake-instance-id' fake_instance = {'uuid': fake_instance_uuid, ""vm_state"": ""stopped""} inst = {""vm_state"": ""stopped"", ""task_state"": """"} self._mox_schedule_method_helper('select_destinations') self.mox.StubOutWithMock(compute_utils, 'add_instance_fault_from_exc') self.mox.StubOutWithMock(db, 'instance_update_and_get_original') request_spec = {'instance_type': 'fake_type', 'instance_uuids': [fake_instance_uuid], 'instance_properties': {'uuid': fake_instance_uuid}} kwargs = { 'context': self.context, 'image': 'fake_image', 'request_spec': request_spec, 'filter_properties': 'fake_props', 'instance': fake_instance, 'instance_type': 'fake_type', 'reservations': list('fake_res'), } self.manager.driver.select_destinations( self.context, request_spec, 'fake_props').AndRaise( exception.NoValidHost(reason="""")) old_ref, new_ref = db.instance_update_and_get_original(self.context, fake_instance_uuid, {""vm_state"": vm_states.STOPPED, ""task_state"": None}).AndReturn( (inst, inst)) compute_utils.add_instance_fault_from_exc(self.context, new_ref, mox.IsA(exception.NoValidHost), mox.IgnoreArg()) self.mox.ReplayAll() self.manager.prep_resize(**kwargs) def test_prep_resize_exception_host_in_error_state_and_raise(self): fake_instance_uuid = 'fake-instance-id' fake_instance = {'uuid': fake_instance_uuid} self._mox_schedule_method_helper('select_destinations') self.mox.StubOutWithMock(compute_utils, 'add_instance_fault_from_exc') self.mox.StubOutWithMock(db, 'instance_update_and_get_original') request_spec = { 'instance_properties': {'uuid': fake_instance_uuid}, 'instance_uuids': [fake_instance_uuid] } kwargs = { 'context': self.context, 'image': 'fake_image', 'request_spec': request_spec, 'filter_properties': 'fake_props', 'instance': fake_instance, 'instance_type': 'fake_type', 'reservations': list('fake_res'), } self.manager.driver.select_destinations( self.context, request_spec, 'fake_props').AndRaise( test.TestingException('something happened')) inst = { ""vm_state"": """", ""task_state"": """", } old_ref, new_ref = db.instance_update_and_get_original(self.context, fake_instance_uuid, {""vm_state"": vm_states.ERROR, ""task_state"": None}).AndReturn((inst, inst)) compute_utils.add_instance_fault_from_exc(self.context, new_ref, mox.IsA(test.TestingException), mox.IgnoreArg()) self.mox.ReplayAll() self.assertRaises(test.TestingException, self.manager.prep_resize, **kwargs) def test_set_vm_state_and_notify_adds_instance_fault(self): request = {'instance_properties': {'uuid': 'fake-uuid'}} updates = {'vm_state': 'foo'} fake_inst = {'uuid': 'fake-uuid'} self.mox.StubOutWithMock(db, 'instance_update_and_get_original') self.mox.StubOutWithMock(db, 'instance_fault_create') self.mox.StubOutWithMock(rpc, 'get_notifier') notifier = self.mox.CreateMockAnything() rpc.get_notifier('scheduler').AndReturn(notifier) db.instance_update_and_get_original(self.context, 'fake-uuid', updates).AndReturn((None, fake_inst)) db.instance_fault_create(self.context, mox.IgnoreArg()).AndReturn( test_instance_fault.fake_faults['fake-uuid'][0]) notifier.error(self.context, 'scheduler.foo', mox.IgnoreArg()) self.mox.ReplayAll() self.manager._set_vm_state_and_notify('foo', {'vm_state': 'foo'}, self.context, None, request) def test_prep_resize_post_populates_retry(self): self.manager.driver = fakes.FakeFilterScheduler() image = 'image' instance_uuid = 'fake-instance-id' instance = fake_instance.fake_db_instance(uuid=instance_uuid) instance_properties = {'project_id': 'fake', 'os_type': 'Linux'} instance_type = ""m1.tiny"" request_spec = {'instance_properties': instance_properties, 'instance_type': instance_type, 'instance_uuids': [instance_uuid]} retry = {'hosts': [], 'num_attempts': 1} filter_properties = {'retry': retry} reservations = None hosts = [dict(host='host', nodename='node', limits={})] self._mox_schedule_method_helper('select_destinations') self.manager.driver.select_destinations( self.context, request_spec, filter_properties).AndReturn(hosts) self.mox.StubOutWithMock(self.manager.compute_rpcapi, 'prep_resize') self.manager.compute_rpcapi.prep_resize(self.context, image, mox.IsA(objects.Instance), instance_type, 'host', reservations, request_spec=request_spec, filter_properties=filter_properties, node='node') self.mox.ReplayAll() self.manager.prep_resize(self.context, image, request_spec, filter_properties, instance, instance_type, reservations) self.assertEqual([['host', 'node']], filter_properties['retry']['hosts']) ",7,305
openstack%2Fnova~master~Id6d3501e3c8b8cbd392fb533bcfcae288224dcc4,openstack/nova,master,Id6d3501e3c8b8cbd392fb533bcfcae288224dcc4,Remove duplicated constant DISK_TYPE_THIN,MERGED,2014-12-06 03:46:14.000000000,2014-12-12 22:06:25.000000000,2014-12-12 22:06:22.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9796}, {'_account_id': 10068}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-06 03:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27486a90059299b0c8837c34ad43203593fc40f0', 'message': 'Remove duplicated constant DISK_TYPE_THIN\n\nChange-Id: Id6d3501e3c8b8cbd392fb533bcfcae288224dcc4\n'}, {'number': 2, 'created': '2014-12-12 11:53:35.000000000', 'files': ['nova/virt/vmwareapi/constants.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/fa71a73d0db9d7b2240582fe431a41567dc76b32', 'message': 'Remove duplicated constant DISK_TYPE_THIN\n\nChange-Id: Id6d3501e3c8b8cbd392fb533bcfcae288224dcc4\n'}]",0,139776,fa71a73d0db9d7b2240582fe431a41567dc76b32,24,10,2,14237,,,0,"Remove duplicated constant DISK_TYPE_THIN

Change-Id: Id6d3501e3c8b8cbd392fb533bcfcae288224dcc4
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/139776/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/vmwareapi/constants.py'],1,27486a90059299b0c8837c34ad43203593fc40f0,rmdupline,,DISK_TYPE_THIN = 'thin',0,1
openstack%2Fsahara~master~I47cefcf4181732b903df81385c9eb27d7482e52b,openstack/sahara,master,I47cefcf4181732b903df81385c9eb27d7482e52b,Disable all set of tests (every plugin) by default,MERGED,2014-11-13 18:08:41.000000000,2014-12-12 22:06:13.000000000,2014-12-12 22:06:12.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 9382}, {'_account_id': 10459}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-11-13 18:08:41.000000000', 'files': ['sahara/tests/integration/configs/config.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/56e7f986eb058e07fa42ea326a65edb82ecec127', 'message': 'Disable all set of tests (every plugin) by default\n\nUsers need to enable them case-by-case.\nCloses-Bug: #1392420\n\nChange-Id: I47cefcf4181732b903df81385c9eb27d7482e52b\n'}]",0,134317,56e7f986eb058e07fa42ea326a65edb82ecec127,37,11,1,10459,,,0,"Disable all set of tests (every plugin) by default

Users need to enable them case-by-case.
Closes-Bug: #1392420

Change-Id: I47cefcf4181732b903df81385c9eb27d7482e52b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/17/134317/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/integration/configs/config.py'],1,56e7f986eb058e07fa42ea326a65edb82ecec127,bug/1392420," default=True, default=True, default=True,"," default=False, default=False, default=False,",3,3
openstack%2Fsahara~master~Id5159c54ad83fd86887f9b718b7545603467bb9a,openstack/sahara,master,Id5159c54ad83fd86887f9b718b7545603467bb9a,Fixed auto security group for nova network,MERGED,2014-11-25 20:40:20.000000000,2014-12-12 22:05:59.000000000,2014-12-12 22:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 9740}, {'_account_id': 10670}, {'_account_id': 12039}, {'_account_id': 13662}]","[{'number': 1, 'created': '2014-11-25 20:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0f49f05c34261ce6153e7440b2bee7939b07baaf', 'message': ""Fixed auto security group for nova network\n\nReplaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.\nAWS::EC2::SecurityGroup supports both neutron and nova network.\nWe don't use neutron-specific instructions.\n\nChange-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a\nCloses-Bug: #1392738\n""}, {'number': 2, 'created': '2014-11-26 17:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8d4a80e30222cd64f81a63991e2bc2acab95971d', 'message': ""Fixed auto security group for nova network\n\nReplaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.\nAWS::EC2::SecurityGroup supports both neutron and nova network.\nWe don't use neutron-specific instructions.\n\nEnabled auto security group in integration tests for hdp2 plugin.\n\nChange-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a\nCloses-Bug: #1392738\n""}, {'number': 3, 'created': '2014-12-01 18:15:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/471f0700e3576e6967e3d4fe41fed0b5dab152e6', 'message': ""Fixed auto security group for nova network\n\nReplaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.\nAWS::EC2::SecurityGroup supports both neutron and nova network.\nWe don't use neutron-specific instructions.\n\nEnabled auto security group in integration tests for hdp2 plugin.\n\nIncreased version of heat engine.\n\nChange-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a\nCloses-Bug: #1392738\n""}, {'number': 4, 'created': '2014-12-02 23:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/97fc1d6757954b7762317e5b0d6801f8d3266375', 'message': ""Fixed auto security group for nova network\n\nReplaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.\nAWS::EC2::SecurityGroup supports both neutron and nova network.\nWe don't use neutron-specific instructions.\n\nEnabled auto security group in integration tests for hdp2 plugin.\n\nIncreased version of heat engine.\n\nChange-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a\nCloses-Bug: #1392738\n""}, {'number': 5, 'created': '2014-12-08 18:56:00.000000000', 'files': ['sahara/utils/openstack/heat.py', 'sahara/tests/integration/tests/gating/test_hdp2_gating.py', 'sahara/service/heat_engine.py', 'sahara/resources/security_group.heat'], 'web_link': 'https://opendev.org/openstack/sahara/commit/23a49916206e591588d1b68cc6c343c09060160a', 'message': ""Fixed auto security group for nova network\n\nReplaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.\nAWS::EC2::SecurityGroup supports both neutron and nova network.\nWe don't use neutron-specific instructions.\n\nEnabled auto security group in integration tests for hdp2 plugin.\n\nIncreased version of heat engine.\n\nChange-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a\nCloses-Bug: #1392738\nCloses-Bug: #1400352""}]",0,137201,23a49916206e591588d1b68cc6c343c09060160a,69,14,5,8411,,,0,"Fixed auto security group for nova network

Replaced OS::Neutron::SecurityGroup with AWS::EC2::SecurityGroup.
AWS::EC2::SecurityGroup supports both neutron and nova network.
We don't use neutron-specific instructions.

Enabled auto security group in integration tests for hdp2 plugin.

Increased version of heat engine.

Change-Id: Id5159c54ad83fd86887f9b718b7545603467bb9a
Closes-Bug: #1392738
Closes-Bug: #1400352",git fetch https://review.opendev.org/openstack/sahara refs/changes/01/137201/4 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/utils/openstack/heat.py', 'sahara/resources/security_group.heat']",2,0f49f05c34261ce6153e7440b2bee7939b07baaf,bug/1392738," ""%(security_group_name)s"": { ""Type"": ""AWS::EC2::SecurityGroup"", ""Properties"": { ""GroupDescription"": ""%(security_group_description)s"", ""SecurityGroupIngress"": %(rules)s"," ""%(security_group_name)s"": { ""Type"": ""OS::Neutron::SecurityGroup"", ""Properties"": { ""description"": ""%(security_group_description)s"", ""name"": ""%(security_group_name)s"", ""rules"": %(rules)s",11,9
openstack%2Frequirements~master~I3912eb965359f1aa29b9313218924ceabd5d839e,openstack/requirements,master,I3912eb965359f1aa29b9313218924ceabd5d839e,Upgrade oslo.vmware>=0.8.0,MERGED,2014-12-11 16:50:20.000000000,2014-12-12 22:05:56.000000000,2014-12-12 22:05:55.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 7575}]","[{'number': 1, 'created': '2014-12-11 16:50:20.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/aface52c8a3063c0b5cda5dade2abc4d96cfb1a2', 'message': 'Upgrade oslo.vmware>=0.8.0\n\nThis release includes several bug fixes (https://launchpad.net/oslo.vmware/+milestone/0.8.0)\nas well as many other changes:\n\n969bfba Switch to use requests/urllib3 and enable cacert validation\n5b9408f Updated from global requirements\n9d9bf2f Updated from global requirements\n1ebbc4d Enable support for python 3.x\n4dc0ded Updated from global requirements\n589ba43 Activate pep8 check that _ is imported\n\nChange-Id: I3912eb965359f1aa29b9313218924ceabd5d839e\n'}]",0,141099,aface52c8a3063c0b5cda5dade2abc4d96cfb1a2,10,5,1,1653,,,0,"Upgrade oslo.vmware>=0.8.0

This release includes several bug fixes (https://launchpad.net/oslo.vmware/+milestone/0.8.0)
as well as many other changes:

969bfba Switch to use requests/urllib3 and enable cacert validation
5b9408f Updated from global requirements
9d9bf2f Updated from global requirements
1ebbc4d Enable support for python 3.x
4dc0ded Updated from global requirements
589ba43 Activate pep8 check that _ is imported

Change-Id: I3912eb965359f1aa29b9313218924ceabd5d839e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/99/141099/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,aface52c8a3063c0b5cda5dade2abc4d96cfb1a2,oslo-0.8.0,oslo.vmware>=0.8.0 # Apache-2.0,oslo.vmware>=0.7.0 # Apache-2.0,1,1
openstack%2Frequirements~master~I5e3e1cd630505f735fa3c8a25a872769db48ff3b,openstack/requirements,master,I5e3e1cd630505f735fa3c8a25a872769db48ff3b,Updating python-glanceclient to 0.15.0 release,MERGED,2014-12-12 08:08:52.000000000,2014-12-12 22:05:45.000000000,2014-12-12 22:05:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6159}, {'_account_id': 6786}, {'_account_id': 7665}, {'_account_id': 7680}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-12-12 08:08:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/44941d7f4603c56988c73d809fe112a7f48fb435', 'message': 'Updating to the 0.15.0 relese\n\nPrimarily, this addresses some forward compatibility\nAPI changes happening in the Glance service. Without this\nrelease, devstack deployments will have errors using the\nv2 API due to patches added in Kilo.\n\nIn addition it contains patches that both Nova and Horizon\nrequired.\n\nRelease notes: https://review.openstack.org/#/c/140079/\nOther Release notes since the requirements were last\nupdated:\nhttps://review.openstack.org/#/c/135267/\n\nChange-Id: I5e3e1cd630505f735fa3c8a25a872769db48ff3b\n'}, {'number': 2, 'created': '2014-12-12 15:49:38.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/68920d14e197c9507740e40e539eedef2cad8964', 'message': 'Updating python-glanceclient to 0.15.0 release\n\nPrimarily, this addresses some forward compatibility\nAPI changes happening in the Glance service. Without this\nrelease, devstack deployments will have errors using the\nv2 API due to patches added in Kilo.\n\nIn addition it contains patches that both Nova and Horizon\nrequired.\n\nRelease notes: https://review.openstack.org/#/c/140079/\nOther Release notes since the requirements were last\nupdated:\nhttps://review.openstack.org/#/c/135267/\n\nChange-Id: I5e3e1cd630505f735fa3c8a25a872769db48ff3b\n'}]",2,141298,68920d14e197c9507740e40e539eedef2cad8964,14,7,2,7665,,,0,"Updating python-glanceclient to 0.15.0 release

Primarily, this addresses some forward compatibility
API changes happening in the Glance service. Without this
release, devstack deployments will have errors using the
v2 API due to patches added in Kilo.

In addition it contains patches that both Nova and Horizon
required.

Release notes: https://review.openstack.org/#/c/140079/
Other Release notes since the requirements were last
updated:
https://review.openstack.org/#/c/135267/

Change-Id: I5e3e1cd630505f735fa3c8a25a872769db48ff3b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/141298/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,44941d7f4603c56988c73d809fe112a7f48fb435,,python-glanceclient>=0.15.0,python-glanceclient>=0.14.0,1,1
openstack%2Fhorizon~master~I5ec4d28a26cfed6e7eaef783a0d5b17762fd75d5,openstack/horizon,master,I5ec4d28a26cfed6e7eaef783a0d5b17762fd75d5,Enable tables inline-editing in lazy-loaded tabs,MERGED,2014-11-28 13:55:45.000000000,2014-12-12 22:04:01.000000000,2014-12-12 22:04:00.000000000,"[{'_account_id': 3}, {'_account_id': 2455}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 7213}, {'_account_id': 8040}, {'_account_id': 11880}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-11-28 13:55:45.000000000', 'files': ['horizon/static/horizon/js/horizon.tabs.js', 'horizon/static/horizon/js/horizon.tables_inline_edit.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2eb96431813cd63d56c221f51bd8604b5d1ef5ed', 'message': 'Enable tables inline-editing in lazy-loaded tabs\n\nPreviously inline-edit was initialized only the first time the page\nwas loaded which had been preventing inline-edit for the tables which\nwere inside lazy-loaded tabs (i.e. loaded with AJAX-request). Fixed\nthat.\n\nChange-Id: I5ec4d28a26cfed6e7eaef783a0d5b17762fd75d5\nCloses-Bug: #1389437\n'}]",0,137790,2eb96431813cd63d56c221f51bd8604b5d1ef5ed,13,8,1,8040,,,0,"Enable tables inline-editing in lazy-loaded tabs

Previously inline-edit was initialized only the first time the page
was loaded which had been preventing inline-edit for the tables which
were inside lazy-loaded tabs (i.e. loaded with AJAX-request). Fixed
that.

Change-Id: I5ec4d28a26cfed6e7eaef783a0d5b17762fd75d5
Closes-Bug: #1389437
",git fetch https://review.opendev.org/openstack/horizon refs/changes/90/137790/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/horizon/js/horizon.tabs.js', 'horizon/static/horizon/js/horizon.tables_inline_edit.js']",2,2eb96431813cd63d56c221f51bd8604b5d1ef5ed,bug/1389437,"horizon.addInitFunction(horizon.inline_edit.init = function(parent) { parent = parent || document; var $table = $(parent).find('table'); $table.on('click', '.ajax-inline-edit', function (evt) { $table.on('click', '.inline-edit-submit', function (evt) { $table.on('keypress', '.inline-edit-form', function (evt) { $table.on('click', '.inline-edit-cancel', function (evt) { $table.on('mouseenter', '.inline_edit_available', function (evt) { $table.on('mouseleave', '.inline_edit_available', function (evt) {","horizon.addInitFunction(horizon.inline_edit.init = function() { $('table').on('click', '.ajax-inline-edit', function (evt) { $('table').on('click', '.inline-edit-submit', function (evt) { $('table').on('keypress', '.inline-edit-form', function (evt) { $('table').on('click', '.inline-edit-cancel', function (evt) { $('table').on('mouseenter', '.inline_edit_available', function (evt) { $('table').on('mouseleave', '.inline_edit_available', function (evt) {",12,7
openstack%2Fmurano~master~I6799463737557a7c94f271019ae6f994d02e582a,openstack/murano,master,I6799463737557a7c94f271019ae6f994d02e582a,[DONT MERGE] Remove postgres app tests,ABANDONED,2014-12-12 21:46:30.000000000,2014-12-12 22:02:59.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-12 21:46:30.000000000', 'files': ['murano/tests/functional/engine/base.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/390ff4e9da812d8a284826a2c76e36e7ba8d3ab9', 'message': '[DONT MERGE] Remove postgres app tests\n\nChange-Id: I6799463737557a7c94f271019ae6f994d02e582a\n'}]",0,141499,390ff4e9da812d8a284826a2c76e36e7ba8d3ab9,5,2,1,7600,,,0,"[DONT MERGE] Remove postgres app tests

Change-Id: I6799463737557a7c94f271019ae6f994d02e582a
",git fetch https://review.opendev.org/openstack/murano refs/changes/99/141499/1 && git format-patch -1 --stdout FETCH_HEAD,['murano/tests/functional/engine/base.py'],1,390ff4e9da812d8a284826a2c76e36e7ba8d3ab9,,," 'PostgreSQL', {""categories"": [""Databases""], ""tags"": [""tag""]}, os.path.join(cls.pkgs_path, 'io.murano.databases.PostgreSql.zip') ) upload_package( def test_deploy_postgresql(self): post_body = { ""instance"": { ""flavor"": ""m1.medium"", ""image"": self.linux, ""assignFloatingIp"": True, ""?"": { ""type"": ""io.murano.resources.LinuxMuranoInstance"", ""id"": str(uuid.uuid4()) }, ""name"": ""testMurano"" }, ""name"": ""teMurano"", ""database"": ""test_db"", ""username"": ""test_usr"", ""password"": ""test_pass"", ""?"": { ""type"": ""io.murano.databases.PostgreSql"", ""id"": str(uuid.uuid4()) } } environment_name = 'Postgreenv' + uuid.uuid4().hex[:5] env = self._quick_deploy(environment_name, post_body) self.deployment_success_check(env, 5432)",0,32
openstack%2Fneutron-specs~master~Ia2e21972c35db043301ffbdbf372d01add7ec099,openstack/neutron-specs,master,Ia2e21972c35db043301ffbdbf372d01add7ec099,Spec for converting from ovs-vsctl calls to OVSDB,MERGED,2014-12-09 00:26:51.000000000,2014-12-12 21:58:17.000000000,2014-12-12 21:58:17.000000000,"[{'_account_id': 3}, {'_account_id': 162}, {'_account_id': 333}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 5756}, {'_account_id': 6854}]","[{'number': 1, 'created': '2014-12-09 00:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e5cb90be1d325dca548de5b42eccbbaf73f61198', 'message': 'Spec for converting from ovs-vsctl calls to OVSDB\n\nChange-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099\n'}, {'number': 2, 'created': '2014-12-10 00:34:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f38dca6e1876258897f7c738bd9db9981c581a6e', 'message': 'Spec for converting from ovs-vsctl calls to OVSDB\n\nChange-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099\n'}, {'number': 3, 'created': '2014-12-10 22:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8bd4f71b5dd39897857085ea568d9a5972b49588', 'message': 'Spec for converting from ovs-vsctl calls to OVSDB\n\nChange-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099\n'}, {'number': 4, 'created': '2014-12-12 20:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/be6f97a30dcff128d53e23358c93cba14397a0e3', 'message': 'Spec for converting from ovs-vsctl calls to OVSDB\n\nChange-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099\n'}, {'number': 5, 'created': '2014-12-12 21:29:39.000000000', 'files': ['specs/kilo/vsctl-to-ovsdb.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/81f5a1e101f5a7fff809fed04963c1bf06f0d94f', 'message': 'Spec for converting from ovs-vsctl calls to OVSDB\n\nChange-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099\n'}]",32,140185,81f5a1e101f5a7fff809fed04963c1bf06f0d94f,30,7,5,5756,,,0,"Spec for converting from ovs-vsctl calls to OVSDB

Change-Id: Ia2e21972c35db043301ffbdbf372d01add7ec099
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/85/140185/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/vsctl-to-ovsdb.rst'],1,e5cb90be1d325dca548de5b42eccbbaf73f61198,bp/vsctl-to-ovsdb,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================== Use OVSDB instead of calling ovs-vsctl ====================================== Problem Description =================== Neutron's ovs_lib uses the Open vSwitch CLI command *ovs-vsctl* to perform basic vSwitch CRUD operations. This is almost an order of magnitude slower than using either direct OVSDB protocol commands, or using the Open vSwitch Python API. Proposed Change =============== First, an interface for interacting with with the OVSDB should be defined as an abstract base class. Then, an implementation of this interface using ovs-vsctl calls should be made and ovs_lib should make all ovsdb-related calls through this new implementation. Next, an implementation of the OVSDB interface should be implemented using the Open vSwitch IDL Python library. A configuration option will be added to allow selection of the OVSDB interface to use. It is necessary to allow this choice as there are differences in how privileges will be handled between the two OVSDB implementations. The ovs-vsctl implemenation uses sudo/rootwrap whereas the IDL library will require either specifically giving the neutron user permissions to the ovsdb unix socket, or using TCP/SSL sockets and controlling access via firewall rules (though likely just using the loopback interface). This will allow leaving the ovs_lib API largely unchanged. On a simple test creating and deleting 100 ports on an existing bridge, the current ovs_lib implementation was nearly 10x slower than using the OVS Python API. It should be noted that ovs_lib was over 100x slower than sending raw OVSDB commands to Open vSwitch. The performance disparity between the raw OVSDB and existing OVS Python API is due to the poor performance of the OVS Python API's own pure-Python JSON parser which tests show to be ~30x slower than Python's stdlib JSON parser which, unfortuanately, is not a good fit for OVS's use case as it is a pull-parser. Significant potential speedups are possible in OVS's JSON parser by writing an extension that adds Python bindings to the C version of their parser. The OVS IDL implementation makes use of monitor commands for syncing a local cache of the OVSDB. Unfortunately, it does not make these monitor events available to users of the library. To replace ovsdb-monitor, it will be necessary to either use a lower-level Open vSwitch API running an additional monitor request to get these event notifications, to modify the IDL library at runtime, or to try to get code merged to the upstream Open vSwitch library that optionally exposes these events. Data Model Impact ----------------- n/a REST API Impact --------------- n/a Security Impact --------------- The existing implementation handles privileges via sudo/rootwrap. The proposed change would be using a programatic API and would instead rely on the appropriate permissions being set on underlying Open vSwitch unix domain socket or through the use of Open vSwitch's SSL authentication. Notifications Impact -------------------- n/a Other End User Impact --------------------- n/a Performance Impact ------------------ With no changes to the upstream OVS Python API, a 6-7x speed improvement is possible. With Python bindings to the OVS C JSON parser, it should be possible to approach the native OVSDB protocol performance which was 100x faster than the current ovs_lib. IPv6 Impact ----------- n/a Other Deployer Impact --------------------- Repeating from the Security section, deployers would have to ensure that the *neutron* user has r/w permissions to the Open vSwitch db.sock. A new config option specifying the connection string for ovs-server would also be required. Packagers will need to add a dependency for python-openvswitch (which seems to be readily available across common distributions as it is part of standard openvswitch packaging). Developer Impact ---------------- For the initial implementation, there shouldn't be any change to ovs_lib's public-facing API, though many of the unit tests will have to be changed because they are tied far too heavily to specific implementation details, mocking out calls to ovs-vsctl, etc. Community Impact ---------------- n/a Alternatives ------------ It would be possible to write our own library around the OVSDB protocol. It would most likely be faster, but it would most likely end up looking very much like the OVS Python API by the time we were finished. Implementation ============== Assignee(s) ----------- otherwiseguy Work Items ---------- * Convert existing OVS unit tests that deal entirely with external Open vSwitch actions to functional tests. * Convert existing ovs-vsctl calls to the equivalent OVS Python API calls * Re-work OVSDB Monitoring to use the OVS Python API * Write Python bindings for OVS's C-based JSON push parser to increase performance Dependencies ============ Adds a requirement for the OVS python bindings Testing ======= Tempest Tests ------------- Existing tempest tests should be useful, but most of the ovs_lib unit tests will need to be removed as they don't test anything but the implementation details. Functional Tests ---------------- Functional tests that actually test the CRUD operations against a real Open vSwitch installation should be created. They should work against both OVSDB interface implementations. API Tests --------- n/a Documentation Impact ==================== User Documentation ------------------ Documentation of the new config option and security considerations will be necessary. Developer Documentation ----------------------- The OVSDB abstract base class should be well-documented. References ========== http://tools.ietf.org/html/draft-pfaff-ovsdb-proto-04 https://github.com/openvswitch/ovs/tree/master/python/ovs ",,177,0
openstack%2Fpython-cinderclient~master~Ie99c671cbfdaed01715046ea65d49e09114b1e08,openstack/python-cinderclient,master,Ie99c671cbfdaed01715046ea65d49e09114b1e08,Fix comment in tearDown(),MERGED,2014-07-23 12:33:46.000000000,2014-12-12 21:54:33.000000000,2014-12-12 21:54:32.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5538}, {'_account_id': 7219}]","[{'number': 1, 'created': '2014-07-23 12:33:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/2836205085ff0a0334fbf2cca14ff828069d9c3b', 'message': 'Fix comment in tearDown()\n\nThis minor change fixes two typos and adds a missing comma to the\ncomment specified in the tearDown() method.\n\nChange-Id: Ie99c671cbfdaed01715046ea65d49e09114b1e08\n'}, {'number': 2, 'created': '2014-07-23 12:35:33.000000000', 'files': ['cinderclient/tests/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/cebd81ef9b71982121703da15fdcd584662a103a', 'message': 'Fix comment in tearDown()\n\nThis minor change fixes two typos in the tearDown() method.\n\nChange-Id: Ie99c671cbfdaed01715046ea65d49e09114b1e08\n'}]",1,108976,cebd81ef9b71982121703da15fdcd584662a103a,12,5,2,7307,,,0,"Fix comment in tearDown()

This minor change fixes two typos in the tearDown() method.

Change-Id: Ie99c671cbfdaed01715046ea65d49e09114b1e08
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/76/108976/2 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/tests/v2/test_shell.py'],1,2836205085ff0a0334fbf2cca14ff828069d9c3b,fix_typo," # For some methods like test_image_meta_bad_action we are # no time to get instantiated, which is OK in this case, so"," # For some method like test_image_meta_bad_action we are # no time to get instantatiated which is OK in this case, so",2,2
openstack%2Fcookbook-openstack-network~master~I5c2546481f753576e8b01f7a2f2815397af68b75,openstack/cookbook-openstack-network,master,I5c2546481f753576e8b01f7a2f2815397af68b75,This adds descriptions to the rake tasks,MERGED,2014-11-30 20:16:51.000000000,2014-12-12 21:36:39.000000000,2014-12-12 21:36:37.000000000,"[{'_account_id': 3}, {'_account_id': 7128}, {'_account_id': 12588}]","[{'number': 1, 'created': '2014-11-30 20:16:51.000000000', 'files': ['Rakefile'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-network/commit/fef28e886f3da0b00ab3e1e8643792966e55680f', 'message': 'This adds descriptions to the rake tasks\n\nThis adds the descriptions to the rake tasks so you can now\ndo rake -T to see the option you have to run.\n\nChange-Id: I5c2546481f753576e8b01f7a2f2815397af68b75\nCloses-Bug: 1397722\n'}]",0,137975,fef28e886f3da0b00ab3e1e8643792966e55680f,8,3,1,12323,,,0,"This adds descriptions to the rake tasks

This adds the descriptions to the rake tasks so you can now
do rake -T to see the option you have to run.

Change-Id: I5c2546481f753576e8b01f7a2f2815397af68b75
Closes-Bug: 1397722
",git fetch https://review.opendev.org/openstack/cookbook-openstack-network refs/changes/75/137975/1 && git format-patch -1 --stdout FETCH_HEAD,['Rakefile'],1,fef28e886f3da0b00ab3e1e8643792966e55680f,bug/1397722,"desc ""Bundler preparation""desc ""Bershelf preparation""desc ""Foodcritic linting""desc ""Rubocop style checking""desc ""Unit testing""desc ""Clean up working directory""",,6,0
openstack%2Fpython-cinderclient~master~If7f1765017f3f0d55975219b12ff7bf149146931,openstack/python-cinderclient,master,If7f1765017f3f0d55975219b12ff7bf149146931,Remove cinderclient/tests from coverage report,MERGED,2014-11-25 15:17:37.000000000,2014-12-12 21:36:24.000000000,2014-12-12 21:36:23.000000000,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 7219}, {'_account_id': 11600}, {'_account_id': 11904}]","[{'number': 1, 'created': '2014-11-25 15:17:37.000000000', 'files': ['.coveragerc'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/ac9ef2bd129f449df0005cb2a8c10d2d9cdf452e', 'message': 'Remove cinderclient/tests from coverage report\n\nCurrently coverage reports on coverage of the tests themselves. This\nmakes the percentage coverage higher than if they are excluded and\ntherefore distorts the reports values for the codes as a whole.\n\nThis commit updates the .coveragerc files to remove\ncinderclient/tests/* from the coverage report.\n\nChange-Id: If7f1765017f3f0d55975219b12ff7bf149146931\n'}]",0,137095,ac9ef2bd129f449df0005cb2a8c10d2d9cdf452e,15,7,1,7219,,,0,"Remove cinderclient/tests from coverage report

Currently coverage reports on coverage of the tests themselves. This
makes the percentage coverage higher than if they are excluded and
therefore distorts the reports values for the codes as a whole.

This commit updates the .coveragerc files to remove
cinderclient/tests/* from the coverage report.

Change-Id: If7f1765017f3f0d55975219b12ff7bf149146931
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/95/137095/1 && git format-patch -1 --stdout FETCH_HEAD,['.coveragerc'],1,ac9ef2bd129f449df0005cb2a8c10d2d9cdf452e,coverage,"omit = cinderclient/openstack/*,cinderclient/tests/*",omit = cinderclient/openstack/*,1,1
openstack%2Fmagnum~master~Iabd7f5f1217402c18820170521354ac04e436551,openstack/magnum,master,Iabd7f5f1217402c18820170521354ac04e436551,Knitting Pod and Service object flow for Kubernetes backend,MERGED,2014-12-12 19:50:56.000000000,2014-12-12 21:07:25.000000000,2014-12-12 21:07:25.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6924}]","[{'number': 1, 'created': '2014-12-12 19:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d163f44f5b79a0fd45dabe6c49d2f0b649fa6d32', 'message': 'Knitting Pod and Service object flow for Kubernetes backend\n\nGet the work flow in place for pods and services to use rpc\nbackend and integrate kube handlers.\n\nPartially-Implements: blueprint magnum-backend-kubernetes\n\nChange-Id: Iabd7f5f1217402c18820170521354ac04e436551\n'}, {'number': 2, 'created': '2014-12-12 20:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6fa7ffe5aa32d0b13ec769c268e26a8a88a63733', 'message': 'Knitting Pod and Service object flow for Kubernetes backend\n\nGet the work flow in place for pods and services to use rpc\nbackend and integrate kube handlers.\n\nPartially-Implements: blueprint magnum-backend-kubernetes\n\nChange-Id: Iabd7f5f1217402c18820170521354ac04e436551\n'}, {'number': 3, 'created': '2014-12-12 20:33:41.000000000', 'files': ['magnum/conductor/api.py', 'magnum/tests/api/controllers/v1/test_all_objects.py', 'magnum/api/controllers/v1/pod.py', 'magnum/conductor/kubecli.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/209a639ba1e97acd069c360da851b9524ad2d077', 'message': 'Knitting Pod and Service object flow for Kubernetes backend\n\nGet the work flow in place for pods and services to use rpc\nbackend and integrate kube handlers.\n\nPartially-Implements: blueprint magnum-backend-kubernetes\n\nChange-Id: Iabd7f5f1217402c18820170521354ac04e436551\n'}]",2,141476,209a639ba1e97acd069c360da851b9524ad2d077,15,3,3,6924,,,0,"Knitting Pod and Service object flow for Kubernetes backend

Get the work flow in place for pods and services to use rpc
backend and integrate kube handlers.

Partially-Implements: blueprint magnum-backend-kubernetes

Change-Id: Iabd7f5f1217402c18820170521354ac04e436551
",git fetch https://review.opendev.org/openstack/magnum refs/changes/76/141476/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/api.py', 'magnum/api/controllers/v1/pod.py', 'magnum/tests/api/controllers/v1/test_all_objects.py', 'magnum/api/controllers/v1/service.py', 'magnum/conductor/handlers/kube.py', 'magnum/conductor/kubecli.py']",6,d163f44f5b79a0fd45dabe6c49d2f0b649fa6d32,bp/magnum-backend-kubernetes,"class KubeClient(object): super(KubeClient, self).__init__() # TODO: Add server endpoint config def service_create(service): LOG.debug(""service_create with contents %s"" % service) try: out, err = utils.trycmd('kubectl', 'create', '-f', service) due to error %s"" % (service, e))","class Handler(object): super(Handler, self).__init__() def service_create(uuid, contents): LOG.debug(""service_create %s contents %s"" % (uuid, contents)) try: out, err = utils.trycmd('kubectl', 'create', '-f', contents) due to error %s"" % (contents, e))",271,109
openstack%2Fproject-config~master~I69e8506022d395caf9780d5d3d2effa40de7e415,openstack/project-config,master,I69e8506022d395caf9780d5d3d2effa40de7e415,Dogfood swift logs with infra jobs,MERGED,2014-12-12 02:47:32.000000000,2014-12-12 20:51:10.000000000,2014-12-12 20:51:09.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-12 02:47:32.000000000', 'files': ['jenkins/jobs/infra.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9a45db8c90fc38a17c3f287ad40b8bf5dc6dc688', 'message': 'Dogfood swift logs with infra jobs\n\nDisable log publishers other than swift to dogfood moving over to\nswift for our log storage needs.\n\nChange-Id: I69e8506022d395caf9780d5d3d2effa40de7e415\n'}]",0,141250,9a45db8c90fc38a17c3f287ad40b8bf5dc6dc688,11,6,1,7069,,,0,"Dogfood swift logs with infra jobs

Disable log publishers other than swift to dogfood moving over to
swift for our log storage needs.

Change-Id: I69e8506022d395caf9780d5d3d2effa40de7e415
",git fetch https://review.opendev.org/openstack/project-config refs/changes/50/141250/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/infra.yaml'],1,9a45db8c90fc38a17c3f287ad40b8bf5dc6dc688,dogfood_swift_logs,, - console-log - console-log - console-log - console-log - console-log - console-log - console-log - console-log,0,8
openstack%2Fproject-config~master~I5bb41da4310434785f42bbaca1d2607b1b3d7895,openstack/project-config,master,I5bb41da4310434785f42bbaca1d2607b1b3d7895,Introduce openstack-server-release-jobs template,MERGED,2014-12-09 13:35:22.000000000,2014-12-12 20:50:18.000000000,2014-12-12 20:50:17.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-09 13:35:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/35df08e408c5bc080ab87dca0aa4b8087a474edd', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThis change adds  merge-release-tags for barbican, kite, zaqar.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}, {'number': 2, 'created': '2014-12-09 13:48:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d2d973f8895cf1516c61d5bf152ec1010d2101a7', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThe effective change of the configuration is an added\nmerge-release-tag for kite.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}, {'number': 3, 'created': '2014-12-09 13:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/20f3c63c2e58a7456c00b6499aa9b40644de593d', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThe effective change of the configuration is an added\nmerge-release-tag for kite.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}, {'number': 4, 'created': '2014-12-09 13:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/4bdeebedd7b91b50220579b5793dc25be443e709', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThe effective change of the configuration is an added\nmerge-release-tag for kite which needed an adjustment in projects.yaml\nas well.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}, {'number': 5, 'created': '2014-12-09 14:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/96f32515f7d722f30c86df89338cfa00e9d5e7c2', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThe effective change of the configuration is an added\nmerge-release-tag for kite which needed an adjustment in projects.yaml\nas well.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}, {'number': 6, 'created': '2014-12-12 17:31:23.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e84d23312e5c3d950e40934f76f4fbd786b55388', 'message': 'Introduce openstack-server-release-jobs template\n\nAdd a new template for server projects that contains the usual release\nsteps.\n\nThe effective change of the configuration is an added\nmerge-release-tag for kite which needed an adjustment in projects.yaml\nas well.\n\nChange-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895\n'}]",0,140326,e84d23312e5c3d950e40934f76f4fbd786b55388,16,3,6,6547,,,0,"Introduce openstack-server-release-jobs template

Add a new template for server projects that contains the usual release
steps.

The effective change of the configuration is an added
merge-release-tag for kite which needed an adjustment in projects.yaml
as well.

Change-Id: I5bb41da4310434785f42bbaca1d2607b1b3d7895
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/140326/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,35df08e408c5bc080ab87dca0aa4b8087a474edd,fix-designate-jobs, # Release OpenStack Server packages. - name: openstack-server-release-jobs pre-release: - '{name}'-tarball release: - '{name}'-tarball - '{name}'-merge-release-tags - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs - name: openstack-server-release-jobs, pre-release: - barbican-tarball release: - barbican-tarball pre-release: - ceilometer-tarball release: - ceilometer-tarball - ceilometer-merge-release-tags pre-release: - cinder-tarball release: - cinder-tarball - cinder-merge-release-tags pre-release: - designate-tarball release: - designate-tarball - designate-merge-release-tags pre-release: - glance-tarball release: - glance-tarball - glance-merge-release-tags pre-release: - heat-tarball release: - heat-tarball - heat-merge-release-tags pre-release: - horizon-tarball release: - horizon-tarball - horizon-merge-release-tags pre-release: - ironic-tarball release: - ironic-tarball - ironic-merge-release-tags pre-release: - keystone-tarball release: - keystone-tarball - keystone-merge-release-tags pre-release: - kite-tarball release: - kite-tarball pre-release: - manila-tarball release: - manila-tarball - manila-merge-release-tags pre-release: - neutron-tarball release: - neutron-tarball - neutron-merge-release-tags pre-release: - nova-tarball release: - nova-tarball - nova-merge-release-tags release: - sahara-merge-release-tags pre-release: - swift-tarball release: - swift-tarball - swift-merge-release-tags pre-release: - trove-tarball release: - trove-tarball - trove-merge-release-tags pre-release: - zaqar-tarball release: - zaqar-tarball,25,79
openstack%2Fproject-config~master~Ib04e8dda5050ae0138fba248ff28f35819fdf254,openstack/project-config,master,Ib04e8dda5050ae0138fba248ff28f35819fdf254,Stop defaulting node builds to Puppet 2,MERGED,2014-12-12 15:25:05.000000000,2014-12-12 20:23:22.000000000,2014-12-12 20:23:21.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}]","[{'number': 1, 'created': '2014-12-12 15:25:05.000000000', 'files': ['nodepool/scripts/prepare_node.sh', 'nodepool/elements/puppet/install.d/05-puppet'], 'web_link': 'https://opendev.org/openstack/project-config/commit/83a1658a0463857594e57183f22837fa309314fe', 'message': ""Stop defaulting node builds to Puppet 2\n\nWe're done with the Puppet 2-to-3 migration, so we no longer need to\nexplicitly override the puppet version to 2 when bootstrapping.\n\nChange-Id: Ib04e8dda5050ae0138fba248ff28f35819fdf254\n""}]",0,141403,83a1658a0463857594e57183f22837fa309314fe,11,6,1,5263,,,0,"Stop defaulting node builds to Puppet 2

We're done with the Puppet 2-to-3 migration, so we no longer need to
explicitly override the puppet version to 2 when bootstrapping.

Change-Id: Ib04e8dda5050ae0138fba248ff28f35819fdf254
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/141403/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/scripts/prepare_node.sh', 'nodepool/elements/puppet/install.d/05-puppet']",2,83a1658a0463857594e57183f22837fa309314fe,unbreak-puppet,,export PUPPET_VERSION=${PUPPET_VERSION:-'2'},0,3
openstack%2Ftelemetry-specs~master~I558614bc2494478e71d4d0cd54da918d77472621,openstack/telemetry-specs,master,I558614bc2494478e71d4d0cd54da918d77472621,configuration via data store,MERGED,2014-10-09 00:39:37.000000000,2014-12-12 20:18:57.000000000,2014-12-12 20:18:54.000000000,"[{'_account_id': 3}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6484}, {'_account_id': 6537}, {'_account_id': 7049}, {'_account_id': 7052}, {'_account_id': 7336}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-10-09 00:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/8cff60e9e0278c2cd789f1cfc5e9758c9ca94417', 'message': 'configuration via data store\n\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 2, 'created': '2014-10-09 00:43:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/23e759a191ca5d640a7862926262fc41445007ed', 'message': 'configuration via data store\n\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 3, 'created': '2014-10-09 00:44:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/2102e6fae60a437f0e43fc7a86721c0c9f2c536d', 'message': 'configuration via data store\n\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 4, 'created': '2014-11-04 23:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/505b5083da794595c76e1a3180b04b1895ad7d5e', 'message': 'configuration via data store\n\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 5, 'created': '2014-11-24 17:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/89bf449046c289cba47142c21f1db3d9965ed2ae', 'message': 'configuration via data store\n\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 6, 'created': '2014-11-25 22:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/d0e912d3f816b60033de0715e90fb8095b6098e1', 'message': 'configuration via data store\n\nMigrating the configuration options to a data store to support increasingly\ncomplex option combinations and lay the foundation for on-the-fly configuration\nupdates.\n\nblueprint ceilometer-configuration-via-data-store\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 7, 'created': '2014-12-01 18:02:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/8f8fcc063b76e1269535a98f4a62f0e3d937a28c', 'message': 'configuration via data store\n\nMigrating the configuration options to a data store to support increasingly\ncomplex option combinations and lay the foundation for on-the-fly configuration\nupdates.\n\nblueprint ceilometer-configuration-via-data-store\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 8, 'created': '2014-12-01 20:18:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/013f6514d349cd15fed26ea91f3d021c945054ea', 'message': 'configuration via data store\n\nMigrating the configuration options to a data store to support increasingly\ncomplex option combinations and lay the foundation for on-the-fly configuration\nupdates.\n\nblueprint ceilometer-configuration-via-data-store\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}, {'number': 9, 'created': '2014-12-10 22:16:24.000000000', 'files': ['specs/kilo/ceilometer-configuration-via-data-store.rst'], 'web_link': 'https://opendev.org/openstack/telemetry-specs/commit/bde03b09cffb15c6901859e14cb58b9ace2d857f', 'message': 'configuration via data store\n\nMigrating the configuration options to a data store to support increasingly\ncomplex option combinations and lay the foundation for on-the-fly configuration\nupdates.\n\nblueprint ceilometer-configuration-via-data-store\nChange-Id: I558614bc2494478e71d4d0cd54da918d77472621\n'}]",33,127086,bde03b09cffb15c6901859e14cb58b9ace2d857f,42,10,9,7336,,,0,"configuration via data store

Migrating the configuration options to a data store to support increasingly
complex option combinations and lay the foundation for on-the-fly configuration
updates.

blueprint ceilometer-configuration-via-data-store
Change-Id: I558614bc2494478e71d4d0cd54da918d77472621
",git fetch https://review.opendev.org/openstack/telemetry-specs refs/changes/86/127086/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/ceilometer-configuration-via-data-store.rst'],1,8cff60e9e0278c2cd789f1cfc5e9758c9ca94417,bp/ceilometer-configuration-via-data-store,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Configuration via Data Store ============================ https://blueprints.launchpad.net/ceilometer/+spec/ceilometer-configuration-via-data-store By updating Ceilometer to monitor values recorded in a persistent data store such as MySQL, the application could be made to dynamically activate/deactivate collection targets or similar functions, have distinctly different configurations for multiple nodes in different environments (i.e. dev/test/prod or HA scenarios) and could ultimately be updated with new collection targets “on-the-fly”. Problem description =================== Currently, Ceilometer relies on multiple configuration files for determining run-time parameters used in polling and notification handling. The current configuration file approach limits the extent to which we can customize Ceilometer functionality (e.g. polling targets, intervals, publishing) and becomes a potential issue in a large-scale deployment. Migrating the configuration options to a data store gives flexibility and lays the foundation for on-the-fly updates to Ceilometer. Proposed change =============== The transition of configuration parameters to a data store can be chunked into three efforts: 1. Migration of pipeline configuration 2. Migration of event traits configuration 3. Migration of general (Oslo) configuration Because there's a significant Oslo project investment in managing the general configuration, we won't attempt to transition that in the Kilo timeframe. The migration of the pipeline configuration and event traits, being limited to Kilo and not having any specific implementation (beyond Pyaml), seem feasible to address. Alternatives ------------ There's no arguing that deployment tools such as Puppet, Chef, etc. support the population of configuration files on a reasonable scale. For small deployments it might be preferable to maintain a file-based configuration. Data model impact ----------------- This will require the addition of multiple table schemas to the Ceilometer data model to handle this ""metadata"". At minimum, there will be one table per configuration type, likely more due to normalization. Alternately, a separate configuration database could be instantiated, with the benefit of providing better segregation of access and support for a multi-node deployment. REST API impact --------------- This configuration data store would require a dedicated set of api requests. Generally modeled on the Alarm api, at minimum the configuration api would consist of: GET /v2/meta/configuration Return all configuration items Parameters: q - Filter rules for items to be returned Return type: list(configuration) POST /v2/meta/configuration Create a new configuration item Parameters: data(configuration) - a configuration within the request body Return type: configuration GET /v2/meta/configuration/(configuration_id) Return this configuration item Return type: configuration PUT /v2/meta/configuration/(configuration_id) Modify this configuration item Parameters: data(configuration) - a configuration within the request body Retun type: configuration Security impact --------------- Data segregation and access control is critical to this change, as this effectively moves an administrative data set into the database and provides api access to it. Pipeline impact --------------- The significant impact to the pipeline will be the (optional) sourcing of configuration data from the database. Other end user impact --------------------- Configuration via the Horizon metering dashboard could be considered for a future iteration. Performance/Scalability Impacts ------------------------------- The absolute number of records in this database should be relatively small, however the number of API requests may be significant. Other deployer impact --------------------- Backwards compatibility with existing configuration files will be required. This will be an explicitly enabled option. Developer impact ---------------- New configuration items would need to be represented in the database, rather than the configuration files. Implementation ============== Assignee(s) ----------- Primary assignee: nealph Other contributors: TBD Ongoing maintainer: nealph Work Items ---------- 1. Database schema design 2. API design 3. Database pre-population, deployment, migration 4. Updates to pipeline to read config via api or natively 5. Tempest tests Future lifecycle ================ We'll want to continue to iterate on this for future cycles to gain additional functionality: Run-time monitoring of config changes Configuration updates from the Horizon dashboard Oslo config migration Dependencies ============ Relates to: https://blueprints.launchpad.net/ceilometer/+spec/dedicated-event-db https://blueprints.launchpad.net/ceilometer/+spec/merge-agent Testing ======= Extensions to Database and API tests should be sufficient for this change Documentation Impact ==================== Documentation will be required/updated for: Configuration api Installation guide References ========== https://etherpad.openstack.org/p/configuration_via_data_store https://wiki.openstack.org/wiki/Ceilometer/blueprints/Configuration-via-data-store ",,195,0
openstack%2Ffuel-docs~stable%2F5.1~I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f,openstack/fuel-docs,stable/5.1,I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f,5.1.1 -- last minute fixes,MERGED,2014-12-09 11:19:43.000000000,2014-12-12 20:15:57.000000000,2014-12-12 20:15:57.000000000,"[{'_account_id': 3}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9788}, {'_account_id': 10014}, {'_account_id': 13082}]","[{'number': 1, 'created': '2014-12-09 11:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/6e46f372d67241a9fc0d17778d7d1139df5de3a2', 'message': '511 -- last minute fixes\n\nA few last-minute fixes to the 5.1.1 docs:\n\nplanning-guide/7000-nsx-plan -- state that NSX is experimental\n\nrelease-notes/020-new-features -- made ""(experimental)"" consistent\nin headers\n\nrelease-notes/050-known-issues -- corrected some syntax in NSX section\n\nterminology/experimental-features -- added xref to planning guide\nfor NSX\n\nChange-Id: I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f\n'}, {'number': 2, 'created': '2014-12-09 11:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/1003beb766762d90c4d524efd3a9328e847110ed', 'message': '5.1.1 -- last minute fixes\n\nA few last-minute fixes to the 5.1.1 docs:\n\nplanning-guide/7000-nsx-plan -- state that NSX is experimental\n\nrelease-notes/020-new-features -- made ""(experimental)"" consistent\nin headers\n\nrelease-notes/050-known-issues -- corrected some syntax in NSX section\n\nterminology/experimental-features -- added xref to planning guide\nfor NSX\n\nChange-Id: I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f\n'}, {'number': 3, 'created': '2014-12-09 19:04:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/e7987508ef1387671fe4ff5cd0a7bdf992901f78', 'message': '5.1.1 -- last minute fixes\n\nA few last-minute fixes to the 5.1.1 docs:\n\nplanning-guide/7000-nsx-plan -- state that NSX is experimental\n\nrelease-notes/020-new-features -- made ""(experimental)"" consistent\nin headers\n\nrelease-notes/050-known-issues -- corrected some syntax in NSX section\n\nterminology/experimental-features -- added xref to planning guide\nfor NSX\n\nChange-Id: I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f\n'}, {'number': 4, 'created': '2014-12-11 00:24:11.000000000', 'files': ['pages/terminology/e/experimental-features.rst', 'pages/planning-guide/7000-nsx-plan.rst', 'pages/release-notes/v5-1/020-new-features.rst', 'pages/release-notes/v5-1/050-known-issues.rst'], 'web_link': 'https://opendev.org/openstack/fuel-docs/commit/5fdfc1bf1e2e0bf2ea790b5e1441b0f68156d663', 'message': '5.1.1 -- last minute fixes\n\nA few last-minute fixes to the 5.1.1 docs:\n\nplanning-guide/7000-nsx-plan -- state that NSX is experimental\n\nrelease-notes/020-new-features -- made ""(experimental)"" consistent\nin headers\n\nrelease-notes/050-known-issues -- corrected some syntax in NSX section\n\nterminology/experimental-features -- added xref to planning guide\nfor NSX\n\nChange-Id: I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f\n'}]",4,140299,5fdfc1bf1e2e0bf2ea790b5e1441b0f68156d663,26,7,4,10014,,,0,"5.1.1 -- last minute fixes

A few last-minute fixes to the 5.1.1 docs:

planning-guide/7000-nsx-plan -- state that NSX is experimental

release-notes/020-new-features -- made ""(experimental)"" consistent
in headers

release-notes/050-known-issues -- corrected some syntax in NSX section

terminology/experimental-features -- added xref to planning guide
for NSX

Change-Id: I350e4bc3b5a8c72442e5b6848a8cebaf0f32167f
",git fetch https://review.opendev.org/openstack/fuel-docs refs/changes/99/140299/4 && git format-patch -1 --stdout FETCH_HEAD,"['pages/terminology/e/experimental-features.rst', 'pages/planning-guide/7000-nsx-plan.rst', 'pages/release-notes/v5-1/020-new-features.rst', 'pages/release-notes/v5-1/050-known-issues.rst']",4,6e46f372d67241a9fc0d17778d7d1139df5de3a2,511-fixes," and replace the old packages with downloaded ones on the Fuel master node. After deployment, run the following command on the controller:* In HA environment with NSX enabled, instances do not receive the network configuration. As a result, the OSTF **Check network connectivity from instance via floating IP** test fails and the Neutron L3 and DHCP agents do not start. To work around this problem, remove Corosync resource bindings (collocations and orders) tied up with *clone_p_neutron-openvswitch-agent*: Then run the **crm configure** command and add Neutron L3-agent location for all controllers. To find the names of the controllers, apply the For sample output, see `LP1396163 <https://bugs.launchpad.net/fuel/+bug/1396163>`_."," and replace the old packages with downloaded ones on the Fuel master node. After deployment, run the following command on the controller:* In HA environment with enabled NSX, instances do not receive the network configuration, As the result, the OSTF **Check network connectivity from instance via floating IP** test fails and Neutron L3 and DHCP agents do not start. To work around this problem, remove Corosync resource bindings (collocations and orders) tied up with *clone_p_neutron-openvswitch-agent*: Then run **crm configure** command and add Neutron L3-agent location for all controllers. To find the names of the controllers, apply For example output, see `LP1396163 <https://bugs.launchpad.net/fuel/+bug/1396163>`_.",24,14
openstack%2Fironic~master~I5076d132b8a715c0d63a8f650704b567abf9161b,openstack/ironic,master,I5076d132b8a715c0d63a8f650704b567abf9161b,Remove unused oslo-incubator modules,ABANDONED,2014-12-12 20:01:18.000000000,2014-12-12 20:10:21.000000000,,[{'_account_id': 12081}],"[{'number': 1, 'created': '2014-12-12 20:01:18.000000000', 'files': ['ironic/tests/drivers/ilo/test_deploy.py', 'ironic/openstack/common/timeutils.py', 'ironic/openstack/common/strutils.py', 'ironic/openstack/common/excutils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/bef38c4a7dbe318a1e0617cec2ba0163a9d61871', 'message': 'Remove unused oslo-incubator modules\n\nAll of these have been moved to oslo.utils. The code has\nalready been migrated. importutils stays as a dependency\nfor logging from incubator.\n\nChange-Id: I5076d132b8a715c0d63a8f650704b567abf9161b\n'}]",0,141478,bef38c4a7dbe318a1e0617cec2ba0163a9d61871,3,1,1,7770,,,0,"Remove unused oslo-incubator modules

All of these have been moved to oslo.utils. The code has
already been migrated. importutils stays as a dependency
for logging from incubator.

Change-Id: I5076d132b8a715c0d63a8f650704b567abf9161b
",git fetch https://review.opendev.org/openstack/ironic refs/changes/78/141478/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/drivers/ilo/test_deploy.py', 'ironic/openstack/common/timeutils.py', 'ironic/openstack/common/strutils.py', 'ironic/openstack/common/excutils.py']",4,bef38c4a7dbe318a1e0617cec2ba0163a9d61871,,,"# Copyright 2011 OpenStack Foundation. # Copyright 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exception related utilities. """""" import logging import sys import time import traceback import six from ironic.openstack.common.gettextutils import _LE class save_and_reraise_exception(object): """"""Save current exception, run some code and then re-raise. In some cases the exception context can be cleared, resulting in None being attempted to be re-raised after an exception handler is run. This can happen when eventlet switches greenthreads or when running an exception handler, code raises and catches an exception. In both cases the exception context will be cleared. To work around this, we save the exception state, run handler code, and then re-raise the original exception. If another exception occurs, the saved exception is logged and the new exception is re-raised. In some cases the caller may not want to re-raise the exception, and for those circumstances this context provides a reraise flag that can be used to suppress the exception. For example:: except Exception: with save_and_reraise_exception() as ctxt: decide_if_need_reraise() if not should_be_reraised: ctxt.reraise = False If another exception occurs and reraise flag is False, the saved exception will not be logged. If the caller wants to raise new exception during exception handling he/she sets reraise to False initially with an ability to set it back to True if needed:: except Exception: with save_and_reraise_exception(reraise=False) as ctxt: [if statements to determine whether to raise a new exception] # Not raising a new exception, so reraise ctxt.reraise = True """""" def __init__(self, reraise=True): self.reraise = reraise def __enter__(self): self.type_, self.value, self.tb, = sys.exc_info() return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type is not None: if self.reraise: logging.error(_LE('Original exception being dropped: %s'), traceback.format_exception(self.type_, self.value, self.tb)) return False if self.reraise: six.reraise(self.type_, self.value, self.tb) def forever_retry_uncaught_exceptions(infunc): def inner_func(*args, **kwargs): last_log_time = 0 last_exc_message = None exc_count = 0 while True: try: return infunc(*args, **kwargs) except Exception as exc: this_exc_message = six.u(str(exc)) if this_exc_message == last_exc_message: exc_count += 1 else: exc_count = 1 # Do not log any more frequently than once a minute unless # the exception message changes cur_time = int(time.time()) if (cur_time - last_log_time > 60 or this_exc_message != last_exc_message): logging.exception( _LE('Unexpected exception occurred %d time(s)... ' 'retrying.') % exc_count) last_log_time = cur_time last_exc_message = this_exc_message exc_count = 0 # This should be a very rare event. In case it isn't, do # a sleep. time.sleep(1) return inner_func ",1,619
openstack%2Fproject-config~master~I0cdfe0e42aad87d8e046d00ba5fb5348caac4d6c,openstack/project-config,master,I0cdfe0e42aad87d8e046d00ba5fb5348caac4d6c,Add link for Trove RSS feed,MERGED,2014-12-10 01:20:28.000000000,2014-12-12 20:09:29.000000000,2014-12-12 20:09:29.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5293}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-10 01:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/459d28c122ffa2bb3cde85335f0761e27314df65', 'message': 'Add link for Trove RSS feed\n\nAdded a link for the Trove RSS Feed to the main specs index.html page.\n\nChange-Id: I0cdfe0e42aad87d8e046d00ba5fb5348caac4d6c\n'}, {'number': 2, 'created': '2014-12-12 19:53:32.000000000', 'files': ['specs/index.html'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2c7d982f58496f1a17d39b6417dd002ec6f09cab', 'message': 'Add link for Trove RSS feed\n\nAdded a link for the Trove RSS Feed to the main specs index.html page.\n\nChange-Id: I0cdfe0e42aad87d8e046d00ba5fb5348caac4d6c\n'}]",0,140549,2c7d982f58496f1a17d39b6417dd002ec6f09cab,21,6,2,5293,,,0,"Add link for Trove RSS feed

Added a link for the Trove RSS Feed to the main specs index.html page.

Change-Id: I0cdfe0e42aad87d8e046d00ba5fb5348caac4d6c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/49/140549/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/index.html'],1,459d28c122ffa2bb3cde85335f0761e27314df65,add-trove-rss," (<a href=""openstack/trove-specs/rss.xml"">RSS</a>)",,1,0
openstack%2Fmanila~master~I5cc863bb89f986815a4f6c1addf593f2da62530f,openstack/manila,master,I5cc863bb89f986815a4f6c1addf593f2da62530f,Fix metadata validation in share api,MERGED,2014-12-12 14:55:59.000000000,2014-12-12 20:04:45.000000000,2014-12-12 20:04:43.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 7534}, {'_account_id': 8851}]","[{'number': 1, 'created': '2014-12-12 14:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/45768c8096134a48fd45c184c53beb8652d06dc4', 'message': 'Fix metadata validation in share api\n\nCurrently validation method _check_metadata_properties()\nexpects that metadata parameter is a dict which contains\nstring keys and values, but this assumption is incorrect,\nbecause user can specify key without value or vice versa.\n\nChange-Id: I5cc863bb89f986815a4f6c1addf593f2da62530f\nCloses-Bug: #1392827\n'}, {'number': 2, 'created': '2014-12-12 16:39:49.000000000', 'files': ['manila/tests/api/v1/test_share_metadata.py', 'manila/share/api.py', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/9c72d34df71c73731f1786d6d755c69ea3118df0', 'message': 'Fix metadata validation in share api\n\nCurrently validation method _check_metadata_properties()\nexpects that metadata parameter is a dict which contains\nstring keys and values, but this assumption is incorrect,\nbecause user can specify key without value or vice versa.\n\nChange-Id: I5cc863bb89f986815a4f6c1addf593f2da62530f\nCloses-Bug: #1392827\n'}]",2,141392,9c72d34df71c73731f1786d6d755c69ea3118df0,11,5,2,14232,,,0,"Fix metadata validation in share api

Currently validation method _check_metadata_properties()
expects that metadata parameter is a dict which contains
string keys and values, but this assumption is incorrect,
because user can specify key without value or vice versa.

Change-Id: I5cc863bb89f986815a4f6c1addf593f2da62530f
Closes-Bug: #1392827
",git fetch https://review.opendev.org/openstack/manila refs/changes/92/141392/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/api/v1/test_share_metadata.py', 'manila/share/api.py', 'test-requirements.txt']",3,45768c8096134a48fd45c184c53beb8652d06dc4,fix_share_metadata_validator,ddt>=0.4.0,,14,3
openstack%2Fsolum~master~I4a7332f72ca6eaafea31a9128c62f6d53fc08351,openstack/solum,master,I4a7332f72ca6eaafea31a9128c62f6d53fc08351,Fix build_lp call in worker/handlers/shell.py,MERGED,2014-12-12 17:33:55.000000000,2014-12-12 19:58:54.000000000,2014-12-12 19:58:54.000000000,"[{'_account_id': 3}, {'_account_id': 6662}, {'_account_id': 9095}]","[{'number': 1, 'created': '2014-12-12 17:33:55.000000000', 'files': ['solum/worker/handlers/shell.py'], 'web_link': 'https://opendev.org/openstack/solum/commit/65bc33e6cbb7d5c9f0302a8e3124ac88a9093a33', 'message': 'Fix build_lp call in worker/handlers/shell.py\n\nChange-Id: I4a7332f72ca6eaafea31a9128c62f6d53fc08351\nCloses-Bug: 1401663\n'}]",0,141435,65bc33e6cbb7d5c9f0302a8e3124ac88a9093a33,7,3,1,1375,,,0,"Fix build_lp call in worker/handlers/shell.py

Change-Id: I4a7332f72ca6eaafea31a9128c62f6d53fc08351
Closes-Bug: 1401663
",git fetch https://review.opendev.org/openstack/solum refs/changes/35/141435/1 && git format-patch -1 --stdout FETCH_HEAD,['solum/worker/handlers/shell.py'],1,65bc33e6cbb7d5c9f0302a8e3124ac88a9093a33,bug/1401663," self.build_lp(ctxt, git_info, name, base_image_id,"," self.build_lp(self, ctxt, git_info, name, base_image_id,",1,1
openstack%2Fironic~master~I67d8b3a5b451577ddf5574234a2e9dad34c9d8bc,openstack/ironic,master,I67d8b3a5b451577ddf5574234a2e9dad34c9d8bc,Remove unused oslo-incubator modules,ABANDONED,2014-12-12 19:22:51.000000000,2014-12-12 19:58:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7770}, {'_account_id': 12081}]","[{'number': 1, 'created': '2014-12-12 19:22:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/2d014b6db60d39014f0b96ed998eed43ef791a79', 'message': 'Remove unused oslo-incubator modules\n\nAll of these have been moved to oslo.utils. The code has\nalready been migrated.\n\nChange-Id: I67d8b3a5b451577ddf5574234a2e9dad34c9d8bc\n'}, {'number': 2, 'created': '2014-12-12 19:32:52.000000000', 'files': ['ironic/openstack/common/importutils.py', 'ironic/tests/drivers/ilo/test_deploy.py', 'ironic/openstack/common/timeutils.py', 'ironic/openstack/common/strutils.py', 'ironic/openstack/common/excutils.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/68aa1155fb34f740f414994297d0a310d644fea6', 'message': 'Remove unused oslo-incubator modules\n\nAll of these have been moved to oslo.utils. The code has\nalready been migrated.\n\nChange-Id: I67d8b3a5b451577ddf5574234a2e9dad34c9d8bc\n'}]",0,141472,68aa1155fb34f740f414994297d0a310d644fea6,8,3,2,7770,,,0,"Remove unused oslo-incubator modules

All of these have been moved to oslo.utils. The code has
already been migrated.

Change-Id: I67d8b3a5b451577ddf5574234a2e9dad34c9d8bc
",git fetch https://review.opendev.org/openstack/ironic refs/changes/72/141472/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/openstack/common/importutils.py', 'ironic/openstack/common/timeutils.py', 'ironic/openstack/common/strutils.py', 'ironic/openstack/common/excutils.py']",4,2d014b6db60d39014f0b96ed998eed43ef791a79,,,"# Copyright 2011 OpenStack Foundation. # Copyright 2012, Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Exception related utilities. """""" import logging import sys import time import traceback import six from ironic.openstack.common.gettextutils import _LE class save_and_reraise_exception(object): """"""Save current exception, run some code and then re-raise. In some cases the exception context can be cleared, resulting in None being attempted to be re-raised after an exception handler is run. This can happen when eventlet switches greenthreads or when running an exception handler, code raises and catches an exception. In both cases the exception context will be cleared. To work around this, we save the exception state, run handler code, and then re-raise the original exception. If another exception occurs, the saved exception is logged and the new exception is re-raised. In some cases the caller may not want to re-raise the exception, and for those circumstances this context provides a reraise flag that can be used to suppress the exception. For example:: except Exception: with save_and_reraise_exception() as ctxt: decide_if_need_reraise() if not should_be_reraised: ctxt.reraise = False If another exception occurs and reraise flag is False, the saved exception will not be logged. If the caller wants to raise new exception during exception handling he/she sets reraise to False initially with an ability to set it back to True if needed:: except Exception: with save_and_reraise_exception(reraise=False) as ctxt: [if statements to determine whether to raise a new exception] # Not raising a new exception, so reraise ctxt.reraise = True """""" def __init__(self, reraise=True): self.reraise = reraise def __enter__(self): self.type_, self.value, self.tb, = sys.exc_info() return self def __exit__(self, exc_type, exc_val, exc_tb): if exc_type is not None: if self.reraise: logging.error(_LE('Original exception being dropped: %s'), traceback.format_exception(self.type_, self.value, self.tb)) return False if self.reraise: six.reraise(self.type_, self.value, self.tb) def forever_retry_uncaught_exceptions(infunc): def inner_func(*args, **kwargs): last_log_time = 0 last_exc_message = None exc_count = 0 while True: try: return infunc(*args, **kwargs) except Exception as exc: this_exc_message = six.u(str(exc)) if this_exc_message == last_exc_message: exc_count += 1 else: exc_count = 1 # Do not log any more frequently than once a minute unless # the exception message changes cur_time = int(time.time()) if (cur_time - last_log_time > 60 or this_exc_message != last_exc_message): logging.exception( _LE('Unexpected exception occurred %d time(s)... ' 'retrying.') % exc_count) last_log_time = cur_time last_exc_message = this_exc_message exc_count = 0 # This should be a very rare event. In case it isn't, do # a sleep. time.sleep(1) return inner_func ",0,691
openstack%2Fmanila~master~I377d46148b8da3c26f26a51a42ae749715e396aa,openstack/manila,master,I377d46148b8da3c26f26a51a42ae749715e396aa,Fix devstack plugin custom config opt setting,MERGED,2014-12-12 15:44:16.000000000,2014-12-12 19:51:11.000000000,2014-12-12 19:51:11.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}]","[{'number': 1, 'created': '2014-12-12 15:44:16.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/f417e25ebc98a5a15af1a715c43ee99fb436446b', 'message': 'Fix devstack plugin custom config opt setting\n\nCommit https://github.com/openstack/manila/commit/1a2ec3da introduced new\napproach to manila configuration file setting and it won\'t consider custom\nopts for DEFAULT group by default behaviour, only when its name added to\n""MANILA_CONFIGURE_GROUPS"".\nWe should make it set always, because DEFAULT group is used always.\n\nChange-Id: I377d46148b8da3c26f26a51a42ae749715e396aa\nCloses-Bug: #1401793\n'}]",0,141410,f417e25ebc98a5a15af1a715c43ee99fb436446b,8,3,1,8851,,,0,"Fix devstack plugin custom config opt setting

Commit https://github.com/openstack/manila/commit/1a2ec3da introduced new
approach to manila configuration file setting and it won't consider custom
opts for DEFAULT group by default behaviour, only when its name added to
""MANILA_CONFIGURE_GROUPS"".
We should make it set always, because DEFAULT group is used always.

Change-Id: I377d46148b8da3c26f26a51a42ae749715e396aa
Closes-Bug: #1401793
",git fetch https://review.opendev.org/openstack/manila refs/changes/10/141410/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,f417e25ebc98a5a15af1a715c43ee99fb436446b,bug/1401793,"# DEFAULT group is always defined, no need to specify it within 'MANILA_CONFIGURE_GROUPS'.function set_config_opts { # expects only one param - name of config group(s) as list separated by commas GROUP_NAMES=$1 if [[ -n ""$GROUP_NAMES"" ]]; then for be in ${GROUP_NAMES//,/ }; do # get backend_specific opt values prefix=MANILA_OPTGROUP_$be\_ ( set -o posix ; set ) | grep ^$prefix | while read -r line ; do # parse it to opt names and values opt=${line#$prefix} opt_name=${opt%%=*} opt_value=${opt##*=} iniset $MANILA_CONF $be $opt_name $opt_value done done fi } set_config_opts $MANILA_CONFIGURE_GROUPS set_config_opts DEFAULT"," if [[ -n ""$MANILA_CONFIGURE_GROUPS"" ]]; then for be in ${MANILA_CONFIGURE_GROUPS//,/ }; do # get backend_specific opt values prefix=MANILA_OPTGROUP_$be\_ compgen -v | grep $prefix | while read -r line ; do # parse it to opt names and values opt=${line#$prefix} opt_name=${opt%%=*} opt_value=${opt##*=} iniset $MANILA_CONF $be $opt_name $opt_value done done fi",21,13
openstack%2Fproject-config~master~Ia1de627c01ee43c461d25b184fb61cbfd91fb19d,openstack/project-config,master,Ia1de627c01ee43c461d25b184fb61cbfd91fb19d,zuul's log path should always be a folder,MERGED,2014-12-12 03:56:00.000000000,2014-12-12 19:49:55.000000000,2014-12-12 19:49:54.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-12 03:56:00.000000000', 'files': ['zuul/openstack_functions.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/353a5e324b09738f225f74e50d89d6cf343a9d79', 'message': ""zuul's log path should always be a folder\n\nzuul sets the path for where logs are stored. In all our cases this\nis a folder containing the console.log and other assets. We should\ndenote this is a folder by leaving a trailing slash. This also means\nthat os-loganalyze can determine if it should load an index.html\nfaster by looking for a trailing slash.\n\nChange-Id: Ia1de627c01ee43c461d25b184fb61cbfd91fb19d\n""}]",0,141263,353a5e324b09738f225f74e50d89d6cf343a9d79,8,3,1,7069,,,0,"zuul's log path should always be a folder

zuul sets the path for where logs are stored. In all our cases this
is a folder containing the console.log and other assets. We should
denote this is a folder by leaving a trailing slash. This also means
that os-loganalyze can determine if it should load an index.html
faster by looking for a trailing slash.

Change-Id: Ia1de627c01ee43c461d25b184fb61cbfd91fb19d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/141263/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/openstack_functions.py'],1,353a5e324b09738f225f74e50d89d6cf343a9d79,swift_log_index," path = ""%s/%s/%s/%s/"" % ( path = ""%s/%s/%s/"" % ( params['LOG_PATH'] = path + '/%s/%s/' % (job.name, params['ZUUL_UUID'][:7])"," path = ""%s/%s/%s/%s"" % ( path = ""%s/%s/%s"" % ( params['LOG_PATH'] = path + '/%s/%s' % (job.name, params['ZUUL_UUID'][:7])",4,4
openstack-attic%2Fnetconn-api~master~I9eb429d60845eb4e465e893c5e6ba570d1817339,openstack-attic/netconn-api,master,I9eb429d60845eb4e465e893c5e6ba570d1817339,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:42:16.000000000,2014-12-12 19:48:04.000000000,2014-12-12 19:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-05 03:42:16.000000000', 'files': ['tools/rfc.sh'], 'web_link': 'https://opendev.org/openstack-attic/netconn-api/commit/df3f840d050a803c843200fb85287d61b8ecd1c0', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I9eb429d60845eb4e465e893c5e6ba570d1817339\n'}]",0,139337,df3f840d050a803c843200fb85287d61b8ecd1c0,7,3,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I9eb429d60845eb4e465e893c5e6ba570d1817339
",git fetch https://review.opendev.org/openstack-attic/netconn-api refs/changes/37/139337/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/rfc.sh'],1,df3f840d050a803c843200fb85287d61b8ecd1c0,infra-manual," echo ""\thttp://docs.openstack.org/infra/manual/developers.html#development-workflow"""," echo ""\thttp://wiki.openstack.org/GerritWorkflow""",1,1
openstack%2Fproject-config~master~Id127d24e4428be8b450de277dc55df20349aab13,openstack/project-config,master,Id127d24e4428be8b450de277dc55df20349aab13,Introduce project-specific stable-maint teams,MERGED,2014-12-10 15:35:37.000000000,2014-12-12 19:47:34.000000000,2014-12-12 19:36:30.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2750}, {'_account_id': 2889}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-10 15:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/613d80b67ea2b02d1d83835f206495623deea6b2', 'message': ""Introduce project-specific stable-maint teams\n\nAs discussed in Paris and subsequently discussed on the mailing-list,\nswitch stable branch maintenance to project-specific teams under the\nguidance and leadership of the stable-maint-core team.\n\nAll $PROJECT-stable-maint teams in Gerrit should be owned by\nstable-maint-core which will vet the addition of members to make sure\nthey are aware of the Stable Branch policy.\n\nRemarks:\n- Sahara was already using their own team, proposed change will align\n  them to use a specific team instead.\n- Designate is still incubated and therefore stable-maint-core doesn't\n  own their stable branches yet. Proposed change fixes ACL to reflect\n  that.\n- All projects still inherit openstack-stable-maint from the\n  all-projects ACL, but this will be removed once the transition is\n  over.\n\nReference:\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-November/050390.html\n\nChange-Id: Id127d24e4428be8b450de277dc55df20349aab13\n""}, {'number': 2, 'created': '2014-12-10 15:45:25.000000000', 'files': ['gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/openstack/swift.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/ceilometer.config', 'gerrit/acls/openstack/designate.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/openstack/heat.config', 'gerrit/acls/openstack/keystone.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/openstack/sahara.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/95f1ef86496f0db8518fe1d5f2f4d50af357ecbf', 'message': ""Introduce project-specific stable-maint teams\n\nAs discussed in Paris and subsequently discussed on the mailing-list,\nswitch stable branch maintenance to project-specific teams under the\nguidance and leadership of the stable-maint-core team.\n\nAll $PROJECT-stable-maint teams in Gerrit should be owned by\nstable-maint-core which will vet the addition of members to make sure\nthey are aware of the Stable Branch policy.\n\nRemarks:\n- Sahara was already using their own team, proposed change will align\n  them to use a specific team instead.\n- Designate is still incubated and therefore stable-maint-core doesn't\n  own their stable branches yet. Proposed change fixes ACL to reflect\n  that.\n- All projects still inherit openstack-stable-maint from the\n  all-projects ACL, but this will be removed once the transition is\n  over.\n\nReference:\nhttp://lists.openstack.org/pipermail/openstack-dev/2014-November/050390.html\n\nChange-Id: Id127d24e4428be8b450de277dc55df20349aab13\n""}]",1,140738,95f1ef86496f0db8518fe1d5f2f4d50af357ecbf,20,8,2,308,,,0,"Introduce project-specific stable-maint teams

As discussed in Paris and subsequently discussed on the mailing-list,
switch stable branch maintenance to project-specific teams under the
guidance and leadership of the stable-maint-core team.

All $PROJECT-stable-maint teams in Gerrit should be owned by
stable-maint-core which will vet the addition of members to make sure
they are aware of the Stable Branch policy.

Remarks:
- Sahara was already using their own team, proposed change will align
  them to use a specific team instead.
- Designate is still incubated and therefore stable-maint-core doesn't
  own their stable branches yet. Proposed change fixes ACL to reflect
  that.
- All projects still inherit openstack-stable-maint from the
  all-projects ACL, but this will be removed once the transition is
  over.

Reference:
http://lists.openstack.org/pipermail/openstack-dev/2014-November/050390.html

Change-Id: Id127d24e4428be8b450de277dc55df20349aab13
",git fetch https://review.opendev.org/openstack/project-config refs/changes/38/140738/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/nova.config', 'gerrit/acls/openstack/trove.config', 'gerrit/acls/openstack/horizon.config', 'gerrit/acls/openstack/swift.config', 'gerrit/acls/openstack/cinder.config', 'gerrit/acls/openstack/ceilometer.config', 'gerrit/acls/openstack/designate.config', 'gerrit/acls/openstack/glance.config', 'gerrit/acls/openstack/heat.config', 'gerrit/acls/openstack/keystone.config', 'gerrit/acls/openstack/neutron.config', 'gerrit/acls/openstack/sahara.config']",12,613d80b67ea2b02d1d83835f206495623deea6b2,stable-maint-apocalypse,"[access ""refs/heads/stable/*""] abandon = group sahara-stable-maint label-Code-Review = -2..+2 group sahara-stable-maintlabel-Workflow = -1..+1 group sahara-stable-maint","[access ""refs/heads/stable/icehouse""] abandon = group sahara-core exclusiveGroupPermissions = abandon label-Code-Review label-Workflow label-Code-Review = -2..+2 group sahara-corelabel-Workflow = -1..+1 group sahara-core rebase = group sahara-core",64,8
openstack%2Fopenstack-manuals~master~I470d41fbbed61e7bd82d189b154f369c95d42c05,openstack/openstack-manuals,master,I470d41fbbed61e7bd82d189b154f369c95d42c05,made change to massively_scalable section,MERGED,2014-12-12 07:48:25.000000000,2014-12-12 19:46:56.000000000,2014-12-12 19:46:55.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10497}]","[{'number': 1, 'created': '2014-12-12 07:48:25.000000000', 'files': ['doc/arch-design/massively_scalable/section_operational_considerations_massively_scalable.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/737432646fb8c89c69b64a3ab10135a671251e95', 'message': 'made change to massively_scalable section\n\nremoved the which - didn’t make sense\nremoved extra to - didn’t make sense\n\nChange-Id: I470d41fbbed61e7bd82d189b154f369c95d42c05\n'}]",0,141294,737432646fb8c89c69b64a3ab10135a671251e95,8,4,1,9382,,,0,"made change to massively_scalable section

removed the which - didn’t make sense
removed extra to - didn’t make sense

Change-Id: I470d41fbbed61e7bd82d189b154f369c95d42c05
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/94/141294/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/arch-design/massively_scalable/section_operational_considerations_massively_scalable.xml'],1,737432646fb8c89c69b64a3ab10135a671251e95,mass_scal," community can help resolve any issues reported by applying increased risk and instability. However, in many cases it"," community can help resolve any issues reported by the applying increased risk to and instability. However, in many cases it",2,2
openstack%2Fgrenade~master~Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4,openstack/grenade,master,Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4,Modify keystone-paste.ini file on Kilo upgrade,MERGED,2014-12-04 13:40:32.000000000,2014-12-12 19:46:48.000000000,2014-12-12 19:46:47.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5046}]","[{'number': 1, 'created': '2014-12-04 13:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/87c8c9c463328a9e558fff2c891891018fd10556', 'message': 'Remove keystone-paste.ini file on Juno upgrade\n\nThis change will allow Keystone to regenerate a new keystone-paste.ini file\ninstead of referencing the Base configuration in Juno upgrade testing. The Base\nconfiguration that pre-dates Juno will contain XmlBodyMiddleware, which as of\nJuno, as been removed.\n\nChange-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4\nCloses-Bug: #1398833\n'}, {'number': 2, 'created': '2014-12-04 14:40:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/f6611b509fea1ee4f70f00d9fde9f3ba8c136d30', 'message': 'Remove keystone-paste.ini file on Juno upgrade\n\nThis change will allow Keystone to regenerate a new keystone-paste.ini file\ninstead of referencing the Base configuration in Juno upgrade testing. The Base\nconfiguration that pre-dates Juno will contain XmlBodyMiddleware, which as of\nJuno, as been removed.\n\nChange-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4\nCloses-Bug: #1398833\n'}, {'number': 3, 'created': '2014-12-04 14:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/dec61601ca8ea785453752d5dafa49b97c32f4ba', 'message': 'Remove keystone-paste.ini file on Juno upgrade\n\nThis change will allow Keystone to regenerate a new keystone-paste.ini file\ninstead of referencing the Base configuration in Juno upgrade testing. The Base\nconfiguration that pre-dates Juno will contain XmlBodyMiddleware, which as of\nJuno, as been removed.\n\nChange-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4\nCloses-Bug: #1398833\n'}, {'number': 4, 'created': '2014-12-04 19:10:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/dcb1d598ce411f4727d1befb6e42b23eef93b695', 'message': 'Remove keystone-paste.ini file on Juno upgrade\n\nThis change will allow Keystone to regenerate a new keystone-paste.ini file\ninstead of referencing the Base configuration in Juno upgrade testing. The Base\nconfiguration that pre-dates Juno will contain XmlBodyMiddleware, which as of\nJuno, as been removed.\n\nChange-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4\nCloses-Bug: #1398833\n'}, {'number': 5, 'created': '2014-12-08 14:10:46.000000000', 'files': ['from-juno/upgrade-keystone'], 'web_link': 'https://opendev.org/openstack/grenade/commit/82d0084595248b1842497b5e443edf532c937144', 'message': 'Modify keystone-paste.ini file on Kilo upgrade\n\nThis change will allow Keystone to modify the keystone-paste.ini file\ninstead of referencing the Base configuration in Kilo upgrade testing. The Base\nconfiguration that pre-dates Kilo will contain XmlBodyMiddleware, which has been removed.\n\nDocumentation has been add in the Kilo Release Notes.\n\nhttps://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_5\n\nChange-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4\nCloses-Bug: #1398833\n'}]",3,139051,82d0084595248b1842497b5e443edf532c937144,21,5,5,5046,,,0,"Modify keystone-paste.ini file on Kilo upgrade

This change will allow Keystone to modify the keystone-paste.ini file
instead of referencing the Base configuration in Kilo upgrade testing. The Base
configuration that pre-dates Kilo will contain XmlBodyMiddleware, which has been removed.

Documentation has been add in the Kilo Release Notes.

https://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_5

Change-Id: Ice45bdd3c1d5a2a8d7dcda05ac895d03a070aaf4
Closes-Bug: #1398833
",git fetch https://review.opendev.org/openstack/grenade refs/changes/51/139051/5 && git format-patch -1 --stdout FETCH_HEAD,['from-juno/upgrade-keystone'],1,87c8c9c463328a9e558fff2c891891018fd10556,bug/1398833,#!/usr/bin/env bash # ``upgrade-keystone`` function configure_keystone_upgrade { XTRACE=$(set +o | grep xtrace) set -o xtrace # Ensure we remove the stale keystone-paste.ini file since it contains # configuration for XML. A new keystone-paste.ini should be generated so # that it doesn't have XmlBodyMiddleware in the pipeline that doesn't # exist. XmlBodyMiddleware has been deprecated for the last year and was # removed in Kilo. rm $KEYSTONE_DIR/etc/keystone/keystone-paste.ini # reset to previous state $XTRACE } ,,18,0
openstack%2Fopenstack-manuals~master~I85aa5f46de70b2cfa856ce3048c7632588c9426a,openstack/openstack-manuals,master,I85aa5f46de70b2cfa856ce3048c7632588c9426a,Adding information on storage IP connections,MERGED,2014-12-10 07:47:29.000000000,2014-12-12 19:46:20.000000000,2014-12-12 19:46:18.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10497}, {'_account_id': 10897}]","[{'number': 1, 'created': '2014-12-10 07:47:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4acea0bd8deb83b1616ddb2795ff764940aa6e7f', 'message': 'Adding information on storage IP connections\n\nAdding information on the option to configure a storage node IP\nto connect with, and send images to, the compute nodes when\nthe storage node is located on a separate network.\n\nChange-Id: I85aa5f46de70b2cfa856ce3048c7632588c9426a\nBackport: none\nCloses-Bug: #1398034\n'}, {'number': 2, 'created': '2014-12-12 07:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/63d2a1c9d7ccc8808b0c469cce65be8faa06e8c1', 'message': 'Adding information on storage IP connections\n\nAdding information on the option to configure a storage node IP\nto connect with, and send images to, the compute nodes when\nthe storage node is located on a separate network.\n\nChange-Id: I85aa5f46de70b2cfa856ce3048c7632588c9426a\nBackport: none\nCloses-Bug: #1398034\n'}, {'number': 3, 'created': '2014-12-12 07:57:57.000000000', 'files': ['doc/admin-guide-cloud/compute/section_compute-images-instances.xml', 'doc/admin-guide-cloud/image/section_glance-nova-image-download.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9ba949a6d252633c08f8e0fb6f0d4eca1171a0c3', 'message': 'Adding information on storage IP connections\n\nAdding information on the option to configure a storage node IP\nto connect with, and send images to, the compute nodes when\nthe storage node is located on a separate network.\n\nChange-Id: I85aa5f46de70b2cfa856ce3048c7632588c9426a\nBackport: none\nCloses-Bug: #1398034\n'}]",0,140596,9ba949a6d252633c08f8e0fb6f0d4eca1171a0c3,14,6,3,10897,,,0,"Adding information on storage IP connections

Adding information on the option to configure a storage node IP
to connect with, and send images to, the compute nodes when
the storage node is located on a separate network.

Change-Id: I85aa5f46de70b2cfa856ce3048c7632588c9426a
Backport: none
Closes-Bug: #1398034
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/140596/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/admin-guide-cloud/compute/section_compute-images-instances.xml', 'doc/admin-guide-cloud/image/section_glance-nova-image-download.xml']",2,4acea0bd8deb83b1616ddb2795ff764940aa6e7f,bug1398034/joseph-r-email," It is possible to set up the Object Storage node on a separate network, and still allow image traffic to flow between the Compute and Object Storage nodes. Configure the <literal>my_block_storage_ip</literal> option in the storage node configuration to allow block storage traffic to reach the Compute node. </para> <para>",,21,5
openstack%2Fmurano~master~Iedd0382b60fbe0598688f4cf3e3dc79fe51a6958,openstack/murano,master,Iedd0382b60fbe0598688f4cf3e3dc79fe51a6958,"Revert ""Use oslo.serialization""",ABANDONED,2014-12-12 19:26:26.000000000,2014-12-12 19:44:33.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-12-12 19:26:26.000000000', 'files': ['murano/engine/auth_utils.py', 'murano/openstack/common/jsonutils.py', 'requirements.txt', 'murano/engine/system/resource_manager.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/openstack/common/importutils.py', 'murano/api/versions.py', 'murano/openstack/common/strutils.py', 'murano/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/a19eabfee13f995197ce6172be11cbf550e7aebc', 'message': 'Revert ""Use oslo.serialization""\n\nThis reverts commit 18694ec63d827e331763e6de6c89cd9cf44be991.\n\nChange-Id: Iedd0382b60fbe0598688f4cf3e3dc79fe51a6958\n'}]",0,141473,a19eabfee13f995197ce6172be11cbf550e7aebc,4,2,1,7225,,,0,"Revert ""Use oslo.serialization""

This reverts commit 18694ec63d827e331763e6de6c89cd9cf44be991.

Change-Id: Iedd0382b60fbe0598688f4cf3e3dc79fe51a6958
",git fetch https://review.opendev.org/openstack/murano refs/changes/73/141473/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/engine/auth_utils.py', 'murano/openstack/common/jsonutils.py', 'requirements.txt', 'murano/engine/system/resource_manager.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/openstack/common/importutils.py', 'murano/api/versions.py', 'murano/openstack/common/strutils.py', 'murano/openstack/common/timeutils.py']",10,a19eabfee13f995197ce6172be11cbf550e7aebc,oslo,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Time related utilities and helper functions. """""" import calendar import datetime import time import iso8601 import six # ISO 8601 extended time format with microseconds _ISO8601_TIME_FORMAT_SUBSECOND = '%Y-%m-%dT%H:%M:%S.%f' _ISO8601_TIME_FORMAT = '%Y-%m-%dT%H:%M:%S' PERFECT_TIME_FORMAT = _ISO8601_TIME_FORMAT_SUBSECOND def isotime(at=None, subsecond=False): """"""Stringify time in ISO 8601 format."""""" if not at: at = utcnow() st = at.strftime(_ISO8601_TIME_FORMAT if not subsecond else _ISO8601_TIME_FORMAT_SUBSECOND) tz = at.tzinfo.tzname(None) if at.tzinfo else 'UTC' st += ('Z' if tz == 'UTC' else tz) return st def parse_isotime(timestr): """"""Parse time from ISO 8601 format."""""" try: return iso8601.parse_date(timestr) except iso8601.ParseError as e: raise ValueError(six.text_type(e)) except TypeError as e: raise ValueError(six.text_type(e)) def strtime(at=None, fmt=PERFECT_TIME_FORMAT): """"""Returns formatted utcnow."""""" if not at: at = utcnow() return at.strftime(fmt) def parse_strtime(timestr, fmt=PERFECT_TIME_FORMAT): """"""Turn a formatted time back into a datetime."""""" return datetime.datetime.strptime(timestr, fmt) def normalize_time(timestamp): """"""Normalize time in arbitrary timezone to UTC naive object."""""" offset = timestamp.utcoffset() if offset is None: return timestamp return timestamp.replace(tzinfo=None) - offset def is_older_than(before, seconds): """"""Return True if before is older than seconds."""""" if isinstance(before, six.string_types): before = parse_strtime(before).replace(tzinfo=None) else: before = before.replace(tzinfo=None) return utcnow() - before > datetime.timedelta(seconds=seconds) def is_newer_than(after, seconds): """"""Return True if after is newer than seconds."""""" if isinstance(after, six.string_types): after = parse_strtime(after).replace(tzinfo=None) else: after = after.replace(tzinfo=None) return after - utcnow() > datetime.timedelta(seconds=seconds) def utcnow_ts(): """"""Timestamp version of our utcnow function."""""" if utcnow.override_time is None: # NOTE(kgriffs): This is several times faster # than going through calendar.timegm(...) return int(time.time()) return calendar.timegm(utcnow().timetuple()) def utcnow(): """"""Overridable version of utils.utcnow."""""" if utcnow.override_time: try: return utcnow.override_time.pop(0) except AttributeError: return utcnow.override_time return datetime.datetime.utcnow() def iso8601_from_timestamp(timestamp): """"""Returns a iso8601 formatted date from timestamp."""""" return isotime(datetime.datetime.utcfromtimestamp(timestamp)) utcnow.override_time = None def set_time_override(override_time=None): """"""Overrides utils.utcnow. Make it return a constant time or a list thereof, one at a time. :param override_time: datetime instance or list thereof. If not given, defaults to the current UTC time. """""" utcnow.override_time = override_time or datetime.datetime.utcnow() def advance_time_delta(timedelta): """"""Advance overridden time using a datetime.timedelta."""""" assert(not utcnow.override_time is None) try: for dt in utcnow.override_time: dt += timedelta except TypeError: utcnow.override_time += timedelta def advance_time_seconds(seconds): """"""Advance overridden time by seconds."""""" advance_time_delta(datetime.timedelta(0, seconds)) def clear_time_override(): """"""Remove the overridden time."""""" utcnow.override_time = None def marshall_now(now=None): """"""Make an rpc-safe datetime with microseconds. Note: tzinfo is stripped, but not required for relative times. """""" if not now: now = utcnow() return dict(day=now.day, month=now.month, year=now.year, hour=now.hour, minute=now.minute, second=now.second, microsecond=now.microsecond) def unmarshall_time(tyme): """"""Unmarshall a datetime dict."""""" return datetime.datetime(day=tyme['day'], month=tyme['month'], year=tyme['year'], hour=tyme['hour'], minute=tyme['minute'], second=tyme['second'], microsecond=tyme['microsecond']) def delta_seconds(before, after): """"""Return the difference between two timing objects. Compute the difference in seconds between two date, time, or datetime objects (as a float, to microsecond resolution). """""" delta = after - before return total_seconds(delta) def total_seconds(delta): """"""Return the total seconds of datetime.timedelta object. Compute total seconds of datetime.timedelta, datetime.timedelta doesn't have method total_seconds in Python2.6, calculate it manually. """""" try: return delta.total_seconds() except AttributeError: return ((delta.days * 24 * 3600) + delta.seconds + float(delta.microseconds) / (10 ** 6)) def is_soon(dt, window): """"""Determines if time is going to happen in the next window seconds. :param dt: the time :param window: minimum seconds to remain to consider the time not soon :return: True if expiration is within the given duration """""" soon = (utcnow() + datetime.timedelta(seconds=window)) return normalize_time(dt) <= soon ",,715,6
openstack%2Fpython-manilaclient~master~Ib56c8b28272f955924c80f0a893de71a62fc5b49,openstack/python-manilaclient,master,Ib56c8b28272f955924c80f0a893de71a62fc5b49,Add manila cli help output to doc,MERGED,2014-11-21 12:08:28.000000000,2014-12-12 19:39:38.000000000,2014-12-12 19:39:38.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 6547}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 14232}]","[{'number': 1, 'created': '2014-11-21 12:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/e53fe1633cc82670a7ee78358da8519e44742e12', 'message': 'Add manila cli help output to doc\n\nDynamically generate the cli help output and include\nit into the documentation.\n\nChange-Id: Ib56c8b28272f955924c80f0a893de71a62fc5b49\n'}, {'number': 2, 'created': '2014-12-11 18:58:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/ccc8533a5d13f787e8ceb5a0257c9792d4bb59c0', 'message': 'Add manila cli help output to doc\n\nDynamically generate the cli help output and include\nit into the documentation.\n\nChange-Id: Ib56c8b28272f955924c80f0a893de71a62fc5b49\n'}, {'number': 3, 'created': '2014-12-11 23:01:05.000000000', 'files': ['.gitignore', 'doc/source/shell.rst', 'doc/source/exts/clidoc/__init__.py', 'doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/python-manilaclient/commit/4faae5a7b86c879006ecfd9a2d55516cb3aa1e17', 'message': 'Add manila cli help output to doc\n\nDynamically generate the cli help output and include\nit into the documentation.\n\nChange-Id: Ib56c8b28272f955924c80f0a893de71a62fc5b49\n'}]",2,136315,4faae5a7b86c879006ecfd9a2d55516cb3aa1e17,21,6,3,7102,,,0,"Add manila cli help output to doc

Dynamically generate the cli help output and include
it into the documentation.

Change-Id: Ib56c8b28272f955924c80f0a893de71a62fc5b49
",git fetch https://review.opendev.org/openstack/python-manilaclient refs/changes/15/136315/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/Makefile', '.gitignore', 'doc/source/shell.rst']",3,e53fe1633cc82670a7ee78358da8519e44742e12,136315, .. include:: manila_cli_output.rst.inc,,11,1
openstack%2Fneutron~master~Ida2f64602cfb2c4e3535beb9f5b1ebf07d9b3520,openstack/neutron,master,Ida2f64602cfb2c4e3535beb9f5b1ebf07d9b3520,ML2: Extension Driver API,ABANDONED,2014-07-16 21:02:12.000000000,2014-12-12 19:36:28.000000000,,"[{'_account_id': 3}, {'_account_id': 1689}, {'_account_id': 5170}, {'_account_id': 9681}, {'_account_id': 9695}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 13961}]","[{'number': 1, 'created': '2014-07-16 21:02:12.000000000', 'files': ['neutron/plugins/ml2/driver_api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/334d8d6c92c6e0c8ec4a100392332570291e2d15', 'message': ""ML2: Extension Driver API\n\nAdd new driver type allowed ML2's core resources to be extended with\nadditional attributes.\n\nThis is currently a work-in-progress. It only defines the extension\ndriver API. Code implementing and testing this new API is needed.\n\nChange-Id: Ida2f64602cfb2c4e3535beb9f5b1ebf07d9b3520\n""}]",0,107499,334d8d6c92c6e0c8ec4a100392332570291e2d15,23,18,1,1689,,,0,"ML2: Extension Driver API

Add new driver type allowed ML2's core resources to be extended with
additional attributes.

This is currently a work-in-progress. It only defines the extension
driver API. Code implementing and testing this new API is needed.

Change-Id: Ida2f64602cfb2c4e3535beb9f5b1ebf07d9b3520
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/107499/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/driver_api.py'],1,334d8d6c92c6e0c8ec4a100392332570291e2d15,extension-driver," @six.add_metaclass(abc.ABCMeta) class ExtensionDriver(object): """"""Define stable abstract interface for ML2 extension drivers. An extension driver extends the core resources implemented by the ML2 plugin with additional attributes. Methods that process create and update operations for these resources validate and persist values for extended attributes supplied through the API. Other methods extend the resource dictionaries returned from the API operations with the values of the extended attributes. Note - Extending existing core APIs reduces portability and interoperability, and should be avoided when other alternatives are available. Extensions that serve to introduce new general features, if proven useful, should be incorporated into the next new core API version. Vendor-specific or technology-specific extensions that aren't of general use are discouraged, but can be supported via ML2 extension drivers, avoiding the need to implement a monolithic plugin when an API extension is required. """""" @abc.abstractmethod def initialize(self): """"""Perform driver initialization. Called after all drivers have been loaded and the database has been initialized. No abstract methods defined below will be called prior to this method being called. """""" pass @abc.abstractproperty def extension_alias(self): """"""Supported extension alias. Return the alias identifying the core API extension supported by this driver. """""" pass def process_create_network(self, session, data, result): """"""Process extended attributes for create network. :param session: database session :param data: dictionary of incoming network data :param result: network dictionary to extend Called inside transaction context on session to validate and persist any extended network attributes defined by this driver. Extended attribute values must also be added to result. """""" pass def process_create_subnet(self, session, data, result): """"""Process extended attributes for create subnet. :param session: database session :param data: dictionary of incoming subnet data :param result: subnet dictionary to extend Called inside transaction context on session to validate and persist any extended subnet attributes defined by this driver. Extended attribute values must also be added to result. """""" pass def process_create_port(self, session, data, result): """"""Process extended attributes for create port. :param session: database session :param data: dictionary of incoming port data :param result: port dictionary to extend Called inside transaction context on session to validate and persist any extended port attributes defined by this driver. Extended attribute values must also be added to result. """""" pass def process_update_network(self, session, data, result): """"""Process extended attributes for update network. :param session: database session :param data: dictionary of incoming network data :param result: network dictionary to extend Called inside transaction context on session to validate and update any extended network attributes defined by this driver. Extended attribute values, whether updated or not, must also be added to result. """""" pass def process_update_subnet(self, session, data, result): """"""Process extended attributes for update subnet. :param session: database session :param data: dictionary of incoming subnet data :param result: subnet dictionary to extend Called inside transaction context on session to validate and update any extended subnet attributes defined by this driver. Extended attribute values, whether updated or not, must also be added to result. """""" pass def process_update_port(self, session, data, result): """"""Process extended attributes for update port. :param session: database session :param data: dictionary of incoming port data :param result: port dictionary to extend Called inside transaction context on session to validate and update any extended port attributes defined by this driver. Extended attribute values, whether updated or not, must also be added to result. """""" pass def extend_network_dict(self, session, result): """"""Add extended attributes to network dictionary. :param session: database session :param result: network dictionary to extend Called inside transaction context on session to add any extended attributes defined by this driver to a network dictionary to be used for mechanism driver calls and/or returned as the result of a network operation. """""" pass def extend_subnet_dict(self, session, result): """"""Add extended attributes to subnet dictionary. :param session: database session :param result: subnet dictionary to extend Called inside transaction context on session to add any extended attributes defined by this driver to a subnet dictionary to be used for mechanism driver calls and/or returned as the result of a subnet operation. """""" pass def extend_port_dict(self, session, result): """"""Add extended attributes to port dictionary. :param session: database session :param result: port dictionary to extend Called inside transaction context on session to add any extended attributes defined by this driver to a port dictionary to be used for mechanism driver calls and/or returned as the result of a port operation. """""" pass",,164,0
openstack%2Fproject-config~master~Id784e2876a2cbbede650b7e101ff90f7d74ec367,openstack/project-config,master,Id784e2876a2cbbede650b7e101ff90f7d74ec367,Support name change in devstack to debs,MERGED,2014-12-11 21:46:53.000000000,2014-12-12 19:30:06.000000000,2014-12-12 19:30:04.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-12-11 21:46:53.000000000', 'files': ['nodepool/elements/cache-devstack/extra-data.d/55-cache-devstack-repos', 'nodepool/scripts/cache_devstack.py'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e89225e97825b1e3775bed21e5bfddb774c7805f', 'message': 'Support name change in devstack to debs\n\nA short time ago, devstack change the name of its lists of debian\npackages from apts to debs. In order to properly pre-cache, we should\nread these.\n\nChange-Id: Id784e2876a2cbbede650b7e101ff90f7d74ec367\n'}]",0,141177,e89225e97825b1e3775bed21e5bfddb774c7805f,14,4,1,2,,,0,"Support name change in devstack to debs

A short time ago, devstack change the name of its lists of debian
packages from apts to debs. In order to properly pre-cache, we should
read these.

Change-Id: Id784e2876a2cbbede650b7e101ff90f7d74ec367
",git fetch https://review.opendev.org/openstack/project-config refs/changes/77/141177/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/cache-devstack/extra-data.d/55-cache-devstack-repos', 'nodepool/scripts/cache_devstack.py']",2,e89225e97825b1e3775bed21e5bfddb774c7805f,," debdir = os.path.join(DEVSTACK, 'files', 'debs') if not os.path.exists(debdir): debdir = os.path.join(DEVSTACK, 'files', 'apts')"," debdir = os.path.join(DEVSTACK, 'files', 'apts')",6,2
openstack%2Fmurano~master~I028409bb4fe05d4d2949f7f028298cd4704345b4,openstack/murano,master,I028409bb4fe05d4d2949f7f028298cd4704345b4,Use oslo.serialization,MERGED,2014-11-29 05:03:01.000000000,2014-12-12 19:26:26.000000000,2014-12-12 19:09:24.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-29 05:03:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/583a84b8e89d5be95c4d934533f9b7654f02007b', 'message': 'Use oslo.serialization\n\nChange-Id: I028409bb4fe05d4d2949f7f028298cd4704345b4\n'}, {'number': 2, 'created': '2014-12-10 22:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/333160b9c3fddf1052b95d65500c20ca8eb6d138', 'message': 'Use oslo.serialization\n\nChange-Id: I028409bb4fe05d4d2949f7f028298cd4704345b4\n'}, {'number': 3, 'created': '2014-12-10 23:16:02.000000000', 'files': ['murano/engine/auth_utils.py', 'murano/openstack/common/jsonutils.py', 'requirements.txt', 'murano/engine/system/resource_manager.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/openstack/common/importutils.py', 'murano/api/versions.py', 'murano/openstack/common/strutils.py', 'murano/openstack/common/timeutils.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/18694ec63d827e331763e6de6c89cd9cf44be991', 'message': 'Use oslo.serialization\n\nChange-Id: I028409bb4fe05d4d2949f7f028298cd4704345b4\n'}]",0,137878,18694ec63d827e331763e6de6c89cd9cf44be991,28,6,3,7600,,,0,"Use oslo.serialization

Change-Id: I028409bb4fe05d4d2949f7f028298cd4704345b4
",git fetch https://review.opendev.org/openstack/murano refs/changes/78/137878/3 && git format-patch -1 --stdout FETCH_HEAD,"['murano/openstack/common/jsonutils.py', 'requirements.txt', 'murano/engine/system/resource_manager.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/openstack/common/importutils.py', 'murano/api/versions.py', 'murano/openstack/common/strutils.py', 'murano/openstack/common/timeutils.py']",9,583a84b8e89d5be95c4d934533f9b7654f02007b,oslo,,"# Copyright 2011 OpenStack Foundation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Time related utilities and helper functions. """""" import calendar import datetime import time import iso8601 import six # ISO 8601 extended time format with microseconds _ISO8601_TIME_FORMAT_SUBSECOND = '%Y-%m-%dT%H:%M:%S.%f' _ISO8601_TIME_FORMAT = '%Y-%m-%dT%H:%M:%S' PERFECT_TIME_FORMAT = _ISO8601_TIME_FORMAT_SUBSECOND def isotime(at=None, subsecond=False): """"""Stringify time in ISO 8601 format."""""" if not at: at = utcnow() st = at.strftime(_ISO8601_TIME_FORMAT if not subsecond else _ISO8601_TIME_FORMAT_SUBSECOND) tz = at.tzinfo.tzname(None) if at.tzinfo else 'UTC' st += ('Z' if tz == 'UTC' else tz) return st def parse_isotime(timestr): """"""Parse time from ISO 8601 format."""""" try: return iso8601.parse_date(timestr) except iso8601.ParseError as e: raise ValueError(six.text_type(e)) except TypeError as e: raise ValueError(six.text_type(e)) def strtime(at=None, fmt=PERFECT_TIME_FORMAT): """"""Returns formatted utcnow."""""" if not at: at = utcnow() return at.strftime(fmt) def parse_strtime(timestr, fmt=PERFECT_TIME_FORMAT): """"""Turn a formatted time back into a datetime."""""" return datetime.datetime.strptime(timestr, fmt) def normalize_time(timestamp): """"""Normalize time in arbitrary timezone to UTC naive object."""""" offset = timestamp.utcoffset() if offset is None: return timestamp return timestamp.replace(tzinfo=None) - offset def is_older_than(before, seconds): """"""Return True if before is older than seconds."""""" if isinstance(before, six.string_types): before = parse_strtime(before).replace(tzinfo=None) else: before = before.replace(tzinfo=None) return utcnow() - before > datetime.timedelta(seconds=seconds) def is_newer_than(after, seconds): """"""Return True if after is newer than seconds."""""" if isinstance(after, six.string_types): after = parse_strtime(after).replace(tzinfo=None) else: after = after.replace(tzinfo=None) return after - utcnow() > datetime.timedelta(seconds=seconds) def utcnow_ts(): """"""Timestamp version of our utcnow function."""""" if utcnow.override_time is None: # NOTE(kgriffs): This is several times faster # than going through calendar.timegm(...) return int(time.time()) return calendar.timegm(utcnow().timetuple()) def utcnow(): """"""Overridable version of utils.utcnow."""""" if utcnow.override_time: try: return utcnow.override_time.pop(0) except AttributeError: return utcnow.override_time return datetime.datetime.utcnow() def iso8601_from_timestamp(timestamp): """"""Returns a iso8601 formatted date from timestamp."""""" return isotime(datetime.datetime.utcfromtimestamp(timestamp)) utcnow.override_time = None def set_time_override(override_time=None): """"""Overrides utils.utcnow. Make it return a constant time or a list thereof, one at a time. :param override_time: datetime instance or list thereof. If not given, defaults to the current UTC time. """""" utcnow.override_time = override_time or datetime.datetime.utcnow() def advance_time_delta(timedelta): """"""Advance overridden time using a datetime.timedelta."""""" assert(not utcnow.override_time is None) try: for dt in utcnow.override_time: dt += timedelta except TypeError: utcnow.override_time += timedelta def advance_time_seconds(seconds): """"""Advance overridden time by seconds."""""" advance_time_delta(datetime.timedelta(0, seconds)) def clear_time_override(): """"""Remove the overridden time."""""" utcnow.override_time = None def marshall_now(now=None): """"""Make an rpc-safe datetime with microseconds. Note: tzinfo is stripped, but not required for relative times. """""" if not now: now = utcnow() return dict(day=now.day, month=now.month, year=now.year, hour=now.hour, minute=now.minute, second=now.second, microsecond=now.microsecond) def unmarshall_time(tyme): """"""Unmarshall a datetime dict."""""" return datetime.datetime(day=tyme['day'], month=tyme['month'], year=tyme['year'], hour=tyme['hour'], minute=tyme['minute'], second=tyme['second'], microsecond=tyme['microsecond']) def delta_seconds(before, after): """"""Return the difference between two timing objects. Compute the difference in seconds between two date, time, or datetime objects (as a float, to microsecond resolution). """""" delta = after - before return total_seconds(delta) def total_seconds(delta): """"""Return the total seconds of datetime.timedelta object. Compute total seconds of datetime.timedelta, datetime.timedelta doesn't have method total_seconds in Python2.6, calculate it manually. """""" try: return delta.total_seconds() except AttributeError: return ((delta.days * 24 * 3600) + delta.seconds + float(delta.microseconds) / (10 ** 6)) def is_soon(dt, window): """"""Determines if time is going to happen in the next window seconds. :param dt: the time :param window: minimum seconds to remain to consider the time not soon :return: True if expiration is within the given duration """""" soon = (utcnow() + datetime.timedelta(seconds=window)) return normalize_time(dt) <= soon ",5,713
openstack%2Frally~master~I04ef6aab8997051dabc0f6deeea07c2627af754e,openstack/rally,master,I04ef6aab8997051dabc0f6deeea07c2627af754e,Add 'Stop scenario after several errors' feature req,MERGED,2014-12-10 11:56:37.000000000,2014-12-12 19:25:10.000000000,2014-12-12 19:25:09.000000000,"[{'_account_id': 3}, {'_account_id': 5950}, {'_account_id': 6172}, {'_account_id': 7227}, {'_account_id': 9545}, {'_account_id': 9705}, {'_account_id': 10475}, {'_account_id': 14135}, {'_account_id': 14283}]","[{'number': 1, 'created': '2014-12-10 11:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/79d210d4392235635bc22d8928e77b1484ef9d51', 'message': ""Add 'Stop scenario after several errors' feature req.\n\nChange-Id: I04ef6aab8997051dabc0f6deeea07c2627af754e\n""}, {'number': 2, 'created': '2014-12-10 19:21:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/21618895bce7a75db21b871de122341860c6c9a3', 'message': ""Add 'Stop scenario after several errors' feature req.\n\nChange-Id: I04ef6aab8997051dabc0f6deeea07c2627af754e\n""}, {'number': 3, 'created': '2014-12-10 20:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/16903a32514533f5a93936f742bafb6d7bf7c1cc', 'message': ""Add 'Stop scenario after several errors' feature req\n\nChange-Id: I04ef6aab8997051dabc0f6deeea07c2627af754e\n""}, {'number': 4, 'created': '2014-12-12 15:26:23.000000000', 'files': ['doc/feature_request/stop_scenario_after_several_errors.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/25840fcf02eddf3c65d6dce16b9a11288247eefd', 'message': ""Add 'Stop scenario after several errors' feature req\n\nChange-Id: I04ef6aab8997051dabc0f6deeea07c2627af754e\n""}]",3,140651,25840fcf02eddf3c65d6dce16b9a11288247eefd,20,9,4,8084,,,0,"Add 'Stop scenario after several errors' feature req

Change-Id: I04ef6aab8997051dabc0f6deeea07c2627af754e
",git fetch https://review.opendev.org/openstack/rally refs/changes/51/140651/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/feature_request/stop_scenario_after_several_errors.rst'],1,79d210d4392235635bc22d8928e77b1484ef9d51,,"================================== Stop scenario after several errors ================================== Use case -------- On the big environments keystone, cinder can die during the tests. This happens often. Problem description ------------------- When we start a rally scenarios on the env where keystone die we get a lot of time from timeout Example ------- Times in hard tests 05:25:40 rally-scenarios.cinder 05:25:40 create-and-delete-volume [4074 iterations, 15 threads] OK 8.91 08:00:02 create-and-delete-snapshot [5238 iterations, 15 threads] OK 17.46 08:53:20 create-and-list-volume [4074 iterations, 15 threads] OK 3.18 12:04:14 create-snapshot-and-attach-volume [2619 iterations, 15 threads] FAIL 14:18:44 create-and-attach-volume [2619 iterations, 15 threads] FAIL 14:23:47 rally-scenarios.vm 14:23:47 boot_runcommand_metadata_delete [5 iterations, 5 threads] FAIL 16:30:46 rally-scenarios.nova 16:30:46 boot_and_list_server [5820 iterations, 15 threads] FAIL 19:19:30 resize_server [5820 iterations, 15 threads] FAIL 02:51:13 boot_and_delete_server_with_secgroups [5820 iterations, 60 threads] FAIL Times in light variant 00:38:25 rally-scenarios.cinder 00:38:25 create-and-delete-volume [14 iterations, 1 threads] OK 5.30 00:40:39 create-and-delete-snapshot [18 iterations, 1 threads] OK 5.65 00:41:52 create-and-list-volume [14 iterations, 1 threads] OK 2.89 00:45:18 create-snapshot-and-attach-volume [9 iterations, 1 threads] OK 17.75 00:48:54 create-and-attach-volume [9 iterations, 1 threads] OK 20.04 00:52:29 rally-scenarios.vm 00:52:29 boot_runcommand_metadata_delete [5 iterations, 5 threads] OK 128.86 00:56:42 rally-scenarios.nova 00:56:42 boot_and_list_server [20 iterations, 1 threads] OK 6.98 01:04:48 resize_server [20 iterations, 1 threads] OK 22.90 In the hard test we have a lot of timeouts from keystone and a lot of time on test execution Possible solution ----------------- Add parameter in rally scenarios about several mistakes in a row. We should have opportunity for set number of errors after which scenario will be stopped and marked as failed. It should be number of timeouts and HTTP 500, 400 ",,59,0
openstack%2Fnova-specs~master~I348152f35395b8ef63ac947c58d5aa15b3afdd41,openstack/nova-specs,master,I348152f35395b8ef63ac947c58d5aa15b3afdd41,Add Barbican Wrapper Specification,MERGED,2014-12-08 21:12:16.000000000,2014-12-12 19:20:52.000000000,2014-12-12 19:20:52.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 6783}, {'_account_id': 6802}, {'_account_id': 7012}, {'_account_id': 7746}, {'_account_id': 11716}]","[{'number': 1, 'created': '2014-12-08 21:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b8cd989207d1501527048f4bb1cece210bc1fb36', 'message': 'Moving Barbican wrapper a.k.a. encryption with Barbican spec from Juno to Kilo\n\nChange-Id: I348152f35395b8ef63ac947c58d5aa15b3afdd41\n'}, {'number': 2, 'created': '2014-12-09 15:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2ca01108599b76e8faa92381d1975d22087dc013', 'message': 'Moving Barbican wrapper a.k.a. encryption with Barbican spec from Juno to Kilo\n\nLink to previously approved spec in Juno: https://review.openstack.org/#/c/94918/\nCode requiring this spec is here: https://review.openstack.org/#/c/104001\n\nPreviously-approved: juno\n\nChange-Id: I348152f35395b8ef63ac947c58d5aa15b3afdd41\n'}, {'number': 3, 'created': '2014-12-09 21:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/90296f2583c95fdd189d7181b53728be9bf17d1a', 'message': 'Add Barbican Wrapper Specification\n\nPreviously approved spec in Juno: https://review.openstack.org/#/c/94918/\nCode requiring this spec is here: https://review.openstack.org/#/c/104001\n\nPreviously-approved: juno\n\nChange-Id: I348152f35395b8ef63ac947c58d5aa15b3afdd41\n'}, {'number': 4, 'created': '2014-12-12 19:12:35.000000000', 'files': ['specs/kilo/approved/encryption-with-barbican.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/df7b480878845fa8df44b95d20d9d588fff3792d', 'message': 'Add Barbican Wrapper Specification\n\nPreviously approved spec in Juno: https://review.openstack.org/#/c/94918/\nCode requiring this spec is here: https://review.openstack.org/#/c/104001\n\nPreviously-approved: juno\n\nChange-Id: I348152f35395b8ef63ac947c58d5aa15b3afdd41\n'}]",5,140144,df7b480878845fa8df44b95d20d9d588fff3792d,22,11,4,6804,,,0,"Add Barbican Wrapper Specification

Previously approved spec in Juno: https://review.openstack.org/#/c/94918/
Code requiring this spec is here: https://review.openstack.org/#/c/104001

Previously-approved: juno

Change-Id: I348152f35395b8ef63ac947c58d5aa15b3afdd41
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/44/140144/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/encryption-with-barbican.rst'],1,b8cd989207d1501527048f4bb1cece210bc1fb36,bp/encryption-with-barbican,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ====================================================== Make key manager interface interoperable with Barbican ====================================================== URL to Launchpad blueprint: https://blueprints.launchpad.net/nova/+spec/encryption-with-barbican The volume encryption feature added in the Havana release currently can only operate with a single key that is hardcoded in. A much more flexible and secure solution would be to generate and store keys in Barbican, a cohesive and secure Linux-based key management system https://github.com/cloudkeep/barbican/wiki, which is now in the OpenStack incubation process. Problem description =================== Problem 1: The OpenStack Volume Encryption feature currently cannot provide its designed level of security due to the absence of a key management service. Only a placeholder is available now, which isn't sufficient for the volume encryption feature to be used in an enterprise environment. Keys cannot be stored, and only one hard-coded key is presented for all volumes. The proposed outcome would provide the ability to create and safely store dedicated keys for individual users or tenants. Problem 2: An ephemeral disk encryption feature supporting LVM was not accepted into the Icehouse release due to the lack of a key manager. For security reasons, since the disk is in close proximity to the virtual host, ephemeral disk encryption must use a key that's safely stored outside of the virtual host environment. An enterprise-grade key manager is needed for both cases, and Barbican (approved for incubation on 3/10/14) is becoming the default key manager that is slated to support OpenStack volume encryption, ephemeral disk storage encryption, and other potential security features. https://wiki.openstack.org/wiki/Barbican/Incubation. In order for Barbican to support these two storage encryption features, an interface between the existing key manager interface (nova/keymgr/key_mgr.py) used for volume encryption and the Barbican key manager needs to be developed. Proposed change =============== Create an interface that will call python-barbicanclient, allowing Barbican to securely generate, store, and present encryption keys to Nova in support of the volume encryption feature. The adapter will be a modification of the present key management abstraction layer in the volume encryption feature supporting block storage encryption on Cinder and ephemeral disk encryption. Alternatives ------------ Instead of implementing the existing key manager interface, python-barbicanclient could be invoked directly, but the additional indirection allows more extensibility if a different key manager needs to be integrated later. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- Use of a bonafide key manager greatly improves the security posture of the volume encryption and upcoming ephemeral disk encryption features. When each user or tenant use a unique key instead of a common key, and when it is stored in a separate server, it will be much more difficult for an attacker to access stored encrypted data owned by a user or group of collective users within a tenant. Though the wrapper will be handling encryption keys, the security risk is considered minimal since the host must be trusted, and the wrapper is only holding the key temporarily. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The additional storage write and read time to initially query Barbican for the encryption key should be negligible. Other deployer impact --------------------- Assuming that Barbican is the default key manager, then no impact. If it's not the default, then a configuration flag in Nova will need to be added. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: hadi-esiely-barrera Other contributors: brianna-poulos bruce-benjamin Work Items ---------- Develop simple translation of existing key manager interface methods (e.g., get_key) into the corresponding python-barbicanclient calls. Dependencies ============ None Testing ======= Tempest testing should be performed to ensure that the wrapper works correctly. Documentation Impact ==================== The use of Barbican as the default key manager for the storage encryption will need to be documented. References ========== None ",,162,0
openstack%2Fnova-specs~master~I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4,openstack/nova-specs,master,I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4,Deprecate `.image.glance` in favor of glanceclient,MERGED,2014-11-10 14:14:22.000000000,2014-12-12 19:19:14.000000000,2014-12-12 19:19:13.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 782}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 6062}, {'_account_id': 6159}, {'_account_id': 7166}, {'_account_id': 11356}]","[{'number': 1, 'created': '2014-11-10 14:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/bbfa034d899e040b1e9cdd8745415145f261904a', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}, {'number': 2, 'created': '2014-11-10 14:40:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a7048f6ade5d81b314fd772a5a53606161555f63', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}, {'number': 3, 'created': '2014-11-20 18:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/d33b36640466c14cfdb320523714314264d537c3', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}, {'number': 4, 'created': '2014-11-21 08:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/c00bc4e70b47be52a75563bb2f6b08c3b5a15aea', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}, {'number': 5, 'created': '2014-12-12 18:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5306428e601840d004f9c3be4e08ac4e5b64ce0e', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}, {'number': 6, 'created': '2014-12-12 19:10:57.000000000', 'files': ['specs/kilo/approved/remove-glanceclient-wrapper.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/5e62be30abdaf0567db3c362d3c8905b78af8ba4', 'message': ""Deprecate `.image.glance` in favor of glanceclient\n\nNova currently maintains a wrapper on top of glanceclient which is both\nold and ugly. This spec proposes getting rid of that code in favor of\nusing just glanceclient in order to reduce the code needed to be\nmaintained by the nova team, allow the glance team to move forward more\neasily and allow nova for better supporting glance's API v2.\n\nChange-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4\n""}]",20,133485,5e62be30abdaf0567db3c362d3c8905b78af8ba4,30,12,6,6159,,,0,"Deprecate `.image.glance` in favor of glanceclient

Nova currently maintains a wrapper on top of glanceclient which is both
old and ugly. This spec proposes getting rid of that code in favor of
using just glanceclient in order to reduce the code needed to be
maintained by the nova team, allow the glance team to move forward more
easily and allow nova for better supporting glance's API v2.

Change-Id: I1a86fcf3f2321f2b16b8787faecd099d80c1e3c4
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/85/133485/6 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/remove-glanceclient-wrapper.rst'],1,bbfa034d899e040b1e9cdd8745415145f261904a,nova-glanceclient,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================== Remove glanceclient wrapper =========================== https://blueprints.launchpad.net/nova/+spec/use-glance-v2-api This spec proposes removing the wrapper code around glanceclient and allow nova to use glanceclient directly. Problem description =================== Nova currently uses a wrapper on top of glanceclient, which is a close-enough implementation of the same API exposed by the client itself. This wrapper has evolved over the years allowing nova to move from older versions of glance's API to newer ones. Unfortunately, this code is quite old and contains some workarounds to allow nova for using some of the latest features exposed through Glance's API. As of Kilo, Glance's team plans to deprecate the version 1 of the API but to do that, it is necessary to ensure that all projects depending on it are able to function correctly with the latest version and that the transition from the previous version to the new one is as painless as possible. Use Cases ---------- The idea behind this cleanup is to reduce the code that needs to be maintained by the nova team and allow Glance to evolve without being blocked by other projects. The changes proposed in this spec shouldn't have any impact on developers, end users or operators. Project Priority ----------------- No idea? Help? Proposed change =============== The proposed change is to remove entirely the `nova.image.glance` module and keep the existing `nova.image.api` module until we're able to get rid of `nova.image.download` too. The `nova.image.glance` modules contains the code for the abovementioned wrapper that we'd like to cleanup. This code contains some logic duplications from glanceclient and most of it is not needed. The bits that are needed - those that at least could be reused - are the ones enhancing image downloads. That is, the piece of code that allows to access the image data directly depending on the store and whether it's been enabled in the configuration file. In order to keep supporting this behavior, we must keep the code under `nova.image.download` until `glance_store` is adopted by nova - a separate blueprint will be written for this. Once `glance_store` is refactored and adopted, there won't be any need to maintain the code under `nova.image.api` either. This will be addressed in the `glance_store` spec as well. During these changes, the existing glance specific config options will be updated to. There are some old and not useful options - host, port, protocol - that could be deprecated in favor of better ones - api_servers. Alternatives ------------ - Keep the wrapper and clean it up until it matches exactly glance's client API. Please, don't! :) Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- The change will keep backwards compatibility with the existing configuration options and work on a upgrade path for deployers. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: flaper87 Other contributors: jokke Work Items ---------- - Rewrite `nova.image.api.Api` methods using glanceclient directly - Move current glance specific options and remove `nova.image.glance` code - Deprecate old `nova.image.glance` options like: host, port, protocol Dependencies ============ None Testing ======= All existing tests will test this change thoroughly for Glance's API v1. It'll be necessary to create a job for Glance's API v2 until it becomes the default one in the gate. Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== - https://etherpad.openstack.org/p/kilo-nova-glance ",,163,0
openstack%2Fnova-specs~master~I6070754d998abc73c8a2e03025700da71dcdafbe,openstack/nova-specs,master,I6070754d998abc73c8a2e03025700da71dcdafbe,Stop encrypted disk on instance suspend/power off,MERGED,2014-12-10 22:20:54.000000000,2014-12-12 19:12:54.000000000,2014-12-12 19:12:53.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 2750}]","[{'number': 1, 'created': '2014-12-10 22:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/b1ae4870eb3ef6944e407ec8cfb0c43e06196ebc', 'message': 'Stop encrypted disk on instance suspend/power off\n\nDisconnecting dm-crypt device from an encrypted LVM volume while the instance\nis suspended or powered off will secure user data from unauthorized access.\nThis will extend data at-rest protection provided by the LVM ephemeral storage\nencryption feature.\n\nChange-Id: I6070754d998abc73c8a2e03025700da71dcdafbe\n'}, {'number': 2, 'created': '2014-12-12 14:37:23.000000000', 'files': ['specs/kilo/approved/stop-dmcrypt-on-suspend.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6348b077a41bc7268d3e3b0910a6d5876dcdc111', 'message': 'Stop encrypted disk on instance suspend/power off\n\nDisconnecting dm-crypt device from an encrypted LVM volume while the instance\nis suspended or powered off will secure user data from unauthorized access.\nThis will extend data at-rest protection provided by the LVM ephemeral storage\nencryption feature.\n\nChange-Id: I6070754d998abc73c8a2e03025700da71dcdafbe\n'}]",0,140847,6348b077a41bc7268d3e3b0910a6d5876dcdc111,12,5,2,7746,,,0,"Stop encrypted disk on instance suspend/power off

Disconnecting dm-crypt device from an encrypted LVM volume while the instance
is suspended or powered off will secure user data from unauthorized access.
This will extend data at-rest protection provided by the LVM ephemeral storage
encryption feature.

Change-Id: I6070754d998abc73c8a2e03025700da71dcdafbe
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/47/140847/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/approved/stop-dmcrypt-on-suspend.rst'],1,b1ae4870eb3ef6944e407ec8cfb0c43e06196ebc,stop-dmcrypt-on-suspend,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================================================================== Stop dm-crypt device when an encrypted instance is suspended/stopped ==================================================================== https://blueprints.launchpad.net/nova/+spec/stop-dmcrypt-on-suspend Disconnect the dm-crypt device from encrypted LVM volume when an instance with encrypted LVM ephemeral storage is suspended or powered off. Problem description =================== The recently introduced LVM ephemeral storage encryption features secures user data at rest. Current implementation makes user data unreadable after the instance has been terminated. While the instance is active (e.g., running, paused, suspended or powered off), on the compute host the data is readable only by the super-user. This protection against unauthorized access can be strengthened further by disconnecting the dm-crypt device when an instance is suspended or powered off and flushing the encryption key from memory. The dm-crypt device is what allows the encrypted data to be accessed in the clear so disconnecting it will render the data unreadable by anyone without the key. Use Cases --------- An encrypted instance operating on sensitive data is stopped but not destroyed -- the work to be resumed later. Project Priority ---------------- None Proposed change =============== The change will add code to stop the dm-crypt device and flush the key in libvirt.driver.power_off() and libvirt.driver.suspend() and code to retrieve instance ephemeral encryption key and restart the dm-crypt device in libvirt.driver.power_on() and libvirt.driver.resume(). Alternatives ------------ There is no real alternative. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- User data will be inaccessible to anyone while the instance is powered off or suspended. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ The power on and resume operations will be marginally slower for encrypted instances. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: dgenin (Dan Genin) Work Items ---------- * Add dm-crypt stop/restart functionality to suspend()/resume(). * Add dm-crypt stop/restart functionality to power_off()/power_on(). Dependencies ============ None Testing ======= Unit and Tempest tests will be written to verify correct operation of the proposed feature. Documentation Impact ==================== The extension of data-at-rest security to powered off and suspended instances should be mentioned in OpenStack Security Guide. References ========== None ",,137,0
openstack%2Fopenstack-ansible~stable%2Fjuno~I88cddb4461d2f0814108d0bec1f739452adc536b,openstack/openstack-ansible,stable/juno,I88cddb4461d2f0814108d0bec1f739452adc536b,Fix swift MaaS check/alarm setup,MERGED,2014-12-12 12:45:06.000000000,2014-12-12 19:11:22.000000000,2014-12-12 19:11:21.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-12 12:45:06.000000000', 'files': ['rpc_deployment/playbooks/monitoring/swift_maas.yml', 'rpc_deployment/playbooks/monitoring/maas_local.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cd1ce729008993c5910be75883b44139ae8ed04e', 'message': ""Fix swift MaaS check/alarm setup\n\n* Metric names adjusted to be correct\n* Thresholds added for checks where required\n* Moved swift checks into swift_maas so swift checks aren't installed for non-swift deploys\n* Fixed targeted host groups for swift checks\n\nChange-Id: I88cddb4461d2f0814108d0bec1f739452adc536b\nCloses-Bug: #1401696\n(cherry picked from commit b75ac5bb13fc669347d7f98159ed047d294e2b1f)\n""}]",0,141353,cd1ce729008993c5910be75883b44139ae8ed04e,8,4,1,2799,,,0,"Fix swift MaaS check/alarm setup

* Metric names adjusted to be correct
* Thresholds added for checks where required
* Moved swift checks into swift_maas so swift checks aren't installed for non-swift deploys
* Fixed targeted host groups for swift checks

Change-Id: I88cddb4461d2f0814108d0bec1f739452adc536b
Closes-Bug: #1401696
(cherry picked from commit b75ac5bb13fc669347d7f98159ed047d294e2b1f)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/53/141353/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/playbooks/monitoring/swift_maas.yml', 'rpc_deployment/playbooks/monitoring/maas_local.yml']",2,cd1ce729008993c5910be75883b44139ae8ed04e,bug/1401696,,"- hosts: swift_obj vars: check_name: swift_account_replication_check check_details: file=swift-recon.py,args=--ring-type,args=account,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_account_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_account_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_async_check check_details: file=swift-recon.py,args=async-pendings check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_async_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_async_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_container_replication_check check_details: file=swift-recon.py,args=--ring-type,args=container,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_container_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_container_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_md5_check check_details: file=swift-recon.py,args=md5 check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_md5_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_md5_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_object_replication_check check_details: file=swift-recon.py,args=--ring-type,args=object,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_object_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_object_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_quarantine_check check_details: file=swift-recon.py,args=quarantine check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_quarantine_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_quarantine_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local ",80,72
openstack%2Fopenstack-ansible~master~I88cddb4461d2f0814108d0bec1f739452adc536b,openstack/openstack-ansible,master,I88cddb4461d2f0814108d0bec1f739452adc536b,Fix swift MaaS check/alarm setup,MERGED,2014-12-12 12:20:04.000000000,2014-12-12 19:11:11.000000000,2014-12-12 19:11:11.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-12 12:20:04.000000000', 'files': ['rpc_deployment/playbooks/monitoring/swift_maas.yml', 'rpc_deployment/playbooks/monitoring/maas_local.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b75ac5bb13fc669347d7f98159ed047d294e2b1f', 'message': ""Fix swift MaaS check/alarm setup\n\n* Metric names adjusted to be correct\n* Thresholds added for checks where required\n* Moved swift checks into swift_maas so swift checks aren't installed for non-swift deploys\n* Fixed targeted host groups for swift checks\n\nChange-Id: I88cddb4461d2f0814108d0bec1f739452adc536b\nCloses-Bug: #1401696\n""}]",0,141347,b75ac5bb13fc669347d7f98159ed047d294e2b1f,8,4,1,2799,,,0,"Fix swift MaaS check/alarm setup

* Metric names adjusted to be correct
* Thresholds added for checks where required
* Moved swift checks into swift_maas so swift checks aren't installed for non-swift deploys
* Fixed targeted host groups for swift checks

Change-Id: I88cddb4461d2f0814108d0bec1f739452adc536b
Closes-Bug: #1401696
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/47/141347/1 && git format-patch -1 --stdout FETCH_HEAD,"['rpc_deployment/playbooks/monitoring/swift_maas.yml', 'rpc_deployment/playbooks/monitoring/maas_local.yml']",2,b75ac5bb13fc669347d7f98159ed047d294e2b1f,bug/1401696,,"- hosts: swift_obj vars: check_name: swift_account_replication_check check_details: file=swift-recon.py,args=--ring-type,args=account,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_account_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_account_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_async_check check_details: file=swift-recon.py,args=async-pendings check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_async_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_async_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_container_replication_check check_details: file=swift-recon.py,args=--ring-type,args=container,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_container_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_container_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_md5_check check_details: file=swift-recon.py,args=md5 check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_md5_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_md5_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_object_replication_check check_details: file=swift-recon.py,args=--ring-type,args=object,args=replication check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_object_replication_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_object_replication_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local - hosts: swift_obj vars: check_name: swift_quarantine_check check_details: file=swift-recon.py,args=quarantine check_period: ""{{ maas_check_period }}"" check_timeout: ""{{ maas_check_timeout }}"" alarms: - { 'name': 'swift_quarantine_check', 'criteria': ':set consecutiveCount={{ maas_alarm_local_consecutive_count }} if (metric[""swift_quarantine_check""] != 1) { return new AlarmStatus(CRITICAL, ""API unavailable""); }' } user: root roles: - maas_local ",80,72
openstack%2Fpuppet-monasca~master~I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6,openstack/puppet-monasca,master,I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6,Fixes minor bugs from refactor,MERGED,2014-12-12 15:11:21.000000000,2014-12-12 19:08:45.000000000,2014-12-12 19:08:45.000000000,"[{'_account_id': 3}, {'_account_id': 8126}]","[{'number': 1, 'created': '2014-12-12 15:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/851a9fb73d9ba65ef4925a457d8b5f6f08af42c6', 'message': 'Fixes influx varaible used elsewhere in the module\n\nChange-Id: I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6\n'}, {'number': 2, 'created': '2014-12-12 16:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/117a82890c3e7df2dc3d91a66ecc29c240119e3b', 'message': 'Fixes influx varaible used elsewhere in the module\n\nChange-Id: I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6\n'}, {'number': 3, 'created': '2014-12-12 18:56:03.000000000', 'files': ['manifests/api.pp', 'manifests/init.pp', 'manifests/influxdb/bootstrap.pp'], 'web_link': 'https://opendev.org/openstack/puppet-monasca/commit/9f879a1ceb3453a1cbada0dc91b11d3f3f3f02af', 'message': 'Fixes minor bugs from refactor\n\nChange-Id: I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6\n'}]",0,141398,9f879a1ceb3453a1cbada0dc91b11d3f3f3f02af,11,2,3,11155,,,0,"Fixes minor bugs from refactor

Change-Id: I8797b25af6b27a0e7a4387e5d88a3f7b8e0772e6
",git fetch https://review.opendev.org/openstack/puppet-monasca refs/changes/98/141398/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/influxdb/bootstrap.pp'],1,851a9fb73d9ba65ef4925a457d8b5f6f08af42c6,, include monasca::params $influxdb_dbuser_password = $::monasca::params::api_db_password,,3,0
openstack%2Fnova-specs~master~I83a146a4561fac50fdd3bd961d16ff32cccbf4b9,openstack/nova-specs,master,I83a146a4561fac50fdd3bd961d16ff32cccbf4b9,Update the testing part of the Template,MERGED,2014-12-12 13:05:42.000000000,2014-12-12 19:06:01.000000000,2014-12-12 19:05:59.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1849}, {'_account_id': 5441}, {'_account_id': 9420}]","[{'number': 1, 'created': '2014-12-12 13:05:42.000000000', 'files': ['specs/kilo-template.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4294a7b81d078b96716f0aad749378a40ce03788', 'message': ""Update the testing part of the Template\n\nBecause of the way the testing part of the specs template is written\nyou basically get one of 3 throw away answers in the spec.\n\n1) we'll have unit tests\n2) we'll add tempest tests\n3) we'll have 3rd party testing\n\nHowever, the specs *rarely* actually talk about what's actually\nimportant to test in the feature. Which means those are all kind of\nthrow away statements.\n\nA much more useful piece of information is to ask what are the\ncritical scenarios to test for a feature. What's really important that\nworks. What's really important that it doesn't break something\nelse. What are some interesting edge cases we should be careful about.\n\nThis is an initial stab at that paragraph change. We should probably\nwordsmith on it though.\n\nChange-Id: I83a146a4561fac50fdd3bd961d16ff32cccbf4b9\n""}]",1,141363,4294a7b81d078b96716f0aad749378a40ce03788,11,6,1,2750,,,0,"Update the testing part of the Template

Because of the way the testing part of the specs template is written
you basically get one of 3 throw away answers in the spec.

1) we'll have unit tests
2) we'll add tempest tests
3) we'll have 3rd party testing

However, the specs *rarely* actually talk about what's actually
important to test in the feature. Which means those are all kind of
throw away statements.

A much more useful piece of information is to ask what are the
critical scenarios to test for a feature. What's really important that
works. What's really important that it doesn't break something
else. What are some interesting edge cases we should be careful about.

This is an initial stab at that paragraph change. We should probably
wordsmith on it though.

Change-Id: I83a146a4561fac50fdd3bd961d16ff32cccbf4b9
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/63/141363/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo-template.rst'],1,4294a7b81d078b96716f0aad749378a40ce03788,testing_spec,"Please discuss the important scenarios needed to test here, as well as specific edge cases we should be ensuring work correctly. For each scenario please specify if this requires specialized hardware, a full openstack environment, or can be simulated inside the Nova tree. ",,5,0
openstack%2Ffuel-library~stable%2F6.0~Id6aa98ad3390359ce0aa7295b2f6b4e645741f36,openstack/fuel-library,stable/6.0,Id6aa98ad3390359ce0aa7295b2f6b4e645741f36,Install and run irqbalance for RedHat-based  systems,MERGED,2014-12-12 17:36:35.000000000,2014-12-12 18:57:42.000000000,2014-12-12 18:57:42.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-12 17:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0466380181cf2ce906ac65cd7d13ba9b4ef2123c', 'message': 'Install and run irqbalance for RedHat-based  systems\n\nChange-Id: Id6aa98ad3390359ce0aa7295b2f6b4e645741f36\nCloses-bug: #1401925\n'}, {'number': 2, 'created': '2014-12-12 17:58:18.000000000', 'files': ['deployment/puppet/osnailyfacter/examples/site.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2db32df2d34022cb35ca939b80b227cb3ce202f3', 'message': 'Install and run irqbalance for RedHat-based  systems\n\nChange-Id: Id6aa98ad3390359ce0aa7295b2f6b4e645741f36\nCloses-bug: #1401925\n'}]",0,141438,2db32df2d34022cb35ca939b80b227cb3ce202f3,17,5,2,8786,,,0,"Install and run irqbalance for RedHat-based  systems

Change-Id: Id6aa98ad3390359ce0aa7295b2f6b4e645741f36
Closes-bug: #1401925
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/38/141438/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/examples/site.pp'],1,0466380181cf2ce906ac65cd7d13ba9b4ef2123c,, if $::osfamily =~ /redhat/i { package {'irqbalance': ensure => present} -> service {'irqbalance': ensure => running } } ,,4,0
openstack%2Fnova-specs~master~Ibe97ba82d017a95bc0a6621b07fe971885b35373,openstack/nova-specs,master,Ibe97ba82d017a95bc0a6621b07fe971885b35373,Add a Quobyte Volume Driver in Nova,MERGED,2014-12-02 14:09:35.000000000,2014-12-12 18:55:45.000000000,2014-12-12 18:55:44.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1561}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 6873}, {'_account_id': 13915}]","[{'number': 1, 'created': '2014-12-02 14:09:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/620379a41e99dbef90cce75e63f6fc5fa10c80c1', 'message': 'Add a Quobyte Volume Driver in Nova\n\nSpecification for the corresponding Nova blueprint.\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\nImplements: quobyte-nova-driver\n'}, {'number': 2, 'created': '2014-12-02 14:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/24b0376a42c412f4478c91ede9f476187d244f74', 'message': 'Add a Quobyte Volume Driver in Nova\n\nhttps://blueprints.launchpad.net/nova/+spec/quobyte-nova-driver\n\nAdd a Nova volume driver for the `Quobyte Unified Storage Plane\n<http://quobyte.com/>`_ storage system, allowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 3, 'created': '2014-12-02 14:41:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/44e435a66ee57c526a2cf3d4a6f3cb5ccbff15a0', 'message': 'Add a Quobyte Volume Driver in Nova\n\nhttps://blueprints.launchpad.net/nova/+spec/quobyte-nova-driver\n\nAdd a Nova volume driver for the `Quobyte Unified Storage Plane\n<http://quobyte.com/>`_ storage system, allowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 4, 'created': '2014-12-04 13:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/21eb8b9bc7a61fae4c71a8247b42f6a7354ca830', 'message': 'Add a Quobyte Volume Driver in Nova\n\nAdd a Nova volume driver for the `Quobyte Unified Storage Plane\n<http://quobyte.com/>`_ storage system, allowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nblueprint quobyte-nova-driver\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 5, 'created': '2014-12-09 09:07:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/583bfaf90c9de32146fd04454f9ac72646e18b9b', 'message': 'Add a Quobyte Volume Driver in Nova\n\nhttps://blueprints.launchpad.net/nova/+spec/quobyte-nova-driver\n\nAdd a Nova volume driver for the `Quobyte Unified Storage Plane\n<http://quobyte.com/>`_ storage system, allowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 6, 'created': '2014-12-12 10:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/9d28eccea2b2ab975727d194edd36b085b0e3728', 'message': 'Add a Quobyte Volume Driver in Nova\n\nAdd a Nova volume driver for Quobyte Unified Storage Plane,\nallowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nBlueprint: quobyte-nova-driver\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 7, 'created': '2014-12-12 10:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/0240de37b569efe65a92ba22159bc59e55f3d031', 'message': 'Add a Quobyte Volume Driver in Nova\n\nAdd a Nova volume driver for Quobyte Unified Storage Plane,\nallowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nBlueprint: quobyte-nova-driver\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}, {'number': 8, 'created': '2014-12-12 18:45:41.000000000', 'files': ['specs/kilo/approved/quobyte-nova-driver.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/6a480787b955d3297d999b8babaaf669b57a5a0f', 'message': 'Add a Quobyte Volume Driver in Nova\n\nAdd a Nova volume driver for Quobyte Unified Storage Plane,\nallowing to attach vm images residing\nin Quobyte USP to Nova instances. These images (raw, qcow2) are stored as\nfiles on a Quobyte USP volume.\n\nBlueprint: quobyte-nova-driver\n\nChange-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373\n'}]",9,138373,6a480787b955d3297d999b8babaaf669b57a5a0f,36,8,8,13915,,,0,"Add a Quobyte Volume Driver in Nova

Add a Nova volume driver for Quobyte Unified Storage Plane,
allowing to attach vm images residing
in Quobyte USP to Nova instances. These images (raw, qcow2) are stored as
files on a Quobyte USP volume.

Blueprint: quobyte-nova-driver

Change-Id: Ibe97ba82d017a95bc0a6621b07fe971885b35373
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/73/138373/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/quobyte-nova-driver.rst'],1,620379a41e99dbef90cce75e63f6fc5fa10c80c1,bp/quobyte-nova-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add a Quobyte Volume Driver in Nova ========================================== https://blueprints.launchpad.net/nova/+spec/quobyte-nova-driver Add a Nova volume driver for the `Quobyte Unified Storage Plane <http://quobyte.com/>`_ storage system, allowing to attach vm images residing in Quobyte USP to Nova instances. These images (raw, qcow2) are stored as files on a Quobyte USP volume. Problem description =================== The Quobyte USP provides flexible access to file based storage. Nova can currently not attach Quobyte USP volumes, although a `Cinder driver <https://blueprints.launchpad.net/cinder/+spec/quobyte-usp- driver>`_ is currently in preparation. Use Cases ---------- Operators can deploy Quobyte USP storage for their Nova installations. Project Priority ----------------- None Proposed change =============== Add Quobyte USP support to nova.virt.libvirt.volume.py by adding a new class LibvirtQuobyteVolumeDriver based on the LibvirtBaseVolumeDriver. Code structure will be similiar to the GlusterFS class LibvirtGlusterfsVolumeDriver. The Driver will check mountpoint availability, run mountpoint preparations if required and mount the given Quobyte USP volume based on the configuration data (connection_info, etc.). Based on the local qemu 2.0.0+ availability the driver optimizes performance by adopting matching caching strategies. Other functionlities include volume disconnect (i.e. unmounting the Quobyte USP volume) and configuration data provisioning (get_config). Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- Quobyte USP specific config options are * quobyte_mount_point_base (Directory where the Quobyte volume is mounted on the compute node) * quobyte_client_cfg (Path to a Quobyte Client configuration file) Mounting Quobyte USP volumes is done as Nova user, not as root. The Nova user needs to be FUSE enabled, e.g. a member of the fuse group. The deployer has to install the Quobyte USP software. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: <silvan@quobyte.com> Other contributors: <mberlin@quobyte.com> Work Items ---------- Implementation has been done and tested via Tempest. The code can be found at `Change-Id: Ica1820031f1fc8b66d7ed7fe76ffeb985cf0ef35 <https://review.openstack.org/#/c/110722/>`_. Dependencies ============ This change depends on the addition of disk driver IO policy configurability as implemented in `Change-Id: Iaaa298029e139690526a61de51b569dd8d34236d <https://review.openstack.org/#/c/117442/20>`_ Testing ======= Currently no additional Tempest tests are required as the existing tests and test scenarios cover the volume usage functionalities provided by the driver. For the corresponding Cinder driver a 3rd party CI is in perparation that will also test the Nova driver. Unit tests have been created in conjunction with the existing driver code. Documentation Impact ==================== None References ========== None ",,149,0
openstack%2Fmurano~master~Ib3711164562bea4ac30a96384733d77753ffa69c,openstack/murano,master,Ib3711164562bea4ac30a96384733d77753ffa69c,Use oslo.utils,MERGED,2014-11-29 04:45:20.000000000,2014-12-12 18:54:33.000000000,2014-12-12 18:54:32.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-29 04:45:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/6654ae983510d43b1526b976e4574138fff3175c', 'message': 'Use oslo.utils\n\nFiles from oslo.utils will go away once Murano\nmigrates to oslo.serialization.\n\nChange-Id: Ib3711164562bea4ac30a96384733d77753ffa69c\n'}, {'number': 2, 'created': '2014-11-29 04:59:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2312d74a877e0958586b3c29d2d071269e33699f', 'message': 'Use oslo.utils\n\nFiles from oslo.utils will go away once Murano\nmigrates to oslo.serialization.\n\nChange-Id: Ib3711164562bea4ac30a96384733d77753ffa69c\n'}, {'number': 3, 'created': '2014-12-10 22:50:01.000000000', 'files': ['requirements.txt', 'murano/db/services/core_services.py', 'murano/tests/unit/api/base.py', 'murano/db/models.py', 'murano/tests/unit/api/v1/test_environments.py', 'openstack-common.conf', 'murano/db/services/instances.py', 'murano/engine/system/net_explorer.py', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py', 'murano/tests/unit/api/v1/test_actions.py', 'murano/common/server.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/bf05953c28bbb5c275bfac8f520fc7377886539a', 'message': 'Use oslo.utils\n\nFiles from oslo.utils will go away once Murano\nmigrates to oslo.serialization.\n\nChange-Id: Ib3711164562bea4ac30a96384733d77753ffa69c\n'}]",0,137877,bf05953c28bbb5c275bfac8f520fc7377886539a,28,7,3,7600,,,0,"Use oslo.utils

Files from oslo.utils will go away once Murano
migrates to oslo.serialization.

Change-Id: Ib3711164562bea4ac30a96384733d77753ffa69c
",git fetch https://review.opendev.org/openstack/murano refs/changes/77/137877/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/db/services/core_services.py', 'murano/tests/unit/api/base.py', 'murano/db/models.py', 'murano/tests/unit/api/v1/test_environments.py', 'openstack-common.conf', 'murano/db/migration/alembic_migrations/versions/001_inital_version.py', 'murano/db/services/instances.py', 'murano/engine/system/net_explorer.py', 'murano/tests/unit/api/v1/test_actions.py', 'murano/common/server.py']",10,6654ae983510d43b1526b976e4574138fff3175c,oslo,from oslo.utils import timeutils,from murano.openstack.common import timeutils,11,11
openstack%2Fmurano~master~I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708,openstack/murano,master,I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708,Remove unused imports from genconfig,MERGED,2014-11-29 03:42:50.000000000,2014-12-12 18:54:27.000000000,2014-12-12 18:54:26.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-29 03:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/dfdf6e869217ec6548b8d38904e360af0cc40306', 'message': ""Remove unused imports from genconfig\n\nThere were two unused imports in opts.py:\n* eventlet_backdoor - not used anywhere\n* lockutils - used only by unit tests\n\nWe don't need these options in generated sample config.\n\nChange-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708\n""}, {'number': 2, 'created': '2014-11-29 03:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b9ed9e01ad5595301217f2c6aa674c3fb4b8abdb', 'message': ""Remove unused imports from genconfig\n\nThere were two unused imports in opts.py:\n* eventlet_backdoor - not used anywhere\n* lockutils - used only by unit tests\n\nWe don't need these options in generated sample config.\n\nChange-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708\n""}, {'number': 3, 'created': '2014-11-29 03:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/eb0469f695ba0c9d4353ef2185e91836ac92f50a', 'message': ""Remove unused imports from genconfig\n\nThere were two unused imports in opts.py:\n* eventlet_backdoor - not used anywhere\n* lockutils - used only by unit tests\n\nWe don't need these options in generated sample config.\n\nChange-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708\n""}, {'number': 4, 'created': '2014-11-29 05:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c717882033c9311eed1fcc44addff0e496fc15cb', 'message': ""Remove unused imports from genconfig\n\nThere were two unused imports in opts.py:\n* eventlet_backdoor - not used anywhere\n* lockutils - used only by unit tests\n\nWe don't need these options in generated sample config.\n\nChange-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708\n""}, {'number': 5, 'created': '2014-12-10 09:32:18.000000000', 'files': ['murano/opts.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/2c2d92de6e3b95f73b2f38d1eaa20da8115bb23e', 'message': ""Remove unused imports from genconfig\n\nThere were two unused imports in opts.py:\n* eventlet_backdoor - not used anywhere\n* lockutils - used only by unit tests\n\nWe don't need these options in generated sample config.\n\nChange-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708\n""}]",0,137875,2c2d92de6e3b95f73b2f38d1eaa20da8115bb23e,28,6,5,7600,,,0,"Remove unused imports from genconfig

There were two unused imports in opts.py:
* eventlet_backdoor - not used anywhere
* lockutils - used only by unit tests

We don't need these options in generated sample config.

Change-Id: I3b7d4f326d42de94dec3fd53e18c4d21c0cb3708
",git fetch https://review.opendev.org/openstack/murano refs/changes/75/137875/2 && git format-patch -1 --stdout FETCH_HEAD,['murano/opts.py'],1,dfdf6e869217ec6548b8d38904e360af0cc40306,genconfig,,"import murano.openstack.common.eventlet_backdoor import murano.openstack.common.lockutils murano.openstack.common.eventlet_backdoor.eventlet_backdoor_opts, murano.openstack.common.lockutils.util_opts,",0,4
openstack%2Fmurano~master~I118de30bb0bae577d24d86fa723522580beb13d0,openstack/murano,master,I118de30bb0bae577d24d86fa723522580beb13d0,Update from oslo incubator,MERGED,2014-11-29 03:22:10.000000000,2014-12-12 18:54:20.000000000,2014-12-12 18:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-29 03:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/14b04871c6db6d8376a85e8044cc7522ad9f7223', 'message': 'Update from oslo incubator\n\nDetails about this change:\n* Cleaned up openstack-common.conf, this file should contain\n  only direct dependencies of Murano\n* Removed unused files from openstack/common\n* Added uuidutils to allow net_explorer.py to use it instead\n  of import from another library\n\nChange-Id: I118de30bb0bae577d24d86fa723522580beb13d0\n'}, {'number': 2, 'created': '2014-11-29 03:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/34c4a484d8d80b3c2c8096e1929ccbbbb7fb36c1', 'message': 'Update from oslo incubator\n\nDetails about this change:\n* Cleaned up openstack-common.conf, this file should contain\n  only direct dependencies of Murano\n* Removed unused files from openstack/common\n* Added uuidutils to allow net_explorer.py to use it instead\n  of import from another library\n\nChange-Id: I118de30bb0bae577d24d86fa723522580beb13d0\n'}, {'number': 3, 'created': '2014-11-29 03:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/ec4ea6dbea9087cef1267db9d5d71708c8b6b240', 'message': 'Update from oslo incubator\n\nDetails about this change:\n* Cleaned up openstack-common.conf, this file should contain\n  only direct dependencies of Murano\n* Removed unused files from openstack/common\n\nChange-Id: I118de30bb0bae577d24d86fa723522580beb13d0\n'}, {'number': 4, 'created': '2014-11-29 04:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/bd70c4666ec2bcce2f14c1ced0054c326cc35651', 'message': 'Update from oslo incubator\n\nDetails about this change:\n* Cleaned up openstack-common.conf, this file should contain\n  only direct dependencies of Murano\n* Removed unused files from openstack/common\n* Moved xmlutils to murano/common; this module was removed from\n  oslo-incubator long time ago, but is still used by\n  common/wsgi.py, which also was deprecated by Oslo and adopted\n  by Murano\n\nChange-Id: I118de30bb0bae577d24d86fa723522580beb13d0\n'}, {'number': 5, 'created': '2014-12-10 09:29:14.000000000', 'files': ['murano/openstack/common/eventlet_backdoor.py', 'murano/openstack/common/threadgroup.py', 'murano/openstack/common/excutils.py', 'murano/openstack/common/sslutils.py', 'murano/openstack/common/context.py', 'murano/openstack/common/__init__.py', 'murano/openstack/common/versionutils.py', 'murano/openstack/common/loopingcall.py', 'murano/openstack/common/fileutils.py', 'murano/openstack/common/lockutils.py', 'murano/openstack/common/policy.py', 'murano/openstack/common/_i18n.py', 'murano/openstack/common/processutils.py', 'murano/openstack/common/test.py', 'openstack-common.conf', 'murano/common/wsgi.py', 'murano/common/xmlutils.py', 'murano/openstack/common/network_utils.py', 'murano/openstack/common/service.py', 'murano/openstack/common/config/__init__.py', 'murano/openstack/common/log.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/aa2c8f0a125de50abd0929a5665431bbb3e01151', 'message': 'Update from oslo incubator\n\nDetails about this change:\n* Cleaned up openstack-common.conf, this file should contain\n  only direct dependencies of Murano\n* Removed unused files from openstack/common\n* Moved xmlutils to murano/common; this module was removed from\n  oslo-incubator long time ago, but is still used by\n  common/wsgi.py, which also was deprecated by Oslo and adopted\n  by Murano\n\nChange-Id: I118de30bb0bae577d24d86fa723522580beb13d0\n'}]",0,137873,aa2c8f0a125de50abd0929a5665431bbb3e01151,31,6,5,7600,,,0,"Update from oslo incubator

Details about this change:
* Cleaned up openstack-common.conf, this file should contain
  only direct dependencies of Murano
* Removed unused files from openstack/common
* Moved xmlutils to murano/common; this module was removed from
  oslo-incubator long time ago, but is still used by
  common/wsgi.py, which also was deprecated by Oslo and adopted
  by Murano

Change-Id: I118de30bb0bae577d24d86fa723522580beb13d0
",git fetch https://review.opendev.org/openstack/murano refs/changes/73/137873/4 && git format-patch -1 --stdout FETCH_HEAD,"['murano/openstack/common/eventlet_backdoor.py', 'murano/openstack/common/threadgroup.py', 'murano/openstack/common/excutils.py', 'murano/openstack/common/sslutils.py', 'murano/openstack/common/context.py', 'murano/openstack/common/__init__.py', 'murano/openstack/common/versionutils.py', 'murano/openstack/common/loopingcall.py', 'murano/openstack/common/fileutils.py', 'murano/openstack/common/uuidutils.py', 'murano/openstack/common/lockutils.py', 'murano/openstack/common/policy.py', 'murano/openstack/common/_i18n.py', 'murano/openstack/common/processutils.py', 'murano/openstack/common/test.py', 'openstack-common.conf', 'murano/openstack/common/network_utils.py', 'murano/openstack/common/service.py', 'murano/openstack/common/config/__init__.py', 'murano/openstack/common/log.py']",20,14b04871c6db6d8376a85e8044cc7522ad9f7223,incubator,"import copyimport socketfrom oslo.serialization import jsonutils from oslo.utils import importutils_PY26 = sys.version_info[0:2] == (2, 6) from murano.openstack.common._i18n import _ 'and will change in J to honor RFC5424.'),DEFAULT_LOG_LEVELS = ['amqp=WARN', 'amqplib=WARN', 'boto=WARN', 'qpid=WARN', 'sqlalchemy=WARN', 'suds=INFO', 'oslo.messaging=INFO', 'iso8601=WARN', 'requests.packages.urllib3.connectionpool=WARN', 'urllib3.connectionpool=WARN', 'websocket=WARN', ""keystonemiddleware=WARN"", ""routes.middleware=WARN"", ""stevedore=WARN""] default=DEFAULT_LOG_LEVELS, 'message.'), 'log message.'), def list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(common_cli_opts)), (None, copy.deepcopy(logging_cli_opts)), (None, copy.deepcopy(generic_log_opts)), (None, copy.deepcopy(log_opts)), ] def isEnabledFor(self, level): if _PY26: # This method was added in python 2.7 (and it does the exact # same logic, so we need to do the exact same logic so that # python 2.6 has this capability as well). return self.logger.isEnabledFor(level) else: return super(BaseLoggerAdapter, self).isEnabledFor(level) if six.PY3: # In Python 3, the code fails because the 'manager' attribute # cannot be found when using a LoggerAdapter as the # underlying logger. Work around this issue. self._logger.manager = self._logger.logger.manager # NOTE(jecarey): If msg is not unicode, coerce it into unicode # before it can get to the python logging and # possibly cause string encoding trouble if not isinstance(msg, six.text_type): extra = {'exc_info': (exc_type, value, tb)} except (moves.configparser.Error, KeyError) as exc:def set_defaults(logging_context_format_string=None, default_log_levels=None): # Just in case the caller is not setting the # default_log_level. This is insurance because # we introduced the default_log_level parameter # later in a backwards in-compatible change if default_log_levels is not None: cfg.set_defaults( log_opts, default_log_levels=default_log_levels) if logging_context_format_string is not None: cfg.set_defaults( log_opts, logging_context_format_string=logging_context_format_string) ""oslo.messaging.notify.log_handler.PublishErrorsHandler"", if CONF.use_syslog: try: facility = _find_facility_from_conf() # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) log_root.addHandler(syslog) except socket.error: log_root.error('Unable to add syslog handler. Verify that syslog ' 'is running.') # NOTE(jecarey): If msg is not unicode, coerce it into unicode # before it can get to the python logging and # possibly cause string encoding trouble if not isinstance(record.msg, six.text_type): record.msg = six.text_type(record.msg) fmt = CONF.logging_context_format_string else: fmt = CONF.logging_default_format_string fmt += "" "" + CONF.logging_debug_format_suffix if sys.version_info < (3, 2): self._fmt = fmt else: self._style = logging.PercentStyle(fmt) self._fmt = self._style._fmt","import refrom murano.openstack.common.gettextutils import _ from murano.openstack.common import importutils from murano.openstack.common import jsonutils_SANITIZE_KEYS = ['adminPass', 'admin_pass', 'password', 'admin_password'] # NOTE(ldbragst): Let's build a list of regex objects using the list of # _SANITIZE_KEYS we already have. This way, we only have to add the new key # to the list of _SANITIZE_KEYS and we can generate regular expressions # for XML and JSON automatically. _SANITIZE_PATTERNS = [] _FORMAT_PATTERNS = [r'(%(key)s\s*[=]\s*[\""\']).*?([\""\'])', r'(<%(key)s>).*?(</%(key)s>)', r'([\""\']%(key)s[\""\']\s*:\s*[\""\']).*?([\""\'])', r'([\'""].*?%(key)s[\'""]\s*:\s*u?[\'""]).*?([\'""])', r'([\'""].*?%(key)s[\'""]\s*,\s*\'--?[A-z]+\'\s*,\s*u?[\'""])' '.*?([\'""])', r'(%(key)s\s*--?[A-z]+\s*).*?([\s])'] for key in _SANITIZE_KEYS: for pattern in _FORMAT_PATTERNS: reg_ex = re.compile(pattern % {'key': key}, re.DOTALL) _SANITIZE_PATTERNS.append(reg_ex) 'and will chang in J to honor RFC5424.'), default=[ 'amqp=WARN', 'amqplib=WARN', 'boto=WARN', 'qpid=WARN', 'sqlalchemy=WARN', 'suds=INFO', 'oslo.messaging=INFO', 'iso8601=WARN', 'requests.packages.urllib3.connectionpool=WARN' ], 'message. '), 'log message. '),def mask_password(message, secret=""***""): """"""Replace password with 'secret' in message. :param message: The string which includes security information. :param secret: value with which to replace passwords. :returns: The unicode value of message with the password fields masked. For example: >>> mask_password(""'adminPass' : 'aaaaa'"") ""'adminPass' : '***'"" >>> mask_password(""'admin_pass' : 'aaaaa'"") ""'admin_pass' : '***'"" >>> mask_password('""password"" : ""aaaaa""') '""password"" : ""***""' >>> mask_password(""'original_password' : 'aaaaa'"") ""'original_password' : '***'"" >>> mask_password(""u'original_password' : u'aaaaa'"") ""u'original_password' : u'***'"" """""" message = six.text_type(message) # NOTE(ldbragst): Check to see if anything in message contains any key # specified in _SANITIZE_KEYS, if not then just return the message since # we don't have to mask any passwords. if not any(key in message for key in _SANITIZE_KEYS): return message secret = r'\g<1>' + secret + r'\g<2>' for pattern in _SANITIZE_PATTERNS: message = re.sub(pattern, secret, message) return message # NOTE(mrodden): catch any Message/other object and # coerce to unicode before they can get # to the python logging and possibly # cause string encoding trouble if not isinstance(msg, six.string_types): extra = {} if CONF.verbose or CONF.debug: extra['exc_info'] = (exc_type, value, tb) except moves.configparser.Error as exc:def set_defaults(logging_context_format_string): cfg.set_defaults(log_opts, logging_context_format_string= logging_context_format_string) if CONF.use_syslog: facility = _find_facility_from_conf() # TODO(bogdando) use the format provided by RFCSysLogHandler # after existing syslog format deprecation in J if CONF.use_syslog_rfc_format: syslog = RFCSysLogHandler(address='/dev/log', facility=facility) else: syslog = logging.handlers.SysLogHandler(address='/dev/log', facility=facility) log_root.addHandler(syslog) ""murano.openstack.common.log_handler.PublishErrorsHandler"", self._fmt = CONF.logging_context_format_string else: self._fmt = CONF.logging_default_format_string self._fmt += "" "" + CONF.logging_debug_format_suffix ",407,737
openstack%2Ftripleo-image-elements~master~I98214ced161864d9d3504e0c357465ed66ee1948,openstack/tripleo-image-elements,master,I98214ced161864d9d3504e0c357465ed66ee1948,Add a pypi mirror to the ci overcloud,MERGED,2014-11-27 11:35:03.000000000,2014-12-12 18:53:17.000000000,2014-12-12 18:53:17.000000000,"[{'_account_id': 3}, {'_account_id': 4220}, {'_account_id': 6449}, {'_account_id': 6488}]","[{'number': 1, 'created': '2014-11-27 11:35:03.000000000', 'files': ['elements/tripleo-cd/bin/prepare-ci-overcloud'], 'web_link': 'https://opendev.org/openstack/tripleo-image-elements/commit/3f99f7d14fffad2b3cba0e3139e428eb332c166f', 'message': 'Add a pypi mirror to the ci overcloud\n\nUsing the bandersnatch element, create a pypi mirror on the ci overcloud\nfor use in ci jobs.\n\nChange-Id: I98214ced161864d9d3504e0c357465ed66ee1948\n'}]",2,137611,3f99f7d14fffad2b3cba0e3139e428eb332c166f,10,4,1,1926,,,0,"Add a pypi mirror to the ci overcloud

Using the bandersnatch element, create a pypi mirror on the ci overcloud
for use in ci jobs.

Change-Id: I98214ced161864d9d3504e0c357465ed66ee1948
",git fetch https://review.opendev.org/openstack/tripleo-image-elements refs/changes/11/137611/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/tripleo-cd/bin/prepare-ci-overcloud'],1,3f99f7d14fffad2b3cba0e3139e428eb332c166f,,"# Create a flavor for mirrors with more disk space then is normal nova flavor-show d1.medium || nova flavor-create d1.medium auto 4096 200 2 # Create and boot bandersnatch pypi mirror BANDERSNATCH_IMG=$TRIPLEO_ROOT/bandersnatch.qcow2 if [ ! -e $BANDERSNATCH_IMG -o ""$USE_CACHE"" != ""1"" ] ; then $TRIPLEO_ROOT/diskimage-builder/bin/disk-image-create -a amd64 -o $BANDERSNATCH_IMG \ $TE_DISTRO vm bandersnatch stackuser dhcp-all-interfaces fi # XXX(lifeless) make a load-image patch for virt use if glance image-show bandersnatch &> /dev/null; then glance image-delete bandersnatch fi glance image-create --name bandersnatch --disk-format qcow2 --container-format bare --is-public 1 --file $BANDERSNATCH_IMG --progress if ! nova $NP_CREDS show bandersnatch ; then nova $NP_CREDS boot --image ""bandersnatch"" --flavor d1.medium \ --nic net-id=$DEFAULT_NET \ --nic net-id=$TESTNETID,v4-fixed-ip=172.16.3.252 --key-name default \ bandersnatch fi ",,22,0
openstack%2Fproject-config~master~Ieaa5401bf929d8e36c326613abb97e7ca4b799f0,openstack/project-config,master,Ieaa5401bf929d8e36c326613abb97e7ca4b799f0,ACL update for group-based-policy proj to create branches,MERGED,2014-12-07 20:24:13.000000000,2014-12-12 18:51:37.000000000,2014-12-12 18:51:36.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 3}, {'_account_id': 490}, {'_account_id': 1689}, {'_account_id': 2750}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-12-07 20:24:13.000000000', 'files': ['gerrit/acls/stackforge/group-based-policy.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/af7979eec19f43c1d1673e2abbc68f0f0254348b', 'message': 'ACL update for group-based-policy proj to create branches\n\nUpdating ACLs for group-based-policy-core group to create\nbranchs and push merge commits for group-based-policy-* projects.\n\nChange-Id: Ieaa5401bf929d8e36c326613abb97e7ca4b799f0\n'}]",0,139879,af7979eec19f43c1d1673e2abbc68f0f0254348b,24,12,1,490,,,0,"ACL update for group-based-policy proj to create branches

Updating ACLs for group-based-policy-core group to create
branchs and push merge commits for group-based-policy-* projects.

Change-Id: Ieaa5401bf929d8e36c326613abb97e7ca4b799f0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/79/139879/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/stackforge/group-based-policy.config'],1,af7979eec19f43c1d1673e2abbc68f0f0254348b,gbp,"create = group group-based-policy-core[access ""refs/for/refs/*""] pushMerge = group group-based-policy-core ",,4,0
openstack%2Fproject-config~master~I63ceb672f9d2643695e0fcf27e6df77f91c4db51,openstack/project-config,master,I63ceb672f9d2643695e0fcf27e6df77f91c4db51,Fix neutron jobs for tempest on stable branches,MERGED,2014-12-09 22:28:50.000000000,2014-12-12 18:46:57.000000000,2014-12-12 18:46:56.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-09 22:28:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e602784713315f73482c1dc7aeb156cc22a3fa63', 'message': 'Fix neutron jobs for tempest on stable branches\n\nNeutron full job is now voting for juno, the smoke one can be\ndropped as it is redundant.\n\nIcehouse full job is non-voting for icehouse, so it should be\ndropped as we do not run non-voting jobs on stable.\n\nChange-Id: I63ceb672f9d2643695e0fcf27e6df77f91c4db51\n'}, {'number': 2, 'created': '2014-12-11 16:32:08.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c3b75ebc30d60de1b943b7af6e8815d5c6cba447', 'message': 'Fix neutron jobs for tempest on stable branches\n\nNeutron full job is now voting for juno, the smoke one can be\ndropped as it is redundant.\n\nIcehouse full job is non-voting for icehouse, so it should be\ndropped as we do not run non-voting jobs on stable.\n\nChange-Id: I63ceb672f9d2643695e0fcf27e6df77f91c4db51\n'}]",4,140503,c3b75ebc30d60de1b943b7af6e8815d5c6cba447,13,5,2,1921,,,0,"Fix neutron jobs for tempest on stable branches

Neutron full job is now voting for juno, the smoke one can be
dropped as it is redundant.

Icehouse full job is non-voting for icehouse, so it should be
dropped as we do not run non-voting jobs on stable.

Change-Id: I63ceb672f9d2643695e0fcf27e6df77f91c4db51
",git fetch https://review.opendev.org/openstack/project-config refs/changes/03/140503/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e602784713315f73482c1dc7aeb156cc22a3fa63,drop_juno_smoke,, - check-tempest-dsvm-neutron-juno - check-tempest-dsvm-neutron-full-icehouse,0,2
openstack%2Fmurano~master~I1063cd0e6f1130a1a6031e8d470861ceb0e9d37c,openstack/murano,master,I1063cd0e6f1130a1a6031e8d470861ceb0e9d37c,Update from global-requirements,MERGED,2014-11-28 23:35:58.000000000,2014-12-12 18:43:21.000000000,2014-12-12 18:43:21.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8443}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-28 23:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/1bd804a632c763db9b9feb99096b46e8bdf814fe', 'message': 'Update from global-requirements\n\nThis is an important update of test libraries, it improves\noutput of test failures.\n\nChange-Id: I1063cd0e6f1130a1a6031e8d470861ceb0e9d37c\n'}, {'number': 2, 'created': '2014-11-28 23:51:01.000000000', 'files': ['requirements.txt', 'test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/830a2b808cdf19c3e7a0840d439b04d53d2a697f', 'message': 'Update from global-requirements\n\nThis is an important update of test libraries, it improves\noutput of test failures. Update of hacking library introduces\na bunch of new rules which are added to ingore list\n(see tox.ini) for now.\n\nChange-Id: I1063cd0e6f1130a1a6031e8d470861ceb0e9d37c\n'}]",1,137866,830a2b808cdf19c3e7a0840d439b04d53d2a697f,18,8,2,7600,,,0,"Update from global-requirements

This is an important update of test libraries, it improves
output of test failures. Update of hacking library introduces
a bunch of new rules which are added to ingore list
(see tox.ini) for now.

Change-Id: I1063cd0e6f1130a1a6031e8d470861ceb0e9d37c
",git fetch https://review.opendev.org/openstack/murano refs/changes/66/137866/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,1bd804a632c763db9b9feb99096b46e8bdf814fe,requirements,"hacking>=0.9.2,<0.10testtools>=0.9.36,!=1.2.0","hacking>=0.8.0,<0.9testtools>=0.9.34",4,4
openstack%2Fdevstack~master~I77749f3f9f1a64719447ddd25ee95bc6d3afa5b3,openstack/devstack,master,I77749f3f9f1a64719447ddd25ee95bc6d3afa5b3,"Revert ""Update used Fedora images to version 21""",MERGED,2014-12-12 00:52:59.000000000,2014-12-12 18:31:37.000000000,2014-12-12 02:35:51.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 4715}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-12 00:52:59.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6d012cf16f8d0f4f0a2fae4f5215fadf9884f7fc', 'message': 'Revert ""Update used Fedora images to version 21""\n\nThis breaks check-heat-dsvm-functional-mysql which assumes the previous glance image name.\n\nThis reverts commit 21dbe993348b794a1b77c4f9db0081d1cc32138c.\n\nChange-Id: I77749f3f9f1a64719447ddd25ee95bc6d3afa5b3\n'}]",0,141230,6d012cf16f8d0f4f0a2fae4f5215fadf9884f7fc,8,5,1,4571,,,0,"Revert ""Update used Fedora images to version 21""

This breaks check-heat-dsvm-functional-mysql which assumes the previous glance image name.

This reverts commit 21dbe993348b794a1b77c4f9db0081d1cc32138c.

Change-Id: I77749f3f9f1a64719447ddd25ee95bc6d3afa5b3
",git fetch https://review.opendev.org/openstack/devstack refs/changes/30/141230/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,6d012cf16f8d0f4f0a2fae4f5215fadf9884f7fc,fedora21," HEAT_CFN_IMAGE_URL=${HEAT_CFN_IMAGE_URL:-""https://download.fedoraproject.org/pub/alt/openstack/20/x86_64/Fedora-x86_64-20-20140618-sda.qcow2""} IMAGE_URL=""https://download.fedoraproject.org/pub/alt/openstack/20/x86_64/Fedora-x86_64-20-20140618-sda.qcow2"""," HEAT_CFN_IMAGE_URL=${HEAT_CFN_IMAGE_URL:-""https://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Base-20141203-21.x86_64.qcow2""} IMAGE_URL=""https://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Base-20141203-21.x86_64.qcow2""",2,2
openstack%2Fmonasca-thresh~master~I0291168635f2311585de011d9003f6af06120b86,openstack/monasca-thresh,master,I0291168635f2311585de011d9003f6af06120b86,Messages not distributed across Kafka partitions,MERGED,2014-12-11 23:39:46.000000000,2014-12-12 18:25:29.000000000,2014-12-12 18:25:28.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-11 23:39:46.000000000', 'files': ['thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBolt.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBoltTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/KafkaAlarmEventForwarder.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineTest.java', 'thresh/src/main/java/monasca/thresh/TopologyModule.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineAlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmEventForwarder.java', 'thresh/src/main/java/monasca/thresh/ThresholdingConfiguration.java'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/50dabd084708ca1e67d54007119db784cfe52490', 'message': 'Messages not distributed across Kafka partitions\n\nChange AlarmStateTransitionNotification Kafka message key to be\nthe message count instead of a constant to get a good\ndistribution across Kafka partitions\n\nJAH-926 event and AlarmStateTransition messages are not\ndistributed across Kafka partitions\n\nChange-Id: I0291168635f2311585de011d9003f6af06120b86\n'}]",0,141215,50dabd084708ca1e67d54007119db784cfe52490,7,3,1,11809,,,0,"Messages not distributed across Kafka partitions

Change AlarmStateTransitionNotification Kafka message key to be
the message count instead of a constant to get a good
distribution across Kafka partitions

JAH-926 event and AlarmStateTransition messages are not
distributed across Kafka partitions

Change-Id: I0291168635f2311585de011d9003f6af06120b86
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/15/141215/1 && git format-patch -1 --stdout FETCH_HEAD,"['thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBolt.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBoltTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/KafkaAlarmEventForwarder.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineTest.java', 'thresh/src/main/java/monasca/thresh/TopologyModule.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineAlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmEventForwarder.java', 'thresh/src/main/java/monasca/thresh/ThresholdingConfiguration.java']",8,50dabd084708ca1e67d54007119db784cfe52490,, /** Configuration for the spout that receives metrics from Kafka. */ /** Configuration for the spout that receives events from Kafka. */ /** Configuration for publishing to the Kafka. */," public static final String ALERTS_EXCHANGE = ""thresh.external.alerts""; public static final String ALERTS_ROUTING_KEY = ""thresh.external.alert""; /** Configuration for the spout that receives metrics from the external exchange. */ /** Configuration for the spout that receives events from the external exchange. */ /** Configuration for publishing to the alerts exchange on the external server. */ @NotEmpty public String alertsExchange = ""alerts""; @NotEmpty public String alertsRoutingKey = ""alert"";",17,31
openstack%2Fmonasca-api~master~If4464e0340d230a693c7930568e9db532fe5c95c,openstack/monasca-api,master,If4464e0340d230a693c7930568e9db532fe5c95c,Distribute the AlarmStateTransitionEvents better,MERGED,2014-12-11 23:27:16.000000000,2014-12-12 18:22:45.000000000,2014-12-12 18:22:44.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 10046}, {'_account_id': 12512}]","[{'number': 1, 'created': '2014-12-11 23:27:16.000000000', 'files': ['src/main/java/monasca/api/app/AlarmService.java', 'docs/monasca-api-spec.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/70fbe68f63ec0786548cd3f0aa163d80e4d4d113', 'message': 'Distribute the AlarmStateTransitionEvents better\n\nThe AlarmStateTransitionEvents used to go to kafka partitions based\non tenant_id, instead use a message count to ensure they are\ndistributed well\n\nJIRA JAH-926 event and AlarmStateTransition messages are not\ndistributed across Kafka partitions\n\nChange-Id: If4464e0340d230a693c7930568e9db532fe5c95c\n'}]",0,141213,70fbe68f63ec0786548cd3f0aa163d80e4d4d113,8,4,1,11809,,,0,"Distribute the AlarmStateTransitionEvents better

The AlarmStateTransitionEvents used to go to kafka partitions based
on tenant_id, instead use a message count to ensure they are
distributed well

JIRA JAH-926 event and AlarmStateTransition messages are not
distributed across Kafka partitions

Change-Id: If4464e0340d230a693c7930568e9db532fe5c95c
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/13/141213/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/main/java/monasca/api/app/AlarmService.java', 'docs/monasca-api-spec.md']",2,70fbe68f63ec0786548cd3f0aa163d80e4d4d113,,In this example the metric uniquely identified with the name `cpu.system_perc` and dimension `hostname=host.domain.com` is compared to the threshold 95.,In this example the metric uniquely identified with the name=cpu.system_perc and dimension hostname=host.domain.com is compared to the threshold 95.,3,2
openstack%2Fnova~master~Id826a33298885e9dbd4b52c9fe518ed2e6d50469,openstack/nova,master,Id826a33298885e9dbd4b52c9fe518ed2e6d50469,VMware: Support volume hotplug,MERGED,2014-09-17 21:20:26.000000000,2014-12-12 18:22:29.000000000,2014-12-11 21:44:40.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7148}, {'_account_id': 7400}, {'_account_id': 8247}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 9569}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-17 21:20:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2cf018687b16b03e60be17ea577161228554ea20', 'message': 'VMware: Throw exception for disk hotplug\n\nVMware IDE adapter does not support disk hotplug. Instead of\nthrowing a exception, the code attempts to reconfigure the VM and\nfails with ""operation cannot be performed in the current state"".\nThe following patch throws an exception.Invalid when attempting\nto hotplug a disk to an active instance.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 2, 'created': '2014-09-18 00:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d47beef726c0f3464256e3c46b69f13540a20ad1', 'message': 'VMware: Throw exception for disk hotplug\n\nVMware IDE adapter does not support disk hotplug. Instead of\nthrowing a exception, the code attempts to reconfigure the VM and\nfails with ""operation cannot be performed in the current state"".\nThe following patch throws an exception.Invalid when attempting\nto hotplug a disk to an active instance.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 3, 'created': '2014-10-10 02:38:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a00726cd096f800c9d97346ada821ae101ed5e40', 'message': 'VMware: Support volume hotplug\n\nWhen a volume is attached to an instance, the disk_type and\nadapter_type are found by making a get_dynamic_property vim\ncall to the instance. If where the adapter_type returned is\n""ide"", the volume attach fails with ""operation cannot be\nperformed in the current state"". This is because VMware IDE\nadapter does not support disk hotplug.\n\nInstead of making a get_dynamic_property vim call to the\ninstance, it should be made to the volume (shadow VM). This\nproperly indicates what adapter_type is needed by the volume.\nIf the instance does not have a controller to support the\nvolume adapter_type (e.g. lsiLogic), one will be added.\nIf the volume adapter_type is ""ide"", a exception.Invalid will\nbe thrown.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 4, 'created': '2014-10-10 03:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d727ecd94e7159ab33595aeb56eead7fed738a5a', 'message': 'VMware: Support volume hotplug\n\nWhen a volume is attached to an instance, the disk_type and\nadapter_type are found by making a get_dynamic_property vim\ncall to the instance. If the adapter_type returned is\n""ide"", the volume attach fails with ""operation cannot be\nperformed in the current state"". This is because VMware IDE\nadapter does not support disk hotplug.\n\nInstead of making a get_dynamic_property vim call to the\ninstance, it should be made to the volume (shadow VM). This\nproperly indicates what adapter_type is needed by the volume.\nIf the instance does not have a controller to support the\nvolume adapter_type (e.g. lsiLogic), one will be added.\nIf the volume adapter_type is ""ide"", a exception.Invalid will\nbe thrown.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 5, 'created': '2014-10-20 20:08:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f2f5cd52ec9d3715a674588d0380857c9400a492', 'message': 'VMware: Support volume hotplug\n\nWhen a volume is attached to an instance, the disk_type and\nadapter_type are found by making a get_dynamic_property vim\ncall to the instance. If the adapter_type returned is\n""ide"", the volume attach fails with ""operation cannot be\nperformed in the current state"". This is because VMware IDE\nadapter does not support disk hotplug.\n\nInstead of making a get_dynamic_property vim call to the\ninstance, it should be made to the volume (shadow VM). This\nproperly indicates what adapter_type is needed by the volume.\nIf the instance does not have a controller to support the\nvolume adapter_type (e.g. lsiLogic), one will be added.\nIf the volume adapter_type is ""ide"", a exception.Invalid will\nbe thrown.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 6, 'created': '2014-11-13 20:39:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f504a5e596367efd7b7dbe767a7af76b9a6308f', 'message': 'VMware: Support volume hotplug\n\nWhen a volume is attached to an instance, the disk_type and\nadapter_type are found by making a get_dynamic_property vim\ncall to the instance. If the adapter_type returned is\n""ide"", the volume attach fails with ""operation cannot be\nperformed in the current state"". This is because VMware IDE\nadapter does not support disk hotplug.\n\nInstead of making a get_dynamic_property vim call to the\ninstance, it should be made to the volume (shadow VM). This\nproperly indicates what adapter_type is needed by the volume.\nIf the instance does not have a controller to support the\nvolume adapter_type (e.g. lsiLogic), one will be added.\nIf the volume adapter_type is ""ide"", a exception.Invalid will\nbe thrown.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}, {'number': 7, 'created': '2014-12-11 19:40:20.000000000', 'files': ['nova/virt/vmwareapi/volumeops.py', 'nova/tests/unit/virt/vmwareapi/test_driver_api.py', 'nova/tests/unit/virt/vmwareapi/test_volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e3fd9b377c082791670ce94ed972e0103f88d399', 'message': 'VMware: Support volume hotplug\n\nWhen a volume is attached to an instance, the disk_type and\nadapter_type are found by making a get_dynamic_property vim\ncall to the instance. If the adapter_type returned is\n""ide"", the volume attach fails with ""operation cannot be\nperformed in the current state"". This is because VMware IDE\nadapter does not support disk hotplug.\n\nInstead of making a get_dynamic_property vim call to the\ninstance, it should be made to the volume (shadow VM). This\nproperly indicates what adapter_type is needed by the volume.\nIf the instance does not have a controller to support the\nvolume adapter_type (e.g. lsiLogic), one will be added.\nIf the volume adapter_type is ""ide"", a exception.Invalid will\nbe thrown.\n\nChange-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469\nCloses-Bug: #1226543\n'}]",11,122251,e3fd9b377c082791670ce94ed972e0103f88d399,72,15,7,8247,,,0,"VMware: Support volume hotplug

When a volume is attached to an instance, the disk_type and
adapter_type are found by making a get_dynamic_property vim
call to the instance. If the adapter_type returned is
""ide"", the volume attach fails with ""operation cannot be
performed in the current state"". This is because VMware IDE
adapter does not support disk hotplug.

Instead of making a get_dynamic_property vim call to the
instance, it should be made to the volume (shadow VM). This
properly indicates what adapter_type is needed by the volume.
If the instance does not have a controller to support the
volume adapter_type (e.g. lsiLogic), one will be added.
If the volume adapter_type is ""ide"", a exception.Invalid will
be thrown.

Change-Id: Id826a33298885e9dbd4b52c9fe518ed2e6d50469
Closes-Bug: #1226543
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/122251/6 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/volumeops.py', 'nova/tests/virt/vmwareapi/test_volumeops.py']",2,2cf018687b16b03e60be17ea577161228554ea20,bug/1226543,"from nova.compute import vm_states from nova import exceptionfrom nova.virt.vmwareapi import vm_util def test_attach_volume_vmdk_invalid(self): connection_info = {'driver_volume_type': 'vmdk', 'serial': 'volume-fake-id', 'data': {'volume': 'vm-10', 'volume_id': 'volume-fake-id'}} volume_ref = mock.MagicMock() instance = mock.MagicMock(name='fake-name', vm_state=vm_states.ACTIVE) path_and_type = ('fake-path', 'ide', 'preallocated') with contextlib.nested( mock.patch.object(vm_util, ""get_vm_ref"", return_value='fake-vm-ref'), mock.patch.object(self._volumeops, ""_get_volume_ref"", return_value=volume_ref), mock.patch.object(vm_util, 'get_vmdk_path_and_adapter_type', return_value=path_and_type), mock.patch.object(self._volumeops, '_get_vmdk_base_volume_device') ) as (get_vm_ref, get_volume_ref, get_vmdk_path_and_adapter_type, get_vmdk_base_volume_device): self.assertRaises(exception.Invalid, self._volumeops._attach_volume_vmdk, connection_info, instance, '/dev/sdb') get_vm_ref.assert_called_once_with(self._volumeops._session, instance) get_volume_ref.assert_called_once_with( connection_info['data']['volume']) get_vmdk_base_volume_device.assert_called_once_with(volume_ref) self.assertTrue(get_vmdk_path_and_adapter_type.called) def test_detach_volume_vmdk_invalid(self): connection_info = {'driver_volume_type': 'vmdk', 'serial': 'volume-fake-id', 'data': {'volume': 'vm-10', 'volume_id': 'volume-fake-id'}} instance = mock.MagicMock(name='fake-name', vm_state=vm_states.ACTIVE) path_and_type = ('fake-path', 'ide', 'preallocated') with contextlib.nested( mock.patch.object(vm_util, ""get_vm_ref"", return_value='fake-vm-ref'), mock.patch.object(self._volumeops, ""_get_vmdk_backed_disk_device""), mock.patch.object(vm_util, 'get_vmdk_path_and_adapter_type', return_value=path_and_type) ) as (get_vm_ref, get_vmdk_backed_disk_device, get_vmdk_path_and_adapter_type): self.assertRaises(exception.Invalid, self._volumeops._detach_volume_vmdk, connection_info, instance, '/dev/sdb') get_vm_ref.assert_called_once_with(self._volumeops._session, instance) get_vmdk_backed_disk_device.assert_called_once_with('fake-vm-ref', connection_info['data']) self.assertTrue(get_vmdk_path_and_adapter_type.called)",,87,11
openstack%2Fmonasca-api~master~Ib9de42f1c2120ef565b2f4a54e26f72ea505f084,openstack/monasca-api,master,Ib9de42f1c2120ef565b2f4a54e26f72ea505f084,Added a link to the API spec docs,MERGED,2014-12-12 17:47:50.000000000,2014-12-12 18:17:53.000000000,2014-12-12 18:17:52.000000000,"[{'_account_id': 3}, {'_account_id': 11809}, {'_account_id': 14273}]","[{'number': 1, 'created': '2014-12-12 17:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/0fedab9f891b202967cb9c1e662a8e96914d2822', 'message': 'Added a link to the API spec docs.\n\nChange-Id: Ib9de42f1c2120ef565b2f4a54e26f72ea505f084\n'}, {'number': 2, 'created': '2014-12-12 18:07:17.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/2d5f2039234cafdc75ef727fc18b63e776c53018', 'message': 'Added a link to the API spec docs\n\nChange-Id: Ib9de42f1c2120ef565b2f4a54e26f72ea505f084\n'}]",0,141442,2d5f2039234cafdc75ef727fc18b63e776c53018,9,3,2,11094,,,0,"Added a link to the API spec docs

Change-Id: Ib9de42f1c2120ef565b2f4a54e26f72ea505f084
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/42/141442/2 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,0fedab9f891b202967cb9c1e662a8e96914d2822,,The full API Specification can be found in [docs/monasca-api-spec.md](docs/monasca-api-spec.md) ,,2,0
openstack%2Fdevstack~master~I8b51ca2c6ef734bf2747cec48a2f751eb682afe5,openstack/devstack,master,I8b51ca2c6ef734bf2747cec48a2f751eb682afe5,Fix fwaas service plugin location,MERGED,2014-12-11 19:19:54.000000000,2014-12-12 18:15:42.000000000,2014-12-11 22:50:53.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 970}, {'_account_id': 5196}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 19:19:54.000000000', 'files': ['lib/neutron_plugins/services/firewall'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6accb136d3219af588d26a904f8a1f748d5e8818', 'message': 'Fix fwaas service plugin location\n\nThis was missed during the services split.\n\nChange-Id: I8b51ca2c6ef734bf2747cec48a2f751eb682afe5\n'}]",0,141136,6accb136d3219af588d26a904f8a1f748d5e8818,14,7,1,105,,,0,"Fix fwaas service plugin location

This was missed during the services split.

Change-Id: I8b51ca2c6ef734bf2747cec48a2f751eb682afe5
",git fetch https://review.opendev.org/openstack/devstack refs/changes/36/141136/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron_plugins/services/firewall'],1,6accb136d3219af588d26a904f8a1f748d5e8818,fw-fix," iniset_multiline $FWAAS_DRIVER_CONF_FILENAME fwaas driver ""neutron_fwaas.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver"""," iniset_multiline $FWAAS_DRIVER_CONF_FILENAME fwaas driver ""neutron.services.firewall.drivers.linux.iptables_fwaas.IptablesFwaasDriver""",1,1
openstack%2Fnova~master~Ib63da2d845843410634a1df0261af33b973daf32,openstack/nova,master,Ib63da2d845843410634a1df0261af33b973daf32,fix import of oslo.concurrency,MERGED,2014-12-11 18:11:23.000000000,2014-12-12 18:13:22.000000000,2014-12-12 01:07:33.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 18:11:23.000000000', 'files': ['nova/virt/libvirt/remotefs.py', 'nova/tests/unit/virt/libvirt/test_remotefs.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e258eecbaef9ba1b4f1ec097b46e389a9d060b14', 'message': ""fix import of oslo.concurrency\n\nIt's now oslo_concurrency, and importing the old symbol triggers a\ndeprecation warning. There were 2 instances of this unfixed.\n\nChange-Id: Ib63da2d845843410634a1df0261af33b973daf32\n""}]",0,141117,e258eecbaef9ba1b4f1ec097b46e389a9d060b14,11,7,1,2750,,,0,"fix import of oslo.concurrency

It's now oslo_concurrency, and importing the old symbol triggers a
deprecation warning. There were 2 instances of this unfixed.

Change-Id: Ib63da2d845843410634a1df0261af33b973daf32
",git fetch https://review.opendev.org/openstack/nova refs/changes/17/141117/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/remotefs.py', 'nova/tests/unit/virt/libvirt/test_remotefs.py']",2,e258eecbaef9ba1b4f1ec097b46e389a9d060b14,oslo_deprecations,from oslo_concurrency import processutils,from oslo.concurrency import processutils,2,2
openstack%2Fproject-config~master~I1bbf5d5d513c6c5dc63c35bc916d38b761d43cdf,openstack/project-config,master,I1bbf5d5d513c6c5dc63c35bc916d38b761d43cdf,"Add neutron jobs to service repos, until they get their own tests",MERGED,2014-12-11 18:36:47.000000000,2014-12-12 18:11:16.000000000,2014-12-12 18:11:16.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-11 18:36:47.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e806ac3291ab92ec3635b72b76a09eb993186b57', 'message': 'Add neutron jobs to service repos, until they get their own tests\n\nChange-Id: I1bbf5d5d513c6c5dc63c35bc916d38b761d43cdf\n'}]",0,141122,e806ac3291ab92ec3635b72b76a09eb993186b57,19,7,1,10980,,,0,"Add neutron jobs to service repos, until they get their own tests

Change-Id: I1bbf5d5d513c6c5dc63c35bc916d38b761d43cdf
",git fetch https://review.opendev.org/openstack/project-config refs/changes/22/141122/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e806ac3291ab92ec3635b72b76a09eb993186b57,add-gate-jobs, - name: check-requirements - name: integrated-gate-neutron - name: check-requirements - name: integrated-gate-neutron - name: check-requirements - name: integrated-gate-neutron,,6,0
openstack%2Fproject-config~master~I671ce746d9009b5458d72eab396d9d66d5b19bb2,openstack/project-config,master,I671ce746d9009b5458d72eab396d9d66d5b19bb2,Remove dibtest from experimental queue,MERGED,2014-12-12 02:06:22.000000000,2014-12-12 18:11:09.000000000,2014-12-12 18:11:09.000000000,"[{'_account_id': 1}, {'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5263}, {'_account_id': 6316}]","[{'number': 1, 'created': '2014-12-12 02:06:22.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/80cf5622477b479128819de85560ed07122c32cd', 'message': ""Remove dibtest from experimental queue\n\ndibtest isn't getting nodes allocated it preventing other experimental\njobs in devstack-gate from reporting back. This is blocking the testing\nof the aiopcpu jobs\n\nChange-Id: I671ce746d9009b5458d72eab396d9d66d5b19bb2\n""}]",0,141245,80cf5622477b479128819de85560ed07122c32cd,11,5,1,1849,,,0,"Remove dibtest from experimental queue

dibtest isn't getting nodes allocated it preventing other experimental
jobs in devstack-gate from reporting back. This is blocking the testing
of the aiopcpu jobs

Change-Id: I671ce746d9009b5458d72eab396d9d66d5b19bb2
",git fetch https://review.opendev.org/openstack/project-config refs/changes/45/141245/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,80cf5622477b479128819de85560ed07122c32cd,,, - experimental-tempest-dsvm-full-dibtest - experimental-tempest-dsvm-neutron-full-dibtest - experimental-tempest-dsvm-full-icehouse-dibtest - experimental-tempest-dsvm-neutron-icehouse-dibtest,0,4
openstack%2Fproject-config~master~I8589bb7dddb5ec6836139eae9e5656ffb0b6d8ec,openstack/project-config,master,I8589bb7dddb5ec6836139eae9e5656ffb0b6d8ec,Change os-ansible-aio-build check settings,MERGED,2014-12-11 15:33:38.000000000,2014-12-12 18:10:52.000000000,2014-12-12 18:10:51.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7353}]","[{'number': 1, 'created': '2014-12-11 15:33:38.000000000', 'files': ['jenkins/jobs/os-ansible-jobs.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3b21f1e905761fee29a444d863fa46ed9485326f', 'message': 'Change os-ansible-aio-build check settings\n\nOnly set the build check to run on the master branch in order to prevent\nissues with tagging/branching and increase the build timeout to 120\nmins in order to cater for new build requirements and further testing.\n\nChange-Id: I8589bb7dddb5ec6836139eae9e5656ffb0b6d8ec\n'}]",0,141072,3b21f1e905761fee29a444d863fa46ed9485326f,10,4,1,6816,,,0,"Change os-ansible-aio-build check settings

Only set the build check to run on the master branch in order to prevent
issues with tagging/branching and increase the build timeout to 120
mins in order to cater for new build requirements and further testing.

Change-Id: I8589bb7dddb5ec6836139eae9e5656ffb0b6d8ec
",git fetch https://review.opendev.org/openstack/project-config refs/changes/72/141072/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/os-ansible-jobs.yaml', 'zuul/layout.yaml']",2,3b21f1e905761fee29a444d863fa46ed9485326f,os-ansible-deployment, branch: master,,2,1
openstack%2Fmurano~master~I13ea64b20b0539ddd16e981d61e2ac19ad03212a,openstack/murano,master,I13ea64b20b0539ddd16e981d61e2ac19ad03212a,Remove py26 from tox targets,MERGED,2014-11-29 01:44:58.000000000,2014-12-12 18:08:04.000000000,2014-12-12 18:08:03.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-29 01:44:58.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/murano/commit/f2956a33a0c98e6f15696a1880f23b22154e07dc', 'message': 'Remove py26 from tox targets\n\nOpenStack drops Python 2.6 support in Kilo.\n\nChange-Id: I13ea64b20b0539ddd16e981d61e2ac19ad03212a\n'}]",0,137868,f2956a33a0c98e6f15696a1880f23b22154e07dc,11,6,1,7600,,,0,"Remove py26 from tox targets

OpenStack drops Python 2.6 support in Kilo.

Change-Id: I13ea64b20b0539ddd16e981d61e2ac19ad03212a
",git fetch https://review.opendev.org/openstack/murano refs/changes/68/137868/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f2956a33a0c98e6f15696a1880f23b22154e07dc,py26-goodbye,"envlist = py27,pep8","envlist = py26,py27,pep8",1,1
openstack%2Fmurano~master~Ie289cb43a696ce3c3d41458f21cdc0e7062f74e1,openstack/murano,master,Ie289cb43a696ce3c3d41458f21cdc0e7062f74e1,Added generated sample config to gitignore,MERGED,2014-11-29 03:46:53.000000000,2014-12-12 18:07:57.000000000,2014-12-12 18:07:56.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-11-29 03:46:53.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/murano/commit/06da408563ffd706167036e8be687b9826c2616a', 'message': 'Added generated sample config to gitignore\n\nChange-Id: Ie289cb43a696ce3c3d41458f21cdc0e7062f74e1\n'}]",0,137876,06da408563ffd706167036e8be687b9826c2616a,17,6,1,7600,,,0,"Added generated sample config to gitignore

Change-Id: Ie289cb43a696ce3c3d41458f21cdc0e7062f74e1
",git fetch https://review.opendev.org/openstack/murano refs/changes/76/137876/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,06da408563ffd706167036e8be687b9826c2616a,gitignore-sample-config, #Autogenerated sample config file etc/murano/murano.conf.sample,,3,0
openstack%2Fnova~master~I106cd57001f028de7cc8ce7c7024809bceaed020,openstack/nova,master,I106cd57001f028de7cc8ce7c7024809bceaed020,Make objects use the generalized backport scheme,MERGED,2014-09-16 18:29:06.000000000,2014-12-12 18:07:47.000000000,2014-12-11 19:16:52.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 5511}, {'_account_id': 6450}, {'_account_id': 6685}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-09-16 18:29:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/84b01e5214870cb81f292775d7b57a975467d764', 'message': 'WIP Instance sub object backporting\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 2, 'created': '2014-09-16 19:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8faff3880b49ba7ddc257bf7fa27ae28fb59c73b', 'message': 'WIP Instance sub object backporting\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 3, 'created': '2014-10-09 15:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2daaaec930a578ef346bd93bafa780c78c2b2161', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 4, 'created': '2014-10-09 19:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fe3c41fe904e4b611ac8b7fb25bd07cdd6b54e6', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 5, 'created': '2014-10-09 20:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0c69701216ca6a896499af09150e665569194121', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 6, 'created': '2014-10-22 14:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f92e954b35dbf19ef324095b9380477c149758a6', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 7, 'created': '2014-10-23 14:09:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b1e5fd09b70ac0285e793f6fe709c0d0e7b1657a', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 8, 'created': '2014-10-28 15:56:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4453d28c3a6119ddab923d646b925ba85512214', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 9, 'created': '2014-11-13 18:11:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/715adfa2cf56829dcd3bfd2cd1a2395186639788', 'message': 'WIP Instance sub object backporting\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n'}, {'number': 10, 'created': '2014-11-21 17:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4c21644bad6bbe03972662448a28409d1af2da54', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 11, 'created': '2014-11-21 19:26:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ce40e8395c1bfe60e24838605e1ae19f1e8fb07', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 12, 'created': '2014-12-05 15:24:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5178ae4a32621e2d9943e7f55e18ac1a30ccc70d', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 13, 'created': '2014-12-08 15:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da0ad7b783c29633c4207f9224e3354d723ec358', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 14, 'created': '2014-12-08 16:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/904565a70783acf5a90ef4c8e36075108306cf19', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 15, 'created': '2014-12-11 15:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/de4eb5fc63678fc8bbc2367a5bc9d6260b2be0aa', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}, {'number': 16, 'created': '2014-12-11 17:08:34.000000000', 'files': ['nova/objects/floating_ip.py', 'nova/objects/compute_node.py', 'nova/objects/service.py', 'nova/objects/block_device.py', 'nova/objects/instance.py', 'nova/objects/instance_pci_requests.py', 'nova/objects/fixed_ip.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/aa2ac81c8aa0b6790679754cf1ddc24d634ee659', 'message': ""Make objects use the generalized backport scheme\n\nThis makes the objects that have subobjects use the base class'\nobj_make_compatible() implementation for backports.\n\nRelated to blueprint kilo-objects\n\nChange-Id: I106cd57001f028de7cc8ce7c7024809bceaed020\n""}]",9,121947,aa2ac81c8aa0b6790679754cf1ddc24d634ee659,115,15,16,4393,,,0,"Make objects use the generalized backport scheme

This makes the objects that have subobjects use the base class'
obj_make_compatible() implementation for backports.

Related to blueprint kilo-objects

Change-Id: I106cd57001f028de7cc8ce7c7024809bceaed020
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/121947/16 && git format-patch -1 --stdout FETCH_HEAD,['nova/objects/instance.py'],1,84b01e5214870cb81f292775d7b57a975467d764,bp/kilo-objects," obj_relationships = { 'fault': [('1.0': '1.0')], 'info_cache': [('1.1', '1.0'), ('1.9', '1.4'), ('1.10', '1.5')], 'security_groups': [('1.2', '1.0')], 'pci_devices': [('1.6', '1.0'), ('1.15', '1.1')], 'numa_topology': [('1.14', '1.0')], } super(Instance, self).obj_make_compatible(primitive, target_version)"," if target_version < (1, 14) and 'numa_topology' in primitive: del primitive['numa_topology'] if target_version < (1, 10) and 'info_cache' in primitive: # NOTE(danms): Instance <= 1.9 (havana) had info_cache 1.4 self.info_cache.obj_make_compatible(primitive['info_cache'], '1.4') primitive['info_cache']['nova_object.version'] = '1.4' if target_version < (1, 15) and 'pci_devices' in primitive: # NOTE(baoli): Instance <= 1.14 (icehouse) had PciDeviceList 1.0 # NOTE(vish): pci_devices is a list object so we must pull the # underlying primitive out of the nova_object_data. self.pci_devices.obj_make_compatible( primitive['pci_devices']['nova_object.data'], '1.0') primitive['pci_devices']['nova_object.version'] = '1.0' if target_version < (1, 6): # NOTE(danms): Before 1.6 there was no pci_devices list if 'pci_devices' in primitive: del primitive['pci_devices']",9,18
openstack%2Fmurano~master~Iec32be5b640dad7e3826b17b1dd41c6957b123a6,openstack/murano,master,Iec32be5b640dad7e3826b17b1dd41c6957b123a6,Update information about murano sample config file,MERGED,2014-11-25 14:20:24.000000000,2014-12-12 18:02:49.000000000,2014-12-12 18:02:48.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-11-25 14:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/9db9cfa6af0f3b46bd9a2cb9d2aa0969986be832', 'message': 'Update information about murano configuration file\n\nChange-Id: Iec32be5b640dad7e3826b17b1dd41c6957b123a6\n'}, {'number': 2, 'created': '2014-12-02 15:58:28.000000000', 'files': ['doc/source/install/manual.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/94fcdd966f6163ddbedc82e7cf19bf83e6a73913', 'message': 'Update information about murano sample config file\n\nChange-Id: Iec32be5b640dad7e3826b17b1dd41c6957b123a6\n'}]",0,137076,94fcdd966f6163ddbedc82e7cf19bf83e6a73913,17,5,2,13149,,,0,"Update information about murano sample config file

Change-Id: Iec32be5b640dad7e3826b17b1dd41c6957b123a6
",git fetch https://review.opendev.org/openstack/murano refs/changes/76/137076/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/manual.rst'],1,9db9cfa6af0f3b46bd9a2cb9d2aa0969986be832,update-manual,3. Generate the sample configuration file with *tox*. .. code-block:: console $ cd ~/murano/murano $ tox -egenconfig .. 4. Copy the sample configuration from the source tree to their final location.5. Edit ``murano.conf`` with your favorite editor. Below is an example6. Create a virtual environment and install Murano prerequisites. We will use7. Create database tables for Murano.8. Open a new console and launch Murano API. A separate terminal is9. Import Core Murano Library.10. Open a new console and launch Murano Engine. A separate terminal is,3. Copy the sample configuration from the source tree to their final location.4. Edit ``murano.conf`` with your favorite editor. Below is an example5. Create a virtual environment and install Murano prerequisites. We will use6. Create database tables for Murano.7. Open a new console and launch Murano API. A separate terminal is8. Import Core Murano Library.8. Open a new console and launch Murano Engine. A separate terminal is,15,7
openstack%2Fmurano-dashboard~master~I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0,openstack/murano-dashboard,master,I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0,Add selenium package to test-requirements,MERGED,2014-11-27 11:15:14.000000000,2014-12-12 18:02:42.000000000,2014-12-12 18:02:41.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-11-27 11:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/578c70ae3c5e92c9bbf8023326a549af3b214a28', 'message': 'Add selenium package to test-requirements\n\nChange-Id: I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0\nCloses-Bug: #1396963\n'}, {'number': 2, 'created': '2014-11-28 13:30:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/787596f3364f84c8dbf6e339c7acf2c5cfa0c699', 'message': 'Add selenium package to test-requirements\n\nChange-Id: I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0\nCloses-Bug: #1396963\n'}, {'number': 3, 'created': '2014-12-09 11:54:05.000000000', 'files': ['test-requirements.txt', 'muranodashboard/tests/functional/base.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/ce845913d1939702782c73868a2c89ccf8307d1b', 'message': 'Add selenium package to test-requirements\n\nChange-Id: I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0\nCloses-Bug: #1396963\n'}]",2,137603,ce845913d1939702782c73868a2c89ccf8307d1b,21,10,3,7549,,,0,"Add selenium package to test-requirements

Change-Id: I835d89ac40f59f66bafd8114ad2d4c4c68c52ce0
Closes-Bug: #1396963
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/03/137603/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,578c70ae3c5e92c9bbf8023326a549af3b214a28,bug/1396963,selenium,,1,0
openstack%2Fmurano-dashboard~master~Ia17d3482cfe9d26d4f338594da033cd19ac13471,openstack/murano-dashboard,master,Ia17d3482cfe9d26d4f338594da033cd19ac13471,Remove unused openstack common modules,MERGED,2014-12-05 14:49:48.000000000,2014-12-12 18:02:35.000000000,2014-12-12 18:02:34.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-12-05 14:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/519991e48e9ebf60b584d3ed875391447c0b6d91', 'message': 'Use oslo.utils\n\nRemove unused jsonutils\n\nChange-Id: Ia17d3482cfe9d26d4f338594da033cd19ac13471\n'}, {'number': 2, 'created': '2014-12-05 15:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/dd89c7695248f0fd76f575333f60d3c72564ca46', 'message': 'Use oslo.utils\n\nRemove unused openstack common modules\n\nChange-Id: Ia17d3482cfe9d26d4f338594da033cd19ac13471\n'}, {'number': 3, 'created': '2014-12-10 14:22:11.000000000', 'files': ['requirements.txt', 'muranodashboard/openstack/common/importutils.py', 'openstack-common.conf', 'muranodashboard/openstack/common/jsonutils.py'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/5c48009eb9b8f98d6cbf556f74b1f85083042511', 'message': 'Remove unused openstack common modules\n\nChange-Id: Ia17d3482cfe9d26d4f338594da033cd19ac13471\n'}]",0,139644,5c48009eb9b8f98d6cbf556f74b1f85083042511,18,8,3,7549,,,0,"Remove unused openstack common modules

Change-Id: Ia17d3482cfe9d26d4f338594da033cd19ac13471
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/44/139644/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'muranodashboard/openstack/common/importutils.py', 'openstack-common.conf', 'muranodashboard/openstack/common/jsonutils.py']",4,519991e48e9ebf60b584d3ed875391447c0b6d91,oslo_update,,"# Copyright 2010 United States Government as represented by the # Administrator of the National Aeronautics and Space Administration. # Copyright 2011 Justin Santa Barbara # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. ''' JSON related utilities. This module provides a few things: 1) A handy function for getting an object down to something that can be JSON serialized. See to_primitive(). 2) Wrappers around loads() and dumps(). The dumps() wrapper will automatically use to_primitive() for you if needed. 3) This sets up anyjson to use the loads() and dumps() wrappers if anyjson is available. ''' import codecs import datetime import functools import inspect import itertools import sys is_simplejson = False if sys.version_info < (2, 7): # On Python <= 2.6, json module is not C boosted, so try to use # simplejson module if available try: import simplejson as json is_simplejson = True except ImportError: import json else: import json import six import six.moves.xmlrpc_client as xmlrpclib from muranodashboard.openstack.common import gettextutils from muranodashboard.openstack.common import importutils from muranodashboard.openstack.common import strutils from muranodashboard.openstack.common import timeutils netaddr = importutils.try_import(""netaddr"") _nasty_type_tests = [inspect.ismodule, inspect.isclass, inspect.ismethod, inspect.isfunction, inspect.isgeneratorfunction, inspect.isgenerator, inspect.istraceback, inspect.isframe, inspect.iscode, inspect.isbuiltin, inspect.isroutine, inspect.isabstract] _simple_types = (six.string_types + six.integer_types + (type(None), bool, float)) def to_primitive(value, convert_instances=False, convert_datetime=True, level=0, max_depth=3): """"""Convert a complex object into primitives. Handy for JSON serialization. We can optionally handle instances, but since this is a recursive function, we could have cyclical data structures. To handle cyclical data structures we could track the actual objects visited in a set, but not all objects are hashable. Instead we just track the depth of the object inspections and don't go too deep. Therefore, convert_instances=True is lossy ... be aware. """""" # handle obvious types first - order of basic types determined by running # full tests on nova project, resulting in the following counts: # 572754 <type 'NoneType'> # 460353 <type 'int'> # 379632 <type 'unicode'> # 274610 <type 'str'> # 199918 <type 'dict'> # 114200 <type 'datetime.datetime'> # 51817 <type 'bool'> # 26164 <type 'list'> # 6491 <type 'float'> # 283 <type 'tuple'> # 19 <type 'long'> if isinstance(value, _simple_types): return value if isinstance(value, datetime.datetime): if convert_datetime: return timeutils.strtime(value) else: return value # value of itertools.count doesn't get caught by nasty_type_tests # and results in infinite loop when list(value) is called. if type(value) == itertools.count: return six.text_type(value) # FIXME(vish): Workaround for LP bug 852095. Without this workaround, # tests that raise an exception in a mocked method that # has a @wrap_exception with a notifier will fail. If # we up the dependency to 0.5.4 (when it is released) we # can remove this workaround. if getattr(value, '__module__', None) == 'mox': return 'mock' if level > max_depth: return '?' # The try block may not be necessary after the class check above, # but just in case ... try: recursive = functools.partial(to_primitive, convert_instances=convert_instances, convert_datetime=convert_datetime, level=level, max_depth=max_depth) if isinstance(value, dict): return dict((k, recursive(v)) for k, v in six.iteritems(value)) elif isinstance(value, (list, tuple)): return [recursive(lv) for lv in value] # It's not clear why xmlrpclib created their own DateTime type, but # for our purposes, make it a datetime type which is explicitly # handled if isinstance(value, xmlrpclib.DateTime): value = datetime.datetime(*tuple(value.timetuple())[:6]) if convert_datetime and isinstance(value, datetime.datetime): return timeutils.strtime(value) elif isinstance(value, gettextutils.Message): return value.data elif hasattr(value, 'iteritems'): return recursive(dict(value.iteritems()), level=level + 1) elif hasattr(value, '__iter__'): return recursive(list(value)) elif convert_instances and hasattr(value, '__dict__'): # Likely an instance of something. Watch for cycles. # Ignore class member vars. return recursive(value.__dict__, level=level + 1) elif netaddr and isinstance(value, netaddr.IPAddress): return six.text_type(value) else: if any(test(value) for test in _nasty_type_tests): return six.text_type(value) return value except TypeError: # Class objects are tricky since they may define something like # __iter__ defined but it isn't callable as list(). return six.text_type(value) def dumps(value, default=to_primitive, **kwargs): if is_simplejson: kwargs['namedtuple_as_object'] = False return json.dumps(value, default=default, **kwargs) def dump(obj, fp, *args, **kwargs): if is_simplejson: kwargs['namedtuple_as_object'] = False return json.dump(obj, fp, *args, **kwargs) def loads(s, encoding='utf-8', **kwargs): return json.loads(strutils.safe_decode(s, encoding), **kwargs) def load(fp, encoding='utf-8', **kwargs): return json.load(codecs.getreader(encoding)(fp), **kwargs) try: import anyjson except ImportError: pass else: anyjson._modules.append((__name__, 'dumps', TypeError, 'loads', ValueError, 'load')) anyjson.force_implementation(__name__) ",5,272
openstack%2Fmurano-dashboard~master~Ia1463aa31c23794b4e473068098125e0acf119b6,openstack/murano-dashboard,master,Ia1463aa31c23794b4e473068098125e0acf119b6,Improve component details page,MERGED,2014-09-10 14:28:42.000000000,2014-12-12 18:02:26.000000000,2014-12-12 18:02:25.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 8040}, {'_account_id': 8443}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-09-10 14:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/644accb5a6446a15aea5a2a6f11af65551a2042a', 'message': 'Improve component details page\n\nDisplay links to corresponding instance and stack for deployed components\n\nCloses-Bug: #1367635\n\nChange-Id: Ia1463aa31c23794b4e473068098125e0acf119b6\n'}, {'number': 2, 'created': '2014-09-10 15:07:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f1063557e18de50a2f49b04110f615b3a94d4945', 'message': 'Improve component details page\n\nDisplay links to corresponding instance and stack for deployed components\n\nCloses-Bug: #1367635\n\nChange-Id: Ia1463aa31c23794b4e473068098125e0acf119b6\n'}, {'number': 3, 'created': '2014-09-11 07:42:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/808ae99591765e1660f521b67a4444502162230b', 'message': 'Improve component details page\n\nDisplay links to corresponding instance and stack for deployed components\n\nCloses-Bug: #1367635\n\nChange-Id: Ia1463aa31c23794b4e473068098125e0acf119b6\n'}, {'number': 4, 'created': '2014-10-09 12:00:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/2e40504b2e150096821de0f0220d31303747201b', 'message': 'Improve component details page\n\nDisplay links to corresponding instance and stack for deployed components\n\nCloses-Bug: #1367635\n\nChange-Id: Ia1463aa31c23794b4e473068098125e0acf119b6\n'}, {'number': 5, 'created': '2014-12-06 14:36:13.000000000', 'files': ['muranodashboard/environments/tabs.py', 'muranodashboard/templates/services/_overview.html'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/66f9dff7a7d92def87e23c85a38e77bcaf2ab686', 'message': ""Improve component details page\n\nDisplay links to corresponding instance and stack for deployed components\n\nOnly applied if parameter, reliable for the virtual machine\ncalled 'instance' or 'instances' in app definition\n\nCloses-Bug: #1367635\n\nChange-Id: Ia1463aa31c23794b4e473068098125e0acf119b6\n""}]",0,120435,66f9dff7a7d92def87e23c85a38e77bcaf2ab686,32,10,5,7549,,,0,"Improve component details page

Display links to corresponding instance and stack for deployed components

Only applied if parameter, reliable for the virtual machine
called 'instance' or 'instances' in app definition

Closes-Bug: #1367635

Change-Id: Ia1463aa31c23794b4e473068098125e0acf119b6
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/35/120435/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/environments/tabs.py', 'muranodashboard/templates/services/_overview.html']",2,644accb5a6446a15aea5a2a6f11af65551a2042a,bug/1367635, {% if key == 'Instance' %} {% elif key == 'Stack'%}," {% if key == 'instance' %} {% elif key == 'stack'%} {% for unit in units %} <div class=""status row detail""> <h4>{% blocktrans %}Component unit{% endblocktrans %}{{ forloop.counter }} </h4> <hr class=""header_rule""> <dl> {% for key, value in unit.items %} {% if key == 'instance' %} <dt>Component instance name</dt> <dd> <a href="" {% url 'horizon:project:instances:detail' value.id %}""> {{ value.name }} </a> </dd><br> {% elif key == 'stack'%} <dt>Heat stack name</dt> <dd> <a href="" {% url 'horizon:project:stacks:detail' value.id %}""> {{ value.name }} </a> </dd><br> {% else %} <dt>{% blocktrans %} {{ key }} {% endblocktrans %}</dt> <dd>{% blocktrans %} {{ value }} {% endblocktrans %}</dd> <br> {% endif %} </dl> {% endfor %} </div> {% endfor %}",32,32
openstack%2Fmurano~stable%2Fjuno~I947ed688b44c52ea72211bf630f411ef538fb9b8,openstack/murano,stable/juno,I947ed688b44c52ea72211bf630f411ef538fb9b8,Fix for functional tests and DB migration unit tests,MERGED,2014-12-04 14:18:17.000000000,2014-12-12 18:02:15.000000000,2014-12-12 18:02:14.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7549}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}, {'_account_id': 13962}]","[{'number': 1, 'created': '2014-12-04 14:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/e4de368657d3bc50f5acfed7795d35c8c79e9762', 'message': ""Fix for functional CLI tests and DB migration unit tests\n\nThis commit consists of two parts. We need to merge them\nboth to pass all the CI jobs:\n\n1. Updated functional CLI tests after a change in tempest\n\nThis change fixes DSVM gate.\nAlso fix contains backported tests from murano-master.\n\n2. Update DB migration tests in respect to new release of Alembic\n\nAfter alembic update output of 'history' command in alembic changed.\nThis commit fixes failing unit tests.\n\nChange-Id: I947ed688b44c52ea72211bf630f411ef538fb9b8\n""}, {'number': 2, 'created': '2014-12-10 23:27:44.000000000', 'files': ['murano/tests/functional/api/v1/test_sessions.py', 'murano/tests/unit/db/migration/test_migrations_base.py', 'murano/tests/functional/cli/muranoclient.py', 'murano/tests/functional/api/v1/test_envs.py', 'murano/tests/functional/api/v1/test_repository.py', 'murano/tests/functional/api/base.py', 'murano/tests/functional/engine/base.py', 'murano/tests/functional/api/v1/test_services.py', 'murano/tests/functional/cli/simple_read_only/test_murano.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/22a0a109c48603d97cba0675ee50b69e14dc7f7f', 'message': ""Fix for functional tests and DB migration unit tests\n\nThis commit consists of three parts. We need to merge them\nboth to pass all the CI jobs:\n\n1. Updated functional CLI tests after a change in tempest\n   Also fix contains backported tests from murano-master.\n\n2. Update DB migration tests in respect to new release of Alembic\n   After alembic update output of 'history' command in alembic\n   changed. This commit fixes failing unit tests.\n\n   commit id (master): 1f1786895538dc187454a9b9b8da2b953e6e929e\n\n3. Fix Murano app names:\n   Names of apps used in CI were changes in murano-incubator. This\n   change updates configuration of functional tests to retrieve\n   apps with respect to their new names.\n\n   commit id (master): 931b2e9d62d7a1cd295d8bbd0b4218f50757d220\n\nCo-authored-by: Ruslan Kamaldinov <rkamaldinov@mirantis.com>\nChange-Id: I947ed688b44c52ea72211bf630f411ef538fb9b8\n""}]",0,139067,22a0a109c48603d97cba0675ee50b69e14dc7f7f,24,10,2,7600,,,0,"Fix for functional tests and DB migration unit tests

This commit consists of three parts. We need to merge them
both to pass all the CI jobs:

1. Updated functional CLI tests after a change in tempest
   Also fix contains backported tests from murano-master.

2. Update DB migration tests in respect to new release of Alembic
   After alembic update output of 'history' command in alembic
   changed. This commit fixes failing unit tests.

   commit id (master): 1f1786895538dc187454a9b9b8da2b953e6e929e

3. Fix Murano app names:
   Names of apps used in CI were changes in murano-incubator. This
   change updates configuration of functional tests to retrieve
   apps with respect to their new names.

   commit id (master): 931b2e9d62d7a1cd295d8bbd0b4218f50757d220

Co-authored-by: Ruslan Kamaldinov <rkamaldinov@mirantis.com>
Change-Id: I947ed688b44c52ea72211bf630f411ef538fb9b8
",git fetch https://review.opendev.org/openstack/murano refs/changes/67/139067/1 && git format-patch -1 --stdout FETCH_HEAD,"['murano/tests/functional/api/v1/test_sessions.py', 'murano/tests/unit/db/migration/test_migrations_base.py', 'murano/tests/functional/cli/muranoclient.py', 'murano/tests/functional/api/v1/test_envs.py', 'murano/tests/functional/api/base.py', 'murano/tests/functional/api/v1/test_repository.py', 'murano/tests/functional/engine/base.py', 'murano/tests/functional/api/v1/test_services.py', 'murano/tests/functional/cli/simple_read_only/test_murano.py']",9,e4de368657d3bc50f5acfed7795d35c8c79e9762,,"import time import uuid environments = self.listing('environment-list') packages = self.listing('package-list') def test_table_struct_of_environment_create(self): env_name = ""gg"" + uuid.uuid4().hex environment = self.listing('environment-create', params=env_name) self.assertTableStruct(environment, ['ID', 'Name', 'Created', 'Updated']) def test_table_struct_of_environment_delete(self): env_name = ""gg"" + uuid.uuid4().hex environment = self.listing('environment-create', params=env_name) ID = self.get_value('ID', 'Name', env_name, environment) delete_env = self.listing('environment-delete', params=ID) self.assertTableStruct(delete_env, ['ID', 'Name', 'Created', 'Updated']) class EnvironmentMuranoClientTest(muranoclient.ClientTestBase): @classmethod def setUpClass(cls): super(EnvironmentMuranoClientTest, cls).setUpClass() def test_environment_create(self): env_name = ""gg"" + uuid.uuid4().hex environment = self.listing('environment-create', params=env_name) environment_list = self.listing('environment-list') self.assertIn(env_name, [env['Name'] for env in environment]) self.assertIn(env_name, [env['Name'] for env in environment_list]) def test_environment_delete(self): env_name = ""gg"" + uuid.uuid4().hex environments = self.listing('environment-create', params=env_name) ID = self.get_value('ID', 'Name', env_name, environments) self.listing('environment-delete', params=ID) start_time = time.time() while env_name in [env['Name'] for env in self.listing('environment-list')]: if start_time - time.time() > 60: self.fail(""Environment is not deleted in 60 seconds"") def test_environment_show(self): env_name = ""gg"" + uuid.uuid4().hex environment = self.listing('environment-create', params=env_name) ID = self.get_value('ID', 'Name', env_name, environment) created = self.get_value('Created', 'Name', env_name, environment) updated = self.get_value('Updated', 'Name', env_name, environment) show_env = self.listing('environment-show', params=ID) self.assertEqual(env_name, self.get_value('Value', 'Property', 'name', show_env)) self.assertEqual(created, self.get_value('Value', 'Property', 'created', show_env)) self.assertEqual(updated, self.get_value('Value', 'Property', 'updated', show_env)) def test_environment_rename(self): env_name = ""gg"" + uuid.uuid4().hex environment = self.listing('environment-create', params=env_name) ID = self.get_value('ID', 'Name', env_name, environment) new_name = ""renamed"" + uuid.uuid4().hex rename_env = self.listing('environment-rename', params='{id} {name}'.format(id=ID, name=new_name)) show_env = self.listing('environment-show', params=ID) self.assertEqual(new_name, self.get_value('Name', 'ID', ID, rename_env)) self.assertEqual(new_name, self.get_value('Value', 'Property', 'name', show_env))", environments = self.parser.listing(self.murano('environment-list')) packages = self.parser.listing(self.murano('package-list')),344,236
openstack%2Fnova~master~Iaff1b435819e9aefcd2b362c846c87f9efa3f618,openstack/nova,master,Iaff1b435819e9aefcd2b362c846c87f9efa3f618,Fix base obj_make_compatible() handling ListOfObjectsField,MERGED,2014-12-08 16:26:56.000000000,2014-12-12 18:02:07.000000000,2014-12-11 19:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 16:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/953cb5abe80e6dea5b7c957b77bbd4b5e5f47dd2', 'message': ""Fix base obj_make_compatible() handling ListOfObjectsField\n\nThis makes the base class' obj_make_compatible() handle lists of\nobjects properly.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Iaff1b435819e9aefcd2b362c846c87f9efa3f618\n""}, {'number': 2, 'created': '2014-12-11 15:35:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8d9646cf2f8e42afdd53e29cda08267fc6b8060d', 'message': ""Fix base obj_make_compatible() handling ListOfObjectsField\n\nThis makes the base class' obj_make_compatible() handle lists of\nobjects properly.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Iaff1b435819e9aefcd2b362c846c87f9efa3f618\n""}, {'number': 3, 'created': '2014-12-11 17:08:33.000000000', 'files': ['nova/objects/base.py', 'nova/tests/unit/objects/test_objects.py', 'nova/objects/instance_numa_topology.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/0d6e110b87c2e65e4093157e39e4e318705fbf51', 'message': ""Fix base obj_make_compatible() handling ListOfObjectsField\n\nThis makes the base class' obj_make_compatible() handle lists of\nobjects properly.\n\nRelated to blueprint kilo-objects\n\nChange-Id: Iaff1b435819e9aefcd2b362c846c87f9efa3f618\n""}]",0,140065,0d6e110b87c2e65e4093157e39e4e318705fbf51,24,9,3,4393,,,0,"Fix base obj_make_compatible() handling ListOfObjectsField

This makes the base class' obj_make_compatible() handle lists of
objects properly.

Related to blueprint kilo-objects

Change-Id: Iaff1b435819e9aefcd2b362c846c87f9efa3f618
",git fetch https://review.opendev.org/openstack/nova refs/changes/65/140065/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/objects/base.py', 'nova/tests/unit/objects/test_objects.py']",2,953cb5abe80e6dea5b7c957b77bbd4b5e5f47dd2,bp/kilo-objects," 'rel_object': fields.ObjectField('MyOwnedObject', nullable=True), 'rel_objects': fields.ListOfObjectsField('MyOwnedObject', nullable=True), myobj_fields = (['foo', 'bar', 'missing', 'readonly', 'rel_object', 'rel_objects'] + base_fields) 'rel_object=<?>,rel_objects=<?>,updated_at=<?>)', repr(obj)) def test_obj_make_compatible_handles_list_of_objects(self): subobj = MyOwnedObject(baz=1) obj = MyObj(rel_objects=[subobj]) obj.obj_relationships = {'rel_objects': [('1.0', '1.123')]} def fake_make_compat(primitive, version): self.assertEqual('1.123', version) self.assertIn('baz', primitive) with mock.patch.object(subobj, 'obj_make_compatible') as mock_mc: mock_mc.side_effect = fake_make_compat obj.obj_to_primitive('1.0') self.assertTrue(mock_mc.called) 'MyObj': '1.6-02b1e712b7ee334fa3fefe024c340977', 'TestSubclassedObject': '1.6-87177ccbefd7a740a9e261f958e15b00',"," 'rel_object': fields.ObjectField('MyOwnedObject', nullable=True) myobj_fields = ['foo', 'bar', 'missing', 'readonly', 'rel_object'] + base_fields 'rel_object=<?>,updated_at=<?>)', repr(obj)) 'MyObj': '1.6-65fc480767fcc4289ce1849e91df9959', 'TestSubclassedObject': '1.6-b9be83b5587fbca3c8570aab67cb3d02',",35,8
openstack%2Ftempest~master~I1fd12cb3e20692c60daa4eb19c6d876b00318d56,openstack/tempest,master,I1fd12cb3e20692c60daa4eb19c6d876b00318d56,Bump working version to 4,MERGED,2014-12-11 16:47:36.000000000,2014-12-12 17:58:39.000000000,2014-12-11 18:53:45.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 16:47:36.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e869ff3d32014aa918ccaee28c7ab9bfa94c1461', 'message': 'Bump working version to 4\n\nWith the tempest-3 tag being published to signify the end of xml\ntesting in tempest we need to bump the working version to tempest-4\nto indicate that the next tag will be 4.\n\nChange-Id: I1fd12cb3e20692c60daa4eb19c6d876b00318d56\n'}]",0,141098,e869ff3d32014aa918ccaee28c7ab9bfa94c1461,7,3,1,5196,,,0,"Bump working version to 4

With the tempest-3 tag being published to signify the end of xml
testing in tempest we need to bump the working version to tempest-4
to indicate that the next tag will be 4.

Change-Id: I1fd12cb3e20692c60daa4eb19c6d876b00318d56
",git fetch https://review.opendev.org/openstack/tempest refs/changes/98/141098/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,e869ff3d32014aa918ccaee28c7ab9bfa94c1461,bump-version-4,version = 4,version = 3,1,1
openstack%2Fmurano-specs~master~I93f445d5ef713f7a18bf3e7463d44d1ebc7bed4c,openstack/murano-specs,master,I93f445d5ef713f7a18bf3e7463d44d1ebc7bed4c,Added new spec,ABANDONED,2014-12-10 19:06:45.000000000,2014-12-12 17:51:36.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-10 19:06:45.000000000', 'files': ['some.spec'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/9e2c83bb5310e4195e22f937bdad1800c904dd9b', 'message': 'Added new spec\n\nChange-Id: I93f445d5ef713f7a18bf3e7463d44d1ebc7bed4c\n'}]",0,140808,9e2c83bb5310e4195e22f937bdad1800c904dd9b,3,1,1,7225,,,0,"Added new spec

Change-Id: I93f445d5ef713f7a18bf3e7463d44d1ebc7bed4c
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/08/140808/1 && git format-patch -1 --stdout FETCH_HEAD,['some.spec'],1,9e2c83bb5310e4195e22f937bdad1800c904dd9b,bp/new-bp,,,0,0
openstack%2Fmurano~master~Ia48911ea6af416befe6fe623be2f7bb131314c47,openstack/murano,master,Ia48911ea6af416befe6fe623be2f7bb131314c47,Add Error Log entry on ValueError exception,ABANDONED,2014-09-08 20:21:22.000000000,2014-12-12 17:46:38.000000000,,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}]","[{'number': 1, 'created': '2014-09-08 20:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/17b8794f4e033bd17761d2473ae2c0757a5279a3', 'message': 'Add Error Log entry on ValueError exception\n\nThis patch adds a new log entry on MuranoPL execution fail.\n\nChange-Id: Ia48911ea6af416befe6fe623be2f7bb131314c47\nCloses-Bug: #1366962\n'}, {'number': 2, 'created': '2014-09-15 09:19:27.000000000', 'files': ['murano/dsl/expressions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/a1fe9cd88025537962831dff1b64bd771f5ea1d5', 'message': 'Add Error Log entry on ValueError exception\n\nThis patch adds a new log entry on MuranoPL execution fail.\n\nChange-Id: Ia48911ea6af416befe6fe623be2f7bb131314c47\nCloses-Bug: #1366962\n'}]",3,119899,a1fe9cd88025537962831dff1b64bd771f5ea1d5,7,6,2,8443,,,0,"Add Error Log entry on ValueError exception

This patch adds a new log entry on MuranoPL execution fail.

Change-Id: Ia48911ea6af416befe6fe623be2f7bb131314c47
Closes-Bug: #1366962
",git fetch https://review.opendev.org/openstack/murano refs/changes/99/119899/2 && git format-patch -1 --stdout FETCH_HEAD,['murano/dsl/expressions.py'],1,17b8794f4e033bd17761d2473ae2c0757a5279a3,(detached,import murano.openstack.common.log as loggingLOG = logging.getLogger(__name__) LOG.error( 'Error in expression {0}'.format(self.expression)) raise SyntaxError(), raise SyntaxError( 'Syntax is incorrect in expression: {0}'.format(expr)),5,3
openstack%2Fmurano~master~I55813580f67a720b01190220e8db81252f25736e,openstack/murano,master,I55813580f67a720b01190220e8db81252f25736e,Add description to action method,ABANDONED,2014-08-04 04:57:21.000000000,2014-12-12 17:46:24.000000000,,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 10063}]","[{'number': 1, 'created': '2014-08-04 04:57:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/2abe178c746efd4a066c903888474aec8a546a32', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\n'}, {'number': 2, 'created': '2014-08-04 15:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/90b5af425cf959d81e53f90c980760a024406d28', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\n'}, {'number': 3, 'created': '2014-08-04 20:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/78f462b66c51768b59bb1728c321a825c0a068e4', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\n'}, {'number': 4, 'created': '2014-08-04 23:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/8762c68024e58fd64425b482cada8c35a8bc4e38', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\n'}, {'number': 5, 'created': '2014-08-18 18:38:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/91aa4a99ac9fdbd19095e7ad7167b5bccfab9594', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\nPartially-Implements: blueprint application-actions\n'}, {'number': 6, 'created': '2014-08-18 18:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/504c7e2c1e366ca246c4e09ba16296a966cadd60', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\nPartially-Implements: blueprint application-actions\n'}, {'number': 7, 'created': '2014-08-20 20:34:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b72d3adea7dd274f40b0bdb49ca275d347f4fe45', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\nPartially-Implements: blueprint application-actions\n'}, {'number': 8, 'created': '2014-08-28 04:56:36.000000000', 'files': ['murano/dsl/murano_method.py', 'murano/dsl/results_serializer.py', 'murano/tests/unit/test_actions.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/8ff863c2f2d1a4ee2dd8891cf3efd69f9bfbdab8', 'message': 'Add description to action method\n\nThis patch adds a new Description field to the MuranoPL method\nThis description method field will be saved as a part of object model\nand will be available to display in UI\n\nChange-Id: I55813580f67a720b01190220e8db81252f25736e\nPartially-Implements: blueprint application-actions\n'}]",3,111639,8ff863c2f2d1a4ee2dd8891cf3efd69f9bfbdab8,45,5,8,8443,,,0,"Add description to action method

This patch adds a new Description field to the MuranoPL method
This description method field will be saved as a part of object model
and will be available to display in UI

Change-Id: I55813580f67a720b01190220e8db81252f25736e
Partially-Implements: blueprint application-actions
",git fetch https://review.opendev.org/openstack/murano refs/changes/39/111639/8 && git format-patch -1 --stdout FETCH_HEAD,"['murano/dsl/murano_method.py', 'murano/dsl/results_serializer.py']",2,2abe178c746efd4a066c903888474aec8a546a32,bp/application-actions," 'enabled': True, 'description': method.description", 'enabled': True,7,1
openstack%2Fmurano-dashboard~master~I3ec2fd4b1931e2c3e71a12900d01ddffecee221a,openstack/murano-dashboard,master,I3ec2fd4b1931e2c3e71a12900d01ddffecee221a,Helpers for installing into horizon,ABANDONED,2014-08-08 21:38:12.000000000,2014-12-12 17:46:13.000000000,,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 7821}]","[{'number': 1, 'created': '2014-08-08 21:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/f91d409987881fac9c0e5849b153f2a9961958b1', 'message': ""Helpers for installing into horizon\n\n* horizon-installation/murano_dashboard.py should be linked to\n  openstack_dashboard/local/enabled, and will enable the dashboard\n* muranodashboard/dashboard.py has a 'permissions' attribute that\n  enables muranodashboard only if murano is installed in keystone.\n  This will need overriding for development (i.e. if you're hosting\n  locally and keystone doesn't know about it).\n\nChange-Id: I3ec2fd4b1931e2c3e71a12900d01ddffecee221a\n""}, {'number': 2, 'created': '2014-08-08 21:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/877dbac72936fbd4b845257ebd73829bde09d235', 'message': ""Helpers for installing into horizon\n\n* horizon-installation/murano_dashboard.py should be linked to\n  openstack_dashboard/local/enabled, and will enable the dashboard\n* muranodashboard/dashboard.py has a 'permissions' attribute that\n  enables muranodashboard only if murano is installed in keystone.\n  This will need overriding for development (i.e. if you're hosting\n  locally and keystone doesn't know about it).\n\nChange-Id: I3ec2fd4b1931e2c3e71a12900d01ddffecee221a\n""}, {'number': 3, 'created': '2014-08-12 16:14:07.000000000', 'files': ['horizon-installation/murano_dashboard.py', 'muranodashboard/dashboard.py', 'horizon-installation/README.md'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/d6772bc03a05796eb4f90a6c210b50d6067b4990', 'message': ""Helpers for installing into horizon\n\n* horizon-installation/murano_dashboard.py should be linked to\n  openstack_dashboard/local/enabled, and will enable the dashboard\n* muranodashboard/dashboard.py has a 'permissions' attribute that\n  enables muranodashboard only if murano is installed in keystone or\n  if MURANO_API_URL is set (for debugging)\n\nChange-Id: I3ec2fd4b1931e2c3e71a12900d01ddffecee221a\n""}]",1,113031,d6772bc03a05796eb4f90a6c210b50d6067b4990,15,3,3,10063,,,0,"Helpers for installing into horizon

* horizon-installation/murano_dashboard.py should be linked to
  openstack_dashboard/local/enabled, and will enable the dashboard
* muranodashboard/dashboard.py has a 'permissions' attribute that
  enables muranodashboard only if murano is installed in keystone or
  if MURANO_API_URL is set (for debugging)

Change-Id: I3ec2fd4b1931e2c3e71a12900d01ddffecee221a
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/31/113031/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon-installation/murano_dashboard.py', 'muranodashboard/dashboard.py', 'horizon-installation/README.md']",3,f91d409987881fac9c0e5849b153f2a9961958b1,misc/install-into-horizon,"For installation into an existing Horizon installation: ln -s /full/path/to/murano-dashboard/horizon-installation/murano\_dashboard.py \ /full/path/to/horizon/openstack_dashboard/local/enabled/80\_murano\_dashboard.py sed -i -e ""s,DISABLED = True,DISABLED = False,"" \ /full/path/to/murano_dashboard/installation/murano_dashboard.py You'll need to add muranodashboard to sys.path by whatever means you deem fit. And install any dependencies (I'm looking at you, yaql and django-floppyforms) as well as python-muranoclient. ",,18,1
openstack%2Fnova~master~I99ff78edcae5eaccabf4ea4caf04b8406ffa2f80,openstack/nova,master,I99ff78edcae5eaccabf4ea4caf04b8406ffa2f80,Replace stubs with mocks,MERGED,2014-12-02 19:33:18.000000000,2014-12-12 17:44:09.000000000,2014-12-12 10:57:24.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 642}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 6802}, {'_account_id': 7746}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-02 19:33:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/46169cd937d01c771b6030dda26606adbf91ca56', 'message': 'Replace stubs with mocks\n\nThis change updates the test cases for volume encryptors to use mocks\nrather than stubs. The impetus for this change is comments on another\nchange (https://review.openstack.org/#/c/124791) that request new\ntests to be written using mock. Mixing stubs and mocks would be\nconfusing so this change removes the existing stubs entirely.\n\nChange-Id: I99ff78edcae5eaccabf4ea4caf04b8406ffa2f80\n'}, {'number': 2, 'created': '2014-12-11 15:29:55.000000000', 'files': ['nova/tests/unit/volume/encryptors/test_luks.py', 'nova/tests/unit/volume/encryptors/test_cryptsetup.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e0f40817df3a3871eedca2a22ba0dc1375475ead', 'message': 'Replace stubs with mocks\n\nThis change updates the test cases for volume encryptors to use mocks\nrather than stubs. The impetus for this change is comments on another\nchange (https://review.openstack.org/#/c/124791) that request new\ntests to be written using mock. Mixing stubs and mocks would be\nconfusing so this change removes the existing stubs entirely.\n\nChange-Id: I99ff78edcae5eaccabf4ea4caf04b8406ffa2f80\n'}]",4,138500,e0f40817df3a3871eedca2a22ba0dc1375475ead,40,12,2,6802,,,0,"Replace stubs with mocks

This change updates the test cases for volume encryptors to use mocks
rather than stubs. The impetus for this change is comments on another
change (https://review.openstack.org/#/c/124791) that request new
tests to be written using mock. Mixing stubs and mocks would be
confusing so this change removes the existing stubs entirely.

Change-Id: I99ff78edcae5eaccabf4ea4caf04b8406ffa2f80
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/138500/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/volume/encryptors/test_luks.py', 'nova/tests/unit/volume/encryptors/test_cryptsetup.py']",2,46169cd937d01c771b6030dda26606adbf91ca56,bug/1372108," import mock @mock.patch('nova.utils.execute') def test__open_volume(self, mock_execute): mock_execute.assert_has_calls([ mock.call('cryptsetup', 'create', '--key-file=-', self.dev_name, self.dev_path, process_input='passphrase', run_as_root=True, check_exit_code=True), ], any_order=False) self.assertEqual(1, mock_execute.call_count) @mock.patch('nova.utils.execute') def test_attach_volume(self, mock_execute): self.encryptor._get_key = mock.MagicMock() self.encryptor._get_key.return_value = fake__get_key(None) mock_execute.assert_has_calls([ mock.call('cryptsetup', 'create', '--key-file=-', self.dev_name, self.dev_path, process_input='0' * 32, run_as_root=True, check_exit_code=True), mock.call('ln', '--symbolic', '--force', '/dev/mapper/%s' % self.dev_name, self.symlink_path, run_as_root=True, check_exit_code=True), ], any_order=False) self.assertEqual(2, mock_execute.call_count) @mock.patch('nova.utils.execute') def test__close_volume(self, mock_execute): mock_execute.assert_has_calls([ mock.call('cryptsetup', 'remove', self.dev_name, run_as_root=True, check_exit_code=True), ], any_order=False) self.assertEqual(1, mock_execute.call_count) @mock.patch('nova.utils.execute') def test_detach_volume(self, mock_execute): mock_execute.assert_has_calls([ mock.call('cryptsetup', 'remove', self.dev_name, run_as_root=True, check_exit_code=True), ], any_order=False) self.assertEqual(1, mock_execute.call_count)","import osfrom nova import utils self.executes = [] def fake_execute(*cmd, **kwargs): self.executes.append(cmd) return None, None self.stubs.Set(utils, 'execute', fake_execute) self.stubs.Set(os.path, ""realpath"", lambda x: x) def test__open_volume(self): expected_commands = [('cryptsetup', 'create', '--key-file=-', self.dev_name, self.dev_path)] self.assertEqual(expected_commands, self.executes) def test_attach_volume(self): self.stubs.Set(self.encryptor, '_get_key', fake__get_key) expected_commands = [('cryptsetup', 'create', '--key-file=-', self.dev_name, self.dev_path), ('ln', '--symbolic', '--force', '/dev/mapper/%s' % self.dev_name, self.symlink_path)] self.assertEqual(expected_commands, self.executes) def test__close_volume(self): expected_commands = [('cryptsetup', 'remove', self.dev_name)] self.assertEqual(expected_commands, self.executes) def test_detach_volume(self): expected_commands = [('cryptsetup', 'remove', self.dev_name)] self.assertEqual(expected_commands, self.executes)",84,52
openstack%2Fneutron-lbaas~master~I22348710a7829197b539830f6acdc92b619bdc0c,openstack/neutron-lbaas,master,I22348710a7829197b539830f6acdc92b619bdc0c,Fixing the tests to run again,MERGED,2014-12-12 05:31:07.000000000,2014-12-12 17:42:59.000000000,2014-12-12 17:42:59.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 05:31:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/7e3359b98865799e443ecbab07267938d7783751', 'message': 'Fixing the tests to run again\n\nAlso some minor pep8 and pylint fixes.\n\nChange-Id: I22348710a7829197b539830f6acdc92b619bdc0c\n'}, {'number': 2, 'created': '2014-12-12 07:55:51.000000000', 'files': ['neutron_lbaas/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron_lbaas/tests/__init__.py', 'neutron_lbaas/tests/unit/db/loadbalancer/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/radware/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py', 'neutron_lbaas/tests/unit/test_true.py', 'neutron_lbaas/tests.skip/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/tests.skip/unit/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron_lbaas/db/migration/alembic_migrations/env.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron_lbaas/tests/unit/services/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/tests/unit/db/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/3028ab0326a4ae0b153f8848f63df45617835f57', 'message': 'Fixing the tests to run again\n\nAlso some minor pep8 and pylint fixes.\n\nChange-Id: I22348710a7829197b539830f6acdc92b619bdc0c\n'}]",0,141272,3028ab0326a4ae0b153f8848f63df45617835f57,10,3,2,6951,,,0,"Fixing the tests to run again

Also some minor pep8 and pylint fixes.

Change-Id: I22348710a7829197b539830f6acdc92b619bdc0c
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/72/141272/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/unit/services/loadbalancer/drivers/test_agent_driver_base.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_agent_scheduler.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/__init__.py', 'neutron_lbaas/tests/unit/db/loadbalancer/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_embrane_defaults.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/a10networks/test_driver_v1.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/logging_noop/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/radware/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/test_netscaler_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_namespace_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/haproxy/test_cfg.py', 'neutron_lbaas/tests/unit/test_true.py', 'neutron_lbaas/tests.skip/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/radware/test_plugin_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/a10networks/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/netscaler/test_ncc_client.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/test_plugin_driver.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/tests.skip/unit/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent_manager.py', 'neutron_lbaas/db/migration/alembic_migrations/env.py', 'neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/__init__.py', 'neutron_lbaas/tests/unit/services/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_agent.py', 'neutron_lbaas/tests/unit/services/loadbalancer/agent/test_api.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/tests/unit/db/__init__.py', 'neutron_lbaas/tests/unit/services/loadbalancer/drivers/embrane/__init__.py']",33,7e3359b98865799e443ecbab07267938d7783751,fix_tests,,,63,108
openstack%2Fmurano-dashboard~master~Iea7b36e6ff6deaaa95e54d77d4473b6efcde0194,openstack/murano-dashboard,master,Iea7b36e6ff6deaaa95e54d77d4473b6efcde0194,Fix UI issues,ABANDONED,2014-12-12 17:39:53.000000000,2014-12-12 17:40:23.000000000,,[{'_account_id': 7821}],"[{'number': 1, 'created': '2014-12-12 17:39:53.000000000', 'files': ['muranodashboard/templates/services/_wizard_create.html', 'muranodashboard/dynamic_ui/forms.py', 'muranodashboard/static/muranodashboard/js/add-select.js'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/3dbe7c07448de10e7687823d449fcb7e46dde1dd', 'message': 'Fix UI issues\n\nChange-Id: Iea7b36e6ff6deaaa95e54d77d4473b6efcde0194\n'}]",0,141440,3dbe7c07448de10e7687823d449fcb7e46dde1dd,3,1,1,7549,,,0,"Fix UI issues

Change-Id: Iea7b36e6ff6deaaa95e54d77d4473b6efcde0194
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/40/141440/1 && git format-patch -1 --stdout FETCH_HEAD,"['muranodashboard/templates/services/_wizard_create.html', 'muranodashboard/dynamic_ui/forms.py', 'muranodashboard/static/muranodashboard/js/add-select.js']",3,3dbe7c07448de10e7687823d449fcb7e46dde1dd,rc1," var CUSTOM_CTRL_CLS = 'murano-add-select'; function bind_add_item_handlers(el) { $selects.each(function () { var $this = $(this), urls = $.parseJSON($this.attr(""data-add-item-url"")); if ( urls[0].length ) { // if instead of single url there is an Application name + url // then it was created by custom FQN reference and not by vanilla horizon $('div.input a[class*=btn]').filter(function() { return !$(this).hasClass(CUSTOM_CTRL_CLS); }).remove(); if ( urls.length == 1 ) { debugger; $button = $(""<a href='"" + urls[0][1] + ""' "" + ""data-add-to-field='"" + $this.attr(""id"") + ""' "" + ""class='btn ajax-add ajax-modal btn-inline "" + CUSTOM_CTRL_CLS + ""'>+</a>""); } else { $button = $(""<div class='btn-group' id='"" + $this.attr(""id"") + ""-button' ><button type='button' class='btn "" + ""btn-default dropdown-toggle "" + CUSTOM_CTRL_CLS + ""' "" + ""data-toggle='dropdown'>+</button>"" + ""<ul class='dropdown-menu' role='menu'></ul></div>""); var $choices = $button.find('ul'); $selects.css('margin-bottom', 22); $button.css('display', 'inline-block'); } $this.after($button); } if ( window.murano === undefined ) window.murano = {}; if ( !murano.bind_add_item_handlers ) { murano.bind_add_item_handlers = true; horizon.modals.addModalInitFunction(bind_add_item_handlers); } });"," if ( window.murano === undefined ) window.murano = {}; if ( !murano.bind_add_item_handlers ) { murano.bind_add_item_handlers = true; horizon.modals.addModalInitFunction(function (el) { $selects.each(function () { var $this = $(this), urls, link, $choices; try { urls = $.parseJSON($this.attr(""data-add-item-url"")); } catch(err) {} if ( urls && urls[0].length ) { if ( urls.length == 1 ) { $this.next().find('a').attr('href', urls[0][1]); } else { link = $this.next().find('a').toggleClass('dropdown-toggle'); link.attr('href', '#'); link.attr('data-toggle', 'dropdown'); link.removeClass('ajax-add ajax-modal') $choices = $(""<ul class='dropdown-menu murano-dropdown-menu' role='menu'></ul>""); $this.next('span').append($choices); } }); } }); ",40,24
openstack%2Fnova~master~Id6b90f6d150d6b4059b9f6d1d988eb9dc476c1f6,openstack/nova,master,Id6b90f6d150d6b4059b9f6d1d988eb9dc476c1f6,Use ComputeNode objects in scheduler host manager,ABANDONED,2014-12-02 03:23:50.000000000,2014-12-12 17:40:10.000000000,,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-02 03:23:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c188ddd5f4ce1d1b56a4b57fc6724b8536cb17e', 'message': 'Use ComputeNode objects in scheduler host manager\n\nThis patch changes the direct use of nova.db.api.compute_node_get_all()\nto instead be a call to nova.objects.ComputeNodeList.get_all(), and\nchanges all use of dict-based accesses of data attributes to be object\nattributes instead.\n\nThe largest changes come in the way that the scheduler unit tests were\nset up. Instead of a bunch of dicts representing compute node and\nservice objects, there is now a fixtures module in\nnova/tests/unit/scheduler that contains the objects used in unit tests.\n\nChange-Id: Id6b90f6d150d6b4059b9f6d1d988eb9dc476c1f6\n'}, {'number': 2, 'created': '2014-12-02 16:40:39.000000000', 'files': ['nova/tests/unit/scheduler/test_baremetal_host_manager.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py', 'nova/scheduler/base_baremetal_host_manager.py', 'nova/tests/unit/scheduler/fakes.py', 'nova/tests/unit/scheduler/test_weights.py', 'nova/tests/unit/scheduler/fixtures.py', 'nova/tests/unit/scheduler/filters/test_numa_topology_filters.py', 'nova/scheduler/host_manager.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d8d2476ddc0dcecb09cd979e1d3a58ff8bbf8e5b', 'message': 'Use ComputeNode objects in scheduler host manager\n\nThis patch changes the direct use of nova.db.api.compute_node_get_all()\nto instead be a call to nova.objects.ComputeNodeList.get_all(), and\nchanges all use of dict-based accesses of data attributes to be object\nattributes instead.\n\nThe largest changes come in the way that the scheduler unit tests were\nset up. Instead of a bunch of dicts representing compute node and\nservice objects, there is now a fixtures module in\nnova/tests/unit/scheduler that contains the objects used in unit tests.\n\nChange-Id: Id6b90f6d150d6b4059b9f6d1d988eb9dc476c1f6\n'}]",0,138236,d8d2476ddc0dcecb09cd979e1d3a58ff8bbf8e5b,16,9,2,7,,,0,"Use ComputeNode objects in scheduler host manager

This patch changes the direct use of nova.db.api.compute_node_get_all()
to instead be a call to nova.objects.ComputeNodeList.get_all(), and
changes all use of dict-based accesses of data attributes to be object
attributes instead.

The largest changes come in the way that the scheduler unit tests were
set up. Instead of a bunch of dicts representing compute node and
service objects, there is now a fixtures module in
nova/tests/unit/scheduler that contains the objects used in unit tests.

Change-Id: Id6b90f6d150d6b4059b9f6d1d988eb9dc476c1f6
",git fetch https://review.opendev.org/openstack/nova refs/changes/36/138236/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/test_baremetal_host_manager.py', 'nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/ironic_host_manager.py', 'nova/tests/unit/scheduler/test_ironic_host_manager.py', 'nova/scheduler/base_baremetal_host_manager.py', 'nova/tests/unit/scheduler/fakes.py', 'nova/tests/unit/scheduler/test_weights.py', 'nova/tests/unit/scheduler/filters/test_numa_topology_filters.py', 'nova/tests/unit/scheduler/fixtures.py', 'nova/scheduler/host_manager.py', 'nova/tests/unit/scheduler/test_filter_scheduler.py']",11,6c188ddd5f4ce1d1b56a4b57fc6724b8536cb17e,compute-node-object,"from nova import objectsfrom nova.tests.unit.scheduler import fixtures self.mox.StubOutWithMock(objects.ComputeNodeList, 'get_all') objects.ComputeNodeList.get_all(mox.IgnoreArg()).AndReturn([]) @mock.patch('nova.objects.ComputeNodeList.get_all') def test_schedule_happy_day(self, cn_get_mock, mock_get_extra): cn_get_mock.return_value = fixtures.COMPUTE_NODES @mock.patch('nova.objects.ComputeNodeList.get_all') def test_schedule_host_pool(self, cn_get_mock, mock_get_extra): cn_get_mock.return_value = fixtures.COMPUTE_NODES @mock.patch('nova.objects.ComputeNodeList.get_all') def test_schedule_large_host_pool(self, cn_get_mock, mock_get_extra): cn_get_mock.return_value = fixtures.COMPUTE_NODES @mock.patch('nova.objects.ComputeNodeList.get_all') def test_schedule_chooses_best_host(self, cn_get_mock, mock_get_extra): cn_get_mock.return_value = fixtures.COMPUTE_NODES @mock.patch('nova.objects.ComputeNodeList.get_all') def test_select_destinations(self, cn_get_mock, mock_get_extra): cn_get_mock.return_value = fixtures.COMPUTE_NODES"," self.mox.StubOutWithMock(db, 'compute_node_get_all') db.compute_node_get_all(mox.IgnoreArg()).AndReturn([]) def test_schedule_happy_day(self, mock_get_extra): fakes.mox_host_manager_db_calls(self.mox, fake_context) def test_schedule_host_pool(self, mock_get_extra): fake_context = context.RequestContext('user', 'project', is_admin=True) fakes.mox_host_manager_db_calls(self.mox, fake_context) def test_schedule_large_host_pool(self, mock_get_extra): fake_context = context.RequestContext('user', 'project', is_admin=True) fakes.mox_host_manager_db_calls(self.mox, fake_context) def test_schedule_chooses_best_host(self, mock_get_extra): fake_context = context.RequestContext('user', 'project', is_admin=True) fakes.mox_host_manager_db_calls(self.mox, fake_context) def test_select_destinations(self, mock_get_extra): fakes.mox_host_manager_db_calls(self.mox, fake_context)",460,524
openstack%2Fsolum~master~I69f138f56eac5645ad9ae47472b4c79f7f7ef5f6,openstack/solum,master,I69f138f56eac5645ad9ae47472b4c79f7f7ef5f6,Get COMMIT_ID properly in cedarish/docker/build-app,MERGED,2014-12-11 19:06:46.000000000,2014-12-12 17:38:00.000000000,2014-12-12 17:37:59.000000000,"[{'_account_id': 3}, {'_account_id': 2506}, {'_account_id': 6662}]","[{'number': 1, 'created': '2014-12-11 19:06:46.000000000', 'files': ['contrib/lp-cedarish/docker/build-app'], 'web_link': 'https://opendev.org/openstack/solum/commit/2e15c87961eae68990432ee203908ef17e79174d', 'message': ""Get COMMIT_ID properly in cedarish/docker/build-app\n\nJust moves a COMMIT_ID fetch to a little later to guarantee we're\nactually getting the commit hash from the user's repo\n\nChange-Id: I69f138f56eac5645ad9ae47472b4c79f7f7ef5f6\n""}]",0,141133,2e15c87961eae68990432ee203908ef17e79174d,7,3,1,1375,,,0,"Get COMMIT_ID properly in cedarish/docker/build-app

Just moves a COMMIT_ID fetch to a little later to guarantee we're
actually getting the commit hash from the user's repo

Change-Id: I69f138f56eac5645ad9ae47472b4c79f7f7ef5f6
",git fetch https://review.opendev.org/openstack/solum refs/changes/33/141133/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/lp-cedarish/docker/build-app'],1,2e15c87961eae68990432ee203908ef17e79174d,get-correct-commit-id,COMMIT_ID=$(git log -1 --pretty=%H),COMMIT_ID=$(git log -1 --pretty=%H),2,1
openstack%2Fproject-config~master~I73e5b4bb83cb104a976ae3e55628a1f3d17361d5,openstack/project-config,master,I73e5b4bb83cb104a976ae3e55628a1f3d17361d5,Make check-heat-dsvm-functional-mysql voting,MERGED,2014-12-04 03:04:11.000000000,2014-12-12 17:36:30.000000000,2014-12-12 17:36:29.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-04 03:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f7ec53a1d7686e5b79f7901ef204d925da672c7c', 'message': 'Make check-heat-dsvm-functional-mysql voting\n\nThis job is stable enough to make voting now.\n\nChange-Id: I73e5b4bb83cb104a976ae3e55628a1f3d17361d5\n'}, {'number': 2, 'created': '2014-12-04 21:57:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e2cf8e90369d1f7ee47f8288c425b88a98e41a2d', 'message': 'Make check-heat-dsvm-functional-mysql voting\n\nThis job is stable enough to make voting now.\n\nChange-Id: I73e5b4bb83cb104a976ae3e55628a1f3d17361d5\n'}, {'number': 3, 'created': '2014-12-10 23:58:30.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9e79bf8224ec130caf280051ccfeda0821f4f620', 'message': 'Make check-heat-dsvm-functional-mysql voting\n\nThis job is stable enough to make voting now. The job will now also run in the gate.\n\nChange-Id: I73e5b4bb83cb104a976ae3e55628a1f3d17361d5'}]",0,138940,9e79bf8224ec130caf280051ccfeda0821f4f620,24,8,3,4571,,,0,"Make check-heat-dsvm-functional-mysql voting

This job is stable enough to make voting now. The job will now also run in the gate.

Change-Id: I73e5b4bb83cb104a976ae3e55628a1f3d17361d5",git fetch https://review.opendev.org/openstack/project-config refs/changes/40/138940/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,f7ec53a1d7686e5b79f7901ef204d925da672c7c,heat-voting, voting: true, voting: false,1,1
openstack%2Fproject-config~master~Iba3c667147141e2611a4d3607f41785650f8f634,openstack/project-config,master,Iba3c667147141e2611a4d3607f41785650f8f634,Check requirements for taskflow,MERGED,2014-12-10 16:34:58.000000000,2014-12-12 17:35:19.000000000,2014-12-12 17:35:18.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-10 16:34:58.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/4a2679f7061622f53ca2af32aa2a21f7e68ec570', 'message': 'Check requirements for taskflow\n\nTaskflow needs to be in sync with everyone else if it\naspires to be adopted!\n\nChange-Id: Iba3c667147141e2611a4d3607f41785650f8f634\n'}]",0,140764,4a2679f7061622f53ca2af32aa2a21f7e68ec570,16,6,1,5638,,,0,"Check requirements for taskflow

Taskflow needs to be in sync with everyone else if it
aspires to be adopted!

Change-Id: Iba3c667147141e2611a4d3607f41785650f8f634
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/140764/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,4a2679f7061622f53ca2af32aa2a21f7e68ec570,, - name: check-requirements,,1,0
openstack%2Fproject-config~master~I73a16a5b30a47d532c69d988c361558d29029cf8,openstack/project-config,master,I73a16a5b30a47d532c69d988c361558d29029cf8,sort oslo channels,MERGED,2014-12-11 06:45:03.000000000,2014-12-12 17:35:12.000000000,2014-12-12 17:35:11.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 5638}, {'_account_id': 6547}, {'_account_id': 12100}]","[{'number': 1, 'created': '2014-12-11 06:45:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/2f7f3a269621030b06994ffa03df6a9ebaf9aa36', 'message': 'WIP: sort oslo channels\n\nChange-Id: I73a16a5b30a47d532c69d988c361558d29029cf8\n'}, {'number': 2, 'created': '2014-12-11 16:16:20.000000000', 'files': ['gerritbot/channels.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/427778b914cfd20d29c51c85473c0de74b7d5e4f', 'message': 'sort oslo channels\n\nChange-Id: I73a16a5b30a47d532c69d988c361558d29029cf8\n'}]",0,140933,427778b914cfd20d29c51c85473c0de74b7d5e4f,16,5,2,5638,,,0,"sort oslo channels

Change-Id: I73a16a5b30a47d532c69d988c361558d29029cf8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/33/140933/2 && git format-patch -1 --stdout FETCH_HEAD,['gerritbot/channels.yaml'],1,2f7f3a269621030b06994ffa03df6a9ebaf9aa36,, - openstack/oslo-incubator - openstack/oslo-specs - openstack/oslosphinx - openstack/oslotest, - openstack/oslo-incubator - openstack/oslo-specs - openstack/oslosphinx - openstack/oslo-specs - openstack/oslotest,4,5
openstack%2Fproject-config~master~I4a72e74af967fff8798a30e91c2ff8d4b1c7f2c9,openstack/project-config,master,I4a72e74af967fff8798a30e91c2ff8d4b1c7f2c9,Add requirements check for tooz,MERGED,2014-12-11 05:20:48.000000000,2014-12-12 17:35:04.000000000,2014-12-12 17:35:03.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}]","[{'number': 1, 'created': '2014-12-11 05:20:48.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9f7cc02b064851a2eb5658269a09aaa5c4d2762d', 'message': 'Add requirements check for tooz\n\nChange-Id: I4a72e74af967fff8798a30e91c2ff8d4b1c7f2c9\n'}]",0,140923,9f7cc02b064851a2eb5658269a09aaa5c4d2762d,12,4,1,5638,,,0,"Add requirements check for tooz

Change-Id: I4a72e74af967fff8798a30e91c2ff8d4b1c7f2c9
",git fetch https://review.opendev.org/openstack/project-config refs/changes/23/140923/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,9f7cc02b064851a2eb5658269a09aaa5c4d2762d,, - name: check-requirements,,1,0
openstack%2Ffuel-web~stable%2F6.0~I7c31e37184139e950e400a8dba4bcd2e86b3c8ef,openstack/fuel-web,stable/6.0,I7c31e37184139e950e400a8dba4bcd2e86b3c8ef,Close DB session in StatsSender.run,MERGED,2014-12-12 17:12:17.000000000,2014-12-12 17:31:53.000000000,2014-12-12 17:31:53.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8789}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-12 17:12:17.000000000', 'files': ['nailgun/nailgun/statistics/statsenderd.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c5fa761684a5e8263847ce921a0d4f7121bad849', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}]",0,141431,c5fa761684a5e8263847ce921a0d4f7121bad849,11,8,1,8392,,,0,"Close DB session in StatsSender.run

DB session.remove() is called in StatsSender.run loop.
Now it fails once after postgres restart and works fine in next iteration.

Change-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef
Closes-Bug: #1401521
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/31/141431/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/statistics/statsenderd.py'],1,c5fa761684a5e8263847ce921a0d4f7121bad849,," stat_settings = getattr( objects.MasterNodeSettings.get_one(), ""settings"", {} ).get(""statistics"", {}) except (AttributeError, TypeError) as e: try: if self.must_send_stats(): if self.ping_collector(): self.send_action_log() self.send_installation_info() time.sleep(dithered(settings.STATS_SEND_INTERVAL)) else: time.sleep(dithered(settings.COLLECTOR_PING_INTERVAL)) else: time.sleep(dithered(settings.STATS_ENABLE_CHECK_INTERVAL)) except Exception as e: logger.error(""Stats sender exception: %s"", six.text_type(e)) finally: db.remove() except (KeyboardInterrupt, SystemExit): logger.info(""Stopping standalone stats sender..."")"," stat_settings = objects.MasterNodeSettings.get_one(). \ settings.get(""statistics"", {}) except Exception as e: if self.must_send_stats(): if self.ping_collector(): self.send_action_log() self.send_installation_info() time.sleep(dithered(settings.STATS_SEND_INTERVAL)) else: time.sleep(dithered(settings.COLLECTOR_PING_INTERVAL)) else: time.sleep(dithered(settings.STATS_ENABLE_CHECK_INTERVAL)) except (KeyboardInterrupt, SystemExit) as e: logger.error(""Stats sender exception: %s"", six.text_type(e)) logger.info(""Stopping standalone stats sender..."")",19,14
openstack%2Ftempest~master~Icc3af198981cb427fb735b747aacfa02b85e7242,openstack/tempest,master,Icc3af198981cb427fb735b747aacfa02b85e7242,Updated from global requirements,MERGED,2014-12-04 21:35:00.000000000,2014-12-12 17:30:20.000000000,2014-12-12 17:30:18.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5803}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-04 21:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/3d2ae268660aa8e882d283e58feaba353868f03e', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}, {'number': 2, 'created': '2014-12-08 08:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/792e505dc1fdc1cb353cbc7e0c054ec97944ec1d', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}, {'number': 3, 'created': '2014-12-08 16:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f1090f62aee239cad7243aaeaea5aebcfb331785', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}, {'number': 4, 'created': '2014-12-09 14:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/da7e2023e0366a3ce71275614afe5d5c65080f51', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}, {'number': 5, 'created': '2014-12-10 17:04:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e67de2935f468794c592ea24d762f245b5b97c26', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}, {'number': 6, 'created': '2014-12-11 07:20:53.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tempest/commit/75a9aec499afef6dde7a34b6db18e00cb9c2b363', 'message': 'Updated from global requirements\n\nChange-Id: Icc3af198981cb427fb735b747aacfa02b85e7242\n'}]",0,139210,75a9aec499afef6dde7a34b6db18e00cb9c2b363,23,5,6,11131,,,0,"Updated from global requirements

Change-Id: Icc3af198981cb427fb735b747aacfa02b85e7242
",git fetch https://review.opendev.org/openstack/tempest refs/changes/10/139210/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3d2ae268660aa8e882d283e58feaba353868f03e,openstack/requirements,python-saharaclient>=0.7.6,python-saharaclient>=0.7.5,1,1
openstack%2Fproject-config~master~I465abfdbe88b30ee1584ede27d7e18977d505f13,openstack/project-config,master,I465abfdbe88b30ee1584ede27d7e18977d505f13,Add compass-install project to stackforge,MERGED,2014-12-09 20:18:56.000000000,2014-12-12 17:25:16.000000000,2014-12-12 17:25:15.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 6786}, {'_account_id': 9853}, {'_account_id': 11809}]","[{'number': 1, 'created': '2014-12-09 20:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/f9022278c77b8d4018fbb1218526d9ee77774060', 'message': 'Add compass-install project to stackforge\n\nChange-Id: I465abfdbe88b30ee1584ede27d7e18977d505f13\n'}, {'number': 2, 'created': '2014-12-09 20:51:03.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/7ebad34e3ec6032b104ce6410111f04fc372b13f', 'message': 'Add compass-install project to stackforge\n\nChange-Id: I465abfdbe88b30ee1584ede27d7e18977d505f13\n'}]",0,140465,7ebad34e3ec6032b104ce6410111f04fc372b13f,17,6,2,9853,,,0,"Add compass-install project to stackforge

Change-Id: I465abfdbe88b30ee1584ede27d7e18977d505f13
",git fetch https://review.opendev.org/openstack/project-config refs/changes/65/140465/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/layout.yaml']",2,f9022278c77b8d4018fbb1218526d9ee77774060,new-project, - name: stackforge/compass-install template: - name: merge-check - name: noop-jobs ,,10,0
openstack%2Ftempest~master~Ic8fc216377942619f11a2462b79d0597071ac294,openstack/tempest,master,Ic8fc216377942619f11a2462b79d0597071ac294,Raise a new exception NotImplemented for HTTP501,MERGED,2014-12-10 07:09:30.000000000,2014-12-12 17:22:03.000000000,2014-12-12 08:58:29.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 5174}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/83bdeeee06d96b944bbe78d53fe1400d5c31d09c', 'message': 'Remove unused request() from identity_client\n\nrequest() method is not used at any places, so this patch removes\nit for the code cleanup.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 2, 'created': '2014-12-10 07:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aa043f229f49aac1e58570ee4398fc52c5ba0ddf', 'message': 'Remove unused request() from identity_client\n\nrequest() method is not used at any places, so this patch removes\nit for the code cleanup.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 3, 'created': '2014-12-10 08:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/492c06e6c2a74f509a3a38a2e655e9a5b10cfc8b', 'message': 'Change a keystone error to Unauthorized\n\nIdentityError inherits from TempestException, and it is used at both\na rest client layer and keystone client layer.\nTo move base rest client code into tempest-lib, we need to separate\nthe exception of a rest client layer also from the other tempest code.\nFor doing that, this patch changes a keystone error to Unauthorized at\na rest client layer.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 4, 'created': '2014-12-10 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5c0ea1a69318bee77f869d639d6315f9a062558b', 'message': 'Change a keystone error to Unauthorized\n\nIdentityError inherits from TempestException, and it is used at both\na rest client layer and keystone client layer.\nTo move base rest client code into tempest-lib, we need to separate\nthe exception of a rest client layer also from the other tempest code.\nFor doing that, this patch changes a keystone error to Unauthorized at\na rest client layer.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 5, 'created': '2014-12-11 05:39:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/133e384bfe63f4673db9dab6a143662e290bd3e7', 'message': 'Raise a new exception NotImplemented for HTTP501\n\nIn _error_checker(), both HTTP500 and 501 are converted to the same\nexception ServerFault. In addition, some method which extracts error\nmessage raises a specific exception IdentityError without considering\nHTTP code.\nThis patch adds a new exception NotImplemented and uses it for HTTP501\nso that we can know which error response is returned from a server.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 6, 'created': '2014-12-11 09:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/0bfe486057112861b26f654ef1f375ea55feca66', 'message': 'Raise a new exception NotImplemented for HTTP501\n\nIn _error_checker(), both HTTP500 and 501 are converted to the same\nexception ServerFault. In addition, some method which extracts error\nmessage raises a specific exception IdentityError without considering\nHTTP code.\nThis patch adds a new exception NotImplemented and uses it for HTTP501\nso that we can know which error response is returned from a server.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}, {'number': 7, 'created': '2014-12-11 11:43:32.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/tests/test_rest_client.py', 'tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/43a694a9883d0a4de5dceb5f038f53a767569cbb', 'message': 'Raise a new exception NotImplemented for HTTP501\n\nIn _error_checker(), both HTTP500 and 501 are converted to the same\nexception ServerFault. In addition, some method which extracts error\nmessage raises a specific exception IdentityError without considering\nHTTP code.\nThis patch adds a new exception NotImplemented and uses it for HTTP501\nso that we can know which error response is returned from a server.\n\nChange-Id: Ic8fc216377942619f11a2462b79d0597071ac294\n'}]",7,140591,43a694a9883d0a4de5dceb5f038f53a767569cbb,32,9,7,6167,,,0,"Raise a new exception NotImplemented for HTTP501

In _error_checker(), both HTTP500 and 501 are converted to the same
exception ServerFault. In addition, some method which extracts error
message raises a specific exception IdentityError without considering
HTTP code.
This patch adds a new exception NotImplemented and uses it for HTTP501
so that we can know which error response is returned from a server.

Change-Id: Ic8fc216377942619f11a2462b79d0597071ac294
",git fetch https://review.opendev.org/openstack/tempest refs/changes/91/140591/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/services/identity/json/identity_client.py', 'tempest/services/identity/v3/json/identity_client.py']",2,83bdeeee06d96b944bbe78d53fe1400d5c31d09c,rest-client,," def request(self, method, url, extra_headers=False, headers=None, body=None): """"""A simple HTTP request interface."""""" if headers is None: # Always accept 'json', for xml token client too. # Because XML response is not easily # converted to the corresponding JSON one headers = self.get_headers(accept_type=""json"") elif extra_headers: try: headers.update(self.get_headers(accept_type=""json"")) except (ValueError, TypeError): headers = self.get_headers(accept_type=""json"") resp, resp_body = self.http_obj.request(url, method, headers=headers, body=body) self._log_request(method, url, resp) if resp.status in [401, 403]: resp_body = json.loads(resp_body) raise exceptions.Unauthorized(resp_body['error']['message']) elif resp.status not in [200, 201, 204]: raise exceptions.IdentityError( 'Unexpected status code {0}'.format(resp.status)) return resp, json.loads(resp_body) ",0,56
openstack%2Ftempest~master~I098fe348220bb24c022c4b0753da322e1cdb1893,openstack/tempest,master,I098fe348220bb24c022c4b0753da322e1cdb1893,Remove XML related code from RestClient,MERGED,2014-12-10 14:12:15.000000000,2014-12-12 17:20:39.000000000,2014-12-12 08:23:32.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 8871}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 14:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/54c4eac6c09c513aab1d3fb4d82c29e79bb394dc', 'message': 'Remove XML related code from RestClient\n\nXML API tests have been removed, but there is still some code related\nto XML API tests in RestClient class.\nThis patch remove it for code cleanup.\n\nChange-Id: I098fe348220bb24c022c4b0753da322e1cdb1893\n'}, {'number': 2, 'created': '2014-12-10 23:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/97290b858416c91e84be8c98daa46d0b4bdcb46f', 'message': 'Remove XML related code from RestClient\n\nXML API tests have been removed, but there is still some code related\nto XML API tests in RestClient class.\nThis patch remove it for code cleanup.\n\nChange-Id: I098fe348220bb24c022c4b0753da322e1cdb1893\n'}, {'number': 3, 'created': '2014-12-11 04:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/71ba098ffe208b70634838ac00a36e3a783bca38', 'message': 'Remove XML related code from RestClient\n\nXML API tests have been removed, but there is still some code related\nto XML API tests in RestClient class.\nThis patch remove it for code cleanup.\n\nChange-Id: I098fe348220bb24c022c4b0753da322e1cdb1893\n'}, {'number': 4, 'created': '2014-12-11 09:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9550c053e6ef535056bae96de035f354996b9a75', 'message': 'Remove XML related code from RestClient\n\nXML API tests have been removed, but there is still some code related\nto XML API tests in RestClient class.\nThis patch remove it for code cleanup.\n\nChange-Id: I098fe348220bb24c022c4b0753da322e1cdb1893\n'}, {'number': 5, 'created': '2014-12-11 11:43:32.000000000', 'files': ['tempest/common/rest_client.py', 'tempest/services/identity/json/identity_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/938e3330e2219740b9ab3f14984f2d67177b268d', 'message': 'Remove XML related code from RestClient\n\nXML API tests have been removed, but there is still some code related\nto XML API tests in RestClient class.\nThis patch remove it for code cleanup.\n\nChange-Id: I098fe348220bb24c022c4b0753da322e1cdb1893\n'}]",4,140689,938e3330e2219740b9ab3f14984f2d67177b268d,27,8,5,6167,,,0,"Remove XML related code from RestClient

XML API tests have been removed, but there is still some code related
to XML API tests in RestClient class.
This patch remove it for code cleanup.

Change-Id: I098fe348220bb24c022c4b0753da322e1cdb1893
",git fetch https://review.opendev.org/openstack/tempest refs/changes/89/140689/5 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/common/rest_client.py', 'tempest/services/identity/json/identity_client.py']",2,54c4eac6c09c513aab1d3fb4d82c29e79bb394dc,rest-client,," # Needed for xml service client self.list_tags = [""roles"", ""tenants"", ""users"", ""services"", ""extensions""] ",1,20
openstack%2Fnova~master~Icf4b2fff1c87d006c9827e5d27b1124e24255c0a,openstack/nova,master,Icf4b2fff1c87d006c9827e5d27b1124e24255c0a,"Re-revert ""libvirt: add version cap tied to gate CI testing""",MERGED,2014-12-08 19:08:39.000000000,2014-12-12 17:17:11.000000000,2014-12-12 17:17:07.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 19:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c5fed475edd1018997c885e3169144c6cdef9c4d', 'message': 'Re-revert ""libvirt: add version cap tied to gate CI testing""\n\nIn the following commit the \'version_cap\' concept was\nreverted in driver.py:\n\n  commit 5dea55785a52b7edb383cf61fab2f65f2ae79a72\n  Author: Sean Dague <sean@dague.net>\n  Date:   Wed Jul 30 18:57:34 2014 +0000\n\n    Revert ""libvirt: add version cap tied to gate CI testing""\n\nUnfortunately, due to a rebase error, when the version checking\ncode was moved into host.py, the version_cap was re-introduced.\n\nThis change reverts it once more\n\nChange-Id: Icf4b2fff1c87d006c9827e5d27b1124e24255c0a\n'}, {'number': 2, 'created': '2014-12-08 19:11:04.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/043bb3f2a143d0104de612afb44eb4b42b52e2fc', 'message': 'Re-revert ""libvirt: add version cap tied to gate CI testing""\n\nIn the following commit the \'version_cap\' concept was\nreverted in driver.py:\n\n  commit 5dea55785a52b7edb383cf61fab2f65f2ae79a72\n  Author: Sean Dague <sean@dague.net>\n  Date:   Wed Jul 30 18:57:34 2014 +0000\n\n    Revert ""libvirt: add version cap tied to gate CI testing""\n\nUnfortunately, due to a rebase error, when the version checking\ncode was moved into host.py, the version_cap was re-introduced:\n\n  commit 069ad9a5b4b2cc9b49b21b09b0667909886961cf\n  Author: Daniel P. Berrange <berrange@redhat.com>\n  Date:   Fri Jul 4 15:12:38 2014 +0100\n\n    libvirt: introduce new \'Host\' class to manage the connection\n\nThis change reverts it once more\n\nChange-Id: Icf4b2fff1c87d006c9827e5d27b1124e24255c0a\n'}]",0,140118,043bb3f2a143d0104de612afb44eb4b42b52e2fc,12,7,2,1779,,,0,"Re-revert ""libvirt: add version cap tied to gate CI testing""

In the following commit the 'version_cap' concept was
reverted in driver.py:

  commit 5dea55785a52b7edb383cf61fab2f65f2ae79a72
  Author: Sean Dague <sean@dague.net>
  Date:   Wed Jul 30 18:57:34 2014 +0000

    Revert ""libvirt: add version cap tied to gate CI testing""

Unfortunately, due to a rebase error, when the version checking
code was moved into host.py, the version_cap was re-introduced:

  commit 069ad9a5b4b2cc9b49b21b09b0667909886961cf
  Author: Daniel P. Berrange <berrange@redhat.com>
  Date:   Fri Jul 4 15:12:38 2014 +0100

    libvirt: introduce new 'Host' class to manage the connection

This change reverts it once more

Change-Id: Icf4b2fff1c87d006c9827e5d27b1124e24255c0a
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/140118/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/libvirt/test_host.py', 'nova/virt/libvirt/host.py']",2,c5fed475edd1018997c885e3169144c6cdef9c4d,libvirt-version-cap,,"from oslo.config import cfglibvirt_opts = [ cfg.StrOpt('version_cap', default='1.2.2', # Must always match the version in the gate help='Limit use of features from newer libvirt versions. ' 'Defaults to the version that is used for automated ' 'testing of OpenStack.'), ] CONF = cfg.CONF CONF.register_opts(libvirt_opts, 'libvirt') if CONF.libvirt.version_cap: libvirt_version_cap = utils.convert_version_to_int( utils.convert_version_to_tuple( CONF.libvirt.version_cap)) if libvirt_version > libvirt_version_cap: libvirt_version = libvirt_version_cap ",0,41
openstack%2Ftempest~master~I46631092e1c851f4603035c3dcc11287b777323c,openstack/tempest,master,I46631092e1c851f4603035c3dcc11287b777323c,Remove Nova v3 API code from RestClient,MERGED,2014-12-11 09:59:50.000000000,2014-12-12 17:17:05.000000000,2014-12-12 15:31:43.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 8556}, {'_account_id': 10016}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-11 09:59:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e36a328ce27ba590d0f5a0f02c793ce4c73d3ab3', 'message': 'Remove Nova v3 API code from RestClient\n\nNova v3 API has disappeared, and Tempest isn\'t testing the API on the\ngate now. In addition, Nova team is creating a new REST API ""Nova v2.1\nAPI + microversions"" and the interfaces are different from v3 API.\nSo it is not necessary to keep Nova v3 API tests in Tempest.\nThis patch removes Nova v3 API code from RestClient for code cleanup.\n\nChange-Id: I46631092e1c851f4603035c3dcc11287b777323c\n'}, {'number': 2, 'created': '2014-12-11 11:43:32.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e8dfd67c5564800cdd4630b73a59aaef11972148', 'message': 'Remove Nova v3 API code from RestClient\n\nNova v3 API has disappeared, and Tempest isn\'t testing the API on the\ngate now. In addition, Nova team is creating a new REST API ""Nova v2.1\nAPI + microversions"" and the interfaces are different from v3 API.\nSo it is not necessary to keep Nova v3 API tests in Tempest.\nThis patch removes Nova v3 API code from RestClient for code cleanup.\n\nChange-Id: I46631092e1c851f4603035c3dcc11287b777323c\n'}]",0,140995,e8dfd67c5564800cdd4630b73a59aaef11972148,12,6,2,6167,,,0,"Remove Nova v3 API code from RestClient

Nova v3 API has disappeared, and Tempest isn't testing the API on the
gate now. In addition, Nova team is creating a new REST API ""Nova v2.1
API + microversions"" and the interfaces are different from v3 API.
So it is not necessary to keep Nova v3 API tests in Tempest.
This patch removes Nova v3 API code from RestClient for code cleanup.

Change-Id: I46631092e1c851f4603035c3dcc11287b777323c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/95/140995/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,e36a328ce27ba590d0f5a0f02c793ce4c73d3ab3,rest-client,, # Special case for compute v3 service which hasn't its own # configuration group else: if service == CONF.compute.catalog_v3_type: endpoint_type = CONF.compute.endpoint_type,0,5
openstack%2Ffuel-web~master~I7c31e37184139e950e400a8dba4bcd2e86b3c8ef,openstack/fuel-web,master,I7c31e37184139e950e400a8dba4bcd2e86b3c8ef,Close DB session in StatsSender.run,MERGED,2014-12-12 14:32:00.000000000,2014-12-12 17:16:31.000000000,2014-12-12 17:16:30.000000000,"[{'_account_id': 3}, {'_account_id': 8053}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-12 14:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c4cc332cc9edc151615f8f5b5a9f699829410d89', 'message': 'Close DB session on DB error\n\nDB session.remove() is called on DB error in MasterNodeSettings.get_one method\n(like in load_db_driver method) as it can be called not only from REST API handlers.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}, {'number': 2, 'created': '2014-12-12 14:58:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/93177442fe1c99f12e1af62af7c03887f1ed36fc', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop (like in load_db_driver method).\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}, {'number': 3, 'created': '2014-12-12 15:10:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1c6cbb500f305265bdcda8c2ac37d5e611fd5fdc', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}, {'number': 4, 'created': '2014-12-12 15:12:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4a621fc7530b03b7088c0c94f0c3b5fef920fff1', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}, {'number': 5, 'created': '2014-12-12 15:15:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0a1f90c20781d50b47b7a1d3ebcc5c9021e0a9ef', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}, {'number': 6, 'created': '2014-12-12 15:21:29.000000000', 'files': ['nailgun/nailgun/statistics/statsenderd.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/24f9c78dd40b2425f6626ea2dcffbd4acdb4607e', 'message': 'Close DB session in StatsSender.run\n\nDB session.remove() is called in StatsSender.run loop.\nNow it fails once after postgres restart and works fine in next iteration.\n\nChange-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef\nCloses-Bug: #1401521\n'}]",1,141387,24f9c78dd40b2425f6626ea2dcffbd4acdb4607e,44,9,6,8392,,,0,"Close DB session in StatsSender.run

DB session.remove() is called in StatsSender.run loop.
Now it fails once after postgres restart and works fine in next iteration.

Change-Id: I7c31e37184139e950e400a8dba4bcd2e86b3c8ef
Closes-Bug: #1401521
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/87/141387/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/objects/master_node_settings.py', 'nailgun/nailgun/statistics/statsenderd.py']",2,c4cc332cc9edc151615f8f5b5a9f699829410d89,bug/1401521," stat_settings = getattr( objects.MasterNodeSettings.get_one(), ""settings"", {} ).get(""statistics"", {})"," stat_settings = objects.MasterNodeSettings.get_one(). \ settings.get(""statistics"", {})",18,6
openstack%2Fproject-config~master~If02ac195d344e223ea509431c58a4d01e3b9f5dd,openstack/project-config,master,If02ac195d344e223ea509431c58a4d01e3b9f5dd,Add docs to python-barbicanclient gates,MERGED,2014-12-04 23:13:07.000000000,2014-12-12 17:15:31.000000000,2014-12-12 17:15:30.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6316}, {'_account_id': 6547}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7973}]","[{'number': 1, 'created': '2014-12-04 23:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/1e2a7a78f17fdbdc33f9e3412bb02362ad6a6f88', 'message': 'Add docs to python-barbicanclient gates\n\nAdd gates to python-barbicanclient to build Sphinx docs\n\nChange-Id: If02ac195d344e223ea509431c58a4d01e3b9f5dd\n'}, {'number': 2, 'created': '2014-12-09 16:37:29.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c958868d86f5e70fe0e12e24e4301ef1ef419dd4', 'message': 'Add docs to python-barbicanclient gates\n\nWe would like to add python-barbicanclient-docs to the check and gate\npipelines to be able to review the output of document changes in the\nsame manner that the Barbican server changes are reviewed.\n\nDocument changes should still be published by\nopenstack-client-publish-jobs upon release.\n\nChange-Id: If02ac195d344e223ea509431c58a4d01e3b9f5dd\n'}]",0,139259,c958868d86f5e70fe0e12e24e4301ef1ef419dd4,20,8,2,7973,,,0,"Add docs to python-barbicanclient gates

We would like to add python-barbicanclient-docs to the check and gate
pipelines to be able to review the output of document changes in the
same manner that the Barbican server changes are reviewed.

Document changes should still be published by
openstack-client-publish-jobs upon release.

Change-Id: If02ac195d344e223ea509431c58a4d01e3b9f5dd
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/139259/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1e2a7a78f17fdbdc33f9e3412bb02362ad6a6f88,python-barbicanclient-docs, - python-barbicanclient-docs - python-barbicanclient-docs,,2,0
openstack%2Fhorizon~master~I1e35f984e4aa50457d3c59f80ceb01f091324656,openstack/horizon,master,I1e35f984e4aa50457d3c59f80ceb01f091324656,Wrong success url for instance floatingip related actions,MERGED,2014-08-08 00:32:55.000000000,2014-12-12 17:15:09.000000000,2014-12-12 17:15:08.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 4428}, {'_account_id': 5733}, {'_account_id': 6610}, {'_account_id': 7012}, {'_account_id': 7187}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 11592}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-08-08 00:32:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/279286589861fc6ecaa7b27241e12b8ea728df21', 'message': 'Wrong success url for instance floatingip related actions\n\nWhen the instances is paginated in multiple pages, the success\nurl for floatingip related actions need te be the current page.\n\nChange-Id: I1e35f984e4aa50457d3c59f80ceb01f091324656\n'}, {'number': 2, 'created': '2014-08-11 00:35:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/21d48958d1318332fdc2119fda4975811a6d143c', 'message': 'Wrong success url for instance floatingip related actions\n\nWhen the instances is paginated in multiple pages, the success\nurl for floatingip related actions best to be the current page.\n\nChange-Id: I1e35f984e4aa50457d3c59f80ceb01f091324656\nCloses-bug: 1354970\n'}, {'number': 3, 'created': '2014-12-11 22:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/06ff06de3bac9a8f59a75c27ab1cf9f86c71a9e3', 'message': 'Wrong success url for instance floatingip related actions\n\nWhen the instances is paginated in multiple pages, the success\nurl for floatingip related actions best to be the current page.\n\nChange-Id: I1e35f984e4aa50457d3c59f80ceb01f091324656\nCloses-Bug: #1354970\n'}, {'number': 4, 'created': '2014-12-12 01:21:48.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/3004a15cfe0bc15180aecaaef6ae658f0259f382', 'message': 'Wrong success url for instance floatingip related actions\n\nWhen the instances is paginated in multiple pages, the success\nurl for floatingip related actions best to be the current page.\n\nChange-Id: I1e35f984e4aa50457d3c59f80ceb01f091324656\nCloses-Bug: #1354970\n'}]",1,112738,3004a15cfe0bc15180aecaaef6ae658f0259f382,29,12,4,4428,,,0,"Wrong success url for instance floatingip related actions

When the instances is paginated in multiple pages, the success
url for floatingip related actions best to be the current page.

Change-Id: I1e35f984e4aa50457d3c59f80ceb01f091324656
Closes-Bug: #1354970
",git fetch https://review.opendev.org/openstack/horizon refs/changes/38/112738/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,279286589861fc6ecaa7b27241e12b8ea728df21,wrong-success-url, next_url = self.table.get_full_url() workflows.IPAssociationWorkflow.redirect_param_name: next_url} return shortcuts.redirect(request.get_full_path()) return shortcuts.redirect(request.get_full_path())," next = urlresolvers.reverse(""horizon:project:instances:index"") workflows.IPAssociationWorkflow.redirect_param_name: next} return shortcuts.redirect(""horizon:project:instances:index"") return shortcuts.redirect(""horizon:project:instances:index"")",4,4
openstack%2Fheat~master~I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c,openstack/heat,master,I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c,Enable ResourceUnknownStatus to report status_reason,MERGED,2014-12-11 13:47:03.000000000,2014-12-12 17:14:51.000000000,2014-12-12 17:14:50.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4571}, {'_account_id': 7193}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 10787}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-11 13:47:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b6a4778107a7acb2a20d74b940e52fb55d29ef9e', 'message': ""Enable ResourceUnknownStatus to report status_reason\n\nThis patch enables the ResourceUnknownStatus exception to report the\ndetailed resource status reason (if given).  By default, the status\nreason is set to 'Unknown'.\n\nChange-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c\nCloses-Bug: 1401522\n""}, {'number': 2, 'created': '2014-12-11 13:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7f1225561e2de9244b9d90bb3570dc651ab3a74e', 'message': ""Enable ResourceUnknownStatus to report status_reason\n\nThis patch enables the ResourceUnknownStatus exception to report the\ndetailed resource status reason (if given).  By default, the status\nreason is set to 'Unknown'.\n\nChange-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c\nCloses-Bug: 1401522\n""}, {'number': 3, 'created': '2014-12-11 14:02:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/fef3bef93cc40e371e2186f39019d29be12d39d1', 'message': ""Enable ResourceUnknownStatus to report status_reason\n\nThis patch enables the ResourceUnknownStatus exception to report the\ndetailed resource status reason (if given).  By default, the status\nreason is set to 'Unknown'.\n\nChange-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c\nCloses-Bug: 1401522\n""}, {'number': 4, 'created': '2014-12-12 04:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a8000dbc2a01b5da7ac42c770bb7d1eea2a49eb4', 'message': ""Enable ResourceUnknownStatus to report status_reason\n\nThis patch enables the ResourceUnknownStatus exception to report the\ndetailed resource status reason (if given).  By default, the status\nreason is set to 'Unknown'.\n\nChange-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c\nCloses-Bug: 1401522\n""}, {'number': 5, 'created': '2014-12-12 07:22:26.000000000', 'files': ['heat/tests/test_instance.py', 'heat/tests/test_server.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/tests/test_neutron.py', 'heat/engine/resource.py', 'heat/tests/test_remote_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/119b20841d564405d39752b99e7f02285dca59ea', 'message': ""Enable ResourceUnknownStatus to report status_reason\n\nThis patch enables the ResourceUnknownStatus exception to report the\ndetailed resource status reason (if given).  By default, the status\nreason is set to 'Unknown'.\n\nChange-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c\nCloses-Bug: 1401522\n""}]",7,141051,119b20841d564405d39752b99e7f02285dca59ea,24,9,5,8246,,,0,"Enable ResourceUnknownStatus to report status_reason

This patch enables the ResourceUnknownStatus exception to report the
detailed resource status reason (if given).  By default, the status
reason is set to 'Unknown'.

Change-Id: I9b9d1ebdb1cd16be5bf0a82567aef18537e9d52c
Closes-Bug: 1401522
",git fetch https://review.opendev.org/openstack/heat refs/changes/51/141051/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_instance.py', 'heat/tests/test_server.py', 'heat/tests/test_neutron.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/engine/resource.py']",5,b6a4778107a7acb2a20d74b940e52fb55d29ef9e,bug/1401522," msg_fmt = _('%(result)s - Unknown status %(resource_status)s and the ' 'reason is ""%(status_reason)s""') def __init__(self, result=_('Resource failed'), status_reason=_('Unknown'), **kwargs): super(ResourceUnknownStatus, self).__init__( result=result, status_reason=status_reason, **kwargs)"," msg_fmt = _('%(result)s - Unknown status %(resource_status)s') def __init__(self, result=_('Resource failed'), **kwargs): super(ResourceUnknownStatus, self).__init__(result=result, **kwargs)",20,16
openstack%2Fheat~master~Iae5be5a7fa8efdc799a5c6d08095a2b847c42629,openstack/heat,master,Iae5be5a7fa8efdc799a5c6d08095a2b847c42629,Fix WaitCondition SupportStatus versions,MERGED,2014-12-12 13:56:51.000000000,2014-12-12 17:14:41.000000000,2014-12-12 17:14:40.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 6577}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-12 13:56:51.000000000', 'files': ['heat/engine/resources/wait_condition.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d5467447301cfecc1e2ee8b4ac1afa87a7b2fe40', 'message': ""Fix WaitCondition SupportStatus versions\n\n14bda35b added some SupportStatus tags to the WaitCondition resources,\nbut unfortunately some of the versions are wrong, and the Heat* resources\naren't marked as new-for-juno.\n\nChange-Id: Iae5be5a7fa8efdc799a5c6d08095a2b847c42629\n""}]",0,141373,d5467447301cfecc1e2ee8b4ac1afa87a7b2fe40,9,4,1,4328,,,0,"Fix WaitCondition SupportStatus versions

14bda35b added some SupportStatus tags to the WaitCondition resources,
but unfortunately some of the versions are wrong, and the Heat* resources
aren't marked as new-for-juno.

Change-Id: Iae5be5a7fa8efdc799a5c6d08095a2b847c42629
",git fetch https://review.opendev.org/openstack/heat refs/changes/73/141373/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/wait_condition.py'],1,d5467447301cfecc1e2ee8b4ac1afa87a7b2fe40,wc_juno, support_status = support.SupportStatus(version='2014.2') support_status = support.SupportStatus(version='2014.1') support_status = support.SupportStatus(version='2014.2') support_status = support.SupportStatus(version='2014.1'), support_status = support.SupportStatus(version='2014.2') support_status = support.SupportStatus(version='2014.2'),8,2
openstack%2Fdevstack~master~Iff79986c2564610efde4791b7e61df3db859e199,openstack/devstack,master,Iff79986c2564610efde4791b7e61df3db859e199,Tempest allow_tenant_isolation in auth section,MERGED,2014-08-14 08:04:25.000000000,2014-12-12 17:14:37.000000000,2014-12-12 17:14:36.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6683}, {'_account_id': 7715}, {'_account_id': 9009}]","[{'number': 1, 'created': '2014-08-14 08:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/515ca71d037b5284c56f0d9d8bf4852769b640ca', 'message': 'Tempest allow_tenant_isolation in auth section\n\nTempest change 107685 moves allow_tenant_isolation from compute\ngroup to auth group. Adding to auth for now, tbd remove it from\ncompute once 107685 is merged.\n\nChange-Id: Iff79986c2564610efde4791b7e61df3db859e199\n'}, {'number': 2, 'created': '2014-08-14 16:18:04.000000000', 'files': ['lib/tempest'], 'web_link': 'https://opendev.org/openstack/devstack/commit/122a16fb95e480126319844d94196ea3327b71e8', 'message': 'Tempest allow_tenant_isolation in auth section\n\nTempest change 107685 moves allow_tenant_isolation from compute\ngroup to auth group, making the old format deprecated.\nSwitching to the new format.\n\nChange-Id: Iff79986c2564610efde4791b7e61df3db859e199\n'}]",0,114156,122a16fb95e480126319844d94196ea3327b71e8,22,7,2,1921,,,0,"Tempest allow_tenant_isolation in auth section

Tempest change 107685 moves allow_tenant_isolation from compute
group to auth group, making the old format deprecated.
Switching to the new format.

Change-Id: Iff79986c2564610efde4791b7e61df3db859e199
",git fetch https://review.opendev.org/openstack/devstack refs/changes/56/114156/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/tempest'],1,515ca71d037b5284c56f0d9d8bf4852769b640ca,bp/test-accounts, # Auth iniset $TEMPEST_CONFIG auth allow_tenant_isolation ${TEMPEST_ALLOW_TENANT_ISOLATION:-True} # TODO(andreaf) Remove allow_tenant_isolation from here once change 107685 is merged,,4,0
openstack%2Fgrenade~master~If057c736996f7723f934fc47300dc81c899eb313,openstack/grenade,master,If057c736996f7723f934fc47300dc81c899eb313,"Fix LB, FW, and VPN references for Neutron post-upgrade in Kilo+",MERGED,2014-12-12 03:12:37.000000000,2014-12-12 17:14:30.000000000,2014-12-12 17:14:30.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 970}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 4395}, {'_account_id': 6524}, {'_account_id': 8124}, {'_account_id': 9656}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-12 03:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/a0f73e6512887f561b9083fd418758dfd6e0951b', 'message': 'Fix LB and VPN providers for Neutron in Kilo+\n\nThese services have moved to their respective repos and neutron\nconfig files for Kilo need to reflect that.\n\nChange-Id: If057c736996f7723f934fc47300dc81c899eb313\n'}, {'number': 2, 'created': '2014-12-12 03:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/grenade/commit/e5569a212e7ad7ac92fedd640164fc9af2e547f6', 'message': 'Fix LB, FW, and VPN references for Neutron post-upgrade in Kilo+\n\nThese services have moved to their respective repos and Neutron\nconfig files for Kilo need to reflect that, once Juno gets\nupgraded to Kilo.\n\nChange-Id: If057c736996f7723f934fc47300dc81c899eb313\n'}, {'number': 3, 'created': '2014-12-12 14:25:53.000000000', 'files': ['from-juno/upgrade-neutron'], 'web_link': 'https://opendev.org/openstack/grenade/commit/32a35a8b6cf09e797702564cf45d383760ca0e12', 'message': 'Fix LB, FW, and VPN references for Neutron post-upgrade in Kilo+\n\nThese services have moved to their respective repos and Neutron\nconfig files for Kilo need to reflect that, once Juno gets\nupgraded to Kilo. A link to the release note for this is provided\nhere:\n\nhttps://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_6\n\nChange-Id: If057c736996f7723f934fc47300dc81c899eb313\n'}]",0,141256,32a35a8b6cf09e797702564cf45d383760ca0e12,23,11,3,748,,,0,"Fix LB, FW, and VPN references for Neutron post-upgrade in Kilo+

These services have moved to their respective repos and Neutron
config files for Kilo need to reflect that, once Juno gets
upgraded to Kilo. A link to the release note for this is provided
here:

https://wiki.openstack.org/wiki/ReleaseNotes/Kilo#Upgrade_Notes_6

Change-Id: If057c736996f7723f934fc47300dc81c899eb313
",git fetch https://review.opendev.org/openstack/grenade refs/changes/56/141256/1 && git format-patch -1 --stdout FETCH_HEAD,['from-juno/upgrade-neutron'],1,a0f73e6512887f561b9083fd418758dfd6e0951b,post-adv-service-upgrade,"#!/usr/bin/env bash # ``upgrade-neutron`` KILO_LB_SP=""LOADBALANCER:Haproxy:neutron_lbaas.services.loadbalancer.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default"" KILO_VPN_SP=""VPN:openswan:neutron_vpaas.services.vpn.service_drivers.ipsec.IPsecVPNDriver:default"" function configure_neutron_upgrade { XTRACE=$(set +o | grep xtrace) set -o xtrace # In Kilo Advanced Services have moved to their own repos, so update their references inicomment $NEUTRON_CONF service_providers service_provider iniadd $NEUTRON_CONF service_providers service_provider $KILO_LB_SP iniadd $NEUTRON_CONF service_providers service_provider $KILO_VPN_SP $XTRACE } ",,18,0
openstack%2Fneutron-specs~master~I6054297ff252223801b3de20a79ad3e8d30e76b6,openstack/neutron-specs,master,I6054297ff252223801b3de20a79ad3e8d30e76b6,Enable to set DHCP port attributes,ABANDONED,2014-04-23 23:36:20.000000000,2014-12-12 17:13:56.000000000,,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 2031}, {'_account_id': 2592}, {'_account_id': 4149}, {'_account_id': 5209}, {'_account_id': 5572}, {'_account_id': 6854}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 8279}]","[{'number': 1, 'created': '2014-04-23 23:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/7dcd9e15ddf512d1430378afa6d34debb37ba94c', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 2, 'created': '2014-04-24 00:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/162989bc407141bd599ec1db2ae2c7292971be54', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 3, 'created': '2014-04-24 00:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2ae379e95d25a96b372601c84c26746b013d153f', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 4, 'created': '2014-04-24 00:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/efe8fefd93ab533715d6e7b33aba8560ee4d5c23', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 5, 'created': '2014-04-24 01:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/812d56f226fb92b048c37d7fb9cdd1047453acdb', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 6, 'created': '2014-05-08 00:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/c02a6b6e6e997c08ecb849f7a3e9563f74ef7915', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 7, 'created': '2014-05-20 23:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/68c165c227be335d44d8e8e453879a912d873da9', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 8, 'created': '2014-06-06 01:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/cccfe3cc64e6a5e5acf4af9da9041dcaf7b9245c', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 9, 'created': '2014-06-11 22:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/55acf13a37f4057e786e0df2a45347d45c26ebeb', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}, {'number': 10, 'created': '2014-06-23 22:49:55.000000000', 'files': ['specs/juno/enable-to-set-dhcp-port-attributes.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/ea9671d8aa17d9135b9c79b5779cf4177405d659', 'message': 'Enable to set DHCP port attributes\n\nChange-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6\n'}]",28,89969,ea9671d8aa17d9135b9c79b5779cf4177405d659,60,11,10,4149,,,0,"Enable to set DHCP port attributes

Change-Id: I6054297ff252223801b3de20a79ad3e8d30e76b6
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/69/89969/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/enable-to-set-dhcp-port-attributes.rst'],1,7dcd9e15ddf512d1430378afa6d34debb37ba94c,bp/enable-to-set-dhcp-port-attributes,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Enable to set DHCP port attributes ========================================== https://blueprints.launchpad.net/neutron/+spec/enable-to-set-dhcp-port-attributes The goal of this blueprint is to enable users to explicitly set DCHP port attributes (especially ip address). Problem description =================== There is no way for a user to specify an ip address (, mac address and so on) of a DHCP port. This is very inconvenient for a user who wishes to fully control over ip address assignment. (Note that 'user' assumed here is an admin user.) This blueprint is based on such actual user's requirement. Use cases --------- * Use case 1 When a user migrates their on-premises system to a cloud environment, there are cases where the user wants to use the same ip address for their virtual servers. In such a case, the user needs to specify an ip address of the DHCP server to avoid conflict with an existing servers' ip address. * Use case 2 A user wants to specify an ip address of a DHCP server for security reasons. They don't want DHCP servers to float around. Proposed change =============== This proposal presupposes the following patch is merged. https://review.openstack.org/#/c/79018/ This patch introduces 'reserved_dhcp_port' value for port's 'device_id' attribute for DHCP port reservation. The user senario to achieve the goal of this buleprint is as follows. * A user creates a DHCP port explicitly specifying 'device_id' attribute to 'reserved_dhcp_port' and 'device_owner' attribute to 'network:dhcp' before dhcp-agent assignment to a network. Note that it is already possible to create such port, but the port is not assigned to DHCP server without the patch shown above. It is assumed that only a small fix is necessary for this proposal. * make not trigger dhcp-agent scheduling when creating such port so that a user can select dhcp-agent by dhcp-agent-network-add. The only concern is that specifying 'device_owner' or 'device_id' at port creation by a user via REST API may not be considered as a public use case. Therefore this proposal is necessary to obtain the following consensus from the Neutron community. * Specifying {'device_id': 'reserved_dhcp_port', 'device_owner': 'network:dhcp'} at port creation is a public use case to achieve the goal of this blueprint. Alternatives ------------ Add 'dhcp_port' input parameter to ""dhcp-agent-network-add"" API provided by the ""dhcpagentscheduler"" extension. * action: POST url: /agents/<agent id>/networks * request body: ** current {'network_id': <network_id>} ** new {'network_id': <network_id>, 'dhcp_port': {'fixed_ips': <fixed ips>, 'mac_address': <mac address>, 'name': <name>}} This was proposed originally by this bluprint in Icehouse. See the followng link for more datails. https://wiki.openstack.org/wiki/Neutron/enable-to-set-dhcp-port-attributes And code is here: https://review.openstack.org/#/c/61026/ This proposal is changed because we think achieving the gaol without API modification is desirable. Data model impact ----------------- None. REST API impact --------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- None. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None. Implementation ============== Assignee(s) ----------- Primary assignee: oda-g Other contributors: None Work Items ---------- Dependencies ============ This proposal presupposes the followng patch is merged. https://review.openstack.org/#/c/79018/ Testing ======= Unit tests will be added. Documentation Impact ==================== Usage of creating a port for DHCP will be added to Cloud admin guide. References ========== [1] https://wiki.openstack.org/wiki/Neutron/enable-to-set-dhcp-port-attributes Original proposed change in Icehouse. [2] https://review.openstack.org/#/c/61026/ Original proposed fix in Icehouse. [3] https://review.openstack.org/#/c/79018/ Provide way to reserve dhcp port during failovers ",,184,0
openstack%2Fnova~master~I0d572918d958bcff6ab15af9ccea09401e53ebac,openstack/nova,master,I0d572918d958bcff6ab15af9ccea09401e53ebac,Updated from global requirements,MERGED,2014-12-10 17:01:28.000000000,2014-12-12 16:59:53.000000000,2014-12-11 19:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 17:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1d6b35e023a356a5ee8eb2ee0d8f3ad5d90ac03e', 'message': 'Updated from global requirements\n\nChange-Id: I0d572918d958bcff6ab15af9ccea09401e53ebac\n'}, {'number': 2, 'created': '2014-12-10 17:34:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/da40b59fb9aff0b374d1a2670bb93f03c6efd202', 'message': 'Updated from global requirements\n\nChange-Id: I0d572918d958bcff6ab15af9ccea09401e53ebac\n'}, {'number': 3, 'created': '2014-12-11 07:17:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/3a472c1160034cded416f9f6fc51f48a58d7c127', 'message': 'Updated from global requirements\n\nChange-Id: I0d572918d958bcff6ab15af9ccea09401e53ebac\n'}]",0,140774,3a472c1160034cded416f9f6fc51f48a58d7c127,19,8,3,11131,,,0,"Updated from global requirements

Change-Id: I0d572918d958bcff6ab15af9ccea09401e53ebac
",git fetch https://review.opendev.org/openstack/nova refs/changes/74/140774/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1d6b35e023a356a5ee8eb2ee0d8f3ad5d90ac03e,openstack/requirements,oslo.vmware>=0.7.0 # Apache-2.0,oslo.vmware>=0.6.0 # Apache-2.0,1,1
openstack%2Fha-guide~master~Iaf6a065f7a174662a0b4380d0b29e29a2ab5cca2,openstack/ha-guide,master,Iaf6a065f7a174662a0b4380d0b29e29a2ab5cca2,Updated from openstack-manuals,MERGED,2014-12-11 20:55:44.000000000,2014-12-12 16:59:12.000000000,2014-12-12 16:59:11.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-11 20:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/07c1d5419bc7a447ab013cd04f520ec9a663e3fb', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iaf6a065f7a174662a0b4380d0b29e29a2ab5cca2\n'}, {'number': 2, 'created': '2014-12-12 08:09:43.000000000', 'files': ['doc/high-availability-guide/openstack.ent', 'doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/7f291a2929d8c0eb25a736fb00c7a730587267f9', 'message': 'Updated from openstack-manuals\n\nChange-Id: Iaf6a065f7a174662a0b4380d0b29e29a2ab5cca2\n'}]",0,141157,7f291a2929d8c0eb25a736fb00c7a730587267f9,9,3,2,11131,,,0,"Updated from openstack-manuals

Change-Id: Iaf6a065f7a174662a0b4380d0b29e29a2ab5cca2
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/57/141157/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/high-availability-guide/openstack.ent'],1,07c1d5419bc7a447ab013cd04f520ec9a663e3fb,openstack/openstack-manuals,"<!-- Useful for describing APIs in the User Guide --> <!ENTITY COPY '<command xmlns=""http://docbook.org/ns/docbook"">COPY</command>'> <!ENTITY GET '<command xmlns=""http://docbook.org/ns/docbook"">GET</command>'> <!ENTITY HEAD '<command xmlns=""http://docbook.org/ns/docbook"">HEAD</command>'> <!ENTITY PUT '<command xmlns=""http://docbook.org/ns/docbook"">PUT</command>'> <!ENTITY POST '<command xmlns=""http://docbook.org/ns/docbook"">POST</command>'> <!ENTITY DELETE '<command xmlns=""http://docbook.org/ns/docbook"">DELETE</command>'> ",,8,0
openstack%2Fsahara~master~I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6,openstack/sahara,master,I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6,Fixed scaling with new node group with auto sg,MERGED,2014-12-05 00:35:44.000000000,2014-12-12 16:58:49.000000000,2014-12-12 13:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8871}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-05 00:35:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/276feadaf2693c09905fc7023827bb9733dff1f3', 'message': 'Fixed scaling with new node group with auto sg\n\nNeed to update node groups after creation of auto security group.\n\nChange-Id: I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6\nCloses-Bug: #1399261\n'}, {'number': 2, 'created': '2014-12-05 11:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/51764b4ec040aead85968b9e7d5a094caaf4c4e7', 'message': 'Fixed scaling with new node group with auto sg\n\nNeed to update node groups after creation of auto security group.\n\nChange-Id: I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6\nCloses-Bug: #1399629'}, {'number': 3, 'created': '2014-12-05 21:36:12.000000000', 'files': ['sahara/service/direct_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/1e3f3663b393c988acca17865278cef39987f24a', 'message': 'Fixed scaling with new node group with auto sg\n\nNeed to update node groups after creation of auto security group.\n\nChange-Id: I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6\nCloses-Bug: #1399802'}]",0,139285,1e3f3663b393c988acca17865278cef39987f24a,27,6,3,8411,,,0,"Fixed scaling with new node group with auto sg

Need to update node groups after creation of auto security group.

Change-Id: I7fbbe941152f9e28c5e94dd272d2ba514efbf7c6
Closes-Bug: #1399802",git fetch https://review.opendev.org/openstack/sahara refs/changes/85/139285/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/direct_engine.py'],1,276feadaf2693c09905fc7023827bb9733dff1f3,bug/1399261," node_groups_to_enlarge = set() node_groups_to_delete = set() node_groups_to_delete.add(node_group.id) elif new_count > node_group.count: node_groups_to_enlarge.add(node_group.id) for ng in cluster.node_groups: if ng.id in node_groups_to_delete: self._delete_auto_security_group(ng) for ng in cluster.node_groups: if ng.id in node_groups_to_enlarge: count = node_group_id_map[ng.id] for idx in six.moves.xrange(ng.count + 1, count + 1): instance_id = self._run_instance( cluster, ng, idx, aa_group=aa_group, old_aa_groups=old_aa_groups) instances_to_add.append(instance_id)"," node_groups_to_enlarge = [] node_groups_to_delete = [] node_groups_to_delete.append(node_group) elif new_count > node_group.count: node_groups_to_enlarge.append(node_group) for ng in node_groups_to_delete: self._delete_auto_security_group(ng) for node_group in node_groups_to_enlarge: count = node_group_id_map[node_group.id] for idx in six.moves.xrange(node_group.count + 1, count + 1): instance_id = self._run_instance( cluster, node_group, idx, aa_group=aa_group, old_aa_groups=old_aa_groups) instances_to_add.append(instance_id)",15,14
openstack%2Foperations-guide~master~I7096f9cf052ca7c250417e96bc985c3b0fdf3e5c,openstack/operations-guide,master,I7096f9cf052ca7c250417e96bc985c3b0fdf3e5c,Updated from openstack-manuals,MERGED,2014-12-12 08:09:49.000000000,2014-12-12 16:55:06.000000000,2014-12-12 16:55:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-12 08:09:49.000000000', 'files': ['doc/glossary/locale/ja.po'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/13fb30b7c263d715eee84f0ca1a16df79697eb88', 'message': 'Updated from openstack-manuals\n\nChange-Id: I7096f9cf052ca7c250417e96bc985c3b0fdf3e5c\n'}]",0,141299,13fb30b7c263d715eee84f0ca1a16df79697eb88,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: I7096f9cf052ca7c250417e96bc985c3b0fdf3e5c
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/99/141299/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/glossary/locale/ja.po'],1,13fb30b7c263d715eee84f0ca1a16df79697eb88,openstack/openstack-manuals,"""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-12 04:50+0000\n"" ""Last-Translator: Tomoyuki KATO <tomo@dream.daynight.jp>\n""msgstr ""クライアントから利用可能な API エンドポイントに関する情報を保存、取得するために、Identity のカタログサービスにより使用される保存方式。SQL データベース、LDAP データベース、KVS バックエンドなどがある。""msgstr ""Object Storage のオブジェクトの一覧、ゲスト仮想マシンの現在の状態、ユーザー名の一覧など、サービスに関する情報を保存および取得するために使用される永続データストア。また、Image Service が仮想マシンイメージを取得および保存するために使用する方式。Object Storage、ローカルファイルシステム、S3、HTTP などの選択肢がある。""msgstr ""インターネットなどの通信リソースにより使用される、利用可能なデータ量。何かをダウンロードするために使用されるデータの合計量、またはダウンロードするために利用可能なデータの合計量を表す。""msgstr ""データの機密性、および区分けした情報へのアクセスの制御に注力したセキュリティモデル。このモデルは、エンティティーをサブジェクト (主体) とオブジェクト (対象) に分ける。サブジェクトが特定のアクセスモードを許可されるかどうかを判断するために、サブジェクトの権限がオブジェクトの区分と比較される。権限や区分のスキーマは、格子モデルで表現される。""msgstr ""ベースボード・マネジメント・コントローラー。IPMI アーキテクチャーにおける管理機能。コンピューターのマザーボードに埋め込まれ、サーバーとして動作する、特別なマイクロコントローラーである。システム管理ソフトウェアとプラットフォームハードウェアの間の通信を管理する。""msgstr ""Border Gateway Protocol は、自律システムを接続する、動的ルーティングプロトコルである。インターネットのバックボーンと比べて、このプロトコルは、より大きなネットワークを形成するために、異なるネットワークを接続する。""msgstr ""リングを再設定するため、深刻な障害の後に最初から再作成するために、Object Storage が使用する設定情報を含む。""msgstr ""超過利用""msgstr ""主環境がリソース制限されたとき、要求時に応じてインスタンスを伸縮自在に構築するために、副環境を利用する慣習。""msgstr ""OpenStack のメッセージキューソフトウェアにより使用される、RPC プリミティブの 1 つ。メッセージを送信し、応答を待つ。""msgstr ""cloudpipe VPN と仮想マシンイメージの復号のために、Compute により提供される簡単な認証局。""msgstr ""changes since""msgstr ""Compute API のパラメーター。古いデータと比較するために、新しいデータ群をダウンロードする代わりに、最後に要求した後に実行された、要求した項目への変更をダウンロードする。""msgstr ""メタデータサービスから取得した、SSH 公開鍵やユーザーデータなどの情報を使用して、インスタンスの起動後に初期化を実行する、一般的に仮想マシンイメージにインストールされるパッケージ。""","""POT-Creation-Date: 2014-12-04 23:29+0000\n"" ""PO-Revision-Date: 2014-12-04 20:38+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"msgstr """"",17,17
openstack%2Fsecurity-doc~master~I95f8cb70a5152edb4518876804f32eb966c5545d,openstack/security-doc,master,I95f8cb70a5152edb4518876804f32eb966c5545d,Updated from openstack-manuals,MERGED,2014-12-11 20:55:53.000000000,2014-12-12 16:53:34.000000000,2014-12-12 16:53:34.000000000,"[{'_account_id': 3}, {'_account_id': 2807}]","[{'number': 1, 'created': '2014-12-11 20:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/security-doc/commit/f4f72f797dae2f28fb47d3a6db3d6183efdbf17e', 'message': 'Updated from openstack-manuals\n\nChange-Id: I95f8cb70a5152edb4518876804f32eb966c5545d\n'}, {'number': 2, 'created': '2014-12-12 08:09:52.000000000', 'files': ['glossary/locale/ja.po', 'security-guide/openstack.ent'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/65617ee7fc556b322debfa8419985a730ac35fad', 'message': 'Updated from openstack-manuals\n\nChange-Id: I95f8cb70a5152edb4518876804f32eb966c5545d\n'}]",0,141159,65617ee7fc556b322debfa8419985a730ac35fad,8,2,2,11131,,,0,"Updated from openstack-manuals

Change-Id: I95f8cb70a5152edb4518876804f32eb966c5545d
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/59/141159/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/openstack.ent'],1,f4f72f797dae2f28fb47d3a6db3d6183efdbf17e,openstack/openstack-manuals,"<!-- Useful for describing APIs in the User Guide --> <!ENTITY COPY '<command xmlns=""http://docbook.org/ns/docbook"">COPY</command>'> <!ENTITY GET '<command xmlns=""http://docbook.org/ns/docbook"">GET</command>'> <!ENTITY HEAD '<command xmlns=""http://docbook.org/ns/docbook"">HEAD</command>'> <!ENTITY PUT '<command xmlns=""http://docbook.org/ns/docbook"">PUT</command>'> <!ENTITY POST '<command xmlns=""http://docbook.org/ns/docbook"">POST</command>'> <!ENTITY DELETE '<command xmlns=""http://docbook.org/ns/docbook"">DELETE</command>'> ",,8,0
openstack%2Ftempest~master~I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9,openstack/tempest,master,I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9,Change rest client exceptions' inheritances,MERGED,2014-12-10 07:09:30.000000000,2014-12-12 16:47:41.000000000,2014-12-11 04:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/322c7c9356dec073b4e229d666d19eb89c0308b0', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded, ServerFault and IdentityError raise in rest_client\nand they should inherit from RestClientException for representing what\nhappens clearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}, {'number': 2, 'created': '2014-12-10 07:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c648dffd1cb3b3bbd14f5f23d988d6a3785b5503', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded, ServerFault and IdentityError raise in rest_client\nand they should inherit from RestClientException for representing what\nhappens clearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}, {'number': 3, 'created': '2014-12-10 08:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4d840b0a5cb04edd9abf6111e9de2b7865106667', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded and ServerFault raise at rest_client layer and they\nshould inherit from RestClientException for representing what happens\nclearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}, {'number': 4, 'created': '2014-12-10 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/abd40f09802b59358aa7944919c6920275452fde', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded, ServerFault and OverLimit raise at rest_client layer\nand they should inherit from RestClientException for representing what\nhappens clearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}, {'number': 5, 'created': '2014-12-10 23:47:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c87ae6842489e07f85452abdb62d6a91310b6a9a', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded, ServerFault and OverLimit raise at rest_client layer\nand they should inherit from RestClientException for representing what\nhappens clearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}, {'number': 6, 'created': '2014-12-11 03:09:53.000000000', 'files': ['tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/c240bccc9173261805f9513d2428a2bb162a9326', 'message': ""Change rest client exceptions' inheritances\n\nRateLimitExceeded, ServerFault and OverLimit raise at rest_client layer\nand they should inherit from RestClientException for representing what\nhappens clearly. This patch changes them.\n\nChange-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9\n""}]",2,140593,c240bccc9173261805f9513d2428a2bb162a9326,32,6,6,6167,,,0,"Change rest client exceptions' inheritances

RateLimitExceeded, ServerFault and OverLimit raise at rest_client layer
and they should inherit from RestClientException for representing what
happens clearly. This patch changes them.

Change-Id: I0b74bd44a88cc68bdaeab6bd605722d47f5a28a9
",git fetch https://review.opendev.org/openstack/tempest refs/changes/93/140593/6 && git format-patch -1 --stdout FETCH_HEAD,['tempest/exceptions.py'],1,322c7c9356dec073b4e229d666d19eb89c0308b0,rest-client,class RateLimitExceeded(RestClientException):class ServerFault(RestClientException):class IdentityError(RestClientException):,class RateLimitExceeded(TempestException):class ServerFault(TempestException):class IdentityError(TempestException):,3,3
openstack%2Fdevstack~master~I26a3d7d0842f9d4c5fc33350992a19f597f39b2e,openstack/devstack,master,I26a3d7d0842f9d4c5fc33350992a19f597f39b2e,Update used Fedora images to version 21,MERGED,2014-12-09 20:04:04.000000000,2014-12-12 16:45:05.000000000,2014-12-11 15:28:45.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 7118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 20:04:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7208a1f1117cdd73d527265de219698ca7d3ae05', 'message': 'Update used Fedora images to version 21\n\nChange-Id: I26a3d7d0842f9d4c5fc33350992a19f597f39b2e\n'}, {'number': 2, 'created': '2014-12-09 21:31:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/0ff57413db9f7f0129f1462977ab7384272cdc58', 'message': 'Update used Fedora images to version 21\n\nChange-Id: I26a3d7d0842f9d4c5fc33350992a19f597f39b2e\n'}, {'number': 3, 'created': '2014-12-11 00:53:46.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/21dbe993348b794a1b77c4f9db0081d1cc32138c', 'message': 'Update used Fedora images to version 21\n\nChange-Id: I26a3d7d0842f9d4c5fc33350992a19f597f39b2e\n'}]",0,140462,21dbe993348b794a1b77c4f9db0081d1cc32138c,15,4,3,167,,,0,"Update used Fedora images to version 21

Change-Id: I26a3d7d0842f9d4c5fc33350992a19f597f39b2e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/62/140462/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,7208a1f1117cdd73d527265de219698ca7d3ae05,fedora21," HEAT_CFN_IMAGE_URL=${HEAT_CFN_IMAGE_URL:-""http://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Base-20141203-21.x86_64.qcow2""} IMAGE_URL=""http://download.fedoraproject.org/pub/fedora/linux/releases/21/Cloud/Images/x86_64/Fedora-Cloud-Base-20141203-21.x86_64.qcow22"""," HEAT_CFN_IMAGE_URL=${HEAT_CFN_IMAGE_URL:-""https://download.fedoraproject.org/pub/alt/openstack/20/x86_64/Fedora-x86_64-20-20140618-sda.qcow2""} IMAGE_URL=""https://download.fedoraproject.org/pub/alt/openstack/20/x86_64/Fedora-x86_64-20-20140618-sda.qcow2""",2,2
openstack%2Fgnocchi~master~Icc0975743b48a686343095a460c904adeaa31cb7,openstack/gnocchi,master,Icc0975743b48a686343095a460c904adeaa31cb7,docs: generate HTTP request from real data,MERGED,2014-12-08 10:12:16.000000000,2014-12-12 16:36:40.000000000,2014-12-12 16:36:39.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-08 10:12:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/2bf36d6d7794b8cfaafa131f329a727e960c34cd', 'message': 'docs: generate HTTP request from real data\n\nThis creates a new special Sphinx module that allows to generate live\nHTTP requests/responses and format them using Sphinx httpdomain.\n\nThis makes sure the documentation is up to date when generated.\n\nChange-Id: Icc0975743b48a686343095a460c904adeaa31cb7\n'}, {'number': 2, 'created': '2014-12-08 13:30:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/cd2cc88b83a14913d552a4aad31d45eedb8c2c65', 'message': 'docs: generate HTTP request from real data\n\nThis creates a new special Sphinx module that allows to generate live\nHTTP requests/responses and format them using Sphinx httpdomain.\n\nThis makes sure the documentation is up to date when generated.\n\nChange-Id: Icc0975743b48a686343095a460c904adeaa31cb7\n'}, {'number': 3, 'created': '2014-12-08 14:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/7ad8c01223f1d0d0e3890034cd82e6815eb4f838', 'message': 'docs: generate HTTP request from real data\n\nThis creates a new special Sphinx module that allows to generate live\nHTTP requests/responses and format them using Sphinx httpdomain.\n\nThis makes sure the documentation is up to date when generated.\n\nChange-Id: Icc0975743b48a686343095a460c904adeaa31cb7\n'}, {'number': 4, 'created': '2014-12-12 14:30:31.000000000', 'files': ['gnocchi/gendoc.py', '.gitignore', 'test-requirements.txt', 'doc/source/conf.py', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py', 'gnocchi/rest/__init__.py', 'gnocchi/tests/base.py', 'requirements.txt', 'doc/source/rest.j2', 'doc/source/rest.rst', 'test-requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/4f5dfd1b0f4f92becb20c7ce46e4b863f316ceeb', 'message': 'docs: generate HTTP request from real data\n\nThis creates a new special Sphinx module that allows to generate live\nHTTP requests/responses and format them using Sphinx httpdomain.\n\nThis makes sure the documentation is up to date when generated.\n\nChange-Id: Icc0975743b48a686343095a460c904adeaa31cb7\n'}]",0,139962,4f5dfd1b0f4f92becb20c7ce46e4b863f316ceeb,12,2,4,1669,,,0,"docs: generate HTTP request from real data

This creates a new special Sphinx module that allows to generate live
HTTP requests/responses and format them using Sphinx httpdomain.

This makes sure the documentation is up to date when generated.

Change-Id: Icc0975743b48a686343095a460c904adeaa31cb7
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/62/139962/4 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/gendoc.py', '.gitignore', 'test-requirements.txt', 'doc/source/conf.py', 'doc/source/rest.yaml', 'gnocchi/tests/test_rest.py', 'gnocchi/rest/__init__.py', 'gnocchi/tests/base.py', 'requirements.txt', 'doc/source/rest.j2', 'doc/source/rest.rst', 'test-requirements-py3.txt', 'tox.ini']",13,2bf36d6d7794b8cfaafa131f329a727e960c34cd,jd/doc+listmetric,commands = doc8 --ignore-path doc/source/rest.rst doc/source {toxinidir}/setup-postgresql-tests.sh python setup.py build_sphinx,commands = doc8 doc/source python setup.py build_sphinx,537,734
openstack%2Ffuel-library~stable%2F6.0~Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,openstack/fuel-library,stable/6.0,Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,Fix killing of Rabbit beam process for OCF scripts,MERGED,2014-12-12 13:04:16.000000000,2014-12-12 16:35:23.000000000,2014-12-12 16:35:22.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9387}]","[{'number': 1, 'created': '2014-12-12 13:04:16.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/87ad22e7965b770bd22c8a576997828afdbb0a38', 'message': ""Fix killing of Rabbit beam process for OCF scripts\n\nW/o this patch, 'killall beam' commands kill all instances\nof rabbitmq including the one for Murano.\n\nThe solution is to use kill_rmq_and_remove_pid()\nprocedure to kill it by pidfile instead.\n\nCloses-bug: #1400670\n\nChange-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,141361,87ad22e7965b770bd22c8a576997828afdbb0a38,14,6,1,6926,,,0,"Fix killing of Rabbit beam process for OCF scripts

W/o this patch, 'killall beam' commands kill all instances
of rabbitmq including the one for Murano.

The solution is to use kill_rmq_and_remove_pid()
procedure to kill it by pidfile instead.

Closes-bug: #1400670

Change-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/61/141361/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,87ad22e7965b770bd22c8a576997828afdbb0a38,," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server can't be started while many tries. Beam will be killed."" kill_rmq_and_remove_pid"," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command."" ocf_run killall beam ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. beam will be killed."" ocf_run killall -9 beam ocf_log err ""${LH} RMQ-server can't be started while many tries. beam will be killed."" ocf_run killall -9 beam",6,6
openstack%2Ftempest~master~I49d50fb14b18c6fb263308a68d7ac6a97b1a9800,openstack/tempest,master,I49d50fb14b18c6fb263308a68d7ac6a97b1a9800,Make InvalidServiceTag inherit from TempestException,MERGED,2014-12-10 07:09:30.000000000,2014-12-12 16:26:38.000000000,2014-12-11 02:00:22.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ed7bcdc6846fe2a2c7d61f3f65f96d2f1844ebc7', 'message': 'Make InvalidServiceTag inherit from TempestException\n\nExceptions which inherit from RestClientException should raise based\non an error response which is returned from REST API servers(nova-api,\netc). However, InvalidServiceTag is not now.\nWe have a plan RestClient is implemented in tempest-lib and related\nexceptions also are moved to tempest-lib.\nFor doing that, this patch separates an unrelated exception from\nRestClientException.\n\nChange-Id: I49d50fb14b18c6fb263308a68d7ac6a97b1a9800\n'}, {'number': 2, 'created': '2014-12-10 07:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/1ad39e12140b24fcd16e6254d241c3d850ad89f1', 'message': 'Make InvalidServiceTag inherit from TempestException\n\nExceptions which inherit from RestClientException should raise based\non an error response which is returned from REST API servers(nova-api,\netc). However, InvalidServiceTag is not now.\nWe have a plan RestClient is implemented in tempest-lib and related\nexceptions also are moved to tempest-lib.\nFor doing that, this patch separates an unrelated exception from\nRestClientException.\n\nChange-Id: I49d50fb14b18c6fb263308a68d7ac6a97b1a9800\n'}, {'number': 3, 'created': '2014-12-10 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e6f619b5fac9d692e1f5161d807cabd44d9430eb', 'message': 'Make InvalidServiceTag inherit from TempestException\n\nExceptions which inherit from RestClientException should raise based\non an error response which is returned from REST API servers(nova-api,\netc). However, InvalidServiceTag is not now.\nWe have a plan RestClient is implemented in tempest-lib and related\nexceptions also are moved to tempest-lib.\nFor doing that, this patch separates an unrelated exception from\nRestClientException.\n\nChange-Id: I49d50fb14b18c6fb263308a68d7ac6a97b1a9800\n'}, {'number': 4, 'created': '2014-12-10 23:47:54.000000000', 'files': ['tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/53c963a916e1e31f2e017e9a7bf9e09c5456880f', 'message': 'Make InvalidServiceTag inherit from TempestException\n\nExceptions which inherit from RestClientException should raise based\non an error response which is returned from REST API servers(nova-api,\netc). However, InvalidServiceTag is not now.\nWe have a plan RestClient is implemented in tempest-lib and related\nexceptions also are moved to tempest-lib.\nFor doing that, this patch separates an unrelated exception from\nRestClientException.\n\nChange-Id: I49d50fb14b18c6fb263308a68d7ac6a97b1a9800\n'}]",0,140592,53c963a916e1e31f2e017e9a7bf9e09c5456880f,16,5,4,6167,,,0,"Make InvalidServiceTag inherit from TempestException

Exceptions which inherit from RestClientException should raise based
on an error response which is returned from REST API servers(nova-api,
etc). However, InvalidServiceTag is not now.
We have a plan RestClient is implemented in tempest-lib and related
exceptions also are moved to tempest-lib.
For doing that, this patch separates an unrelated exception from
RestClientException.

Change-Id: I49d50fb14b18c6fb263308a68d7ac6a97b1a9800
",git fetch https://review.opendev.org/openstack/tempest refs/changes/92/140592/4 && git format-patch -1 --stdout FETCH_HEAD,['tempest/exceptions.py'],1,ed7bcdc6846fe2a2c7d61f3f65f96d2f1844ebc7,rest-client,class InvalidServiceTag(TempestException):,class InvalidServiceTag(RestClientException):,1,1
openstack%2Fdevstack-gate~master~I8bd9d6cfa524a9061195f3282e53a2275da80093,openstack/devstack-gate,master,I8bd9d6cfa524a9061195f3282e53a2275da80093,Add Error message for max attempts reached on git remote update,ABANDONED,2014-12-11 15:51:44.000000000,2014-12-12 16:24:22.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-11 15:51:44.000000000', 'files': ['functions.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/3b6406a3e5f754e2318ca17b43562bdd3409d417', 'message': 'Add Error message for max attempts reached on git remote update\n\nAdd this message will help to filter in logstash when the failure in git\nremote update is a final failure. Since it retries 3 times it causes\nsome false positives in some searches.\n\nChange-Id: I8bd9d6cfa524a9061195f3282e53a2275da80093\n'}]",0,141080,3b6406a3e5f754e2318ca17b43562bdd3409d417,3,1,1,5174,,,0,"Add Error message for max attempts reached on git remote update

Add this message will help to filter in logstash when the failure in git
remote update is a final failure. Since it retries 3 times it causes
some false positives in some searches.

Change-Id: I8bd9d6cfa524a9061195f3282e53a2275da80093
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/80/141080/1 && git format-patch -1 --stdout FETCH_HEAD,['functions.sh'],1,3b6406a3e5f754e2318ca17b43562bdd3409d417,," echo ""Max attempts reached for git remote update: Failed""",,1,0
openstack%2Ftempest~master~Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5,openstack/tempest,master,Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5,Move safe_body() into specific class,MERGED,2014-12-10 07:09:30.000000000,2014-12-12 16:16:41.000000000,2014-12-11 02:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 2750}, {'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8859}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/529d5ef569fe98965dcd9f0d0fd483b38bff2d34', 'message': 'Move safe_body() into specific method\n\nsafe_body() is used in _log_request_full() only, so this patch\nmoves safe_body() into the method for the code cleanup.\n\nChange-Id: Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5\n'}, {'number': 2, 'created': '2014-12-10 13:56:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d282e6c41509b2db38b92de44cf60d450e45426a', 'message': 'Move safe_body() into specific class\n\nsafe_body() is used in RestClient class only, so this patch\nmoves safe_body() into the class for the code cleanup.\n\nChange-Id: Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5\n'}, {'number': 3, 'created': '2014-12-10 23:47:54.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/e9140bfb08995ee0ad03b46855dd0c6588851c33', 'message': 'Move safe_body() into specific class\n\nsafe_body() is used in RestClient class only, so this patch\nmoves safe_body() into the class for the code cleanup.\n\nChange-Id: Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5\n'}]",3,140590,e9140bfb08995ee0ad03b46855dd0c6588851c33,18,7,3,6167,,,0,"Move safe_body() into specific class

safe_body() is used in RestClient class only, so this patch
moves safe_body() into the class for the code cleanup.

Change-Id: Ice80d5ab19438162ba7a5705fa78c1ab91c1ccd5
",git fetch https://review.opendev.org/openstack/tempest refs/changes/90/140590/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,529d5ef569fe98965dcd9f0d0fd483b38bff2d34,rest-client," # convert a structure into a string safely def _safe_body(body, maxlen=4096): try: text = six.text_type(body) except UnicodeDecodeError: # if this isn't actually text, return marker that return ""<BinaryData: removed>"" if len(text) > maxlen: return text[:maxlen] else: return text _safe_body(req_body), _safe_body(resp_body)),","# convert a structure into a string safely def safe_body(body, maxlen=4096): try: text = six.text_type(body) except UnicodeDecodeError: # if this isn't actually text, return marker that return ""<BinaryData: removed>"" if len(text) > maxlen: return text[:maxlen] else: return text safe_body(req_body), safe_body(resp_body)),",14,15
openstack%2Fpython-ceilometerclient~master~If02a849af2b0dd471ffa078a53864b3cf751b9bb,openstack/python-ceilometerclient,master,If02a849af2b0dd471ffa078a53864b3cf751b9bb,Allow graceful shutdown on Ctrl+C,MERGED,2014-12-12 01:55:49.000000000,2014-12-12 16:13:11.000000000,2014-12-12 08:55:44.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 7052}, {'_account_id': 7770}, {'_account_id': 8290}]","[{'number': 1, 'created': '2014-12-12 01:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/59804f3c6da23f37efd7fffba1a77a2243f9e8be', 'message': 'Allow graceful shutdown on Ctrl+C\n\nChange-Id: If02a849af2b0dd471ffa078a53864b3cf751b9bb\n'}, {'number': 2, 'created': '2014-12-12 06:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/fcbf8cf3b2e63dfbc1b582ccb467f7ec43d3edf8', 'message': 'Allow graceful shutdown on Ctrl+C\n\nChange-Id: If02a849af2b0dd471ffa078a53864b3cf751b9bb\n'}, {'number': 3, 'created': '2014-12-12 06:54:17.000000000', 'files': ['ceilometerclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-ceilometerclient/commit/400c25f75f93d7452bf57bfbddc5f15371c20a07', 'message': 'Allow graceful shutdown on Ctrl+C\n\nChange-Id: If02a849af2b0dd471ffa078a53864b3cf751b9bb\n'}]",4,141242,400c25f75f93d7452bf57bfbddc5f15371c20a07,16,6,3,8290,,,0,"Allow graceful shutdown on Ctrl+C

Change-Id: If02a849af2b0dd471ffa078a53864b3cf751b9bb
",git fetch https://review.opendev.org/openstack/python-ceilometerclient refs/changes/42/141242/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometerclient/shell.py'],1,59804f3c6da23f37efd7fffba1a77a2243f9e8be,ctrl_c," except KeyboardInterrupt: print(""Shutting down ceilometerclient"", file=sys.stderr) sys.exit(1)",,3,0
openstack%2Fdevstack~master~Ia01a5f330a47b32207586902a861bedfc8a0f6e2,openstack/devstack,master,Ia01a5f330a47b32207586902a861bedfc8a0f6e2,Allow use of dnf instead of yum on Fedora,MERGED,2014-12-09 15:29:47.000000000,2014-12-12 16:13:03.000000000,2014-12-11 14:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 866}, {'_account_id': 970}, {'_account_id': 1779}, {'_account_id': 6962}, {'_account_id': 7118}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 11564}]","[{'number': 1, 'created': '2014-12-09 15:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/05adf4b2baf61e150a747e4333820c72d49609d0', 'message': ""Allow use of dnf instead of yum on Fedora\n\nSince Fedora 20 it has been possible to use 'dnf' as a drop-in\nreplacement for 'yum', and it is targetted to become the default\nin Fedora 22\n\n   http://fedoraproject.org/wiki/Changes/ReplaceYumWithDNF\n\nThere are many benefits of 'dnf' over 'yum' but the biggest\nfrom the POV of an openstack developer is its speed.\n\nAssuming an existing running devstack install ie all required\nRPMs already installed on the system. Now look at how long it\ntakes to run stack.sh, during which yum does not have to\nactually install anything\n\n # ./unstack.sh\n # time ./stack.sh\n real 11m12.193s\n user 10m17.129s\n sys  0m15.275s\n\nNow, with 'export YUM=dnf' set in local.conf, run the same\ntest again\n\n # ./unstack.sh\n # time ./stack.sh\n real 0m48.610s\n user 0m28.939s\n sys  0m7.801s\n\nSo, this is showing that devstack is wasting 10 minutes just\nfor yum to figure out that everything is already installed.\nThe overhead of yum vs dnf is even worse when yum has to\nacutally depsolve to install new packages.\n\nChange-Id: Ia01a5f330a47b32207586902a861bedfc8a0f6e2\n""}, {'number': 2, 'created': '2014-12-09 20:52:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9da162f78a43e64d28914fe2fdf46d0ebc30be08', 'message': ""Allow use of dnf instead of yum on Fedora\n\nSince Fedora 20 it has been possible to use 'dnf' as a drop-in\nreplacement for 'yum', and it is targetted to become the default\nin Fedora 22\n\n   http://fedoraproject.org/wiki/Changes/ReplaceYumWithDNF\n\nThere are many benefits of 'dnf' over 'yum' but the biggest\nfrom the POV of an openstack developer is its speed.\n\nAssuming an existing running devstack install ie all required\nRPMs already installed on the system. Now look at how long it\ntakes to run stack.sh, during which yum does not have to\nactually install anything\n\n # ./unstack.sh\n # time ./stack.sh\n real 11m12.193s\n user 10m17.129s\n sys  0m15.275s\n\nNow, with 'export YUM=dnf' set in local.conf, run the same\ntest again\n\n # ./unstack.sh\n # time ./stack.sh\n real 0m48.610s\n user 0m28.939s\n sys  0m7.801s\n\nSo, this is showing that devstack is wasting 10 minutes just\nfor yum to figure out that everything is already installed.\nThe overhead of yum vs dnf is even worse when yum has to\nacutally depsolve to install new packages.\n\nChange-Id: Ia01a5f330a47b32207586902a861bedfc8a0f6e2\n""}, {'number': 3, 'created': '2014-12-10 22:38:30.000000000', 'files': ['functions-common', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/63d25d978ba0a0cdb1b689cafcebdaae7d609e06', 'message': ""Allow use of dnf instead of yum on Fedora\n\nSince Fedora 20 it has been possible to use 'dnf' as a drop-in\nreplacement for 'yum', and it is targetted to become the default\nin Fedora 22\n\n   http://fedoraproject.org/wiki/Changes/ReplaceYumWithDNF\n\nThere are many benefits of 'dnf' over 'yum' but the biggest\nfrom the POV of an openstack developer is its speed.\n\nAssuming an existing running devstack install ie all required\nRPMs already installed on the system. Now look at how long it\ntakes to run stack.sh, during which yum does not have to\nactually install anything\n\n # ./unstack.sh\n # time ./stack.sh\n real 11m12.193s\n user 10m17.129s\n sys  0m15.275s\n\nNow, with 'export YUM=dnf' set in local.conf, run the same\ntest again\n\n # ./unstack.sh\n # time ./stack.sh\n real 0m48.610s\n user 0m28.939s\n sys  0m7.801s\n\nSo, this is showing that devstack is wasting 10 minutes just\nfor yum to figure out that everything is already installed.\nThe overhead of yum vs dnf is even worse when yum has to\nacutally depsolve to install new packages.\n\nChange-Id: Ia01a5f330a47b32207586902a861bedfc8a0f6e2\n""}]",2,140370,63d25d978ba0a0cdb1b689cafcebdaae7d609e06,21,10,3,1779,,,0,"Allow use of dnf instead of yum on Fedora

Since Fedora 20 it has been possible to use 'dnf' as a drop-in
replacement for 'yum', and it is targetted to become the default
in Fedora 22

   http://fedoraproject.org/wiki/Changes/ReplaceYumWithDNF

There are many benefits of 'dnf' over 'yum' but the biggest
from the POV of an openstack developer is its speed.

Assuming an existing running devstack install ie all required
RPMs already installed on the system. Now look at how long it
takes to run stack.sh, during which yum does not have to
actually install anything

 # ./unstack.sh
 # time ./stack.sh
 real 11m12.193s
 user 10m17.129s
 sys  0m15.275s

Now, with 'export YUM=dnf' set in local.conf, run the same
test again

 # ./unstack.sh
 # time ./stack.sh
 real 0m48.610s
 user 0m28.939s
 sys  0m7.801s

So, this is showing that devstack is wasting 10 minutes just
for yum to figure out that everything is already installed.
The overhead of yum vs dnf is even worse when yum has to
acutally depsolve to install new packages.

Change-Id: Ia01a5f330a47b32207586902a861bedfc8a0f6e2
",git fetch https://review.opendev.org/openstack/devstack refs/changes/70/140370/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,05adf4b2baf61e150a747e4333820c72d49609d0,fedora-dnf," if test -z ""$YUM""; then YUM=yum fi sudo $YUM remove -y ""$@"" ||:# # Can be made to use 'dnf' instead by setting the YUM # env variable to the value 'dnf'. # # In future Fedora 'dnf' will become the only # supported installer, but for now 'yum' and # 'dnf' are both available in parallel with # compatible CLIs. Stick with yum by default # until Fedora switches permanently if test -z ""$YUM""; then YUM=yum fi $YUM install -y ""$@"" 2>&1 | \ die $LINENO ""$YUM install failure"""," sudo yum remove -y ""$@"" yum install -y ""$@"" 2>&1 | \ die $LINENO ""Yum install failure""",19,3
openstack%2Fnova~master~I0b9b664a592364bedd11124a1ec921d8ea011704,openstack/nova,master,I0b9b664a592364bedd11124a1ec921d8ea011704,Add backoff to ebtables retry,MERGED,2014-12-09 22:55:00.000000000,2014-12-12 16:12:17.000000000,2014-12-11 02:47:37.000000000,"[{'_account_id': 3}, {'_account_id': 1849}, {'_account_id': 2271}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 22:55:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/03151fc0d34149184ea34d17f254fa531bd1b151', 'message': 'Add backup to ebtables retry\n\nWe need a backup between ebtables retries. In some tempest tests we\nhave seen the retries complete in 100ms and still fail.\n\nWe now sleep for ebtables_retry_interval * loop count seconds. With\na default of 1.0 this means by default we sleep for 1.0s, 2.0s, and\n3.0s before we finally giving up.\n\nChange-Id: I0b9b664a592364bedd11124a1ec921d8ea011704\nPartial-Bug: #1316621\n'}, {'number': 2, 'created': '2014-12-09 23:35:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/231213306bfe114e3a4795357b148e6c5f9da4ab', 'message': 'Add backup to ebtables retry\n\nWe need a backup between ebtables retries. In some tempest tests we\nhave seen the retries complete in 100ms and still fail.\n\nWe now sleep for ebtables_retry_interval * loop count seconds. With\na default of 1.0 this means by default we sleep for 1.0s, 2.0s, and\n3.0s before we finally giving up.\n\nChange-Id: I0b9b664a592364bedd11124a1ec921d8ea011704\nPartial-Bug: #1316621\n'}, {'number': 3, 'created': '2014-12-10 22:09:26.000000000', 'files': ['nova/tests/unit/network/test_linux_net.py', 'nova/network/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4f418727f7de689a2387d3a7a2cc90ae9503c91e', 'message': 'Add backoff to ebtables retry\n\nWe need a backoff between ebtables retries. In some tempest tests we\nhave seen the retries complete in 100ms and still fail.\n\nWe now sleep for ebtables_retry_interval * loop count seconds. With\na default of 1.0 this means by default we sleep for 1.0s, 2.0s, and\n3.0s before we finally giving up.\n\nChange-Id: I0b9b664a592364bedd11124a1ec921d8ea011704\nPartial-Bug: #1316621\n'}]",1,140514,4f418727f7de689a2387d3a7a2cc90ae9503c91e,20,7,3,3189,,,0,"Add backoff to ebtables retry

We need a backoff between ebtables retries. In some tempest tests we
have seen the retries complete in 100ms and still fail.

We now sleep for ebtables_retry_interval * loop count seconds. With
a default of 1.0 this means by default we sleep for 1.0s, 2.0s, and
3.0s before we finally giving up.

Change-Id: I0b9b664a592364bedd11124a1ec921d8ea011704
Partial-Bug: #1316621
",git fetch https://review.opendev.org/openstack/nova refs/changes/14/140514/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/linux_net.py'],1,03151fc0d34149184ea34d17f254fa531bd1b151,bug/1316621,"import time cfg.FloatOpt('ebtables_retry_interval', default=1.0, help='Number of seconds to wait between ebtables retries.'), count = 1 while count <= attempts: # Updated our counters if needed sleep = CONF.ebtables_retry_interval * count count += 1 if count > attempts and check_exit_code: # We need to sleep a bit before retrying LOG.warning(_LW('%s failed. Sleeping %ss and retrying.'), ' '.join(cmd), sleep) time.sleep(sleep)"," while attempts > 0: attempts -= 1 if not attempts and check_exit_code: LOG.warning(_LW('%s failed. Retrying.'), ' '.join(cmd))",15,4
openstack%2Ftempest~master~I3eae85f8e42f8ed58c87e6336792faf66c8f13aa,openstack/tempest,master,I3eae85f8e42f8ed58c87e6336792faf66c8f13aa,Framework for staged setup,MERGED,2014-08-19 17:31:14.000000000,2014-12-12 16:10:49.000000000,2014-12-11 01:52:04.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 8556}, {'_account_id': 8576}, {'_account_id': 8859}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-08-19 17:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ef644037e5a2ef475bf2faaaddb2f67c562a0716', 'message': 'Fixed structure, safe, class setUp for all tests\n\nPoC for a possible way to enforce all setup class methods to be\nsafe (do not leak resources) and also skip / fail quickly.\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 2, 'created': '2014-10-09 07:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/be187f1aec1f2c2e3599c79d282c4545eed50923', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 3, 'created': '2014-10-09 11:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bf15516c89d83b3acb8c36ca499d98697d340209', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 4, 'created': '2014-10-09 11:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/cd4e230e2664d580c348a099045fe70a58277012', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 5, 'created': '2014-10-09 12:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/188b4074f1b1e434bb234291909729ba94afd887', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 6, 'created': '2014-10-09 22:22:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/15208e60e0f109844adda520a7ca1e11d8e24d88', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 7, 'created': '2014-11-07 12:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/040278a77f2329967622b677977aa23734d9eefd', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 8, 'created': '2014-11-07 12:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/afd62cc7697e1a5ded9e4d7b3c63a1e1c9889b11', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 9, 'created': '2014-11-07 14:36:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/83471ec15cbe2d9a770b5becbc3fb4d335687558', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 10, 'created': '2014-12-08 20:32:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4ce3eaddf7d9664d86f450386073e0d0135eb3a3', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 11, 'created': '2014-12-09 20:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff274ec940009603ae911630847eb447e869bf75', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 12, 'created': '2014-12-09 21:19:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/aaeb1223e8b3e77cb9643f8ce3c76451865558a3', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 13, 'created': '2014-12-09 21:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/83499116fd483c12620ed23819c9beda98e86dab', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 14, 'created': '2014-12-09 22:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/2778813fd8895cf769f39902282920f2cfc8cddc', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}, {'number': 15, 'created': '2014-12-10 21:42:46.000000000', 'files': ['HACKING.rst', 'tempest/test.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a5ddd556c61ff53e4b9644fa869ccea33e3b0302', 'message': 'Framework for staged setup\n\nSplit up the resource_setup in a number of methods to avoid\ncalls to tearDownClass when not needed, and enforce good\npractices in the structure of the setUpClass.\n\nPartially-implements bp:resource-cleanup\n\nChange-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa\n'}]",44,115353,a5ddd556c61ff53e4b9644fa869ccea33e3b0302,81,10,15,1921,,,0,"Framework for staged setup

Split up the resource_setup in a number of methods to avoid
calls to tearDownClass when not needed, and enforce good
practices in the structure of the setUpClass.

Partially-implements bp:resource-cleanup

Change-Id: I3eae85f8e42f8ed58c87e6336792faf66c8f13aa
",git fetch https://review.opendev.org/openstack/tempest refs/changes/53/115353/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/compute/base.py', 'tempest/test.py']",2,ef644037e5a2ef475bf2faaaddb2f67c562a0716,bp/resource-cleanup," @safe_setup # All checks that may generate a skip cls.setup_skip_checks() # Any setup code that does not require / generate test resources cls.setup_pre_resources() # Allocation of all required credentials cls.setup_allocate_credentials() # Shortcuts to clients cls.setup_clients() # Allocation of shared test resources cls.setup_create_resources() # Any setup code to be run after resource allocation cls.setup_post_resources() # NOTE(andreaf): The following setup_* functions provide a fixed structure # for the setUpClass fixture. This structure promotes good practices # in the setUpClass of all test classes: # - allocate resources only when confirmed that tests will be run # - always invoke tearDownClass, so failures during resource allocation # do not cause resource leaks @classmethod def setup_skip_checks(cls): pass @classmethod def setup_pre_resources(cls): pass @classmethod def setup_allocate_credentials(cls): pass @classmethod def setup_clients(cls): pass @classmethod def setup_create_resources(cls): pass @classmethod def setup_post_resources(cls): pass",,81,16
openstack%2Fnova~master~Ie655d1b742a05d6187056d3086e22bd1d166a3d6,openstack/nova,master,Ie655d1b742a05d6187056d3086e22bd1d166a3d6,WIP: Use 1 transaction per DB api,ABANDONED,2014-11-20 16:21:21.000000000,2014-12-12 16:10:01.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-20 16:21:21.000000000', 'files': ['nova/hacking/checks.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/95878747bedfb0205ef2934d519aeda9dac70829', 'message': 'WIP: Use 1 transaction per DB api\n\nImplements DB transaction scoping for Nova along the lines of:\n\nhttps://review.openstack.org/#/c/125181/\n\nChange-Id: Ie655d1b742a05d6187056d3086e22bd1d166a3d6\n'}]",0,136040,95878747bedfb0205ef2934d519aeda9dac70829,10,8,1,9555,,,0,"WIP: Use 1 transaction per DB api

Implements DB transaction scoping for Nova along the lines of:

https://review.openstack.org/#/c/125181/

Change-Id: Ie655d1b742a05d6187056d3086e22bd1d166a3d6
",git fetch https://review.opendev.org/openstack/nova refs/changes/40/136040/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/hacking/checks.py', 'nova/tests/unit/db/test_db_api.py', 'nova/db/sqlalchemy/api.py']",3,95878747bedfb0205ef2934d519aeda9dac70829,db/consistent_object_update,"from sqlalchemy.orm.session import make_transientclass SessionContext(object): def __init__(self, mode='write', use_slave=None, make_transient=True): if mode not in ['read', 'write']: raise Exception(""Invalid session mode: %s"" % mode) self.mode = mode if use_slave is None: # Default to using slave if configured, or for read sessions use_slave = CONF.database.slave_connection != '' or mode == 'read' self.use_slave = use_slave self.make_transient = make_transient def __enter__(self): self.session = get_session(autocommit=False, autoflush=True, use_slave=self.use_slave, info={'mode': self.mode}) return self.session def __exit__(self, exc_type, exc_value, traceback): if exc_type is not None: self.session.rollback() elif self.mode == 'write': self.session.commit() if self.make_transient: for db_inst in self.session: make_transient(db_inst) self.session.close() return False def require_session(mode, create=True): if mode not in ['read', 'write']: raise Exception(""Invalid session mode: %s"" % mode) def decorator(f): @functools.wraps(f) def wrapped(*args, **kwargs): # use_slave is only used for session creation, so don't pass it # through use_slave = kwargs.pop('use_slave', None) # We were passed an existing session session = kwargs.get('session') if session is not None: session_mode = session.info.get('mode') if session_mode is None: session.info['mode'] = mode elif mode == 'write' and session_mode == 'read': raise Exception(""Writer function %s() called by a reader"" % f.func_name) return f(*args, **kwargs) # No existing session: create one if not create: raise Exception(""%s() is not allowed to create a session"" % f.func_name) with SessionContext(mode=mode, use_slave=use_slave) as session: kwargs['session'] = session return f(*args, **kwargs) return wrapped return decorator def session_reader(create=True): return require_session('read', create=create) def session_writer(create=True): return require_session('write', create=create) context, project_id, user_id, session=session))) context, project_id, session=session)) context, project_id, user_id, session=session))@session_writer() def service_destroy(context, service_id, session=None): count = model_query(context, models.Service, session=session).\ filter_by(id=service_id).\ soft_delete(synchronize_session=False) if count == 0: raise exception.ServiceNotFound(service_id=service_id) model_query(context, models.ComputeNode, session=session).\ filter_by(service_id=service_id).\ soft_delete(synchronize_session=False) @session_reader(create=False) def _service_get(context, service_id, with_compute_node=True, session=None): query = model_query(context, models.Service, session=session).\@session_reader() def service_get(context, service_id, with_compute_node=False, session=None): session=session)@session_reader() def service_get_all(context, disabled=None, session=None): query = model_query(context, models.Service, session=session)@session_reader() def service_get_all_by_topic(context, topic, session=None): return model_query(context, models.Service, read_deleted=""no"", session=session).\@session_reader() def service_get_by_host_and_topic(context, host, topic, session=None): return model_query(context, models.Service, read_deleted=""no"", session=session).\@session_reader() def service_get_all_by_host(context, host, session=None): return model_query(context, models.Service, read_deleted=""no"", session=session).\@session_reader() def service_get_by_compute_host(context, host, session=None): session=session).\@session_reader() def service_get_by_args(context, host, binary, session=None): result = model_query(context, models.Service, session=session).\@session_writer() def service_create(context, values, session=None): service_ref.save(session=session)@session_writer() def service_update(context, service_id, values, session=None): service_ref = _service_get(context, service_id, with_compute_node=False, session=session) service_ref.update(values)@session_reader() def compute_node_get(context, compute_id, session=None): return _compute_node_get(context, compute_id, session=session) @session_reader(create=False)@session_reader() def compute_node_get_by_service_id(context, service_id, session=None): result = model_query(context, models.ComputeNode, read_deleted='no', session=session).\@session_reader() def compute_node_search_by_hypervisor(context, hypervisor_match, session=None): return model_query(context, models.ComputeNode, session=session).\@session_writer() def compute_node_create(context, values, session=None): compute_node_ref.save(session=session)@session_writer() def compute_node_update(context, compute_id, values, session=None): compute_ref = _compute_node_get(context, compute_id, session=session) # Always update this, even if there's going to be no other # changes in data. This ensures that we invalidate the # scheduler cache of compute node data in case of races. values['updated_at'] = timeutils.utcnow() datetime_keys = ('created_at', 'deleted_at', 'updated_at') convert_objects_related_datetimes(values, *datetime_keys) compute_ref.update(values)@session_writer() def compute_node_delete(context, compute_id, session=None): result = model_query(context, models.ComputeNode, session=session).\ filter_by(id=compute_id).\ soft_delete(synchronize_session=False) if not result: raise exception.ComputeHostNotFound(host=compute_id) @session_reader() def compute_node_statistics(context, session=None): read_deleted=""no"", session=session).\@session_writer() def certificate_create(context, values, session=None): certificate_ref.save(session=session)@session_reader() def certificate_get_all_by_project(context, project_id, session=None): return model_query(context, models.Certificate, read_deleted=""no"", session=session).\@session_reader() def certificate_get_all_by_user(context, user_id, session=None): return model_query(context, models.Certificate, read_deleted=""no"", session=session).\@session_reader() def certificate_get_all_by_user_and_project(context, user_id, project_id, session=None): return model_query(context, models.Certificate, read_deleted=""no"", session=session).\@session_reader() def floating_ip_get(context, id, session=None): try: result = model_query(context, models.FloatingIp, project_only=True, session=session).\@session_reader() def floating_ip_get_pools(context, session=None): base_model=models.FloatingIp, session=session).distinct():@session_writer() auto_assigned=False, session=None): floating_ip_ref = model_query(context, models.FloatingIp, session=session, read_deleted=""no"").\ filter_by(fixed_ip_id=None).\ filter_by(project_id=None).\ filter_by(pool=pool).\ with_lockmode('update').\ first() # NOTE(vish): if with_lockmode isn't supported, as in sqlite, # then this has concurrency issues if not floating_ip_ref: raise exception.NoMoreFloatingIps() floating_ip_ref['project_id'] = project_id floating_ip_ref['auto_assigned'] = auto_assigned session.add(floating_ip_ref)@session_writer() def floating_ip_bulk_create(context, ips, session=None): for ip in ips: model = models.FloatingIp() model.update(ip) result.append(model) try: # NOTE(boris-42): To get existing address we have to do each # time session.flush().. session.add(model) session.flush() except db_exc.DBDuplicateEntry: raise exception.FloatingIpExists(address=ip['address'])def floating_ip_bulk_destroy(context, ips, session=None): # This function both delete the floating ips in the DB, and releases their # quotas. Quotas also use the DB, but as the quotas api is external to the # DB api we can't share a transaction with it. Consequently we need to # ensure that the floating IP portion of the transaction is complete before # we touch the quota. This is is not only non-atomic, it is also a race # condition. if session is not None: raise Exception(""floating_ip_bulk_destroy requires its own "" + ""transaction"") @session_writer() def _delete_floating_ips(session=None): # NOTE(mdbooth): This function races between the select query and # the delete. query = model_query(context, models.FloatingIp, session=session).\ model_query(context, models.FloatingIp, session=session).\ return project_id_to_quota_count project_id_to_quota_count = _delete_floating_ips() # Delete the quotas, if needed. for project_id, count in project_id_to_quota_count.iteritems(): try: reservations = quota.QUOTAS.reserve(context, project_id=project_id, floating_ips=count) quota.QUOTAS.commit(context, reservations, project_id=project_id) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_(""Failed to update usages bulk "" ""deallocating floating IP""))@session_writer() def floating_ip_create(context, values, session=None): floating_ip_ref.save(session=session)@session_reader()@session_reader() def _validate_unique_server_name(context, name, session=None):@session_writer() def instance_create(context, values, session=None): security_group_ensure_default(context, session=session) default_group = _security_group_ensure_default(context, session=session) context.project_id, security_groups, session=session)) if 'hostname' in values: _validate_unique_server_name(context, values['hostname'], session=session) instance_ref.security_groups = _get_sec_group_models(session, security_groups) session.add(instance_ref) ec2_instance_create(context, instance_ref['uuid'], session=session)@session_reader(create=False)@session_writer() def instance_destroy(context, instance_uuid, constraint=None, session=None): if uuidutils.is_uuid_like(instance_uuid): instance_ref = _instance_get_by_uuid(context, instance_uuid, session=session) else: raise exception.InvalidUUID(instance_uuid) query = model_query(context, models.Instance, session=session).\ filter_by(uuid=instance_uuid) if constraint is not None: query = constraint.apply(models.Instance, query) count = query.soft_delete() if count == 0: raise exception.ConstraintNotMet() model_query(context, models.SecurityGroupInstanceAssociation, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceInfoCache, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceMetadata, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceFault, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceExtra, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete()@session_reader() def instance_get_by_uuid(context, uuid, columns_to_join=None, session=None): columns_to_join=columns_to_join, session=session) @session_reader(create=False) def _instance_get_by_uuid(context, uuid, columns_to_join=None, session=None): result = _build_instance_get(context, columns_to_join=columns_to_join, session=session,).\@session_reader() def instance_get(context, instance_id, columns_to_join=None, session=None): try: result = _build_instance_get(context, columns_to_join=columns_to_join, session=session).\ filter_by(id=instance_id).first()@session_reader(create=False) def _build_instance_get(context, columns_to_join=None, session=None): query = model_query(context, models.Instance, project_only=True, session=session).\@session_reader(create=False) def _instances_fill_metadata(context, instances, manual_joins=None, session=None): session=session): session=session): for row in _instance_pcidevs_get_multi(context, uuids, session=session):@session_reader() def instance_get_all(context, columns_to_join=None, session=None): query = model_query(context, models.Instance, session=session) return _instances_fill_metadata(context, instances, manual_joins, session=session)@session_reader() session=None): sort_dirs=[sort_dir], session=session)@session_reader() columns_to_join=None, sort_keys=None, sort_dirs=None, session=None): return _instances_fill_metadata(context, query_prefix.all(), manual_joins, session=session)@session_reader() columns_to_join=None, session=None): return _instances_fill_metadata(context, query.all(), manual_joins, session=session) @session_reader(create=False) def _instance_get_all_query(context, project_only=False, joins=None, session=None): session=session)@session_reader() session=None): instances = _instance_get_all_query(context, session=session).\ filter_by(host=host).all() return _instances_fill_metadata(context, instances, session=session) @session_reader(create=False)@session_reader() columns_to_join=None, session=None): instances = _instance_get_all_query(context, joins=columns_to_join, session=session).\ filter_by(host=host).filter_by(node=node).all() return _instances_fill_metadata(context, instances, manual_joins=manual_joins, session=session)@session_reader() def instance_get_all_by_host_and_not_type(context, host, type_id=None, session=None): instances = _instance_get_all_query(context, session=session).\ filter_by(host=host).\ filter(models.Instance.instance_type_id != type_id).all() return _instances_fill_metadata(context, instances, session=session)@session_reader() def instance_get_floating_address(context, instance_id, session=None): fixed_ips = fixed_ip_get_by_instance(context, instance['uuid'], session=session) fixed_ips[0]['address'], session=session)@session_reader() def instance_floating_address_get_all(context, instance_uuid, session=None): base_model=models.FloatingIp, session=session).\@session_reader() def instance_get_all_hung_in_rebooting(context, reboot_window, session=None): instances = model_query(context, models.Instance, session=session).\ filter(models.Instance.updated_at <= reboot_window).\ filter_by(task_state=task_states.REBOOTING).all() return _instances_fill_metadata(context, instances, manual_joins=[], session=session)@session_writer() def instance_update(context, instance_uuid, values, session=None): instance_ref = _instance_update(context, instance_uuid, values, session=session)[1]@session_writer() columns_to_join=None, session=None): columns_to_join=columns_to_join, session=session)@session_writer() metadata, session=None):@session_writer() columns_to_join=None, session=None): instance_ref = _instance_get_by_uuid(context, instance_uuid, columns_to_join=columns_to_join, session=session) if ""expected_task_state"" in values: # it is not a db column so always pop out expected = values.pop(""expected_task_state"") if not isinstance(expected, (tuple, list, set)): expected = (expected,) actual_state = instance_ref[""task_state""] if actual_state not in expected: if actual_state == task_states.DELETING: raise exception.UnexpectedDeletingTaskStateError( actual=actual_state, expected=expected) else: raise exception.UnexpectedTaskStateError( actual=actual_state, expected=expected) if ""expected_vm_state"" in values: expected = values.pop(""expected_vm_state"") if not isinstance(expected, (tuple, list, set)): expected = (expected,) actual_state = instance_ref[""vm_state""] if actual_state not in expected: raise exception.UnexpectedVMStateError(actual=actual_state, expected=expected) instance_hostname = instance_ref['hostname'] or '' if (""hostname"" in values and values[""hostname""].lower() != instance_hostname.lower()): _validate_unique_server_name(context, values['hostname'], session=session) if copy_old_instance: old_instance_ref = copy.copy(instance_ref) else: old_instance_ref = None metadata = values.get('metadata') if metadata is not None: _instance_metadata_update_in_place(context, instance_ref, 'metadata', models.InstanceMetadata, values.pop('metadata'), session=session) system_metadata = values.get('system_metadata') if system_metadata is not None: _instance_metadata_update_in_place(context, instance_ref, 'system_metadata', models.InstanceSystemMetadata, values.pop('system_metadata'), session=session) _handle_objects_related_type_conversions(values) instance_ref.update(values) session.add(instance_ref)@session_writer() def instance_add_security_group(context, instance_uuid, security_group_id, session=None): sec_group_ref.save(session=session)@session_writer() def instance_remove_security_group(context, instance_uuid, security_group_id, session=None): model_query(context, models.SecurityGroupInstanceAssociation, session=session).\ filter_by(instance_uuid=instance_uuid).\ filter_by(security_group_id=security_group_id).\ soft_delete()@session_writer(create=False)@session_reader(create=False) def _security_group_get_query(context, read_deleted=None, project_only=False, join_rules=True, session=None): query = model_query(context, models.SecurityGroup, read_deleted=read_deleted, project_only=project_only, session=session)@session_reader(create=False) def _security_group_get_by_names(context, project_id, group_names, session=None): query = _security_group_get_query(context, read_deleted=""no"", join_rules=False, session=session).\@session_writer() def security_group_get_all(context, session=None): return _security_group_get_query(context, session=session).all()@session_reader() def security_group_get(context, security_group_id, columns_to_join=None, session=None): query = _security_group_get_query(context, project_only=True, session=session).\@session_reader() columns_to_join=None, session=None): query = _security_group_get_query(context, read_deleted=""no"", join_rules=False, session=session).\@session_reader() def security_group_get_by_project(context, project_id, session=None): return _security_group_get_query(context, read_deleted=""no"", session=session).\@session_reader() def security_group_get_by_instance(context, instance_uuid, session=None): return _security_group_get_query(context, read_deleted=""no"", session=session).\@session_reader() def security_group_in_use(context, group_id, session=None): # Are there any instances that haven't been deleted # that include this group? inst_assoc = model_query(context, models.SecurityGroupInstanceAssociation, read_deleted=""no"", session=session).\ filter_by(security_group_id=group_id).\ all() for ia in inst_assoc: num_instances = model_query(context, models.Instance, read_deleted=""no"", session=session).\ filter_by(uuid=ia.instance_uuid).\ count() if num_instances: return True@session_writer() def security_group_create(context, values, session=None): return _security_group_create(context, values, session=session)@session_writer() columns_to_join=None, session=None): query = model_query(context, models.SecurityGroup, session=session).filter_by(id=security_group_id) if columns_to_join: for column in columns_to_join: query = query.options(joinedload_all(column)) security_group_ref = query.first() if not security_group_ref: raise exception.SecurityGroupNotFound( security_group_id=security_group_id) security_group_ref.update(values) name = security_group_ref['name'] project_id = security_group_ref['project_id'] try: security_group_ref.save(session=session) except db_exc.DBDuplicateEntry: raise exception.SecurityGroupExists( project_id=project_id, security_group_name=name)@session_writer() def security_group_ensure_default(context, session=None): return _security_group_ensure_default(context, session=session) 'default', session=session) @session_writer(create=False) def _security_group_ensure_default(context, session=None): values = {'name': 'default', 'description': 'default', 'user_id': context.user_id, 'project_id': context.project_id} try: # Establish a savepoint in the current transaction in case # _security_group_create() fails with session.begin_nested(): except exception.SecurityGroupExists: # If it already exists, fetch the existing one and return it return _security_group_get_by_names(context, context.project_id, ['default'], session=session)[0] usage = model_query(context, models.QuotaUsage, read_deleted=""no"", session=session).\ filter_by(project_id=context.project_id).\ filter_by(user_id=context.user_id).\ filter_by(resource='security_groups') # Create quota usage for auto created default security group if not usage.first(): _quota_usage_create(context.project_id, context.user_id, 'security_groups', 1, 0, None, session=session) else: usage.update({'in_use': int(usage.first().in_use) + 1}) default_rules = _security_group_rule_get_default_query(context, session=session).all() for default_rule in default_rules: # This is suboptimal, it should be programmatic to know # the values of the default_rule rule_values = {'protocol': default_rule.protocol, 'from_port': default_rule.from_port, 'to_port': default_rule.to_port, 'cidr': default_rule.cidr, 'parent_group_id': default_group.id, } _security_group_rule_create(context, rule_values, session=session) return default_group@session_writer() def security_group_destroy(context, security_group_id, session=None): model_query(context, models.SecurityGroup, session=session).\ filter_by(id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupInstanceAssociation, session=session).\ filter_by(security_group_id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupIngressRule, session=session).\ filter_by(group_id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupIngressRule, session=session).\ filter_by(parent_group_id=security_group_id).\ soft_delete() @session_reader(create=False)@session_writer(create=False)@session_reader(create=False)@session_reader() def security_group_rule_get(context, security_group_rule_id, session=None): result = (_security_group_rule_get_query(context, session=session).@session_reader() columns_to_join=None, session=None): query = (_security_group_rule_get_query(context, session=session).@session_reader() security_group_id, session=None): return (_security_group_rule_get_query(context, session=session).@session_writer() def security_group_rule_create(context, values, session=None): return _security_group_rule_create(context, values, session=session)@session_writer() def security_group_rule_destroy(context, security_group_rule_id, session=None): count = (_security_group_rule_get_query(context, session=session).@session_reader() def security_group_rule_count_by_group(context, security_group_id, session=None): read_deleted=""no"", session=session).@session_reader(create=False)@session_reader() def security_group_default_rule_get(context, security_group_rule_default_id, session=None): result = _security_group_rule_get_default_query(context, session=session).\@session_writer() security_group_rule_default_id, session=None): count = _security_group_rule_get_default_query(context, session=session).\ filter_by(id=security_group_rule_default_id).\ soft_delete() if count == 0: raise exception.SecurityGroupDefaultRuleNotFound( rule_id=security_group_rule_default_id)@session_writer() def security_group_default_rule_create(context, values, session=None): security_group_default_rule_ref.save(session=session)@session_reader() def security_group_default_rule_list(context, session=None): return _security_group_rule_get_default_query(context, session=session).\@session_writer() def ec2_instance_create(context, instance_uuid, id=None, session=None): ec2_instance_ref.save(session=session)"," context, project_id, user_id, session))) context, project_id, session)) context, project_id, user_id, session))def service_destroy(context, service_id): session = get_session() with session.begin(): count = model_query(context, models.Service, session=session).\ filter_by(id=service_id).\ soft_delete(synchronize_session=False) if count == 0: raise exception.ServiceNotFound(service_id=service_id) model_query(context, models.ComputeNode, session=session).\ filter_by(service_id=service_id).\ soft_delete(synchronize_session=False) def _service_get(context, service_id, with_compute_node=True, session=None, use_slave=False): query = model_query(context, models.Service, session=session, use_slave=use_slave).\def service_get(context, service_id, with_compute_node=False, use_slave=False): use_slave=use_slave)def service_get_all(context, disabled=None): query = model_query(context, models.Service)def service_get_all_by_topic(context, topic): return model_query(context, models.Service, read_deleted=""no"").\def service_get_by_host_and_topic(context, host, topic): return model_query(context, models.Service, read_deleted=""no"").\def service_get_all_by_host(context, host): return model_query(context, models.Service, read_deleted=""no"").\def service_get_by_compute_host(context, host, use_slave=False): use_slave=use_slave).\def service_get_by_args(context, host, binary): result = model_query(context, models.Service).\def service_create(context, values): service_ref.save()def service_update(context, service_id, values): session = get_session() with session.begin(): service_ref = _service_get(context, service_id, with_compute_node=False, session=session) service_ref.update(values) def compute_node_get(context, compute_id): return _compute_node_get(context, compute_id) def compute_node_get_by_service_id(context, service_id): result = model_query(context, models.ComputeNode, read_deleted='no').\def compute_node_search_by_hypervisor(context, hypervisor_match): return model_query(context, models.ComputeNode).\def compute_node_create(context, values): compute_node_ref.save()def compute_node_update(context, compute_id, values): session = get_session() with session.begin(): compute_ref = _compute_node_get(context, compute_id, session=session) # Always update this, even if there's going to be no other # changes in data. This ensures that we invalidate the # scheduler cache of compute node data in case of races. values['updated_at'] = timeutils.utcnow() datetime_keys = ('created_at', 'deleted_at', 'updated_at') convert_objects_related_datetimes(values, *datetime_keys) compute_ref.update(values)def compute_node_delete(context, compute_id): session = get_session() with session.begin(): result = model_query(context, models.ComputeNode, session=session).\ filter_by(id=compute_id).\ soft_delete(synchronize_session=False) if not result: raise exception.ComputeHostNotFound(host=compute_id) def compute_node_statistics(context): read_deleted=""no"").\def certificate_create(context, values): certificate_ref.save()def certificate_get_all_by_project(context, project_id): return model_query(context, models.Certificate, read_deleted=""no"").\def certificate_get_all_by_user(context, user_id): return model_query(context, models.Certificate, read_deleted=""no"").\def certificate_get_all_by_user_and_project(context, user_id, project_id): return model_query(context, models.Certificate, read_deleted=""no"").\def floating_ip_get(context, id): try: result = model_query(context, models.FloatingIp, project_only=True).\def floating_ip_get_pools(context): base_model=models.FloatingIp).distinct(): auto_assigned=False): session = get_session() with session.begin(): floating_ip_ref = model_query(context, models.FloatingIp, session=session, read_deleted=""no"").\ filter_by(fixed_ip_id=None).\ filter_by(project_id=None).\ filter_by(pool=pool).\ with_lockmode('update').\ first() # NOTE(vish): if with_lockmode isn't supported, as in sqlite, # then this has concurrency issues if not floating_ip_ref: raise exception.NoMoreFloatingIps() floating_ip_ref['project_id'] = project_id floating_ip_ref['auto_assigned'] = auto_assigned session.add(floating_ip_ref)def floating_ip_bulk_create(context, ips): session = get_session() with session.begin(): for ip in ips: model = models.FloatingIp() model.update(ip) result.append(model) try: # NOTE(boris-42): To get existing address we have to do each # time session.flush().. session.add(model) session.flush() except db_exc.DBDuplicateEntry: raise exception.FloatingIpExists(address=ip['address'])def floating_ip_bulk_destroy(context, ips): session = get_session() with session.begin(): query = model_query(context, models.FloatingIp).\ model_query(context, models.FloatingIp).\ # Delete the quotas, if needed. for project_id, count in project_id_to_quota_count.iteritems(): try: reservations = quota.QUOTAS.reserve(context, project_id=project_id, floating_ips=count) quota.QUOTAS.commit(context, reservations, project_id=project_id) except Exception: with excutils.save_and_reraise_exception(): LOG.exception(_(""Failed to update usages bulk "" ""deallocating floating IP""))def floating_ip_create(context, values): floating_ip_ref.save()def _validate_unique_server_name(context, session, name):def instance_create(context, values): security_group_ensure_default(context) default_group = _security_group_ensure_default(context, session) session, context.project_id, security_groups)) session = get_session() with session.begin(): if 'hostname' in values: _validate_unique_server_name(context, session, values['hostname']) instance_ref.security_groups = _get_sec_group_models(session, security_groups) session.add(instance_ref) ec2_instance_create(context, instance_ref['uuid'])def instance_destroy(context, instance_uuid, constraint=None): session = get_session() with session.begin(): if uuidutils.is_uuid_like(instance_uuid): instance_ref = _instance_get_by_uuid(context, instance_uuid, session=session) else: raise exception.InvalidUUID(instance_uuid) query = model_query(context, models.Instance, session=session).\ filter_by(uuid=instance_uuid) if constraint is not None: query = constraint.apply(models.Instance, query) count = query.soft_delete() if count == 0: raise exception.ConstraintNotMet() model_query(context, models.SecurityGroupInstanceAssociation, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceInfoCache, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceMetadata, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceFault, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete() model_query(context, models.InstanceExtra, session=session).\ filter_by(instance_uuid=instance_uuid).\ soft_delete()def instance_get_by_uuid(context, uuid, columns_to_join=None, use_slave=False): columns_to_join=columns_to_join, use_slave=use_slave) def _instance_get_by_uuid(context, uuid, session=None, columns_to_join=None, use_slave=False): result = _build_instance_get(context, session=session, columns_to_join=columns_to_join, use_slave=use_slave).\def instance_get(context, instance_id, columns_to_join=None): try: result = _build_instance_get(context, columns_to_join=columns_to_join ).filter_by(id=instance_id).first() def _build_instance_get(context, session=None, columns_to_join=None, use_slave=False): query = model_query(context, models.Instance, session=session, project_only=True, use_slave=use_slave).\def _instances_fill_metadata(context, instances, manual_joins=None, use_slave=False): use_slave=use_slave): use_slave=use_slave): for row in _instance_pcidevs_get_multi(context, uuids):def instance_get_all(context, columns_to_join=None): query = model_query(context, models.Instance) return _instances_fill_metadata(context, instances, manual_joins) use_slave=False): use_slave=use_slave, sort_dirs=[sort_dir]) columns_to_join=None, use_slave=False, sort_keys=None, sort_dirs=None): if CONF.database.slave_connection == '': use_slave = False session = get_session(use_slave=use_slave) return _instances_fill_metadata(context, query_prefix.all(), manual_joins) use_slave=False, columns_to_join=None): session = get_session(use_slave=use_slave) return _instances_fill_metadata(context, query.all(), manual_joins) def _instance_get_all_query(context, project_only=False, joins=None, use_slave=False): use_slave=use_slave) use_slave=False): return _instances_fill_metadata(context, _instance_get_all_query(context, use_slave=use_slave).filter_by(host=host).all(), use_slave=use_slave) columns_to_join=None): return _instances_fill_metadata(context, _instance_get_all_query( context, joins=columns_to_join).filter_by(host=host). filter_by(node=node).all(), manual_joins=manual_joins)def instance_get_all_by_host_and_not_type(context, host, type_id=None): return _instances_fill_metadata(context, _instance_get_all_query(context).filter_by(host=host). filter(models.Instance.instance_type_id != type_id).all())def instance_get_floating_address(context, instance_id): fixed_ips = fixed_ip_get_by_instance(context, instance['uuid']) fixed_ips[0]['address'])def instance_floating_address_get_all(context, instance_uuid): base_model=models.FloatingIp).\def instance_get_all_hung_in_rebooting(context, reboot_window): return _instances_fill_metadata(context, model_query(context, models.Instance). filter(models.Instance.updated_at <= reboot_window). filter_by(task_state=task_states.REBOOTING).all(), manual_joins=[])def instance_update(context, instance_uuid, values): instance_ref = _instance_update(context, instance_uuid, values)[1] columns_to_join=None): columns_to_join=columns_to_join) metadata, session): columns_to_join=None): session = get_session() with session.begin(): instance_ref = _instance_get_by_uuid(context, instance_uuid, session=session, columns_to_join=columns_to_join) if ""expected_task_state"" in values: # it is not a db column so always pop out expected = values.pop(""expected_task_state"") if not isinstance(expected, (tuple, list, set)): expected = (expected,) actual_state = instance_ref[""task_state""] if actual_state not in expected: if actual_state == task_states.DELETING: raise exception.UnexpectedDeletingTaskStateError( actual=actual_state, expected=expected) else: raise exception.UnexpectedTaskStateError( actual=actual_state, expected=expected) if ""expected_vm_state"" in values: expected = values.pop(""expected_vm_state"") if not isinstance(expected, (tuple, list, set)): expected = (expected,) actual_state = instance_ref[""vm_state""] if actual_state not in expected: raise exception.UnexpectedVMStateError(actual=actual_state, expected=expected) instance_hostname = instance_ref['hostname'] or '' if (""hostname"" in values and values[""hostname""].lower() != instance_hostname.lower()): _validate_unique_server_name(context, session, values['hostname']) if copy_old_instance: old_instance_ref = copy.copy(instance_ref) else: old_instance_ref = None metadata = values.get('metadata') if metadata is not None: _instance_metadata_update_in_place(context, instance_ref, 'metadata', models.InstanceMetadata, values.pop('metadata'), session) system_metadata = values.get('system_metadata') if system_metadata is not None: _instance_metadata_update_in_place(context, instance_ref, 'system_metadata', models.InstanceSystemMetadata, values.pop('system_metadata'), session) _handle_objects_related_type_conversions(values) instance_ref.update(values) session.add(instance_ref)def instance_add_security_group(context, instance_uuid, security_group_id): sec_group_ref.save()def instance_remove_security_group(context, instance_uuid, security_group_id): model_query(context, models.SecurityGroupInstanceAssociation).\ filter_by(instance_uuid=instance_uuid).\ filter_by(security_group_id=security_group_id).\ soft_delete()def _security_group_get_query(context, session=None, read_deleted=None, project_only=False, join_rules=True): query = model_query(context, models.SecurityGroup, session=session, read_deleted=read_deleted, project_only=project_only)def _security_group_get_by_names(context, session, project_id, group_names): query = _security_group_get_query(context, session=session, read_deleted=""no"", join_rules=False).\def security_group_get_all(context): return _security_group_get_query(context).all()def security_group_get(context, security_group_id, columns_to_join=None): query = _security_group_get_query(context, project_only=True).\ columns_to_join=None): query = _security_group_get_query(context, read_deleted=""no"", join_rules=False).\def security_group_get_by_project(context, project_id): return _security_group_get_query(context, read_deleted=""no"").\def security_group_get_by_instance(context, instance_uuid): return _security_group_get_query(context, read_deleted=""no"").\def security_group_in_use(context, group_id): session = get_session() with session.begin(): # Are there any instances that haven't been deleted # that include this group? inst_assoc = model_query(context, models.SecurityGroupInstanceAssociation, read_deleted=""no"", session=session).\ filter_by(security_group_id=group_id).\ all() for ia in inst_assoc: num_instances = model_query(context, models.Instance, session=session, read_deleted=""no"").\ filter_by(uuid=ia.instance_uuid).\ count() if num_instances: return Truedef security_group_create(context, values): return _security_group_create(context, values) columns_to_join=None): session = get_session() with session.begin(): query = model_query(context, models.SecurityGroup, session=session).filter_by(id=security_group_id) if columns_to_join: for column in columns_to_join: query = query.options(joinedload_all(column)) security_group_ref = query.first() if not security_group_ref: raise exception.SecurityGroupNotFound( security_group_id=security_group_id) security_group_ref.update(values) name = security_group_ref['name'] project_id = security_group_ref['project_id'] try: security_group_ref.save(session=session) except db_exc.DBDuplicateEntry: raise exception.SecurityGroupExists( project_id=project_id, security_group_name=name)def security_group_ensure_default(context): return _security_group_ensure_default(context) 'default') def _security_group_ensure_default(context, session=None): if session is None: session = get_session() with session.begin(subtransactions=True): try: default_group = _security_group_get_by_names(context, session, context.project_id, ['default'])[0] except exception.NotFound: values = {'name': 'default', 'description': 'default', 'user_id': context.user_id, 'project_id': context.project_id} usage = model_query(context, models.QuotaUsage, read_deleted=""no"", session=session).\ filter_by(project_id=context.project_id).\ filter_by(user_id=context.user_id).\ filter_by(resource='security_groups') # Create quota usage for auto created default security group if not usage.first(): _quota_usage_create(context.project_id, context.user_id, 'security_groups', 1, 0, None, session=session) else: usage.update({'in_use': int(usage.first().in_use) + 1}) default_rules = _security_group_rule_get_default_query(context, session=session).all() for default_rule in default_rules: # This is suboptimal, it should be programmatic to know # the values of the default_rule rule_values = {'protocol': default_rule.protocol, 'from_port': default_rule.from_port, 'to_port': default_rule.to_port, 'cidr': default_rule.cidr, 'parent_group_id': default_group.id, } _security_group_rule_create(context, rule_values, session=session) return default_groupdef security_group_destroy(context, security_group_id): session = get_session() with session.begin(): model_query(context, models.SecurityGroup, session=session).\ filter_by(id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupInstanceAssociation, session=session).\ filter_by(security_group_id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupIngressRule, session=session).\ filter_by(group_id=security_group_id).\ soft_delete() model_query(context, models.SecurityGroupIngressRule, session=session).\ filter_by(parent_group_id=security_group_id).\ soft_delete() def security_group_rule_get(context, security_group_rule_id): result = (_security_group_rule_get_query(context). columns_to_join=None): query = (_security_group_rule_get_query(context). security_group_id): return (_security_group_rule_get_query(context).def security_group_rule_create(context, values): return _security_group_rule_create(context, values)def security_group_rule_destroy(context, security_group_rule_id): count = (_security_group_rule_get_query(context).def security_group_rule_count_by_group(context, security_group_id): read_deleted=""no"").def security_group_default_rule_get(context, security_group_rule_default_id): result = _security_group_rule_get_default_query(context).\ security_group_rule_default_id): session = get_session() with session.begin(): count = _security_group_rule_get_default_query(context, session=session).\ filter_by(id=security_group_rule_default_id).\ soft_delete() if count == 0: raise exception.SecurityGroupDefaultRuleNotFound( rule_id=security_group_rule_default_id)def security_group_default_rule_create(context, values): security_group_default_rule_ref.save()def security_group_default_rule_list(context): return _security_group_rule_get_default_query(context).\def ec2_instance_create(context, instance_uuid, id=None): ec2_instance_ref.save()",724,521
openstack%2Fnova~master~I24dfef04cd0cddbff72267b93e0148b8fb204717,openstack/nova,master,I24dfef04cd0cddbff72267b93e0148b8fb204717,Add support for clean_shutdown to shelve in compute api layer,MERGED,2014-11-17 22:11:28.000000000,2014-12-12 16:09:17.000000000,2014-12-11 14:08:11.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 8688}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-17 22:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fcbe05deec1d830b10f9ec6a935cb8b909289ed', 'message': 'Add support for clean_shutdown to shelve in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 2, 'created': '2014-11-18 17:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/653f74439508072b68208e20d6c2016624d20c7a', 'message': 'Add support for clean_shutdown to shelve in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 3, 'created': '2014-12-08 13:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30e8fbf8e3801c938a6a0a639120c28537df3425', 'message': 'Add support for clean_shutdown to shelve in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 4, 'created': '2014-12-10 13:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/082457d2746133e25c51cb908db33578e245a70d', 'message': 'Add support for clean_shutdown to shelve in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 5, 'created': '2014-12-10 20:25:20.000000000', 'files': ['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/394ac5eea215831e82f96d43177442af67b40bb4', 'message': 'Add support for clean_shutdown to shelve in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717\nPartially-Implements: blueprint user-defined-shutdown\n'}]",0,135098,394ac5eea215831e82f96d43177442af67b40bb4,47,13,5,1501,,,0,"Add support for clean_shutdown to shelve in compute api layer

Change Iec3dfd17725440958aac395ebc471e51afd6522e added
clean_shutdown support to the compute manager in Juno.
This change is part of a set to extend that to the compute
API layer, which will in turn allow us to extend the REST API
to provide a forced-shutdown option to those operations.

Change-Id: I24dfef04cd0cddbff72267b93e0148b8fb204717
Partially-Implements: blueprint user-defined-shutdown
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/135098/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",2,0fcbe05deec1d830b10f9ec6a935cb8b909289ed,bug/1384637," def shelve(self, context, instance, clean_shutdown=True): image_id=image_id, clean_shutdown=clean_shutdown) instance=instance, clean_shutdown=clean_shutdown) def shelve_offload(self, context, instance, clean_shutdown=True): self.compute_rpcapi.shelve_offload_instance(context, instance=instance, clean_shutdown=clean_shutdown)"," def shelve(self, context, instance): image_id=image_id) instance=instance) def shelve_offload(self, context, instance): self.compute_rpcapi.shelve_offload_instance(context, instance=instance)",121,5
openstack%2Fmagnum~master~I096f20e953eb77c8da248cad7a3919994cc3a1f8,openstack/magnum,master,I096f20e953eb77c8da248cad7a3919994cc3a1f8,Update migration files to reflect new schema,MERGED,2014-12-12 15:38:18.000000000,2014-12-12 16:04:14.000000000,2014-12-12 16:04:13.000000000,"[{'_account_id': 3}, {'_account_id': 2834}]","[{'number': 1, 'created': '2014-12-12 15:38:18.000000000', 'files': ['magnum/db/sqlalchemy/alembic/versions/2581ebaf0cb2_initial_migration.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/de215c5fa67421cc9a4b23798a0d0d5dedd7c8f2', 'message': 'Update migration files to reflect new schema\n\nChange-Id: I096f20e953eb77c8da248cad7a3919994cc3a1f8\n'}]",0,141407,de215c5fa67421cc9a4b23798a0d0d5dedd7c8f2,6,2,1,6924,,,0,"Update migration files to reflect new schema

Change-Id: I096f20e953eb77c8da248cad7a3919994cc3a1f8
",git fetch https://review.opendev.org/openstack/magnum refs/changes/07/141407/1 && git format-patch -1 --stdout FETCH_HEAD,['magnum/db/sqlalchemy/alembic/versions/2581ebaf0cb2_initial_migration.py'],1,de215c5fa67421cc9a4b23798a0d0d5dedd7c8f2,," sa.Column('bay_uuid', sa.String(length=36), nullable=True), sa.Column('name', sa.String(length=255), nullable=True),",,2,0
openstack%2Fmagnum~master~I27bb1d4ec2174abb30e7770daaeab24c26987d01,openstack/magnum,master,I27bb1d4ec2174abb30e7770daaeab24c26987d01,Implement Service object Rest APIs,MERGED,2014-12-11 18:03:17.000000000,2014-12-12 16:02:55.000000000,2014-12-12 16:02:55.000000000,"[{'_account_id': 3}, {'_account_id': 2834}, {'_account_id': 6924}]","[{'number': 1, 'created': '2014-12-11 18:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/683478a4897dbc11603a9b245da40000f469bc67', 'message': 'WIP: Expose Service Rest API calls\n\nChange-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01\n'}, {'number': 2, 'created': '2014-12-11 19:22:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/beb1fe6775d8de4d0715b851ad4d651dc167f00f', 'message': 'WIP: Expose Service Rest API calls\n\nChange-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01\n'}, {'number': 3, 'created': '2014-12-12 15:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ea5b4378a92eb1f98d95b6b126a3e1bce2f7b84e', 'message': 'Implement Service object Rest APIs\n\nPartially Implements: magnum-backend-kubernetes\n\nChange-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01\n'}, {'number': 4, 'created': '2014-12-12 15:32:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6504820c587e15610d1a69ea4eedc3037c7bc97d', 'message': 'Implement Service object Rest APIs\n\nPartially Implements: magnum-backend-kubernetes\n\nChange-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01\n'}, {'number': 5, 'created': '2014-12-12 15:33:13.000000000', 'files': ['magnum/objects/service.py', 'magnum/api/controllers/v1/__init__.py', 'magnum/tests/api/controllers/v1/test_all_objects.py', 'magnum/db/sqlalchemy/models.py', 'magnum/api/controllers/v1/service.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/598b9aae99ed1ceb27555efe702f02cdaf2cc426', 'message': 'Implement Service object Rest APIs\n\nPartially Implements: blueprint magnum-backend-kubernetes\n\nChange-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01\n'}]",3,141116,598b9aae99ed1ceb27555efe702f02cdaf2cc426,15,3,5,6924,,,0,"Implement Service object Rest APIs

Partially Implements: blueprint magnum-backend-kubernetes

Change-Id: I27bb1d4ec2174abb30e7770daaeab24c26987d01
",git fetch https://review.opendev.org/openstack/magnum refs/changes/16/141116/5 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/test_functional.py', 'magnum/api/controllers/v1/__init__.py', 'magnum/api/controllers/v1/service.py']",3,683478a4897dbc11603a9b245da40000f469bc67,bp/magnum-backend-kubernetes,"import datetimeimport wsmeext.pecan as wsme_pecan from magnum.api.controllers import base from magnum.api.controllers import link from magnum.api.controllers.v1 import collection from magnum.api.controllers.v1 import types from magnum.api.controllers.v1 import utils as api_utilsfrom magnum import objectsclass ServicePatchType(types.JsonPatchType): @staticmethod def mandatory_attrs(): return ['/service_uuid'] class Service(base.APIBase): _service_uuid = None def _get_service_uuid(self): return self._service_uuid def _set_service_uuid(self, value): if value and self._service_uuid != value: try: pod = objects.Service.get(pecan.request.context, value) self._service_uuid = Service.uuid self.service_id = Service.id except exception.PodNotFound as e: # Change error code because 404 (NotFound) is inappropriate # response for a POST request to create a Pod e.code = 400 # BadRequest raise e elif value == wtypes.Unset: self._pod_uuid = wtypes.Unset """"""Description of this service"""""" bay_uuid = types.uuid """"""Unique UUID of the bay the service runs on"""""" self.fields = [] fields = list(objects.Service.fields) fields.append('service_uuid') for field in fields: # Skip fields we do not expose. if not hasattr(self, field): continue self.fields.append(field) setattr(self, field, kwargs.get(field, wtypes.Unset)) self.fields.append('service_id') setattr(self, 'service_uuid', kwargs.get('service_id', wtypes.Unset)) @staticmethod def _convert_with_links(service, url, expand=True): if not expand: service.unset_fields_except(['uuid', 'name', 'desc', 'bay_uuid']) # never expose the pod_id attribute service.pod_id = wtypes.Unset service.links = [link.Link.make_link('self', url, 'services', service.uuid), link.Link.make_link('bookmark', url, 'services', service.uuid, bookmark=True) ] return service @classmethod def convert_with_links(cls, rpc_service, expand=True): pod = Service(**rpc_service.as_dict()) return cls._convert_with_links(pod, pecan.request.host_url, expand) @classmethod def sample(cls, expand=True): sample = cls(uuid='fe78db47-9a37-4e9f-8572-804a10abc0aa', name='MyService', desc='Service - Description', bay_uuid='7ae81bb3-dec3-4289-8d6c-da80bd8001ae', created_at=datetime.datetime.utcnow(), updated_at=datetime.datetime.utcnow()) sample._service_uuid = '87504bd9-ca50-40fd-b14e-bcb23ed42b27' return cls._convert_with_links(sample, 'http://localhost:9511', expand) class ServiceCollection(collection.Collection): """"""API representation of a collection of pods."""""" services = [Service] """"""A list containing services objects"""""" def __init__(self, **kwargs): self._type = 'services' @staticmethod def convert_with_links(rpc_pods, limit, url=None, expand=False, **kwargs): collection = ServiceCollection() collection.services = [Service.convert_with_links(p, expand) for p in rpc_pods] collection.next = collection.get_next(limit, url=url, **kwargs) return collection sample = cls() sample.pods = [Service.sample()] return sample class ServicesController(rest.RestController): """"""REST controller for Services."""""" from_services = False """"""A flag to indicate if the requests to this controller are coming from the top-level resource Services."""""" _custom_actions = { 'detail': ['GET'], } def _get_services_collection(self, marker, limit, sort_key, sort_dir, expand=False, resource_url=None): limit = api_utils.validate_limit(limit) sort_dir = api_utils.validate_sort_dir(sort_dir) marker_obj = None if marker: marker_obj = objects.Service.get_by_uuid(pecan.request.context, marker) services = objects.Service.list(pecan.request.context, limit, marker_obj, sort_key=sort_key, sort_dir=sort_dir) return ServiceCollection.convert_with_links(services, limit, url=resource_url, expand=expand, sort_key=sort_key, sort_dir=sort_dir) @wsme_pecan.wsexpose(ServiceCollection, types.uuid, types.uuid, int, wtypes.text, wtypes.text) def get_all(self, service_uuid=None, marker=None, limit=None, sort_key='id', sort_dir='asc'): """"""Retrieve a list of services. :param marker: pagination marker for large data sets. :param limit: maximum number of resources to return in a single result. :param sort_key: column to sort results by. Default: id. :param sort_dir: direction to sort. ""asc"" or ""desc"". Default: asc. """""" return self._get_services_collection(marker, limit, sort_key, sort_dir) @wsme_pecan.wsexpose(ServiceCollection, types.uuid, types.uuid, int, wtypes.text, wtypes.text) def detail(self, service_uuid=None, marker=None, limit=None, sort_key='id', sort_dir='asc'): """"""Retrieve a list of services with detail. :param service_uuid: UUID of a service, to get only services for that service. :param marker: pagination marker for large data sets. :param limit: maximum number of resources to return in a single result. :param sort_key: column to sort results by. Default: id. :param sort_dir: direction to sort. ""asc"" or ""desc"". Default: asc. """""" # NOTE(lucasagomes): /detail should only work agaist collections parent = pecan.request.path.split('/')[:-1][-1] if parent != ""services"": raise exception.HTTPNotFound expand = True resource_url = '/'.join(['services', 'detail']) return self._get_services_collection(marker, limit, sort_key, sort_dir, expand, resource_url) @wsme_pecan.wsexpose(Service, types.uuid) def get_one(self, service_uuid): """"""Retrieve information about the given service. :param service_uuid: UUID of a service. """""" if self.from_services: raise exception.OperationNotPermitted rpc_service = objects.Service.get_by_uuid(pecan.request.context, service_uuid) return Service.convert_with_links(rpc_service) @wsme_pecan.wsexpose(Service, body=Service, status_code=201) def post(self, service): """"""Create a new service. :param service: a service within the request body. """""" if self.from_services: raise exception.OperationNotPermitted new_service = objects.Service(pecan.request.context, **service.as_dict()) new_service.create() # Set the HTTP Location Header pecan.response.location = link.build_url('services', new_service.uuid) return Service.convert_with_links(new_service) @wsme.validate(types.uuid, [ServicePatchType]) @wsme_pecan.wsexpose(Service, types.uuid, body=[ServicePatchType]) def patch(self, service_uuid, patch): """"""Update an existing service. :param service_uuid: UUID of a service. :param patch: a json PATCH document to apply to this service. """""" if self.from_services: raise exception.OperationNotPermitted rpc_service = objects.Service.get_by_uuid(pecan.request.context, service_uuid) try: service_dict = rpc_service.as_dict() # NOTE(lucasagomes): # 1) Remove service_id because it's an internal value and # not present in the API object # 2) Add service_uuid service_dict['service_uuid'] = service_dict.pop('service_id', None) service = Service(**api_utils.apply_jsonpatch(service_dict, patch)) except api_utils.JSONPATCH_EXCEPTIONS as e: raise exception.PatchError(patch=patch, reason=e) # Update only the fields that have changed for field in objects.Service.fields: try: patch_val = getattr(service, field) except AttributeError: # Ignore fields that aren't exposed in the API continue if patch_val == wtypes.Unset: patch_val = None if rpc_service[field] != patch_val: rpc_service[field] = patch_val if hasattr(pecan.request, 'rpcapi'): rpc_service = objects.Service.get_by_id(pecan.request.context, rpc_service.service_id) topic = pecan.request.rpcapi.get_topic_for(rpc_service) new_service = pecan.request.rpcapi.update_service( pecan.request.context, rpc_service, topic) return Service.convert_with_links(new_service) else: rpc_service.save() return Service.convert_with_links(rpc_service) @wsme_pecan.wsexpose(None, types.uuid, status_code=204) def delete(self, service_uuid): """"""Delete a service. :param service_uuid: UUID of a service. """""" if self.from_services: raise exception.OperationNotPermitted rpc_service = objects.Service.get_by_uuid(pecan.request.context, service_uuid) rpc_service.destroy()"," from magnum.api.controllers.v1.base import Basefrom magnum.common import yamlutilsclass ServiceController(rest.RestController): @exception.wrap_pecan_controller_exception @pecan.expose(content_type='application/x-yaml') def get(self): """"""Retrieve a service by UUID."""""" res_yaml = yamlutils.dump({'dummy_data'}) pecan.response.status = 200 return res_yaml @exception.wrap_pecan_controller_exception @pecan.expose(content_type='application/x-yaml') def put(self): """"""Create a new service."""""" res_yaml = yamlutils.dump({'dummy_data'}) pecan.response.status = 200 return res_yaml @exception.wrap_pecan_controller_exception @pecan.expose(content_type='application/x-yaml') def delete(self): """"""Delete an existing service."""""" res_yaml = yamlutils.dump({'dummy_data'}) pecan.response.status = 200 return res_yaml class Service(Base): return cls(id=str(uuid.uuid1(), name=""Docker"", desc='Docker Services'))",307,30
openstack%2Fnova~master~I5f00f63742fac89fea65149582f36866146e86f5,openstack/nova,master,I5f00f63742fac89fea65149582f36866146e86f5,Add support for clean_shutdown to rescue in compute api layer,MERGED,2014-11-19 22:35:45.000000000,2014-12-12 16:02:34.000000000,2014-12-11 14:08:38.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-19 22:35:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/742b07fc170f3ab4b46c3276036a101af389d78e', 'message': 'Add support for clean_shutdown to rescue in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nAlso adds a couple of missing unit test cases for rescue to the\ncompute_api tests\n\nChange-Id: I5f00f63742fac89fea65149582f36866146e86f5\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 2, 'created': '2014-12-08 13:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fbd14fd1f6f5e950dd48401ac5952ee3fa72242', 'message': 'Add support for clean_shutdown to rescue in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nAlso adds a couple of missing unit test cases for rescue to the\ncompute_api tests\n\nChange-Id: I5f00f63742fac89fea65149582f36866146e86f5\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 3, 'created': '2014-12-10 13:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/48c609c55283f4a63809b07ef1779965c343159d', 'message': 'Add support for clean_shutdown to rescue in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nAlso adds a couple of missing unit test cases for rescue to the\ncompute_api tests\n\nChange-Id: I5f00f63742fac89fea65149582f36866146e86f5\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 4, 'created': '2014-12-10 20:25:36.000000000', 'files': ['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6de862b973547f0984c516a536b758087028c959', 'message': 'Add support for clean_shutdown to rescue in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nAlso adds a couple of missing unit test cases for rescue to the\ncompute_api tests\n\nChange-Id: I5f00f63742fac89fea65149582f36866146e86f5\nPartially-Implements: blueprint user-defined-shutdown\n'}]",1,135756,6de862b973547f0984c516a536b758087028c959,34,9,4,1501,,,0,"Add support for clean_shutdown to rescue in compute api layer

Change Iec3dfd17725440958aac395ebc471e51afd6522e added
clean_shutdown support to the compute manager in Juno.
This change is part of a set to extend that to the compute
API layer, which will in turn allow us to extend the REST API
to provide a forced-shutdown option to those operations.

Also adds a couple of missing unit test cases for rescue to the
compute_api tests

Change-Id: I5f00f63742fac89fea65149582f36866146e86f5
Partially-Implements: blueprint user-defined-shutdown
",git fetch https://review.opendev.org/openstack/nova refs/changes/56/135756/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/cells_api.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",3,742b07fc170f3ab4b46c3276036a101af389d78e,bug/1384637," rescue_image_ref=None, clean_shutdown=True): rescue_password=rescue_password, rescue_image_ref=rescue_image_ref, clean_shutdown=clean_shutdown)"," rescue_image_ref=None): rescue_password=rescue_password, rescue_image_ref=rescue_image_ref)",28,10
openstack%2Fnova~master~I38707cf869705f983ab35e549d95dc4be4811ece,openstack/nova,master,I38707cf869705f983ab35e549d95dc4be4811ece,Add support for clean_shutdown to stop in compute api layer,MERGED,2014-11-14 19:51:24.000000000,2014-12-12 15:59:17.000000000,2014-12-11 14:07:47.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6062}, {'_account_id': 8688}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-11-14 19:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4fd7e98c53905f55dbc5b75973def16761074f5c', 'message': 'Add support for clean_shutdown to stop in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I38707cf869705f983ab35e549d95dc4be4811ece\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 2, 'created': '2014-11-18 16:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/47e6d0e2234df3481ca7ea140c36124f95d73e92', 'message': 'Add support for clean_shutdown to stop in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I38707cf869705f983ab35e549d95dc4be4811ece\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 3, 'created': '2014-12-08 13:45:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0df00173f52947fddc5ed6578c7725c8b8734631', 'message': 'Add support for clean_shutdown to stop in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I38707cf869705f983ab35e549d95dc4be4811ece\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 4, 'created': '2014-12-10 13:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/13baae51c73bbd6fe06ce9a14651bb6ffdb9a171', 'message': 'Add support for clean_shutdown to stop in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I38707cf869705f983ab35e549d95dc4be4811ece\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 5, 'created': '2014-12-10 20:24:50.000000000', 'files': ['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e37692154d0f6e806140b5029ebb8c7b492498d1', 'message': 'Add support for clean_shutdown to stop in compute api layer\n\nChange Iec3dfd17725440958aac395ebc471e51afd6522e added\nclean_shutdown support to the compute manager in Juno.\nThis change is part of a set to extend that to the compute\nAPI layer, which will in turn allow us to extend the REST API\nto provide a forced-shutdown option to those operations.\n\nChange-Id: I38707cf869705f983ab35e549d95dc4be4811ece\nPartially-Implements: blueprint user-defined-shutdown\n'}]",2,134634,e37692154d0f6e806140b5029ebb8c7b492498d1,45,12,5,1501,,,0,"Add support for clean_shutdown to stop in compute api layer

Change Iec3dfd17725440958aac395ebc471e51afd6522e added
clean_shutdown support to the compute manager in Juno.
This change is part of a set to extend that to the compute
API layer, which will in turn allow us to extend the REST API
to provide a forced-shutdown option to those operations.

Change-Id: I38707cf869705f983ab35e549d95dc4be4811ece
Partially-Implements: blueprint user-defined-shutdown
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/134634/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/compute/api.py']",2,4fd7e98c53905f55dbc5b75973def16761074f5c,bug/1384637," def force_stop(self, context, instance, do_cast=True, clean_shutdown=True): self.compute_rpcapi.stop_instance(context, instance, do_cast=do_cast, clean_shutdown=clean_shutdown) def stop(self, context, instance, do_cast=True, clean_shutdown=True): self.force_stop(context, instance, do_cast, clean_shutdown)"," def force_stop(self, context, instance, do_cast=True): self.compute_rpcapi.stop_instance(context, instance, do_cast=do_cast) def stop(self, context, instance, do_cast=True): self.force_stop(context, instance, do_cast)",20,8
openstack%2Fnova~master~Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8,openstack/nova,master,Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8,Extend clean_shutdown to the compute rpc layer,MERGED,2014-10-22 19:34:09.000000000,2014-12-12 15:54:14.000000000,2014-12-11 13:52:42.000000000,"[{'_account_id': 3}, {'_account_id': 1501}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 7461}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-10-22 19:34:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/849d94749ff987a23a02ff47382bc7df8cbd308f', 'message': 'Extend clean_shutdown to the compute api layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nand shelve in Juno to the compute api layer.  This will in turn allow\nus to extend the API to provide a forced-shutdown option to those\noperations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 2, 'created': '2014-11-07 13:21:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0a2cb2f1871e5126e5c3dada30738946158fd066', 'message': 'Extend clean_shutdown to the compute rpc layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nshelve and shelve_offload in Juno to the compute rpc layer.  This\nwill in turn allow us to extend the API to provide a\nforced-shutdown option to those operations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 3, 'created': '2014-11-13 13:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a6e19d556daa22227eaf15ce276ffaa1c837ac5d', 'message': 'Extend clean_shutdown to the compute rpc layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nshelve and shelve_offload in Juno to the compute rpc layer.  This\nwill in turn allow us to extend the API to provide a\nforced-shutdown option to those operations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 4, 'created': '2014-12-08 12:44:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bf9eb26bdfddf00be655a071903bb1a2630afd3', 'message': 'Extend clean_shutdown to the compute rpc layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nshelve and shelve_offload in Juno to the compute rpc layer.  This\nwill in turn allow us to extend the API to provide a\nforced-shutdown option to those operations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 5, 'created': '2014-12-10 13:30:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6f4088d06030efeafdf9b1b0b704ca238f6b2d79', 'message': 'Extend clean_shutdown to the compute rpc layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nshelve and shelve_offload in Juno to the compute rpc layer.  This\nwill in turn allow us to extend the API to provide a\nforced-shutdown option to those operations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}, {'number': 6, 'created': '2014-12-10 20:24:34.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/cells/manager.py', 'nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/cells/test_cells_rpcapi.py', 'nova/tests/unit/cells/test_cells_manager.py', 'nova/cells/messaging.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/tests/unit/cells/test_cells_messaging.py', 'nova/cells/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c6ac4e1c88d3708d874a9777b9ff368d442c3416', 'message': 'Extend clean_shutdown to the compute rpc layer\n\nAdds the clean_shutdown parameter added to stop, resize, rescue,\nshelve and shelve_offload in Juno to the compute rpc layer.  This\nwill in turn allow us to extend the API to provide a\nforced-shutdown option to those operations.\n\nChange-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8\nPartially-Implements: blueprint user-defined-shutdown\n'}]",14,130338,c6ac4e1c88d3708d874a9777b9ff368d442c3416,72,14,6,1501,,,0,"Extend clean_shutdown to the compute rpc layer

Adds the clean_shutdown parameter added to stop, resize, rescue,
shelve and shelve_offload in Juno to the compute rpc layer.  This
will in turn allow us to extend the API to provide a
forced-shutdown option to those operations.

Change-Id: Ie24c66e5006e64ef8b45d9d5056cc7876481a2f8
Partially-Implements: blueprint user-defined-shutdown
",git fetch https://review.opendev.org/openstack/nova refs/changes/38/130338/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/compute/test_compute_api.py', 'nova/cells/manager.py', 'nova/tests/cells/test_cells_rpcapi.py', 'nova/tests/cells/test_cells_messaging.py', 'nova/tests/cells/test_cells_manager.py', 'nova/tests/compute/test_rpcapi.py', 'nova/cells/messaging.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/cells/rpcapi.py', 'nova/compute/api.py']",11,849d94749ff987a23a02ff47382bc7df8cbd308f,bp/user-defined-shutdown," def force_stop(self, context, instance, do_cast=True, clean_shutdown=True): self.compute_rpcapi.stop_instance(context, instance, do_cast=do_cast, clean_shutdown=clean_shutdown) def stop(self, context, instance, do_cast=True, clean_shutdown=True): self.force_stop(context, instance, do_cast, clean_shutdown)"," def force_stop(self, context, instance, do_cast=True): self.compute_rpcapi.stop_instance(context, instance, do_cast=do_cast) def stop(self, context, instance, do_cast=True): self.force_stop(context, instance, do_cast)",128,51
openstack%2Fdevstack~master~I96a98331ece15da869a3ea7af80d16fab2351329,openstack/devstack,master,I96a98331ece15da869a3ea7af80d16fab2351329,Use latest version of python-openstackclient,MERGED,2014-12-10 00:02:02.000000000,2014-12-12 15:51:29.000000000,2014-12-11 16:16:05.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 6482}, {'_account_id': 7118}, {'_account_id': 7575}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 00:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/8383fd97aa6380dc4bd35f7a0f0ff278a3803163', 'message': ""Use latest version of python-openstackclient\n\nSome options in openstack client like --or-show are available only\nfrom 1.0.0. For libraries like openstackclient which are not\n'required' by other projects there is no way to specify lower\nlimits in devstack. Hence, forcing pip to always upgrade the\npackage if latest is available.\n\nChange-Id: I96a98331ece15da869a3ea7af80d16fab2351329\n""}, {'number': 2, 'created': '2014-12-10 00:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e083236405a5d390b68645f1d44911097b417104', 'message': ""Use latest version of python-openstackclient\n\nSome options in openstack client like --or-show that is \nused by devstack is available only from 1.0.0. For libraries \nlike openstackclient which are not 'required' by other \nprojects there is no way to specify lower limits in devstack. \nHence, forcing pip to always upgrade the package if latest\nis available.\n\nChange-Id: I96a98331ece15da869a3ea7af80d16fab2351329\n""}, {'number': 3, 'created': '2014-12-10 20:01:47.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/342ac4b77429aa0ccf0bfbd864d91477cfb656c0', 'message': ""Use latest version of python-openstackclient\n\nSome options in openstack client like --or-show are available only\nfrom 1.0.0. Adding this 'requirement' explictly as openstackclient\nis not as part of requirements of other projects.\n\nChange-Id: I96a98331ece15da869a3ea7af80d16fab2351329\n""}]",4,140532,342ac4b77429aa0ccf0bfbd864d91477cfb656c0,17,7,3,7575,,,0,"Use latest version of python-openstackclient

Some options in openstack client like --or-show are available only
from 1.0.0. Adding this 'requirement' explictly as openstackclient
is not as part of requirements of other projects.

Change-Id: I96a98331ece15da869a3ea7af80d16fab2351329
",git fetch https://review.opendev.org/openstack/devstack refs/changes/32/140532/2 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,8383fd97aa6380dc4bd35f7a0f0ff278a3803163,use_latest_libary, pip_install -U python-openstackclient, pip_install python-openstackclient,1,1
openstack%2Fdevstack~master~I9cdd51f09edaccf218988240b48ce733d5771a65,openstack/devstack,master,I9cdd51f09edaccf218988240b48ce733d5771a65,Update devstack to work with new split neutron services repos,MERGED,2014-12-10 05:03:13.000000000,2014-12-12 15:47:43.000000000,2014-12-10 23:01:40.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 6951}, {'_account_id': 6995}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10385}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 05:03:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9692f5dfecf2a84cc7e5776796e9ad22fc1abc3b', 'message': 'Update devstack to work with new split neutron services repos\n\nThis commit udpates devstack to work with the latest neutron services, which\nare now in their own repositories.\n\nChange-Id: I9cdd51f09edaccf218988240b48ce733d5771a65\n'}, {'number': 2, 'created': '2014-12-10 13:59:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/293757758a06d20b3b0b5bde0be56bb5c3b74a61', 'message': 'Update devstack to work with new split neutron services repos\n\nThis commit udpates devstack to work with the latest neutron services, which\nare now in their own repositories.\n\nChange-Id: I9cdd51f09edaccf218988240b48ce733d5771a65\n'}, {'number': 3, 'created': '2014-12-10 16:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7ef396de434f8cb1549d5a883da3195e69a8375b', 'message': 'Update devstack to work with new split neutron services repos\n\nThis commit udpates devstack to work with the latest neutron services, which\nare now in their own repositories.\n\nChange-Id: I9cdd51f09edaccf218988240b48ce733d5771a65\n'}, {'number': 4, 'created': '2014-12-10 17:22:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/1d7d77c3ed19d6d50084b3d2551b3063fb30e43e', 'message': 'Update devstack to work with new split neutron services repos\n\nThis commit udpates devstack to work with the latest neutron services, which\nare now in their own repositories. This will also unblock third party CI for\nservices testing.\n\nChange-Id: I9cdd51f09edaccf218988240b48ce733d5771a65\n'}, {'number': 5, 'created': '2014-12-10 19:16:46.000000000', 'files': ['lib/neutron_plugins/services/loadbalancer', 'lib/neutron', 'lib/neutron_plugins/services/vpn', 'lib/neutron_plugins/services/firewall', 'stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/20b839fd51ff0ccecbc67f3d29578ce042c8b3c3', 'message': 'Update devstack to work with new split neutron services repos\n\nThis commit udpates devstack to work with the latest neutron services, which\nare now in their own repositories. This will also unblock third party CI for\nservices testing. This also allows devstack users to run neutron with\nservices again.\n\nChange-Id: I9cdd51f09edaccf218988240b48ce733d5771a65\n'}]",5,140572,20b839fd51ff0ccecbc67f3d29578ce042c8b3c3,37,14,5,105,,,0,"Update devstack to work with new split neutron services repos

This commit udpates devstack to work with the latest neutron services, which
are now in their own repositories. This will also unblock third party CI for
services testing. This also allows devstack users to run neutron with
services again.

Change-Id: I9cdd51f09edaccf218988240b48ce733d5771a65
",git fetch https://review.opendev.org/openstack/devstack refs/changes/72/140572/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/neutron_plugins/services/loadbalancer', 'lib/neutron', 'lib/neutron_plugins/services/vpn', 'lib/neutron_plugins/services/firewall', 'stackrc']",5,9692f5dfecf2a84cc7e5776796e9ad22fc1abc3b,devstack/services,# neutron fwaas service NEUTRON_FWAAS_REPO=${NEUTRON_FWAAS_REPO:-${GIT_BASE}/openstack/neutron-fwaas.git} NEUTRON_FWAAS_BRANCH=${NEUTRON_FWAAS_BRANCH:-master} # neutron lbaas service NEUTRON_LBAAS_REPO=${NEUTRON_LBAAS_REPO:-${GIT_BASE}/openstack/neutron-lbaas.git} NEUTRON_LBAAS_BRANCH=${NEUTRON_LBAAS_BRANCH:-master} # neutron vpnaas service NEUTRON_VPNAAS_REPO=${NEUTRON_VPNAAS_REPO:-${GIT_BASE}/openstack/neutron-vpnaas.git} NEUTRON_VPNAAS_BRANCH=${NEUTRON_VPNAAS_BRANCH:-master} ,,30,3
openstack%2Fironic-inspector~master~Ia43f834023b189324cba38a19cc782fc0b7745d4,openstack/ironic-inspector,master,Ia43f834023b189324cba38a19cc782fc0b7745d4,Wait for power off before finishing discovery,MERGED,2014-12-12 13:45:58.000000000,2014-12-12 15:46:04.000000000,2014-12-12 15:46:03.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-12 13:45:58.000000000', 'files': ['ironic_discoverd/process.py', 'ironic_discoverd/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/6432b534f6d9e023eae4bc3ab0425c690dc045b2', 'message': ""Wait for power off before finishing discovery\n\nThis used to be part of returning-to-ramdisk, but was lost after\nrevert. Also do not make the ramdisk wait for it's own power off.\n\nChange-Id: Ia43f834023b189324cba38a19cc782fc0b7745d4\nCloses-Bug: #1401872\n""}]",0,141370,6432b534f6d9e023eae4bc3ab0425c690dc045b2,8,3,1,10239,,,0,"Wait for power off before finishing discovery

This used to be part of returning-to-ramdisk, but was lost after
revert. Also do not make the ramdisk wait for it's own power off.

Change-Id: Ia43f834023b189324cba38a19cc782fc0b7745d4
Closes-Bug: #1401872
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/70/141370/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/process.py', 'ironic_discoverd/test/test_process.py']",2,6432b534f6d9e023eae4bc3ab0425c690dc045b2,bug/1401872," self.power_off_attempts = 2 # Simulate longer power off self.cli.node.get.side_effect = ( [self.node] * self.power_off_attempts + [mock.Mock(power_state='power off')]) self.assertEqual(self.power_off_attempts + 1, self.cli.node.get.call_count) @mock.patch.object(time, 'time') def test_power_off_timeout(self, time_mock, filters_mock, post_hook_mock): conf.CONF.set('discoverd', 'timeout', '100') time_mock.return_value = self.started_at + 1000 self.cli.node.get.return_value = self.node self.assertRaisesRegexp(utils.DiscoveryFailed, 'power off', self.call) self.cli.node.update.assert_called_once_with(self.uuid, self.patch_before) ",,47,10
openstack%2Fnova~master~I91055dc705f2ef54c830e641f9cf9ba0683eb313,openstack/nova,master,I91055dc705f2ef54c830e641f9cf9ba0683eb313,libvirt: Fix NUMA memnode assignments to host cells,MERGED,2014-12-09 15:09:42.000000000,2014-12-12 15:45:56.000000000,2014-12-11 17:09:55.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 5170}, {'_account_id': 5511}, {'_account_id': 7730}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11647}]","[{'number': 1, 'created': '2014-12-09 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2354d7610e2c86dcb371d5bfb15b3c8741018ee8', 'message': 'libvirt: Fix NUMA memnode assignments to host cells\n\nThis fix\n\n  https://review.openstack.org/138128\n\nbreaks assignments for NUMA topologies where host cell ID\nthat the instance cell is pinned to is not in increasing order. The\nreason for this is that the main loop of the method that will go through\nthe host cells (always in ascending order), and find instance cells that\nmatch (may not be in ascending order depending on how the fitting logic\nand usage of the host) but we simply append memnodes so they may end up\nin the wrong order when we hit the normalization loop.\n\nWe fix this by ""pre-allocating"" the memnodes list and making sure to add\nthe matching memnode to the same position as the guest config cell\nbefore hitting the normalization loop.\n\nChange-Id: I91055dc705f2ef54c830e641f9cf9ba0683eb313\nCloses-bug: #1397381\n'}, {'number': 2, 'created': '2014-12-09 18:08:51.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/08290cec7f02fa908dfda89d1749142d2d520f48', 'message': 'libvirt: Fix NUMA memnode assignments to host cells\n\nThis fix\n\n  https://review.openstack.org/138128\n\nbreaks assignments for NUMA topologies where host cell ID\nthat the instance cell is pinned to is not in increasing order. The\nreason for this is that the main loop of the method that will go through\nthe host cells (always in ascending order), and find instance cells that\nmatch (may not be in ascending order depending on how the fitting logic\nand usage of the host) but we simply append memnodes so they may end up\nin the wrong order when we hit the normalization loop.\n\nWe fix this by ""pre-allocating"" the memnodes list and making sure to add\nthe matching memnode to the same position as the guest config cell\nbefore hitting the normalization loop.\n\nChange-Id: I91055dc705f2ef54c830e641f9cf9ba0683eb313\nCloses-bug: #1397381\n'}]",2,140357,08290cec7f02fa908dfda89d1749142d2d520f48,23,12,2,5511,,,0,"libvirt: Fix NUMA memnode assignments to host cells

This fix

  https://review.openstack.org/138128

breaks assignments for NUMA topologies where host cell ID
that the instance cell is pinned to is not in increasing order. The
reason for this is that the main loop of the method that will go through
the host cells (always in ascending order), and find instance cells that
match (may not be in ascending order depending on how the fitting logic
and usage of the host) but we simply append memnodes so they may end up
in the wrong order when we hit the normalization loop.

We fix this by ""pre-allocating"" the memnodes list and making sure to add
the matching memnode to the same position as the guest config cell
before hitting the normalization loop.

Change-Id: I91055dc705f2ef54c830e641f9cf9ba0683eb313
Closes-bug: #1397381
",git fetch https://review.opendev.org/openstack/nova refs/changes/57/140357/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",2,2354d7610e2c86dcb371d5bfb15b3c8741018ee8,bp/virt-driver-cpu-pinning," @mock.patch.object(objects.Flavor, 'get_by_id') def test_get_guest_config_numa_host_instance_topo_reordered(self, mock_flavor): instance_topology = objects.InstanceNUMATopology( cells=[objects.InstanceNUMACell( id=3, cpuset=set([0, 1]), memory=1024), objects.InstanceNUMACell( id=0, cpuset=set([2, 3]), memory=1024)]) instance_ref = objects.Instance(**self.test_instance) instance_ref.numa_topology = instance_topology flavor = objects.Flavor(memory_mb=2048, vcpus=4, root_gb=496, ephemeral_gb=8128, swap=33550336, name='fake', extra_specs={}) mock_flavor.return_value = flavor caps = vconfig.LibvirtConfigCaps() caps.host = vconfig.LibvirtConfigCapsHost() caps.host.cpu = vconfig.LibvirtConfigCPU() caps.host.cpu.arch = ""x86_64"" caps.host.topology = self._fake_caps_numa_topology() conn = libvirt_driver.LibvirtDriver(fake.FakeVirtAPI(), True) disk_info = blockinfo.get_disk_info(CONF.libvirt.virt_type, instance_ref) with contextlib.nested( mock.patch.object( objects.Flavor, ""get_by_id"", return_value=flavor), mock.patch.object( objects.InstanceNUMATopology, ""get_by_instance_uuid"", return_value=instance_topology), mock.patch.object(host.Host, 'has_min_version', return_value=True), mock.patch.object( conn, ""_get_host_capabilities"", return_value=caps), ): cfg = conn._get_guest_config(instance_ref, [], {}, disk_info) self.assertIsNone(cfg.cpuset) # Test that the pinning is correct and limited to allowed only self.assertEqual(0, cfg.cputune.vcpupin[0].id) self.assertEqual(set([6, 7]), cfg.cputune.vcpupin[0].cpuset) self.assertEqual(1, cfg.cputune.vcpupin[1].id) self.assertEqual(set([6, 7]), cfg.cputune.vcpupin[1].cpuset) self.assertEqual(2, cfg.cputune.vcpupin[2].id) self.assertEqual(set([0, 1]), cfg.cputune.vcpupin[2].cpuset) self.assertEqual(3, cfg.cputune.vcpupin[3].id) self.assertEqual(set([0, 1]), cfg.cputune.vcpupin[3].cpuset) self.assertIsNotNone(cfg.cpu.numa) self.assertIsInstance(cfg.cputune.emulatorpin, vconfig.LibvirtConfigGuestCPUTuneEmulatorPin) self.assertEqual(set([0, 1, 6, 7]), cfg.cputune.emulatorpin.cpuset) for index, (instance_cell, numa_cfg_cell) in enumerate(zip( instance_topology.cells, cfg.cpu.numa.cells)): self.assertEqual(index, numa_cfg_cell.id) self.assertEqual(instance_cell.cpuset, numa_cfg_cell.cpus) self.assertEqual(instance_cell.memory * units.Ki, numa_cfg_cell.memory) allnodes = set([cell.id for cell in instance_topology.cells]) self.assertEqual(allnodes, set(cfg.numatune.memory.nodeset)) self.assertEqual(""strict"", cfg.numatune.memory.mode) for index, (instance_cell, memnode) in enumerate(zip( instance_topology.cells, cfg.numatune.memnodes)): self.assertEqual(index, memnode.cellid) self.assertEqual([instance_cell.id], memnode.nodeset) self.assertEqual(""strict"", memnode.mode) ",,80,4
openstack%2Fsahara~master~I165a99328f4af979c1de43aa13430a6eb6938cff,openstack/sahara,master,I165a99328f4af979c1de43aa13430a6eb6938cff,Update oslo-incubator periodic_task,MERGED,2014-12-04 18:42:05.000000000,2014-12-12 15:44:00.000000000,2014-12-12 12:07:06.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7bb383ca0c9deedae5b09f16622685818745796b', 'message': 'Update oslo-incubator periodic_task\n\nChanges -\n * add list_opts to all modules with configuration options\n * Remove code that moved to oslo.i18n\n\nChange-Id: I165a99328f4af979c1de43aa13430a6eb6938cff\n'}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/efb750e7206fe9944a5a78b4fa64ca8a9934eda9', 'message': 'Update oslo-incubator periodic_task\n\nChanges -\n * add list_opts to all modules with configuration options\n * Remove code that moved to oslo.i18n\n\nChange-Id: I165a99328f4af979c1de43aa13430a6eb6938cff\n'}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['sahara/openstack/common/periodic_task.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/2b9b98df7a913c2da2d810015f5821ef1ca729e1', 'message': 'Update oslo-incubator periodic_task\n\nChanges -\n * add list_opts to all modules with configuration options\n * Remove code that moved to oslo.i18n\n\nChange-Id: I165a99328f4af979c1de43aa13430a6eb6938cff\n'}]",0,139151,2b9b98df7a913c2da2d810015f5821ef1ca729e1,34,10,3,7555,,,0,"Update oslo-incubator periodic_task

Changes -
 * add list_opts to all modules with configuration options
 * Remove code that moved to oslo.i18n

Change-Id: I165a99328f4af979c1de43aa13430a6eb6938cff
",git fetch https://review.opendev.org/openstack/sahara refs/changes/51/139151/3 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/periodic_task.py'],1,7bb383ca0c9deedae5b09f16622685818745796b,,"import copydef list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(periodic_opts))] ",,6,0
openstack%2Foslo.concurrency~master~I34cf8b6358f59583cc178c029ebdd024f583dafe,openstack/oslo.concurrency,master,I34cf8b6358f59583cc178c029ebdd024f583dafe,Activate pep8 check that _ is imported,MERGED,2014-12-11 22:50:47.000000000,2014-12-12 15:39:10.000000000,2014-12-12 15:39:09.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6601}]","[{'number': 1, 'created': '2014-12-11 22:50:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/2aafe6f6ecc2533f78f8997895fd4afbdb107736', 'message': 'Activate pep8 check that _ is imported\n\nRemove the specification in tox.ini that _ is a builtin so that\nit will no longer assume that _ does not need to be imported.\n\nThis helps ensure that the _ from i18n is used.\n\nActivating this check did not flag any violations.\n\nChange-Id: I34cf8b6358f59583cc178c029ebdd024f583dafe\n'}]",0,141193,2aafe6f6ecc2533f78f8997895fd4afbdb107736,11,4,1,6601,,,0,"Activate pep8 check that _ is imported

Remove the specification in tox.ini that _ is a builtin so that
it will no longer assume that _ does not need to be imported.

This helps ensure that the _ from i18n is used.

Activating this check did not flag any violations.

Change-Id: I34cf8b6358f59583cc178c029ebdd024f583dafe
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/93/141193/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2aafe6f6ecc2533f78f8997895fd4afbdb107736,i18n_import,,builtins = _,0,1
openstack%2Ftempest~master~I450f896f29051921b011e1643f1a1e24ed82ac08,openstack/tempest,master,I450f896f29051921b011e1643f1a1e24ed82ac08,Use assertIn to check for subnet membership,MERGED,2014-12-10 17:38:22.000000000,2014-12-12 15:29:52.000000000,2014-12-11 08:14:24.000000000,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 17:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/335463ad2309a577f4de4456c8e3eca79613b967', 'message': 'Use assertIn to check for subnet membership\n\nFor dual stacked networks, the gateway port will have multiple subnets\nassociated\n\nChange-Id: I450f896f29051921b011e1643f1a1e24ed82ac08\n'}, {'number': 2, 'created': '2014-12-10 17:47:14.000000000', 'files': ['tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/2bc293ee97272768876995a6621d58112bd61ad4', 'message': 'Use assertIn to check for subnet membership\n\nFor dual stacked networks, the gateway port will have multiple subnets\nassociated\n\nChange-Id: I450f896f29051921b011e1643f1a1e24ed82ac08\n'}]",1,140783,2bc293ee97272768876995a6621d58112bd61ad4,10,4,2,4656,,,0,"Use assertIn to check for subnet membership

For dual stacked networks, the gateway port will have multiple subnets
associated

Change-Id: I450f896f29051921b011e1643f1a1e24ed82ac08
",git fetch https://review.opendev.org/openstack/tempest refs/changes/83/140783/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_routers.py'],1,335463ad2309a577f4de4456c8e3eca79613b967,network_tests_refactor," self.assertIn(map(lambda x: x['subnet_id'], fixed_ips), public_subnet_id)"," self.assertEqual(fixed_ips[0]['subnet_id'], public_subnet_id)",2,1
openstack%2Foslo.log~master~Id1c195c2abf790aeaaf38a09bc06fca59e354206,openstack/oslo.log,master,Id1c195c2abf790aeaaf38a09bc06fca59e354206,Updated from global requirements,MERGED,2014-12-11 07:19:29.000000000,2014-12-12 15:29:11.000000000,2014-12-12 15:29:11.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 07:19:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/3071f0debc4284c28ca8fc471179231c252754eb', 'message': 'Updated from global requirements\n\nChange-Id: Id1c195c2abf790aeaaf38a09bc06fca59e354206\n'}]",0,140949,3071f0debc4284c28ca8fc471179231c252754eb,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: Id1c195c2abf790aeaaf38a09bc06fca59e354206
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/49/140949/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3071f0debc4284c28ca8fc471179231c252754eb,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fnova~master~I4f34c9c795f99e56dd6ca27be237e8c2252f782e,openstack/nova,master,I4f34c9c795f99e56dd6ca27be237e8c2252f782e,libvirt: Convert more tests to use instance objects,MERGED,2014-12-10 15:06:18.000000000,2014-12-12 15:20:39.000000000,2014-12-12 01:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/63f45b9a22b1da281517baabec16de81bcb6f550', 'message': 'libvirt: Convert more tests to use instance objects\n\nConvert a bunch more test cases over to use objects.Instance\ninstead of a dict()\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I4f34c9c795f99e56dd6ca27be237e8c2252f782e\n'}, {'number': 2, 'created': '2014-12-10 17:09:31.000000000', 'files': ['nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a7a4ab382c4199e87566c73ef65e3c368cb09a6b', 'message': 'libvirt: Convert more tests to use instance objects\n\nConvert a bunch more test cases over to use objects.Instance\ninstead of a dict()\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: I4f34c9c795f99e56dd6ca27be237e8c2252f782e\n'}]",1,140712,a7a4ab382c4199e87566c73ef65e3c368cb09a6b,20,10,2,1779,,,0,"libvirt: Convert more tests to use instance objects

Convert a bunch more test cases over to use objects.Instance
instead of a dict()

Blueprint: libvirt-driver-class-refactor
Change-Id: I4f34c9c795f99e56dd6ca27be237e8c2252f782e
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/140712/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/libvirt/test_driver.py'],1,63f45b9a22b1da281517baabec16de81bcb6f550,bp/libvirt-driver-class-refactor," instance = objects.Instance(**self.test_instance) instance, mode=mode) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) instance = objects.Instance(**self.test_instance) actual = conn.get_diagnostics(instance) instance.launched_at = lt actual = conn.get_instance_diagnostics(instance) instance = objects.Instance(**self.test_instance) actual = conn.get_diagnostics(instance) instance.launched_at = lt actual = conn.get_instance_diagnostics(instance) instance = objects.Instance(**self.test_instance) actual = conn.get_diagnostics(instance) instance.launched_at = lt actual = conn.get_instance_diagnostics(instance) instance = objects.Instance(**self.test_instance) actual = conn.get_diagnostics(instance) instance.launched_at = lt actual = conn.get_instance_diagnostics(instance) instance = objects.Instance(**self.test_instance) actual = conn.get_diagnostics(instance) instance.launched_at = lt actual = conn.get_instance_diagnostics(instance)"," {'name': 'fake_instance'}, mode=mode) instance = {'name': 'test', 'uuid': 'uuid'} instance = {'name': 'test', 'uuid': 'uuid'} instance = {'name': 'test', 'uuid': 'uuid'} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {""name"": ""instancename"", ""id"": ""instanceid"", ""uuid"": ""875a8070-d0b9-4949-8b31-104d125c9a64""} instance = {'name': 'test'} actual = conn.get_diagnostics({""name"": ""testvirt""}) actual = conn.get_instance_diagnostics({""name"": ""testvirt"", ""launched_at"": lt}) actual = conn.get_diagnostics({""name"": ""testvirt""}) actual = conn.get_instance_diagnostics({""name"": ""testvirt"", ""launched_at"": lt}) actual = conn.get_diagnostics({""name"": ""testvirt""}) actual = conn.get_instance_diagnostics({""name"": ""testvirt"", ""launched_at"": lt}) actual = conn.get_diagnostics({""name"": ""testvirt""}) actual = conn.get_instance_diagnostics({""name"": ""testvirt"", ""launched_at"": lt}) actual = conn.get_diagnostics({""name"": ""testvirt""}) actual = conn.get_instance_diagnostics({""name"": ""testvirt"", ""launched_at"": lt})",34,36
openstack%2Fbarbican~master~I4c22176468836fd8d55644689cbd95aff9a84500,openstack/barbican,master,I4c22176468836fd8d55644689cbd95aff9a84500,Add I18n-related unit tests (Part 1),MERGED,2014-12-10 18:37:25.000000000,2014-12-12 15:18:47.000000000,2014-12-12 15:18:46.000000000,"[{'_account_id': 3}, {'_account_id': 994}, {'_account_id': 7136}, {'_account_id': 7262}, {'_account_id': 7789}, {'_account_id': 9234}, {'_account_id': 11970}]","[{'number': 1, 'created': '2014-12-10 18:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/6e39c1fc3e8e1d311c5fa5f46145361123d7a0a9', 'message': ""Add I18n-related unit tests (Part 1)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database test case class, to verify that just\nadding this component doesn't cause the IOError broken pipe error seen\nin the overall CR.\n\nChange-Id: I4c22176468836fd8d55644689cbd95aff9a84500\n""}, {'number': 2, 'created': '2014-12-10 18:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/c6150edcde1d56fb7bd588a718f2f2cd3f9ca7a0', 'message': ""Add I18n-related unit tests (Part 1)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database test case class, to verify that just\nadding this component doesn't cause the IOError broken pipe error seen\nin the overall CR.\n\nChange-Id: I4c22176468836fd8d55644689cbd95aff9a84500\n""}, {'number': 3, 'created': '2014-12-10 20:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/b1ba9038d98f25ca6644e153a33190bee319769e', 'message': ""Add I18n-related unit tests (Part 1)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database test case class, to verify that just\nadding this component doesn't cause the IOError broken pipe error seen\nin the overall CR.\n\nChange-Id: I4c22176468836fd8d55644689cbd95aff9a84500\n""}, {'number': 4, 'created': '2014-12-10 20:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/barbican/commit/09cc65e5c4b4d71d89a0b2f49eb447819db500d3', 'message': ""Add I18n-related unit tests (Part 1)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database test case class, to verify that just\nadding this component doesn't cause the IOError broken pipe error seen\nin the overall CR.\n\nChange-Id: I4c22176468836fd8d55644689cbd95aff9a84500\n""}, {'number': 5, 'created': '2014-12-12 04:12:04.000000000', 'files': ['barbican/tests/database_utils.py', 'barbican/model/repositories.py'], 'web_link': 'https://opendev.org/openstack/barbican/commit/6126a7ba40aba5b62520accfd786fcb8be69e7d4', 'message': ""Add I18n-related unit tests (Part 1)\n\nThis CR is the first of several dependent CRs that break up the overall\ntests added via this abandoned CR:\nhttps://review.openstack.org/#/c/139894\nThis CR adds the new database test case class, to verify that just\nadding this component doesn't cause the IOError broken pipe error seen\nin the overall CR.\n\nChange-Id: I4c22176468836fd8d55644689cbd95aff9a84500\n""}]",3,140800,6126a7ba40aba5b62520accfd786fcb8be69e7d4,19,7,5,7789,,,0,"Add I18n-related unit tests (Part 1)

This CR is the first of several dependent CRs that break up the overall
tests added via this abandoned CR:
https://review.openstack.org/#/c/139894
This CR adds the new database test case class, to verify that just
adding this component doesn't cause the IOError broken pipe error seen
in the overall CR.

Change-Id: I4c22176468836fd8d55644689cbd95aff9a84500
",git fetch https://review.opendev.org/openstack/barbican refs/changes/00/140800/3 && git format-patch -1 --stdout FETCH_HEAD,"['barbican/model/repositories.py', 'barbican/tests/utils.py']",2,6e39c1fc3e8e1d311c5fa5f46145361123d7a0a9,add-i18n-related-unit-tests-make-repos-package,"from barbican.model import repositories class RepositoryTestCase(BaseTestCase): """"""Base test case class for in-memory database unit tests. Database oriented unit tests should *not* modify the global state in the barbican/model/repositories.py module, as this can lead to hard to debug errors. Instead only utilize methods in this fixture. """""" def setUp(self): super(RepositoryTestCase, self).setUp() # Ensure we are using in-memory SQLite database, and creating tables. repositories.CONF.set_override(""sql_connection"", ""sqlite:///:memory:"") repositories.CONF.set_override(""db_auto_create"", True) repositories.CONF.set_override(""debug"", True) # Ensure the connection is completely closed, so any previous in-memory # database can be removed prior to starting the next test run. repositories.hard_reset() repositories.start() self.addCleanup(self._cleanup) # lambda: repositories.clear()) def _cleanup(self): repositories.clear() ",,37,0
openstack%2Fglance~master~I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b,openstack/glance,master,I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b,Add ModelSMigrationSync classes,MERGED,2014-07-30 15:37:21.000000000,2014-12-12 15:15:44.000000000,2014-12-12 15:15:43.000000000,"[{'_account_id': 3}, {'_account_id': 6159}, {'_account_id': 6484}, {'_account_id': 6549}, {'_account_id': 6849}, {'_account_id': 7491}, {'_account_id': 7763}, {'_account_id': 8127}, {'_account_id': 8759}, {'_account_id': 8871}, {'_account_id': 9236}, {'_account_id': 12363}, {'_account_id': 12395}]","[{'number': 1, 'created': '2014-07-30 15:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/564445318ccfaa8e473fbfc748cefbd6c4ddb31b', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 2, 'created': '2014-07-31 11:16:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/0e6a5ce4137b96c397c16d21b355ecf48b8c72c7', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 3, 'created': '2014-07-31 15:45:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/99db989d03beb7834acc9adfaf878b59a176ef91', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 4, 'created': '2014-08-13 14:53:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5505f34deb208c74f498c165087195cbfe88ab4e', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 5, 'created': '2014-08-13 16:17:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4143824957e07ca53dbbcbb2ef11bac7fe23edce', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 6, 'created': '2014-08-21 13:22:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/991f8a59e07900936838840cd19aa3fa2fa94580', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 7, 'created': '2014-08-21 13:32:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4208e7080f6186a615f1e5a17f6d9f9dd83145d5', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 8, 'created': '2014-08-26 10:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9aae65461c2d19637c0b5e9bec8f2a798bf26138', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 9, 'created': '2014-08-26 13:17:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/15ed9af6878910c48e756cbfe094963f99ea9b9e', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 10, 'created': '2014-08-27 13:28:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5bcbe8bf887e43604c0164f6335ccbc86c6a0ea6', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 11, 'created': '2014-08-27 14:15:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/18cfefc715c2c931d0553d6af421030bc64ecc10', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 12, 'created': '2014-08-27 14:30:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3bba7e33e02c3bca230b54b80906897b3dac6957', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 13, 'created': '2014-08-28 16:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f5d4d383cc4a806218ccd6636e4ee76ad641719b', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 14, 'created': '2014-08-29 10:08:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3387825028ccd1f5c1f1b75892c38f671fa5e0a1', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 15, 'created': '2014-09-01 14:31:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/14b15bd07df97c24f115b6d2e19d893d70a79e9b', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 16, 'created': '2014-09-02 10:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8b1b2a85c70e0f1315b924d025ec5c027744a8b5', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 17, 'created': '2014-09-04 11:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fe35ed3fface1995b651845305aea319a4e80411', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nCloses-bug: 1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 18, 'created': '2014-09-04 11:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/87f3f08ea0f1f60728cd546375d0a10dfd3fb246', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nCloses-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 19, 'created': '2014-09-08 17:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d37f308400d10ba0ab9e51c3b6b754564da1b577', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 20, 'created': '2014-09-15 12:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/178b92f5b784e139225143ed3e0cfa3158a0ff6d', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 21, 'created': '2014-10-03 12:25:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a5dc71cd2d22ce675410e4ed0ea6df4897bebb99', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 22, 'created': '2014-10-06 16:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/02febb7df2f06e12702de16a4b052de0b9fd09cd', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 23, 'created': '2014-10-07 12:08:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1758f63039b181b2c0d5b061cec1fc0931a61ae5', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 24, 'created': '2014-10-09 12:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a3accfbcb25e984c43c70789d79a1ba2a19665b6', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 25, 'created': '2014-10-10 11:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b133fa98b9e757d80865deb12373602dee03d2fa', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 26, 'created': '2014-11-20 14:21:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7207323ed81529768f9468c7d79148a9a672ae28', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 27, 'created': '2014-11-24 12:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/afd6c6c9a96709f6487264fc9f14c2be5da9a3fc', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 28, 'created': '2014-11-25 12:47:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cde30f5a1215209296d272bc33041162d45d07be', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 29, 'created': '2014-11-25 13:23:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d0854e536fc8848b2eed69a1c74682c7726c9be8', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}, {'number': 30, 'created': '2014-11-25 16:38:56.000000000', 'files': ['glance/tests/unit/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/e90f184143c8d69d826e7763a2503bc480927a5b', 'message': 'Add ModelSMigrationSync classes\n\nAdd classes for testing correspondence between migration scripts\nand metadata.\nWe need oslotest in test-requirements due to bug#1356425\n\nPartial-Bug: #1365436\nChange-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b\n'}]",14,110683,e90f184143c8d69d826e7763a2503bc480927a5b,125,13,30,12363,,,0,"Add ModelSMigrationSync classes

Add classes for testing correspondence between migration scripts
and metadata.
We need oslotest in test-requirements due to bug#1356425

Partial-Bug: #1365436
Change-Id: I0db68ea3557dd9d214ea50ff7c96de1a47a58d4b
",git fetch https://review.opendev.org/openstack/glance refs/changes/83/110683/12 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/test_migrations.py', 'requirements.txt', 'glance/db/migration.py']",3,564445318ccfaa8e473fbfc748cefbd6c4ddb31b,bug/1365436,"from oslo.config import cfg from oslo import db db.options.set_defaults(cfg.CONF) def db_sync(version=None, init_version=0, engine=None): if engine is None: engine = db_api.get_engine() return IMPL.db_sync(engine=engine,","def db_sync(version=None, init_version=0): return IMPL.db_sync(engine=db_api.get_engine(),",45,2
openstack%2Fsahara~master~I41e76ce9e4d50883619b1336a99cca0ec42fffeb,openstack/sahara,master,I41e76ce9e4d50883619b1336a99cca0ec42fffeb,Update oslo-incubator threadgroup,MERGED,2014-12-04 18:42:05.000000000,2014-12-12 15:12:01.000000000,2014-12-12 12:04:16.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 8871}, {'_account_id': 10670}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/65e2ddf416a78700070c75934a7356f4b14e9496', 'message': ""Update oslo-incubator threadgroup\n\nChanges -\n * threadgroup: don't log GreenletExit\n\nChange-Id: I41e76ce9e4d50883619b1336a99cca0ec42fffeb\n""}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9f805cc2a9cb19d57d865d9f078bf6ff6f8f4da1', 'message': ""Update oslo-incubator threadgroup\n\nChanges -\n * threadgroup: don't log GreenletExit\n\nChange-Id: I41e76ce9e4d50883619b1336a99cca0ec42fffeb\n""}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['sahara/openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/77354aed8e608fa8f975f4c7ca9563cc7ac3c5c6', 'message': ""Update oslo-incubator threadgroup\n\nChanges -\n * threadgroup: don't log GreenletExit\n\nChange-Id: I41e76ce9e4d50883619b1336a99cca0ec42fffeb\n""}]",0,139150,77354aed8e608fa8f975f4c7ca9563cc7ac3c5c6,28,10,3,7555,,,0,"Update oslo-incubator threadgroup

Changes -
 * threadgroup: don't log GreenletExit

Change-Id: I41e76ce9e4d50883619b1336a99cca0ec42fffeb
",git fetch https://review.opendev.org/openstack/sahara refs/changes/50/139150/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/threadgroup.py'],1,65e2ddf416a78700070c75934a7356f4b14e9496,, except eventlet.greenlet.GreenletExit: pass,,2,0
openstack%2Fironic-inspector~master~Ib134d9483a29f961e4472c0c007405caa0fbc19f,openstack/ironic-inspector,master,Ib134d9483a29f961e4472c0c007405caa0fbc19f,Review and fix logging messages,MERGED,2014-12-12 13:13:22.000000000,2014-12-12 15:03:02.000000000,2014-12-12 15:03:01.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-12 13:13:22.000000000', 'files': ['ironic_discoverd/process.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/firewall.py', 'ironic_discoverd/node_cache.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/bdaf0f4d15e13bb16688a26ecafb639a78fd4ef8', 'message': 'Review and fix logging messages\n\nFixes levels and wording for many messages.\nAlso adds a couple more helpful messages.\n\nChange-Id: Ib134d9483a29f961e4472c0c007405caa0fbc19f\nCloses-Bug: #1401585\n'}]",9,141366,bdaf0f4d15e13bb16688a26ecafb639a78fd4ef8,11,3,1,10239,,,0,"Review and fix logging messages

Fixes levels and wording for many messages.
Also adds a couple more helpful messages.

Change-Id: Ib134d9483a29f961e4472c0c007405caa0fbc19f
Closes-Bug: #1401585
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/66/141366/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/process.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/main.py', 'ironic_discoverd/firewall.py', 'ironic_discoverd/node_cache.py']",5,bdaf0f4d15e13bb16688a26ecafb639a78fd4ef8,bug/1401585," except sqlite3.IntegrityError as exc: LOG.error('Database integrity error %s, some or all of ' '%s\'s %s seem to be on discovery already', exc, name, value) LOG.debug('Empty value for attribute %s', name) LOG.debug('Trying to use %s of value %s for node look up' % (name, value))"," except sqlite3.IntegrityError: LOG.warning('Empty value for attribute %s', name) LOG.debug('Trying to use %s %s for discovery' % (name, value)) LOG.debug('Timeout is disabled')",32,18
openstack%2Fnova~master~Ib2257ac97c533a8a0d7f45994d21a67d08444e19,openstack/nova,master,Ib2257ac97c533a8a0d7f45994d21a67d08444e19,virt: Convert more tests to use instance objects,MERGED,2014-12-10 15:06:18.000000000,2014-12-12 15:00:50.000000000,2014-12-11 19:16:23.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4e9586797f664cfdb8a6718b17e1ca6b8d626d88', 'message': 'virt: Convert more tests to use instance objects\n\nUpdate a couple of methods in test_virt_drivers so that they\nuse instance objects instead of dicts\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ib2257ac97c533a8a0d7f45994d21a67d08444e19\n'}, {'number': 2, 'created': '2014-12-10 17:09:30.000000000', 'files': ['nova/tests/unit/virt/test_virt_drivers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ba1ab66ce69333b2e005e7c1abc5e6d319a2738b', 'message': 'virt: Convert more tests to use instance objects\n\nUpdate a couple of methods in test_virt_drivers so that they\nuse instance objects instead of dicts\n\nBlueprint: libvirt-driver-class-refactor\nChange-Id: Ib2257ac97c533a8a0d7f45994d21a67d08444e19\n'}]",0,140711,ba1ab66ce69333b2e005e7c1abc5e6d319a2738b,19,10,2,1779,,,0,"virt: Convert more tests to use instance objects

Update a couple of methods in test_virt_drivers so that they
use instance objects instead of dicts

Blueprint: libvirt-driver-class-refactor
Change-Id: Ib2257ac97c533a8a0d7f45994d21a67d08444e19
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/140711/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/virt/test_virt_drivers.py'],1,4e9586797f664cfdb8a6718b17e1ca6b8d626d88,bp/libvirt-driver-class-refactor, fake_instance = test_utils.get_test_instance(obj=True) fake_instance = test_utils.get_test_instance(obj=True) fake_instance)," fake_instance = {'id': 42, 'name': 'I just made this up!', 'uuid': 'bda5fb9e-b347-40e8-8256-42397848cb00'} {'name': 'I just made this name up'})",3,3
openstack%2Fpuppet-vswitch~master~I26d53c832e651668b40a70010bb994e5d2ec10da,openstack/puppet-vswitch,master,I26d53c832e651668b40a70010bb994e5d2ec10da,Adds filtering for BONDING (LACP),MERGED,2014-12-08 04:44:39.000000000,2014-12-12 14:49:41.000000000,2014-12-12 14:49:41.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 5241}, {'_account_id': 6525}, {'_account_id': 7065}, {'_account_id': 7155}, {'_account_id': 7462}, {'_account_id': 10540}, {'_account_id': 11166}, {'_account_id': 11491}]","[{'number': 1, 'created': '2014-12-08 04:44:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/e2d6c7f5ab692ad13a6f3c524152ab8c8063c999', 'message': 'Adds filtering for BONDING (LACP)\n\n- Separated ifcfg file capture from cleaning filter\n- Fixed REGEX when ifcfg file used as template\n\nRHBZ#1165185\n\nChange-Id: I26d53c832e651668b40a70010bb994e5d2ec10da\n'}, {'number': 2, 'created': '2014-12-08 11:33:43.000000000', 'files': ['lib/puppet/provider/vs_port/ovs_redhat.rb'], 'web_link': 'https://opendev.org/openstack/puppet-vswitch/commit/fd49af3de8ab156e9680d42b6309c79d4e68e9cb', 'message': 'Adds filtering for BONDING (LACP)\n\n- Separated ifcfg file capture from cleaning filter\n- Fixed REGEX when ifcfg file used as template\n\nRHBZ#1165185\n\nChange-Id: I26d53c832e651668b40a70010bb994e5d2ec10da\n'}]",2,139905,fd49af3de8ab156e9680d42b6309c79d4e68e9cb,14,10,2,6525,,,0,"Adds filtering for BONDING (LACP)

- Separated ifcfg file capture from cleaning filter
- Fixed REGEX when ifcfg file used as template

RHBZ#1165185

Change-Id: I26d53c832e651668b40a70010bb994e5d2ec10da
",git fetch https://review.opendev.org/openstack/puppet-vswitch refs/changes/05/139905/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/puppet/provider/vs_port/ovs_redhat.rb'],1,e2d6c7f5ab692ad13a6f3c524152ab8c8063c999,bonding," template = cleared(from_str(File.read(BASE + @resource[:interface]))) if bonding? port.set('BONDING_MASTER' => 'yes') config = from_str(File.read(BASE + @resource[:interface])) port.set('BONDING_OPTS' => config['BONDING_OPTS']) if config.has_key?('BONDING_OPTS') end def bonding? if File.read('/sys/class/net/bond0/operstate') =~ /up/ return true else return false end rescue Errno::ENOENT return false end if m = line.match(/^([A-Za-z_]*)=(.*)$/) def cleared(data) data.each do |key, value| case key when /vlan/i data.delete(key) when /bonding/i data.delete(key) end end end ", template = from_str(File.read(BASE + @resource[:interface])) if m = line.match(/^(.*)=(.*)$/) items.delete('VLAN') if items.has_key?('VLAN'),30,3
openstack%2Foslo.messaging~master~I55eed75a9d6a8375823480220b8312eb255e417a,openstack/oslo.messaging,master,I55eed75a9d6a8375823480220b8312eb255e417a,Updated from global requirements,MERGED,2014-12-11 07:19:32.000000000,2014-12-12 14:48:52.000000000,2014-12-12 14:48:50.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 07:19:32.000000000', 'files': ['requirements.txt', 'requirements-py3.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/709c401cb8ff8c3fa155bc5e8b7ca2e4d17f3273', 'message': 'Updated from global requirements\n\nChange-Id: I55eed75a9d6a8375823480220b8312eb255e417a\n'}]",0,140950,709c401cb8ff8c3fa155bc5e8b7ca2e4d17f3273,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I55eed75a9d6a8375823480220b8312eb255e417a
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/50/140950/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'requirements-py3.txt']",2,709c401cb8ff8c3fa155bc5e8b7ca2e4d17f3273,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,2,2
openstack%2Foslo.log~master~I6c155370dbd01fe4748d5137bdf288e8d3e1a67e,openstack/oslo.log,master,I6c155370dbd01fe4748d5137bdf288e8d3e1a67e,Add pbr to installation requirements,MERGED,2014-10-24 13:33:55.000000000,2014-12-12 14:48:12.000000000,2014-12-12 14:48:10.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 5638}, {'_account_id': 6928}]","[{'number': 1, 'created': '2014-10-24 13:33:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/1d74e386419a5b56ea44169f3d39c81f0d52d16a', 'message': 'Add pbr to installation requirements\n\nAdd pbr to the list of installation requirements so that it is installed\nvia pip before this library is installed, instead of with easy_install.\nThis avoids issues like Bug #1384919, and ensures that projects that use\nthis library as a dependency are properly installed.\n\nChange-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e\n'}]",0,130785,1d74e386419a5b56ea44169f3d39c81f0d52d16a,10,5,1,2472,,,0,"Add pbr to installation requirements

Add pbr to the list of installation requirements so that it is installed
via pip before this library is installed, instead of with easy_install.
This avoids issues like Bug #1384919, and ensures that projects that use
this library as a dependency are properly installed.

Change-Id: I6c155370dbd01fe4748d5137bdf288e8d3e1a67e
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/85/130785/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1d74e386419a5b56ea44169f3d39c81f0d52d16a,bug/1384919,"pbr>=0.6,!=0.7,<1.0",,1,0
openstack%2Fnova~master~Ie43ebea3ecabd0dd11a5c341bf2310a00f143031,openstack/nova,master,Ie43ebea3ecabd0dd11a5c341bf2310a00f143031,virt: delete unused 'interface_stats' method,MERGED,2014-12-08 17:47:20.000000000,2014-12-12 14:47:08.000000000,2014-12-11 19:12:04.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 7730}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-08 17:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b4685081c5d2a49e5d00a55996fa806c58daa567', 'message': ""virt: delete unused 'interface_stats' method\n\nThe only use of the virt driver 'interface_stats' method was\nremoved 3+ years ago by\n\n  commit 07646e85841a4f7c81e80254ac63715bece2aadd\n  Author: Brian Waldon <brian.waldon@rackspace.com>\n  Date:   Tue Aug 2 10:09:58 2011 -0400\n\n    removing compute monitor\n\nChange-Id: Ie43ebea3ecabd0dd11a5c341bf2310a00f143031\n""}, {'number': 2, 'created': '2014-12-10 15:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/950827e49089a692db52b5faa5ac24d70e8949d0', 'message': ""virt: delete unused 'interface_stats' method\n\nThe only use of the virt driver 'interface_stats' method was\nremoved 3+ years ago by\n\n  commit 07646e85841a4f7c81e80254ac63715bece2aadd\n  Author: Brian Waldon <brian.waldon@rackspace.com>\n  Date:   Tue Aug 2 10:09:58 2011 -0400\n\n    removing compute monitor\n\nChange-Id: Ie43ebea3ecabd0dd11a5c341bf2310a00f143031\n""}, {'number': 3, 'created': '2014-12-10 17:09:30.000000000', 'files': ['nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/virt/driver.py', 'nova/tests/unit/virt/test_virt_drivers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3d9768e936d425b4fb33e8fd4e41d5e1533daf4c', 'message': ""virt: delete unused 'interface_stats' method\n\nThe only use of the virt driver 'interface_stats' method was\nremoved 3+ years ago by\n\n  commit 07646e85841a4f7c81e80254ac63715bece2aadd\n  Author: Brian Waldon <brian.waldon@rackspace.com>\n  Date:   Tue Aug 2 10:09:58 2011 -0400\n\n    removing compute monitor\n\nChange-Id: Ie43ebea3ecabd0dd11a5c341bf2310a00f143031\n""}]",0,140099,3d9768e936d425b4fb33e8fd4e41d5e1533daf4c,24,10,3,1779,,,0,"virt: delete unused 'interface_stats' method

The only use of the virt driver 'interface_stats' method was
removed 3+ years ago by

  commit 07646e85841a4f7c81e80254ac63715bece2aadd
  Author: Brian Waldon <brian.waldon@rackspace.com>
  Date:   Tue Aug 2 10:09:58 2011 -0400

    removing compute monitor

Change-Id: Ie43ebea3ecabd0dd11a5c341bf2310a00f143031
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/140099/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/libvirt/driver.py', 'nova/virt/fake.py', 'nova/virt/driver.py', 'nova/tests/unit/virt/test_virt_drivers.py']",4,b4685081c5d2a49e5d00a55996fa806c58daa567,bp/libvirt-driver-class-refactor,," def test_interface_stats(self): instance_ref, network_info = self._get_running_instance() stats = self.connection.interface_stats(instance_ref['name'], 'someid') self.assertEqual(len(stats), 8) @catch_notimplementederror",0,33
openstack%2Ffuel-main~master~I7641f3144dca428a039d4ae71aa1d1918b8da28a,openstack/fuel-main,master,I7641f3144dca428a039d4ae71aa1d1918b8da28a,Vlan+vCenter test,ABANDONED,2014-12-12 11:09:18.000000000,2014-12-12 14:43:46.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 10068}, {'_account_id': 13306}]","[{'number': 1, 'created': '2014-12-12 11:09:18.000000000', 'files': ['fuelweb_test/tests/test_alrem.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/cf05e8887fe9559505a1554ecbc871a08f527257', 'message': 'Vlan+vCenter test\n\nChange-Id: I7641f3144dca428a039d4ae71aa1d1918b8da28a\n'}]",0,141330,cf05e8887fe9559505a1554ecbc871a08f527257,7,4,1,13306,,,0,"Vlan+vCenter test

Change-Id: I7641f3144dca428a039d4ae71aa1d1918b8da28a
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/30/141330/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_alrem.py'],1,cf05e8887fe9559505a1554ecbc871a08f527257,okosse,"# Copyright 2014 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import time from proboscis.asserts import assert_true from proboscis import test from devops.helpers.helpers import wait from fuelweb_test import settings from fuelweb_test.helpers import os_actions from fuelweb_test.helpers.decorators import log_snapshot_on_error from fuelweb_test.tests.base_test_case import SetupEnvironment from fuelweb_test.tests.base_test_case import TestBasic from fuelweb_test import logger @test(groups=[""alrem""]) class alremVcenterDeploy(TestBasic): @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_vmdk_1_6"", ""vcenter_multiple_cluster6""]) @log_snapshot_on_error def vcenter_vmdk_1(self): """"""Deploy cluster with controller node only and test VMDK driver support feature Scenario: 1. Create cluster 2. Add 2 nodes with controller and cinder roles 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_SIMPLE, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['cinder'], 'slave-03': ['cinder']} ) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) @test(depends_on=[SetupEnvironment.prepare_slaves_1], groups=[""vcenter_vmdk_2"", ""vcenter_multiple_cluster6""]) @log_snapshot_on_error def vcenter_vmdk_2(self): """"""Deploy cluster with controller node only and test VMDK driver support feature Scenario: 1. Create cluster 2. Add 2 nodes with controller and cinder roles 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_1_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_SIMPLE, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller', 'cinder'], } ) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_vmdk_3"", ""vcenter_multiple_cluster6""]) @log_snapshot_on_error def vcenter_vmdk_3(self): """"""Deploy cluster with controller node only and test VMDK driver support feature Scenario: 1. Create cluster 2. Add 2 nodes with controller and cinder roles 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_SIMPLE, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller', 'cinder'], 'slave-02': ['cinder'], } ) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_vlan""]) @log_snapshot_on_error def vcenter_vlan(self): """"""Deploy cluster with controller node only and test VMDK driver support feature Scenario: 1. Create cluster 2. Add 2 nodes with controller and cinder roles 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_SIMPLE, settings={ 'use_vcenter': True, 'volumes_vmdk': True, 'volumes_lvm': False, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter' } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['cinder'], 'slave-03': ['cinder'], } ) # Deploy cluster ''' {""networks"":[{""name"":""public"",""ip_ranges"":[[""172.16.0.2"",""172.16.0.127""]], ""id"":2, ""meta"":{""name"":""public"", ""notation"":""ip_ranges"", ""render_type"":null, ""map_priority"":1, ""assign_vip"":true, ""use_gateway"":true, ""vlan_start"":null, ""render_addr_mask"":""public"", ""cidr"":""172.16.0.0/24"", ""configurable"":true, ""gateway"":""172.16.0.1"", ""ip_range"":[""172.16.0.2"",""172.16.0.127""]}, ""vlan_start"":null, ""cidr"":""172.16.0.0/24"", ""group_id"":1, ""gateway"":""172.16.0.1""}, {""name"":""management"", ""ip_ranges"":[[""192.168.0.1"",""192.168.0.254""]], ""id"":3, ""meta"":{""name"":""management"", ""notation"":""cidr"", ""render_type"":""cidr"", ""map_priority"":2, ""assign_vip"":true, ""use_gateway"":false, ""vlan_start"":101, ""render_addr_mask"":""internal"", ""cidr"":""192.168.0.0/24"", ""configurable"":true}, ""vlan_start"":101, ""cidr"":""192.168.0.0/24"", ""group_id"":1, ""gateway"":null}, {""name"":""storage"", ""ip_ranges"":[[""192.168.1.1"",""192.168.1.254""]], ""id"":4, ""meta"":{""name"":""storage"", ""notation"":""cidr"", ""render_type"":""cidr"", ""map_priority"":2, ""assign_vip"":false, ""use_gateway"":false, ""vlan_start"":102, ""render_addr_mask"":""storage"", ""cidr"":""192.168.1.0/24"", ""configurable"":true}, ""vlan_start"":102, ""cidr"":""192.168.1.0/24"", ""group_id"":1, ""gateway"":null}, {""name"":""fixed"", ""ip_ranges"":[], ""id"":5, ""meta"":{""ext_net_data"":[""fixed_networks_vlan_start"",""fixed_networks_amount""], ""name"":""fixed"", ""notation"":null, ""render_type"":null, ""map_priority"":2, ""assign_vip"":false, ""use_gateway"":false, ""vlan_start"":null, ""render_addr_mask"":null, ""configurable"":false}, ""vlan_start"":null, ""cidr"":null, ""group_id"":1, ""gateway"":null}, {""name"":""fuelweb_admin"", ""ip_ranges"":[[""10.108.0.3"",""10.108.0.254""]], ""id"":1, ""meta"":{""notation"":""ip_ranges"", ""render_type"":null, ""assign_vip"":false, ""configurable"":false, ""unmovable"":true, ""use_gateway"":true, ""render_addr_mask"":null, ""map_priority"":0}, ""vlan_start"":null, ""cidr"":""10.108.0.0/24"", ""group_id"":null, ""gateway"":null}], ""networking_parameters"":{""dns_nameservers"":[""8.8.4.4"",""8.8.8.8""], ""net_manager"":""VlanManager"", ""fixed_networks_vlan_start"":103, ""fixed_networks_cidr"":""10.0.0.0/16"", ""floating_ranges"":[[""172.16.0.128"",""172.16.0.254""]], ""fixed_network_size"":32,""fixed_networks_amount"":8}} ''' networking_parameters = {""dns_nameservers"":[""8.8.4.4"",""8.8.8.8""], ""net_manager"":""VlanManager"", ""fixed_networks_vlan_start"":103, ""fixed_networks_cidr"":""10.0.0.0/16"", ""floating_ranges"":[[""172.16.0.128"",""172.16.0.254""]], ""fixed_network_size"":32, ""fixed_networks_amount"":8 } self.fuel_web.client.update_network( cluster_id, networking_parameters=networking_parameters ) # self.fuel_web.update_vlan_network_fixed( # cluster_id, amount=8, network_size=32) self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) @test(depends_on=[SetupEnvironment.prepare_slaves_5], groups=[""vcenter_ha_vmdk_1_6"", ""vcenter_ha_vmdk_6"", ""vcenter_multiple_cluster6""]) @log_snapshot_on_error def vcenter_ha_vmdk_1(self): """"""Deploy cluster with 3 controller nodes and run osft Scenario: 1. Create cluster 2. Add 3 nodes with controller role 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_5_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_HA, settings={ 'use_vcenter': True, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter', 'volumes_vmdk': True, 'volumes_lvm': False, } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller'], 'slave-04': ['cinder'], 'slave-05': ['cinder'], } ) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) @test(depends_on=[SetupEnvironment.prepare_slaves_3], groups=[""vcenter_ha_vmdk_2_6"", ""vcenter_ha_vmdk_6"", ""vcenter_multiple_cluster6""]) @log_snapshot_on_error def vcenter_ha_vmdk_2(self): """"""Deploy cluster with 3 controller nodes and run osft Scenario: 1. Create cluster 2. Add 3 nodes with controller role 3. Deploy the cluster 4. Run osft """""" self.env.revert_snapshot(""ready_with_3_slaves"") # Configure cluster cluster_id = self.fuel_web.create_cluster( name=self.__class__.__name__, mode=settings.DEPLOYMENT_MODE_HA, settings={ 'use_vcenter': True, 'host_ip': settings.VCENTER_IP, 'vc_user': settings.VCENTER_USERNAME, 'vc_password': settings.VCENTER_PASSWORD, 'cluster': settings.VCENTER_CLUSTERS, 'tenant': 'vcenter', 'user': 'vcenter', 'password': 'vcenter', 'volumes_vmdk': True, 'volumes_lvm': False, } ) logger.info(""cluster is {0}"".format(cluster_id)) # Add nodes to roles self.fuel_web.update_nodes( cluster_id, {'slave-01': ['controller'], 'slave-02': ['controller'], 'slave-03': ['controller', 'cinder'], } ) # Deploy cluster self.fuel_web.deploy_cluster_wait(cluster_id) # Wait until nova-compute get information about clusters # Fix me. Later need to change sleep with wait function. time.sleep(60) self.fuel_web.verify_network(cluster_id) self.fuel_web.run_ostf( cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'], #should_fail=1, #failed_test_name=[('Launch instance, create snapshot,' # ' launch instance from snapshot'), # ] ) ",,493,0
openstack%2Fsahara~master~I87c39f2c2588114f1be7f375df33ec0c4c6f930b,openstack/sahara,master,I87c39f2c2588114f1be7f375df33ec0c4c6f930b,Update oslo-incubator policy,MERGED,2014-12-04 18:42:05.000000000,2014-12-12 14:40:41.000000000,2014-12-12 11:53:44.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7555}, {'_account_id': 7745}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-04 18:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e8bb500f04e5906462632c0233934938d25d7d49', 'message': ""Update oslo-incubator policy\n\nChanges -\n * Improving docstrings for policy API\n * Don't log missing policy.d as a warning\n * Add rule overwrite flag to Enforcer class\n * Fixed a problem with neutron http policy check\n * Expanding the help text for policy_dirs\n * policy: add a missing staticmethod declaration\n * Fixes nits in module policy\n * add list_opts to all modules with configuration options\n * Correct default rule name for policy.Enforcer\n * Minor fixes in policy module\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Allow dictionary lookup in credentials with dot notation\n * Fix typo to show correct log message\n\nChange-Id: I87c39f2c2588114f1be7f375df33ec0c4c6f930b\n""}, {'number': 2, 'created': '2014-12-04 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/b32002028578b7bc7b61955d7c0f709b7cbe597c', 'message': ""Update oslo-incubator policy\n\nChanges -\n * Improving docstrings for policy API\n * Don't log missing policy.d as a warning\n * Add rule overwrite flag to Enforcer class\n * Fixed a problem with neutron http policy check\n * Expanding the help text for policy_dirs\n * policy: add a missing staticmethod declaration\n * Fixes nits in module policy\n * add list_opts to all modules with configuration options\n * Correct default rule name for policy.Enforcer\n * Minor fixes in policy module\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Allow dictionary lookup in credentials with dot notation\n * Fix typo to show correct log message\n\nChange-Id: I87c39f2c2588114f1be7f375df33ec0c4c6f930b\n""}, {'number': 3, 'created': '2014-12-05 17:53:18.000000000', 'files': ['etc/sahara/sahara.conf.sample', 'sahara/openstack/common/policy.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/f638946f459b81aa96c1cc341c0ee2e9f2afce1a', 'message': ""Update oslo-incubator policy\n\nChanges -\n * Improving docstrings for policy API\n * Don't log missing policy.d as a warning\n * Add rule overwrite flag to Enforcer class\n * Fixed a problem with neutron http policy check\n * Expanding the help text for policy_dirs\n * policy: add a missing staticmethod declaration\n * Fixes nits in module policy\n * add list_opts to all modules with configuration options\n * Correct default rule name for policy.Enforcer\n * Minor fixes in policy module\n * Delete graduated serialization files\n * Remove code that moved to oslo.i18n\n * Allow dictionary lookup in credentials with dot notation\n * Fix typo to show correct log message\n\nChange-Id: I87c39f2c2588114f1be7f375df33ec0c4c6f930b\n""}]",0,139149,f638946f459b81aa96c1cc341c0ee2e9f2afce1a,28,10,3,7555,,,0,"Update oslo-incubator policy

Changes -
 * Improving docstrings for policy API
 * Don't log missing policy.d as a warning
 * Add rule overwrite flag to Enforcer class
 * Fixed a problem with neutron http policy check
 * Expanding the help text for policy_dirs
 * policy: add a missing staticmethod declaration
 * Fixes nits in module policy
 * add list_opts to all modules with configuration options
 * Correct default rule name for policy.Enforcer
 * Minor fixes in policy module
 * Delete graduated serialization files
 * Remove code that moved to oslo.i18n
 * Allow dictionary lookup in credentials with dot notation
 * Fix typo to show correct log message

Change-Id: I87c39f2c2588114f1be7f375df33ec0c4c6f930b
",git fetch https://review.opendev.org/openstack/sahara refs/changes/49/139149/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/openstack/common/policy.py'],1,e8bb500f04e5906462632c0233934938d25d7d49,,"# -*- coding: utf-8 -*- #combined as with an ""or"" conjunction. As an example, take the following rule, expressed in the list-of-lists representation::This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct class to perform that check:: +===========================================================================+ | TYPE | SYNTAX | +===========================================================================+ |User's Role | role:admin | +---------------------------------------------------------------------------+ |Rules already defined on policy | rule:admin_required | +---------------------------------------------------------------------------+ |Against URL's¹ | http://my-url.org/check | +---------------------------------------------------------------------------+ |User attributes² | project_id:%(target.project.id)s | +---------------------------------------------------------------------------+ |Strings | <variable>:'xpto2035abc' | | | 'myproject':<variable> | +---------------------------------------------------------------------------+ | | project_id:xpto2035abc | |Literals | domain_id:20 | | | True:%(user.enabled)s | +===========================================================================+ ¹URL checking must return 'True' to be valid ²User attributes (obtained through the token): user_id, domain_id or project_id Conjunction operators are available, allowing for more expressiveness in crafting policies. So, in the policy language, the previous check in list-of-lists becomes:: <some_value>:%(user.id)s <some_value>:%(target.role.name)simport copyfrom sahara.openstack.common._i18n import _, _LE, _LI 'stored. They can be relative to any directory ' 'in the search path defined by the config_dir ' 'option, or absolute paths. The file defined by ' 'policy_file must exist for these directories to ' 'be searched.')),def list_opts(): """"""Entry point for oslo.config-generator."""""" return [(None, copy.deepcopy(policy_opts))] :param overwrite: Whether to overwrite existing rules when reload rules from config file. default_rule=None, use_conf=True, overwrite=True): self.overwrite = overwrite :param force_reload: Whether to reload rules from config file. self._load_policy_file(self.policy_path, force_reload, overwrite=self.overwrite) LOG.info(_LI(""Can not find policy directory: %s""), path) @staticmethod def _walk_through_policy_directory(path, func, *args): if reloaded or not self.rules or not overwrite: self.set_rules(rules, overwrite=overwrite, use_conf=True) # Convert instances of object() in target temporarily to # empty dict to avoid circular reference detection # errors in jsonutils.dumps(). temp_target = copy.deepcopy(target) for key in target.keys(): element = target.get(key) if type(element) is object: temp_target[key] = {} data = {'target': jsonutils.dumps(temp_target),","combined as with an ""or"" conjunction. This is the original way of expressing policies, but there now exists a new way: the policy language. In the policy language, each check is specified the same way as in the list-of-lists representation: a simple ""a:b"" pair that is matched to the correct code to perform that check. However, conjunction operators are available, allowing for more expressiveness in crafting policies. As an example, take the following rule, expressed in the list-of-lists representation::In the policy language, this becomes::It is possible to perform policy checks on the following user attributes (obtained through the token): user_id, domain_id or project_id:: domain_id:<some_value> <some_value>:user.id <some_value>:target.role.name All these attributes (related to users, API calls, and context) can be checked against each other or against constants, be it literals (True, <a_number>) or strings.from sahara.openstack.common._i18n import _, _LE, _LW 'stored')), default_rule=None, use_conf=True): :param force_reload: Whether to overwrite current rules. self._load_policy_file(self.policy_path, force_reload) LOG.warn(_LW(""Can not find policy directories %s""), path) def _walk_through_policy_directory(self, path, func, *args): if reloaded or not self.rules: self.set_rules(rules, overwrite) data = {'target': jsonutils.dumps(target),",73,35
openstack%2Ffuel-web~master~I8f1a882790c865017778b81badd289ce086c7907,openstack/fuel-web,master,I8f1a882790c865017778b81badd289ce086c7907,Fixes textarea control,MERGED,2014-12-10 12:50:39.000000000,2014-12-12 14:40:36.000000000,2014-12-12 14:40:35.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-10 12:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5b0fdb59e0e609121c8b261ad9ac652e74481239', 'message': 'Fixes textarea control\n\nCloses-Bug: #1401093\n\nChange-Id: I8f1a882790c865017778b81badd289ce086c7907\n'}, {'number': 2, 'created': '2014-12-12 08:48:18.000000000', 'files': ['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3a2b1fcccc08e850e00e5cec52ea57a197932e8a', 'message': 'Fixes textarea control\n\nCloses-Bug: #1401093\n\nChange-Id: I8f1a882790c865017778b81badd289ce086c7907\n'}]",4,140664,3a2b1fcccc08e850e00e5cec52ea57a197932e8a,20,7,2,8766,,,0,"Fixes textarea control

Closes-Bug: #1401093

Change-Id: I8f1a882790c865017778b81badd289ce086c7907
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/64/140664/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/js/views/cluster_page_tabs/settings_tab.jsx'],1,5b0fdb59e0e609121c8b261ad9ac652e74481239,bug/1401093," composeOptions: function(setting) { if (setting.type != 'select') return; return _.map(setting.values, function(value, index) { children={this.composeOptions(setting)}"," composeOptions: function(values) { return _.map(values, function(value, index) { children={setting.type == 'select' && this.composeOptions(setting.values)}",4,3
openstack%2Fneutron-specs~master~Ia7315c102b35cbec137ffb8a0d36652e18069322,openstack/neutron-specs,master,Ia7315c102b35cbec137ffb8a0d36652e18069322,Reorganize unit test tree,MERGED,2014-12-09 04:00:24.000000000,2014-12-12 14:26:11.000000000,2014-12-12 14:26:10.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 2035}, {'_account_id': 2592}, {'_account_id': 5948}, {'_account_id': 6524}, {'_account_id': 8788}, {'_account_id': 8873}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-09 04:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2232b9bb9a11d53ce5f17aeee78fd949983ac56f', 'message': 'Reorganize unit test tree\n\nAdd spec for reoganizing the unit test tree for consistency.\n\nChange-Id: Ia7315c102b35cbec137ffb8a0d36652e18069322\nImplements: reorganize-unit-test-tree\n'}, {'number': 2, 'created': '2014-12-09 04:24:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6c2e884ecaebd3f47d27ec4bd80d1566e64b67e0', 'message': 'Reorganize unit test tree\n\nAdd spec for reoganizing the unit test tree for consistency.\n\nChange-Id: Ia7315c102b35cbec137ffb8a0d36652e18069322\nImplements: reorganize-unit-test-tree\n'}, {'number': 3, 'created': '2014-12-09 05:05:52.000000000', 'files': ['specs/kilo/reorganize-unit-test-tree.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/43f5cf5f52688a1dfdd46c0135fbf551cd76e1ab', 'message': 'Reorganize unit test tree\n\nAdd spec for reoganizing the unit test tree for consistency.\n\nChange-Id: Ia7315c102b35cbec137ffb8a0d36652e18069322\nImplements: reorganize-unit-test-tree\n'}]",5,140221,43f5cf5f52688a1dfdd46c0135fbf551cd76e1ab,20,12,3,2035,,,0,"Reorganize unit test tree

Add spec for reoganizing the unit test tree for consistency.

Change-Id: Ia7315c102b35cbec137ffb8a0d36652e18069322
Implements: reorganize-unit-test-tree
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/21/140221/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/reorganize-unit-test-tree.rst'],1,2232b9bb9a11d53ce5f17aeee78fd949983ac56f,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Example Spec - The title of your blueprint ========================================== https://blueprints.launchpad.net/neutron/+spec/reorganize-unit-test-tree Reorganize the structure of the unit test tree to be consistent with the structure of the code tree. Problem Description =================== There is no consistent organization of unit test modules (neutron/test/unit/*). There is no easy way to find the unit tests for a given module, making it challenging to determine whether code is well-tested. There are also no clear guideline as to where new tests should go, ensuring that the problem continues. Proposed Change =============== The module structure of the neutron/tests/unit subtree should be changed to mirror the structure of the code tree. * The path structure should be the same. This implies that modules under the path: neutron/[path] should have test modules in the following location neutron/tests/unit/[path] For example, test modules for 'neutron/scheduler' should have tests at 'neutron/tests/unit/scheduler'. * The name of the test modules should correspond to the name of the module under test, prefixed with 'test_'. For example, the module 'neutron/scheduler/dhcp_agent_scheduler.py' implies the test module 'neutron/tests/unit/scheduler/test_dhcp_agent_scheduler.py'. This requirement should be documented such that new changes follow this scheme. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- None Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None IPv6 Impact ----------- None Other Deployer Impact --------------------- None Developer Impact ---------------- Patch authors and reviewers will need to ensure that new changes maintain the consistent structuring of the unit test tree. Community Impact ---------------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: marun Work Items ---------- * Reorganize the test tree Dependencies ============ None Testing ======= None Tempest Tests ------------- None Functional Tests ---------------- None API Tests --------- None Documentation Impact ==================== None User Documentation ------------------ None Developer Documentation ----------------------- The required structure of new code should be documented in the in-tree developer documentation. References ========== [1] https://pytest.org/latest/goodpractises.html ",,164,0
openstack%2Fneutron-specs~master~I06f16c7f86a334f96df8abaa074085a6a59eef67,openstack/neutron-specs,master,I06f16c7f86a334f96df8abaa074085a6a59eef67,Citrix NetScaler LBaaS v2 driver,MERGED,2014-12-06 01:35:23.000000000,2014-12-12 14:25:12.000000000,2014-12-12 14:25:11.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 2592}, {'_account_id': 6951}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-12-06 01:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/1ca215742296f97f5a9dc180b3c6e0eb837a6c40', 'message': 'Citrix NetScaler LBaaS v2 driver\n\nChange-Id: I06f16c7f86a334f96df8abaa074085a6a59eef67\n'}, {'number': 2, 'created': '2014-12-06 08:15:19.000000000', 'files': ['specs/kilo/netscaler-lbaas-v2-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/8dd45a6cc152af8a07986fd55c7639b5e6a2690d', 'message': 'Citrix NetScaler LBaaS v2 driver\n\nChange-Id: I06f16c7f86a334f96df8abaa074085a6a59eef67\n'}]",0,139772,8dd45a6cc152af8a07986fd55c7639b5e6a2690d,11,8,2,9461,,,0,"Citrix NetScaler LBaaS v2 driver

Change-Id: I06f16c7f86a334f96df8abaa074085a6a59eef67
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/72/139772/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/netscaler-lbaas-v2-driver.rst'],1,1ca215742296f97f5a9dc180b3c6e0eb837a6c40,bp/netscaler-lbaas-v2-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Neutron LBaaS v2 driver for Citrix NetScaler appliances. ========================================== https://blueprints.launchpad.net/neutron/+spec/netscaler-lbaas-v2-driver Neutron LBaaS v2 driver for Citrix NetScaler appliances. Problem Description =================== Enable NetScaler appliances to be LBaaS backends. Proposed Change =============== The driver will implement the LBaaS v2 driver interface, as a shim to a middle ware NetScaler Control Center, ultimately configuring LB in NetScaler appliances. This implementation will be similar to the current v1 driver. This driver will include TLS and L7 functionality included in LBaaS v2. Data Model Impact ----------------- None REST API Impact --------------- None Security Impact --------------- Driver communicates with infrastructure hardware via https. Notifications Impact -------------------- None Other End User Impact --------------------- None Performance Impact ------------------ None IPv6 Impact ----------- Will support ipv6 at the same level as neutron lbaas. Other Deployer Impact --------------------- NetScaler Control Center virtual appliance must be deployed prior to using this driver. Developer Impact ---------------- None Community Impact ---------------- None Alternatives ------------ N/A Implementation ============== Assignee(s) ----------- Primary assignee: https://launchpad.net/~vijay-venkatachalam Work Items ---------- * Driver shim * Unit tests for shim * 3rd-party CI Dependencies ============ * LBaaS v2 Testing ======= Tempest Tests ------------- Third-party CI will run existing LB tempest tests with NetScaler Control Center as middleware and NetScaler VPX appliances as backends. Functional Tests ---------------- Third-party CI will run existing LB functional tests with NetScaler Control Center as middleware and NetScaler VPX appliances as backends. API Tests --------- Third-party CI will run existing LBaaS API tests with NetScaler Control Center as middleware and NetScaler VPX appliances as backends. Documentation Impact ==================== User Documentation ------------------ None Developer Documentation ----------------------- None References ========== * LBaaS v2 - https://review.openstack.org/#/c/138205/ ",,150,0
openstack%2Fironic-inspector~master~I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12,openstack/ironic-inspector,master,I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12,Retry on Conflict exceptions from Ironic,MERGED,2014-12-11 16:45:06.000000000,2014-12-12 14:16:31.000000000,2014-12-12 14:16:31.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-11 16:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/098dff42fa1d68d003856261ff6a787e0cbf91e7', 'message': 'Retry on Conflict exceptions from Ironic\n\nChange-Id: I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12\nCloses-Bug: #1401222\n'}, {'number': 2, 'created': '2014-12-12 12:23:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/e2bfdd053f6433c7b878332f4d841251fc5e7ed0', 'message': 'Retry on Conflict exceptions from Ironic\n\nRetried is everything, except get and list calls and port creation\n(for which Conflict is an expected exception).\n\nUnit tests are added for the most critical cases.\n\nChange-Id: I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12\nCloses-Bug: #1401222\n'}, {'number': 3, 'created': '2014-12-12 12:49:35.000000000', 'files': ['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/process.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/utils.py', 'ironic_discoverd/test/test_process.py'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/16bbe0e3a736a3f058e1ab67139e50e985ea8a2c', 'message': 'Retry on Conflict exceptions from Ironic\n\nRetried is everything, except get and list calls and port creation\n(for which Conflict is an expected exception).\n\nUnit tests are added for the most critical cases.\n\nChange-Id: I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12\nCloses-Bug: #1401222\n'}]",1,141096,16bbe0e3a736a3f058e1ab67139e50e985ea8a2c,13,3,3,10239,,,0,"Retry on Conflict exceptions from Ironic

Retried is everything, except get and list calls and port creation
(for which Conflict is an expected exception).

Unit tests are added for the most critical cases.

Change-Id: I92675c3d72a2f598c4e0d1ae8b0a4a4aa0a2ed12
Closes-Bug: #1401222
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/96/141096/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_discoverd/test/test_discover.py', 'ironic_discoverd/test/test_main.py', 'ironic_discoverd/process.py', 'ironic_discoverd/discover.py', 'ironic_discoverd/utils.py', 'ironic_discoverd/test/test_process.py']",6,098dff42fa1d68d003856261ff6a787e0cbf91e7,bug/1401222, self.cli.node.set_power_state.side_effect = exceptions.BadRequest(), self.cli.node.set_power_state.side_effect = exceptions.Conflict(),58,13
openstack%2Fdevstack-gate~master~I9660a0af74e8b43942f99a6f889213b457cd85db,openstack/devstack-gate,master,I9660a0af74e8b43942f99a6f889213b457cd85db,Add tooz to devstack-vm-gate-wrap.sh,MERGED,2014-12-11 20:26:50.000000000,2014-12-12 14:06:37.000000000,2014-12-12 14:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6786}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-12-11 20:26:50.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/d27273357824e015326194303aee6dcc0d1b8cbb', 'message': 'Add tooz to devstack-vm-gate-wrap.sh\n\nFix for gate-tempest-dsvm-neutron-src-tooz job failures.\n\nChange-Id: I9660a0af74e8b43942f99a6f889213b457cd85db\n'}]",0,141151,d27273357824e015326194303aee6dcc0d1b8cbb,12,5,1,5638,,,0,"Add tooz to devstack-vm-gate-wrap.sh

Fix for gate-tempest-dsvm-neutron-src-tooz job failures.

Change-Id: I9660a0af74e8b43942f99a6f889213b457cd85db
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/51/141151/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,d27273357824e015326194303aee6dcc0d1b8cbb,,"PROJECTS=""openstack/tooz $PROJECTS""",,1,0
openstack%2Fnova~master~I8ff717a05893d8e2adbdf0c17bd4b81677d15b8c,openstack/nova,master,I8ff717a05893d8e2adbdf0c17bd4b81677d15b8c,Inline _instance_extra_get_by_instance_uuid_query,MERGED,2014-12-10 16:46:56.000000000,2014-12-12 14:02:03.000000000,2014-12-10 20:24:54.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 16:46:56.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2d7a1e9aebb4f7ff6c445dba40673c96f50cc298', 'message': ""Inline _instance_extra_get_by_instance_uuid_query\n\nThis function didn't do anything special, and only had 1 caller.\n\nChange-Id: I8ff717a05893d8e2adbdf0c17bd4b81677d15b8c\n""}]",0,140767,2d7a1e9aebb4f7ff6c445dba40673c96f50cc298,12,7,1,9555,,,0,"Inline _instance_extra_get_by_instance_uuid_query

This function didn't do anything special, and only had 1 caller.

Change-Id: I8ff717a05893d8e2adbdf0c17bd4b81677d15b8c
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/140767/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,2d7a1e9aebb4f7ff6c445dba40673c96f50cc298,db/cleanup," query = model_query(context, models.InstanceExtra).\ filter_by(instance_uuid=instance_uuid)","def _instance_extra_get_by_instance_uuid_query(context, instance_uuid): return (model_query(context, models.InstanceExtra) .filter_by(instance_uuid=instance_uuid)) query = _instance_extra_get_by_instance_uuid_query( context, instance_uuid)",2,7
openstack%2Ffuel-library~master~Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,openstack/fuel-library,master,Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e,Fix killing of Rabbit beam process for OCF scripts,MERGED,2014-12-12 13:00:56.000000000,2014-12-12 13:57:43.000000000,2014-12-12 13:57:43.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}]","[{'number': 1, 'created': '2014-12-12 13:00:56.000000000', 'files': ['deployment/puppet/nova/files/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cda822d7f3690f4439ecd834b6af0cede3fc23fb', 'message': ""Fix killing of Rabbit beam process for OCF scripts\n\nW/o this patch, 'killall beam' commands kill all instances\nof rabbitmq including the one for Murano.\n\nThe solution is to use kill_rmq_and_remove_pid()\nprocedure to kill it by pidfile instead.\n\nCloses-bug: #1400670\n\nChange-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e\nSigned-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>\n""}]",0,141359,cda822d7f3690f4439ecd834b6af0cede3fc23fb,14,7,1,6926,,,0,"Fix killing of Rabbit beam process for OCF scripts

W/o this patch, 'killall beam' commands kill all instances
of rabbitmq including the one for Murano.

The solution is to use kill_rmq_and_remove_pid()
procedure to kill it by pidfile instead.

Closes-bug: #1400670

Change-Id: Ic8bb0b4ea22df22784bdb8fca0ccd0f2cb02bc9e
Signed-off-by: Bogdan Dobrelya <bdobrelia@mirantis.com>
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/59/141359/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nova/files/ocf/rabbitmq'],1,cda822d7f3690f4439ecd834b6af0cede3fc23fb,fix1400670," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. Beam will be killed."" kill_rmq_and_remove_pid ocf_log err ""${LH} RMQ-server can't be started while many tries. Beam will be killed."" kill_rmq_and_remove_pid"," ocf_log err ""${LH} Can't stop rabbitmq app by stop_app command."" ocf_run killall beam ocf_log err ""${LH} RMQ-server app can't be stopped during Mnesia cleaning. beam will be killed."" ocf_run killall -9 beam ocf_log err ""${LH} RMQ-server can't be started while many tries. beam will be killed."" ocf_run killall -9 beam",6,6
openstack%2Fdevstack-gate~master~Id7f74431478228d49370df31e18bc047fa44b383,openstack/devstack-gate,master,Id7f74431478228d49370df31e18bc047fa44b383,Add oslo.context to devstack-vm-gate-wrap.sh,MERGED,2014-11-17 22:04:20.000000000,2014-12-12 13:54:04.000000000,2014-12-12 13:54:02.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5638}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7118}, {'_account_id': 8871}]","[{'number': 1, 'created': '2014-11-17 22:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/27136080773d093a40b69222f9b63855b03162ff', 'message': 'Add oslo.context to devstack-vm-gate-wrap.sh\n\nChange-Id: Id7f74431478228d49370df31e18bc047fa44b383\n'}, {'number': 2, 'created': '2014-11-24 23:42:55.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/ba1ccfd1dfdb94f6b8b8441ddb706953f5cf8977', 'message': 'Add oslo.context to devstack-vm-gate-wrap.sh\n\nChange-Id: Id7f74431478228d49370df31e18bc047fa44b383\n'}]",0,135093,ba1ccfd1dfdb94f6b8b8441ddb706953f5cf8977,20,7,2,5638,,,0,"Add oslo.context to devstack-vm-gate-wrap.sh

Change-Id: Id7f74431478228d49370df31e18bc047fa44b383
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/93/135093/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,27136080773d093a40b69222f9b63855b03162ff,,"PROJECTS=""openstack/oslo.context $PROJECTS""",,1,0
openstack%2Fdevstack~master~Id238748417ffab53e02d59413dba66f61e724383,openstack/devstack,master,Id238748417ffab53e02d59413dba66f61e724383,add shebang lines to all lib files,MERGED,2014-12-05 19:28:18.000000000,2014-12-12 13:50:23.000000000,2014-12-10 20:32:15.000000000,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5196}, {'_account_id': 6524}, {'_account_id': 7118}, {'_account_id': 9008}, {'_account_id': 10385}, {'_account_id': 10386}]","[{'number': 1, 'created': '2014-12-05 19:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/9e889c41f5fda1531b66d52d85699bb51d849336', 'message': 'add shebang lines to all lib files\n\nWith gerrit 2.8, and the new change screen, this will trigger syntax\nhighlighting in gerrit. Thus making reviewing code a lot nicer.\n\nChange-Id: Id238748417ffab53e02d59413dba66f61e724383\n'}, {'number': 2, 'created': '2014-12-08 12:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ff00b57c820ed42336c5636a21b0703810c7b24c', 'message': 'add shebang lines to all lib files\n\nWith gerrit 2.8, and the new change screen, this will trigger syntax\nhighlighting in gerrit. Thus making reviewing code a lot nicer.\n\nChange-Id: Id238748417ffab53e02d59413dba66f61e724383\n'}, {'number': 3, 'created': '2014-12-10 16:28:12.000000000', 'files': ['lib/ironic', 'lib/ldap', 'lib/neutron_plugins/linuxbridge_agent', 'lib/neutron_plugins/plumgrid', 'lib/neutron_plugins/ovs_base', 'functions', 'lib/neutron_plugins/openvswitch_agent', 'lib/nova', 'lib/neutron_plugins/bigswitch_floodlight', 'lib/cinder_plugins/vsphere', 'lib/cinder_backends/xiv', 'lib/nova_plugins/hypervisor-xenserver', 'lib/neutron_thirdparty/ryu', 'functions-common', 'lib/swift', 'lib/glance', 'lib/cinder_backends/nfs', 'lib/neutron_thirdparty/midonet', 'lib/horizon', 'lib/neutron_thirdparty/trema', 'lib/cinder_backends/solidfire', 'lib/gantt', 'lib/zaqar', 'lib/stackforge', 'lib/nova_plugins/hypervisor-libvirt', 'lib/databases/postgresql', 'lib/neutron_plugins/midonet', 'lib/nova_plugins/hypervisor-fake', 'lib/cinder_backends/vmdk', 'lib/cinder_plugins/XenAPINFS', 'lib/neutron_plugins/ibm', 'lib/neutron_thirdparty/vmware_nsx', 'lib/nova_plugins/hypervisor-ironic', 'lib/rpc_backend', 'lib/neutron_plugins/ml2', 'lib/nova_plugins/hypervisor-vsphere', 'lib/tempest', 'lib/cinder_backends/lvm', 'lib/tls', 'lib/dib', 'lib/cinder_plugins/nfs', 'lib/neutron_plugins/brocade', 'lib/trove', 'lib/ceilometer', 'lib/oslo', 'lib/cinder_backends/netapp_nfs', 'lib/neutron_thirdparty/bigswitch_floodlight', 'lib/nova_plugins/functions-libvirt', 'lib/config', 'lib/ceph', 'lib/neutron_plugins/vmware_nsx', 'lib/sahara', 'lib/cinder_backends/netapp_iscsi', 'lib/cinder_plugins/glusterfs', 'lib/infra', 'lib/opendaylight', 'lib/database', 'lib/neutron_plugins/embrane', 'lib/neutron_plugins/nec', 'lib/heat', 'lib/keystone', 'stackrc', 'lib/databases/mysql', 'lib/neutron_plugins/ofagent_agent', 'lib/cinder', 'lib/neutron', 'lib/template', 'lib/nova_plugins/hypervisor-openvz', 'lib/neutron_plugins/openvswitch', 'lib/cinder_backends/glusterfs', 'lib/dstat', 'lib/cinder_backends/ceph', 'lib/neutron_plugins/oneconvergence', 'lib/neutron_plugins/nuage', 'lib/apache', 'lib/cinder_plugins/sheepdog', 'lib/neutron_plugins/cisco'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e263c82e48a431e502bd6baceb6dfcfdc1750cbb', 'message': 'add shebang lines to all lib files\n\nWith gerrit 2.8, and the new change screen, this will trigger syntax\nhighlighting in gerrit. Thus making reviewing code a lot nicer.\n\nChange-Id: Id238748417ffab53e02d59413dba66f61e724383\n'}]",1,139715,e263c82e48a431e502bd6baceb6dfcfdc1750cbb,30,10,3,2750,,,0,"add shebang lines to all lib files

With gerrit 2.8, and the new change screen, this will trigger syntax
highlighting in gerrit. Thus making reviewing code a lot nicer.

Change-Id: Id238748417ffab53e02d59413dba66f61e724383
",git fetch https://review.opendev.org/openstack/devstack refs/changes/15/139715/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'lib/ldap', 'lib/neutron_plugins/linuxbridge_agent', 'lib/neutron_plugins/plumgrid', 'lib/neutron_plugins/ovs_base', 'functions', 'lib/neutron_plugins/openvswitch_agent', 'lib/neutron_plugins/bigswitch_floodlight', 'lib/cinder_plugins/vsphere', 'lib/cinder_backends/xiv', 'lib/nova_plugins/hypervisor-xenserver', 'lib/neutron_thirdparty/ryu', 'functions-common', 'lib/swift', 'lib/glance', 'lib/cinder_backends/nfs', 'lib/neutron_thirdparty/midonet', 'lib/horizon', 'lib/neutron_thirdparty/trema', 'lib/cinder_backends/solidfire', 'lib/gantt', 'lib/zaqar', 'lib/stackforge', 'lib/nova_plugins/hypervisor-libvirt', 'lib/databases/postgresql', 'lib/neutron_plugins/midonet', 'lib/nova_plugins/hypervisor-fake', 'lib/cinder_backends/vmdk', 'lib/cinder_plugins/XenAPINFS', 'lib/neutron_plugins/ibm', 'lib/neutron_thirdparty/vmware_nsx', 'lib/nova_plugins/hypervisor-ironic', 'lib/rpc_backend', 'lib/neutron_plugins/ml2', 'lib/nova_plugins/hypervisor-vsphere', 'lib/cinder_backends/lvm', 'lib/tls', 'lib/dib', 'lib/cinder_plugins/nfs', 'lib/neutron_plugins/brocade', 'lib/trove', 'lib/ceilometer', 'lib/cinder_backends/netapp_nfs', 'lib/neutron_thirdparty/bigswitch_floodlight', 'lib/nova_plugins/functions-libvirt', 'lib/config', 'lib/ceph', 'lib/neutron_plugins/vmware_nsx', 'lib/sahara', 'lib/cinder_backends/netapp_iscsi', 'lib/cinder_plugins/glusterfs', 'lib/opendaylight', 'lib/database', 'lib/neutron_plugins/embrane', 'lib/neutron_plugins/nec', 'lib/heat', 'lib/keystone', 'stackrc', 'lib/databases/mysql', 'lib/neutron_plugins/ofagent_agent', 'lib/cinder', 'lib/template', 'lib/nova_plugins/hypervisor-openvz', 'lib/neutron_plugins/openvswitch', 'lib/cinder_backends/glusterfs', 'lib/dstat', 'lib/cinder_backends/ceph', 'lib/neutron_plugins/oneconvergence', 'lib/neutron_plugins/nuage', 'lib/apache', 'lib/cinder_plugins/sheepdog', 'lib/neutron_plugins/cisco']",72,9e889c41f5fda1531b66d52d85699bb51d849336,baremetal,#!/bin/bash #,,144,1
openstack%2Fnova~master~Ibf5d1284b44013c736b6b70ca4fa5d706c365c7d,openstack/nova,master,Ibf5d1284b44013c736b6b70ca4fa5d706c365c7d,Only check db/api.py for session in arguments,MERGED,2014-12-10 14:11:11.000000000,2014-12-12 13:49:44.000000000,2014-12-12 01:38:57.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 9555}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 14:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e114404c6cbb78320fe7dcdf9ed47fe524b32326', 'message': 'Only check db/api.py for session in arguments\n\nWe were checking both db/api.py and db/sqlalchemy/api.py for session\nin db apis, but db apis are only defined externall in db/api.py. This\nrule will falsely match on non-api methods in db/sqlalchemy/api.py\nwhich take a session argument. Passing the session around within this\nmodule is considered a good thing.\n\nChange-Id: Ibf5d1284b44013c736b6b70ca4fa5d706c365c7d\n'}, {'number': 2, 'created': '2014-12-10 16:56:55.000000000', 'files': ['nova/hacking/checks.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3c2a7c8ec4058d51609544e4314f23d571bb9dc1', 'message': 'Only check db/api.py for session in arguments\n\nWe were checking both db/api.py and db/sqlalchemy/api.py for session\nin db apis, but db apis are only defined externall in db/api.py. This\nrule will falsely match on non-api methods in db/sqlalchemy/api.py\nwhich take a session argument. Passing the session around within this\nmodule is considered a good thing.\n\nChange-Id: Ibf5d1284b44013c736b6b70ca4fa5d706c365c7d\n'}]",0,140686,3c2a7c8ec4058d51609544e4314f23d571bb9dc1,17,8,2,9555,,,0,"Only check db/api.py for session in arguments

We were checking both db/api.py and db/sqlalchemy/api.py for session
in db apis, but db apis are only defined externall in db/api.py. This
rule will falsely match on non-api methods in db/sqlalchemy/api.py
which take a session argument. Passing the session around within this
module is considered a good thing.

Change-Id: Ibf5d1284b44013c736b6b70ca4fa5d706c365c7d
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/140686/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/hacking/checks.py'],1,e114404c6cbb78320fe7dcdf9ed47fe524b32326,db/oslo," if ""db/api.py"" in filename:"," if ""db/api.py"" in filename or ""db/sqlalchemy/api.py"" in filename:",1,1
openstack%2Fceilometer~master~I2171c067bd8bb293a8478756f8b4938f312614a1,openstack/ceilometer,master,I2171c067bd8bb293a8478756f8b4938f312614a1,remove useless looping in pipeline,MERGED,2014-12-10 16:56:33.000000000,2014-12-12 13:27:17.000000000,2014-12-12 13:27:16.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 7052}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9562}, {'_account_id': 11564}, {'_account_id': 13273}, {'_account_id': 13367}]","[{'number': 1, 'created': '2014-12-10 16:56:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/3bf2afa8b4ae3a8ecf6ff55410a74dc6abfd34c8', 'message': ""remove useless looping in pipeline\n\npreviously, the pipeline filtered at the publisher stage. this\nlogic has been moved to an earlier stage yet we still do processing\nat publisher.\n\nthit patch removes legacy code. at worse it will have on effect to\nperformance. at best, we publisher quicker as we don't loop and\ngroupby needlessly for each batch of samples.\n\nChange-Id: I2171c067bd8bb293a8478756f8b4938f312614a1\nCloses-Bug: #1401176\n""}, {'number': 2, 'created': '2014-12-10 17:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/720eea96bb8092b78014eed7d3f560b452842e9d', 'message': ""remove useless looping in pipeline\n\npreviously, the pipeline filtered at the publisher stage. this\nlogic has been moved to an earlier stage yet we still do processing\nat publisher.\n\nthis patch removes legacy code. at worse, it will have no effect to\nperformance. at best, we publish quicker as we don't loop and\ngroupby needlessly for each batch of samples.\n\nChange-Id: I2171c067bd8bb293a8478756f8b4938f312614a1\nCloses-Bug: #1401176""}, {'number': 3, 'created': '2014-12-10 20:06:28.000000000', 'files': ['ceilometer/pipeline.py', 'ceilometer/tests/pipeline_base.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/494689ff9ed52a32208a1c9966d30c50c0a3af3b', 'message': ""remove useless looping in pipeline\n\npreviously, the pipeline filtered at the publisher stage. this\nlogic has been moved to an earlier stage yet we still do processing\nat publisher.\n\nthis patch removes legacy code. at worse, it will have no effect on\nperformance. at best, we publish quicker as we don't loop and\ngroupby needlessly for each batch of samples.\n\nChange-Id: I2171c067bd8bb293a8478756f8b4938f312614a1\nCloses-Bug: #1401176\n""}]",0,140772,494689ff9ed52a32208a1c9966d30c50c0a3af3b,25,13,3,6537,,,0,"remove useless looping in pipeline

previously, the pipeline filtered at the publisher stage. this
logic has been moved to an earlier stage yet we still do processing
at publisher.

this patch removes legacy code. at worse, it will have no effect on
performance. at best, we publish quicker as we don't loop and
groupby needlessly for each batch of samples.

Change-Id: I2171c067bd8bb293a8478756f8b4938f312614a1
Closes-Bug: #1401176
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/72/140772/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/pipeline.py', 'ceilometer/tests/pipeline_base.py']",2,3bf2afa8b4ae3a8ecf6ff55410a74dc6abfd34c8,bug/1401176, core_temp = publisher.samples[0] amb_temp = publisher.samples[1], core_temp = publisher.samples[1] amb_temp = publisher.samples[0],3,6
openstack%2Ffuel-main~stable%2F6.0~Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d,openstack/fuel-main,stable/6.0,Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d,Fix test groups vcenter_one_node_simple and vcenter_ha,MERGED,2014-12-12 12:50:42.000000000,2014-12-12 13:21:09.000000000,2014-12-12 13:21:08.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-12 12:50:42.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/dd85e4a99c70cdd66190eb3b7d32780c3b8cbf55', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved (see https://review.openstack.org/#/c/138744/)\nand mark 'should fail' must be canceled.\n\nCloses-bug: 1401846\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n(cherry picked from commit 7331c71e0cd7376a14a912924ee23aaecaa8f34f)\n""}]",0,141354,dd85e4a99c70cdd66190eb3b7d32780c3b8cbf55,7,3,1,12199,,,0,"Fix test groups vcenter_one_node_simple and vcenter_ha

There is ostf test 'Launch instance, create snapshot, launch instance from
snapshot' which never works in Fuel 5.x with vCenter hypervisor due to
timeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it
was marked as 'should fail'.

Now problem with timeouts solved (see https://review.openstack.org/#/c/138744/)
and mark 'should fail' must be canceled.

Closes-bug: 1401846
Change-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d
(cherry picked from commit 7331c71e0cd7376a14a912924ee23aaecaa8f34f)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/54/141354/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,dd85e4a99c70cdd66190eb3b7d32780c3b8cbf55,," cluster_id=cluster_id, test_sets=['smoke', 'sanity']) cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'])"," cluster_id=cluster_id, test_sets=['smoke', 'sanity'], should_fail=1, failed_test_name=[('Launch instance, create snapshot,' ' launch instance from snapshot')]) cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'], should_fail=1, failed_test_name=[('Launch instance, create snapshot,' ' launch instance from snapshot')])",2,8
openstack%2Foslo.concurrency~master~I9e49b796692b71bf518e5fbd96b663329cc505b3,openstack/oslo.concurrency,master,I9e49b796692b71bf518e5fbd96b663329cc505b3,Drop requirements-py3.txt,MERGED,2014-12-11 08:54:07.000000000,2014-12-12 13:17:01.000000000,2014-12-12 13:17:01.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 9107}]","[{'number': 1, 'created': '2014-12-11 08:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/0a67af4f4c3dcbb29d13008257b84361880a2c39', 'message': 'Drop requirements-py3.txt\n\nThe file was identical to requirements.txt, just reuse this one.\n\nKeep py33 and py34 sections in tox.ini, because eventlet is not tested\nyet on Python 3.\n\nChange-Id: I9e49b796692b71bf518e5fbd96b663329cc505b3\n'}, {'number': 2, 'created': '2014-12-11 22:37:26.000000000', 'files': ['requirements-py3.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/32bf9400e6479b0c8a0fda5a845277d033c9ac2b', 'message': 'Drop requirements-py3.txt\n\nThe file was identical to requirements.txt, just reuse this one.\n\nKeep py33 and py34 sections in tox.ini, because eventlet is not tested\nyet on Python 3.\n\nChange-Id: I9e49b796692b71bf518e5fbd96b663329cc505b3\n'}]",4,140980,32bf9400e6479b0c8a0fda5a845277d033c9ac2b,13,4,2,9107,,,0,"Drop requirements-py3.txt

The file was identical to requirements.txt, just reuse this one.

Keep py33 and py34 sections in tox.ini, because eventlet is not tested
yet on Python 3.

Change-Id: I9e49b796692b71bf518e5fbd96b663329cc505b3
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/80/140980/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-py3.txt', 'tox.ini']",2,0a67af4f4c3dcbb29d13008257b84361880a2c39,drop_req_py3,deps = -r{toxinidir}/requirements.txtdeps = -r{toxinidir}/requirements.txt,deps = -r{toxinidir}/requirements-py3.txtdeps = -r{toxinidir}/requirements-py3.txt,2,16
openstack%2Fnova~master~Idc9b587c705c1c1ab4e1173ad1e8e244037284d7,openstack/nova,master,Idc9b587c705c1c1ab4e1173ad1e8e244037284d7,simplify database fixture to the features we use,MERGED,2014-12-09 16:50:40.000000000,2014-12-12 13:06:02.000000000,2014-12-10 20:28:19.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 16:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/27df3396055416c27a387f652ad2628cf34b4aeb', 'message': ""simplify database fixture to the features we use\n\nThe Database fixture has existed for a long time, and has a large\namount of vestigial code that is no longer usable as it's masked by\nother test setup. For instance, the conf fixture always sets the db\nconnection string to in memory db.\n\nSimplify what the Database fixture is doing to just the inmemory\nschema caching and reconstruction. Also provide a test case\ndemonstrating that this both sets up the db correctly, as well as\nresets it after we've made changes.\n\nChange-Id: Idc9b587c705c1c1ab4e1173ad1e8e244037284d7\n""}, {'number': 2, 'created': '2014-12-09 19:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3ddfce4893c0eab5a51d3f158a89cb421b5d3c1', 'message': ""simplify database fixture to the features we use\n\nThe Database fixture has existed for a long time, and has a large\namount of vestigial code that is no longer usable as it's masked by\nother test setup. For instance, the conf fixture always sets the db\nconnection string to in memory db.\n\nSimplify what the Database fixture is doing to just the inmemory\nschema caching and reconstruction. Also provide a test case\ndemonstrating that this both sets up the db correctly, as well as\nresets it after we've made changes.\n\nChange-Id: Idc9b587c705c1c1ab4e1173ad1e8e244037284d7\n""}, {'number': 3, 'created': '2014-12-10 13:51:59.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ccac8cfef73b2a4f6e839d03edef2889e6a78cd5', 'message': ""simplify database fixture to the features we use\n\nThe Database fixture has existed for a long time, and has a large\namount of vestigial code that is no longer usable as it's masked by\nother test setup. For instance, the conf fixture always sets the db\nconnection string to in memory db.\n\nSimplify what the Database fixture is doing to just the inmemory\nschema caching and reconstruction. Also provide a test case\ndemonstrating that this both sets up the db correctly, as well as\nresets it after we've made changes.\n\nChange-Id: Idc9b587c705c1c1ab4e1173ad1e8e244037284d7\n""}]",0,140399,ccac8cfef73b2a4f6e839d03edef2889e6a78cd5,25,11,3,2750,,,0,"simplify database fixture to the features we use

The Database fixture has existed for a long time, and has a large
amount of vestigial code that is no longer usable as it's masked by
other test setup. For instance, the conf fixture always sets the db
connection string to in memory db.

Simplify what the Database fixture is doing to just the inmemory
schema caching and reconstruction. Also provide a test case
demonstrating that this both sets up the db correctly, as well as
resets it after we've made changes.

Change-Id: Idc9b587c705c1c1ab4e1173ad1e8e244037284d7
",git fetch https://review.opendev.org/openstack/nova refs/changes/99/140399/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py']",3,27df3396055416c27a387f652ad2628cf34b4aeb,fixtures_series,"from nova.db import api as sql from nova.db import migration from nova.db.sqlalchemy import api as session class TestDatabaseFixture(testtools.TestCase): def test_fixture_reset(self): # because this sets up reasonable db connection strings self.useFixture(conf_fixture.ConfFixture()) self.useFixture(fixtures.Database()) engine = session.get_engine() conn = engine.connect() result = conn.execute(""select * from instance_types"") rows = result.fetchall() self.assertEqual(len(rows), 5, ""Rows %s"" % rows) # insert a 6th instance type, column 5 below is an int id # which has a constraint on it, so if new standard instance # types are added you have to bump it. conn.execute(""insert into instance_types VALUES "" ""(NULL, NULL, NULL, 't1.test', 6, 4096, 2, 0, NULL, '87'"" "", 1.0, 40, 0, 0, 1, 0)"") result = conn.execute(""select * from instance_types"") rows = result.fetchall() self.assertEqual(len(rows), 6, ""Rows %s"" % rows) # reset by invoking the fixture again # # NOTE(sdague): it's important to reestablish the db # connection because otherwise we have a reference to the old # in mem db. self.useFixture(fixtures.Database()) conn = engine.connect() result = conn.execute(""select * from instance_types"") rows = result.fetchall() self.assertEqual(len(rows), 5, ""Rows %s"" % rows)",,65,59
openstack%2Fnova~master~I591f3c270804dfb01eab7c8c5d43b87a7abcdeda,openstack/nova,master,I591f3c270804dfb01eab7c8c5d43b87a7abcdeda,extract the timeout setup as a fixture,MERGED,2014-12-09 14:11:13.000000000,2014-12-12 13:04:26.000000000,2014-12-10 17:27:39.000000000,"[{'_account_id': 3}, {'_account_id': 100}, {'_account_id': 679}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 14:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/baa21c9a23b0282ededa42c2c3dd897b6e891c76', 'message': 'extract the timeout setup as a fixture\n\nIncludes tests for the nova specific parts of this.\n\nChange-Id: I591f3c270804dfb01eab7c8c5d43b87a7abcdeda\n'}, {'number': 2, 'created': '2014-12-09 19:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3b124cfa404cf2b660279e0091eabe480ca1a14', 'message': 'extract the timeout setup as a fixture\n\nIncludes tests for the nova specific parts of this.\n\nChange-Id: I591f3c270804dfb01eab7c8c5d43b87a7abcdeda\n'}, {'number': 3, 'created': '2014-12-10 13:51:59.000000000', 'files': ['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/666cccd3eb212ec82bb04101bfe710fb27a152c7', 'message': 'extract the timeout setup as a fixture\n\nIncludes tests for the nova specific parts of this.\n\nChange-Id: I591f3c270804dfb01eab7c8c5d43b87a7abcdeda\n'}]",0,140334,666cccd3eb212ec82bb04101bfe710fb27a152c7,31,11,3,2750,,,0,"extract the timeout setup as a fixture

Includes tests for the nova specific parts of this.

Change-Id: I591f3c270804dfb01eab7c8c5d43b87a7abcdeda
",git fetch https://review.opendev.org/openstack/nova refs/changes/34/140334/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/fixtures.py', 'nova/test.py', 'nova/tests/unit/test_fixtures.py']",3,baa21c9a23b0282ededa42c2c3dd897b6e891c76,fixtures_series," class TestTimeout(testtools.TestCase): """"""Tests for our timeout fixture. Testing the actual timeout mechanism is beyond the scope of this test, because it's a pretty clear pass through to fixtures' timeout fixture, which tested in their tree. """""" def test_scaling(self): # a bad scaling factor self.assertRaises(ValueError, fixtures.Timeout, 1, 0.5) # various things that should work. timeout = fixtures.Timeout(10) self.assertEqual(timeout.test_timeout, 10) timeout = fixtures.Timeout(""10"") self.assertEqual(timeout.test_timeout, 10) timeout = fixtures.Timeout(""10"", 2) self.assertEqual(timeout.test_timeout, 20)",,53,26
openstack%2Foslo-incubator~master~I681ed0de6f6b1bf89469331e9bda86dffff508a9,openstack/oslo-incubator,master,I681ed0de6f6b1bf89469331e9bda86dffff508a9,Add __slots__ to Resource class,ABANDONED,2014-02-03 12:37:41.000000000,2014-12-12 12:58:06.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 7491}, {'_account_id': 7536}, {'_account_id': 7763}, {'_account_id': 8041}, {'_account_id': 9550}, {'_account_id': 9796}, {'_account_id': 12000}]","[{'number': 1, 'created': '2014-02-03 12:37:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/2d8210f500319ac16299b6cfa2c88bfdefd3935a', 'message': ""Add __slots__ to Resource class\n\nUsing __slots__ in Resource class allows replace dictionaries\nof creation attributes by attributes of class.\n\nWith usage of __slots__ we define creation attributes of\nResource classes common way and we don't need _info() dict\nof resource.\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}, {'number': 2, 'created': '2014-02-03 12:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/b6c24acac323bcaec8b64a46c04b87a26132b060', 'message': ""Add __slots__ to Resource class\n\nBy using builtin __slots__ attribute we can define attributes\nneeded for object creation.\nWith such approach we can define attributes directly in class\ninstead of static module variable.\n\nExample:\n\nclass Server(base.Resource):\n    __slots__ = set(['name', 'image', 'flavor'])\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}, {'number': 3, 'created': '2014-02-20 17:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/d24e01f7d972646b5a5e5cacb0393cb923b747eb', 'message': ""Add __slots__ to Resource class\n\nBy using builtin __slots__ attribute we can define attributes\nneeded for object creation.\nWith such approach we can define attributes directly in class\ninstead of static module variable.\n\nExample:\n\nclass Server(base.Resource):\n    __slots__ = set(['name', 'image', 'flavor'])\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}, {'number': 4, 'created': '2014-03-03 16:08:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/5df6781b5fbaea81f99ad5e31e69e7bb140435a7', 'message': ""Add __slots__ to Resource class\n\nResource classes in different projects have static module\nvariables for creation attributes or define required attributes\nas arguments of method create(). For this reason we can't use base\nmethod create() as in CrudManager, we should override this method in\nall implementations of Resource class.\n\nBy using builtin __slots__ attribute we can define attributes\nneeded for object creation.\nWith such approach we can define attributes directly in class\ninstead of static module variable and use them from base method\ncreate().\n\nExample of usage __slots__:\n\nclass Server(base.Resource):\n    __slots__ = set(['name', 'image', 'flavor'])\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}, {'number': 5, 'created': '2014-03-04 11:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/de902f25d955c040afe3e3a051ab1b4e13061948', 'message': ""Add __slots__ to Resource class\n\nResource classes in different projects have static module\nvariables for creation attributes or define required attributes\nas arguments of method create(). For this reason we can't use base\nmethod create() as in CrudManager, we should override this method in\nall implementations of Resource class.\n\nBy using builtin __slots__ attribute we can define attributes\nneeded for object creation.\nWith such approach we can define attributes directly in class\ninstead of static module variable and use them from base method\ncreate().\n\nExample of usage __slots__:\n\nclass Server(base.Resource):\n    __slots__ = set(['name', 'image', 'flavor'])\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}, {'number': 6, 'created': '2014-03-04 12:34:15.000000000', 'files': ['openstack/common/apiclient/base.py', 'tests/unit/apiclient/test_base.py'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/36a609b2dbd7b19a927e615bd5b1014a38a444e9', 'message': ""Add __slots__ to Resource class\n\nResource classes in different projects have static module\nvariables for creation attributes or define required attributes\nas arguments of method create(). For this reason we can't use base\nmethod create() as in CrudManager, we should override this method in\nall implementations of Resource class.\n\nBy using builtin __slots__ attribute we can define attributes\nneeded for object creation.\nWith such approach we can define attributes directly in class\ninstead of static module variable and use them from base method\ncreate().\n\nExample of usage __slots__:\n\nclass Server(base.Resource):\n    __slots__ = set(['name', 'image', 'flavor'])\n\nbp common-client-library-2\n\nChange-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9\n""}]",4,70706,36a609b2dbd7b19a927e615bd5b1014a38a444e9,35,9,6,9550,,,0,"Add __slots__ to Resource class

Resource classes in different projects have static module
variables for creation attributes or define required attributes
as arguments of method create(). For this reason we can't use base
method create() as in CrudManager, we should override this method in
all implementations of Resource class.

By using builtin __slots__ attribute we can define attributes
needed for object creation.
With such approach we can define attributes directly in class
instead of static module variable and use them from base method
create().

Example of usage __slots__:

class Server(base.Resource):
    __slots__ = set(['name', 'image', 'flavor'])

bp common-client-library-2

Change-Id: I681ed0de6f6b1bf89469331e9bda86dffff508a9
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/06/70706/5 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/apiclient/base.py', 'tests/unit/apiclient/test_base.py']",2,2d8210f500319ac16299b6cfa2c88bfdefd3935a,bp/common-client-library-2," __slots__ = set(['id', 'name', 'foo']) __slots__ = set(['id', 'domain_id', 'crud_resource_id']) r = HumanResource(None, dict(foo=""bar"", name=""spam"")) self.assertEqual('<HumanResource foo=bar, id=None, name=spam>', repr(r)) r = CrudResource(mgr, {""id"": 1}) def test_to_dict(self): r = CrudResource(None, {'id': 1, ""domain_id"": ""my-domain""}) info = r.to_dict() self.assertIn('id', info) self.assertIn('crud_resource_id', info) self.assertNotIn('_loaded', info) def test_resource_getattr_not_in_slots(self): f = HumanResource(self.tc.human_resources, {'id': 1}) self.assertFalse(f.is_loaded) def test_resource_getattr_in_slots_not_set(self): f = CrudResource(self.tc.crud_resources, {'id': 1}) self.assertEqual(None, f.crud_resource_id) self.http_client.assert_called('GET', '/crud_resources/1') r1 = CrudResource(None, {'id': 1, 'domain_id': 'hi'}) r2 = CrudResource(None, {'id': 1, 'domain_id': 'hello'}) r1 = CrudResource(None, {'id': 1}) r1 = CrudResource(None, {'id': 1, 'domain_id': 'hi'}) r2 = CrudResource(None, {'id': 1, 'domain_id': 'hi'}) crud_resource.to_dict(),"," pass self.crud_resource_json.update(kw) r = base.Resource(None, dict(foo=""bar"", baz=""spam"")) self.assertEqual(repr(r), ""<Resource baz=spam, foo=bar>"") r = base.Resource(None, {""name"": ""1""}) self.assertIsNone(r.human_id) r = base.Resource(mgr, {""id"": 1}) # Missing stuff still fails after a second get r1 = base.Resource(None, {'id': 1, 'name': 'hi'}) r2 = base.Resource(None, {'id': 1, 'name': 'hello'}) r1 = base.Resource(None, {'id': 1}) r1 = base.Resource(None, {'name': 'joe', 'age': 12}) r2 = base.Resource(None, {'name': 'joe', 'age': 12}) crud_resource._info,",52,34
openstack%2Fpython-ironicclient~master~Ic4c6fea2349f9215b9014bb23f6d96d99866c90d,openstack/python-ironicclient,master,Ic4c6fea2349f9215b9014bb23f6d96d99866c90d,Use HTTPClient from common Oslo code,ABANDONED,2014-04-28 20:01:23.000000000,2014-12-12 12:57:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6773}, {'_account_id': 7763}, {'_account_id': 8041}, {'_account_id': 8106}, {'_account_id': 8968}, {'_account_id': 9550}]","[{'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a11897b71c580b8f93a89dfc9ea887d978c07840', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a1f52cc45149750ba8fdc073573f9060800fb109', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e17db66b2c9ad779adba36591482a0d1da6da15f', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': ['ironicclient/common/http.py', 'ironicclient/tests/v1/test_driver.py', 'ironicclient/tests/test_client.py', 'ironicclient/tests/v1/test_node.py', 'ironicclient/tests/v1/test_port.py', 'ironicclient/common/base.py', 'requirements.txt', 'ironicclient/shell.py', 'ironicclient/tests/test_http.py', 'ironicclient/tests/v1/test_chassis.py', 'ironicclient/v1/client.py', 'ironicclient/tests/utils.py', 'ironicclient/client.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5fcf7213222f23a9512c2c0f6375ad4a4e9ed09e', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e9e6c509eaedfa24c34c936a2ce4ed847ac478c9', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e40b9047719a28d0ba87d5cb333f3ab028569544', 'message': 'Use HTTPClient from common Oslo code\n\nIn the process of unification of the clients code we should\nreuse common functionality from Oslo.\n\nbp common-client-library-2\n\nChange-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d\n'}]",10,64286,5fcf7213222f23a9512c2c0f6375ad4a4e9ed09e,38,8,6,9550,,,0,"Use HTTPClient from common Oslo code

In the process of unification of the clients code we should
reuse common functionality from Oslo.

bp common-client-library-2

Change-Id: Ic4c6fea2349f9215b9014bb23f6d96d99866c90d
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/86/64286/3 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/common/http.py', 'ironicclient/tests/v1/test_driver.py', 'ironicclient/tests/test_client.py', 'ironicclient/tests/v1/test_node.py', 'ironicclient/tests/v1/test_port.py', 'ironicclient/common/base.py', 'requirements.txt', 'ironicclient/shell.py', 'ironicclient/tests/test_http.py', 'ironicclient/tests/v1/test_chassis.py', 'ironicclient/v1/client.py', 'ironicclient/tests/utils.py', 'ironicclient/client.py']",13,a11897b71c580b8f93a89dfc9ea887d978c07840,bp/common-client-library-2,,"def get_client(api_version, **kwargs): """"""Get an authtenticated client, based on the credentials in the keyword args. :param api_version: the API version to use ('1' or '2') :param kwargs: keyword args containing credentials, either: * os_auth_token: pre-existing token to re-use * ironic_url: ironic API endpoint or: * os_username: name of user * os_password: user's password * os_auth_url: endpoint to authenticate against * insecure: allow insecure SSL (no cert verification) * os_tenant_{name|id}: name or ID of tenant """""" if kwargs.get('os_auth_token') and kwargs.get('ironic_url'): token = kwargs.get('os_auth_token') endpoint = kwargs.get('ironic_url') elif (kwargs.get('os_username') and kwargs.get('os_password') and kwargs.get('os_auth_url') and (kwargs.get('os_tenant_id') or kwargs.get('os_tenant_name'))): ks_kwargs = { 'username': kwargs.get('os_username'), 'password': kwargs.get('os_password'), 'tenant_id': kwargs.get('os_tenant_id'), 'tenant_name': kwargs.get('os_tenant_name'), 'auth_url': kwargs.get('os_auth_url'), 'service_type': kwargs.get('os_service_type'), 'endpoint_type': kwargs.get('os_endpoint_type'), 'insecure': kwargs.get('insecure'), } _ksclient = _get_ksclient(**ks_kwargs) token = (kwargs.get('os_auth_token') if kwargs.get('os_auth_token') else _ksclient.auth_token) endpoint = kwargs.get('ironic_url') or \ _get_endpoint(_ksclient, **ks_kwargs) cli_kwargs = { 'token': token, 'insecure': kwargs.get('insecure'), 'timeout': kwargs.get('timeout'), 'ca_file': kwargs.get('ca_file'), 'cert_file': kwargs.get('cert_file'), 'key_file': kwargs.get('key_file'), } return Client(api_version, endpoint, **cli_kwargs) ",192,728
openstack%2Ffuel-main~master~Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d,openstack/fuel-main,master,Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d,Fix test groups vcenter_one_node_simple and vcenter_ha,MERGED,2014-12-12 11:12:59.000000000,2014-12-12 12:50:42.000000000,2014-12-12 12:38:15.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 12141}]","[{'number': 1, 'created': '2014-12-12 11:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ccf8a28f9963f9df45b2862aa7452c2674d689cd', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved and mark 'should fail' must be canceled.\n\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n""}, {'number': 2, 'created': '2014-12-12 11:18:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/bf93786a03d6798ff7d68c11a9100b2c2b125364', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved and mark 'should fail' must be canceled.\n\nCloses-bug: 1401846\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n""}, {'number': 3, 'created': '2014-12-12 11:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2fc5c1a78a0f637789731c70d02f125fd6281090', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved(https://github.com/stackforge/fuel-ostf/commit/a9afb68710d809570460c29d6c3293219d3624d4)\nand mark 'should fail' must be canceled.\n\nCloses-bug: 1401846\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n""}, {'number': 4, 'created': '2014-12-12 11:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/60bed8a43f7719e88859e0dd0a2a925571d2aa55', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved (see https://review.openstack.org/#/c/138744/) and mark 'should fail' must be canceled.\n\nCloses-bug: 1401846\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n""}, {'number': 5, 'created': '2014-12-12 11:38:54.000000000', 'files': ['fuelweb_test/tests/test_vcenter.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7331c71e0cd7376a14a912924ee23aaecaa8f34f', 'message': ""Fix test groups vcenter_one_node_simple and vcenter_ha\n\nThere is ostf test 'Launch instance, create snapshot, launch instance from\nsnapshot' which never works in Fuel 5.x with vCenter hypervisor due to\ntimeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it\nwas marked as 'should fail'.\n\nNow problem with timeouts solved (see https://review.openstack.org/#/c/138744/)\nand mark 'should fail' must be canceled.\n\nCloses-bug: 1401846\nChange-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d\n""}]",1,141333,7331c71e0cd7376a14a912924ee23aaecaa8f34f,30,6,5,12199,,,0,"Fix test groups vcenter_one_node_simple and vcenter_ha

There is ostf test 'Launch instance, create snapshot, launch instance from
snapshot' which never works in Fuel 5.x with vCenter hypervisor due to
timeout problem. And in system tests vcenter_one_node_simple and vcenter_ha it
was marked as 'should fail'.

Now problem with timeouts solved (see https://review.openstack.org/#/c/138744/)
and mark 'should fail' must be canceled.

Closes-bug: 1401846
Change-Id: Idc63dea0c32fcc471629b10a07a09fb3ecce9d2d
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/33/141333/5 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_vcenter.py'],1,ccf8a28f9963f9df45b2862aa7452c2674d689cd,1400287-again," cluster_id=cluster_id, test_sets=['smoke', 'sanity']) cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'])"," cluster_id=cluster_id, test_sets=['smoke', 'sanity'], should_fail=1, failed_test_name=[('Launch instance, create snapshot,' ' launch instance from snapshot')]) cluster_id=cluster_id, test_sets=['ha', 'smoke', 'sanity'], should_fail=1, failed_test_name=[('Launch instance, create snapshot,' ' launch instance from snapshot')])",2,8
openstack%2Foslo.db~master~I37ddd669b89669730ae1ff07c7bc7a6ba5705f67,openstack/oslo.db,master,I37ddd669b89669730ae1ff07c7bc7a6ba5705f67,"Repair string-based disconnect filters for MySQL, DB2",MERGED,2014-12-05 20:55:12.000000000,2014-12-12 12:48:23.000000000,2014-12-12 12:48:22.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-12-05 20:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/5290f7cd8913deb725661fd18a30d2c6392238a7', 'message': 'Repair string-based disconnect filters for MySQL, DB2\n\nThe two regexp-based filters in exc_filters.py->_is_db_connection_error()\nwere both incorrectly formed.  The tests for these filters would pass\nbecause the fixture also set the is_disconnect flag to True, which\nnormally would be set by SQLAlchemy, and therefore the\n_raise_for_remaining_DBAPIError() would catch this and kick in.\nHowever, the _is_db_connection_error() filters are intended to\nwork independently of whether this flag is set; so two new tests\nare added which unset the flag, and ensure that the exception messages\nas given are caught here.\n\nChange-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67\n'}, {'number': 2, 'created': '2014-12-05 21:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/4425637140566a9d679dff281ed0fbbd546756fc', 'message': 'Repair string-based disconnect filters for MySQL, DB2\n\nThe two regexp-based filters in exc_filters.py->_is_db_connection_error()\nwere both incorrectly formed.  The tests for these filters would pass\nbecause the fixture also set the is_disconnect flag to True, which\nnormally would be set by SQLAlchemy, and therefore the\n_raise_operational_errors_directly_filter() or possibly\nthe _raise_for_remaining_DBAPIError() filters would catch this,\nview the is_disconnect flag as True, and promote to a DBConnectionError.\nHowever, the _is_db_connection_error() filters are intended to\nwork independently of whether this flag is set; so two new tests\nare added which unset the flag, and ensure that the exception messages\nas given are caught here.\n\nChange-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67\n'}, {'number': 3, 'created': '2014-12-05 21:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/07c3d7d03db45b02f4b98d2597994e7adfadc852', 'message': 'Repair string-based disconnect filters for MySQL, DB2\n\nThe two regexp-based filters in exc_filters.py->_is_db_connection_error()\nwere both incorrectly formed.  The tests for these filters would pass\nbecause the fixture also set the is_disconnect flag to True, which\nnormally would be set by SQLAlchemy, and therefore the\n_raise_operational_errors_directly_filter() or possibly\nthe _raise_for_remaining_DBAPIError() filters would catch this,\nview the is_disconnect flag as True, and promote to a DBConnectionError.\nHowever, the _is_db_connection_error() filters are intended to\nwork independently of whether this flag is set; so two new tests\nare added which unset the flag, and ensure that the exception messages\nas given are caught here.\n\nChange-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67\n'}, {'number': 4, 'created': '2014-12-06 20:59:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/8b16e9b5ff2a21c068d04d8a57cc172b4e3798f2', 'message': 'Repair string-based disconnect filters for MySQL, DB2\n\nThe two regexp-based filters in exc_filters.py->_is_db_connection_error()\nwere both incorrectly formed.  The tests for these filters would pass\nbecause the fixture also set the is_disconnect flag to True, which\nnormally would be set by SQLAlchemy, and therefore the\n_raise_operational_errors_directly_filter() or possibly\nthe _raise_for_remaining_DBAPIError() filters would catch this,\nview the is_disconnect flag as True, and promote to a DBConnectionError.\nHowever, the _is_db_connection_error() filters are intended to\nwork independently of whether this flag is set; so two new tests\nare added which unset the flag, and ensure that the exception messages\nas given are caught here.\n\nChange-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67\n'}, {'number': 5, 'created': '2014-12-12 10:50:03.000000000', 'files': ['oslo/db/sqlalchemy/exc_filters.py', 'tests/sqlalchemy/test_exc_filters.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/0265aa4e01270b8fc7cab1266b8602e1921c9ddb', 'message': 'Repair string-based disconnect filters for MySQL, DB2\n\nThe two regexp-based filters in exc_filters.py->_is_db_connection_error()\nwere both incorrectly formed.  The tests for these filters would pass\nbecause the fixture also set the is_disconnect flag to True, which\nnormally would be set by SQLAlchemy, and therefore the\n_raise_operational_errors_directly_filter() or possibly\nthe _raise_for_remaining_DBAPIError() filters would catch this,\nview the is_disconnect flag as True, and promote to a DBConnectionError.\nHowever, the _is_db_connection_error() filters are intended to\nwork independently of whether this flag is set; so two new tests\nare added which unset the flag, and ensure that the exception messages\nas given are caught here.\n\nChange-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67\n'}]",0,139733,0265aa4e01270b8fc7cab1266b8602e1921c9ddb,15,4,5,11816,,,0,"Repair string-based disconnect filters for MySQL, DB2

The two regexp-based filters in exc_filters.py->_is_db_connection_error()
were both incorrectly formed.  The tests for these filters would pass
because the fixture also set the is_disconnect flag to True, which
normally would be set by SQLAlchemy, and therefore the
_raise_operational_errors_directly_filter() or possibly
the _raise_for_remaining_DBAPIError() filters would catch this,
view the is_disconnect flag as True, and promote to a DBConnectionError.
However, the _is_db_connection_error() filters are intended to
work independently of whether this flag is set; so two new tests
are added which unset the flag, and ensure that the exception messages
as given are caught here.

Change-Id: I37ddd669b89669730ae1ff07c7bc7a6ba5705f67
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/33/139733/5 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/db/sqlalchemy/exc_filters.py', 'tests/sqlalchemy/test_exc_filters.py']",2,5290f7cd8913deb725661fd18a30d2c6392238a7,fix_connect_filters_for_sqla_10," def _fixture( self, dialect_name, exception, num_disconnects, is_disconnect=True): mock.Mock(return_value=is_disconnect)) def _test_ping_listener_disconnected( self, dialect_name, exc_obj, is_disconnect=True): with self._fixture(dialect_name, exc_obj, 1, is_disconnect): with self._fixture(dialect_name, exc_obj, 2, is_disconnect): def test_mysql_ping_listener_disconnected_regex_only(self): # intentionally set the is_disconnect flag to False # in the ""sqlalchemy"" layer to make sure the regexp # on _is_db_connection_error is catching for code in [2002, 2003, 2006, 2013]: self._test_ping_listener_disconnected( ""mysql"", self.OperationalError('%d MySQL server has gone away' % code), is_disconnect=False ) def test_db2_ping_listener_disconnected_regex_only(self): self._test_ping_listener_disconnected( ""ibm_db_sa"", self.OperationalError( 'SQL30081N: DB2 Server connection is no longer active'), is_disconnect=False ) "," def _fixture(self, dialect_name, exception, num_disconnects): mock.Mock(return_value=True)) def _test_ping_listener_disconnected(self, dialect_name, exc_obj): with self._fixture(dialect_name, exc_obj, 1): with self._fixture(dialect_name, exc_obj, 2):",29,7
openstack%2Foslo.db~master~I61714f3c32625a621eaba501d20346519b8b12c7,openstack/oslo.db,master,I61714f3c32625a621eaba501d20346519b8b12c7,Upgrade exc_filters for 'engine' argument and connect behavior,MERGED,2014-12-05 20:04:34.000000000,2014-12-12 12:46:33.000000000,2014-12-12 12:46:32.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6849}, {'_account_id': 7491}]","[{'number': 1, 'created': '2014-12-05 20:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/552dd63fa7295d2c5373719537fc9b771e79dd70', 'message': 'Upgrade exc_filters for \'engine\' argument and connect behavior\n\nThis patch applies upgrades to the sqlalchemy/exc_filters.py and\nsqlalchemy/compat/handle_error.py compatibility layers to accommodate\nnew changes in SQLAlchemy 1.0.  SQLA 1.0 will now route errors that\noccur upon connect through the handle_error() event, just like any other,\nso that when 1.0 is present we no longer need to use\nexc_filters.handle_connect_error; the method becomes a passthrough\nas far as running the event handler.  Additionally, SQLAlchemy 1.0\nhas added the ""engine"" parameter to ExceptionContext, specifically\nto suit the case when the initial connect has failed and there is\nno Connection object; the compatibility layer here now emulates\nthis behavior for SQLAlchemy versions prior to 1.0.\n\nChange-Id: I61714f3c32625a621eaba501d20346519b8b12c7\n'}, {'number': 2, 'created': '2014-12-05 21:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/afa1e64fc490c3e782e63fb34c7af398d559fa77', 'message': 'Upgrade exc_filters for \'engine\' argument and connect behavior\n\nThis patch applies upgrades to the sqlalchemy/exc_filters.py and\nsqlalchemy/compat/handle_error.py compatibility layers to accommodate\nnew changes in SQLAlchemy 1.0.  SQLA 1.0 will now route errors that\noccur upon connect through the handle_error() event, just like any other,\nso that when 1.0 is present we no longer need to use\nexc_filters.handle_connect_error; the method becomes a passthrough\nas far as running the event handler.  Additionally, SQLAlchemy 1.0\nhas added the ""engine"" parameter to ExceptionContext, specifically\nto suit the case when the initial connect has failed and there is\nno Connection object; the compatibility layer here now emulates\nthis behavior for SQLAlchemy versions prior to 1.0.\n\nChange-Id: I61714f3c32625a621eaba501d20346519b8b12c7\n'}, {'number': 3, 'created': '2014-12-05 21:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/07b2bfd53e121397faff9c60112cdf64e41fb293', 'message': 'Upgrade exc_filters for \'engine\' argument and connect behavior\n\nThis patch applies upgrades to the sqlalchemy/exc_filters.py and\nsqlalchemy/compat/handle_error.py compatibility layers to accommodate\nnew changes in SQLAlchemy 1.0.  SQLA 1.0 will now route errors that\noccur upon connect through the handle_error() event, just like any other,\nso that when 1.0 is present we no longer need to use\nexc_filters.handle_connect_error; the method becomes a passthrough\nas far as running the event handler.  Additionally, SQLAlchemy 1.0\nhas added the ""engine"" parameter to ExceptionContext, specifically\nto suit the case when the initial connect has failed and there is\nno Connection object; the compatibility layer here now emulates\nthis behavior for SQLAlchemy versions prior to 1.0.\n\nChange-Id: I61714f3c32625a621eaba501d20346519b8b12c7\n'}, {'number': 4, 'created': '2014-12-06 20:59:19.000000000', 'files': ['oslo/db/sqlalchemy/exc_filters.py', 'oslo/db/sqlalchemy/compat/__init__.py', 'oslo/db/sqlalchemy/compat/handle_error.py', 'oslo/db/sqlalchemy/compat/utils.py'], 'web_link': 'https://opendev.org/openstack/oslo.db/commit/32e5c6096a9523a0d22bbef2569181c281800313', 'message': 'Upgrade exc_filters for \'engine\' argument and connect behavior\n\nThis patch applies upgrades to the sqlalchemy/exc_filters.py and\nsqlalchemy/compat/handle_error.py compatibility layers to accommodate\nnew changes in SQLAlchemy 1.0.  SQLA 1.0 will now route errors that\noccur upon connect through the handle_error() event, just like any other,\nso that when 1.0 is present we no longer need to use\nexc_filters.handle_connect_error; the method becomes a passthrough\nas far as running the event handler.  Additionally, SQLAlchemy 1.0\nhas added the ""engine"" parameter to ExceptionContext, specifically\nto suit the case when the initial connect has failed and there is\nno Connection object; the compatibility layer here now emulates\nthis behavior for SQLAlchemy versions prior to 1.0.\n\nChange-Id: I61714f3c32625a621eaba501d20346519b8b12c7\n'}]",0,139725,32e5c6096a9523a0d22bbef2569181c281800313,12,4,4,11816,,,0,"Upgrade exc_filters for 'engine' argument and connect behavior

This patch applies upgrades to the sqlalchemy/exc_filters.py and
sqlalchemy/compat/handle_error.py compatibility layers to accommodate
new changes in SQLAlchemy 1.0.  SQLA 1.0 will now route errors that
occur upon connect through the handle_error() event, just like any other,
so that when 1.0 is present we no longer need to use
exc_filters.handle_connect_error; the method becomes a passthrough
as far as running the event handler.  Additionally, SQLAlchemy 1.0
has added the ""engine"" parameter to ExceptionContext, specifically
to suit the case when the initial connect has failed and there is
no Connection object; the compatibility layer here now emulates
this behavior for SQLAlchemy versions prior to 1.0.

Change-Id: I61714f3c32625a621eaba501d20346519b8b12c7
",git fetch https://review.opendev.org/openstack/oslo.db refs/changes/25/139725/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/db/sqlalchemy/exc_filters.py', 'oslo/db/sqlalchemy/compat/__init__.py', 'oslo/db/sqlalchemy/compat/handle_error.py', 'oslo/db/sqlalchemy/compat/utils.py']",4,552dd63fa7295d2c5373719537fc9b771e79dd70,fix_connect_filters_for_sqla_10,"sqla_100 = _SQLA_VERSION >= (1, 0, 0)",,66,26
openstack%2Fmurano-specs~master~I205d1e3cbc73bdcfdef8a916c0e2cc1c254d16dd,openstack/murano-specs,master,I205d1e3cbc73bdcfdef8a916c0e2cc1c254d16dd,rename spec file and correct identation problem,ABANDONED,2014-12-12 12:05:48.000000000,2014-12-12 12:45:38.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-12 12:05:48.000000000', 'files': ['specs/kilo/conf-language-support.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/993fe1b6b96237b85e883473d538b7e0c54c10c8', 'message': 'rename spec file and correct identation problem\n\nChange-Id: I205d1e3cbc73bdcfdef8a916c0e2cc1c254d16dd\n'}]",0,141343,993fe1b6b96237b85e883473d538b7e0c54c10c8,3,1,1,13931,,,0,"rename spec file and correct identation problem

Change-Id: I205d1e3cbc73bdcfdef8a916c0e2cc1c254d16dd
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/43/141343/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/conf-language-support.rst'],1,993fe1b6b96237b85e883473d538b7e0c54c10c8,specs/supportconfigurationlanguages,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Configuration Language Support ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/murano/+spec/conf-language-support Problem description =================== They are a huge community of applications (opscode, puppet-labs) where the deployment installations instructions are specified in configuration languages (puppet, chef). In order to reuse this community, some adaptors (chef adaptor and puppet adaptor) are required in the VM side, since current applications execute shell scripts Proposed change =============== Inclusion of new Application objects to be used by murano-agent. They can be called like PuppetApplication and ChefApplication for the configuration of software. Alternatives ------------ None Data model impact ----------------- ***TBD** REST API impact --------------- None Versioning impact ------------------------- None Other end user impact --------------------- None Deployer impact --------------- **TBD** Developer impact ---------------- **TBD** Murano-dashboard / Horizon impact --------------------------------- **TBD** Implementation ============== Assignee(s) ----------- **TBD** Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- **TBD** Dependencies ============ **TBD** Testing ======= **TBD** Documentation Impact ==================== **TBD** References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",,133,0
openstack%2Fmurano-specs~master~I871446350fdc32469083beb1060494ba08bb346d,openstack/murano-specs,master,I871446350fdc32469083beb1060494ba08bb346d,delete file,ABANDONED,2014-12-12 12:05:48.000000000,2014-12-12 12:45:01.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-12 12:05:48.000000000', 'files': ['specs/kilo/configurationlanguages.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/3dff6dba3a56f5d838bf9c06068e5e8396237095', 'message': 'delete file\n\nChange-Id: I871446350fdc32469083beb1060494ba08bb346d\n'}]",0,141344,3dff6dba3a56f5d838bf9c06068e5e8396237095,3,1,1,13931,,,0,"delete file

Change-Id: I871446350fdc32469083beb1060494ba08bb346d
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/44/141344/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/configurationlanguages.rst'],1,3dff6dba3a56f5d838bf9c06068e5e8396237095,specs/supportconfigurationlanguages,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Configuration Language Support ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/murano/+spec/conf-language-support Problem description =================== They are a huge community of applications (opscode, puppet-labs) where the deployment installations instructions are specified in configuration languages (puppet, chef). In order to reuse this community, some adaptors (chef adaptor and puppet adaptor) are required in the VM side, since current applications execute shell scripts Proposed change =============== Inclusion of new Application objects to be used by murano-agent. They can be called like PuppetApplication and ChefApplication for the configuration of software. Alternatives ------------ None Data model impact ----------------- ***TBD** REST API impact --------------- None Versioning impact ------------------------- None Other end user impact --------------------- None Deployer impact --------------- **TBD** Developer impact ---------------- **TBD** Murano-dashboard / Horizon impact --------------------------------- **TBD** Implementation ============== Assignee(s) ----------- **TBD** Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- **TBD** Dependencies ============ **TBD** Testing ======= **TBD** Documentation Impact ==================== **TBD** References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to ",0,133
openstack%2Foslo.serialization~master~Ia182d834cf3156f16f851ee7524e1713dd47425d,openstack/oslo.serialization,master,Ia182d834cf3156f16f851ee7524e1713dd47425d,Activate pep8 check that _ is imported,MERGED,2014-12-11 23:04:42.000000000,2014-12-12 12:44:33.000000000,2014-12-12 12:44:33.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 23:04:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/437eaf8db510a3263ce230ce0ae910388d480858', 'message': ""Activate pep8 check that _ is imported\n\nCurrently translatable messages are not used, so there are no uses\nof _.\n\nThis will ensure if _ is used in the future pep8 won't assume\nit is provided as a builtin.\n\nChange-Id: Ia182d834cf3156f16f851ee7524e1713dd47425d\n""}]",0,141203,437eaf8db510a3263ce230ce0ae910388d480858,7,3,1,6601,,,0,"Activate pep8 check that _ is imported

Currently translatable messages are not used, so there are no uses
of _.

This will ensure if _ is used in the future pep8 won't assume
it is provided as a builtin.

Change-Id: Ia182d834cf3156f16f851ee7524e1713dd47425d
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/03/141203/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,437eaf8db510a3263ce230ce0ae910388d480858,i18n_import,,builtins = _,0,1
openstack%2Ftempest~master~Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0,openstack/tempest,master,Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0,Make RestClientException independent,ABANDONED,2014-12-10 07:09:30.000000000,2014-12-12 12:44:04.000000000,,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5196}, {'_account_id': 6167}, {'_account_id': 8871}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/7c364974afb498579131d4a1e484130776c494dd', 'message': 'Make RestClientException independent\n\nRestClientException class will be moved to rest_client.py for\nimplementing common rest client in tempest-lib. Before doing that,\nthis patch makes RestClientException class independent from the\nTempest original class.\n\nChange-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0\n'}, {'number': 2, 'created': '2014-12-10 07:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/10bf6119e05a60ab7fbc73562020efbb51054e6a', 'message': 'Make RestClientException independent\n\nRestClientException class will be moved to rest_client.py for\nimplementing common rest client in tempest-lib. Before doing that,\nthis patch makes RestClientException class independent from the\nTempest original class.\n\nChange-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0\n'}, {'number': 3, 'created': '2014-12-10 08:08:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/325fd841471dbdc2b9ed5ed51ba78a69d1a6a536', 'message': 'Make RestClientException independent\n\nRestClientException class will be moved to rest_client.py for\nimplementing common rest client in tempest-lib. Before doing that,\nthis patch makes RestClientException class independent from the\nTempest original class.\n\nChange-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0\n'}, {'number': 4, 'created': '2014-12-10 08:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/c81badc824670d40ef24314ff77143a7cf9fd82f', 'message': 'Make RestClientException independent\n\nRestClientException class will be moved to rest_client.py for\nimplementing common rest client in tempest-lib. Before doing that,\nthis patch makes RestClientException class independent from the\nTempest original class.\n\nChange-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0\n'}, {'number': 5, 'created': '2014-12-10 13:56:32.000000000', 'files': ['tempest/exceptions.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/8769d5bd1bd6a1818d7ab16f898049e547a4dab4', 'message': 'Make RestClientException independent\n\nRestClientException class will be moved to rest_client.py for\nimplementing common rest client in tempest-lib. Before doing that,\nthis patch makes RestClientException class independent from the\nTempest original class.\n\nChange-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0\n'}]",3,140594,8769d5bd1bd6a1818d7ab16f898049e547a4dab4,20,6,5,6167,,,0,"Make RestClientException independent

RestClientException class will be moved to rest_client.py for
implementing common rest client in tempest-lib. Before doing that,
this patch makes RestClientException class independent from the
Tempest original class.

Change-Id: Iddfd5b4b10a750882ce4ebfe94804f9b83f4c4a0
",git fetch https://review.opendev.org/openstack/tempest refs/changes/94/140594/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/exceptions.py'],1,7c364974afb498579131d4a1e484130776c494dd,rest-client,"class RestClientException(testtools.TestCase.failureException): """""" Base Rest Client Exception To correctly use this class, inherit from it and define a 'message' property. That message will get printf'd with the keyword arguments provided to the constructor. """""" message = ""An unknown exception occurred"" def __init__(self, *args, **kwargs): super(RestClientException, self).__init__() try: self._error_string = self.message % kwargs except Exception: # at least get the core message out if something happened self._error_string = self.message if len(args) > 0: # If there is a non-kwarg parameter, assume it's the error # message or reason description and tack it on to the end # of the exception message # Convert all arguments into their string representations... args = [""%s"" % arg for arg in args] self._error_string = (self._error_string + ""\nDetails: %s"" % '\n'.join(args)) def __str__(self): return self._error_string","class RestClientException(TempestException, testtools.TestCase.failureException): pass",28,3
openstack%2Foslo.messaging~master~I52a8a8beb5b0d32647f52bb21abd5f7164dac2df,openstack/oslo.messaging,master,I52a8a8beb5b0d32647f52bb21abd5f7164dac2df,rabbit: add some tests when rpc_backend is set,MERGED,2014-12-04 07:36:20.000000000,2014-12-12 12:43:32.000000000,2014-12-12 12:43:31.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 8415}]","[{'number': 1, 'created': '2014-12-04 07:36:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1442af39a35f0dc4b3834b53980a8759afe7917b', 'message': 'rabbit: add some tests when rpc_backend is set\n\nThis change improves test coverage of the rabbit driver for new\nvalue allowed in rpc_backend config option.\n\nChange-Id: I52a8a8beb5b0d32647f52bb21abd5f7164dac2df\n'}, {'number': 2, 'created': '2014-12-04 07:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5a261bd18e66881e5b41fc6640efb6cf1bcb291d', 'message': 'rabbit: add some tests when rpc_backend is set\n\nThis change improves test coverage of the rabbit driver for new\nvalue allowed in rpc_backend config option.\n\nChange-Id: I52a8a8beb5b0d32647f52bb21abd5f7164dac2df\n'}, {'number': 3, 'created': '2014-12-04 08:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/7ac3f50d9730f69cb3119ad3c68a734843b49d83', 'message': 'rabbit: add some tests when rpc_backend is set\n\nThis change improves test coverage of the rabbit driver for new\nvalue allowed in rpc_backend config option.\n\nChange-Id: I52a8a8beb5b0d32647f52bb21abd5f7164dac2df\n'}, {'number': 4, 'created': '2014-12-11 07:15:44.000000000', 'files': ['tests/drivers/test_impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/98bfdd1d347ed795319bd7b4463133c5c6345a94', 'message': 'rabbit: add some tests when rpc_backend is set\n\nThis change improves test coverage of the rabbit driver for new\nvalue allowed in rpc_backend config option.\n\nChange-Id: I52a8a8beb5b0d32647f52bb21abd5f7164dac2df\n'}]",0,138974,98bfdd1d347ed795319bd7b4463133c5c6345a94,14,4,4,2813,,,0,"rabbit: add some tests when rpc_backend is set

This change improves test coverage of the rabbit driver for new
value allowed in rpc_backend config option.

Change-Id: I52a8a8beb5b0d32647f52bb21abd5f7164dac2df
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/74/138974/4 && git format-patch -1 --stdout FETCH_HEAD,['tests/drivers/test_impl_rabbit.py'],1,1442af39a35f0dc4b3834b53980a8759afe7917b,sileht/fake_rabbit," scenarios = [ ('rabbit', dict(transport_driver='rabbit', url='amqp://guest:guest@localhost:5672//')), ('kombu', dict(transport_driver='kombu', url='amqp://guest:guest@localhost:5672//')), ('rabbit+memory', dict(transport_driver='kombu+memory', url='memory:///')) ] self.messaging_conf.transport_driver = self.transport_driver driver = transport._driver url = driver._get_connection()._url self.assertIsInstance(driver, rabbit_driver.RabbitDriver) self.assertEqual(self.url, url)"," def setUp(self): super(TestRabbitDriverLoad, self).setUp() self.messaging_conf.transport_driver = 'rabbit' self.assertIsInstance(transport._driver, rabbit_driver.RabbitDriver)",14,4
openstack%2Foslo.rootwrap~master~Ifd514de79f8c82bb2423d9e7e7f8479f16d5f71c,openstack/oslo.rootwrap,master,Ifd514de79f8c82bb2423d9e7e7f8479f16d5f71c,Activate pep8 check that _ is imported,MERGED,2014-12-11 23:01:01.000000000,2014-12-12 12:41:08.000000000,2014-12-12 12:41:08.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2813}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 23:01:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.rootwrap/commit/c651d837a716dfbbb68fb44d5789e9c4384a0bd1', 'message': ""Activate pep8 check that _ is imported\n\nCurrently translatable messages are not used, so there are no uses\nof _.\n\nThis will ensure if _ is used in the future pep8 won't assume\nit is provided as a builtin.\n\nChange-Id: Ifd514de79f8c82bb2423d9e7e7f8479f16d5f71c\n""}]",0,141202,c651d837a716dfbbb68fb44d5789e9c4384a0bd1,8,4,1,6601,,,0,"Activate pep8 check that _ is imported

Currently translatable messages are not used, so there are no uses
of _.

This will ensure if _ is used in the future pep8 won't assume
it is provided as a builtin.

Change-Id: Ifd514de79f8c82bb2423d9e7e7f8479f16d5f71c
",git fetch https://review.opendev.org/openstack/oslo.rootwrap refs/changes/02/141202/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c651d837a716dfbbb68fb44d5789e9c4384a0bd1,i18n_import,,builtins = _,0,1
openstack%2Ftempest~master~I33db1b937efc6393d979da6c3f6b55cf31b5779c,openstack/tempest,master,I33db1b937efc6393d979da6c3f6b55cf31b5779c,Remove unused TOKEN_CHARS_RE,MERGED,2014-12-10 07:09:30.000000000,2014-12-12 12:36:34.000000000,2014-12-10 16:32:34.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 8556}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 07:09:30.000000000', 'files': ['tempest/common/rest_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/5f93d37ed1756998ce4ee2368e74bb600f7d5cdc', 'message': 'Remove unused TOKEN_CHARS_RE\n\nTOKEN_CHARS_RE is not used in rest_client.py, and this patch\nremoves it.\n\nChange-Id: I33db1b937efc6393d979da6c3f6b55cf31b5779c\n'}]",0,140589,5f93d37ed1756998ce4ee2368e74bb600f7d5cdc,8,4,1,6167,,,0,"Remove unused TOKEN_CHARS_RE

TOKEN_CHARS_RE is not used in rest_client.py, and this patch
removes it.

Change-Id: I33db1b937efc6393d979da6c3f6b55cf31b5779c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/89/140589/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/common/rest_client.py'],1,5f93d37ed1756998ce4ee2368e74bb600f7d5cdc,rest-client,,TOKEN_CHARS_RE = re.compile('^[-A-Za-z0-9+/=]*$'),0,1
openstack%2Fmagnum~master~I4977f830e1f5816352da8f5f1e697d277577896a,openstack/magnum,master,I4977f830e1f5816352da8f5f1e697d277577896a,Add heat client,MERGED,2014-12-12 08:35:16.000000000,2014-12-12 12:23:44.000000000,2014-12-12 12:23:44.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-12 08:35:16.000000000', 'files': ['magnum/tests/common/test_heat.py', 'requirements.txt', 'magnum/common/heat.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/99509fa5ce2ed38fef206ced67a74ca67703f0e0', 'message': 'Add heat client\n\nThis client will be used to create a bay.\n\nChange-Id: I4977f830e1f5816352da8f5f1e697d277577896a\n'}]",0,141305,99509fa5ce2ed38fef206ced67a74ca67703f0e0,6,2,1,12385,,,0,"Add heat client

This client will be used to create a bay.

Change-Id: I4977f830e1f5816352da8f5f1e697d277577896a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/05/141305/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/common/test_heat.py', 'requirements.txt', 'magnum/common/heat.py']",3,99509fa5ce2ed38fef206ced67a74ca67703f0e0,impl-heatbay,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from heatclient import client as heatclient from oslo.config import cfg from magnum.common import exception from magnum.common import keystone from magnum.openstack.common._i18n import _ from magnum.openstack.common import log as logging LOG = logging.getLogger(__name__) heat_client_opts = [ cfg.StrOpt('endpoint_type', default='publicURL', help=_( 'Type of endpoint in Identity service catalog to use ' 'for communication with the OpenStack service.')), cfg.StrOpt('ca_file', help=_('Optional CA cert file to use in SSL connections.')), cfg.StrOpt('cert_file', help=_('Optional PEM-formatted certificate chain file.')), cfg.StrOpt('key_file', help=_('Optional PEM-formatted file that contains the ' 'private key.')), cfg.BoolOpt('insecure', default=False, help=_(""If set, then the server's certificate will not "" ""be verified.""))] cfg.CONF.register_opts(heat_client_opts, group='heat_client') cfg.CONF.import_opt('auth_uri', 'keystonemiddleware.auth_token', group='keystone_authtoken') cfg.CONF.import_opt('auth_version', 'keystonemiddleware.auth_token', group='keystone_authtoken') @exception.wrap_keystone_exception def get_client(context): endpoint_type = cfg.CONF.heat_client.endpoint_type auth_url = cfg.CONF.keystone_authtoken.auth_uri, auth_version = cfg.CONF.keystone_authtoken.auth_version auth_url = keystone.get_keystone_url(auth_url, auth_version) args = { 'auth_url': auth_url, 'token': context.auth_token, 'username': None, 'password': None, 'ca_file': cfg.CONF.heat_client.ca_file, 'cert_file': cfg.CONF.heat_client.cert_file, 'key_file': cfg.CONF.heat_client.key_file, 'insecure': cfg.CONF.heat_client.insecure } endpoint = keystone.get_service_url(service_type='orchestration', endpoint_type=endpoint_type) return heatclient.Client('1', endpoint, **args) ",,119,0
openstack%2Fmagnum~master~Ib075148afb0ddf503e71b333cef85523561a2732,openstack/magnum,master,Ib075148afb0ddf503e71b333cef85523561a2732,Add keystone client,MERGED,2014-12-12 07:40:19.000000000,2014-12-12 12:23:38.000000000,2014-12-12 12:23:38.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-12 07:40:19.000000000', 'files': ['magnum/tests/base.py', 'magnum/common/keystone.py', 'magnum/common/exception.py', 'magnum/tests/common/test_keystone.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/6919cad7733d4e5d63382e41b760397551aa5c93', 'message': 'Add keystone client\n\nThis client will be used by novaclient and heatclient to create a bay.\nThe original sources are come from Ironic.\n\nChange-Id: Ib075148afb0ddf503e71b333cef85523561a2732\n'}]",0,141290,6919cad7733d4e5d63382e41b760397551aa5c93,6,2,1,12385,,,0,"Add keystone client

This client will be used by novaclient and heatclient to create a bay.
The original sources are come from Ironic.

Change-Id: Ib075148afb0ddf503e71b333cef85523561a2732
",git fetch https://review.opendev.org/openstack/magnum refs/changes/90/141290/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/base.py', 'magnum/common/keystone.py', 'magnum/common/exception.py', 'magnum/tests/common/test_keystone.py']",4,6919cad7733d4e5d63382e41b760397551aa5c93,impl-heatbay,"# -*- encoding: utf-8 -*- # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from keystoneclient import exceptions as ksexception import mock from magnum.common import exception from magnum.common import keystone from magnum.tests import base class FakeCatalog: def url_for(self, **kwargs): return 'fake-url' class FakeClient: def __init__(self, **kwargs): self.service_catalog = FakeCatalog() def has_service_catalog(self): return True class KeystoneTestCase(base.TestCase): def setUp(self): super(KeystoneTestCase, self).setUp() self.config(group='keystone_authtoken', auth_uri='http://127.0.0.1:9898/', admin_user='fake', admin_password='fake', admin_tenant_name='fake') def test_failure_authorization(self): self.assertRaises(exception.KeystoneFailure, keystone.get_service_url) @mock.patch.object(FakeCatalog, 'url_for') @mock.patch('keystoneclient.v2_0.client.Client') def test_get_url(self, mock_ks, mock_uf): fake_url = 'http://127.0.0.1:6385' mock_uf.return_value = fake_url mock_ks.return_value = FakeClient() res = keystone.get_service_url() self.assertEqual(fake_url, res) @mock.patch.object(FakeCatalog, 'url_for') @mock.patch('keystoneclient.v2_0.client.Client') def test_url_not_found(self, mock_ks, mock_uf): mock_uf.side_effect = ksexception.EndpointNotFound mock_ks.return_value = FakeClient() self.assertRaises(exception.CatalogNotFound, keystone.get_service_url) @mock.patch.object(FakeClient, 'has_service_catalog') @mock.patch('keystoneclient.v2_0.client.Client') def test_no_catalog(self, mock_ks, mock_hsc): mock_hsc.return_value = False mock_ks.return_value = FakeClient() self.assertRaises(exception.KeystoneFailure, keystone.get_service_url) @mock.patch('keystoneclient.v2_0.client.Client') def test_unauthorized(self, mock_ks): mock_ks.side_effect = ksexception.Unauthorized self.assertRaises(exception.KeystoneUnauthorized, keystone.get_service_url) def test_get_service_url_fail_missing_auth_uri(self): self.config(group='keystone_authtoken', auth_uri=None) self.assertRaises(exception.KeystoneFailure, keystone.get_service_url) @mock.patch('keystoneclient.v2_0.client.Client') def test_get_service_url_versionless_v2(self, mock_ks): mock_ks.return_value = FakeClient() self.config(group='keystone_authtoken', auth_uri='http://127.0.0.1') expected_url = 'http://127.0.0.1/v2.0' keystone.get_service_url() mock_ks.assert_called_once_with(username='fake', password='fake', tenant_name='fake', auth_url=expected_url) @mock.patch('keystoneclient.v3.client.Client') def test_get_service_url_versionless_v3(self, mock_ks): mock_ks.return_value = FakeClient() self.config(group='keystone_authtoken', auth_version='v3.0', auth_uri='http://127.0.0.1') expected_url = 'http://127.0.0.1/v3' keystone.get_service_url() mock_ks.assert_called_once_with(username='fake', password='fake', tenant_name='fake', auth_url=expected_url) @mock.patch('keystoneclient.v2_0.client.Client') def test_get_service_url_version_override(self, mock_ks): mock_ks.return_value = FakeClient() self.config(group='keystone_authtoken', auth_uri='http://127.0.0.1/v2.0/') expected_url = 'http://127.0.0.1/v2.0' keystone.get_service_url() mock_ks.assert_called_once_with(username='fake', password='fake', tenant_name='fake', auth_url=expected_url) @mock.patch('keystoneclient.v2_0.client.Client') def test_get_admin_auth_token(self, mock_ks): fake_client = FakeClient() fake_client.auth_token = '123456' mock_ks.return_value = fake_client self.assertEqual('123456', keystone.get_admin_auth_token()) ",,270,1
openstack%2Fmagnum~master~I8100c59a5608da2703860da0ba3e6628971af5f1,openstack/magnum,master,I8100c59a5608da2703860da0ba3e6628971af5f1,Fix failing creation of MagnumException subclasses,MERGED,2014-12-12 05:58:13.000000000,2014-12-12 12:23:14.000000000,2014-12-12 12:23:13.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-12 05:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/70e188a347bd9f925971861f04f35e2120075257', 'message': 'Fix failing creation of MagnumException subclasses\n\nChange-Id: I8100c59a5608da2703860da0ba3e6628971af5f1\n'}, {'number': 2, 'created': '2014-12-12 06:01:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9fce08636fa45b027dc68722f1b79a34ce8c942f', 'message': 'Fix failing creation of MagnumException subclasses\n\nChange-Id: I8100c59a5608da2703860da0ba3e6628971af5f1\n'}, {'number': 3, 'created': '2014-12-12 07:07:16.000000000', 'files': ['magnum/tests/common/test_exception.py', 'magnum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/bb5615495a18e7a97f1c2a3c977c20f350fa28a4', 'message': 'Fix failing creation of MagnumException subclasses\n\nChange-Id: I8100c59a5608da2703860da0ba3e6628971af5f1\n'}]",0,141276,bb5615495a18e7a97f1c2a3c977c20f350fa28a4,10,2,3,12385,,,0,"Fix failing creation of MagnumException subclasses

Change-Id: I8100c59a5608da2703860da0ba3e6628971af5f1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/76/141276/3 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/common/test_exception.py', 'magnum/common/exception.py']",2,70e188a347bd9f925971861f04f35e2120075257,fix-exception," msg_fmt = _('Unsupported object type %(objtype)s') msg_fmt = _('Version %(objver)s of %(objname)s is not supported') msg_fmt = _('Cannot call %(method)s on orphaned %(objtype)s object') msg_fmt = _(""Unacceptable parameters."") msg_fmt = _(""Expected a uuid but received %(uuid)s."") msg_fmt = _(""Expected an uuid or int but received %(identity)s."") msg_fmt = _('Conflict.') msg_fmt = _(""Unacceptable parameters."") msg_fmt = _(""Invalid resource state."") msg_fmt = _(""%(err)s"") msg_fmt = _(""Instance %(instance_uuid)s is already associated with a node,"" msg_fmt = _(""Instance %(instance)s could not be found."") msg_fmt = _(""Couldn't apply patch '%(patch)s'. Reason: %(reason)s"") msg_fmt = _(""Not authorized."") msg_fmt = _(""Operation not permitted."") msg_fmt = _(""Expected a MAC address but received %(mac)s."") msg_fmt = _(""Failed to establish SSH connection to host %(host)s."") msg_fmt = _(""Failed to create a file system. "" msg_fmt = _(""Bay %(bay)s could not be found."") msg_fmt = _(""Bay %(bay)s is associated with instance %(instance)s."") msg_fmt = _(""A node with UUID %(uuid)s already exists."") msg_fmt = _(""Bay %(bay)s is locked by host %(host)s, please retry "" msg_fmt = _(""Bay %(bay)s found not to be locked on release"") msg_fmt = _(""Container %(container)s could not be found."") msg_fmt = _(""Container %(container)s is associated with "" msg_fmt = _(""A node with UUID %(uuid)s already exists."") msg_fmt = _(""Container %(container)s is locked by host %(host)s, "" msg_fmt = _(""Container %(container)s found not to be locked on release"") msg_fmt = _(""Pod %(pod)s could not be found."") msg_fmt = _(""Pod %(pod)s is associated with instance %(instance)s."") msg_fmt = _(""A node with UUID %(uuid)s already exists."") msg_fmt = _(""Pod %(pod)s is locked by host %(host)s, please retry "" msg_fmt = _(""Pod %(pod)s found not to be locked on release"") msg_fmt = _(""Service %(service)s could not be found."") msg_fmt = _(""Service %(service)s is associated with "" msg_fmt = _(""A node with UUID %(uuid)s already exists."") msg_fmt = _(""Service %(service)s is locked by host %(host)s, please retry "" msg_fmt = _(""Service %(service)s found not to be locked on release"")"," message = _('Unsupported object type %(objtype)s') message = _('Version %(objver)s of %(objname)s is not supported') message = _('Cannot call %(method)s on orphaned %(objtype)s object') message = _(""Unacceptable parameters."") message = _(""Expected a uuid but received %(uuid)s."") message = _(""Expected an uuid or int but received %(identity)s."") message = _('Conflict.') message = _(""Unacceptable parameters."") message = _(""Invalid resource state."") message = _(""%(err)s"") message = _(""Instance %(instance_uuid)s is already associated with a node,"" message = _(""Instance %(instance)s could not be found."") message = _(""Couldn't apply patch '%(patch)s'. Reason: %(reason)s"") message = _(""Not authorized."") message = _(""Operation not permitted."") message = _(""Expected a MAC address but received %(mac)s."") message = _(""Failed to establish SSH connection to host %(host)s."") message = _(""Failed to create a file system. "" message = _(""Bay %(bay)s could not be found."") message = _(""Bay %(bay)s is associated with instance %(instance)s."") message = _(""A node with UUID %(uuid)s already exists."") message = _(""Bay %(bay)s is locked by host %(host)s, please retry "" message = _(""Bay %(bay)s found not to be locked on release"") message = _(""Container %(container)s could not be found."") message = _(""Container %(container)s is associated with "" message = _(""A node with UUID %(uuid)s already exists."") message = _(""Container %(container)s is locked by host %(host)s, "" message = _(""Container %(container)s found not to be locked on release"") message = _(""Pod %(pod)s could not be found."") message = _(""Pod %(pod)s is associated with instance %(instance)s."") message = _(""A node with UUID %(uuid)s already exists."") message = _(""Pod %(pod)s is locked by host %(host)s, please retry "" message = _(""Pod %(pod)s found not to be locked on release"") message = _(""Service %(service)s could not be found."") message = _(""Service %(service)s is associated with "" message = _(""A node with UUID %(uuid)s already exists."") message = _(""Service %(service)s is locked by host %(host)s, please retry "" message = _(""Service %(service)s found not to be locked on release"")",237,38
openstack%2Fheat~master~I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e,openstack/heat,master,I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e,Move basic instance group functional tests,MERGED,2014-12-09 06:16:28.000000000,2014-12-12 12:23:04.000000000,2014-12-12 12:23:02.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 6577}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 06:16:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f64803e198fd95e645b155f615421d69468f2365', 'message': 'Move basic instance group functional tests\n\nChange-Id: I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e\n'}, {'number': 2, 'created': '2014-12-10 08:02:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5f1e64bf7768990cf876610c973f2c9df664ff2c', 'message': 'Move basic instance group functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e\n'}, {'number': 3, 'created': '2014-12-10 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/310dba020cc0ecd61f26153aafd81d1dbc865e91', 'message': 'Move basic instance group functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e\n'}, {'number': 4, 'created': '2014-12-11 10:17:36.000000000', 'files': ['heat_integrationtests/functional/test_instance_group.py', 'heat/tests/test_instance_group.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/595ba546c05e84a584c90e6b0e24759cf4330449', 'message': 'Move basic instance group functional tests\n\nPart of blueprint decouple-nested\nChange-Id: I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e\n'}]",1,140246,595ba546c05e84a584c90e6b0e24759cf4330449,24,5,4,4715,,,0,"Move basic instance group functional tests

Part of blueprint decouple-nested
Change-Id: I6cb85c506a56d2fc2b8a22d1a207cfc67ee85f1e
",git fetch https://review.opendev.org/openstack/heat refs/changes/46/140246/4 && git format-patch -1 --stdout FETCH_HEAD,"['heat_integrationtests/functional/test_instance_group.py', 'heat/tests/test_instance_group.py']",2,f64803e198fd95e645b155f615421d69468f2365,bug/1360292,," def test_basic_create_works(self): """"""Make sure the working case is good."""""" t = template_format.parse(ig_template) stack = utils.parse_stack(t) # start with min then delete self._stub_create(1) self.m.StubOutWithMock(instance.Instance, 'FnGetAtt') instance.Instance.FnGetAtt('PublicIp').AndReturn('1.2.3.4') self.m.ReplayAll() lc_rsrc = self.create_resource(t, stack, 'JobServerConfig') # check bdm in configuration self.assertIsNotNone(lc_rsrc.properties['BlockDeviceMappings']) rsrc = self.create_resource(t, stack, 'JobServerGroup') self.assertEqual(utils.PhysName(stack.name, rsrc.name), rsrc.FnGetRefId()) self.assertEqual('1.2.3.4', rsrc.FnGetAtt('InstanceList')) # check bdm in instance_definition instance_definition = rsrc._get_instance_definition() self.assertIn('BlockDeviceMappings', instance_definition['Properties']) nested = rsrc.nested() self.assertEqual(rsrc.resource_id, nested.id) rsrc.delete() self.m.VerifyAll() def test_override_aws_ec2_instance(self): """""" If AWS::EC2::Instance is overridden, InstanceGroup will automatically use that overridden resource type. """""" # resources may need to be initialised if this is the first test run. resources.initialise() class MyInstance(instance.Instance): """"""A customized Instance resource."""""" original_instance = resources.global_env().get_class( ""AWS::EC2::Instance"") resource._register_class(""AWS::EC2::Instance"", MyInstance) self.addCleanup(resource._register_class, ""AWS::EC2::Instance"", original_instance) t = template_format.parse(ig_template) stack = utils.parse_stack(t) self._stub_create(1, instance_class=MyInstance) self.m.ReplayAll() self.create_resource(t, stack, 'JobServerConfig') rsrc = self.create_resource(t, stack, 'JobServerGroup') self.assertEqual(utils.PhysName(stack.name, rsrc.name), rsrc.FnGetRefId()) rsrc.delete() self.m.VerifyAll() ",128,60
openstack%2Foslotest~master~I5b840eaf1a55d3df40ed56af19ea7349f167b5a9,openstack/oslotest,master,I5b840eaf1a55d3df40ed56af19ea7349f167b5a9,Activate pep8 check that _ is imported,MERGED,2014-12-11 23:09:35.000000000,2014-12-12 12:18:51.000000000,2014-12-12 12:18:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 23:09:35.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslotest/commit/28f55cb1d09377a64f7792792931d4eb9601234b', 'message': ""Activate pep8 check that _ is imported\n\nCurrently translatable messages are not used, so there are no uses\nof _.\n\nThis will ensure if _ is used in the future pep8 won't assume\nit is provided as a builtin, and to be consistent with the rest of\noslo.\n\nChange-Id: I5b840eaf1a55d3df40ed56af19ea7349f167b5a9\n""}]",0,141205,28f55cb1d09377a64f7792792931d4eb9601234b,7,3,1,6601,,,0,"Activate pep8 check that _ is imported

Currently translatable messages are not used, so there are no uses
of _.

This will ensure if _ is used in the future pep8 won't assume
it is provided as a builtin, and to be consistent with the rest of
oslo.

Change-Id: I5b840eaf1a55d3df40ed56af19ea7349f167b5a9
",git fetch https://review.opendev.org/openstack/oslotest refs/changes/05/141205/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,28f55cb1d09377a64f7792792931d4eb9601234b,i18n_import,,builtins = _,0,1
openstack%2Ftempest~master~Ia1ed4ab3cd2e4941fb072b3390f4859420989e74,openstack/tempest,master,Ia1ed4ab3cd2e4941fb072b3390f4859420989e74,Remove network debug,MERGED,2014-12-10 00:02:02.000000000,2014-12-12 12:13:13.000000000,2014-12-11 08:53:54.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 00:02:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/f4dbdbecf9cf915e869a09cefbd09eddff94826a', 'message': 'Remove network debug\n\nThis commit removes all of the network debugging gorp usage from\ntempest. These were added as a crutch over a year ago to enable\nreal neutron testing in the gate, which was impossible to debug\nat the time. This debug info is an inherent layer violation in tempest\nwhich is only supposed to be black-box and not care about any of the\nunderlying internals. It also assumes a single host environment and\nthat tempest is running on that machine, which is mostly specific to\nthe gate and devtest setups. Additionally the amount of output on a\nfailure is staggering to the point where keeping this around is\ncounter-productive. If we are unable to debug issues at this point\nneutron needs to improve their logging so people can figure out what\nfailed.\n\nChange-Id: Ia1ed4ab3cd2e4941fb072b3390f4859420989e74\n'}, {'number': 2, 'created': '2014-12-10 00:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45ead3236833d5947073ff447e9522c715ea4c03', 'message': 'Remove network debug\n\nThis commit removes all of the network debugging gorp usage from\ntempest. These were added as a crutch over a year ago to enable\nreal neutron testing in the gate, which was impossible to debug\nat the time. This debug info is an inherent layer violation in tempest\nwhich is only supposed to be black-box and not care about any of the\nunderlying internals. It also assumes a single host environment and\nthat tempest is running on that machine, which is mostly specific to\nthe gate and devtest setups. Additionally the amount of output on a\nfailure is staggering to the point where keeping this around is\ncounter-productive. If we are unable to debug issues at this point\nneutron needs to improve their logging so people can figure out what\nfailed.\n\nChange-Id: Ia1ed4ab3cd2e4941fb072b3390f4859420989e74\n'}, {'number': 3, 'created': '2014-12-10 01:28:18.000000000', 'files': ['tempest/tests/common/test_debug.py', 'tempest/scenario/manager.py', 'tempest/common/commands.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/common/debug.py', 'tempest/config.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/tests/test_commands.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/53483137c70dfeebff3c53c6f841ea55f9cca679', 'message': 'Remove network debug\n\nThis commit removes all of the network debugging gorp usage from\ntempest. These were added as a crutch over a year ago to enable\nreal neutron testing in the gate, which was impossible to debug\nat the time. This debug info is an inherent layer violation in tempest\nwhich is only supposed to be black-box and not care about any of the\nunderlying internals. It also assumes a single host environment and\nthat tempest is running on that machine, which is mostly specific to\nthe gate and devtest setups. Additionally the amount of output on a\nfailure is staggering to the point where keeping this around is\ncounter-productive. If we are unable to debug issues at this point\nneutron needs to improve their logging so people can figure out what\nfailed.\n\nChange-Id: Ia1ed4ab3cd2e4941fb072b3390f4859420989e74\n'}]",0,140531,53483137c70dfeebff3c53c6f841ea55f9cca679,14,5,3,5196,,,0,"Remove network debug

This commit removes all of the network debugging gorp usage from
tempest. These were added as a crutch over a year ago to enable
real neutron testing in the gate, which was impossible to debug
at the time. This debug info is an inherent layer violation in tempest
which is only supposed to be black-box and not care about any of the
underlying internals. It also assumes a single host environment and
that tempest is running on that machine, which is mostly specific to
the gate and devtest setups. Additionally the amount of output on a
failure is staggering to the point where keeping this around is
counter-productive. If we are unable to debug issues at this point
neutron needs to improve their logging so people can figure out what
failed.

Change-Id: Ia1ed4ab3cd2e4941fb072b3390f4859420989e74
",git fetch https://review.opendev.org/openstack/tempest refs/changes/31/140531/2 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/tests/common/test_debug.py', 'tempest/common/commands.py', 'tempest/scenario/manager.py', 'tempest/scenario/test_network_basic_ops.py', 'etc/tempest.conf.sample', 'tempest/common/debug.py', 'tempest/config.py', 'tempest/scenario/test_security_groups_basic_ops.py', 'tempest/tests/test_commands.py']",9,f4dbdbecf9cf915e869a09cefbd09eddff94826a,kill-net-debug,,"# Copyright 2014 NEC Corporation. All rights reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import subprocess import mock from tempest.common import commands from tempest.tests import base class TestCommands(base.TestCase): def setUp(self): super(TestCommands, self).setUp() self.subprocess_args = {'stdout': subprocess.PIPE, 'stderr': subprocess.STDOUT} @mock.patch('subprocess.Popen') def test_ip_addr_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'a'] commands.ip_addr_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_route_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'r'] commands.ip_route_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_raw(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'list'] commands.ip_ns_raw() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_iptables_raw(self, mock): table = 'filter' expected = ['/usr/bin/sudo', '-n', 'iptables', '--line-numbers', '-L', '-nv', '-t', '%s' % table] commands.iptables_raw(table) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_list(self, mock): expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'list'] commands.ip_ns_list() mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_addr(self, mock): ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'ip', 'a'] commands.ip_ns_addr(ns) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_ip_ns_route(self, mock): ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'ip', 'r'] commands.ip_ns_route(ns) mock.assert_called_once_with(expected, **self.subprocess_args) @mock.patch('subprocess.Popen') def test_iptables_ns(self, mock): table = 'filter' ns_list = commands.ip_ns_list() for ns in ns_list: expected = ['/usr/bin/sudo', '-n', 'ip', 'netns', 'exec', ns, 'iptables', '-v', '-S', '-t', table] commands.iptables_ns(ns, table) mock.assert_called_once_with(expected, **self.subprocess_args) ",0,339
openstack%2Fos-loganalyze~master~I0d67ad6e1e77cee9d2a7359f20cb59a60cdab1a4,openstack/os-loganalyze,master,I0d67ad6e1e77cee9d2a7359f20cb59a60cdab1a4,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:54:24.000000000,2014-12-12 12:11:26.000000000,2014-12-12 12:11:25.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-12-05 03:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/9e37d0881dc79deddc42b1e8562dc086d800f24d', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I0d67ad6e1e77cee9d2a7359f20cb59a60cdab1a4\n'}, {'number': 2, 'created': '2014-12-05 20:03:57.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/os-loganalyze/commit/607a35253bd584632c9d6fc70abefbaf1c70b673', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I0d67ad6e1e77cee9d2a7359f20cb59a60cdab1a4\n'}]",0,139427,607a35253bd584632c9d6fc70abefbaf1c70b673,14,6,2,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I0d67ad6e1e77cee9d2a7359f20cb59a60cdab1a4
",git fetch https://review.opendev.org/openstack/os-loganalyze refs/changes/27/139427/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,9e37d0881dc79deddc42b1e8562dc086d800f24d,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Ftempest~master~I303d15cdf9fb458df49e4b8eaf3adc41226bf176,openstack/tempest,master,I303d15cdf9fb458df49e4b8eaf3adc41226bf176,Check that the number of fixed_ips is at least one,MERGED,2014-12-09 23:41:36.000000000,2014-12-12 12:10:07.000000000,2014-12-10 19:45:19.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 23:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a4f1f5bb1de5a74844926e3126b96b48b837c24', 'message': 'Check IP version to determine number of expected fixed ips\n\nIn DevStack-Gate, we are attempting to run dual stacked, so even when\nrunning IPv6 tests, an IPv4 address will be present.\n\nChange-Id: I303d15cdf9fb458df49e4b8eaf3adc41226bf176\nDepends-On: I3d416275f77913769b98e77f7e47bed17fc4d1cc\n'}, {'number': 2, 'created': '2014-12-10 00:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/edcbf180240d3f4f8359ef473b1ba3744a969ce8', 'message': 'Check IP version to determine number of expected fixed ips\n\nIn DevStack-Gate, we are attempting to run dual stacked, so even when\nrunning IPv6 tests, an IPv4 address will be present.\n\nChange-Id: I303d15cdf9fb458df49e4b8eaf3adc41226bf176\nRequired-By: I3d416275f77913769b98e77f7e47bed17fc4d1cc\n'}, {'number': 3, 'created': '2014-12-10 00:20:33.000000000', 'files': ['tempest/api/network/test_routers.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/08803f64e68a05c2b73367aded5de088a47769a7', 'message': 'Check that the number of fixed_ips is at least one\n\nIn DevStack-Gate, we are attempting to run dual stacked, so even when\nrunning IPv6 tests, an IPv4 address will be present.\n\nChange-Id: I303d15cdf9fb458df49e4b8eaf3adc41226bf176\nRequired-By: I3d416275f77913769b98e77f7e47bed17fc4d1cc\n'}]",3,140528,08803f64e68a05c2b73367aded5de088a47769a7,13,5,3,4656,,,0,"Check that the number of fixed_ips is at least one

In DevStack-Gate, we are attempting to run dual stacked, so even when
running IPv6 tests, an IPv4 address will be present.

Change-Id: I303d15cdf9fb458df49e4b8eaf3adc41226bf176
Required-By: I3d416275f77913769b98e77f7e47bed17fc4d1cc
",git fetch https://review.opendev.org/openstack/tempest refs/changes/28/140528/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/network/test_routers.py'],1,6a4f1f5bb1de5a74844926e3126b96b48b837c24,network_tests_refactor," cls.expected_fixed_ip_count = (1 if cls._ip_version == 4 else 2) self.assertEqual(len(fixed_ips), self.expected_fixed_ip_count)"," self.assertEqual(len(fixed_ips), 1)",2,1
openstack%2Fnose-html-output~master~I30671e48bf8086211e6bc64deabb9e637796925c,openstack/nose-html-output,master,I30671e48bf8086211e6bc64deabb9e637796925c,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:54:18.000000000,2014-12-12 12:10:04.000000000,2014-12-12 12:10:04.000000000,"[{'_account_id': 3}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 6609}, {'_account_id': 6786}, {'_account_id': 7069}]","[{'number': 1, 'created': '2014-12-05 03:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nose-html-output/commit/3006f5c84ca7fd905387a4d5d4357169acf44d77', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I30671e48bf8086211e6bc64deabb9e637796925c\n'}, {'number': 2, 'created': '2014-12-05 19:59:38.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/nose-html-output/commit/4e71a5434fa6ef017c0651f7c49d2414b27eec9c', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I30671e48bf8086211e6bc64deabb9e637796925c\n'}]",0,139426,4e71a5434fa6ef017c0651f7c49d2414b27eec9c,14,6,2,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I30671e48bf8086211e6bc64deabb9e637796925c
",git fetch https://review.opendev.org/openstack/nose-html-output refs/changes/26/139426/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,3006f5c84ca7fd905387a4d5d4357169acf44d77,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Ftempest~master~I4064e134493085d90a0f0967b7b9ad640aadf75c,openstack/tempest,master,I4064e134493085d90a0f0967b7b9ad640aadf75c,Skip test_update_router_admin_state for baremetal,MERGED,2014-12-09 22:16:33.000000000,2014-12-12 12:06:54.000000000,2014-12-10 20:32:26.000000000,"[{'_account_id': 3}, {'_account_id': 1192}, {'_account_id': 5174}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-09 22:16:33.000000000', 'files': ['tempest/scenario/test_network_basic_ops.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/cf61121ac27f70ad7f66770f2d41d29328e161de', 'message': 'Skip test_update_router_admin_state for baremetal\n\nThe baremetal deployment relies on a flat network without tenant isolation.\nThe router servicing this single network should not be taken up and down,\nespecially if there are other tests running that may be accessing things\nvia public IP.  This is accounted for already during network/router/subnet\ncreation, but this test needs to be skipped as well.\n\nChange-Id: I4064e134493085d90a0f0967b7b9ad640aadf75c\nCloses-bug: #1400902\n'}]",0,140499,cf61121ac27f70ad7f66770f2d41d29328e161de,9,5,1,1420,,,0,"Skip test_update_router_admin_state for baremetal

The baremetal deployment relies on a flat network without tenant isolation.
The router servicing this single network should not be taken up and down,
especially if there are other tests running that may be accessing things
via public IP.  This is accounted for already during network/router/subnet
creation, but this test needs to be skipped as well.

Change-Id: I4064e134493085d90a0f0967b7b9ad640aadf75c
Closes-bug: #1400902
",git fetch https://review.opendev.org/openstack/tempest refs/changes/99/140499/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/scenario/test_network_basic_ops.py'],1,cf61121ac27f70ad7f66770f2d41d29328e161de,1400902," @testtools.skipIf(CONF.baremetal.driver_enabled, 'Router state cannot be altered on a shared baremetal ' 'network')",,3,0
openstack%2Fnova~master~I628ae22db08140b1675f90c29c7113fa17ec468a,openstack/nova,master,I628ae22db08140b1675f90c29c7113fa17ec468a,Improve performance of Unshelve api,ABANDONED,2014-12-10 10:53:59.000000000,2014-12-12 12:06:06.000000000,,"[{'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2014-12-10 10:53:59.000000000', 'files': ['nova/scheduler/filters/host_aggregate_group_filter.py', 'nova/scheduler/filter_scheduler.py', 'nova/compute/task_states.py', 'nova/compute/vm_states.py', 'nova/api/openstack/common.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/7d57920622dee85246462b2fa6001d46343d2744', 'message': 'Improve performance of Unshelve api\n\nImproved the performance of unshelve instance by eliminating\ndownloading/copying snapshot time. All instance files will be retained in\nthe instance store backed by NFS on the compute node when an instance is\nshelved. An existing configuration parameter “shelved_offload_time"" is used\nhere to indicate the instance files shouldn’t be deleted.\n\n-1, never offload (CPU/Memory/Disks resources are not released).\n0, offload when shelved (CPU/Memory/Disks resources are not released).\n> 0, offload using “_poll_shelved_instances” periodic task\n(CPU/Memory/Disks resources are not released).\n\nNew value will be added\n-2, offload partially, release CPU/Memory but retain instance files.\n\nAdded new VM state \'SHELVED_PARTIAL_OFFLOADED\' and new Task state\n\'SHELVING_PARTIAL_OFFLOADING\', so user can identify by VM status\nthat, instance is partially offloaded and instance files are persisted\non the host.\n\nNote:\nTo use this feature, You must configure instance path on NFS either on\nall of the compute nodes or group of compute nodes defined by host aggregate.\n\nAdded new scheduling filter \'HostAggregateGroupFilter\' which can filter\nthe host on the basis of \'host aggregate group id\' stored in the\nfilter_properties.\n\nDocImpact:\nAn existing configuration parameter “shelved_offload_time"" will be modified\nhere to indicate the instance files shouldn’t be deleted.\n\n-1, never offload\n0, offload when shelved\n> 0, offload using “_poll_shelved_instances” periodic task\n\nNew value will be added\n-2, offload partially, release CPU/Memory but retain instance files\n\nNote: In case shelved_offload_time=-2, You must configure instance path on\nNFS either on all of the compute nodes or group of compute nodes defined\nby host aggregate.\n\nIf HostAggregate groups configured with same properties on multiple NFS, then\nadd \'HostAggregateGroupFilter\' in the \'scheduler_default_filters\'\nconfiguration parameter as mentioned below:\nscheduler_default_filters=HostAggregateGroupFilter,AvailabilityZoneFilter,...\n\nblueprint: improve-unshelve-performance\nChange-Id: I628ae22db08140b1675f90c29c7113fa17ec468a\n'}]",0,140644,7d57920622dee85246462b2fa6001d46343d2744,5,3,1,9303,,,0,"Improve performance of Unshelve api

Improved the performance of unshelve instance by eliminating
downloading/copying snapshot time. All instance files will be retained in
the instance store backed by NFS on the compute node when an instance is
shelved. An existing configuration parameter “shelved_offload_time"" is used
here to indicate the instance files shouldn’t be deleted.

-1, never offload (CPU/Memory/Disks resources are not released).
0, offload when shelved (CPU/Memory/Disks resources are not released).
> 0, offload using “_poll_shelved_instances” periodic task
(CPU/Memory/Disks resources are not released).

New value will be added
-2, offload partially, release CPU/Memory but retain instance files.

Added new VM state 'SHELVED_PARTIAL_OFFLOADED' and new Task state
'SHELVING_PARTIAL_OFFLOADING', so user can identify by VM status
that, instance is partially offloaded and instance files are persisted
on the host.

Note:
To use this feature, You must configure instance path on NFS either on
all of the compute nodes or group of compute nodes defined by host aggregate.

Added new scheduling filter 'HostAggregateGroupFilter' which can filter
the host on the basis of 'host aggregate group id' stored in the
filter_properties.

DocImpact:
An existing configuration parameter “shelved_offload_time"" will be modified
here to indicate the instance files shouldn’t be deleted.

-1, never offload
0, offload when shelved
> 0, offload using “_poll_shelved_instances” periodic task

New value will be added
-2, offload partially, release CPU/Memory but retain instance files

Note: In case shelved_offload_time=-2, You must configure instance path on
NFS either on all of the compute nodes or group of compute nodes defined
by host aggregate.

If HostAggregate groups configured with same properties on multiple NFS, then
add 'HostAggregateGroupFilter' in the 'scheduler_default_filters'
configuration parameter as mentioned below:
scheduler_default_filters=HostAggregateGroupFilter,AvailabilityZoneFilter,...

blueprint: improve-unshelve-performance
Change-Id: I628ae22db08140b1675f90c29c7113fa17ec468a
",git fetch https://review.opendev.org/openstack/nova refs/changes/44/140644/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/filters/host_aggregate_group_filter.py', 'nova/scheduler/filter_scheduler.py', 'nova/compute/task_states.py', 'nova/compute/vm_states.py', 'nova/api/openstack/common.py', 'nova/conductor/manager.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py', 'nova/compute/api.py']",9,7d57920622dee85246462b2fa6001d46343d2744,bp/improve-unshelve-performance," host = instance['host'] or instance.system_metadata.get('shelved_host') if not instance.host: instance.host = host instance.save() if not self.is_volume_backed_instance(context, instance): self.compute_rpcapi.shelve_instance(context, instance=instance) vm_states.SHELVED_OFFLOADED, vm_states.SHELVED_PARTIAL_OFFLOADED])"," def _create_image(self, context, instance, name, image_type, extra_properties=None): """"""Create new image entry in the image service. This new image will be reserved for the compute manager to upload a snapshot or backup. :param context: security context :param instance: nova.db.sqlalchemy.models.Instance :param name: string for name of the snapshot :param image_type: snapshot | backup :param extra_properties: dict of extra image properties to include """""" if extra_properties is None: extra_properties = {} instance_uuid = instance['uuid'] properties = { 'instance_uuid': instance_uuid, 'user_id': str(context.user_id), 'image_type': image_type, } image_ref = instance.image_ref sent_meta = compute_utils.get_image_metadata( context, self.image_api, image_ref, instance) sent_meta['name'] = name sent_meta['is_public'] = False # The properties set up above and in extra_properties have precedence properties.update(extra_properties or {}) sent_meta['properties'].update(properties) return self.image_api.create(context, sent_meta) image_id = None if not self.is_volume_backed_instance(context, instance): name = '%s-shelved' % instance['display_name'] image_meta = self._create_image(context, instance, name, 'snapshot') image_id = image_meta['id'] self.compute_rpcapi.shelve_instance(context, instance=instance, image_id=image_id) vm_states.SHELVED_OFFLOADED])",210,81
openstack%2Fmurano-specs~master~I04a0930a93d3ab5db3f546ceacde337b3a93a559,openstack/murano-specs,master,I04a0930a93d3ab5db3f546ceacde337b3a93a559,identation correction,ABANDONED,2014-12-12 11:26:44.000000000,2014-12-12 11:54:28.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2014-12-12 11:26:44.000000000', 'files': ['specs/kilo/configurationlanguages.rst'], 'web_link': 'https://opendev.org/openstack/murano-specs/commit/e99b50030f5fc066e8d0cfc71809cf41c2ee70fb', 'message': 'identation correction\n\nChange-Id: I04a0930a93d3ab5db3f546ceacde337b3a93a559\n'}]",0,141336,e99b50030f5fc066e8d0cfc71809cf41c2ee70fb,3,1,1,13931,,,0,"identation correction

Change-Id: I04a0930a93d3ab5db3f546ceacde337b3a93a559
",git fetch https://review.opendev.org/openstack/murano-specs refs/changes/36/141336/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/configurationlanguages.rst'],1,e99b50030f5fc066e8d0cfc71809cf41c2ee70fb,specs/supportconfigurationlanguages,"in the VM side, since current applications execute shell scripts"," in the VM side, since current applications execute shell scripts",1,1
openstack%2Fsahara~master~I7051efb0beda6640e4c1d39994146599b6827528,openstack/sahara,master,I7051efb0beda6640e4c1d39994146599b6827528,All user preserve EDP objects after test,MERGED,2014-12-12 04:05:26.000000000,2014-12-12 11:52:31.000000000,2014-12-12 11:52:30.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}]","[{'number': 1, 'created': '2014-12-12 04:05:26.000000000', 'files': ['sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/configs/itest.conf.sample-full', 'sahara/tests/integration/configs/config.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/80308390f63703c70c986f9a80c7c63055c243e1', 'message': 'All user preserve EDP objects after test\n\nUser can enable RETAIN_EDP_AFTER_TEST option to presever EDP objects\nafter integration test. This is only for debug usage.\n\nCloses-Bug: #1401736\n\nChange-Id: I7051efb0beda6640e4c1d39994146599b6827528\n'}]",0,141265,80308390f63703c70c986f9a80c7c63055c243e1,8,4,1,13662,,,0,"All user preserve EDP objects after test

User can enable RETAIN_EDP_AFTER_TEST option to presever EDP objects
after integration test. This is only for debug usage.

Closes-Bug: #1401736

Change-Id: I7051efb0beda6640e4c1d39994146599b6827528
",git fetch https://review.opendev.org/openstack/sahara refs/changes/65/141265/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/tests/integration/tests/edp.py', 'sahara/tests/integration/configs/config.py', 'sahara/tests/integration/configs/itest.conf.sample-full']",3,80308390f63703c70c986f9a80c7c63055c243e1,Bug1401736,"# If this flag is True, do not delete the EDP binaries, data # source, job, and job executions after test. # This is a debugging aid for instances when errors are logged # on the cluster nodes but the cause of the failure is not # evident from the integration test logs, ie an Oozie exception. # It is intended for use on local hosts, not the official ci host. # RETAIN_EDP_AFTER_TEST = False ",,31,7
openstack%2Fhorizon~master~If39a5dcbac45635ad9988edfdc1830aeabc663a4,openstack/horizon,master,If39a5dcbac45635ad9988edfdc1830aeabc663a4,Add _wait_till_text_present_in_element method,MERGED,2014-08-06 20:28:12.000000000,2014-12-12 11:49:29.000000000,2014-12-12 11:49:28.000000000,"[{'_account_id': 3}, {'_account_id': 581}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 6914}, {'_account_id': 8090}, {'_account_id': 8577}, {'_account_id': 10670}, {'_account_id': 11473}, {'_account_id': 12355}, {'_account_id': 12954}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-08-06 20:28:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e4dec1856e0e06b89190974d6920cb672117487b', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 2, 'created': '2014-08-06 20:40:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4fe9c1e67c73d9af121024c2be8a7e9c8b3de6ac', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 3, 'created': '2014-08-06 21:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/03d7fe4ec013dccc868fbd35332e79ab273fda07', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nConflicts:\n\topenstack_dashboard/test/integration_tests/pages/pageobject.py\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 4, 'created': '2014-08-13 16:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/ec1fbad53723e3dfb9a82a7ca3fc125c01f69c48', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nConflicts:\n\topenstack_dashboard/test/integration_tests/pages/pageobject.py\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 5, 'created': '2014-08-19 18:52:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b65b60ccba73802e9e2e674db8ddd2c90e25b90a', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nConflicts:\n\topenstack_dashboard/test/integration_tests/pages/pageobject.py\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 6, 'created': '2014-09-25 17:50:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c3806c96b4f7be9999d70d2a51fc49018f515241', 'message': 'Add wait_till_text_present_in_element method\n\n* refactor imports in the pageobject.py\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 7, 'created': '2014-09-25 18:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6f554c457a83f4fff0c51c76067d020f73fd896a', 'message': 'Add _wait_till_text_present_in_element method\n\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}, {'number': 8, 'created': '2014-12-07 14:49:56.000000000', 'files': ['openstack_dashboard/test/integration_tests/basewebobject.py', 'openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/integration_tests/helpers.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5ab83caf30d927c099cc8d5acff59b9af1bbbc9', 'message': 'Add _wait_till_text_present_in_element method\n\n* add selenium configuration group\n* add implicit/explicit wait and set page timeout\n\nPartially implements blueprint: selenium-integration-testing\n\nChange-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4\n'}]",15,112406,e5ab83caf30d927c099cc8d5acff59b9af1bbbc9,49,12,8,11473,,,0,"Add _wait_till_text_present_in_element method

* add selenium configuration group
* add implicit/explicit wait and set page timeout

Partially implements blueprint: selenium-integration-testing

Change-Id: If39a5dcbac45635ad9988edfdc1830aeabc663a4
",git fetch https://review.opendev.org/openstack/horizon refs/changes/06/112406/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/integration_tests/config.py', 'openstack_dashboard/test/integration_tests/horizon.conf', 'openstack_dashboard/test/integration_tests/pages/pageobject.py', 'openstack_dashboard/test/integration_tests/helpers.py']",4,e4dec1856e0e06b89190974d6920cb672117487b,bp/selenium-integration-testing, self.driver.implicitly_wait(self.conf.selenium.implicit_wait) self.driver.set_page_load_timeout(self.conf.selenium.page_timeout), self.driver.implicitly_wait(self.conf.dashboard.page_timeout),54,13
openstack%2Fdevstack~master~I6cbea259f177b07efed5ea3b00642d3ceedb9de8,openstack/devstack,master,I6cbea259f177b07efed5ea3b00642d3ceedb9de8,WIP - Configuring DevStack for the Neutron advanced services split.,ABANDONED,2014-12-09 22:49:30.000000000,2014-12-12 11:45:27.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 10385}, {'_account_id': 11628}]","[{'number': 1, 'created': '2014-12-09 22:49:30.000000000', 'files': ['stackrc'], 'web_link': 'https://opendev.org/openstack/devstack/commit/0a224cf8faebe04a10abc795dfeace92a2b20135', 'message': 'WIP - Configuring DevStack for the Neutron advanced services split.\n\nThis patch will allow DevStack to pull from the new FWaaS/LBaaS/VPNaaS\nrepositories.\n\nChange-Id: I6cbea259f177b07efed5ea3b00642d3ceedb9de8\n'}]",0,140513,0a224cf8faebe04a10abc795dfeace92a2b20135,6,4,1,11628,,,0,"WIP - Configuring DevStack for the Neutron advanced services split.

This patch will allow DevStack to pull from the new FWaaS/LBaaS/VPNaaS
repositories.

Change-Id: I6cbea259f177b07efed5ea3b00642d3ceedb9de8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/13/140513/1 && git format-patch -1 --stdout FETCH_HEAD,['stackrc'],1,0a224cf8faebe04a10abc795dfeace92a2b20135,master,# neutron fwaas service NEUTRON_FWAAS_REPO=${NEUTRON_REPO:-${GIT_BASE}/openstack/neutron-fwaas.git} NEUTRON_FWAAS_BRANCH=${NEUTRON_BRANCH:-master} # neutron lbaas service NEUTRON_LBAAS_REPO=${NEUTRON_REPO:-${GIT_BASE}/openstack/neutron-lbaas.git} NEUTRON_LBAAS_BRANCH=${NEUTRON_BRANCH:-master} # neutron vpnaas service NEUTRON_VPNAAS_REPO=${NEUTRON_REPO:-${GIT_BASE}/openstack/neutron-vpnaas.git} NEUTRON_VPNAAS_BRANCH=${NEUTRON_BRANCH:-master} ,,12,0
openstack%2Ffuel-web~master~Id77fe2def289b0a91b61a8404702fa1c26f1d076,openstack/fuel-web,master,Id77fe2def289b0a91b61a8404702fa1c26f1d076,Fix style for Healthcheck select all,MERGED,2014-12-11 10:01:00.000000000,2014-12-12 11:08:54.000000000,2014-12-12 11:08:53.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 13445}]","[{'number': 1, 'created': '2014-12-11 10:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c2bf643f4b230ad14891f457d65040969d99c330', 'message': 'Fix style for Healthcheck select all\n\n - also fixed margin in wizard\n\nCloses-bug: #1400759\n\nChange-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076\n'}, {'number': 2, 'created': '2014-12-11 10:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f82f0de8b2f173abd82ffd23bef63c59f1cbaf7d', 'message': 'Fix style for Healthcheck select all\n\n - also fixed margin in wizard on Compute pane\n\nCloses-bug: #1400759\n\nChange-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076\n'}, {'number': 3, 'created': '2014-12-11 12:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/488492a5e6897d870064871ef081db403d27a4dd', 'message': 'Fix style for Healthcheck select all\n\n - also fixed margin in wizard on Compute pane\n\nCloses-bug: #1400759\n\nChange-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076\n'}, {'number': 4, 'created': '2014-12-11 13:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/16a50546616ae3840d2e968966b5a7147e1b29c5', 'message': 'Fix style for Healthcheck select all\n\n - also fixed margin in wizard on Compute pane\n\nCloses-bug: #1400759\n\nChange-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076\n'}, {'number': 5, 'created': '2014-12-12 09:26:48.000000000', 'files': ['nailgun/static/css/styles.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/040b96c8858e3ab778b1805f37dfc2e5c7124549', 'message': 'Fix style for Healthcheck select all\n\n - also fixed margin in wizard on Compute pane\n\nCloses-bug: #1400759\n\nChange-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076\n'}]",4,140996,040b96c8858e3ab778b1805f37dfc2e5c7124549,35,7,5,9091,,,0,"Fix style for Healthcheck select all

 - also fixed margin in wizard on Compute pane

Closes-bug: #1400759

Change-Id: Id77fe2def289b0a91b61a8404702fa1c26f1d076
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/96/140996/4 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/css/styles.less'],1,c2bf643f4b230ad14891f457d65040969d99c330,css_fixes, .custom-tumbler { margin: 4px 0 0 0; input[type=checkbox][disabled] + span { cursor: not-allowed; } margin: 5px 0 0 0;, .custom-tumbler input[type=checkbox][disabled] + span { cursor: not-allowed; float: none; margin: 5px;,6,4
openstack%2Fsahara~master~I53090f95c657ef5ef215a3654476ffebf4826cf4,openstack/sahara,master,I53090f95c657ef5ef215a3654476ffebf4826cf4,Fixed configs generation for vanilla2,MERGED,2014-12-08 20:12:03.000000000,2014-12-12 11:08:24.000000000,2014-12-12 11:08:24.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 10670}]","[{'number': 1, 'created': '2014-12-08 20:12:03.000000000', 'files': ['sahara/plugins/vanilla/hadoop2/config.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/79587dfe28f6118f9c620ba5bd10fb684e765d18', 'message': 'Fixed configs generation for vanilla2\n\nPlugin has convention that config should contain configs only for\nexisting services. Initialization with empty dict leads to copy of\nall configuration files.\n\nChange-Id: I53090f95c657ef5ef215a3654476ffebf4826cf4\nCloses-Bug: #1399822\n'}]",0,140137,79587dfe28f6118f9c620ba5bd10fb684e765d18,12,5,1,8411,,,0,"Fixed configs generation for vanilla2

Plugin has convention that config should contain configs only for
existing services. Initialization with empty dict leads to copy of
all configuration files.

Change-Id: I53090f95c657ef5ef215a3654476ffebf4826cf4
Closes-Bug: #1399822
",git fetch https://review.opendev.org/openstack/sahara refs/changes/37/140137/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/plugins/vanilla/hadoop2/config.py'],1,79587dfe28f6118f9c620ba5bd10fb684e765d18,bug/1399822,, xml_configs[service] = {} env_configs[service] = {},0,2
openstack%2Fsahara~master~I62bfd6db5ce9cbf6ab3c3a33d0053f0c4166082a,openstack/sahara,master,I62bfd6db5ce9cbf6ab3c3a33d0053f0c4166082a,Disabled requiretty in cloud-init script,MERGED,2014-12-04 03:12:37.000000000,2014-12-12 11:02:36.000000000,2014-12-12 11:02:35.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-04 03:12:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1d6754e826b315b310e2c0d7b7ede582851348ec', 'message': 'Disabled requiretty in cloud-init script\n\nSahara expects requiretty to be disabled. Usually we disable it in\ndiskimagebuilder. Disabling it in runtime to be able to use stock\nimages.\n\nChange-Id: I62bfd6db5ce9cbf6ab3c3a33d0053f0c4166082a\nCloses-Bug: #1399052\n'}, {'number': 2, 'created': '2014-12-04 23:18:50.000000000', 'files': ['sahara/tests/unit/service/test_instances.py', 'sahara/service/engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/0a0cb1f68aff196c926963fdf15f15902216bebc', 'message': 'Disabled requiretty in cloud-init script\n\nSahara expects requiretty to be disabled. Usually we disable it in\ndiskimagebuilder. Disabling it in runtime to be able to use stock\nimages.\n\nChange-Id: I62bfd6db5ce9cbf6ab3c3a33d0053f0c4166082a\nCloses-Bug: #1399052\n'}]",0,138942,0a0cb1f68aff196c926963fdf15f15902216bebc,19,6,2,8411,,,0,"Disabled requiretty in cloud-init script

Sahara expects requiretty to be disabled. Usually we disable it in
diskimagebuilder. Disabling it in runtime to be able to use stock
images.

Change-Id: I62bfd6db5ce9cbf6ab3c3a33d0053f0c4166082a
Closes-Bug: #1399052
",git fetch https://review.opendev.org/openstack/sahara refs/changes/42/138942/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/service/engine.py'],1,1d6754e826b315b310e2c0d7b7ede582851348ec,bug/1399052,# ====== COMMENT OUT Defaults requiretty in /etc/sudoers ======== sed '/^Defaults requiretty*/ s/^/#/' -i /etc/sudoers\n,,2,0
openstack%2Fheat~master~Ib108a6f5c319c3060475a2daa47e8e35441a840e,openstack/heat,master,Ib108a6f5c319c3060475a2daa47e8e35441a840e,Support tox test case single run,MERGED,2014-12-10 02:55:03.000000000,2014-12-12 11:02:26.000000000,2014-12-12 11:02:25.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4715}, {'_account_id': 6698}, {'_account_id': 8289}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-10 02:55:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e77befb285253acb6e5796d3352767fb9e12bd48', 'message': 'Support tox test case single run\n\nFor example ""tox -epy27 -- heat.tests.test_hot.StackParametersTest"" will\nrun correctly with this patch. Otherwise the same command line still run all.\n\nChange-Id: Ib108a6f5c319c3060475a2daa47e8e35441a840e\n'}, {'number': 2, 'created': '2014-12-10 02:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9975e76bb06dfadcead0ac9dc3b3934a47766286', 'message': 'Support tox test case single run\n\nFor example ""tox -epy27 -- heat.tests.test_hot.StackParametersTest"" will\nrun correctly with this patch. Otherwise the same command line still run all.\n\nChange-Id: Ib108a6f5c319c3060475a2daa47e8e35441a840e\n'}, {'number': 3, 'created': '2014-12-12 03:05:38.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/e00e23604cc62e8c7f485c01f3e6ebff03530160', 'message': 'Support tox test case single run\n\nFor example ""tox -epy27 -- heat.tests.test_hot.StackParametersTest"" will\nrun correctly with this patch. Otherwise the same command line still run all.\n\nChange-Id: Ib108a6f5c319c3060475a2daa47e8e35441a840e\n'}]",1,140559,e00e23604cc62e8c7f485c01f3e6ebff03530160,26,9,3,7761,,,0,"Support tox test case single run

For example ""tox -epy27 -- heat.tests.test_hot.StackParametersTest"" will
run correctly with this patch. Otherwise the same command line still run all.

Change-Id: Ib108a6f5c319c3060475a2daa47e8e35441a840e
",git fetch https://review.opendev.org/openstack/heat refs/changes/59/140559/3 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e77befb285253acb6e5796d3352767fb9e12bd48,tox_single_run, python setup.py testr --slowest --testr-args='^(?!heat_integrationtests){posargs}' python setup.py testr --coverage --testr-args='^(?!heat_integrationtests){posargs}', python setup.py testr --slowest --testr-args='^(?!heat_integrationtests) {posargs}' python setup.py testr --coverage --testr-args='^(?!heat_integrationtests) {posargs}',2,2
openstack%2Ffuel-web~stable%2F6.0~Ia85d6f4668b9be94480bd07d78fe968a805f0f97,openstack/fuel-web,stable/6.0,Ia85d6f4668b9be94480bd07d78fe968a805f0f97,Do not save task.message in action logs,MERGED,2014-12-12 10:29:27.000000000,2014-12-12 10:58:16.000000000,2014-12-12 10:58:16.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-12 10:29:27.000000000', 'files': ['nailgun/nailgun/task/helpers.py', 'nailgun/nailgun/test/integration/test_task_managers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7a8237fa982ed6a413e969774e7f3149a0f19ef2', 'message': 'Do not save task.message in action logs\n\ntask.message is not saved in action logs now.\nKey ""additional_info.message"" is kept to keep compatibility with\ncurrent validation and migration in collector.\nTest added.\n\nChange-Id: Ia85d6f4668b9be94480bd07d78fe968a805f0f97\nCloses-Bug: #1401572\n(cherry picked from commit b77f20bc1a7b45dac71f02f960934270c24ccceb)\n'}]",0,141319,7a8237fa982ed6a413e969774e7f3149a0f19ef2,11,10,1,8392,,,0,"Do not save task.message in action logs

task.message is not saved in action logs now.
Key ""additional_info.message"" is kept to keep compatibility with
current validation and migration in collector.
Test added.

Change-Id: Ia85d6f4668b9be94480bd07d78fe968a805f0f97
Closes-Bug: #1401572
(cherry picked from commit b77f20bc1a7b45dac71f02f960934270c24ccceb)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/19/141319/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/helpers.py', 'nailgun/nailgun/test/integration/test_task_managers.py']",2,7a8237fa982ed6a413e969774e7f3149a0f19ef2,," self.assertEqual(action_log.additional_info[""message""], """") self.assertEqual(al.additional_info[""message""], """")",,3,1
openstack%2Ffuel-library~master~If8265bcdd7144a44b97a9f2e7d72f8a4b263920a,openstack/fuel-library,master,If8265bcdd7144a44b97a9f2e7d72f8a4b263920a,Rebase postgresql to puppetlabs-postgresql-4.0.0,MERGED,2014-10-27 10:15:32.000000000,2014-12-12 10:52:14.000000000,2014-10-27 15:04:34.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7745}, {'_account_id': 8749}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 11090}, {'_account_id': 12200}]","[{'number': 1, 'created': '2014-10-27 10:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2d6f7e77cc90b4bb4359dab1821c2886acff2159', 'message': 'Rebase postgresql to puppetlabs-postgresql-4.0.0\n\nOlder postgresql lacks capability to handle\nbindir path changes in postgres 9.0 and newer.\n\nChange-Id: If8265bcdd7144a44b97a9f2e7d72f8a4b263920a\nPartial-Bug: #1386118\n'}, {'number': 2, 'created': '2014-10-27 13:37:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/671b6ed6b0c84c0554ff2f0facf286ee2f86db47', 'message': 'Rebase postgresql to puppetlabs-postgresql-4.0.0\n\nRebases to puppetlabs-postgresql commit id:\n5d4a543a54df0c9c52a5c7c1f68e5ae51d862947\n\nOlder postgresql lacks capability to handle\nbindir path changes in postgres 9.0 and newer.\n\nChange-Id: If8265bcdd7144a44b97a9f2e7d72f8a4b263920a\nPartial-Bug: #1386118\n'}, {'number': 3, 'created': '2014-10-27 14:26:40.000000000', 'files': ['deployment/puppet/postgresql/manifests/server/database.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/table_grant_spec.rb', 'deployment/puppet/postgresql/manifests/lib/devel.pp', 'deployment/puppet/postgresql/lib/puppet/provider/postgresql_conf/parsed.rb', 'deployment/puppet/postgresql/spec/unit/defines/validate_db_connection_spec.rb', 'deployment/puppet/postgresql/spec/acceptance/server/schema_spec.rb', 'deployment/puppet/postgresql/Gemfile', 'deployment/puppet/postgresql/manifests/server/pg_hba_rule.pp', 'deployment/puppet/postgresql/manifests/globals.pp', 'deployment/puppet/postgresql/manifests/role.pp', 'deployment/puppet/postgresql/spec/unit/classes/lib/python_spec.rb', 'deployment/puppet/postgresql/spec/unit/provider/postgresql_conf/parsed_spec.rb', 'deployment/puppet/postgresql/Rakefile', 'deployment/puppet/postgresql/spec/base.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/tablespace_spec.rb', 'deployment/puppet/postgresql/manifests/config/beforeservice.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-510-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/postgresql/spec/unit/defines/server/database_spec.rb', 'deployment/puppet/postgresql/lib/puppet/parser/functions/postgresql_escape.rb', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-12042-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-64-x64-pe.yml', 'deployment/puppet/postgresql/lib/puppet/provider/postgresql_psql/ruby.rb', 'deployment/puppet/postgresql/manifests/server.pp', 'deployment/puppet/postgresql/spec/unit/classes/globals_spec.rb', 'deployment/puppet/postgresql/manifests/server/pg_ident_rule.pp', 'deployment/puppet/postgresql/spec/acceptance/postgresql_psql_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/db_spec.rb', 'deployment/puppet/postgresql/Modulefile', 'deployment/puppet/postgresql/manifests/server/passwd.pp', 'deployment/puppet/postgresql/manifests/server/postgis.pp', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_acls_to_resources_hash_spec.rb', 'deployment/puppet/postgresql/tests/init.pp', 'deployment/puppet/postgresql/templates/systemd-port-override.erb', 'deployment/puppet/postgresql/manifests/validate_db_connection.pp', 'deployment/puppet/postgresql/spec/unit/puppet/provider/postgresql_psql/ruby_spec.rb', 'deployment/puppet/postgresql/manifests/initdb.pp', 'deployment/puppet/postgresql/manifests/init.pp', 'deployment/puppet/postgresql/manifests/server/install.pp', 'deployment/puppet/postgresql/spec/spec_helper.rb', 'deployment/puppet/postgresql/files/RPM-GPG-KEY-PGDG', 'deployment/puppet/postgresql/manifests/database_user.pp', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_password_spec.rb', 'deployment/puppet/postgresql/manifests/server/initdb.pp', 'deployment/puppet/postgresql/manifests/server/tablespace.pp', 'deployment/puppet/postgresql/manifests/server/grant.pp', 'deployment/puppet/postgresql/spec/unit/classes/server_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/server/contrib_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/server/initdb_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_user.pp', 'deployment/puppet/postgresql/CHANGELOG.md', 'deployment/puppet/postgresql/spec/unit/classes/lib/devel_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/client_spec.rb', 'deployment/puppet/postgresql/manifests/server/schema.pp', 'deployment/puppet/postgresql/tests/server.pp', 'deployment/puppet/postgresql/spec/manifests/test_user.pp', 'deployment/puppet/postgresql/NOTICE', 'deployment/puppet/postgresql/.project', 'deployment/puppet/postgresql/templates/pg_hba_rule.conf', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-10044-x64.yml', 'deployment/puppet/postgresql/spec/unit/classes/repo_spec.rb', 'deployment/puppet/postgresql/manifests/server/config.pp', 'deployment/puppet/postgresql/manifests/database_grant.pp', 'deployment/puppet/postgresql/manifests/repo/apt_postgresql_org.pp', 'deployment/puppet/postgresql/.gitignore', 'deployment/puppet/postgresql/manifests/server/role.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/pg_ident_rule_spec.rb', 'deployment/puppet/postgresql/manifests/server/service.pp', 'deployment/puppet/postgresql/manifests/database.pp', 'deployment/puppet/postgresql/tests/postgresql_db.pp', 'deployment/puppet/postgresql/manifests/server/contrib.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/pg_hba_rule_spec.rb', 'deployment/puppet/postgresql/spec/unit/type/postgresql_conf_spec.rb', 'deployment/puppet/postgresql/lib/puppet/type/postgresql_psql.rb', 'deployment/puppet/postgresql/manifests/params.pp', 'deployment/puppet/postgresql/spec/unit/classes/server/postgis_spec.rb', 'deployment/puppet/postgresql/manifests/lib/python.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/database_grant_spec.rb', 'deployment/puppet/postgresql/README.md', 'deployment/puppet/postgresql/checksums.json', 'deployment/puppet/postgresql/LICENSE', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/postgresql/spec/manifests/test_grant_create.pp', 'deployment/puppet/postgresql/manifests/server/config_entry.pp', 'deployment/puppet/postgresql/manifests/server/plperl.pp', 'deployment/puppet/postgresql/spec/manifests/test_psql.pp', 'deployment/puppet/postgresql/lib/puppet/parser/functions/postgresql_acls_to_resources_hash.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/config_entry_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/grant_spec.rb', 'deployment/puppet/postgresql/lib/puppet/type/postgresql_conf.rb', 'deployment/puppet/postgresql/spec/unit/classes/lib/java_spec.rb', 'deployment/puppet/postgresql/templates/pg_hba.conf.erb', 'deployment/puppet/postgresql/spec/acceptance/default_parameters_spec.rb', 'deployment/puppet/postgresql/manifests/server/table_grant.pp', 'deployment/puppet/postgresql/spec/manifests/test_db.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/debian-73-x64.yml', 'deployment/puppet/postgresql/spec/unit/classes/server/plperl_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_database.pp', 'deployment/puppet/postgresql/spec/manifests/test_initdb.pp', 'deployment/puppet/postgresql/manifests/repo.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/debian-607-x64.yml', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_escape_spec.rb', 'deployment/puppet/postgresql/files/validate_postgresql_connection.sh', 'deployment/puppet/postgresql/manifests/config.pp', 'deployment/puppet/postgresql/spec/acceptance/db_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/schema_spec.rb', 'deployment/puppet/postgresql/manifests/psql.pp', 'deployment/puppet/postgresql/spec/acceptance/alternative_port_spec.rb', 'deployment/puppet/postgresql/manifests/repo/yum_postgresql_org.pp', 'deployment/puppet/postgresql/spec/spec_helper_acceptance.rb', 'deployment/puppet/postgresql/spec/unit/puppet/type/postgresql_psql_spec.rb', 'deployment/puppet/postgresql/manifests/server/database_grant.pp', 'deployment/puppet/postgresql/manifests/lib/perl.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/default.yml', 'deployment/puppet/postgresql/manifests/server/reload.pp', 'deployment/puppet/postgresql/templates/pg_ident_rule.conf', 'deployment/puppet/postgresql/spec/unit/classes/params_spec.rb', 'deployment/puppet/postgresql/manifests/db.pp', 'deployment/puppet/postgresql/spec/unit/classes/lib/perl_spec.rb', 'deployment/puppet/postgresql/CONTRIBUTING.md', 'deployment/puppet/postgresql/manifests/config/afterservice.pp', 'deployment/puppet/postgresql/manifests/lib/java.pp', 'deployment/puppet/postgresql/spec/postgresql_spec.rb', 'deployment/puppet/postgresql/manifests/server/db.pp', 'deployment/puppet/postgresql/spec/Vagrantfile', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/postgresql/manifests/client.pp', 'deployment/puppet/postgresql/spec/spec.opts', 'deployment/puppet/postgresql/spec/unit/defines/server/role_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_grant.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e97c8338c9969aaef60b71b50cec52cb3c4524c2', 'message': 'Rebase postgresql to puppetlabs-postgresql-4.0.0\n\nRebases to puppetlabs-postgresql commit id:\n5d4a543a54df0c9c52a5c7c1f68e5ae51d862947\n\nOlder postgresql lacks capability to handle\nbindir path changes in postgres 9.0 and newer.\n\nChange-Id: If8265bcdd7144a44b97a9f2e7d72f8a4b263920a\nPartial-Bug: #1386118\nRelated blueprint merge-openstack-puppet-modules\n'}]",0,131073,e97c8338c9969aaef60b71b50cec52cb3c4524c2,30,9,3,7195,,,0,"Rebase postgresql to puppetlabs-postgresql-4.0.0

Rebases to puppetlabs-postgresql commit id:
5d4a543a54df0c9c52a5c7c1f68e5ae51d862947

Older postgresql lacks capability to handle
bindir path changes in postgres 9.0 and newer.

Change-Id: If8265bcdd7144a44b97a9f2e7d72f8a4b263920a
Partial-Bug: #1386118
Related blueprint merge-openstack-puppet-modules
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/73/131073/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/postgresql/manifests/server/database.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/table_grant_spec.rb', 'deployment/puppet/postgresql/manifests/lib/devel.pp', 'deployment/puppet/postgresql/lib/puppet/provider/postgresql_conf/parsed.rb', 'deployment/puppet/postgresql/spec/unit/defines/validate_db_connection_spec.rb', 'deployment/puppet/postgresql/spec/acceptance/server/schema_spec.rb', 'deployment/puppet/postgresql/Gemfile', 'deployment/puppet/postgresql/manifests/server/pg_hba_rule.pp', 'deployment/puppet/postgresql/manifests/globals.pp', 'deployment/puppet/postgresql/manifests/role.pp', 'deployment/puppet/postgresql/spec/unit/classes/lib/python_spec.rb', 'deployment/puppet/postgresql/spec/unit/provider/postgresql_conf/parsed_spec.rb', 'deployment/puppet/postgresql/Rakefile', 'deployment/puppet/postgresql/spec/base.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/tablespace_spec.rb', 'deployment/puppet/postgresql/manifests/config/beforeservice.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-510-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-1404-x64.yml', 'deployment/puppet/postgresql/spec/unit/defines/server/database_spec.rb', 'deployment/puppet/postgresql/lib/puppet/parser/functions/postgresql_escape.rb', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-12042-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-64-x64-pe.yml', 'deployment/puppet/postgresql/lib/puppet/provider/postgresql_psql/ruby.rb', 'deployment/puppet/postgresql/manifests/server.pp', 'deployment/puppet/postgresql/spec/unit/classes/globals_spec.rb', 'deployment/puppet/postgresql/manifests/server/pg_ident_rule.pp', 'deployment/puppet/postgresql/spec/acceptance/postgresql_psql_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/db_spec.rb', 'deployment/puppet/postgresql/Modulefile', 'deployment/puppet/postgresql/manifests/server/passwd.pp', 'deployment/puppet/postgresql/manifests/server/postgis.pp', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_acls_to_resources_hash_spec.rb', 'deployment/puppet/postgresql/tests/init.pp', 'deployment/puppet/postgresql/templates/systemd-port-override.erb', 'deployment/puppet/postgresql/manifests/validate_db_connection.pp', 'deployment/puppet/postgresql/spec/unit/puppet/provider/postgresql_psql/ruby_spec.rb', 'deployment/puppet/postgresql/manifests/initdb.pp', 'deployment/puppet/postgresql/manifests/init.pp', 'deployment/puppet/postgresql/manifests/server/install.pp', 'deployment/puppet/postgresql/spec/spec_helper.rb', 'deployment/puppet/postgresql/files/RPM-GPG-KEY-PGDG', 'deployment/puppet/postgresql/manifests/database_user.pp', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_password_spec.rb', 'deployment/puppet/postgresql/manifests/server/initdb.pp', 'deployment/puppet/postgresql/manifests/server/tablespace.pp', 'deployment/puppet/postgresql/manifests/server/grant.pp', 'deployment/puppet/postgresql/spec/unit/classes/server_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/server/contrib_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/server/initdb_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_user.pp', 'deployment/puppet/postgresql/CHANGELOG.md', 'deployment/puppet/postgresql/spec/unit/classes/lib/devel_spec.rb', 'deployment/puppet/postgresql/spec/unit/classes/client_spec.rb', 'deployment/puppet/postgresql/manifests/server/schema.pp', 'deployment/puppet/postgresql/tests/server.pp', 'deployment/puppet/postgresql/spec/manifests/test_user.pp', 'deployment/puppet/postgresql/NOTICE', 'deployment/puppet/postgresql/.project', 'deployment/puppet/postgresql/templates/pg_hba_rule.conf', 'deployment/puppet/postgresql/spec/acceptance/nodesets/ubuntu-server-10044-x64.yml', 'deployment/puppet/postgresql/spec/unit/classes/repo_spec.rb', 'deployment/puppet/postgresql/manifests/server/config.pp', 'deployment/puppet/postgresql/manifests/database_grant.pp', 'deployment/puppet/postgresql/manifests/repo/apt_postgresql_org.pp', 'deployment/puppet/postgresql/.gitignore', 'deployment/puppet/postgresql/manifests/server/role.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/pg_ident_rule_spec.rb', 'deployment/puppet/postgresql/manifests/server/service.pp', 'deployment/puppet/postgresql/manifests/database.pp', 'deployment/puppet/postgresql/tests/postgresql_db.pp', 'deployment/puppet/postgresql/manifests/server/contrib.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/pg_hba_rule_spec.rb', 'deployment/puppet/postgresql/spec/unit/type/postgresql_conf_spec.rb', 'deployment/puppet/postgresql/lib/puppet/type/postgresql_psql.rb', 'deployment/puppet/postgresql/manifests/params.pp', 'deployment/puppet/postgresql/spec/unit/classes/server/postgis_spec.rb', 'deployment/puppet/postgresql/manifests/lib/python.pp', 'deployment/puppet/postgresql/spec/unit/defines/server/database_grant_spec.rb', 'deployment/puppet/postgresql/README.md', 'deployment/puppet/postgresql/checksums.json', 'deployment/puppet/postgresql/LICENSE', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-59-x64.yml', 'deployment/puppet/postgresql/spec/manifests/test_grant_create.pp', 'deployment/puppet/postgresql/manifests/server/config_entry.pp', 'deployment/puppet/postgresql/manifests/server/plperl.pp', 'deployment/puppet/postgresql/spec/manifests/test_psql.pp', 'deployment/puppet/postgresql/lib/puppet/parser/functions/postgresql_acls_to_resources_hash.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/config_entry_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/grant_spec.rb', 'deployment/puppet/postgresql/lib/puppet/type/postgresql_conf.rb', 'deployment/puppet/postgresql/spec/unit/classes/lib/java_spec.rb', 'deployment/puppet/postgresql/templates/pg_hba.conf.erb', 'deployment/puppet/postgresql/spec/acceptance/default_parameters_spec.rb', 'deployment/puppet/postgresql/manifests/server/table_grant.pp', 'deployment/puppet/postgresql/spec/manifests/test_db.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-64-x64.yml', 'deployment/puppet/postgresql/spec/acceptance/nodesets/debian-73-x64.yml', 'deployment/puppet/postgresql/spec/unit/classes/server/plperl_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_database.pp', 'deployment/puppet/postgresql/spec/manifests/test_initdb.pp', 'deployment/puppet/postgresql/manifests/repo.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/debian-607-x64.yml', 'deployment/puppet/postgresql/spec/unit/functions/postgresql_escape_spec.rb', 'deployment/puppet/postgresql/files/validate_postgresql_connection.sh', 'deployment/puppet/postgresql/manifests/config.pp', 'deployment/puppet/postgresql/spec/acceptance/db_spec.rb', 'deployment/puppet/postgresql/spec/unit/defines/server/schema_spec.rb', 'deployment/puppet/postgresql/manifests/psql.pp', 'deployment/puppet/postgresql/spec/acceptance/alternative_port_spec.rb', 'deployment/puppet/postgresql/manifests/repo/yum_postgresql_org.pp', 'deployment/puppet/postgresql/spec/spec_helper_acceptance.rb', 'deployment/puppet/postgresql/spec/unit/puppet/type/postgresql_psql_spec.rb', 'deployment/puppet/postgresql/manifests/server/database_grant.pp', 'deployment/puppet/postgresql/manifests/lib/perl.pp', 'deployment/puppet/postgresql/spec/acceptance/nodesets/default.yml', 'deployment/puppet/postgresql/manifests/server/reload.pp', 'deployment/puppet/postgresql/templates/pg_ident_rule.conf', 'deployment/puppet/postgresql/spec/unit/classes/params_spec.rb', 'deployment/puppet/postgresql/manifests/db.pp', 'deployment/puppet/postgresql/spec/unit/classes/lib/perl_spec.rb', 'deployment/puppet/postgresql/CONTRIBUTING.md', 'deployment/puppet/postgresql/manifests/config/afterservice.pp', 'deployment/puppet/postgresql/manifests/lib/java.pp', 'deployment/puppet/postgresql/spec/postgresql_spec.rb', 'deployment/puppet/postgresql/manifests/server/db.pp', 'deployment/puppet/postgresql/spec/Vagrantfile', 'deployment/puppet/postgresql/spec/acceptance/nodesets/centos-65-x64.yml', 'deployment/puppet/postgresql/manifests/client.pp', 'deployment/puppet/postgresql/spec/spec.opts', 'deployment/puppet/postgresql/spec/unit/defines/server/role_spec.rb', 'deployment/puppet/postgresql/tests/postgresql_grant.pp']",131,2d6f7e77cc90b4bb4359dab1821c2886acff2159,adapt-postgres,,"# TODO: in mysql module, the grant resource name might look like this: 'user@host/dbname'; # I think that the API for the resource type should split these up, because it's # easier / safer to recombine them for mysql than it is to parse them for other # databases. Also, in the mysql module, the hostname portion of that string # affects the user's ability to connect from remote hosts. In postgres this is # managed via pg_hba.conf; not sure if we want to try to reconcile that difference # in the modules or not. postgresql::database_grant{'test1': # TODO: mysql supports an array of privileges here. We should do that if we # port this to ruby. privilege => 'ALL', db => 'test1', role => 'dan', } ",6368,1461
openstack%2Ffuel-main~master~Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee,openstack/fuel-main,master,Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee,Add multiple cluster networks support to tests,MERGED,2014-10-06 17:05:32.000000000,2014-12-12 10:49:37.000000000,2014-12-12 10:48:03.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8787}, {'_account_id': 8829}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2014-10-06 17:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/eb4a21df418fdc687e5e4f465011273484ec5827', 'message': '(WORK IN PROGRESS)Add multiple cluster networks support\n\nAdd support of environments deployment with two sets of\nnetworks to the system tests.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-cluster-networks\n'}, {'number': 2, 'created': '2014-10-06 17:34:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/91821cb14e9cd29d13ea843008970de5e44f5ef5', 'message': '(WORK IN PROGRESS)Add multiple cluster networks support\n\nAdd support of environments deployment with two sets of\nnetworks to the system tests.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-cluster-networks\n'}, {'number': 3, 'created': '2014-10-06 17:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c67af6bd4ff1c0b69f1b4a2261d6846700b9b2df', 'message': '(WORK IN PROGRESS)Add multiple cluster networks support\n\nAdd support of environments deployment with two sets of\nnetworks to the system tests.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-cluster-networks\n'}, {'number': 4, 'created': '2014-10-21 08:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/db48e7d19797b9c72fa7d7da21fa919210313207', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 5, 'created': '2014-10-21 12:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/78797145bb6016aae2cd07e7676f18c40ab1f34b', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 6, 'created': '2014-10-21 12:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/94e9b5a369cf8dfe1388207d9a777713fcfcad55', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 7, 'created': '2014-10-21 14:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/23f04da8f69cb27cf6c1916a6608d5b5664ba06f', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 8, 'created': '2014-10-26 20:59:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ab78c28cb97b8cc63e76d891066028d36bcb766a', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 9, 'created': '2014-10-26 21:06:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/85cd6dac26c4b2ecbf6b43527bedc8378eb554e5', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 10, 'created': '2014-10-28 19:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/f391147413139f20eca48f46c13cff5f19794431', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 11, 'created': '2014-11-17 23:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3c74208941e5f525a31647ae1fba3a9feca46dd5', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 12, 'created': '2014-11-17 23:32:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/3fa167e3518dd583bf4ce2a07c9455e1e9c153ba', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}, {'number': 13, 'created': '2014-12-11 15:31:13.000000000', 'files': ['fuelweb_test/helpers/multiple_networks_hacks.py', 'fuelweb_test/models/fuel_web_client.py', 'fuelweb_test/models/environment.py', 'fuelweb_test/models/nailgun_client.py', 'fuelweb_test/tests/test_multiple_networks.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/150f56916d797ce5582916712aa8e930e6538a39', 'message': 'Add multiple cluster networks support to tests\n\nAdd possibility to deploy environments with two sets of\nL2 networks in the system tests. This patch implements\nsupport of defining cluster nodes groups and editing of\nnetworks settings based on network group name. Also, due\nto lack of automatic cobbler configuring add the method\nwich allows to rewrite default dnsmasq template.\n\nChange-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee\nImplements: blueprint multiple-l2-networks-test\n'}]",5,126359,150f56916d797ce5582916712aa8e930e6538a39,83,9,13,11081,,,0,"Add multiple cluster networks support to tests

Add possibility to deploy environments with two sets of
L2 networks in the system tests. This patch implements
support of defining cluster nodes groups and editing of
networks settings based on network group name. Also, due
to lack of automatic cobbler configuring add the method
wich allows to rewrite default dnsmasq template.

Change-Id: Ib59b5cc1073b4c44c5d142ab20fe9feebf56d3ee
Implements: blueprint multiple-l2-networks-test
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/59/126359/12 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/models/environment.py', 'fuelweb_test/tests/test_multiple_networks.py', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py']",4,eb4a21df418fdc687e5e4f465011273484ec5827,bp/multiple-l2-networks-test," 'admin2': ADMIN_FORWARD, 'public2': PUBLIC_FORWARD, 'management2': MGMT_FORWARD, 'private2': PRIVATE_FORWARD, 'storage2': STORAGE_FORWARD, 'storage': False, 'admin2': False, 'public2': False, 'management2': False, 'private2': False, 'storage2': False 'admin2': 'eth5', 'public2': 'eth6', 'management2': 'eth7', 'private2': 'eth8', 'storage2': 'eth9',POOL_DEFAULT2 = os.environ.get('POOL_DEFAULT2', '10.108.0.0/16:24') POOL_ADMIN2 = os.environ.get('POOL_ADMIN2', POOL_DEFAULT2) POOL_PUBLIC2 = os.environ.get('POOL_PUBLIC2', POOL_DEFAULT2) POOL_MANAGEMENT2 = os.environ.get('POOL_MANAGEMENT', POOL_DEFAULT2) POOL_PRIVATE2 = os.environ.get('POOL_PRIVATE', POOL_DEFAULT2) POOL_STORAGE2 = os.environ.get('POOL_STORAGE', POOL_DEFAULT2) DEFAULT_POOLS2 = { 'admin2': POOL_ADMIN2, 'public2': POOL_PUBLIC2, 'management2': POOL_MANAGEMENT2, 'private2': POOL_PRIVATE2, 'storage2': POOL_STORAGE2, } 'admin2': os.environ.get( 'PUBLIC_POOL2', DEFAULT_POOLS2.get('admin2')).split(':'), 'public2': os.environ.get( 'PUBLIC_POOL2', DEFAULT_POOLS2.get('public2')).split(':'), 'management2': os.environ.get( 'PRIVATE_POOL2', DEFAULT_POOLS2.get('management2')).split(':'), 'private2': os.environ.get( 'INTERNAL_POOL2', DEFAULT_POOLS2.get('private2')).split(':'), 'storage2': os.environ.get( 'NAT_POOL2', DEFAULT_POOLS2.get('storage2')).split(':'), } DEFAULT_INTERFACE_ORDER2 = 'admin2,public2,management2,private2,storage2' INTERFACE_ORDER2 = os.environ.get('INTERFACE_ORDER2', DEFAULT_INTERFACE_ORDER2).split(',') MULTIPLE_NETWORKS = os.environ.get('MULTIPLE_NETWORKS', False) == 'true'", 'storage': False} ,214,2
openstack%2Fnova~master~I6d0b49812f8ca965ca53be34ef009997c8e79728,openstack/nova,master,I6d0b49812f8ca965ca53be34ef009997c8e79728,Fixes Hyper-V volume discovery exception message,MERGED,2014-08-25 23:16:36.000000000,2014-12-12 10:44:22.000000000,2014-12-12 10:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1779}, {'_account_id': 1849}, {'_account_id': 5170}, {'_account_id': 8543}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 10618}]","[{'number': 1, 'created': '2014-08-25 23:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f61f075d60025c41a8752d711afeeeb15cb08b67', 'message': 'Fixes Hyper-V volume discovery exception message\n\nOn some editions of Windows / Hyper-V server the SAN policy is set\nby default to ""Online All"", bringing online any disk, local or shared,\nattached to the host.\n\nSince only offline disks can be attached as passthrough disks to a Hyper-V\nVM, this prevents Cinder volumes from being attached to instances,\nresulting in an exception that can be particularly hard to troubleshoot\nwithout a clear knowledge of the context.\n\nThis patch includes some details in the exception message for\ntroubleshooting purposes.\n\nChange-Id: I6d0b49812f8ca965ca53be34ef009997c8e79728\nCloses-Bug: #1361419\n'}, {'number': 2, 'created': '2014-08-26 00:36:02.000000000', 'files': ['nova/virt/hyperv/volumeops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/bc5627db0fede19200a372839b8f071c019caf56', 'message': 'Fixes Hyper-V volume discovery exception message\n\nOn some editions of Windows / Hyper-V server the SAN policy is set\nby default to ""Online All"", bringing online any disk, local or shared,\nattached to the host.\n\nSince only offline disks can be attached as passthrough disks to a Hyper-V\nVM, this prevents Cinder volumes from being attached to instances,\nresulting in an exception that can be particularly hard to troubleshoot\nwithout a clear knowledge of the context.\n\nThis patch includes some details in the exception message for\ntroubleshooting purposes.\n\nChange-Id: I6d0b49812f8ca965ca53be34ef009997c8e79728\nCloses-Bug: #1361419\n'}]",0,116751,bc5627db0fede19200a372839b8f071c019caf56,16,10,2,3185,,,0,"Fixes Hyper-V volume discovery exception message

On some editions of Windows / Hyper-V server the SAN policy is set
by default to ""Online All"", bringing online any disk, local or shared,
attached to the host.

Since only offline disks can be attached as passthrough disks to a Hyper-V
VM, this prevents Cinder volumes from being attached to instances,
resulting in an exception that can be particularly hard to troubleshoot
without a clear knowledge of the context.

This patch includes some details in the exception message for
troubleshooting purposes.

Change-Id: I6d0b49812f8ca965ca53be34ef009997c8e79728
Closes-Bug: #1361419
",git fetch https://review.opendev.org/openstack/nova refs/changes/51/116751/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hyperv/volumeops.py'],1,f61f075d60025c41a8752d711afeeeb15cb08b67,bug/1361419," 'target_iqn: %s. Please ensure that ' 'the host\'s SAN policy is set to ' '""OfflineAll"" or ""OfflineShared""') % target_iqn)", 'target_iqn: %s') % target_iqn),4,1
openstack%2Ffuel-web~master~Ibdb45822b0960e1a1fe511bb70273896c8e28892,openstack/fuel-web,master,Ibdb45822b0960e1a1fe511bb70273896c8e28892,Support for multiple binds in wizard,MERGED,2014-12-10 15:30:28.000000000,2014-12-12 10:43:57.000000000,2014-12-12 10:43:57.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9091}, {'_account_id': 9730}, {'_account_id': 12139}, {'_account_id': 13445}, {'_account_id': 13516}]","[{'number': 1, 'created': '2014-12-10 15:30:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/5bd45e3faaf5b7215eeae2b0f91d858e35e402e7', 'message': 'Support for multiple binds in wizard\n\nChange-Id: Ibdb45822b0960e1a1fe511bb70273896c8e28892\nCloses-bug: #1381640\n'}, {'number': 2, 'created': '2014-12-11 13:04:53.000000000', 'files': ['nailgun/static/js/views/wizard.js', 'nailgun/nailgun/fixtures/openstack.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/beafeb9f8bd14b57a07afc9d7b0a608ee3adda02', 'message': 'Support for multiple binds in wizard\n\nChange-Id: Ibdb45822b0960e1a1fe511bb70273896c8e28892\nCloses-bug: #1381640\n'}]",6,140735,beafeb9f8bd14b57a07afc9d7b0a608ee3adda02,26,10,2,9091,,,0,"Support for multiple binds in wizard

Change-Id: Ibdb45822b0960e1a1fe511bb70273896c8e28892
Closes-bug: #1381640
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/35/140735/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/js/views/wizard.js', 'nailgun/nailgun/fixtures/openstack.yaml']",2,5bd45e3faaf5b7215eeae2b0f91d858e35e402e7,multiple_binds," bind: - ""settings:vcenter.host_ip.value"" - ""settings:storage.vc_host.value"" bind: - ""settings:vcenter.vc_user.value"" - ""settings:storage.vc_user.value"" bind: - ""settings:vcenter.vc_password.value"" - ""settings:storage.vc_password.value"""," bind: ""settings:vcenter.host_ip.value"" bind: ""settings:vcenter.vc_user.value"" bind: ""settings:vcenter.vc_password.value""",14,3
openstack%2Fopenstack-manuals~master~I0bcc4bf542e51d3cfba1a1755436623da4f72e51,openstack/openstack-manuals,master,I0bcc4bf542e51d3cfba1a1755436623da4f72e51,Update CLI reference for glance,MERGED,2014-12-12 10:17:25.000000000,2014-12-12 10:43:43.000000000,2014-12-12 10:43:42.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-12 10:17:25.000000000', 'files': ['doc/cli-reference/generated/ch_cli_glance_commands.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f3047b31cec501be4c114e506b1f7bbcf3715d04', 'message': 'Update CLI reference for glance\n\nChange-Id: I0bcc4bf542e51d3cfba1a1755436623da4f72e51\n'}]",0,141317,f3047b31cec501be4c114e506b1f7bbcf3715d04,6,2,1,167,,,0,"Update CLI reference for glance

Change-Id: I0bcc4bf542e51d3cfba1a1755436623da4f72e51
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/17/141317/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/cli-reference/generated/ch_cli_glance_commands.xml'],1,f3047b31cec501be4c114e506b1f7bbcf3715d04,update_client_glance, <literal>0.15.0</literal>. [--os-image-api-version OS_IMAGE_API_VERSION] [-k] [--os-cert OS_CERT] [--cert-file OS_CERT] [--os-key OS_KEY] [--key-file OS_KEY] [--os-cacert &lt;ca-certificate-file&gt;] [--ca-file OS_CACERT] [--os-username OS_USERNAME] [--os-user-id OS_USER_ID] <term><command>bash-completion</command></term> <listitem> <para> Prints all of the commands and options to stdout so that the </para> </listitem> </varlistentry> <varlistentry> Defaults to <code>env[OS_IMAGE_URL]</code>. If the provided image url contains a a version number and `--os-image-api- version` is omitted the version of the URL will be picked as the image api version to use. <screen><computeroutput>usage: glance --os-image-api-version 2 image-create [--property &lt;key=value&gt;] [--file &lt;FILE&gt;] [--progress] &lt;unavailable&gt;</computeroutput></screen> <varlistentry> <term><command>--file &lt;FILE&gt;</command></term> <listitem> <para> Local file to save downloaded image data to. If this is not specified the image data will be written to stdout. </para> </listitem> </varlistentry> <varlistentry> <term><command>--progress</command></term> <listitem> <para> Show upload progress bar. </para> </listitem> </varlistentry> [--property-filter &lt;KEY=VALUE&gt;] <term><command>--property-filter &lt;KEY=VALUE&gt;</command></term> <listitem> <para> Filter images by a user-defined image property. </para> </listitem> </varlistentry> <varlistentry>," <literal>0.14.2</literal>. [--os-image-api-version OS_IMAGE_API_VERSION] [--profile HMAC_KEY] [-k] [--os-cert OS_CERT] [--cert-file OS_CERT] [--os-key OS_KEY] [--key-file OS_KEY] [--os-cacert &lt;ca-certificate-file&gt;] [--ca-file OS_CACERT] [--os-username OS_USERNAME] [--os-user-id OS_USER_ID] Defaults to <code>env[OS_IMAGE_URL]</code>. <term><command>--profile HMAC_KEY HMAC</command></term> <listitem> <para> key to use for encrypting context data for performance profiling of operation. This key should be the value of HMAC key configured in osprofiler middleware in glance, it is specified in paste configuration file at /etc/glance/api-paste.ini and /etc/glance/registry-paste.ini. Without key the profiling will not be triggered even if osprofiler is enabled on server side. </para> </listitem> </varlistentry> <varlistentry> <screen><computeroutput>usage: glance --os-image-api-version 2 image-create [--property &lt;key=value&gt;] &lt;unavailable&gt;</computeroutput></screen>",49,23
openstack%2Fmurano-agent~master~I7ef3035e8cb342c7b8d1494903a58fc292ec2485,openstack/murano-agent,master,I7ef3035e8cb342c7b8d1494903a58fc292ec2485,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:57:15.000000000,2014-12-12 10:31:24.000000000,2014-12-12 10:31:24.000000000,"[{'_account_id': 3}, {'_account_id': 7227}, {'_account_id': 7562}, {'_account_id': 7600}, {'_account_id': 7821}, {'_account_id': 13149}]","[{'number': 1, 'created': '2014-12-05 03:57:15.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/murano-agent/commit/8287087690b7da8b0ac4d9d2d49051a9becf0030', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I7ef3035e8cb342c7b8d1494903a58fc292ec2485\n'}]",0,139477,8287087690b7da8b0ac4d9d2d49051a9becf0030,36,6,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I7ef3035e8cb342c7b8d1494903a58fc292ec2485
",git fetch https://review.opendev.org/openstack/murano-agent refs/changes/77/139477/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,8287087690b7da8b0ac4d9d2d49051a9becf0030,infra-manual,* http://docs.openstack.org/infra/manual/developers.html * http://docs.openstack.org/infra/manual/developers.html#development-workflow,* http://wiki.openstack.org/HowToContribute * https://wiki.openstack.org/wiki/GerritWorkflow,2,2
openstack%2Ffuel-web~master~Ia85d6f4668b9be94480bd07d78fe968a805f0f97,openstack/fuel-web,master,Ia85d6f4668b9be94480bd07d78fe968a805f0f97,Do not save task.message in action logs,MERGED,2014-12-11 17:13:19.000000000,2014-12-12 10:29:27.000000000,2014-12-12 10:27:37.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8907}, {'_account_id': 8931}, {'_account_id': 8954}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}]","[{'number': 1, 'created': '2014-12-11 17:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4248e360810a8bc19641a71f46d2e3585938de9a', 'message': 'taks.message is not saved in action logs\n\nKey ""additional_info.message"" is kept to keep compatibility with\ncurrent validation and migration in collector.\nTest added.\n\nChange-Id: Ia85d6f4668b9be94480bd07d78fe968a805f0f97\nCloses-Bug: #1401572\n'}, {'number': 2, 'created': '2014-12-12 08:29:03.000000000', 'files': ['nailgun/nailgun/task/helpers.py', 'nailgun/nailgun/test/integration/test_task_managers.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b77f20bc1a7b45dac71f02f960934270c24ccceb', 'message': 'Do not save task.message in action logs\n\ntask.message is not saved in action logs now.\nKey ""additional_info.message"" is kept to keep compatibility with\ncurrent validation and migration in collector.\nTest added.\n\nChange-Id: Ia85d6f4668b9be94480bd07d78fe968a805f0f97\nCloses-Bug: #1401572\n'}]",1,141102,b77f20bc1a7b45dac71f02f960934270c24ccceb,21,9,2,8392,,,0,"Do not save task.message in action logs

task.message is not saved in action logs now.
Key ""additional_info.message"" is kept to keep compatibility with
current validation and migration in collector.
Test added.

Change-Id: Ia85d6f4668b9be94480bd07d78fe968a805f0f97
Closes-Bug: #1401572
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/02/141102/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/task/helpers.py', 'nailgun/nailgun/test/integration/test_task_managers.py']",2,4248e360810a8bc19641a71f46d2e3585938de9a,bug/1401572," self.assertEqual(action_log.additional_info[""message""], """") self.assertEqual(al.additional_info[""message""], """")",,3,1
openstack%2Fgnocchi~master~I7594eecc07a625d4bd707867f35fc84307c3ed22,openstack/gnocchi,master,I7594eecc07a625d4bd707867f35fc84307c3ed22,Remove useless dependencies,MERGED,2014-12-12 08:43:02.000000000,2014-12-12 10:28:10.000000000,2014-12-12 10:28:09.000000000,"[{'_account_id': 3}, {'_account_id': 2284}]","[{'number': 1, 'created': '2014-12-12 08:43:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/749a7b0b8850427ce8c710a64ee9a9b588080669', 'message': 'Remove useless dependencies\n\nChange-Id: I7594eecc07a625d4bd707867f35fc84307c3ed22\n'}, {'number': 2, 'created': '2014-12-12 09:58:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/59dec8f75c9ba50a8598534aaa6b9894611b2f5a', 'message': 'Remove useless dependencies\n\nChange-Id: I7594eecc07a625d4bd707867f35fc84307c3ed22\n'}]",0,141307,59dec8f75c9ba50a8598534aaa6b9894611b2f5a,8,2,2,1669,,,0,"Remove useless dependencies

Change-Id: I7594eecc07a625d4bd707867f35fc84307c3ed22
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/07/141307/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,749a7b0b8850427ce8c710a64ee9a9b588080669,jd/remove-dep,,lockfile>=0.9.1# pytimeparse misses this dep for now future,0,3
openstack%2Fopenstack-specs~master~I3458bc41aa1d4f2425e2a0603d00560173921402,openstack/openstack-specs,master,I3458bc41aa1d4f2425e2a0603d00560173921402,Workflow documentation is now in infra-manual,MERGED,2014-12-05 03:43:08.000000000,2014-12-12 10:20:59.000000000,2014-12-12 10:20:59.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 6772}]","[{'number': 1, 'created': '2014-12-05 03:43:08.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-specs/commit/5191b37a08b7cbdcdac8be7f15af8cad44d7978d', 'message': 'Workflow documentation is now in infra-manual\n\nReplace URLs for workflow documentation to appropriate parts of the\nOpenStack Project Infrastructure Manual.\n\nChange-Id: I3458bc41aa1d4f2425e2a0603d00560173921402\n'}]",0,139346,5191b37a08b7cbdcdac8be7f15af8cad44d7978d,10,5,1,5263,,,0,"Workflow documentation is now in infra-manual

Replace URLs for workflow documentation to appropriate parts of the
OpenStack Project Infrastructure Manual.

Change-Id: I3458bc41aa1d4f2425e2a0603d00560173921402
",git fetch https://review.opendev.org/openstack/openstack-specs refs/changes/46/139346/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,5191b37a08b7cbdcdac8be7f15af8cad44d7978d,infra-manual,you must follow the steps in this page: http://docs.openstack.org/infra/manual/developers.html http://docs.openstack.org/infra/manual/developers.html#development-workflow,"you must follow the steps in the ""If you're a developer, start here"" section of this page: http://wiki.openstack.org/HowToContribute http://wiki.openstack.org/GerritWorkflow",3,4
openstack%2Fsahara~master~I32116d42453bd3470b65bf863cf493f27301dab7,openstack/sahara,master,I32116d42453bd3470b65bf863cf493f27301dab7,Enable HDFS NameNode High Availability with HDP 2.0.6 plugin,MERGED,2014-10-30 15:43:53.000000000,2014-12-12 10:20:10.000000000,2014-12-12 10:20:10.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8091}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12561}, {'_account_id': 13207}]","[{'number': 1, 'created': '2014-10-30 15:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/668b48d1c5602c4f4f49bdebb72a1a945aece499', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 2, 'created': '2014-11-18 12:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/6d4bbd5df45eec13ec2a47a78416f1c03f4fa60d', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 3, 'created': '2014-11-18 12:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c9f790b6be50b5bca2fe73e04f9e6ef3a8487772', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 4, 'created': '2014-11-19 10:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e092978460cc1e5b453b3ad4fa1f78769fe7d991', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 5, 'created': '2014-11-24 12:46:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8ec1d08529efdd560b6c9847e92d5ac4499b6c99', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 6, 'created': '2014-11-24 14:57:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cfd744604afb9c50d3f29e4e34b5e5fdef5e1c57', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 7, 'created': '2014-11-25 11:14:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d5ec7a0205de84981ccbd95fc7ebfadd45161031', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 8, 'created': '2014-11-25 11:16:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/522fa86e775bfda5284f4d2dccfe44fc973d0a37', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 9, 'created': '2014-11-25 14:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f096e651228cfa540da8e9a96443f7ebdaebefb9', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 10, 'created': '2014-11-27 10:09:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/85b9127365ceda4f64f83a208f33fbd9d7d5f47f', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 11, 'created': '2014-12-02 12:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d038a10c34274ec8a8634fb400d5bda93967de82', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 12, 'created': '2014-12-02 13:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/ff762d25e13b77f3c20d5cb8ca49aea2588505fc', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 13, 'created': '2014-12-02 14:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0d18a8acb97b2cd14d1a0ed07486adbf9e3e162b', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 14, 'created': '2014-12-08 10:14:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/0eab1fe9ac2d65dc73af091abb6443dd51f2839a', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 15, 'created': '2014-12-11 15:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8769b4f34f4cdee7c3e7c60357d6b7e85b45fcf0', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}, {'number': 16, 'created': '2014-12-12 08:20:42.000000000', 'files': ['sahara/plugins/hdp/versions/version_2_0_6/resources/ambari-config-resource.json', 'sahara/tests/unit/plugins/hdp/test_clusterspec_hdp2.py', 'sahara/plugins/hdp/clusterspec.py', 'sahara/plugins/hdp/hadoopserver.py', 'doc/source/userdoc/hdp_plugin.rst', 'sahara/plugins/hdp/versions/version_2_0_6/resources/default-cluster.template', 'sahara/tests/unit/plugins/hdp/hdp_test_base.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py', 'sahara/plugins/exceptions.py', 'doc/source/userdoc/features.rst', 'sahara/plugins/hdp/ambariplugin.py', 'sahara/plugins/hdp/versions/version_2_0_6/services.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/6894d85bb88b34ec33fc0bece7f356983a0392f2', 'message': 'Enable HDFS NameNode High Availability with HDP 2.0.6 plugin\n\nExtend HDP 2.0.6 plugin to include the setup and configuration of the\nHDFS NameNode High Availability after creating and configuring\nthe cluster.\n\nChange-Id: I32116d42453bd3470b65bf863cf493f27301dab7\nImplements: blueprint hdp-plugin-enable-hdfs-ha\n'}]",47,132051,6894d85bb88b34ec33fc0bece7f356983a0392f2,105,12,16,13207,,,0,"Enable HDFS NameNode High Availability with HDP 2.0.6 plugin

Extend HDP 2.0.6 plugin to include the setup and configuration of the
HDFS NameNode High Availability after creating and configuring
the cluster.

Change-Id: I32116d42453bd3470b65bf863cf493f27301dab7
Implements: blueprint hdp-plugin-enable-hdfs-ha
",git fetch https://review.opendev.org/openstack/sahara refs/changes/51/132051/16 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/exceptions.py', 'sahara/plugins/hdp/versions/version_2_0_6/resources/ambari-config-resource.json', 'sahara/service/ops.py', 'sahara/plugins/hdp/clusterspec.py', 'sahara/plugins/hdp/hadoopserver.py', 'sahara/plugins/hdp/ambariplugin.py', 'sahara/plugins/hdp/versions/version_2_0_6/resources/default-cluster.template', 'sahara/plugins/hdp/versions/version_2_0_6/services.py', 'sahara/plugins/provisioning.py', 'sahara/plugins/hdp/versions/version_2_0_6/versionhandler.py']",10,668b48d1c5602c4f4f49bdebb72a1a945aece499,bp/hdp-plugin-enable-hdfs-ha," if (status == 'FAILED' or status == 'ABORTED' or status == 'TIMEDOUT'): def setup_hdfs_ha(self, cluster_spec, servers, ambari_info, name): # Get HA cluster map hac = self._hdfs_ha_cluster_map(cluster_spec, servers, ambari_info, name) # start active namenode in order to format and save namesapce self._hdfs_ha_update_host_component(hac, hac['nn_active'], 'NAMENODE', 'STARTED') hac['server_active'].set_namenode_safemode() hac['server_active'].save_namenode_namespace() # shutdown active namenode self._hdfs_ha_update_host_component(hac, hac['nn_active'], 'NAMENODE', 'INSTALLED') # Install HDFS_CLIENT on namenodes, to be used later for updating # HDFS configs if hac['nn_active'] not in hac['hdfsc_hosts']: self._hdfs_ha_add_host_component(hac, hac['nn_active'], 'HDFS_CLIENT') if hac['nn_standby'] not in hac['hdfsc_hosts']: self._hdfs_ha_add_host_component(hac, hac['nn_standby'], 'HDFS_CLIENT') # start the journal_nodes for jn in hac['jn_hosts']: self._hdfs_ha_update_host_component(hac, jn, 'JOURNALNODE', 'STARTED') # disable any secondary namnodes for snn in hac['snn_hosts']: self._hdfs_ha_update_host_component(hac, snn, 'SECONDARY_NAMENODE', 'DISABLED') # get hdfs-site config tag hdfs_site_tag = self._hdfs_ha_get_config_tag(hac, 'hdfs-site') # get hdfs-site config hdfs_site = self._hdfs_ha_get_config(hac, 'hdfs-site', hdfs_site_tag) # update hdfs-site with HDFS HA properties hdfs_site_ha = self._hdfs_ha_update_hdfs_site(hac, hdfs_site) # put new hdfs-site config self._hdfs_ha_put_config(hac, 'hdfs-site', hac['config_ver'], hdfs_site_ha) # get core-site tag core_site_tag = self._hdfs_ha_get_config_tag(hac, 'core-site') # get core-site config core_site = self._hdfs_ha_get_config(hac, 'core-site', core_site_tag) # update core-site with HDFS HA properties core_site_ha = self._hdfs_ha_update_core_site(hac, core_site) # put new HA core-site config self._hdfs_ha_put_config(hac, 'core-site', hac['config_ver'], core_site_ha) # update hbase-site if Hbase is installed if hac['hbase_hosts']: hbase_site_tag = self._hdfs_ha_get_config_tag(hac, 'hbase-site') hbase_site = self._hdfs_ha_get_config(hac, 'hbase-site', hbase_site_tag) hbase_site_ha = self._hdfs_ha_update_hbase_site(hac, hbase_site) self._hdfs_ha_put_config(hac, 'hbase_site', hac['config_ver'], hbase_site_ha) # force the deployment of HDFS HA configs on namenodes by re-installing # hdfs-client self._hdfs_ha_update_host_component(hac, hac['nn_active'], 'HDFS_CLIENT', 'INSTALLED') self._hdfs_ha_update_host_component(hac, hac['nn_standby'], 'HDFS_CLIENT', 'INSTALLED') # initialize shared edits on the active namenode hac['server_active'].initialize_shared_edits() # start zookeeper servers for zk in hac['zk_hosts']: self._hdfs_ha_update_host_component(hac, zk, 'ZOOKEEPER_SERVER', 'STARTED') # start active namenode self._hdfs_ha_update_host_component(hac, hac['nn_active'], 'NAMENODE', 'STARTED') # setup active namenode automatic failover hac['server_active'].format_zookeeper_fc() # format standby namenode hac['server_standby'].bootstrap_standby_namenode() # start namenode process on standby namenode self._hdfs_ha_update_host_component(hac, hac['nn_standby'], 'NAMENODE', 'STARTED') # add, install and start ZKFC on namenodes for automatic fail-over for nn in hac['nn_hosts']: self._hdfs_ha_add_host_component(hac, nn, 'ZKFC') self._hdfs_ha_update_host_component(hac, nn, 'ZKFC', 'INSTALLED') self._hdfs_ha_update_host_component(hac, nn, 'ZKFC', 'STARTED') # delete any secondary namenodes for snn in hac['snn_hosts']: self._hdfs_ha_delete_host_component(hac, snn, 'SECONDARY_NAMENODE') # stop journalnodes and namenodes before terminating # not doing so causes warnings in Ambari for stale config for jn in hac['jn_hosts']: self._hdfs_ha_update_host_component(hac, jn, 'JOURNALNODE', 'INSTALLED') for nn in hac['nn_hosts']: self._hdfs_ha_update_host_component(hac, nn, 'NAMENODE', 'INSTALLED') # install httpfs and write temp file if HUE is installed if hac['hue_host']: self._hdfs_ha_setup_hue(hac) def _hdfs_ha_cluster_map(self, cluster_spec, servers, ambari_info, name): hacluster = {} hacluster['name'] = name hacluster['config_ver'] = 'v2' # set namnode ports hacluster['nn_rpc'] = '8020' hacluster['nn_ui'] = '50070' # set HA cluster name hacluster['ha_name'] = name hacluster['ambari_info'] = ambari_info # get host lists hacluster['nn_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'NAMENODE')] hacluster['snn_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'SECONDARY_NAMENODE')] hacluster['jn_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'JOURNALNODE')] hacluster['zk_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'ZOOKEEPER_SERVER')] hacluster['hdfsc_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'HDFS_CLIENT')] hacluster['hbase_hosts'] = [x.fqdn().lower() for x in cluster_spec.determine_component_hosts( 'HBASE_MASTER')] hues = cluster_spec.determine_component_hosts('HUE') hacluster['hue_host'] = [] for hue in hues: hacluster['hue_host'].append(hue.fqdn().lower()) # get servers for remote command execution # consider hacluster['nn_hosts'][0] as active namenode hacluster['nn_active'] = hacluster['nn_hosts'][0] hacluster['nn_standby'] = hacluster['nn_hosts'][1] # get the 2 namenode servers and hue server for server in servers: if server.instance.fqdn().lower() == hacluster['nn_active']: hacluster['server_active'] = server if server.instance.fqdn().lower() == hacluster['nn_standby']: hacluster['server_standby'] = server if hacluster['hue_host']: if server.instance.fqdn().lower() == hacluster['hue_host'][0]: hacluster['server_hue'] = server return hacluster def _hdfs_ha_delete_host_component(self, hac, host, component): delete_service_component_url = ('http://{0}/api/v1/clusters/{1}/hosts' '/{2}/host_components/{3}').format( hac['ambari_info'].get_address(), hac['name'], host, component) result = self._delete(delete_service_component_url, hac['ambari_info']) if result.status_code != 200: LOG.error(_LE('Configuring HDFS HA failed. %s'), result.text) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_add_host_component(self, hac, host, component): add_host_component_url = ('http://{0}/api/v1/clusters/{1}' '/hosts/{2}/host_components/{3}').format( hac['ambari_info'].get_address(), hac['name'], host, component) result = self._post(add_host_component_url, hac['ambari_info']) if result.status_code != 201: LOG.error(_LE('Configuring HDFS HA failed. %s'), result.text) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_update_host_component(self, hac, host, component, state): update_host_component_url = ('http://{0}/api/v1/clusters/{1}' '/hosts/{2}/host_components/{3}').format( hac['ambari_info'].get_address(), hac['name'], host, component) component_state = {""HostRoles"": {""state"": state}} body = json.dumps(component_state) result = self._put(update_host_component_url, hac['ambari_info'], data=body) if result.status_code == 202: json_result = json.loads(result.text) request_id = json_result['Requests']['id'] success = self._wait_for_async_request(self._get_async_request_uri( hac['ambari_info'], hac['name'], request_id), hac['ambari_info']) if success: LOG.info(_LI(""HDFS-HA : Host component updated successfully : "" ""{0} {1}"").format(host, component)) else: LOG.critical(_LC(""HDFS-HA : Host component update failed : "" ""{0} {1}"").format(host, component)) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) elif result.status_code != 200: LOG.error( _LE('Configuring HDFS HA failed. {0}').format(result.text)) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_get_config_tag(self, hac, config_name): config_url = ('http://{0}/api/v1/clusters/{1}' '/configurations?type={2}').format( hac['ambari_info'].get_address(), hac['name'], config_name) result = self._get(config_url, hac['ambari_info']) if result.status_code == 200: json_result = json.loads(result.text) items = json_result['items'] return items[0]['tag'] else: LOG.error( _LE('Configuring HDFS HA failed. {0}').format(result.text)) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_get_config(self, hac, config_name, tag): config_url = ('http://{0}/api/v1/clusters/{1}' '/configurations?type={2}&tag={3}').format( hac['ambari_info'].get_address(), hac['name'], config_name, tag) result = self._get(config_url, hac['ambari_info']) if result.status_code == 200: json_result = json.loads(result.text) items = json_result['items'] return items[0]['properties'] else: LOG.error( _LE('Configuring HDFS HA failed. {0}').format(result.text)) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_put_config(self, hac, config_name, tag, properties): config_url = ('http://{0}/api/v1/clusters/{1}').format( hac['ambari_info'].get_address(), hac['name']) body = {} clusters = {} body['Clusters'] = clusters body['Clusters']['desired_config'] = {} body['Clusters']['desired_config']['type'] = config_name body['Clusters']['desired_config']['tag'] = tag body['Clusters']['desired_config']['properties'] = properties LOG.debug((""body : %s"") % (body)) result = self._put(config_url, hac['ambari_info'], data=json.dumps(body)) if result.status_code != 200: LOG.error( _LE('Configuring HDFS HA failed. {0}').format(result.text)) raise ex.NameNodeHAConfigurationError( 'Configuring HDFS HA failed. %s' % result.text) def _hdfs_ha_update_hdfs_site(self, hac, hdfs_site): hdfs_site['dfs.nameservices'] = hac['ha_name'] hdfs_site['dfs.ha.namenodes.{0}'.format( hac['ha_name'])] = hac['nn_active'] + ',' + hac['nn_standby'] hdfs_site['dfs.namenode.rpc-address.{0}.{1}'.format( hac['ha_name'], hac['nn_active'])] = '{0}:{1}'.format( hac['nn_active'], hac['nn_rpc']) hdfs_site['dfs.namenode.rpc-address.{0}.{1}'.format( hac['ha_name'], hac['nn_standby'])] = '{0}:{1}'.format( hac['nn_standby'], hac['nn_rpc']) hdfs_site['dfs.namenode.http-address.{0}.{1}'.format( hac['ha_name'], hac['nn_active'])] = '{0}:{1}'.format( hac['nn_active'], hac['nn_ui']) hdfs_site['dfs.namenode.http-address.{0}.{1}'.format( hac['ha_name'], hac['nn_standby'])] = '{0}:{1}'.format( hac['nn_standby'], hac['nn_ui']) qjournal = ';'.join([x+':8485' for x in hac['jn_hosts']]) hdfs_site['dfs.namenode.shared.edits.dir'] = ('qjournal://{0}/{1}'. format(qjournal, hac['ha_name'])) hdfs_site['dfs.client.failover.proxy.provider.{0}'.format( hac['ha_name'])] = (""org.apache.hadoop.hdfs.server.namenode.ha."" ""ConfiguredFailoverProxyProvider"") hdfs_site['dfs.ha.fencing.methods'] = 'shell(/bin/true)' hdfs_site['dfs.ha.automatic-failover.enabled'] = 'true' return hdfs_site def _hdfs_ha_update_core_site(self, hac, core_site): core_site['fs.defaultFS'] = 'hdfs://{0}'.format(hac['ha_name']) core_site['ha.zookeeper.quorum'] = '{0}'.format( ','.join([x+':2181' for x in hac['zk_hosts']])) # if HUE is installed add some httpfs configs if hac['hue_host']: core_site['hadoop.proxyuser.httpfs.groups'] = '*' core_site['hadoop.proxyuser.httpfs.hosts'] = '*' return core_site def _hdfs_ha_update_hbase_site(self, hac, hbase_site): hbase_site['hbase.rootdir'] = 'hdfs://{0}/apps/hbase/data'.format( hac['ha_name']) return hbase_site def _hdfs_ha_setup_hue(self, hac): hac['server_hue'].install_httpfs() # write a temp file and # use it when starting HUE with HDFS HA enabled hac['server_hue'].write_hue_temp_file('/tmp/hueini-hdfsha', hac['ha_name']) hac['server_hue'].start_httpfs()", if status == 'FAILED' or status == 'ABORTED':,595,5
openstack%2Fceilometer~master~I0d186247b4b87fd94317318c180bdfb9c6da70fc,openstack/ceilometer,master,I0d186247b4b87fd94317318c180bdfb9c6da70fc,Encompassing one source pollsters with common context,MERGED,2014-12-04 12:26:57.000000000,2014-12-12 10:19:50.000000000,2014-12-12 10:19:49.000000000,"[{'_account_id': 3}, {'_account_id': 2284}, {'_account_id': 3012}, {'_account_id': 7729}, {'_account_id': 8052}, {'_account_id': 9562}, {'_account_id': 10987}]","[{'number': 1, 'created': '2014-12-04 12:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e81c7757abe3c870e7a532c564938d34e298db52', 'message': '[WIP] encompassing one source pollsters with common context\n\nAfter per-source separation of static resources & discovery samples are\npublishing with context of separate pollster, so if it is used arithmetic\ntransformer that handle different meters , it will fail.\n\nNow samples are publishing from source context, after all source meters\nwere  collected.\n\n(WIP writing tests to check samples created with arithmetic transformer)\n\nChange-Id: I0d186247b4b87fd94317318c180bdfb9c6da70fc\nCloses-bug: #1394228\n'}, {'number': 2, 'created': '2014-12-09 13:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/69fd371f8dfc080f14bee63570a196518ef0842a', 'message': 'Encompassing one source pollsters with common context\n\nAfter per-source separation of static resources & discovery samples are\npublishing with context of separate pollster, so if it is used arithmetic\ntransformer which handle different meters, it will fail.\n\nNow samples are publishing from common source context, after all \nsource meters have been collected.\n\nChange-Id: I0d186247b4b87fd94317318c180bdfb9c6da70fc\nCloses-bug: #1394228'}, {'number': 3, 'created': '2014-12-10 15:45:03.000000000', 'files': ['ceilometer/tests/agentbase.py', 'ceilometer/agent.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/21935cb0c1074233a0782795d3cdf7d2798fd67d', 'message': 'Encompassing one source pollsters with common context\n\nAfter per-source separation of static resources & discovery samples are\npublishing with context of separate pollster, so if it is used arithmetic\ntransformer which handle different meters, it will fail.\n\nNow samples are publishing from common source context, after all\nsource meters have been collected.\n\nChange-Id: I0d186247b4b87fd94317318c180bdfb9c6da70fc\nCloses-bug: #1394228\n'}]",0,139037,21935cb0c1074233a0782795d3cdf7d2798fd67d,13,7,3,10987,,,0,"Encompassing one source pollsters with common context

After per-source separation of static resources & discovery samples are
publishing with context of separate pollster, so if it is used arithmetic
transformer which handle different meters, it will fail.

Now samples are publishing from common source context, after all
source meters have been collected.

Change-Id: I0d186247b4b87fd94317318c180bdfb9c6da70fc
Closes-bug: #1394228
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/37/139037/1 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/agentbase.py', 'ceilometer/agent.py']",2,e81c7757abe3c870e7a532c564938d34e298db52,transformer," def key(source_name, pollster): return '%s-%s' % (source_name, pollster.name) self.pollster_matches = collections.defaultdict(set) self.pollster_matches[pipeline.source.name].add(pollster) key = Resources.key(pipeline.source.name, pollster) for source_name in self.pollster_matches: with self.publishers[source_name] as publisher: for pollster in self.pollster_matches[source_name]: LOG.info(_(""Polling pollster %(poll)s in the context of "" ""%(src)s""), dict(poll=pollster.name, src=source_name)) pollster_resources = None if pollster.obj.default_discovery: pollster_resources = self.manager.discover( [pollster.obj.default_discovery], discovery_cache) key = Resources.key(source_name, pollster) source_resources = list( self.resources[key].get(discovery_cache)) polling_resources = (source_resources or pollster_resources or agent_resources) if not polling_resources: LOG.info(_( ""Skip polling pollster %s, no resources found""), pollster.name) continue try: samples = list(pollster.obj.get_samples( manager=self.manager, cache=cache, resources=polling_resources )) publisher(samples) except Exception as err: LOG.warning(_( 'Continue after error from %(name)s: %(error)s') % ({'name': pollster.name, 'error': err}), exc_info=True)"," def key(source, pollster): return '%s-%s' % (source.name, pollster.name) self.pollster_matches = set() self.pollster_matches.update([(pipeline.source, pollster)]) key = Resources.key(pipeline.source, pollster) for source, pollster in self.pollster_matches: LOG.info(_(""Polling pollster %(poll)s in the context of %(src)s""), dict(poll=pollster.name, src=source)) pollster_resources = None if pollster.obj.default_discovery: pollster_resources = self.manager.discover( [pollster.obj.default_discovery], discovery_cache) key = Resources.key(source, pollster) source_resources = list(self.resources[key].get(discovery_cache)) polling_resources = (source_resources or pollster_resources or agent_resources) if not polling_resources: LOG.info(_(""Skip polling pollster %s, no resources found""), pollster.name) continue with self.publishers[source.name] as publisher: try: samples = list(pollster.obj.get_samples( manager=self.manager, cache=cache, resources=polling_resources )) publisher(samples) except Exception as err: LOG.warning(_( 'Continue after error from %(name)s: %(error)s') % ({'name': pollster.name, 'error': err}), exc_info=True)",40,35
openstack%2Fec2-api~master~Ic9af4f35239e534b4ce05cd186f071cd22f8882d,openstack/ec2-api,master,Ic9af4f35239e534b4ce05cd186f071cd22f8882d,support aws v4 signature,MERGED,2014-12-11 19:05:04.000000000,2014-12-12 10:15:18.000000000,2014-12-12 10:15:17.000000000,"[{'_account_id': 3}, {'_account_id': 9312}, {'_account_id': 10224}]","[{'number': 1, 'created': '2014-12-11 19:05:04.000000000', 'files': ['.gitignore', 'ec2api/api/__init__.py', 'etc/ec2api/api-paste.ini'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/e4c4463ab10ebf6e21d84f9b3369494b0055f963', 'message': 'support aws v4 signature\n\nChange-Id: Ic9af4f35239e534b4ce05cd186f071cd22f8882d\n'}]",0,141132,e4c4463ab10ebf6e21d84f9b3369494b0055f963,6,3,1,10234,,,0,"support aws v4 signature

Change-Id: Ic9af4f35239e534b4ce05cd186f071cd22f8882d
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/32/141132/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'ec2api/api/__init__.py', 'etc/ec2api/api-paste.ini']",3,e4c4463ab10ebf6e21d84f9b3369494b0055f963,,/: ec2apicloud,/services/Cloud: ec2apicloud,146,81
openstack%2Fmurano~master~I602279541353fad148f3e719950b8dac6b1af021,openstack/murano,master,I602279541353fad148f3e719950b8dac6b1af021,Test commit,ABANDONED,2014-12-12 09:40:50.000000000,2014-12-12 10:12:53.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 10068}, {'_account_id': 14266}]","[{'number': 1, 'created': '2014-12-12 09:40:50.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/murano/commit/cdc8ca4119611462e488a4256cf3fe44b11dce88', 'message': 'Test commit\n\nChange-Id: I602279541353fad148f3e719950b8dac6b1af021\n'}]",0,141312,cdc8ca4119611462e488a4256cf3fe44b11dce88,7,4,1,14266,,,0,"Test commit

Change-Id: I602279541353fad148f3e719950b8dac6b1af021
",git fetch https://review.opendev.org/openstack/murano refs/changes/12/141312/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cdc8ca4119611462e488a4256cf3fe44b11dce88,,No license (just test),Apache License Version 2.0 http://www.apache.org/licenses/LICENSE-2.0,1,1
openstack%2Fsahara-specs~master~Ib35f29ed86f8d670ccf065fd7175015178966d2e,openstack/sahara-specs,master,Ib35f29ed86f8d670ccf065fd7175015178966d2e,Add more services into CDH,MERGED,2014-12-05 08:50:58.000000000,2014-12-12 10:00:20.000000000,2014-12-12 10:00:19.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 8090}, {'_account_id': 8411}]","[{'number': 1, 'created': '2014-12-05 08:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/c2df380208d930e82e69263d1db45d1608f27f2f', 'message': 'Add more services into CDH\n\nWe plan to add Flume, Sentry, SOLR, Sqoop, Key-Value Store Indexer,\nand Impala services in one time.\n\nImplements bp: add-cdh-more-services\n\nChange-Id: Ib35f29ed86f8d670ccf065fd7175015178966d2e\n'}, {'number': 2, 'created': '2014-12-05 08:52:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/705e0489611ce15869f651b5870795e46c34375e', 'message': 'Add more services into CDH\n\nWe plan to add Flume, Sentry, SOLR, Sqoop, Key-Value Store Indexer,\nand Impala services in one time.\n\nImplements bp: add-cdh-more-services\n\nChange-Id: Ib35f29ed86f8d670ccf065fd7175015178966d2e\n'}, {'number': 3, 'created': '2014-12-09 15:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/afc759cca56f1d2d1f7015ae9cad679cdb813e2c', 'message': 'Add more services into CDH\n\nWe plan to add Flume, Sentry, SOLR, Sqoop, Key-Value Store Indexer,\nand Impala services in one time.\n\nImplements bp: add-cdh-more-services\n\nChange-Id: Ib35f29ed86f8d670ccf065fd7175015178966d2e\n'}, {'number': 4, 'created': '2014-12-10 01:35:46.000000000', 'files': ['specs/kilo/add-more-cdh-services.rst'], 'web_link': 'https://opendev.org/openstack/sahara-specs/commit/afd716414005400375bcddea6e87772cfe260464', 'message': 'Add more services into CDH\n\nWe plan to add Flume, Sentry, SOLR, Sqoop, Key-Value Store Indexer,\nand Impala services in one time.\n\nImplements bp: add-cdh-more-services\n\nChange-Id: Ib35f29ed86f8d670ccf065fd7175015178966d2e\n'}]",2,139574,afd716414005400375bcddea6e87772cfe260464,17,4,4,13662,,,0,"Add more services into CDH

We plan to add Flume, Sentry, SOLR, Sqoop, Key-Value Store Indexer,
and Impala services in one time.

Implements bp: add-cdh-more-services

Change-Id: Ib35f29ed86f8d670ccf065fd7175015178966d2e
",git fetch https://review.opendev.org/openstack/sahara-specs refs/changes/74/139574/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/add-more-cdh-services.rst'],1,c2df380208d930e82e69263d1db45d1608f27f2f,bp/add-cdh-more-services,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Add More Services into CDH plugin ========================================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/sahara/+spec/add-cdh-more-services This specification proposes to add below services into CDH plugins: Flume, Sentry, Sqoop, SOLR, Key-Value Store Indexer, and Impala. Those services can be added into CDH plugin by using CM API first_run to start them, which can save much effort to prepare and start those services one by one. Problem description =================== Now services supported in Sahara CDH plugin is still limited. We wan to add more services ASAP. They are Flume, Sentry, Sqoop, SOLR, Key-Value Store Indexer, and Impala. Proposed change =============== Since we plan to use first_run to prepare and start those services, we will not need to call other CM APIs for those services in start_cluster() method. The implementation will need below changes on codes for each service: * Add process names of the service in some places. * Add service or process configuration, and network ports to open. * Add service validation. * Moidify some util methods, like get_service, to meet more services. * Some other changes for a few specific services if needed. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Other end user impact --------------------- None Deployer impact --------------- None Developer impact ---------------- None Sahara-image-elements impact ---------------------------- None Sahara-dashboard / Horizon impact --------------------------------- None Implementation ============== Assignee(s) ----------- Primary assignee: ken chen Other contributors: ken chen Work Items ---------- The work items will be: * Change python codes in sahara/sahara/plugins/cdh. * Add more service resource files in sahara/sahara/plugins/cdh/resources. * Test and evaluate the change. Dependencies ============ None Testing ======= Take an integration test to create a cluster. Documentation Impact ==================== None References ========== None ",,120,0
openstack%2Fsahara-image-elements~master~I042a55697a36a9b4dbf1da0a29cf357dbab54dee,openstack/sahara-image-elements,master,I042a55697a36a9b4dbf1da0a29cf357dbab54dee,Adding ability to build images for Hadoop 2.6.0,MERGED,2014-12-02 15:12:47.000000000,2014-12-12 09:59:11.000000000,2014-12-12 09:59:10.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8411}, {'_account_id': 8932}, {'_account_id': 12039}]","[{'number': 1, 'created': '2014-12-02 15:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/67ca4783a5e7909e35a8fad04cfd7514de0c6b30', 'message': 'Adding ability to build images for Hadoop 2.6.0\n\nChange-Id: I042a55697a36a9b4dbf1da0a29cf357dbab54dee\n'}, {'number': 2, 'created': '2014-12-09 14:23:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/75bf9f901b059536fee809e9c1f6d29d29649963', 'message': 'Adding ability to build images for Hadoop 2.6.0\n\npartially implements bp: add-vanilla-2-hadoop-2-6-0\n\nChange-Id: I042a55697a36a9b4dbf1da0a29cf357dbab54dee\n'}, {'number': 3, 'created': '2014-12-09 15:17:14.000000000', 'files': ['elements/oozie/install.d/50-setup-oozie', 'diskimage-create/diskimage-create.sh', 'elements/hadoop/post-install.d/40-setup-hadoop', 'elements/oozie/root.d/0-check'], 'web_link': 'https://opendev.org/openstack/sahara-image-elements/commit/f2a0837046b2ef448fcbe134dfe107d037bc43c6', 'message': 'Adding ability to build images for Hadoop 2.6.0\n\npartially implements bp: add-vanilla-2-hadoop-2-6-0\n\nChange-Id: I042a55697a36a9b4dbf1da0a29cf357dbab54dee\n'}]",4,138391,f2a0837046b2ef448fcbe134dfe107d037bc43c6,26,8,3,12039,,,0,"Adding ability to build images for Hadoop 2.6.0

partially implements bp: add-vanilla-2-hadoop-2-6-0

Change-Id: I042a55697a36a9b4dbf1da0a29cf357dbab54dee
",git fetch https://review.opendev.org/openstack/sahara-image-elements refs/changes/91/138391/1 && git format-patch -1 --stdout FETCH_HEAD,"['diskimage-create/README.rst', 'elements/oozie/install.d/50-setup-oozie', 'diskimage-create/diskimage-create.sh', 'elements/hadoop/post-install.d/40-setup-hadoop', 'elements/oozie/root.d/0-check']",5,67ca4783a5e7909e35a8fad04cfd7514de0c6b30,bp/add-vanilla-2-hadoop-2-6-0,"elif [ ""$DIB_HADOOP_VERSION"" == ""2.6.0"" ]; then if [ -z ""$OOZIE_HADOOP_V2_6_DOWNLOAD_URL"" -a -z ""$OOZIE_HADOOP_V2_6_FILE"" ]; then echo ""OOZIE_HADOOP_V2_6_FILE and OOZIE_HADOOP_V2_6_DOWNLOAD_URL are not set. Impossible to install Oozie. Exit"" exit 1 fi",,37,6
openstack%2Ffuel-main~stable%2F6.0~Id804ff9358d56446fbec4c30f8bab498433c9734,openstack/fuel-main,stable/6.0,Id804ff9358d56446fbec4c30f8bab498433c9734,Fix wrong script path in rollback tests,MERGED,2014-12-11 14:18:47.000000000,2014-12-12 09:57:14.000000000,2014-12-12 09:57:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-12-11 14:18:47.000000000', 'files': ['fuelweb_test/tests/test_upgrade.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/2a7730609e8f3c2f6eddd9502165fa3c931dda99', 'message': 'Fix wrong script path in rollback tests\n\nSome time ago engines were moved to other folder.\n\nCloses-Bug:#1401511\n\nChange-Id: Id804ff9358d56446fbec4c30f8bab498433c9734\n(cherry picked from commit b9d3597a4b5e2a17937e8f44365fbed2aa4c25a9)\n'}]",0,141058,2a7730609e8f3c2f6eddd9502165fa3c931dda99,8,4,1,8882,,,0,"Fix wrong script path in rollback tests

Some time ago engines were moved to other folder.

Closes-Bug:#1401511

Change-Id: Id804ff9358d56446fbec4c30f8bab498433c9734
(cherry picked from commit b9d3597a4b5e2a17937e8f44365fbed2aa4c25a9)
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/58/141058/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_upgrade.py'],1,2a7730609e8f3c2f6eddd9502165fa3c931dda99,, '/var/upgrade/.fuel-upgrade-venv/lib/' 'python2.6/site-packages/' '/var/upgrade/.fuel-upgrade-venv/lib/' 'python2.6/site-packages/', '/var/upgrade/site-packages/' '/var/upgrade/site-packages/',4,2
openstack%2Ffuel-main~stable%2F6.0~I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,openstack/fuel-main,stable/6.0,I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5,Wait for Keystone start after master node reset,MERGED,2014-12-11 22:53:25.000000000,2014-12-12 09:55:58.000000000,2014-12-12 09:55:58.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11969}]","[{'number': 1, 'created': '2014-12-11 22:53:25.000000000', 'files': ['fuelweb_test/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/01a807a40012f26c5041d9144a351ac8b0dbbc87', 'message': 'Wait for Keystone start after master node reset\n\nUse protected Nailgun API URL to check that Keystone\nis up and works fine before running tests.\n\nChange-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5\nCloses-bug: #1401692\n'}]",0,141195,01a807a40012f26c5041d9144a351ac8b0dbbc87,9,6,1,11081,,,0,"Wait for Keystone start after master node reset

Use protected Nailgun API URL to check that Keystone
is up and works fine before running tests.

Change-Id: I28a84f8e2a304e18cf54eb7d08b24f0ef67503f5
Closes-bug: #1401692
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/95/141195/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/models/environment.py'],1,01a807a40012f26c5041d9144a351ac8b0dbbc87,," _wait(self._fuel_web.client.get_releases, timeout=120)"," _wait(self._fuel_web.get_nailgun_version, timeout=120)",1,1
openstack%2Ffuel-main~stable%2F6.0~I7962d8af4c57ce671c7e7c531b70aaebbbc8e330,openstack/fuel-main,stable/6.0,I7962d8af4c57ce671c7e7c531b70aaebbbc8e330,Disable monit and heat tests because these features weren't included in 6.0,MERGED,2014-12-10 14:59:48.000000000,2014-12-12 09:55:13.000000000,2014-12-12 09:55:13.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 11969}, {'_account_id': 12129}]","[{'number': 1, 'created': '2014-12-10 14:59:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/8b8ef50acb62d1d728c09a7aad6f220393c9408d', 'message': ""Add skiptest to monit and heat tests because these\nfeatures weren't included in 6.0\n\nChange-Id: I7962d8af4c57ce671c7e7c531b70aaebbbc8e330\nCloses-Bug: #1400258\n""}, {'number': 2, 'created': '2014-12-12 08:44:01.000000000', 'files': ['fuelweb_test/tests/tests_strength/test_failover.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/932c550968fd22dcc988b0697b6472d72a8070ea', 'message': ""Disable monit and heat tests because these\nfeatures weren't included in 6.0\n\nChange-Id: I7962d8af4c57ce671c7e7c531b70aaebbbc8e330\nCloses-Bug: #1400258\n""}]",2,140710,932c550968fd22dcc988b0697b6472d72a8070ea,14,6,2,10136,,,0,"Disable monit and heat tests because these
features weren't included in 6.0

Change-Id: I7962d8af4c57ce671c7e7c531b70aaebbbc8e330
Closes-Bug: #1400258
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/10/140710/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/tests_strength/test_failover.py'],1,8b8ef50acb62d1d728c09a7aad6f220393c9408d,disableMonit," raise SkipTest(""feature isn't implemented in this iso version"") raise SkipTest(""feature isn't implemented in this iso version"")",,2,0
openstack%2Ffuel-main~stable%2F6.0~Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6,openstack/fuel-main,stable/6.0,Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6,6.0 Add single path variable for each plugin,MERGED,2014-12-11 11:33:25.000000000,2014-12-12 09:50:39.000000000,2014-12-12 09:50:39.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-12-11 11:33:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ad36a9057c31311cfaf662d3c41655cf73662681', 'message': '6.0 Add single path veriable for aech plugin\n\nTo get possibility download 3 plugin during\nswarm tets we add single path variable\nfor each plugin:\n* GLUSTER_PLUGIN_PATH\n* EXAMPLE_PLUGIN_PATH\n* LBAAS_PLUGIN_PATH\n\nChange-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6\nCloses-Bug: #1401219\n'}, {'number': 2, 'created': '2014-12-11 13:37:03.000000000', 'files': ['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/12ef78303559322129211bf3d1f0e645ba8f702e', 'message': '6.0 Add single path variable for each plugin\n\nTo get possibility download 3 plugin during\nswarm tets we add single path variable\nfor each plugin:\n* GLUSTER_PLUGIN_PATH\n* EXAMPLE_PLUGIN_PATH\n* LBAAS_PLUGIN_PATH\n\nChange-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6\nCloses-Bug: #1401219\n'}]",0,141021,12ef78303559322129211bf3d1f0e645ba8f702e,13,5,2,6719,,,0,"6.0 Add single path variable for each plugin

To get possibility download 3 plugin during
swarm tets we add single path variable
for each plugin:
* GLUSTER_PLUGIN_PATH
* EXAMPLE_PLUGIN_PATH
* LBAAS_PLUGIN_PATH

Change-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6
Closes-Bug: #1401219
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/21/141021/2 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py']",4,ad36a9057c31311cfaf662d3c41655cf73662681,,"from fuelweb_test.settings import EXAMPLE_PLUGIN_PATH self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH)) self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH)) self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH))","from fuelweb_test.settings import PLUGIN_PATH self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH)) self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH)) self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH))",21,18
openstack%2Ffuel-main~master~Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6,openstack/fuel-main,master,Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6,Add single path variable for each plugin,MERGED,2014-12-11 11:29:59.000000000,2014-12-12 09:50:15.000000000,2014-12-12 09:50:14.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}]","[{'number': 1, 'created': '2014-12-11 11:29:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/12544ed2fb6b7253477ef402ef51e933eaf77bf6', 'message': 'Add single path veriable for aech plugin\n\nTo get possibility download 3 plugin during\nswarm tets we add single path variable\nfor each plugin:\n* GLUSTER_PLUGIN_PATH\n* EXAMPLE_PLUGIN_PATH\n* LBAAS_PLUGIN_PATH\n\nChange-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6\nCloses-Bug: #1401219\n'}, {'number': 2, 'created': '2014-12-11 11:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/1b3ceb5f435bdd9b2600f2dd9098da06ac7b78da', 'message': 'Add single path veriable for aech plugin\n\nTo get possibility download 3 plugin during\nswarm tets we add single path variable\nfor each plugin:\n* GLUSTER_PLUGIN_PATH\n* EXAMPLE_PLUGIN_PATH\n* LBAAS_PLUGIN_PATH\n\nChange-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6\nCloses-Bug: #1401219\n'}, {'number': 3, 'created': '2014-12-11 13:36:24.000000000', 'files': ['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/ab64a3d6fd2a3c4735b42007b2022a91e9345379', 'message': 'Add single path variable for each plugin\n\nTo get possibility download 3 plugin during\nswarm tets we add single path variable\nfor each plugin:\n* GLUSTER_PLUGIN_PATH\n* EXAMPLE_PLUGIN_PATH\n* LBAAS_PLUGIN_PATH\n\nChange-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6\nCloses-Bug: #1401219\n'}]",0,141020,ab64a3d6fd2a3c4735b42007b2022a91e9345379,19,5,3,6719,,,0,"Add single path variable for each plugin

To get possibility download 3 plugin during
swarm tets we add single path variable
for each plugin:
* GLUSTER_PLUGIN_PATH
* EXAMPLE_PLUGIN_PATH
* LBAAS_PLUGIN_PATH

Change-Id: Ic06bbcef9badbe99a9b2d81627f8070d9e8964f6
Closes-Bug: #1401219
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/20/141020/1 && git format-patch -1 --stdout FETCH_HEAD,"['fuelweb_test/tests/plugins/plugin_lbaas/test_plugin_lbaas.py', 'fuelweb_test/tests/plugins/plugin_glusterfs/test_plugin_glusterfs.py', 'fuelweb_test/settings.py', 'fuelweb_test/tests/plugins/plugin_example/test_fuel_plugin_example.py']",4,12544ed2fb6b7253477ef402ef51e933eaf77bf6,bug/1401219,"from fuelweb_test.settings import EXAMPLE_PLUGIN_PATH self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH)) self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH)) self.env.get_admin_remote(), EXAMPLE_PLUGIN_PATH, '/var') plugin=os.path.basename(EXAMPLE_PLUGIN_PATH))","from fuelweb_test.settings import PLUGIN_PATH self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH)) self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH)) self.env.get_admin_remote(), PLUGIN_PATH, '/var') plugin=os.path.basename(PLUGIN_PATH))",21,18
openstack%2Fsahara~master~I1c0889244c3249cd50762791081041144da967e4,openstack/sahara,master,I1c0889244c3249cd50762791081041144da967e4,Fix HIVESERVER2 number issue,ABANDONED,2014-12-05 15:15:23.000000000,2014-12-12 09:41:37.000000000,,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 13662}]","[{'number': 1, 'created': '2014-12-05 15:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/38a00f1e6d13a0dbd61be348117c08d92c4f5bc1', 'message': 'Fix HIVESERVER2 number issue\n\nThere was a bug that HIVESERVER2 process number cannot be >1. This\npatch is to fix it.\n\nCloses-Bug: #1399667\n\nChange-Id: I1c0889244c3249cd50762791081041144da967e4\n'}, {'number': 2, 'created': '2014-12-05 15:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/dd10180ec213511af9a93ea217ac4226a5f3b0c4', 'message': 'Fix HIVESERVER2 number issue\n\nThere was a bug that HIVESERVER2 process number cannot be >1. This\npatch is to fix it.\n\nCloses-Bug: #1399667\n\nChange-Id: I1c0889244c3249cd50762791081041144da967e4\n'}, {'number': 3, 'created': '2014-12-06 02:17:51.000000000', 'files': ['sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/utils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/a41732f2a336adbbe9391a05a7a391263d75b891', 'message': 'Fix HIVESERVER2 number issue\n\nThere was a bug that HIVESERVER2 process number cannot be >1. This\npatch is to fix it.\n\nCloses-Bug: #1399667\n\nChange-Id: I1c0889244c3249cd50762791081041144da967e4\n'}]",0,139658,a41732f2a336adbbe9391a05a7a391263d75b891,28,6,3,13662,,,0,"Fix HIVESERVER2 number issue

There was a bug that HIVESERVER2 process number cannot be >1. This
patch is to fix it.

Closes-Bug: #1399667

Change-Id: I1c0889244c3249cd50762791081041144da967e4
",git fetch https://review.opendev.org/openstack/sahara refs/changes/58/139658/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/utils.py']",2,38a00f1e6d13a0dbd61be348117c08d92c4f5bc1,Bug1399667,"def get_hive_servers(cluster): return u.get_instances(cluster, 'HIVESERVER2')","def get_hive_server(cluster): return u.get_instance(cluster, 'HIVESERVER2')",12,11
openstack%2Fheat-specs~master~Ife53e87c9d328a111a611eafaf397322db0e3d69,openstack/heat-specs,master,Ife53e87c9d328a111a611eafaf397322db0e3d69,Reorganize user-access code,ABANDONED,2014-12-09 08:31:55.000000000,2014-12-12 09:22:50.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-12-09 08:31:55.000000000', 'files': ['specs/kilo/reorganize-user-access-code.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/82b941f53271c4f855fb4e64ab900f0c7e427d1a', 'message': 'Reorganize user-access code\n\nIn order to reorganize the resources code structure,\nto make AWS and OS user-access resources decoupled first.\n\nSpecification blueprint reorg-user-access-code\n\nChange-Id: Ife53e87c9d328a111a611eafaf397322db0e3d69\n'}]",5,140268,82b941f53271c4f855fb4e64ab900f0c7e427d1a,7,5,1,8289,,,0,"Reorganize user-access code

In order to reorganize the resources code structure,
to make AWS and OS user-access resources decoupled first.

Specification blueprint reorg-user-access-code

Change-Id: Ife53e87c9d328a111a611eafaf397322db0e3d69
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/68/140268/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/reorganize-user-access-code.rst'],1,82b941f53271c4f855fb4e64ab900f0c7e427d1a,bp/reorg-user-access-code,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================ Reorganize user-access code ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/reorg-user-access-code Reorganize the user-access code to make AWS and OS resources decoupled. Problem description =================== The code structure of the resources folder is in some confusion. https://blueprints.launchpad.net/heat/+spec/reorganize-resources-code-structure There is too much coupling between AWS and OS resources for reorganizing to be possible, for example user-access code. Proposed change =============== The new code structure will be:: heat |----engine |----resources |----aws |----user.py |----openstack |----access_policy.py * module /heat/engine/resources/aws/user.py includes resources AWS::IAM::User and AWS::IAM::AccessKey. * module /heat/engine/resources/openstack/access_policy.py includes resource OS::Heat::AccessPolicy. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: huangtianhua <huangtianhua@huawei.com> Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- * Move the AWS user-access resources to separate module /heat/engine/resources/aws/user.py * Move the OpenStack AccessPolicy resource to separate module /heat/engine/resources/openstack/access_policy.py Dependencies ============ None ",,87,0
openstack%2Fheat-specs~master~I8b60f44bb46e5d5aba00550440512239a77a1616,openstack/heat-specs,master,I8b60f44bb46e5d5aba00550440512239a77a1616,Reorganize instance code,ABANDONED,2014-12-09 03:14:18.000000000,2014-12-12 09:22:01.000000000,,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4715}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-09 03:14:18.000000000', 'files': ['specs/kilo/reorganize-instance-code.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/fa7a57092743119184420ce973f45a3ff66d3e7d', 'message': 'Reorganize instance code\n\nIn order to reorganize the resources code structure,\nto make AWS and OS resources decoupled first.\n\nSpecification blueprint reorg-instance-code\n\nChange-Id: I8b60f44bb46e5d5aba00550440512239a77a1616\n'}]",1,140214,fa7a57092743119184420ce973f45a3ff66d3e7d,4,4,1,8289,,,0,"Reorganize instance code

In order to reorganize the resources code structure,
to make AWS and OS resources decoupled first.

Specification blueprint reorg-instance-code

Change-Id: I8b60f44bb46e5d5aba00550440512239a77a1616
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/14/140214/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/reorganize-instance-code.rst'],1,fa7a57092743119184420ce973f45a3ff66d3e7d,bp/reorg-instance-code,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================ Decouple instance code ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/reorg-instance-code Reorganize the instance code to make AWS and OS resources decoupled. Problem description =================== The code structure of the resources folder is in some confusion. https://blueprints.launchpad.net/heat/+spec/reorganize-resources-code-structure There is too much coupling between AWS and OS resources for reorganizing to be possible, for example instance code. Proposed change =============== The new code structure will be:: heat |----engine |----resources |----aws |----instance.py |----openstack |----ha_restarter.py * module /heat/engine/resources/aws/instance.py includes AWS::EC2::Instance resource. * module /heat/engine/resources/openstack/ha_restarter.py includes OS::Heat::HARestarter resource. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: huangtianhua <huangtianhua@huawei.com> Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- * Put the AWS resources to separate module /heat/engine/resources/aws/instance.py * Put the OpenStack resources to separate module /heat/engine/resources/openstack/ha_restarter.py Dependencies ============ None ",,87,0
openstack%2Fheat-specs~master~Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25,openstack/heat-specs,master,Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25,Reorganize Volumes code,ABANDONED,2014-12-09 02:52:49.000000000,2014-12-12 09:21:42.000000000,,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7256}]","[{'number': 1, 'created': '2014-12-09 02:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/ec6f148a0d243ccc64d596dfd906971e024a333f', 'message': 'Reorganize Volumes code\n\nIn order to reorganize the resources code structure,\nto make AWS and OS Volumes resources decoupled first.\n\nSpecification blueprint reorg-volume-code\n\nChange-Id: Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25\n'}, {'number': 2, 'created': '2014-12-09 03:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/fe7039185fda325b7e51c684f111669a192856e7', 'message': 'Reorganize Volumes code\n\nIn order to reorganize the resources code structure,\nto make AWS and OS Volumes resources decoupled first.\n\nSpecification blueprint reorg-volume-code\n\nChange-Id: Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25\n'}, {'number': 3, 'created': '2014-12-09 08:15:15.000000000', 'files': ['specs/kilo/reorganize-volume-code.rst'], 'web_link': 'https://opendev.org/openstack/heat-specs/commit/7a882f2195bd88dd4b81914d04e5da523a724f96', 'message': 'Reorganize Volumes code\n\nIn order to reorganize the resources code structure,\nto make AWS and OS Volumes resources decoupled first.\n\nSpecification blueprint reorg-volume-code\n\nChange-Id: Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25\n'}]",0,140209,7a882f2195bd88dd4b81914d04e5da523a724f96,7,3,3,8289,,,0,"Reorganize Volumes code

In order to reorganize the resources code structure,
to make AWS and OS Volumes resources decoupled first.

Specification blueprint reorg-volume-code

Change-Id: Ib393abc45fbf20642cd8ee3cf9791af39bf6fe25
",git fetch https://review.opendev.org/openstack/heat-specs refs/changes/09/140209/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/reorganize-volume-code.rst'],1,ec6f148a0d243ccc64d596dfd906971e024a333f,bp/reorg-volume-code,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/heat/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================ Reorganize WaitConditions code ================================ Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/heat/+spec/reorg-volume-code Reorganize the volume code to make AWS and OS resources decoupled. Problem description =================== The code structure of the resources folder is in some confusion. https://blueprints.launchpad.net/heat/+spec/reorganize-resources-code-structure There is too much coupling between AWS and OS resources for reorganizing to be possible, for example Volumes code. Proposed change =============== The new code structure will be:: heat |----engine |----resources |----aws |----volume.py |----openstack |----volume.py |----common |----volume_tasks.py * module /heat/engine/resources/aws/volume.py includes resources AWS::EC2::Volume and AWS::EC2::VolumeAttachment. * module /heat/engine/resources/openstack/volume.py includes resources OS::Cinder::Volume and OS::Cinder::VolumeAttachment. * module /heat/common/volume_tasks.py includes attach/detach tasks. Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: huangtianhua <huangtianhua@huawei.com> Milestones ---------- Target Milestone for completion: Kilo-1 Work Items ---------- * Put the AWS resources to separate module resources/aws/volume.py * Put the OpenStack resources to separate module resources/openstack/volume.py * Rename module /heat/engine/resources/volume.py to /heat/common/volume_tasks.py Dependencies ============ None ",,90,0
openstack%2Fheat-templates~master~Id2d2f623508be3049a7db8a39f5444ccac9257d6,openstack/heat-templates,master,Id2d2f623508be3049a7db8a39f5444ccac9257d6,Write each deployed config json to file,MERGED,2014-12-11 00:57:13.000000000,2014-12-12 09:11:01.000000000,2014-12-12 09:11:01.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7193}, {'_account_id': 8246}]","[{'number': 1, 'created': '2014-12-11 00:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/3bd1a6e8df7f3aa7d565b7aad5d5ad69597fadc6', 'message': 'Write each deployed config json to file\n\nPreviously 55-heat-config assumed that executing a hook with some\nconfig is an idempotent operation, so it made no effort to prevent\na hook being invoked with the same config multiple times. This means\nthat whenever *any* deployment metadata changes *all* configs are\nrun against their hooks again. This would be undesirable for\nnon-idempotent configs, or configs which are expensive to execute.\n\nThis change writes out the config json to files in\n/var/run/heat-config/deployed and uses the presence of this file to\ndetermine whether that config has been deployed already. This also\nimproves the debugging experience as a single hook execution can be\ntriggered manually by running:\n  /var/lib/heat-config/hooks/<hook> < /var/run/heat-config/deployed/<cid>.json\n\nCloses-Bug: #1376008\nCloses-Bug: #1365302\n\nChange-Id: Id2d2f623508be3049a7db8a39f5444ccac9257d6\n'}, {'number': 2, 'created': '2014-12-12 01:38:20.000000000', 'files': ['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config', 'tests/software_config/test_heat_config.py'], 'web_link': 'https://opendev.org/openstack/heat-templates/commit/2b33ca539f2bade702c07e18d86220a8148fa29f', 'message': 'Write each deployed config json to file\n\nPreviously 55-heat-config assumed that executing a hook with some\nconfig is an idempotent operation, so it made no effort to prevent\na hook being invoked with the same config multiple times. This means\nthat whenever *any* deployment metadata changes *all* configs are\nrun against their hooks again. This would be undesirable for\nnon-idempotent configs, or configs which are expensive to execute.\n\nThis change writes out the config json to files in\n/var/run/heat-config/deployed and uses the presence of this file to\ndetermine whether that config has been deployed already. This also\nimproves the debugging experience as a single hook execution can be\ntriggered manually by running:\n  /var/lib/heat-config/hooks/<hook> < /var/run/heat-config/deployed/<cid>.json\n\nCloses-Bug: #1376008\nCloses-Bug: #1365302\n\nChange-Id: Id2d2f623508be3049a7db8a39f5444ccac9257d6\n'}]",0,140886,2b33ca539f2bade702c07e18d86220a8148fa29f,16,5,2,4571,,,0,"Write each deployed config json to file

Previously 55-heat-config assumed that executing a hook with some
config is an idempotent operation, so it made no effort to prevent
a hook being invoked with the same config multiple times. This means
that whenever *any* deployment metadata changes *all* configs are
run against their hooks again. This would be undesirable for
non-idempotent configs, or configs which are expensive to execute.

This change writes out the config json to files in
/var/run/heat-config/deployed and uses the presence of this file to
determine whether that config has been deployed already. This also
improves the debugging experience as a single hook execution can be
triggered manually by running:
  /var/lib/heat-config/hooks/<hook> < /var/run/heat-config/deployed/<cid>.json

Closes-Bug: #1376008
Closes-Bug: #1365302

Change-Id: Id2d2f623508be3049a7db8a39f5444ccac9257d6
",git fetch https://review.opendev.org/openstack/heat-templates refs/changes/86/140886/2 && git format-patch -1 --stdout FETCH_HEAD,"['hot/software-config/elements/heat-config/os-refresh-config/configure.d/55-heat-config', 'tests/software_config/test_heat_config.py']",2,3bd1a6e8df7f3aa7d565b7aad5d5ad69597fadc6,heat-config-kubelet,"import copy 'id': '1111', 'id': '2222', 'id': '3333', 'id': '4444', 'id': '5555', 'id': '6666', self.deployed_dir = self.useFixture(fixtures.TempDir()) def run_heat_config(self, data): with self.write_config_file(data) as config_file: 'HEAT_CONFIG_DEPLOYED': self.deployed_dir.join(), def test_hooks_exist(self): for hook in self.fake_hooks: else: self.assertThat(hook_path, matchers.FileExists()) @requests_mock.Mocker(kw='mock_request') def test_run_heat_config(self, mock_request): mock_request.register_uri('POST', 'mock://192.0.2.2/foo') mock_request.register_uri('POST', 'mock://192.0.2.3/foo') self.run_heat_config(self.data) for config in self.data: hook = config['group'] stdin_path = self.hooks_dir.join('%s.stdin' % hook) stdout_path = self.hooks_dir.join('%s.stdout' % hook) deployed_file = self.deployed_dir.join('%s.json' % config['id']) if hook == 'no-such-hook': # parsed stdin should match the written deployed file self.assertEqual(config, self.json_from_file(deployed_file)) # clean up files in preperation for second run os.remove(stdin_path) os.remove(stdout_path) # run again with no changes, assert no new files self.run_heat_config(self.data) for config in self.data: hook = config['group'] stdin_path = self.hooks_dir.join('%s.stdin' % hook) stdout_path = self.hooks_dir.join('%s.stdout' % hook) self.assertThat( stdin_path, matchers.Not(matchers.FileExists())) self.assertThat( stdout_path, matchers.Not(matchers.FileExists())) # run again changing the puppet config data = copy.deepcopy(self.data) for config in data: if config['id'] == '4444': config['id'] = '44444444' self.run_heat_config(data) for config in self.data: hook = config['group'] stdin_path = self.hooks_dir.join('%s.stdin' % hook) stdout_path = self.hooks_dir.join('%s.stdout' % hook) if hook == 'puppet': self.assertThat(stdin_path, matchers.FileExists()) self.assertThat(stdout_path, matchers.FileExists()) else: self.assertThat( stdin_path, matchers.Not(matchers.FileExists())) self.assertThat( stdout_path, matchers.Not(matchers.FileExists()))"," @requests_mock.Mocker(kw='mock_request') def test_run_heat_config(self, mock_request): mock_request.register_uri('POST', 'mock://192.0.2.2/foo') mock_request.register_uri('POST', 'mock://192.0.2.3/foo') with self.write_config_file(self.data) as config_file: for config in self.data: hook = config['group'] stdin_path = self.hooks_dir.join('%s.stdin' % hook) stdout_path = self.hooks_dir.join('%s.stdout' % hook) self.assertThat(hook_path, matchers.FileExists())",90,13
openstack%2Fmistral~master~Ia7e81896b7f40a99c47a999582c87afe0e1b3fda,openstack/mistral,master,Ia7e81896b7f40a99c47a999582c87afe0e1b3fda,API controllers should log requests at INFO level,MERGED,2014-12-11 22:36:31.000000000,2014-12-12 09:02:32.000000000,2014-12-12 09:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 7700}, {'_account_id': 8731}, {'_account_id': 9432}]","[{'number': 1, 'created': '2014-12-11 22:36:31.000000000', 'files': ['mistral/api/controllers/v2/action.py', 'mistral/api/controllers/v1/task.py', 'mistral/api/controllers/v1/workbook_definition.py', 'mistral/api/controllers/v2/cron_trigger.py', 'mistral/api/controllers/v1/execution.py', 'mistral/api/controllers/v2/workbook.py', 'mistral/api/controllers/v2/execution.py', 'mistral/api/controllers/v1/listener.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v1/workbook.py', 'mistral/api/controllers/v2/workflow.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/3c5ed8808803bc4bc6893ced47a412a401cd34ab', 'message': 'API controllers should log requests at INFO level\n\n  Closes-Bug: 1401688\n\n  * Change all instances of LOG.debug to LOG.info in API controllers.\n\nChange-Id: Ia7e81896b7f40a99c47a999582c87afe0e1b3fda\n'}]",0,141191,3c5ed8808803bc4bc6893ced47a412a401cd34ab,7,5,1,14272,,,0,"API controllers should log requests at INFO level

  Closes-Bug: 1401688

  * Change all instances of LOG.debug to LOG.info in API controllers.

Change-Id: Ia7e81896b7f40a99c47a999582c87afe0e1b3fda
",git fetch https://review.opendev.org/openstack/mistral refs/changes/91/141191/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/api/controllers/v1/task.py', 'mistral/api/controllers/v1/workbook_definition.py', 'mistral/api/controllers/v2/action.py', 'mistral/api/controllers/v2/cron_trigger.py', 'mistral/api/controllers/v1/execution.py', 'mistral/api/controllers/v2/execution.py', 'mistral/api/controllers/v2/workbook.py', 'mistral/api/controllers/v1/listener.py', 'mistral/api/controllers/v2/task.py', 'mistral/api/controllers/v1/workbook.py', 'mistral/api/controllers/v2/workflow.py']",11,3c5ed8808803bc4bc6893ced47a412a401cd34ab,bug/1401688," LOG.info(""Fetch workflow [name=%s]"" % name) LOG.info(""Update workflow(s) [definition=%s]"" % definition) LOG.info(""Create workflow(s) [definition=%s]"" % definition) LOG.info(""Delete workflow [name=%s]"" % name) LOG.info(""Fetch workflows."")"," LOG.debug(""Fetch workflow [name=%s]"" % name) LOG.debug(""Update workflow(s) [definition=%s]"" % definition) LOG.debug(""Create workflow(s) [definition=%s]"" % definition) LOG.debug(""Delete workflow [name=%s]"" % name) LOG.debug(""Fetch workflows."")",79,79
openstack%2Ftricircle~master~I16652ea0d1e615e09e0367224d57f85bc6709538,openstack/tricircle,master,I16652ea0d1e615e09e0367224d57f85bc6709538,novaproxy performance optimization,MERGED,2014-12-12 08:34:52.000000000,2014-12-12 08:35:47.000000000,2014-12-12 08:35:47.000000000,"[{'_account_id': 3}, {'_account_id': 9684}]","[{'number': 1, 'created': '2014-12-12 08:34:52.000000000', 'files': ['novaproxy/nova/compute/manager_proxy.py'], 'web_link': 'https://opendev.org/openstack/tricircle/commit/7c5a2be5078f7bf021aa235e19ab01b4956805b7', 'message': 'novaproxy performance optimization\n\nadding paging search for periodic sync instance state, add a periodic\ntask for check if the cascaded instance should be full deleted for proxy\nerror exit when deleting.\n\nChange-Id: I16652ea0d1e615e09e0367224d57f85bc6709538\n'}]",0,141304,7c5a2be5078f7bf021aa235e19ab01b4956805b7,6,2,1,9684,,,0,"novaproxy performance optimization

adding paging search for periodic sync instance state, add a periodic
task for check if the cascaded instance should be full deleted for proxy
error exit when deleting.

Change-Id: I16652ea0d1e615e09e0367224d57f85bc6709538
",git fetch https://review.opendev.org/openstack/tricircle refs/changes/04/141304/1 && git format-patch -1 --stdout FETCH_HEAD,['novaproxy/nova/compute/manager_proxy.py'],1,7c5a2be5078f7bf021aa235e19ab01b4956805b7,," QUERY_PER_PAGE_LIMIT = 50 # sync keypair when operating instance to check if it's necessary. csd_keypairs = csd_nova_client.keypairs.list() # if self._change_since_time is None: # search_opts_args = {'all_tenants': True} # servers = cascaded_nova_cli.servers.list( # search_opts=search_opts_args) # else: # In first time query, the self._change_since_time is # None, but has not affect. search_opts_args = { 'changes-since': self._change_since_time, 'all_tenants': True } # (jd):update change_since time for next search, it's done before # the state-sync handle in case of the handle spend too much # time which results in missing some instance the next time to # search. datetime.timedelta(seconds=time_shift_tolerance) LOG.debug(_('the change since time update to %s'), marker = None while True: servers = cascaded_nova_cli.servers.list( search_opts=search_opts_args, limit=self.QUERY_PER_PAGE_LIMIT, marker=marker) if servers: marker = servers[-1].id else: break for server in servers: csg_uuid = ComputeManager._extract_csg_uuid(server) if csg_uuid: csd_task_state = server._info['OS-EXT-STS:task_state'] if csd_task_state in EXCLUDE_TASK_STATES: continue self._instance_update( context, csg_uuid, vm_state=server._info['OS-EXT-STS:vm_state'], task_state=server._info['OS-EXT-STS:task_state'], power_state=server._info['OS-EXT-STS:power_state'], launched_at=server._info['OS-SRV-USG:launched_at'] ) LOG.debug(_('Updated the server %s from nova-proxy'), server.id) except exception.InstanceNotFound: pass @periodic_task.periodic_task( spacing=CONF.running_deleted_instance_poll_interval) def _cleanup_running_deleted_instances(self, context): try: kwargs = { 'username': CONF.nova_admin_username, 'password': CONF.nova_admin_password, 'tenant': CONF.nova_admin_tenant_name, 'auth_url': cfg.CONF.keystone_auth_url, 'region_name': CONF.proxy_region_name } req_context = compute_context.RequestContext(**kwargs) openstack_clients = clients.OpenStackClients(req_context) csd_nova_client = openstack_clients.nova() except Exception: with excutils.save_and_reraise_exception(): LOG.error(_('Failed to get nova python client.')) with utils.temporary_mutation(context, read_deleted=""yes""): for instance in self._running_deleted_instances(context): csd_instance_uuid = self._uuid_mapping.get(instance.uuid, '') if not csd_instance_uuid: continue LOG.debug(_('Get cascaded instance %s that should be deleted'), csd_instance_uuid) try: csd_instance = csd_nova_client.servers.get(csd_instance_uuid) if csd_instance._info['OS-EXT-STS:vm_state'] != 'deleted': csd_nova_client.servers.delete(csd_instance) self._uuid_mapping.pop(instance.uuid, '') LOG.debug(_('delete the cascaded instance %s in' 'periodic_task'), csd_instance.id) except Exception: pass def _running_deleted_instances(self, context): """"""Returns a list of instances nova thinks is deleted, but the hypervisor thinks is still running. """""" timeout = CONF.running_deleted_instance_timeout filters = {'deleted': True, 'soft_deleted': False, # 'host': self.host } instances = self._get_instances_on_db(context, filters) return [i for i in instances if self._deleted_old_enough(i, timeout)] def _deleted_old_enough(self, instance, timeout): deleted_at = instance['deleted_at'] if isinstance(instance, obj_base.NovaObject) and deleted_at: deleted_at = deleted_at.replace(tzinfo=None) return (not deleted_at or timeutils.is_older_than(deleted_at, timeout)) def _get_instances_on_db(self, context, filters): return objects.InstanceList.get_by_filters(context, filters, use_slave=True) "," QUERY_PER_PAGE_LIMIT = 30 csd_keypairs = csd_nova_client.keypairs.list() if self._change_since_time is None: search_opts_args = {'all_tenants': True} servers = cascaded_nova_cli.servers.list( search_opts=search_opts_args) else: search_opts_args = { 'changes-since': self._change_since_time, 'all_tenants': True } servers = cascaded_nova_cli.servers.list( search_opts=search_opts_args) datetime.timedelta(seconds=time_shift_tolerance) LOG.debug(_('the change since time is %s'), if len(servers) > 0: for server in servers: csg_uuid = ComputeManager._extract_csg_uuid(server) if csg_uuid: csd_task_state = server._info['OS-EXT-STS:task_state'] if csd_task_state in EXCLUDE_TASK_STATES: continue self._instance_update( context, csg_uuid, vm_state=server._info['OS-EXT-STS:vm_state'], task_state=server._info['OS-EXT-STS:task_state'], power_state=server._info['OS-EXT-STS:power_state'], launched_at=server._info['OS-SRV-USG:launched_at'] ) LOG.debug(_('Updated the server %s from nova-proxy'), server.id)",109,32
openstack%2Ffuel-library~master~Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,openstack/fuel-library,master,Ia1b6fc205ae040b7cabd60e3104ea97d565d797a,Fix for murano-manage package-import,MERGED,2014-12-11 16:07:59.000000000,2014-12-12 08:27:58.000000000,2014-12-11 17:49:10.000000000,"[{'_account_id': 3}, {'_account_id': 7468}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}]","[{'number': 1, 'created': '2014-12-11 16:07:59.000000000', 'files': ['deployment/puppet/murano/manifests/application_package.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13', 'message': 'Fix for murano-manage package-import\n\n* This patchset resolves issue with re-upload of already existing murano application package\n\nChange-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a\nRelated-Bug: # 1401503\n'}]",0,141083,9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13,15,5,1,7613,,,0,"Fix for murano-manage package-import

* This patchset resolves issue with re-upload of already existing murano application package

Change-Id: Ia1b6fc205ae040b7cabd60e3104ea97d565d797a
Related-Bug: # 1401503
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/83/141083/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/murano/manifests/application_package.pp'],1,9e0eed5c36958ba42e1e061a8bd55b6bff7fdb13,bug/1401503," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' --update"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}' --update"","," '' => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}'"", default => ""${murano_manage} --config-file=/etc/murano/murano.conf import-package '${package_path}' -c '${package_category}'"",",2,2
openstack%2Fironic-specs~master~I1b02789840aa16e08f5081058e803169eac6b759,openstack/ironic-specs,master,I1b02789840aa16e08f5081058e803169eac6b759,Remove spec added for an example to render,MERGED,2014-12-12 00:47:08.000000000,2014-12-12 08:26:40.000000000,2014-12-12 08:26:40.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}]","[{'number': 1, 'created': '2014-12-12 00:47:08.000000000', 'files': ['specs/backlog/example.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/3dd8a26c1aa0d6f91698b343f248d0e25326fd0e', 'message': 'Remove spec added for an example to render\n\nWe have actual backlog specs now, so this is no longer needed to ensure\nbacklog specs render properly.\n\nChange-Id: I1b02789840aa16e08f5081058e803169eac6b759\n'}]",0,141228,3dd8a26c1aa0d6f91698b343f248d0e25326fd0e,7,3,1,10342,,,0,"Remove spec added for an example to render

We have actual backlog specs now, so this is no longer needed to ensure
backlog specs render properly.

Change-Id: I1b02789840aa16e08f5081058e803169eac6b759
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/28/141228/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/backlog/example.rst'],1,3dd8a26c1aa0d6f91698b343f248d0e25326fd0e,jay/RemoveExampleSpec,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== This is a sample to test rendering only ========================================== This is only a sample. It tests the rendering of templates in the backlog. Problem description =================== There is not a clear way for reviewers to know that short specs are being rendered properly without a sample. This sample can be deleted once any real spec file is added to the backlog dir. Or, alternately, it can remain here. Proposed change =============== Add this sample. That's all that needs to be done. ",0,25
openstack%2Fapi-site~master~I3fcd2e97263d937857ac7863d99ba73b569be274,openstack/api-site,master,I3fcd2e97263d937857ac7863d99ba73b569be274,Imported Translations from Transifex,MERGED,2014-12-12 06:06:12.000000000,2014-12-12 08:07:59.000000000,2014-12-12 08:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-12 06:06:12.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/4bedb562841f5adad6a0669417ed506eb8b2b42b', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I3fcd2e97263d937857ac7863d99ba73b569be274\n'}]",0,141279,4bedb562841f5adad6a0669417ed506eb8b2b42b,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I3fcd2e97263d937857ac7863d99ba73b569be274
",git fetch https://review.opendev.org/openstack/api-site refs/changes/79/141279/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po']",2,4bedb562841f5adad6a0669417ed506eb8b2b42b,transifex/translations,"""POT-Creation-Date: 2014-12-11 17:30+0000\n"" ""PO-Revision-Date: 2014-12-11 17:30+0000\n"" ""Last-Translator: openstackjenkins <jenkins@openstack.org>\n""msgid ""Flavors swap value"" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2-ext.xml90(para) msgid """" ""Create or list flavors with a swap value. Requires the os-flavormanage "" ""extension. The swap value is the amount of swap disk space, in GBs, to "" ""allocate to a server."" msgstr """" #: ./api-ref/src/docbkx/ch_compute-v2-ext.xml98(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml99(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml108(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml109(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml116(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml118(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml126(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml127(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml139(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml140(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml148(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml149(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml156(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml157(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml163(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml164(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml170(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml171(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml177(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml178(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml184(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml190(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml191(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml198(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml199(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml207(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml208(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml216(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml217(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml223(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml224(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml231(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml232(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml241(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml242(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml248(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml249(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml276(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml277(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml285(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml286(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml292(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml293(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml300(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml301(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml309(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml310(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml316(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml317(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml325(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml327(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml334(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml335(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml342(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml343(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml359(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml360(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml367(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml368(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml370(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml386(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml387(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml393(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml394(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml401(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml402(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml409(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml410(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml417(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml418(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml425(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml426(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml435(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml437(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml443(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml445(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml452(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml453(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml460(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml462(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml471(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml473(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml479(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml480(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml487(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml488(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml494(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml495(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml502(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml503(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml511(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml512(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml519(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml520(para)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml62(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml63(para)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml74(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml111(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml132(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml145(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml154(title)","""POT-Creation-Date: 2014-10-23 15:31+0000\n"" ""PO-Revision-Date: 2014-10-27 08:51+0000\n"" ""Last-Translator: Frédéric <frosmont@free.fr>\n""#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml90(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml99(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml100(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml107(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml109(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml117(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml118(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml130(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml131(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml139(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml140(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml147(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml148(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml154(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml155(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml161(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml162(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml168(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml169(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml175(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml181(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml182(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml189(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml190(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml198(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml199(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml207(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml208(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml214(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml215(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml222(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml223(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml232(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml233(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml239(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml240(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml267(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml268(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml276(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml277(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml283(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml284(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml291(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml292(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml300(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml301(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml307(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml308(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml316(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml318(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml325(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml326(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml333(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml334(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml350(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml351(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml358(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml359(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml361(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml377(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml378(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml384(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml385(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml392(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml393(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml400(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml401(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml408(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml409(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml416(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml417(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml426(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml428(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml434(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml436(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml443(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml444(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml451(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml453(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml462(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml464(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml470(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml471(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml478(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml479(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml485(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml486(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml493(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml494(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml502(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml503(para)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml510(title)#: ./api-ref/src/docbkx/ch_compute-v2-ext.xml511(para)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml51(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml52(para)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml63(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml100(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml121(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml134(title)#: ./api-ref/src/docbkx/ch_orchestration-v1.xml143(title)",223,204
openstack%2Fopenstack-doc-tools~master~I268ef741f20200d59191a383d20a8fbeba134fb3,openstack/openstack-doc-tools,master,I268ef741f20200d59191a383d20a8fbeba134fb3,Add new parameter --url-exception to not check URLs for reachability,MERGED,2014-12-11 19:41:21.000000000,2014-12-12 08:07:53.000000000,2014-12-12 08:07:52.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-11 19:41:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/a340d5e489e83923891fb653e832070536429169', 'message': 'Add new parameter --url-exception to not check URLs for reachability\n\nThere exists URLs that are not reachable but are still valid URLs.\nThose URLs should not be checked for reachability.\n\nChange-Id: I268ef741f20200d59191a383d20a8fbeba134fb3\n'}, {'number': 2, 'created': '2014-12-11 19:44:04.000000000', 'files': ['os_doc_tools/doctest.py'], 'web_link': 'https://opendev.org/openstack/openstack-doc-tools/commit/a86c86f39cb4d7f5f12386085620eb54aefb4649', 'message': 'Add new parameter --url-exception to not check URLs for reachability\n\nThere exists URLs that are not reachable but are still valid URLs.\nThose URLs should not be checked for reachability.\n\nChange-Id: I268ef741f20200d59191a383d20a8fbeba134fb3\n'}]",0,141142,a86c86f39cb4d7f5f12386085620eb54aefb4649,8,3,2,167,,,0,"Add new parameter --url-exception to not check URLs for reachability

There exists URLs that are not reachable but are still valid URLs.
Those URLs should not be checked for reachability.

Change-Id: I268ef741f20200d59191a383d20a8fbeba134fb3
",git fetch https://review.opendev.org/openstack/openstack-doc-tools refs/changes/42/141142/1 && git format-patch -1 --stdout FETCH_HEAD,['os_doc_tools/doctest.py'],1,a340d5e489e83923891fb653e832070536429169,checklinks_ignore_urls,"# These URLs will not be checked for reachability. Add valuas via # --url-exception. URL_EXCEPTIONS = [] if url in URL_EXCEPTIONS: continue def add_url_exceptions(url_exception, verbose): """"""Add list of exceptions from url_exception."""""" for entry in url_exception: if verbose: print("" Adding URL to ignore list: %s"" % entry) URL_EXCEPTIONS.append(entry) cfg.MultiStrOpt(""url-exception"", help=""URL that will be skipped during reachability "" ""check.""), if CONF.url_exception: add_url_exceptions(CONF.url_exception, CONF.verbose) ",,22,0
openstack%2Fopenstack-manuals~master~I79dfdf1c2611419f0852a12a3627cfddc9730a17,openstack/openstack-manuals,master,I79dfdf1c2611419f0852a12a3627cfddc9730a17,Imported Translations from Transifex,MERGED,2014-12-12 06:13:04.000000000,2014-12-12 08:07:37.000000000,2014-12-12 08:07:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2014-12-12 06:13:04.000000000', 'files': ['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/glossary/locale/ja.po', 'doc/cli-reference/locale/cli-reference.pot', 'doc/common/locale/fr.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/76fcca9685fdf03204888fb7da4ed3ec6667591f', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I79dfdf1c2611419f0852a12a3627cfddc9730a17\n'}]",0,141281,76fcca9685fdf03204888fb7da4ed3ec6667591f,6,2,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I79dfdf1c2611419f0852a12a3627cfddc9730a17
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/81/141281/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/locale/ja.po', 'doc/user-guide/locale/fr.po', 'doc/common/locale/common.pot', 'doc/arch-design/locale/arch-design.pot', 'doc/install-guide/locale/ja.po', 'doc/common/locale/ja.po', 'doc/glossary/locale/ja.po', 'doc/user-guide/locale/user-guide.pot', 'doc/cli-reference/locale/cli-reference.pot', 'doc/common/locale/fr.po']",10,76fcca9685fdf03204888fb7da4ed3ec6667591f,transifex/translations,"""POT-Creation-Date: 2014-12-12 04:44+0000\n"" ""PO-Revision-Date: 2014-12-11 19:34+0000\n""msgid """" ""<literal>openstack</literal> - Common OpenStack client supporting multiple "" ""services""""<placeholder-1/>.""#: ./doc/common/section_cli_install.xml222(title)#: ./doc/common/section_cli_install.xml223(para)#: ./doc/common/section_cli_install.xml230(para)#: ./doc/common/section_cli_install.xml233(para)#: ./doc/common/section_cli_install.xml234(replaceable) #: ./doc/common/section_cli_install.xml236(replaceable) #: ./doc/common/section_cli_install.xml248(replaceable) #: ./doc/common/section_cli_install.xml252(replaceable) #: ./doc/common/section_cli_install.xml259(replaceable) #: ./doc/common/section_cli_install.xml268(replaceable) #: ./doc/common/section_cli_install.xml271(replaceable)#: ./doc/common/section_cli_install.xml235(para)#: ./doc/common/section_cli_install.xml240(title)#: ./doc/common/section_cli_install.xml241(para)#: ./doc/common/section_cli_install.xml243(para)#: ./doc/common/section_cli_install.xml249(para)#: ./doc/common/section_cli_install.xml253(para)#: ./doc/common/section_cli_install.xml264(title)#: ./doc/common/section_cli_install.xml265(para)#: ./doc/common/section_cli_install.xml269(para)#: ./doc/common/section_cli_install.xml274(title)#: ./doc/common/section_cli_install.xml275(para)","""POT-Creation-Date: 2014-12-10 04:44+0000\n"" ""PO-Revision-Date: 2014-12-09 07:11+0000\n""msgid ""<literal>common</literal> - Common OpenStack client""""<replaceable>pip</replaceable>.""#: ./doc/common/section_cli_install.xml223(title)#: ./doc/common/section_cli_install.xml224(para)#: ./doc/common/section_cli_install.xml231(para)#: ./doc/common/section_cli_install.xml234(para)#: ./doc/common/section_cli_install.xml235(replaceable) #: ./doc/common/section_cli_install.xml237(replaceable) #: ./doc/common/section_cli_install.xml249(replaceable) #: ./doc/common/section_cli_install.xml253(replaceable) #: ./doc/common/section_cli_install.xml260(replaceable) #: ./doc/common/section_cli_install.xml269(replaceable) #: ./doc/common/section_cli_install.xml272(replaceable)#: ./doc/common/section_cli_install.xml236(para)#: ./doc/common/section_cli_install.xml241(title)#: ./doc/common/section_cli_install.xml242(para)#: ./doc/common/section_cli_install.xml244(para)#: ./doc/common/section_cli_install.xml250(para)#: ./doc/common/section_cli_install.xml254(para)#: ./doc/common/section_cli_install.xml265(title)#: ./doc/common/section_cli_install.xml266(para)#: ./doc/common/section_cli_install.xml270(para)#: ./doc/common/section_cli_install.xml275(title)#: ./doc/common/section_cli_install.xml276(para)",1877,361
openstack%2Fmanila~master~Ie867a7250b27d9f42c20c9bcf7ab797f3d7f8081,openstack/manila,master,Ie867a7250b27d9f42c20c9bcf7ab797f3d7f8081,Add cmode driver opts to devstack plugin,ABANDONED,2014-09-15 17:13:16.000000000,2014-12-12 07:55:49.000000000,,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11878}]","[{'number': 1, 'created': '2014-09-15 17:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/cc3adbef30e1ec4d9bc670f8fb7e7a1dd5a83274', 'message': 'Add cmode driver opts to devstack plugin\n\nAdd NetApp Cluster Mode driver specific opts to devstack to be able to deploy\nenvironment with enabled Cluster mode from scratch.\n\nIf multibackend enabled, then there will be two manila share services linked\nto the same backend.\n\nDO NOT MERGE: it works, but not intended to be merged.\n\nChange-Id: Ie867a7250b27d9f42c20c9bcf7ab797f3d7f8081\n'}, {'number': 2, 'created': '2014-09-17 14:28:03.000000000', 'files': ['contrib/devstack/lib/manila'], 'web_link': 'https://opendev.org/openstack/manila/commit/017ea6848949b38976cc8b6a776c521a2f41189c', 'message': 'Add cmode driver opts to devstack plugin\n\nAdd NetApp Cluster Mode driver specific opts to devstack to be able to deploy\nenvironment with enabled Cluster mode from scratch.\n\nIf multibackend enabled, then there will be two manila share services linked\nto the same backend.\n\nDO NOT MERGE: it works, but not intended to be merged.\n\nChange-Id: Ie867a7250b27d9f42c20c9bcf7ab797f3d7f8081\n'}]",0,121627,017ea6848949b38976cc8b6a776c521a2f41189c,14,5,2,8851,,,0,"Add cmode driver opts to devstack plugin

Add NetApp Cluster Mode driver specific opts to devstack to be able to deploy
environment with enabled Cluster mode from scratch.

If multibackend enabled, then there will be two manila share services linked
to the same backend.

DO NOT MERGE: it works, but not intended to be merged.

Change-Id: Ie867a7250b27d9f42c20c9bcf7ab797f3d7f8081
",git fetch https://review.opendev.org/openstack/manila refs/changes/27/121627/2 && git format-patch -1 --stdout FETCH_HEAD,['contrib/devstack/lib/manila'],1,cc3adbef30e1ec4d9bc670f8fb7e7a1dd5a83274,cmode_in_devstack,"# These are used by NetApp Cluster Mode Driver MANILA_NETAPP_NAS_LOGIN=${MANILA_NETAPP_NAS_LOGIN:-""admin""} MANILA_NETAPP_NAS_PASSWORD=${MANILA_NETAPP_NAS_PASSWORD:-""password_not_set""} MANILA_NETAPP_NAS_HOSTNAME=${MANILA_NETAPP_NAS_HOSTNAME:-""hostname_not_set""} MANILA_NETAPP_NAS_TRANSPORT_TYPE=${MANILA_NETAPP_NAS_TRANSPORT_TYPE:-""http""} MANILA_NETAPP_AGGREGATE_NAME_SEARCH_PATTERN=${MANILA_NETAPP_AGGREGATE_NAME_SEARCH_PATTERN:-""(.*)""} MANILA_NETAPP_ROOT_VOLUME_AGGREGATE=${MANILA_NETAPP_ROOT_VOLUME_AGGREGATE:-""aggregate_name_not_set""} MANILA_NETAPP_ROOT_VOLUME_NAME=${MANILA_NETAPP_ROOT_VOLUME_NAME:-""root""} # Set NetApp Cluster Mode Driver specific opts iniset $MANILA_CONF $1 netapp_nas_login $MANILA_NETAPP_NAS_LOGIN iniset $MANILA_CONF $1 netapp_nas_password $MANILA_NETAPP_NAS_PASSWORD iniset $MANILA_CONF $1 netapp_nas_server_hostname $MANILA_NETAPP_NAS_HOSTNAME iniset $MANILA_CONF $1 netapp_nas_transport_type $MANILA_NETAPP_NAS_TRANSPORT_TYPE iniset $MANILA_CONF $1 netapp_aggregate_name_search_pattern $MANILA_NETAPP_AGGREGATE_NAME_SEARCH_PATTERN iniset $MANILA_CONF $1 netapp_root_volume_aggregate $MANILA_NETAPP_ROOT_VOLUME_AGGREGATE iniset $MANILA_CONF $1 netapp_root_volume_name $MANILA_NETAPP_ROOT_VOLUME_NAME",,18,0
openstack%2Fheat~master~Id416595c531db8510d9fd88d1573372f3c4934eb,openstack/heat,master,Id416595c531db8510d9fd88d1573372f3c4934eb,Small re-factoring in template_resource,MERGED,2014-12-01 14:47:39.000000000,2014-12-12 07:53:04.000000000,2014-12-12 07:53:02.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 12606}, {'_account_id': 13009}, {'_account_id': 14082}]","[{'number': 1, 'created': '2014-12-01 14:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/24f19b2232efbd6c541fd4fed33bc690939912bc', 'message': 'Small re-factoring in template_resource\n\nChange-Id: Id416595c531db8510d9fd88d1573372f3c4934eb\n'}, {'number': 2, 'created': '2014-12-01 14:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e1e4431088999b262e36845f36ea952acf258a39', 'message': 'Small re-factoring in template_resource\n\nChange-Id: Id416595c531db8510d9fd88d1573372f3c4934eb\n'}, {'number': 3, 'created': '2014-12-02 08:42:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/d68817ef558e2b4c42cf801411eb5fb57eecda1a', 'message': 'Small re-factoring in template_resource\n\nChange-Id: Id416595c531db8510d9fd88d1573372f3c4934eb\n'}, {'number': 4, 'created': '2014-12-10 12:26:56.000000000', 'files': ['heat/tests/test_engine_service.py', 'heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ffaeef9b5dd01b22b2bcb9e56519bc8aa74075ad', 'message': 'Small re-factoring in template_resource\n\nChange-Id: Id416595c531db8510d9fd88d1573372f3c4934eb\n'}]",6,138080,ffaeef9b5dd01b22b2bcb9e56519bc8aa74075ad,29,8,4,6577,,,0,"Small re-factoring in template_resource

Change-Id: Id416595c531db8510d9fd88d1573372f3c4934eb
",git fetch https://review.opendev.org/openstack/heat refs/changes/80/138080/3 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_engine_service.py', 'heat/tests/test_provider_template.py', 'heat/engine/resources/template_resource.py']",3,24f19b2232efbd6c541fd4fed33bc690939912bc,bug/1394552,"def get_template_file(template_name, allowed_schemes): try: return urlfetch.get(template_name, allowed_schemes=allowed_schemes) except (IOError, exceptions.RequestException) as r_exc: args = {'name': template_name, 'exc': six.text_type(r_exc)} msg = _(""Could not fetch remote template '%(name)s': %(exc)s"") % args def initialize_schemes(tmpl): return ((properties.Properties.schema_from_params(tmpl.param_schemata())), (attributes.Attributes.schema_from_outputs(tmpl[tmpl.OUTPUTS]))) def generate_class(name, template_name): data = get_template_file(template_name, ('file',)) props, attrs = initialize_schemes(tmpl) {'properties_schema': props, 'attributes_schema': attrs}) except (exception.NotFound, ValueError) as download_error: self.properties_schema, self.attributes_schema = \ initialize_schemes(tmpl) t_data = get_template_file(self.template_name, self.allowed_schemes) except exception.NotFound as err: reported_excp = err","def generate_class(name, template_name): try: data = urlfetch.get(template_name, allowed_schemes=('file',)) except IOError: msg = _('No such file: %s') % template_name properties_schema = properties.Properties.schema_from_params( tmpl.param_schemata()) attributes_schema = attributes.Attributes.schema_from_outputs( tmpl[tmpl.OUTPUTS]) {""properties_schema"": properties_schema, ""attributes_schema"": attributes_schema}) except ValueError as download_error: self.properties_schema = (properties.Properties .schema_from_params(tmpl.param_schemata())) self.attributes_schema = (attributes.Attributes .schema_from_outputs(tmpl[tmpl.OUTPUTS])) t_data = urlfetch.get(self.template_name, allowed_schemes=self.allowed_schemes) except (exceptions.RequestException, IOError) as r_exc: reported_excp = ValueError(_(""Could not fetch remote template "" ""'%(name)s': %(exc)s"") % { 'name': self.template_name, 'exc': str(r_exc)})",27,24
openstack%2Fhorizon~master~Ie3f8301995d685bc1b31076aa99ec2d692ad3330,openstack/horizon,master,Ie3f8301995d685bc1b31076aa99ec2d692ad3330,Imported Translations from Transifex,MERGED,2014-12-12 06:04:35.000000000,2014-12-12 07:52:53.000000000,2014-12-12 07:52:52.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}]","[{'number': 1, 'created': '2014-12-12 06:04:35.000000000', 'files': ['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1dd399ae352023ec10eca855e18100228d18816', 'message': 'Imported Translations from Transifex\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie3f8301995d685bc1b31076aa99ec2d692ad3330\n'}]",0,141278,f1dd399ae352023ec10eca855e18100228d18816,7,3,1,11131,,,0,"Imported Translations from Transifex

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ie3f8301995d685bc1b31076aa99ec2d692ad3330
",git fetch https://review.opendev.org/openstack/horizon refs/changes/78/141278/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po']",17,f1dd399ae352023ec10eca855e18100228d18816,transifex/translations,"""POT-Creation-Date: 2014-12-11 21:40-0600\n"" ""PO-Revision-Date: 2014-12-12 03:41+0000\n""#: dashboards/project/volumes/volumes/tables.py:300#: dashboards/project/data_processing/clusters/tabs.py:135#: dashboards/project/volumes/volumes/tables.py:316 #: dashboards/project/volumes/volumes/tables.py:345#: dashboards/project/volumes/volumes/tables.py:352#: dashboards/project/data_processing/clusters/tabs.py:150#: dashboards/project/volumes/tabs.py:83#: dashboards/project/volumes/volumes/tables.py:361 usage/quotas.py:74#: dashboards/admin/volumes/tabs.py:115#: dashboards/project/volumes/tabs.py:99#: dashboards/project/volumes/volumes/tables.py:250#: dashboards/project/volumes/volumes/tables.py:348#: dashboards/project/volumes/volumes/tables.py:326#: dashboards/project/volumes/volumes/tables.py:322#: dashboards/project/volumes/volumes/tables.py:319msgid ""Network Details"" msgstr """"#: dashboards/admin/routers/templates/routers/detail.html:6#: dashboards/admin/volumes/tabs.py:53 dashboards/admin/volumes/tabs.py:141#: dashboards/admin/volumes/tabs.py:68#: dashboards/admin/volumes/tabs.py:80#: dashboards/admin/volumes/tabs.py:88#: dashboards/admin/volumes/tabs.py:109#: dashboards/admin/volumes/tabs.py:133 dashboards/project/volumes/tabs.py:113#: dashboards/project/volumes/volumes/tables.py:117 #: dashboards/project/volumes/volumes/tables.py:185#: dashboards/project/volumes/volumes/tables.py:413#: dashboards/project/data_processing/clusters/tabs.py:112#: dashboards/project/data_processing/clusters/tabs.py:138#: dashboards/project/data_processing/clusters/tabs.py:141#: dashboards/project/data_processing/clusters/tabs.py:146#: dashboards/project/data_processing/clusters/tabs.py:175#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:12 #, python-format msgid ""%(conf_name)s: %(conf_val)s"" msgstr """" #: dashboards/project/volumes/volumes/tables.py:191#: dashboards/project/volumes/volumes/tables.py:94 #: dashboards/project/volumes/volumes/tables.py:119#: dashboards/project/volumes/volumes/tables.py:166#: dashboards/project/volumes/volumes/tables.py:350msgid ""Network Details: %(network_name)s"" msgstr """"msgid ""Subnet Details"" msgstr """"""available by clicking on the \""Subnet Details\"" tab."" msgstr """"""available at \""Subnet Details\"" tab."" msgstr """"msgid ""Port Details"" msgstr """""" Clicking the <i class=\""fa fa-random\""></i> button in the intersection will install a rule to switch the traffic behavior.<br/>\n""msgstr """"msgid ""Stack Details: %(stack_name)s"" msgstr """"msgid ""Resource Details: %s"" msgstr """"msgid ""Stack Details"" msgstr """"msgid ""Resource Details"" msgstr """"#: dashboards/project/volumes/tabs.py:62 msgid ""Unable to retrieve snapshot list."" msgstr """" #: dashboards/project/volumes/tabs.py:127#: dashboards/project/volumes/tabs.py:144#: dashboards/project/volumes/volumes/tables.py:434#: dashboards/project/volumes/volumes/tables.py:131#: dashboards/project/volumes/volumes/tables.py:231#: dashboards/project/volumes/volumes/tables.py:219#: dashboards/project/volumes/volumes/tables.py:142#: dashboards/project/volumes/volumes/tables.py:176#: dashboards/project/volumes/volumes/tables.py:203#: dashboards/project/volumes/volumes/tables.py:263#: dashboards/project/volumes/volumes/tables.py:281#: dashboards/project/volumes/volumes/tables.py:302#: dashboards/project/volumes/volumes/tables.py:304#: dashboards/project/volumes/volumes/tables.py:354#: dashboards/project/volumes/volumes/tables.py:357#: dashboards/project/volumes/volumes/tables.py:378#: dashboards/project/volumes/volumes/tables.py:387#: dashboards/project/volumes/volumes/tables.py:415#: dashboards/project/volumes/volumes/tables.py:424","""POT-Creation-Date: 2014-12-10 22:10-0600\n"" ""PO-Revision-Date: 2014-12-11 00:12+0000\n""#: dashboards/project/volumes/volumes/tables.py:307#: dashboards/project/data_processing/clusters/tabs.py:134#: dashboards/project/volumes/volumes/tables.py:323 #: dashboards/project/volumes/volumes/tables.py:352#: dashboards/project/volumes/volumes/tables.py:359#: dashboards/project/data_processing/clusters/tabs.py:149#: dashboards/project/volumes/tabs.py:62#: dashboards/project/volumes/volumes/tables.py:368 usage/quotas.py:74#: dashboards/admin/volumes/tabs.py:112#: dashboards/project/volumes/tabs.py:76#: dashboards/project/volumes/volumes/tables.py:257#: dashboards/project/volumes/volumes/tables.py:355#: dashboards/project/volumes/volumes/tables.py:333#: dashboards/project/volumes/volumes/tables.py:329#: dashboards/project/volumes/volumes/tables.py:326msgid ""Network Detail"" msgstr ""Network Detail""#: dashboards/admin/routers/templates/routers/detail.html:6 msgid ""Router Detail"" msgstr ""Router Detail"" #: dashboards/admin/volumes/tabs.py:50 dashboards/admin/volumes/tabs.py:138#: dashboards/admin/volumes/tabs.py:65#: dashboards/admin/volumes/tabs.py:77#: dashboards/admin/volumes/tabs.py:85#: dashboards/admin/volumes/tabs.py:106#: dashboards/admin/volumes/tabs.py:130 dashboards/project/volumes/tabs.py:90#: dashboards/project/volumes/volumes/tables.py:124 #: dashboards/project/volumes/volumes/tables.py:192#: dashboards/project/volumes/volumes/tables.py:420#: dashboards/project/data_processing/nodegroup_templates/templates/data_processing.nodegroup_templates/_service_confs.html:12#: dashboards/project/data_processing/clusters/tabs.py:111#: dashboards/project/data_processing/clusters/tabs.py:137#: dashboards/project/data_processing/clusters/tabs.py:140#: dashboards/project/data_processing/clusters/tabs.py:145#: dashboards/project/data_processing/clusters/tabs.py:174#: dashboards/project/volumes/volumes/tables.py:198#: dashboards/project/volumes/volumes/tables.py:101 #: dashboards/project/volumes/volumes/tables.py:126#: dashboards/project/volumes/volumes/tables.py:173#: dashboards/project/volumes/volumes/tables.py:357msgid ""Network Detail: %(network_name)s"" msgstr ""Network Detail: %(network_name)s""msgid ""Subnet Detail"" msgstr ""Subnet Detail""""available by clicking on the \""Subnet Detail\"" tab."" msgstr ""Create a subnet associated with the network. Advanced configuration is available by clicking on the \""Subnet Detail\"" tab.""""available at \""Subnet Detail\"" tab."" msgstr ""Update a subnet associated with the network. Advanced configuration are available at \""Subnet Detail\"" tab.""msgid ""Port Detail"" msgstr ""Port Detail"""" Clicking the <i class=\""icon-random\""></i> button in the intersection will install a rule to switch the traffic behavior.<br/>\n""msgstr ""The colour and icon of an intersection indicates whether or not traffic is permitted from the source (row) to the destination (column).\n Clicking the <i class=\""icon-random\""></i> button in the intersection will install a rule to switch the traffic behaviour.<br/>\n\n <b>Note:</b> Rules only affect one direction of traffic. The opposite direction is outlined when hovering over an intersection.\n ""msgid ""Stack Detail: %(stack_name)s"" msgstr ""Stack Detail: %(stack_name)s""msgid ""Resource Detail: %s"" msgstr ""Resource Detail: %s""msgid ""Stack Detail"" msgstr ""Stack Detail""msgid ""Resource Detail"" msgstr ""Resource Detail""#: dashboards/project/volumes/tabs.py:104#: dashboards/project/volumes/tabs.py:121#: dashboards/project/volumes/volumes/tables.py:441#: dashboards/project/volumes/volumes/tables.py:138#: dashboards/project/volumes/volumes/tables.py:238#: dashboards/project/volumes/volumes/tables.py:226#: dashboards/project/volumes/volumes/tables.py:88 #, python-format msgid ""Unable to delete volume \""%s\"". One or more snapshots depend on it."" msgstr ""Unable to delete volume \""%s\"". One or more snapshots depend on it."" #: dashboards/project/volumes/volumes/tables.py:149#: dashboards/project/volumes/volumes/tables.py:183#: dashboards/project/volumes/volumes/tables.py:210#: dashboards/project/volumes/volumes/tables.py:270#: dashboards/project/volumes/volumes/tables.py:288#: dashboards/project/volumes/volumes/tables.py:309#: dashboards/project/volumes/volumes/tables.py:311#: dashboards/project/volumes/volumes/tables.py:361#: dashboards/project/volumes/volumes/tables.py:364#: dashboards/project/volumes/volumes/tables.py:385#: dashboards/project/volumes/volumes/tables.py:394#: dashboards/project/volumes/volumes/tables.py:422#: dashboards/project/volumes/volumes/tables.py:431",1425,1424
openstack%2Fheat~master~Ifce77584f9f29418f3b3ca47ca6fa001ded904dc,openstack/heat,master,Ifce77584f9f29418f3b3ca47ca6fa001ded904dc,Updated from global requirements,MERGED,2014-12-08 16:17:47.000000000,2014-12-12 07:52:43.000000000,2014-12-12 07:52:42.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7491}, {'_account_id': 8871}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-08 16:17:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/932a0fb0966666d3ba22a0cdae70aade51f1070f', 'message': 'Updated from global requirements\n\nChange-Id: Ifce77584f9f29418f3b3ca47ca6fa001ded904dc\n'}, {'number': 2, 'created': '2014-12-09 14:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7499589584b73f9b622e6151f00f1913c0b6a908', 'message': 'Updated from global requirements\n\nChange-Id: Ifce77584f9f29418f3b3ca47ca6fa001ded904dc\n'}, {'number': 3, 'created': '2014-12-10 16:57:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/621f8d7c262dbd34ce06c1b6ec5abd721b1763d3', 'message': 'Updated from global requirements\n\nChange-Id: Ifce77584f9f29418f3b3ca47ca6fa001ded904dc\n'}, {'number': 4, 'created': '2014-12-11 07:13:29.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/heat/commit/85650b3e485a33ddcabbc443b494104b05347386', 'message': 'Updated from global requirements\n\nChange-Id: Ifce77584f9f29418f3b3ca47ca6fa001ded904dc\n'}]",0,140052,85650b3e485a33ddcabbc443b494104b05347386,19,5,4,11131,,,0,"Updated from global requirements

Change-Id: Ifce77584f9f29418f3b3ca47ca6fa001ded904dc
",git fetch https://review.opendev.org/openstack/heat refs/changes/52/140052/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,932a0fb0966666d3ba22a0cdae70aade51f1070f,openstack/requirements,"SQLAlchemy>=0.9.7,<=0.9.99","SQLAlchemy>=0.8.4,<=0.8.99,>=0.9.7,<=0.9.99",1,1
openstack%2Fpython-heatclient~master~Icabc07996dfa7bb9cae2a5fab2bd7732fa85c402,openstack/python-heatclient,master,Icabc07996dfa7bb9cae2a5fab2bd7732fa85c402,Updated from global requirements,MERGED,2014-12-11 07:19:55.000000000,2014-12-12 07:27:28.000000000,2014-12-12 07:27:27.000000000,"[{'_account_id': 3}, {'_account_id': 4715}]","[{'number': 1, 'created': '2014-12-11 07:19:55.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/892d423da360c609afb6d74d25e54123dc0d0d1e', 'message': 'Updated from global requirements\n\nChange-Id: Icabc07996dfa7bb9cae2a5fab2bd7732fa85c402\n'}]",0,140955,892d423da360c609afb6d74d25e54123dc0d0d1e,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Icabc07996dfa7bb9cae2a5fab2bd7732fa85c402
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/55/140955/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,892d423da360c609afb6d74d25e54123dc0d0d1e,openstack/requirements,oslo.utils>=1.1.0 # Apache-2.0,oslo.utils>=1.0.0 # Apache-2.0,1,1
openstack%2Fopenstack-ansible~master~I581ab1e58464e3a99edeb52039a7b8f6e88f3149,openstack/openstack-ansible,master,I581ab1e58464e3a99edeb52039a7b8f6e88f3149,Correct Swift service health checks,MERGED,2014-12-12 00:02:42.000000000,2014-12-12 07:26:23.000000000,2014-12-12 05:06:31.000000000,"[{'_account_id': 3}, {'_account_id': 6589}, {'_account_id': 6714}, {'_account_id': 7353}, {'_account_id': 9884}, {'_account_id': 12892}]","[{'number': 1, 'created': '2014-12-12 00:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a68dddf2af5fa655a222dbbcbfc388fcb8ffcac1', 'message': 'Correct Swift service health checks\n\nThe account, container, and object service checks should currently fail\nbecause they are trying to connect to the {{ ansible_ssh_host }}\naddress. The services are only bound to the storage networking\ninterface. Additionally, the health check url is misspelled for all\nservices.\n\n  - Use the storage network address for Swift service checks\n  - Correct the health check url spelling\n\nChange-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149\nCloses-Bug: #1401701\n'}, {'number': 2, 'created': '2014-12-12 02:43:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/638bf6bcdb0edfcfa338ad4f37fa42ebdc343de9', 'message': 'Correct Swift service health checks\n\nThe account, container, and object service checks currently fail\nbecause they are trying to connect to the {{ ansible_ssh_host }}\naddress. The services are only bound to the storage network\ninterface. This does not effect the proxy service as it is bound\nto all interfaces.\n\nAdditionally, the health check url is misspelled for all services.\n\n  - Use the storage network address for Swift service checks\n  - Correct the health check url spelling\n\nChange-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149\nCloses-Bug: #1401701\n'}, {'number': 3, 'created': '2014-12-12 04:03:43.000000000', 'files': ['rpc_deployment/playbooks/monitoring/swift_maas.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c2fb63bfdd7f5b9cf47a8598a5178543b794f8c0', 'message': 'Correct Swift service health checks\n\nThe account, container, and object service checks currently fail\nbecause they are trying to connect to the {{ ansible_ssh_host }}\naddress. The services are only bound to the storage network\ninterface. This does not effect the proxy service as it is bound\nto all interfaces.\n\nAdditionally, the health check url is misspelled for all services.\n\n  - Use the storage network address for Swift service checks\n  - Correct the health check url spelling\n\nChange-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149\nCloses-Bug: #1401701\n'}]",2,141222,c2fb63bfdd7f5b9cf47a8598a5178543b794f8c0,20,6,3,6714,,,0,"Correct Swift service health checks

The account, container, and object service checks currently fail
because they are trying to connect to the {{ ansible_ssh_host }}
address. The services are only bound to the storage network
interface. This does not effect the proxy service as it is bound
to all interfaces.

Additionally, the health check url is misspelled for all services.

  - Use the storage network address for Swift service checks
  - Correct the health check url spelling

Change-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149
Closes-Bug: #1401701
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/22/141222/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/playbooks/monitoring/swift_maas.yml'],1,a68dddf2af5fa655a222dbbcbfc388fcb8ffcac1,bug/1401701," check_details: file=service_api_local_check.py,args=swift_object_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},args=6000 check_details: file=service_api_local_check.py,args=swift_container_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},args=6001 check_details: file=service_api_local_check.py,args=swift_account_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},t,args=6002 check_details: file=service_api_local_check.py,args=swift_proxy_server,args=--path,args=/healthcheck,args={{ ansible_ssh_host }},args=8080"," check_details: file=service_api_local_check.py,args=swift_object_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6000 check_details: file=service_api_local_check.py,args=swift_container_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6001 check_details: file=service_api_local_check.py,args=swift_account_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6002 check_details: file=service_api_local_check.py,args=swift_proxy_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=8080",4,4
openstack%2Fheat~master~I901b9e39dd0d394991520fea1f527e250c2c9680,openstack/heat,master,I901b9e39dd0d394991520fea1f527e250c2c9680,Check if encoded user credential may get truncated,MERGED,2014-11-28 11:43:09.000000000,2014-12-12 07:08:21.000000000,2014-12-12 07:08:19.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 7404}, {'_account_id': 8246}, {'_account_id': 8289}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-11-28 11:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a6ab56b03f0d4bbfe0abbfa4796137e7e2253e5a', 'message': ""Don't block stack deletion if user creds fail\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.  In this case, stack deletion\nwill abort due to uncaught exception.\n\nThis patch first check if the encoded credential might be truncated when\nit is generated and fail early during stack creation.  It also handles\nthe stack deletion error so that stack can be properly deleted.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nCloses-Bug: 1386213\n""}, {'number': 2, 'created': '2014-11-28 13:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/7c024133ffee90bdb77d8a84d56ca680222d14db', 'message': ""Don't block stack deletion if user creds fail\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.  In this case, stack deletion\nwill abort due to uncaught exception.\n\nThis patch first check if the encoded credential might be truncated when\nit is generated and fail early during stack creation.  It also handles\nthe stack deletion error so that stack can be properly deleted.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nCloses-Bug: 1386213\n""}, {'number': 3, 'created': '2014-11-28 14:20:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/93fc49485a98c21cb15325f190fd81b59c52d4e1', 'message': ""Don't block stack deletion if user creds fail\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.  In this case, stack deletion\nwill abort due to uncaught exception.\n\nThis patch first check if the encoded credential might be truncated when\nit is generated and fail early during stack creation.  It also handles\nthe stack deletion error so that stack can be properly deleted.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nCloses-Bug: 1386213\n""}, {'number': 4, 'created': '2014-12-01 10:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/3ea0c257dd33f7023508e9797e09184e9a95561c', 'message': ""Don't block stack deletion if user creds fail\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.  In this case, stack deletion\nwill abort due to uncaught exception.\n\nThis patch first check if the encoded credential might be truncated when\nit is generated and fail early during stack creation.  It also handles\nthe stack deletion error so that stack can be properly deleted.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nCloses-Bug: 1386213\n""}, {'number': 5, 'created': '2014-12-04 11:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/86f7261772c0fe040a79eb80144da667bdb135e0', 'message': 'Check if encoded user credential may get truncated\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.\n\nThis patch checks if the encoded credential might be truncated when\nit is generated and fail early during stack creation, or else it will\ncause troubles later on when operating the stack.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nPartial-Bug: 1386213\n'}, {'number': 6, 'created': '2014-12-09 12:49:02.000000000', 'files': ['heat/db/sqlalchemy/api.py', 'heat/tests/test_sqlalchemy_api.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/0d9af5c6833e26532bf798ebd0756e93d674b7fc', 'message': 'Check if encoded user credential may get truncated\n\nIn some deployments, user passwords are generated by other\nauthentication infrastructures where the length of the Base64 encoded\ncredentials is longer than the DB limit.\n\nThis patch checks if the encoded credential might be truncated when\nit is generated and fail early during stack creation, or else it will\ncause troubles later on when operating the stack.\n\nChange-Id: I901b9e39dd0d394991520fea1f527e250c2c9680\nPartial-Bug: 1386213\n'}]",11,137771,0d9af5c6833e26532bf798ebd0756e93d674b7fc,37,8,6,8246,,,0,"Check if encoded user credential may get truncated

In some deployments, user passwords are generated by other
authentication infrastructures where the length of the Base64 encoded
credentials is longer than the DB limit.

This patch checks if the encoded credential might be truncated when
it is generated and fail early during stack creation, or else it will
cause troubles later on when operating the stack.

Change-Id: I901b9e39dd0d394991520fea1f527e250c2c9680
Partial-Bug: 1386213
",git fetch https://review.opendev.org/openstack/heat refs/changes/71/137771/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_parser.py', 'heat/db/sqlalchemy/api.py', 'heat/engine/stack.py', 'heat/tests/test_sqlalchemy_api.py']",4,a6ab56b03f0d4bbfe0abbfa4796137e7e2253e5a,bug/1386213," def test_user_creds_password_too_long(self): self.ctx.trust_id = None self.ctx.password = 'O123456789O1234567' * 20 error = self.assertRaises(exception.Error, db_api.user_creds_create, self.ctx) self.assertIn('Length of OS_PASSWORD after encryption exceeds ' 'Heat limit (255 chars)', six.text_type(error)) ",,43,1
openstack%2Fheat~master~I9389664743c55385c78dfc3ba43afc14e6ae8c57,openstack/heat,master,I9389664743c55385c78dfc3ba43afc14e6ae8c57,Fixed typo in remote stack resource,MERGED,2014-12-12 01:19:01.000000000,2014-12-12 07:08:11.000000000,2014-12-12 07:08:10.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 4715}, {'_account_id': 8289}]","[{'number': 1, 'created': '2014-12-12 01:19:01.000000000', 'files': ['heat/engine/resources/remote_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/c9b604b375b8a698e98015a248211849da9936c8', 'message': 'Fixed typo in remote stack resource\n\nThis patch fixes a typo in error message in RemoteStack code.\n\nChange-Id: I9389664743c55385c78dfc3ba43afc14e6ae8c57\n'}]",0,141233,c9b604b375b8a698e98015a248211849da9936c8,9,4,1,8246,,,0,"Fixed typo in remote stack resource

This patch fixes a typo in error message in RemoteStack code.

Change-Id: I9389664743c55385c78dfc3ba43afc14e6ae8c57
",git fetch https://review.opendev.org/openstack/heat refs/changes/33/141233/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/remote_stack.py'],1,c9b604b375b8a698e98015a248211849da9936c8,remote-stack, msg = _('Resource action mismatch detected: expected=%(expected)s ', msg = _('Resource action misatch detected: expected=%(expected)s ',1,1
openstack%2Ftaskflow~master~I26c3bed2800789720cfc907c8e7dcbb3bad36447,openstack/taskflow,master,I26c3bed2800789720cfc907c8e7dcbb3bad36447,Avoid holding the lock while scanning for existing jobs,MERGED,2014-12-11 21:18:57.000000000,2014-12-12 06:53:38.000000000,2014-12-12 06:53:38.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2014-12-11 21:18:57.000000000', 'files': ['taskflow/jobs/backends/impl_zookeeper.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/1c7d242033c2ebf34ab73c6ba32308b9bba30ffd', 'message': 'Avoid holding the lock while scanning for existing jobs\n\nUnder python we can safely check if a string key is in\na dictionary without having to hold a lock on that dictionary\nto avoid concurrent deletions from affecting this check,\nso we can use that to our benefit to avoid holding the lock\nwhen searching for which potential jobs to request that do\nnot already exist in the currently known jobs.\n\nChange-Id: I26c3bed2800789720cfc907c8e7dcbb3bad36447\n'}]",0,141169,1c7d242033c2ebf34ab73c6ba32308b9bba30ffd,6,2,1,1297,,,0,"Avoid holding the lock while scanning for existing jobs

Under python we can safely check if a string key is in
a dictionary without having to hold a lock on that dictionary
to avoid concurrent deletions from affecting this check,
so we can use that to our benefit to avoid holding the lock
when searching for which potential jobs to request that do
not already exist in the currently known jobs.

Change-Id: I26c3bed2800789720cfc907c8e7dcbb3bad36447
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/69/141169/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/jobs/backends/impl_zookeeper.py'],1,1c7d242033c2ebf34ab73c6ba32308b9bba30ffd,, pending_removals = [] pending_removals.append(path) for path in child_paths: if path in self._bad_paths: continue # This pre-check will *not* guarantee that we will not already # have the job (if it's being populated elsewhere) but it will # reduce the amount of duplicated requests in general; later when # the job information has been populated we will ensure that we # are not adding duplicates into the currently known jobs... if path in self._known_jobs: continue if path not in investigate_paths: investigate_paths.append(path) if pending_removals: with self._job_cond: for path in pending_removals:, removals = [] removals.append(path) for path in child_paths: if path in self._bad_paths: continue # This pre-check will not guarantee that we will not already # have the job (if it's being populated elsewhere) but it will # reduce the amount of duplicated requests in general. if path in self._known_jobs: continue if path not in investigate_paths: investigate_paths.append(path) if removals: with self._job_cond: for path in removals:,16,14
openstack%2Fopenstack-ansible~stable%2Fjuno~I581ab1e58464e3a99edeb52039a7b8f6e88f3149,openstack/openstack-ansible,stable/juno,I581ab1e58464e3a99edeb52039a7b8f6e88f3149,Correct Swift service health checks,MERGED,2014-12-12 05:13:52.000000000,2014-12-12 06:22:41.000000000,2014-12-12 05:15:59.000000000,"[{'_account_id': 3}, {'_account_id': 7353}, {'_account_id': 9884}]","[{'number': 1, 'created': '2014-12-12 05:13:52.000000000', 'files': ['rpc_deployment/playbooks/monitoring/swift_maas.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/348dadac61a647a3469fd7bf3b1411df53f6457f', 'message': 'Correct Swift service health checks\n\nThe account, container, and object service checks currently fail\nbecause they are trying to connect to the {{ ansible_ssh_host }}\naddress. The services are only bound to the storage network\ninterface. This does not effect the proxy service as it is bound\nto all interfaces.\n\nAdditionally, the health check url is misspelled for all services.\n\n  - Use the storage network address for Swift service checks\n  - Correct the health check url spelling\n\nChange-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149\nCloses-Bug: #1401701\n(cherry picked from commit c2fb63bfdd7f5b9cf47a8598a5178543b794f8c0)\n'}]",0,141271,348dadac61a647a3469fd7bf3b1411df53f6457f,7,3,1,6714,,,0,"Correct Swift service health checks

The account, container, and object service checks currently fail
because they are trying to connect to the {{ ansible_ssh_host }}
address. The services are only bound to the storage network
interface. This does not effect the proxy service as it is bound
to all interfaces.

Additionally, the health check url is misspelled for all services.

  - Use the storage network address for Swift service checks
  - Correct the health check url spelling

Change-Id: I581ab1e58464e3a99edeb52039a7b8f6e88f3149
Closes-Bug: #1401701
(cherry picked from commit c2fb63bfdd7f5b9cf47a8598a5178543b794f8c0)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/71/141271/1 && git format-patch -1 --stdout FETCH_HEAD,['rpc_deployment/playbooks/monitoring/swift_maas.yml'],1,348dadac61a647a3469fd7bf3b1411df53f6457f,bug/1401701," storage_bridge: ""{{ 'ansible_' + swift.storage_network|replace('-', '_') }}"" storage_address: ""{{ hostvars[inventory_hostname][storage_bridge]['ipv4']['address'] }}"" check_details: file=service_api_local_check.py,args=swift_object_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},args=6000 storage_bridge: ""{{ 'ansible_' + swift.storage_network|replace('-', '_') }}"" storage_address: ""{{ hostvars[inventory_hostname][storage_bridge]['ipv4']['address'] }}"" check_details: file=service_api_local_check.py,args=swift_container_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},args=6001 storage_bridge: ""{{ 'ansible_' + swift.storage_network|replace('-', '_') }}"" storage_address: ""{{ hostvars[inventory_hostname][storage_bridge]['ipv4']['address'] }}"" check_details: file=service_api_local_check.py,args=swift_account_server,args=--path,args=/healthcheck,args={{ storage_address | default(container_address) }},args=6002 check_details: file=service_api_local_check.py,args=swift_proxy_server,args=--path,args=/healthcheck,args={{ ansible_ssh_host }},args=8080"," check_details: file=service_api_local_check.py,args=swift_object_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6000 check_details: file=service_api_local_check.py,args=swift_container_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6001 check_details: file=service_api_local_check.py,args=swift_account_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=6002 check_details: file=service_api_local_check.py,args=swift_proxy_server,args=--path,args=/healtcheck,args={{ ansible_ssh_host }},args=8080",10,4
openstack%2Fheat~master~Icefec1b794ef0589d535f944ae5a7605cabe7e8b,openstack/heat,master,Icefec1b794ef0589d535f944ae5a7605cabe7e8b,Stricter complexity checking in tox configuration,MERGED,2014-12-10 12:28:50.000000000,2014-12-12 06:07:30.000000000,2014-12-12 06:07:28.000000000,"[{'_account_id': 3}, {'_account_id': 1633}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 6610}, {'_account_id': 6698}, {'_account_id': 8246}, {'_account_id': 8871}, {'_account_id': 9542}, {'_account_id': 13009}, {'_account_id': 13323}]","[{'number': 1, 'created': '2014-12-10 12:28:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/heat/commit/354e23edb380d0cfa7851fe8fa5636611da93e5f', 'message': 'Stricter complexity checking in tox configuration\n\nThis is the last patch to fix complexity issue we have in Heat code.\n\nChange-Id: Icefec1b794ef0589d535f944ae5a7605cabe7e8b\n'}]",0,140660,354e23edb380d0cfa7851fe8fa5636611da93e5f,20,11,1,8246,,,0,"Stricter complexity checking in tox configuration

This is the last patch to fix complexity issue we have in Heat code.

Change-Id: Icefec1b794ef0589d535f944ae5a7605cabe7e8b
",git fetch https://review.opendev.org/openstack/heat refs/changes/60/140660/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,354e23edb380d0cfa7851fe8fa5636611da93e5f,tox-config,max-complexity=20,# 28 is currently the most complex thing we have # TODO(asalkeld): get this number down to 20 max-complexity=29,1,3
openstack%2Fpython-cinderclient~master~I8e440464d4cc4229c4f5f2246aa60a792430ff26,openstack/python-cinderclient,master,I8e440464d4cc4229c4f5f2246aa60a792430ff26,ingore .idea folder in python-cinderclient,ABANDONED,2014-08-28 06:50:34.000000000,2014-12-12 05:24:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2759}, {'_account_id': 4523}, {'_account_id': 8874}]","[{'number': 1, 'created': '2014-08-28 06:50:34.000000000', 'files': ['.gitignore'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/f794d0c38a2c1b6e354f670797bc170eb4a9fc32', 'message': 'ingore .idea folder in python-cinderclient\n\nIf we use JetBrains PyCharm as python develop tool, JetBrains PyCharm\nwould automatically generate its config folder name .idea in the root\ndir of your python code.\n\nMany Code projects, such as nova and cinder, have ignore .idea folder.\nProject python-cinderclient should also ignore .idea folder.\n\nChange-Id: I8e440464d4cc4229c4f5f2246aa60a792430ff26\nCloses-Bug: #1362446\n'}]",0,117439,f794d0c38a2c1b6e354f670797bc170eb4a9fc32,12,6,1,8874,,,0,"ingore .idea folder in python-cinderclient

If we use JetBrains PyCharm as python develop tool, JetBrains PyCharm
would automatically generate its config folder name .idea in the root
dir of your python code.

Many Code projects, such as nova and cinder, have ignore .idea folder.
Project python-cinderclient should also ignore .idea folder.

Change-Id: I8e440464d4cc4229c4f5f2246aa60a792430ff26
Closes-Bug: #1362446
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/39/117439/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitignore'],1,f794d0c38a2c1b6e354f670797bc170eb4a9fc32,bug/1362446,.idea,,1,0
openstack%2Foperations-guide~master~Ia089c9aeddb8ea3aef1dd36c4f57995ea6806482,openstack/operations-guide,master,Ia089c9aeddb8ea3aef1dd36c4f57995ea6806482,Updated from openstack-manuals,MERGED,2014-12-11 20:55:50.000000000,2014-12-12 04:53:42.000000000,2014-12-12 04:53:41.000000000,"[{'_account_id': 3}, {'_account_id': 612}]","[{'number': 1, 'created': '2014-12-11 20:55:50.000000000', 'files': ['doc/openstack-ops/openstack.ent'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/ed442ef9ad77873038ca5fef87c93ed0469535e4', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ia089c9aeddb8ea3aef1dd36c4f57995ea6806482\n'}]",0,141158,ed442ef9ad77873038ca5fef87c93ed0469535e4,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ia089c9aeddb8ea3aef1dd36c4f57995ea6806482
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/58/141158/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/openstack-ops/openstack.ent'],1,ed442ef9ad77873038ca5fef87c93ed0469535e4,openstack/openstack-manuals,"<!-- Useful for describing APIs in the User Guide --> <!ENTITY COPY '<command xmlns=""http://docbook.org/ns/docbook"">COPY</command>'> <!ENTITY GET '<command xmlns=""http://docbook.org/ns/docbook"">GET</command>'> <!ENTITY HEAD '<command xmlns=""http://docbook.org/ns/docbook"">HEAD</command>'> <!ENTITY PUT '<command xmlns=""http://docbook.org/ns/docbook"">PUT</command>'> <!ENTITY POST '<command xmlns=""http://docbook.org/ns/docbook"">POST</command>'> <!ENTITY DELETE '<command xmlns=""http://docbook.org/ns/docbook"">DELETE</command>'> ",,8,0
openstack%2Fneutron-specs~master~I81a05a5c906a1fee43ed59cd38a46176682ca363,openstack/neutron-specs,master,I81a05a5c906a1fee43ed59cd38a46176682ca363,OVSvAPP solution for VLAN and security groups,ABANDONED,2014-07-03 05:47:21.000000000,2014-12-12 04:48:56.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 9361}, {'_account_id': 10068}, {'_account_id': 10370}, {'_account_id': 11412}, {'_account_id': 11415}]","[{'number': 1, 'created': '2014-07-03 05:47:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/15f4ca082cbdc37196c842a3018003a65547ff55', 'message': 'OVSvAPP solution for VLAN and security groups\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 2, 'created': '2014-07-08 06:21:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0ee53ee96f3081709227c7b9e6b73b19d4efe42d', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint esx-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 3, 'created': '2014-07-12 00:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/6b3d3ee34b98bcfe6d2ea5a8286e258ca6d84795', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 4, 'created': '2014-07-12 00:17:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2c4bc80edc8cb40bdff435558b5cdd98a648917e', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 5, 'created': '2014-09-26 10:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/4572d5330a95013290186e75e6261cd98e8e94f7', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 6, 'created': '2014-09-26 10:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/36c2d104ca6c8833b0bdc4d1c1805418a80b8f8c', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 7, 'created': '2014-10-15 17:32:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/606573f14d1bb31e189e89fc99a4c2497e9e40f8', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 8, 'created': '2014-10-15 17:49:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/fd808b2502db98637ed6d1a0b042a2030845597d', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 9, 'created': '2014-10-21 10:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b9774d84735362a28be856f952d66691bfc2707b', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 10, 'created': '2014-11-17 05:48:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/60d0154772a448ef66e746dca45f37be387ee9e4', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 11, 'created': '2014-11-19 08:55:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/76663841b5bf645be871b5579d1375b486ab2f10', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 12, 'created': '2014-11-19 08:59:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/0a1ee3a43c861784c8cd136aa617ef384a7eb42c', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 13, 'created': '2014-11-30 15:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/10ce880b731ae3032b80043065fc75d7da343d79', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 14, 'created': '2014-12-02 06:29:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/f54c52a419b31372e6a840a15304adc156069d83', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}, {'number': 15, 'created': '2014-12-03 02:53:54.000000000', 'files': ['specs/kilo/ovsvapp-solution-for-esx-deployments.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/239a5ebc1cd9a89c76de351cc597616f7bf5271e', 'message': 'OVSvAPP solution for VLAN and security groups\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363\n'}]",51,104452,239a5ebc1cd9a89c76de351cc597616f7bf5271e,51,8,15,10368,,,0,"OVSvAPP solution for VLAN and security groups

Part of umbrella blueprint vsphere-neutron

Co-Authored-By: Romil Gupta <romilg@hp.com>

Change-Id: I81a05a5c906a1fee43ed59cd38a46176682ca363
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/52/104452/11 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ovsvapp_esx_vlan.rst'],1,15f4ca082cbdc37196c842a3018003a65547ff55,bp/vsphere-neutron,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= OVSvApp Solution : ESX with VLAN ================================= OpenStack has very good number of networking features like VLAN provisioning, Security Groups etc. for KVM based networks with vendor agnostic capabilities. However OpenStack has very limited features for ESX networks. The idea of this proposal is to bring these vendor agnostic features to ESX networks with minimal efforts by steering the ESX tenant VMs' traffic through a service VM called OVSvApp VM which hosts the OpenStack features. The value-add with this design is faster deployment of solutions on ESX environments together with minimum effort required for adding new Openstack features like DVR, LBaaS, VPNaaS etc. on ESX networks. Include the URL of your launchpad blueprint: None Problem description =================== In existing ESX solutions, Tenant VMs hosted on the ESX Hypervisor can be provisioned by Openstack only through vendor specific plugins. Using this plugin implies that the customers are tied to specific vendor and will not have the flexibility to choose different vendors for their networks based on vendor agnostic OpenStack. Proposed change =============== To address the above challenge, the proposed solution allows the customers to host VMs on ESX hypervisors together with the flexibility of creating portgroups dynamically on Distributed Virtual Switch/Virtual Standard Switch, and then steer its traffic through the OVSvApp VM which provides VLAN and Security Group features based on Openstack. The Neutron Server side implementation for VLAN provisioning, Security Groups is used as is and will have very minimal changes to process the ESX VM networking information. OVSvApp VM is a VM with Open vSwitch installed and it runs an OVSvApp agent (L2 agent in terms of Openstack) , which would wait for cluster events like ""VM_CREATE"", ""VM_DELETE"" and ""VM_UPDATE"" from vCenter and process accordingly by fetching the Open vSwitch(OVS) FLOWs information from the Neutron Server and programming the Open vSwitch. OVSvApp agent manages at least 3 OVS Bridges namely Security Group Bridge, Integration Bridge and Physical Bridges(1 or more) to connect to the network interfaces. The VM traffic initially reaches the Security Group Bridge which will have FLOWs based on the customer's Openstack Security Groups rules which will either allow/block the traffic from the tenant VMs. Open vSwitch based Firewall Driver is added to accomplish Security Groups functionality, similar to iptable Firewall Driver. The Integration Bridge connects Security Group Bridge and Physical Bridges. The reason to have Integration Bridge is to leverage existing Openstack Open vSwitch L2 agent feature to a maximum. The Physical Bridge functionality is similar to the one existing in Openstack. Alternatives ------------ 1. No alternative to our OVSvAPP solution. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Existence of a Trunk Portgroup for all tenant data traffic to pass through OVSvApp VM may hit performance. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Raghuveer Shenoy <rshenoy> Other contributors: Romil Gupta <romilg> Gangadhar Singh <gangadhar-singh> Rashmi P <prashmi> Vishal Thapar <vthapar> Work Items ---------- OVSvApp agent implementation ML2 - rpc and mechanism driver Security Groups Dependencies ============ Open vSwitch, suds Testing ======= Unit tests will be added. Existing tempest tests should be good enough for OVSvApp agent flow. Documentation Impact ==================== OVSvApp solution needs a configuration file which has details about vCenter server with its intricacies and Open vSwitch bridges. References ========== https://blueprints.launchpad.net/neutron/+spec/neutron-agent-for-dynamically -creating-port-groups-in-vcenter ",,161,0
openstack%2Fneutron-specs~master~I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2,openstack/neutron-specs,master,I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2,OVSvApp Solution for VXLAN overlay,ABANDONED,2014-07-01 04:55:22.000000000,2014-12-12 04:48:21.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 10370}, {'_account_id': 11415}]","[{'number': 1, 'created': '2014-07-01 04:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/156350be49e669620c2e608acae1c93e6045a408', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 2, 'created': '2014-07-01 08:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/117ef987929f095862a3efe6c0ad6ceda138a810', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPatchSet 2: Fixed Jenkins errors\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 3, 'created': '2014-07-08 06:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/527da67e33e4ecc67ea8cdf3630c560f43f95a76', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPart of umbrella blueprint esx-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 4, 'created': '2014-07-12 00:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/a9927023acd720fd496e9efabfecbe409348292d', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 5, 'created': '2014-10-15 17:31:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/42c9817fc2fe432f9f9c9468660156a24e88fc6d', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 6, 'created': '2014-10-15 17:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/64d09ba91a64549963341950dd3a5c3362ecd0d3', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 7, 'created': '2014-11-13 09:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/647a6e0ee6b3f9237169515ec65dc7d3121e9da2', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 8, 'created': '2014-11-13 09:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/72c9d2eb70d4b5579040dec4d63fb9785fb49337', 'message': 'OVSvApp Solution for ESXi networks with VXLAN deployment\n\nChanged to Kilo format\n\nPart of umbrella blueprint vsphere-neutron\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 9, 'created': '2014-11-17 10:19:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e2107a136ca73862afad5d024d7b61a982c1912d', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 10, 'created': '2014-11-19 09:19:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/470e65d5876680759d51fa0866f1e3817c24fa70', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 11, 'created': '2014-11-19 09:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/2b71dac5a6745db22966312c2a5df3e18092f854', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 12, 'created': '2014-11-30 15:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/72124a32e5828f2b8be89c598b6175b910cc2596', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 13, 'created': '2014-11-30 15:58:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/64ffcccac84ddc979824f3ceacbb0878b1f35b64', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 14, 'created': '2014-12-03 09:22:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/b1553d31d135ccaa5bffc0ced9a268439af1a1d5', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com> and\nRashmi <prashmi@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}, {'number': 15, 'created': '2014-12-03 09:26:18.000000000', 'files': ['specs/kilo/ovsvapp_esx_vxlan.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/775f5c811898b0e534f42945b39bb050c7b169ae', 'message': 'OVSvApp Solution for VXLAN overlay\n\nPart of umbrella blueprint vsphere-neutron\n\nCo-Authored-By: Romil Gupta <romilg@hp.com> and\nRashmi <prashmi@hp.com>\n\nChange-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2\n'}]",8,103728,775f5c811898b0e534f42945b39bb050c7b169ae,43,4,15,11412,,,0,"OVSvApp Solution for VXLAN overlay

Part of umbrella blueprint vsphere-neutron

Co-Authored-By: Romil Gupta <romilg@hp.com> and
Rashmi <prashmi@hp.com>

Change-Id: I8fb3f183e5806714632b61b5d6d2b02fdfc73cc2
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/28/103728/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/ovsvapp_esx_vxlan.rst'],1,156350be49e669620c2e608acae1c93e6045a408,bp/vsphere-neutron,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================== OVSvApp Solution : ESX + VXLAN ============================== The idea of this proposal is to provide a decentralized management model for ESX-VXLAN deployments based on Openstack’s KVM VXLAN solution using a virtual machine (OVSvApp) for ESXi Networks. The solution provides 2^24 networks using VMware VLAN primitive APIs, which can only provide 4096 networks. Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/ovsvapp-esxi-vxlan Problem description =================== The idea of this proposal is to discuss the design options for the OVSvApp solution for supporting VXLAN on ESXi networks based on Openstack. Proposed change =============== To address the above challenge, the proposed solution allows the customers to host VMs on ESX hypervisors together with the flexibility of creating portgroups dynamically on Distributed Virtual Switch/Virtual Standard Switch, and then steer its traffic through the OVSvApp VM which provides VXLAN tunnelling based on Openstack. The solution uses/modifies Openstack’s Neutron Server and OVS agent to provide VXLAN connectivity. Existing Neutron Server will be used as is to provide tenants, networks, subnets, ports, tunnel information to OVS agent. OVS agent will be enhanced to process VM Creation/VM deletion event from VCenter Manager (Vmware Manager to provision the Hosts on the ESXi Hypervsior). It maps VLAN created by Vmware primitive APIs to VXLAN VNI provided by the Neutron Server. The VLANs will be local to the Hypervisor and will be mapped to a Global VXLAN VNI (let’s assume: 5000). On Hypervisor (HV) 1, this will map to a Local VLAN of 1, but on HV 2, this same VNI will map to VLAN 5. This in-memory mapping helps the solution to provide high scalability numbers theoretically: 2^24. This solution deployment comprises of two ESXi Distributed Virtual Switch (DVS), software switches by VMware and OVSvApp VM. Tenant VMs are booted on 1st DVS and will not have any ‘uplinks’ (external network connectivity) but will provide connectivity to VMs and OVSvApp.2nd DVS consists of uplinks to provide data connectivity to OVSvApp and management connectivity to the Neutron Server. asciiflow:: +-------------+ +-----------+ neutron +-----------------------------------+ | | server | | | +---+---------+ | | | | +-+--------+ | +----------+ | | nova |------+--------------------->|vCenter |-------+ | |compute | | +------------------+ | | | +----------+ | | +----------+ | | +----------------+ +------+v---v----+ +-------+ +-----> OVSvAPP VM-1 | +-------+ +-----> OVSvAPP VM-2 | | vm-1| | | (l2 agent) | | vm-2 | | | (l2 agent ) | +---+---+ | +------+---------v +---+---+ | +------+---------v +---|------|------------|-----+ +---|------|------------|-----+ | | | | | | | | | | | +-v------+------+ | | | +-v------+------+ | | | | | | | | | | | | | | DVS-1 | | | | | DVS-1 | | | | +---------------+ | | + +---------------+ | | | | | | | | | | | | | | | +-------------v--+ | | +-------------v--+ | | | | | | | | | DVS-2 | | | | DVS-2 | | v +-----+----------+ | | ++---------------+ | | | | | | | | ESX-1 hypervi|or | | ESX-2 hy|ervisor | +-------+-------|-------------+ +----------|------------------+ | | uplink -esx-1 uplink-esx-2 | | +---------data network----------+ OVSvApp Internals & Data Flow asciiflow:: +-----------------+ +-----------------+ | Compute Node | | Compute Node | | | | | +-----------------+ +-----------------+ +--------+ +--------+ +--------+ +--------+ | VM1 | +--+| VM2 | | VM1 | | VM2 | +------+-+ | +----+---+ +-------++ +----+---+ | | | | <-----+-----+-------------> +------|-------------|----+ | +-v-----v-++---------+| | +--v------++-----v---+| | | PG-1 || PG-2 || + | | PG-1 || PG-10 || | | || || | | || || | +---------++---------+| | +---------++---------+| | | | | +--------------+----------+ +--------------+----------+ | | +-----+------v--v----------------+ +-----+---------v----------------+ | | +------------+ | | | +------------+ | | | | BR-INT | | | | | BR-INT | | | V | | | | | V | | | | | | +------+-----+ | | | +------+-----+ | | M | | | | M | | | | | +------v-----+ | | | +------v-----+ | | | | BR-TUN | | | | | BR-TUN | | | | | | | | | | | | | | +------+-----+ | | | +------+-----+ | | | | | | | | | +-----+-------------+------------+ +-----+-------------+------------+ | | | | +--------data network----------------- Use Cases: ========== Intra-VXLAN on same Hypervisor ============================== L2 learning capabilities of DVS are used for intra-VXLAN traffic on the same hypervisor. Intra-VXLAN across Hypervisors ============================== VM traffic flows through the Logical Port on Integration Bridge and reaches Tunnel Bridge. Tunnel Bridge strips VLAN tags (hypervisor local significance) and adds VXLAN header (Global VNI) and forwards the traffic on the wire. Inter-VXLAN traffic (same/across Hypervisors) ============================================= VM Traffic flows through the Network Node (NN) which then forwards to VXLAN tunnel. Alternatives ------------ 1. No alternative to our OVSvAPP solution. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Existence of a Trunk Portgroup for all tenant data traffic to pass through OVSvApp VM may hit performance. Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Singh, Gangadhar P,Rashmi Other contributors: Gupta, Romil Shenoy, Raghuveer Thapar, Vishal Work Items ---------- OVSvApp agent implementation ML2 - rpc and mechanism driver Dependencies ============ None Testing ======= Unit tests will be added. Existing tempest tests should be good enough for OVSvApp agent flow. Documentation Impact ==================== OVSvApp solution needs a configuration file which has details about vCenter server with its intricacies and Open vSwitch bridges. References ========== None ",,237,0
openstack%2Fopenstack-manuals~master~I21813e5975c8cefa9dd5f34cb2039b2f41471cd8,openstack/openstack-manuals,master,I21813e5975c8cefa9dd5f34cb2039b2f41471cd8,Adds large object information to End User Guide,MERGED,2014-12-11 18:54:11.000000000,2014-12-12 04:43:38.000000000,2014-12-12 04:43:37.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 964}]","[{'number': 1, 'created': '2014-12-11 18:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/efc93f74f7638af779dc243fbbe96ea82a04df5d', 'message': 'Adds large object information to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I21813e5975c8cefa9dd5f34cb2039b2f41471cd8\nPartial-bug: 1392382\n'}, {'number': 2, 'created': '2014-12-11 21:58:31.000000000', 'files': ['doc/user-guide/samples/large-object-upload-segment-req.txt', 'doc/user-guide/section_object-api-create-large-objects.xml', 'doc/user-guide/samples/slo-manifest-example.txt', 'doc/user-guide/samples/large-object-upload-next-segment-req.txt', 'doc/user-guide/samples/upload-manifest-req.txt', 'doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/samples/upload-manifest-resp.txt'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/356358e94f6493b5a198d36ca1fb5bcaaa157267', 'message': 'Adds large object information to End User Guide\n\nWith the moving of the Object Storage API content from a\nlong-form dev guide to a specification, some topics needed\nTo be added to the End User Guide.\n\nChange-Id: I21813e5975c8cefa9dd5f34cb2039b2f41471cd8\nPartial-bug: 1392382\n'}]",0,141128,356358e94f6493b5a198d36ca1fb5bcaaa157267,9,3,2,12454,,,0,"Adds large object information to End User Guide

With the moving of the Object Storage API content from a
long-form dev guide to a specification, some topics needed
To be added to the End User Guide.

Change-Id: I21813e5975c8cefa9dd5f34cb2039b2f41471cd8
Partial-bug: 1392382
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/28/141128/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide/samples/large-object-upload-segment-req.txt', 'doc/user-guide/section_object-api-create-large-objects.xml', 'doc/user-guide/samples/slo-manifest-example.txt', 'doc/user-guide/samples/large-object-upload-next-segment-req.txt', 'doc/user-guide/samples/upload-manifest-req.txt', 'doc/user-guide/section_cli_swift_howto.xml', 'doc/user-guide/samples/upload-manifest-resp.txt']",7,efc93f74f7638af779dc243fbbe96ea82a04df5d,bug/1392382,[...],,428,0
openstack-attic%2Fidentity-api~master~Ib35492ba4be77b38bdc4fcfdbcd81e70d09835de,openstack-attic/identity-api,master,Ib35492ba4be77b38bdc4fcfdbcd81e70d09835de,Indicate repo is frozen in README,MERGED,2014-12-11 23:20:44.000000000,2014-12-12 04:39:43.000000000,2014-12-12 04:39:42.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 6486}]","[{'number': 1, 'created': '2014-12-11 23:20:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack-attic/identity-api/commit/9ec83671ac530621c84b2ad385fa0eb745274237', 'message': 'Indicate repo is frozen in README\n\nChange-Id: Ib35492ba4be77b38bdc4fcfdbcd81e70d09835de\n'}]",2,141208,9ec83671ac530621c84b2ad385fa0eb745274237,7,3,1,964,,,0,"Indicate repo is frozen in README

Change-Id: Ib35492ba4be77b38bdc4fcfdbcd81e70d09835de
",git fetch https://review.opendev.org/openstack-attic/identity-api refs/changes/08/141208/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,9ec83671ac530621c84b2ad385fa0eb745274237,freeze,This repository is now frozen-in-time and will not accept new patches. It was the original holder for API information for the OpenStack,This repository contains the RESTful API information for the OpenStack,3,1
openstack%2Fhorizon~master~If593f248fc4efc4df7296e27c991241c4bdd5260,openstack/horizon,master,If593f248fc4efc4df7296e27c991241c4bdd5260,Fixes Inconsistent usage of Detail / Details,MERGED,2014-12-10 10:35:18.000000000,2014-12-12 03:39:22.000000000,2014-12-12 03:39:21.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6610}, {'_account_id': 8871}, {'_account_id': 9317}, {'_account_id': 9981}, {'_account_id': 11599}, {'_account_id': 12355}, {'_account_id': 12826}, {'_account_id': 13785}]","[{'number': 1, 'created': '2014-12-10 10:35:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e81dfce9cb5a49682c5670556d6b06d447fa879f', 'message': 'Fixes Inconsistent usage of Detail / Details\n\nThis patch changes all the instances of ""Detail"" to ""Details""\n\nChange-Id: If593f248fc4efc4df7296e27c991241c4bdd5260\nCloses-bug: #1396080\n'}, {'number': 2, 'created': '2014-12-11 15:52:28.000000000', 'files': ['openstack_dashboard/dashboards/admin/networks/templates/networks/subnets/index.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/detail.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/resource.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/ports/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/subnets/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/detail.html', 'openstack_dashboard/dashboards/project/networks/subnets/workflows.py', 'openstack_dashboard/dashboards/admin/routers/templates/routers/detail.html', 'openstack_dashboard/dashboards/project/networks/views.py', 'openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/dashboards/project/networks/workflows.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/129614b0b795b7f7c10442f55134c79a62874401', 'message': 'Fixes Inconsistent usage of Detail / Details\n\nThis patch changes all the instances of ""Detail"" to ""Details""\n\nChange-Id: If593f248fc4efc4df7296e27c991241c4bdd5260\nCloses-bug: #1396080\n'}]",0,140635,129614b0b795b7f7c10442f55134c79a62874401,26,10,2,11599,,,0,"Fixes Inconsistent usage of Detail / Details

This patch changes all the instances of ""Detail"" to ""Details""

Change-Id: If593f248fc4efc4df7296e27c991241c4bdd5260
Closes-bug: #1396080
",git fetch https://review.opendev.org/openstack/horizon refs/changes/35/140635/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/networks/templates/networks/subnets/index.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/detail.html', 'openstack_dashboard/dashboards/project/stacks/templates/stacks/resource.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/ports/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/subnets/detail.html', 'openstack_dashboard/dashboards/project/networks/templates/networks/detail.html', 'openstack_dashboard/dashboards/project/networks/subnets/workflows.py', 'openstack_dashboard/dashboards/admin/routers/templates/routers/detail.html', 'openstack_dashboard/dashboards/project/networks/workflows.py']",9,e81dfce9cb5a49682c5670556d6b06d447fa879f,bugs/#1396080_detail," name = _(""Subnet Details"")"," name = _(""Subnet Detail"")",14,14
openstack%2Fneutron-specs~master~I78cfde4989fe7e5ce6dadbb87d13dc2db984c523,openstack/neutron-specs,master,I78cfde4989fe7e5ce6dadbb87d13dc2db984c523,Spec for the brocade lbaas driver based on v1 lbaas data model,ABANDONED,2014-11-13 04:15:49.000000000,2014-12-12 03:37:51.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7590}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-11-13 04:15:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/26d68c41e54edf7f43959300cfc3d0538f17a374', 'message': 'Spec for the brocade lbaas driver based on v1 lbaas data model\n\nChange-Id: I78cfde4989fe7e5ce6dadbb87d13dc2db984c523\n'}, {'number': 2, 'created': '2014-11-13 05:05:11.000000000', 'files': ['specs/kilo/brocade-lbaas-v1-driver.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/d2470964a63c9b047a02987e9cd888ee2dd706e1', 'message': 'Spec for the brocade lbaas driver based on v1 lbaas data model\n\nChange-Id: I78cfde4989fe7e5ce6dadbb87d13dc2db984c523\n'}]",0,134110,d2470964a63c9b047a02987e9cd888ee2dd706e1,10,4,2,7590,,,0,"Spec for the brocade lbaas driver based on v1 lbaas data model

Change-Id: I78cfde4989fe7e5ce6dadbb87d13dc2db984c523
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/10/134110/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/brocade-lbaas-v1-driver.rst'],1,26d68c41e54edf7f43959300cfc3d0538f17a374,bp/neutron-brocade-lbaas-driver,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================================= Brocade LBaaS Plugin Driver (Support for v1 Data Model) ======================================================= Problem description =================== URL of the launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/neutron-brocade-lbaas-driver Brocade LBaaS Plugin and Driver for the Brocade ADX Load Balancer Devices for the LBaaS in Neutron. Proposed change =============== The Brocade ADX loadbalancer integration in Neutron LBaaS implements the LBaaS driver CRUD APIs defined in the IceHouse/Juno release. It implements all the defined operations on VIPs, Pools, Pool Members and Health Monitors. The integration consists of a plugin driver class configured in the Neutron configuration file (neutron.conf), and the accompanying unit tests. Implementation comprise of Plugin Driver and Brocade Device Driver. Brocade LBaaS Plugin Driver extends/implements the framework abstract plugin driver and forwards the requests to the Device Driver. A simple file based device inventory component supports the Brocade hardware and virtual load balancer devices. The Plugin Driver forwards the request to the Brocade Device Driver. The device driver communicates with the Brocade ADX Load Balancer Device via SOAP/XML APIs. The device driver use SUDs python module for the SOAP/XML API calls. Supported Features Protocols: HTTPS, HTTP, TCP LB Algorithms: ROUND_ROBIN, LEAST_CONNECTIONS Session persistence: SOURCE_IP Health Monitoring: TCP, HTTP, HTTPS Stats retrieval CRUD on Pool, Member, Health Monitor, Vip Associate/Disassociate Monitors to/from Pool Product Versions supported ADX 12.5 and above Virtual ADX 3.0, 3.1 and above Exceptions Brocade LBaaS Device Driver will raise one of the following exceptions ConfigError . Raised when a configuration exception occurs on the load balancer device UnsupportedFeature . Raised when a particular feature is not yet supported by the Device Driver (For example, Session Persistence for APP_COOKIE/HTTP_COOKIE) UnsupportedOption . Raised when an unsupported value is specified for an attribute. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- service_provider entry in the neutron.conf file needs to be updated to reflect Brocade as one of the service_provider for the plugin to be effective. Otherwise, HAProxy will be the default LBaaS Service Provider. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- https://launchpad.net/~pattabi Work Items ---------- Plugin Driver Implementation - Implement the Abstract Device Driver APIs Dependencies ============ Driver likely affected by LBaaS model and TLS changes for Kilo: * https://blueprints.launchpad.net/neutron/+spec/lbaas-api-and-objmodel-improvement * https://blueprints.launchpad.net/neutron/+spec/lbaas-ssl-termination Testing ======= - Unit Tests - Brocade QA - Existing LBaaS tests provide complete coverage, if driver is installed and configured (as our CI will do.) Documentation Impact ==================== None References ========== None ",,166,0
openstack%2Foctavia~master~I0d91934db47a6e45f0c9ac22089f8689957bd239,openstack/octavia,master,I0d91934db47a6e45f0c9ac22089f8689957bd239,Implementing simple operator API,MERGED,2014-09-12 20:52:50.000000000,2014-12-12 03:12:02.000000000,2014-12-12 03:12:02.000000000,"[{'_account_id': 3}, {'_account_id': 6287}, {'_account_id': 6951}, {'_account_id': 7010}, {'_account_id': 10806}, {'_account_id': 10850}, {'_account_id': 10980}, {'_account_id': 11685}]","[{'number': 1, 'created': '2014-09-12 20:52:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a868cd7422585ab204ce849e5075bc84752f566c', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that defin the API resources\nDefined the wsme types that define the resource response and request bodies\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 2, 'created': '2014-09-28 07:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/23470d09609ae3dad2b53c245943d5c89157fdfa', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 3, 'created': '2014-10-08 03:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/10ac57e1afd2f4b94d791f593a295bbd1f4fc852', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 4, 'created': '2014-10-08 17:01:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8e948ab3403bf970757a7713ab99e0f817d00a8a', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 5, 'created': '2014-10-10 21:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/57162425f7683381a0c3c33986c6f96e2c92465c', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 6, 'created': '2014-10-13 21:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/3c3d12f45e9dbfac81b98add06083c4c0381a77e', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 7, 'created': '2014-10-14 06:11:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/77529df70bee0cb326de6c0a63bcf11534eca065', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 8, 'created': '2014-10-14 19:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/481970cf2ed2bf9469953b20a06ecb77ddff1a7a', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 9, 'created': '2014-10-14 21:11:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/afd0d24a1f85192fff72b9b9091af3b9dc20970a', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 10, 'created': '2014-10-14 23:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/b75a6eeb2be9fca03d9d140ef88370f83ed52632', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 11, 'created': '2014-10-14 23:46:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/428ae8f720926a43e63ddf1bb3d545c68d10a16d', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 12, 'created': '2014-10-15 15:58:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/75475f106e8dc456939ae9dac4497b82b84c33cf', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 13, 'created': '2014-10-15 21:44:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f1ac72d1b43dbb74af41bec572531fd3a4ea2f83', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 14, 'created': '2014-10-15 23:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7962d794ebdfa3837dea0aed95766bcd38d3c7f2', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 15, 'created': '2014-11-10 05:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/701e9e9f04e3a52e295a6082f09d8ed19a3361df', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 16, 'created': '2014-11-11 23:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/7753ffb8b0dc28db7a580c3ca055c20317896f35', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 17, 'created': '2014-11-12 06:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a84f01d0b2a4e225c62e711e7f77cfb3a5e8da6e', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 18, 'created': '2014-11-12 23:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6efc7766d328aa43c0f5dbee44ec9666c33b7d05', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 19, 'created': '2014-11-12 23:52:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/8fb56d8b3403a4f9f1551753d9816d457bfcfb2e', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 20, 'created': '2014-11-13 04:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a985c527002ae44a956da0e5c44ed00a43659743', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 21, 'created': '2014-11-19 20:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/ea5229de6a9516522a70cfb91e97b743d9bced41', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 22, 'created': '2014-11-25 18:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/28e340e9a5e0f37d70eea8dde5dede10f9f8dc54', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 23, 'created': '2014-12-11 22:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/69c9021c7b2ded010e852577d67e004c79d4e655', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}, {'number': 24, 'created': '2014-12-12 02:22:19.000000000', 'files': ['octavia/db/base_models.py', 'octavia/tests/unit/api/v1/types/test_listeners.py', 'octavia/api/v1/handlers/abstract_handler.py', 'octavia/tests/functional/api/v1/base.py', 'bin/octavia-api.py', 'octavia/tests/functional/api/v1/test_listener.py', 'octavia/api/config.py', 'octavia/api/__init__.py', 'etc/octavia.conf', 'octavia/api/v1/controllers/listener.py', 'octavia/api/v1/types/load_balancer.py', 'octavia/tests/unit/api/v1/types/__init__.py', 'octavia/common/constants.py', 'octavia/api/app.py', 'octavia/tests/functional/db/test_models.py', 'octavia/api/v1/handlers/__init__.py', 'octavia/api/v1/types/base.py', 'octavia/tests/unit/api/v1/types/test_load_balancers.py', 'octavia/common/exceptions.py', 'octavia/api/v1/controllers/base.py', 'octavia/tests/unit/api/__init__.py', 'octavia/api/v1/types/__init__.py', 'octavia/tests/functional/api/v1/test_health_monitor.py', 'octavia/db/models.py', 'octavia/api/v1/types/pool.py', 'octavia/db/migration/alembic_migrations/versions/35dee79d5865_initial_create.py', 'octavia/tests/unit/api/v1/types/test_health_monitors.py', 'octavia/tests/unit/common/test_exceptions.py', 'octavia/common/service.py', 'octavia/tests/functional/db/test_repositories.py', 'octavia/common/data_models.py', 'octavia/tests/functional/api/__init__.py', 'octavia/api/v1/controllers/health_monitor.py', 'octavia/api/v1/__init__.py', 'octavia/api/v1/controllers/__init__.py', 'octavia/db/migration/alembic_migrations/versions/4faaa983e7a9_update_member_address_column.py', 'octavia/tests/unit/api/v1/types/test_pools.py', 'octavia/api/v1/types/health_monitor.py', 'octavia/common/context.py', 'octavia/api/v1/controllers/member.py', 'octavia/tests/functional/api/v1/test_load_balancer.py', 'bin/__init__.py', 'octavia/api/v1/handlers/controller_simulator/__init__.py', 'octavia/api/v1/controllers/load_balancer.py', 'requirements.txt', 'octavia/db/api.py', 'octavia/db/repositories.py', 'octavia/api/v1/types/listener.py', 'octavia/api/v1/controllers/pool.py', 'octavia/api/v1/handlers/controller_simulator/handler.py', 'octavia/tests/functional/api/v1/test_member.py', 'octavia/api/v1/types/member.py', 'octavia/tests/functional/db/__init__.py', 'octavia/tests/unit/api/v1/types/base.py', 'octavia/tests/functional/__init__.py', 'octavia/tests/functional/api/v1/test_pool.py', 'octavia/tests/unit/api/v1/types/test_members.py', 'octavia/tests/functional/db/base.py', 'octavia/api/root_controller.py', 'octavia/tests/unit/api/v1/__init__.py', 'octavia/api/v1/hooks.py', 'octavia/tests/functional/api/v1/__init__.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/9786021205546e2a08ab54f4ddffd87017fba65d', 'message': 'Implementing simple operator API\n\nSetup executable to use wsgiref.simple_server\nSimple setup of pecan\nDefined controllers that define the API resources\nImplemented all controllers to manipulate database and send to handler\nAdded repository methods required for creating multiple items in one transaction\nDefined a few API exceptions based of wsme exceptions\nDefined the wsme types that define the resource response and request bodies\nDefined an abstract handler that all handlers should subclass\nDefined a simple handler that is responsible for sending to controller\nAdded some wsme type tests\n\nImplements: bp/operator-api\n\nChange-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239\n'}]",19,121233,9786021205546e2a08ab54f4ddffd87017fba65d,98,8,24,6951,,,0,"Implementing simple operator API

Setup executable to use wsgiref.simple_server
Simple setup of pecan
Defined controllers that define the API resources
Implemented all controllers to manipulate database and send to handler
Added repository methods required for creating multiple items in one transaction
Defined a few API exceptions based of wsme exceptions
Defined the wsme types that define the resource response and request bodies
Defined an abstract handler that all handlers should subclass
Defined a simple handler that is responsible for sending to controller
Added some wsme type tests

Implements: bp/operator-api

Change-Id: I0d91934db47a6e45f0c9ac22089f8689957bd239
",git fetch https://review.opendev.org/openstack/octavia refs/changes/33/121233/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/api/v1/controllers/v1.py', 'octavia/api/v1/controllers/member.py', 'bin/__init__.py', 'bin/octavia-api.py', 'octavia/api/config.py', 'octavia/api/__init__.py', 'etc/octavia.conf', 'octavia/api/v1/controllers/listener.py', 'octavia/api/v1/controllers/load_balancer.py', 'octavia/tests/unit/api/v1/types/__init__.py', 'requirements.txt', 'octavia/api/app.py', 'octavia/api/v1/types/base.py', 'octavia/api/v1/controllers/pool.py', 'octavia/tests/unit/db/test_models.py', 'octavia/api/v1/controllers/base.py', 'octavia/tests/unit/api/__init__.py', 'octavia/api/v1/types/__init__.py', 'octavia/tests/unit/api/v1/test_controllers.py', 'octavia/tests/unit/api/v1/types/base.py', 'octavia/tests/unit/api/v1/types/test_types.py', 'octavia/common/data_models.py', 'octavia/api/v1/controllers/health_monitor.py', 'octavia/api/root_controller.py', 'octavia/api/v1/__init__.py', 'octavia/api/v1/controllers/__init__.py', 'octavia/tests/unit/api/v1/__init__.py']",27,a868cd7422585ab204ce849e5075bc84752f566c,bp/operator-api, ,,813,3
openstack%2Fneutron~master~Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e,openstack/neutron,master,Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e,Fix for KeyError: 'gw_port_host' on l3_agent,MERGED,2014-12-02 22:32:19.000000000,2014-12-12 02:35:22.000000000,2014-12-12 02:35:20.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7016}, {'_account_id': 7787}, {'_account_id': 7962}, {'_account_id': 8253}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9846}, {'_account_id': 9925}, {'_account_id': 10116}, {'_account_id': 10117}, {'_account_id': 10119}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10294}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 10971}, {'_account_id': 12040}, {'_account_id': 13051}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14214}]","[{'number': 1, 'created': '2014-12-02 22:32:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2487ca8e444cc74756b33d3717ebd7e32ab011fe', 'message': ""Fix for KeyError: 'gw_port_host' on l3_agent\n\nThe dictionary field 'gw_port_host' was added for\nDVR routers and is used by the scheduler and l3_agent\nto schedule where the SNAT port for a DVR router\nwill be hosted.  In some code flows on the l3_agent,\nthis field is checked to determine what the agent\nshould do if the host matches its own or not.\n\nRecently it has been seen that the router data sent\nfrom the scheduler is missing this field in some cases.\nThis causes the agent to throw a KeyError and not function\nproperly.  This patch will make the l3_agent more robust\nand less fragile by calling 'get' instead of assuming the\nfield will be there.\n\nMore work may be needed on the scheduler side to see why\nthis field is missing. That is why I am marking this as a\npartial-fix for now. But this patch will make the l3_agent\nless prone to errors and therefore an improvement.\n\nChange-Id: Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e\nPartial-Bug: #1394043\n""}, {'number': 2, 'created': '2014-12-09 21:53:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e2ac82226558460ffbb6ca7d157f556fbe37e2d8', 'message': ""Fix for KeyError: 'gw_port_host' on l3_agent\n\nThe dictionary field 'gw_port_host' was added for\nDVR routers and is used by the scheduler and l3_agent\nto schedule where the SNAT port for a DVR router\nwill be hosted.  In some code flows on the l3_agent,\nthis field is checked to determine what the agent\nshould do if the host matches its own or not.\n\nRecently it has been seen that the router data sent\nfrom the scheduler is missing this field in some cases.\nThis causes the agent to throw a KeyError and not function\nproperly.  This patch will make the l3_agent more robust\nand less fragile by calling 'get' instead of assuming the\nfield will be there.\n\nMore work may be needed on the scheduler side to see why\nthis field is missing. That is why I am marking this as a\npartial-fix for now. But this patch will make the l3_agent\nless prone to errors and therefore an improvement.\n\nChange-Id: Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e\nPartial-Bug: #1394043\n""}, {'number': 3, 'created': '2014-12-11 21:28:42.000000000', 'files': ['neutron/agent/l3/agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/5908a60ab98886a807044da56f51bceafd15edc9', 'message': ""Fix for KeyError: 'gw_port_host' on l3_agent\n\nThe dictionary field 'gw_port_host' was added for\nDVR routers and is used by the scheduler and l3_agent\nto schedule where the SNAT port for a DVR router\nwill be hosted.  In some code flows on the l3_agent,\nthis field is checked to determine what the agent\nshould do if the host matches its own or not.\n\nRecently it has been seen that the router data sent\nfrom the scheduler is missing this field in some cases.\nThis causes the agent to throw a KeyError and not function\nproperly.  This patch will make the l3_agent more robust\nand less fragile by calling 'get' instead of assuming the\nfield will be there.\n\nMore work may be needed on the scheduler side to see why\nthis field is missing. That is why I am marking this as a\npartial-fix for now. But this patch will make the l3_agent\nless prone to errors and therefore an improvement.\n\nChange-Id: Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e\nPartial-Bug: #1394043\n""}]",0,138562,5908a60ab98886a807044da56f51bceafd15edc9,73,29,3,10971,,,0,"Fix for KeyError: 'gw_port_host' on l3_agent

The dictionary field 'gw_port_host' was added for
DVR routers and is used by the scheduler and l3_agent
to schedule where the SNAT port for a DVR router
will be hosted.  In some code flows on the l3_agent,
this field is checked to determine what the agent
should do if the host matches its own or not.

Recently it has been seen that the router data sent
from the scheduler is missing this field in some cases.
This causes the agent to throw a KeyError and not function
properly.  This patch will make the l3_agent more robust
and less fragile by calling 'get' instead of assuming the
field will be there.

More work may be needed on the scheduler side to see why
this field is missing. That is why I am marking this as a
partial-fix for now. But this patch will make the l3_agent
less prone to errors and therefore an improvement.

Change-Id: Ib26ccfa7b945cb4e8f2ec4adc5e6ae91cbaae02e
Partial-Bug: #1394043
",git fetch https://review.opendev.org/openstack/neutron refs/changes/62/138562/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/l3_agent.py'],1,2487ca8e444cc74756b33d3717ebd7e32ab011fe,gw_key_err, ex_gw_port and ri.router.get('gw_port_host') == self.host): ri.router.get('gw_port_host') == self.host): ri.router.get('gw_port_host') == self.host): ri.router.get('gw_port_host') == self.host): ri.router.get('gw_port_host') == self.host):, ex_gw_port and ri.router['gw_port_host'] == self.host): ri.router['gw_port_host'] == self.host): ri.router['gw_port_host'] == self.host): ri.router['gw_port_host'] == self.host): ri.router['gw_port_host'] == self.host):,5,5
openstack%2Fnova~master~I6bc4e46aa5a72645c72f7232627c7aa9efd2591d,openstack/nova,master,I6bc4e46aa5a72645c72f7232627c7aa9efd2591d,downgrade 'No network configured!' to debug log level,MERGED,2014-12-05 19:06:40.000000000,2014-12-12 02:33:41.000000000,2014-12-12 02:33:38.000000000,"[{'_account_id': 3}, {'_account_id': 1653}, {'_account_id': 1849}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9550}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13909}]","[{'number': 1, 'created': '2014-12-05 19:06:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7a3082c05e6cba28cf8a55c210bb230c9492ec3', 'message': ""See what is triggering 'No network configured'\n\nA warning message saying 'No network configured' pops up frequently in\ntesting, see what is throwing this to figure out of this is a real bug\nor should really be a debug message.\n\nBased on the details in bug 1191044, it looks like a user can cause this\nwarning if they boot an instance in a tenant that has no neutron\nnetworks set up.\n\nChange-Id: I6bc4e46aa5a72645c72f7232627c7aa9efd2591d\nRelated-Bug: #1191044\n""}, {'number': 2, 'created': '2014-12-06 00:04:33.000000000', 'files': ['nova/network/neutronv2/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4c49db4c9c550271c026742e3f09bb967d0627bd', 'message': ""downgrade 'No network configured!' to debug log level\n\nBased on the details in bug 1191044, a user can cause the warning\n'No network configured!' if they boot an instance in a tenant that\nhas no neutron networks set up.\n\nTempest doesn't create a network for every test that creates a nova\ninstance. The lack of a network is not a sign of something wrong with\nnova so a warning log is too much. Move to debug instead.\n\nThis should help reduce the amount of warnings that occur on every\ntempest run.\n\nAlso drop the exclamation mark.\n\nChange-Id: I6bc4e46aa5a72645c72f7232627c7aa9efd2591d\nRelated-Bug: #1191044\n""}]",0,139712,4c49db4c9c550271c026742e3f09bb967d0627bd,29,13,2,1849,,,0,"downgrade 'No network configured!' to debug log level

Based on the details in bug 1191044, a user can cause the warning
'No network configured!' if they boot an instance in a tenant that
has no neutron networks set up.

Tempest doesn't create a network for every test that creates a nova
instance. The lack of a network is not a sign of something wrong with
nova so a warning log is too much. Move to debug instead.

This should help reduce the amount of warnings that occur on every
tempest run.

Also drop the exclamation mark.

Change-Id: I6bc4e46aa5a72645c72f7232627c7aa9efd2591d
Related-Bug: #1191044
",git fetch https://review.opendev.org/openstack/nova refs/changes/12/139712/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/neutronv2/api.py'],1,d7a3082c05e6cba28cf8a55c210bb230c9492ec3,bug/1191044," LOG.warning(_LW(""No network configured!""), instance=instance, exc_info=True)"," LOG.warning(_LW(""No network configured!""), instance=instance)",1,1
openstack%2Fheat~master~Id1a7bf2a353cb1f255ab335ab8c39edbeb4dc292,openstack/heat,master,Id1a7bf2a353cb1f255ab335ab8c39edbeb4dc292,Allow VolumeAttachments to delete in parallel,MERGED,2014-12-11 19:35:49.000000000,2014-12-12 02:29:46.000000000,2014-12-12 02:29:45.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 9542}]","[{'number': 1, 'created': '2014-12-11 19:35:49.000000000', 'files': ['heat/engine/resources/volume.py', 'heat/tests/test_volume.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/023ce006a0a11084fe4d05d779efced40f97fa70', 'message': 'Allow VolumeAttachments to delete in parallel\n\nDeleting a VolumeAttachment was still blocking; this change allows other\nresources to be processed while we are waiting for the volume to be\ndetached.\n\nChange-Id: Id1a7bf2a353cb1f255ab335ab8c39edbeb4dc292\n'}]",0,141139,023ce006a0a11084fe4d05d779efced40f97fa70,8,3,1,4257,,,0,"Allow VolumeAttachments to delete in parallel

Deleting a VolumeAttachment was still blocking; this change allows other
resources to be processed while we are waiting for the volume to be
detached.

Change-Id: Id1a7bf2a353cb1f255ab335ab8c39edbeb4dc292
",git fetch https://review.opendev.org/openstack/heat refs/changes/39/141139/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/volume.py', 'heat/tests/test_volume.py']",2,023ce006a0a11084fe4d05d779efced40f97fa70,," self.m.StubOutWithMock(vol.VolumeAttachment, 'check_delete_complete') cookie = object() vol.VolumeAttachment.handle_delete().AndReturn(cookie) vol.VolumeAttachment.check_delete_complete(cookie).AndReturn(True)", vol.VolumeAttachment.handle_delete().AndReturn(None),10,2
openstack%2Fheat~master~Ic20b4b0c1d66c088cb023585323404fe16b00097,openstack/heat,master,Ic20b4b0c1d66c088cb023585323404fe16b00097,Always use fakes_v1_1 for heat.tests.v1_1 fakes import,MERGED,2014-12-05 14:51:55.000000000,2014-12-12 02:29:37.000000000,2014-12-12 02:29:36.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4715}, {'_account_id': 8871}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-05 14:51:55.000000000', 'files': ['heat/tests/test_eip.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_security_group.py', 'heat/tests/test_volume.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_clients.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/tests/test_nova_floatingip.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_nova_servergroup.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_instance_group_update_policy.py', 'heat/tests/test_nokey.py', 'heat/tests/test_nova_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/9811a3a3d3a15800ef067372c1dc0a8c57de8148', 'message': ""Always use fakes_v1_1 for heat.tests.v1_1 fakes import\n\nIn some places there is import fakes from heat.tests.v1_1\nas fakes_v1_1 and it's necessary because of importing\nheat.tests.fakes. This patch makes all tests use 'fakes_v1_1'\nfor this import.\n\nChange-Id: Ic20b4b0c1d66c088cb023585323404fe16b00097\n""}]",0,139647,9811a3a3d3a15800ef067372c1dc0a8c57de8148,12,5,1,13009,,,0,"Always use fakes_v1_1 for heat.tests.v1_1 fakes import

In some places there is import fakes from heat.tests.v1_1
as fakes_v1_1 and it's necessary because of importing
heat.tests.fakes. This patch makes all tests use 'fakes_v1_1'
for this import.

Change-Id: Ic20b4b0c1d66c088cb023585323404fe16b00097
",git fetch https://review.opendev.org/openstack/heat refs/changes/47/139647/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/test_eip.py', 'heat/tests/test_instance.py', 'heat/tests/test_neutron_autoscaling.py', 'heat/tests/test_security_group.py', 'heat/tests/test_volume.py', 'heat/tests/test_neutron_security_group.py', 'heat/tests/test_clients.py', 'heat/tests/test_neutron_loadbalancer.py', 'heat/tests/test_nova_floatingip.py', 'heat/tests/test_loadbalancer.py', 'heat/tests/test_nova_keypair.py', 'heat/tests/test_engine_service.py', 'heat/tests/test_validate.py', 'heat/tests/test_nova_servergroup.py', 'heat/tests/test_server_tags.py', 'heat/tests/test_instance_network.py', 'heat/tests/test_sqlalchemy_api.py', 'heat/tests/test_instance_group_update_policy.py', 'heat/tests/test_nokey.py', 'heat/tests/test_nova_utils.py']",20,9811a3a3d3a15800ef067372c1dc0a8c57de8148,fakes_v1_1,from heat.tests.v1_1 import fakes as fakes_v1_1 'notakey').AndRaise(fakes_v1_1.fake_exception()) server.get.side_effect = fakes_v1_1.fake_exception(413) server.get().AndRaise(fakes_v1_1.fake_exception(500)) server.get().AndRaise(fakes_v1_1.fake_exception(503)) server.get().AndRaise(fakes_v1_1.fake_exception(501)),from heat.tests.v1_1 import fakes 'notakey').AndRaise(fakes.fake_exception()) server.get.side_effect = fakes.fake_exception(413) server.get().AndRaise(fakes.fake_exception(500)) server.get().AndRaise(fakes.fake_exception(503)) server.get().AndRaise(fakes.fake_exception(501)),80,80
openstack%2Fheat~master~I788c181ce55f076243f9bbdf791289a5f45c3758,openstack/heat,master,I788c181ce55f076243f9bbdf791289a5f45c3758,Unit test for resource attribute SHOW fix,MERGED,2014-12-09 01:34:51.000000000,2014-12-12 02:29:27.000000000,2014-12-12 02:29:26.000000000,"[{'_account_id': 3}, {'_account_id': 4571}, {'_account_id': 4715}, {'_account_id': 7256}, {'_account_id': 7634}, {'_account_id': 8289}, {'_account_id': 9189}, {'_account_id': 9542}, {'_account_id': 13009}]","[{'number': 1, 'created': '2014-12-09 01:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/c0f73e75575f5080d5d5527c19265e1739077401', 'message': 'Check SHOW attr has info when formatting resource\n\nIf the SHOW attribute of a given resource cannot be resolved, fall back\nto displaying all attributes instead to prevent it from breaking.\n\nCloses-Bug: #1400557\nChange-Id: I788c181ce55f076243f9bbdf791289a5f45c3758\n'}, {'number': 2, 'created': '2014-12-11 17:16:46.000000000', 'files': ['heat/tests/test_engine_api_utils.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ffd97b013c4af550ee9ded7a88f3b122fdb32236', 'message': ""Unit test for resource attribute SHOW fix\n\nThe change https://review.openstack.org/#/c/140766 was merged before a\nprevious version of this patch (for bug 1400557), but didn't have any\nunit tests.  I've removed the fix but left the unit test here.\n\nCloses-Bug: #1401107\nChange-Id: I788c181ce55f076243f9bbdf791289a5f45c3758\n""}]",0,140199,ffd97b013c4af550ee9ded7a88f3b122fdb32236,19,9,2,9189,,,0,"Unit test for resource attribute SHOW fix

The change https://review.openstack.org/#/c/140766 was merged before a
previous version of this patch (for bug 1400557), but didn't have any
unit tests.  I've removed the fix but left the unit test here.

Closes-Bug: #1401107
Change-Id: I788c181ce55f076243f9bbdf791289a5f45c3758
",git fetch https://review.opendev.org/openstack/heat refs/changes/99/140199/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/api.py', 'heat/tests/test_engine_api_utils.py']",2,c0f73e75575f5080d5d5527c19265e1739077401,bug/1401107," def test_format_resource_attributes_show_attribute_fail(self): res = mock.Mock() res.attributes = {'a': 'a_value', 'show': ''} formatted_attributes = api.format_resource_attributes(res) self.assertIn('a', formatted_attributes) self.assertIn('show', formatted_attributes) ",,9,1
openstack%2Fneutron-lbaas~master~I3545271204aac08e552e7ba760ef5e3be6fbed41,openstack/neutron-lbaas,master,I3545271204aac08e552e7ba760ef5e3be6fbed41,Add neutron import unit test,ABANDONED,2014-12-10 05:24:34.000000000,2014-12-12 02:20:15.000000000,,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 05:24:34.000000000', 'files': ['neutron_lbaas/tests/unit/test_true.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ef86520f4de3d6671fd9cc58c091a876468f9b52', 'message': 'Add neutron import unit test\n\nChange-Id: I3545271204aac08e552e7ba760ef5e3be6fbed41\n'}]",0,140574,ef86520f4de3d6671fd9cc58c091a876468f9b52,5,3,1,10980,,,0,"Add neutron import unit test

Change-Id: I3545271204aac08e552e7ba760ef5e3be6fbed41
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/74/140574/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas/tests/unit/test_true.py'],1,ef86520f4de3d6671fd9cc58c091a876468f9b52,,import neutron def test_import_neutron(self): self.assertTrue(neutron.__file__),,4,0
openstack%2Fneutron-lbaas~master~I7e1714c3df80e1780877a1545f9bd60087a857c0,openstack/neutron-lbaas,master,I7e1714c3df80e1780877a1545f9bd60087a857c0,Merge branch 'feature/lbaasv2',ABANDONED,2014-12-10 15:48:19.000000000,2014-12-12 02:19:42.000000000,,"[{'_account_id': 3}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 15:48:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/11c44d7d21a05b524191e0144a2e0973a94572a2', 'message': ""Merge branch 'feature/lbaasv2'\n\nChange-Id: I7e1714c3df80e1780877a1545f9bd60087a857c0\n""}, {'number': 2, 'created': '2014-12-10 22:05:39.000000000', 'files': ['neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/constants.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', '.gitreview', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron/services/loadbalancer/drivers/driver_mixins.py', 'neutron_lbaas/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/services/loadbalancer/plugin.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_base.py', 'neutron_lbaas/services/loadbalancer/constants.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py', 'neutron/services/loadbalancer/drivers/logging_noop/driver.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/6e75bfffe7ab3670b184cdada12df4385ae415f9', 'message': ""Merge branch 'feature/lbaasv2'\n\nChange-Id: I7e1714c3df80e1780877a1545f9bd60087a857c0\n""}]",0,140742,6e75bfffe7ab3670b184cdada12df4385ae415f9,6,2,2,10980,,,0,"Merge branch 'feature/lbaasv2'

Change-Id: I7e1714c3df80e1780877a1545f9bd60087a857c0
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/42/140742/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/services/loadbalancer/drivers/driver_base.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron/services/loadbalancer/constants.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', '.gitreview', 'neutron/tests/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron/services/loadbalancer/drivers/driver_mixins.py', 'neutron_lbaas/services/loadbalancer/drivers/logging_noop/driver.py', 'neutron/tests/unit/services/loadbalancer/test_loadbalancer_quota_ext.py', 'neutron/services/loadbalancer/plugin.py', 'neutron_lbaas/services/loadbalancer/plugin.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/test_loadbalancer_plugin.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_base.py', 'neutron_lbaas/services/loadbalancer/constants.py', 'neutron_lbaas/tests.skip/unit/services/loadbalancer/drivers/logging_noop/test_logging_noop_driver.py', 'neutron_lbaas/services/loadbalancer/drivers/driver_mixins.py', 'neutron/services/loadbalancer/drivers/logging_noop/driver.py']",17,11c44d7d21a05b524191e0144a2e0973a94572a2,bp/lbaas-api-and-objmodel-improvement,,"<<<<<<< HEAD (221f29 Post-split, get jenkins tests passing) ======= # Copyright 2014, Doug Wiegley (dougwig), A10 Networks # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from neutron.openstack.common import log as logging from neutron.services.loadbalancer.drivers import driver_base LOG = logging.getLogger(__name__) class LoggingNoopLoadBalancerDriver(driver_base.LoadBalancerBaseDriver): def __init__(self, plugin): self.plugin = plugin # Each of the major LBaaS objects in the neutron database # need a corresponding manager/handler class. # # Put common things that are shared across the entire driver, like # config or a rest client handle, here. # # This function is executed when neutron-server starts. self.load_balancer = LoggingNoopLoadBalancerManager(self) self.listener = LoggingNoopListenerManager(self) self.pool = LoggingNoopPoolManager(self) self.member = LoggingNoopMemberManager(self) self.health_monitor = LoggingNoopHealthMonitorManager(self) class LoggingNoopCommonManager(object): def create(self, context, obj): LOG.debug(""LB %s no-op, create %s"", self.__class__.__name__, obj.id) def update(self, context, old_obj, obj): LOG.debug(""LB %s no-op, update %s"", self.__class__.__name__, obj.id) def delete(self, context, obj): LOG.debug(""LB %s no-op, delete %s"", self.__class__.__name__, obj.id) class LoggingNoopLoadBalancerManager(LoggingNoopCommonManager, driver_base.BaseLoadBalancerManager): def refresh(self, context, lb_obj, force=False): # This is intended to trigger the backend to check and repair # the state of this load balancer and all of its dependent objects LOG.debug(""LB pool refresh %s, force=%s"", lb_obj.id, force) def stats(self, context, lb_obj): LOG.debug(""LB stats %s"", lb_obj.id) return { ""bytes_in"": 0, ""bytes_out"": 0, ""active_connections"": 0, ""total_connections"": 0 } def create(self, context, loadbalancer): super(LoggingNoopLoadBalancerManager, self).create(context, loadbalancer) self.driver.activate_cascade(context, loadbalancer) def update(self, context, old_loadbalancer, loadbalancer): super(LoggingNoopLoadBalancerManager, self).update(context, old_loadbalancer, loadbalancer) self.driver.activate_cascade(context, loadbalancer) def delete(self, context, loadbalancer): super(LoggingNoopLoadBalancerManager, self).delete(context, loadbalancer) self.db_delete(context, loadbalancer.id) class LoggingNoopListenerManager(LoggingNoopCommonManager, driver_base.BaseListenerManager): def create(self, context, obj): super(LoggingNoopListenerManager, self).create(context, obj) self.driver.activate_cascade(context, obj) def update(self, context, old_listener, new_listener): super(LoggingNoopListenerManager, self).update(context, old_listener, new_listener) if new_listener.attached_to_loadbalancer(): # Always activate listener and its children if attached to # loadbalancer self.driver.activate_cascade(context, new_listener) elif old_listener.attached_to_loadbalancer(): # If listener has just been detached from loadbalancer # defer listener and its children self.defer_cascade(context, new_listener) if not new_listener.default_pool and old_listener.default_pool: # if listener's pool has been detached then defer the pool # and its children self.driver.pool.defer_cascade(context, old_listener.default_pool) def delete(self, context, listener): super(LoggingNoopListenerManager, self).delete(context, listener) if listener.default_pool: self.driver.pool.defer_cascade(context, listener.default_pool) self.db_delete(context, listener.id) class LoggingNoopPoolManager(LoggingNoopCommonManager, driver_base.BasePoolManager): def create(self, context, pool): super(LoggingNoopPoolManager, self).create(context, pool) # This shouldn't be called since a pool cannot be created and linked # to a loadbalancer at the same time self.driver.activate_cascade(context, pool) def update(self, context, old_pool, pool): super(LoggingNoopPoolManager, self).update(context, old_pool, pool) self.driver.activate_cascade(context, pool) if not pool.healthmonitor and old_pool.healthmonitor: self.driver.health_monitor.defer(context, old_pool.healthmonitor.id) def delete(self, context, pool): super(LoggingNoopPoolManager, self).delete(context, pool) if pool.healthmonitor: self.driver.health_monitor.defer(context, pool.healthmonitor.id) self.db_delete(context, pool.id) class LoggingNoopMemberManager(LoggingNoopCommonManager, driver_base.BaseMemberManager): def create(self, context, member): super(LoggingNoopMemberManager, self).create(context, member) self.driver.activate_cascade(context, member) def update(self, context, old_member, member): super(LoggingNoopMemberManager, self).update(context, old_member, member) self.driver.activate_cascade(context, member) def delete(self, context, member): super(LoggingNoopMemberManager, self).delete(context, member) self.db_delete(context, member.id) class LoggingNoopHealthMonitorManager(LoggingNoopCommonManager, driver_base.BaseHealthMonitorManager): def create(self, context, healthmonitor): super(LoggingNoopHealthMonitorManager, self).create(context, healthmonitor) self.driver.activate_cascade(context, healthmonitor) def update(self, context, old_healthmonitor, healthmonitor): super(LoggingNoopHealthMonitorManager, self).update(context, old_healthmonitor, healthmonitor) self.driver.activate_cascade(context, healthmonitor) def delete(self, context, healthmonitor): super(LoggingNoopHealthMonitorManager, self).delete(context, healthmonitor) self.db_delete(context, healthmonitor.id) >>>>>>> BRANCH (45eb37 Implement Jinja templates for haproxy config) ",1304,2752
openstack%2Fkeystonemiddleware~master~Ib1c772e55f7c7b622d0c2a55d87d77d2dc30d4bb,openstack/keystonemiddleware,master,Ib1c772e55f7c7b622d0c2a55d87d77d2dc30d4bb,Use new ksc features in User Token Plugin,MERGED,2014-10-27 08:35:07.000000000,2014-12-12 02:11:12.000000000,2014-12-12 02:11:11.000000000,"[{'_account_id': 3}, {'_account_id': 1916}, {'_account_id': 6486}, {'_account_id': 7191}, {'_account_id': 8978}, {'_account_id': 13055}]","[{'number': 1, 'created': '2014-10-27 08:35:07.000000000', 'files': ['keystonemiddleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/keystonemiddleware/commit/c4335169fd823e54a7c3ef11ab862ed0240e8b58', 'message': ""Use new ksc features in User Token Plugin\n\nWhen the user token plugin was created some problems were noticed.\n\nFirstly the way the auth_ref was being constructed meant that it would\ntry and retrieve the token from the body of the message which wouldn't\nwork for v3 or PKI tokens. To overcome this we stored the token data in\nthe plugin and added the ability to override the token data in the\nauth_ref.\n\nSecondly that there was no way to signal that this plugin couldn't be\nreauthenticated and it would therefore retry unauthenticated requests\nthat we knew wouldn't work.\n\nBoth of these issues were addressed in keystoneclient and they should be\nupdated to work correctly in auth_token middleware.\n\nChange-Id: Ib1c772e55f7c7b622d0c2a55d87d77d2dc30d4bb\n""}]",1,131048,c4335169fd823e54a7c3ef11ab862ed0240e8b58,11,6,1,7191,,,0,"Use new ksc features in User Token Plugin

When the user token plugin was created some problems were noticed.

Firstly the way the auth_ref was being constructed meant that it would
try and retrieve the token from the body of the message which wouldn't
work for v3 or PKI tokens. To overcome this we stored the token data in
the plugin and added the ability to override the token data in the
auth_ref.

Secondly that there was no way to signal that this plugin couldn't be
reauthenticated and it would therefore retry unauthenticated requests
that we knew wouldn't work.

Both of these issues were addressed in keystoneclient and they should be
updated to work correctly in auth_token middleware.

Change-Id: Ib1c772e55f7c7b622d0c2a55d87d77d2dc30d4bb
",git fetch https://review.opendev.org/openstack/keystonemiddleware refs/changes/48/131048/1 && git format-patch -1 --stdout FETCH_HEAD,['keystonemiddleware/auth_token.py'],1,c4335169fd823e54a7c3ef11ab862ed0240e8b58,no-reauth," def __init__(self, auth_ref): super(_UserAuthPlugin, self).__init__(reauthenticate=False) def get_auth_ref(self, session, **kwargs): # NOTE(jamielennox): We will always use the auth_ref that was # calculated by the middleware. reauthenticate=False in __init__ should # ensure that this function is only called on the first access. auth_ref = access.AccessInfo.factory(body=token_info, auth_token=user_token) env['keystone.token_auth'] = _UserAuthPlugin(auth_ref)"," def __init__(self, user_token, auth_ref): # FIXME(jamielennox): set reauthenticate=False here when keystoneclient # 0.11 is released to prevent trying to refetch authentication. super(_UserAuthPlugin, self).__init__() self._user_token = user_token def get_token(self, session, **kwargs): # NOTE(jamielennox): This is needed partially because the AccessInfo # factory is so bad that we don't always get the correct token data. # Override and always return the token that was provided in the req. return self._user_token def get_auth_ref(self, session, **kwargs): # NOTE(jamielennox): We can't go out and fetch this auth_ref, we've # got it already so always return it. In the event it tries to # re-authenticate it will get the same old auth_ref which is not # perfect, but the best we can do for now. auth_ref = access.AccessInfo.factory(body=token_info) env['keystone.token_auth'] = _UserAuthPlugin( user_token, auth_ref)",8,18
openstack%2Fheat~master~I301ab3a321fbcbcc47c2b0e04101fbee783968ce,openstack/heat,master,I301ab3a321fbcbcc47c2b0e04101fbee783968ce,Use Fedora-Cloud-Base-20141203-21.x86_64 for testing,ABANDONED,2014-12-12 01:42:57.000000000,2014-12-12 01:45:41.000000000,,[],"[{'number': 1, 'created': '2014-12-12 01:42:57.000000000', 'files': ['heat_integrationtests/post_test_hook.sh'], 'web_link': 'https://opendev.org/openstack/heat/commit/3cdbf7889db78989a502deb837a688558e8829d5', 'message': 'Use Fedora-Cloud-Base-20141203-21.x86_64 for testing\n\nDevstack has switched to using Fedora-Cloud-Base-20141203-21.x86_64\nso check-heat-dsvm-functional-mysql will be broken until this change\nlands, assuming the tests pass using Fedora-Cloud-Base-20141203-21.x86_64\n\nChange-Id: I301ab3a321fbcbcc47c2b0e04101fbee783968ce\n'}]",0,141240,3cdbf7889db78989a502deb837a688558e8829d5,2,0,1,4571,,,0,"Use Fedora-Cloud-Base-20141203-21.x86_64 for testing

Devstack has switched to using Fedora-Cloud-Base-20141203-21.x86_64
so check-heat-dsvm-functional-mysql will be broken until this change
lands, assuming the tests pass using Fedora-Cloud-Base-20141203-21.x86_64

Change-Id: I301ab3a321fbcbcc47c2b0e04101fbee783968ce
",git fetch https://review.opendev.org/openstack/heat refs/changes/40/141240/1 && git format-patch -1 --stdout FETCH_HEAD,['heat_integrationtests/post_test_hook.sh'],1,3cdbf7889db78989a502deb837a688558e8829d5,f21-test-image,export HEAT_TEST_IMAGE_REF=Fedora-Cloud-Base-20141203-21.x86_64,export HEAT_TEST_IMAGE_REF=Fedora-x86_64-20-20140618-sda,1,1
openstack%2Fpython-cinderclient~master~I53f03dac1f5ef60a33911221432b0d276cc251fd,openstack/python-cinderclient,master,I53f03dac1f5ef60a33911221432b0d276cc251fd,Use strutils.to_slug() instead of utils.slugify(),ABANDONED,2014-05-27 15:22:25.000000000,2014-12-12 01:30:40.000000000,,"[{'_account_id': 3}, {'_account_id': 167}, {'_account_id': 5538}, {'_account_id': 9126}]","[{'number': 1, 'created': '2014-05-27 15:22:25.000000000', 'files': ['cinderclient/base.py', 'cinderclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e0fc0e418b6e31a1b00d77b68cd3e1436590c694', 'message': 'Use strutils.to_slug() instead of utils.slugify()\n\nThis removes the definition of slugify in cinderclient and uses the to_slug provided within common.\n\nChange-Id: I53f03dac1f5ef60a33911221432b0d276cc251fd\nCloses-Bug: 1266127\n'}]",1,95797,e0fc0e418b6e31a1b00d77b68cd3e1436590c694,10,4,1,1057,,,0,"Use strutils.to_slug() instead of utils.slugify()

This removes the definition of slugify in cinderclient and uses the to_slug provided within common.

Change-Id: I53f03dac1f5ef60a33911221432b0d276cc251fd
Closes-Bug: 1266127
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/97/95797/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/base.py', 'cinderclient/utils.py']",2,e0fc0e418b6e31a1b00d77b68cd3e1436590c694,bug/1266127,,"import re _slugify_strip_re = re.compile(r'[^\w\s-]') _slugify_hyphenate_re = re.compile(r'[-\s]+') # http://code.activestate.com/recipes/ # 577257-slugify-make-a-string-usable-in-a-url-or-filename/ def slugify(value): """""" Normalizes string, converts to lowercase, removes non-alpha characters, and converts spaces to hyphens. From Django's ""django/template/defaultfilters.py"". """""" import unicodedata if not isinstance(value, six.text_type): value = six.text_type(value) value = unicodedata.normalize('NFKD', value).encode('ascii', 'ignore') value = six.text_type(_slugify_strip_re.sub('', value).strip().lower()) return _slugify_hyphenate_re.sub('-', value)",1,22
openstack%2Fpython-cinderclient~master~Ic8209b3ac0931507c71c4efebb188d6587c46a6b,openstack/python-cinderclient,master,Ic8209b3ac0931507c71c4efebb188d6587c46a6b,Non-ascii volume type name fix,ABANDONED,2014-05-05 13:59:05.000000000,2014-12-12 01:26:53.000000000,,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 8871}, {'_account_id': 9225}, {'_account_id': 9412}, {'_account_id': 9449}, {'_account_id': 9450}, {'_account_id': 10242}]","[{'number': 1, 'created': '2014-05-05 13:59:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/41d871f7497a6b20e74acaa18f9634aa85683d9b', 'message': 'Non-ascii volume type name fix\n\nUser can create a volume type name using non-ascii charaters\nsuccessfully, but when that data is displayed in Horizon, it\nbreaks the page. To solve it, this patch uses the function\nencode in _add_details function.\n\nChange-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b\nCloses-Bug: #1314352\n'}, {'number': 2, 'created': '2014-05-08 13:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/df5d2e6ed1935490a4e476f36c503f73fa182a25', 'message': ""Non-ascii volume type name fix\n\nUser can create a volume type name using non-ascii charaters\nsuccessfully, but when that data is displayed in Horizon, it\nbreaks the page.\nThe problem is the volume type name is also used as 'name' parameter\nin the setattr call, inside _add_details function, and 'name'\ncan't have non-ascii characteres.\nThen, this patch removes the non-ascii characters for 'name',\nwithout affecting the correct display of non-ascii characters in\nin Horizon.\n\nChange-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b\nCloses-Bug: #1314352\n""}, {'number': 3, 'created': '2014-05-13 14:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/0af6181803f354861b177cf834afe1a2f6fa8db2', 'message': ""Non-ascii volume type name fix\n\nUser can create a volume type name using non-ascii charaters\nsuccessfully, but when that data is displayed in Horizon, it\nbreaks the page.\nThe problem is the volume type name is also used as 'name' parameter\nin the setattr call, inside _add_details function in the cinderclient\nclass Resource, and 'name' can't have non-ascii characteres.\nThen, this patch removes the non-ascii characters for 'name',\nwithout affecting the correct display of non-ascii characters in\nin Horizon.\n\nChange-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b\nCloses-Bug: #1314352\n""}, {'number': 4, 'created': '2014-06-25 14:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/eacb1ea6c9864be66702761fefe577eb7d13a164', 'message': ""Non-ascii volume type name fix\n\nUser can create a volume type name using non-ascii charaters\nsuccessfully, but when that data is displayed in Horizon, it\nbreaks the page.\nThe problem is the volume type name is also used as 'name' parameter\nin the setattr call, inside _add_details function in the cinderclient\nclass Resource, and 'name' can't have non-ascii characteres.\nThen, this patch removes the non-ascii characters for 'name',\nwithout affecting the correct display of non-ascii characters in\nin Horizon.\n\nChange-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b\nCloses-Bug: #1314352\n""}, {'number': 5, 'created': '2014-07-14 20:47:09.000000000', 'files': ['cinderclient/base.py', 'cinderclient/tests/test_base.py', 'cinderclient/openstack/common/apiclient/base.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/43c06c0eb6724307baa26d3993af12a572640215', 'message': ""Non-ascii volume type name fix\n\nUser can create a volume type name using non-ascii charaters\nsuccessfully, but when that data is displayed in Horizon, it\nbreaks the page.\nThe problem is the volume type name is also used as 'name' parameter\nin the setattr call, inside _add_details function in the cinderclient\nclass Resource, and 'name' can't have non-ascii characteres.\nThen, this patch removes the non-ascii characters for 'name',\nwithout affecting the correct display of non-ascii characters in\nin Horizon.\n\nChange-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b\nCloses-Bug: #1314352\n""}]",2,92116,43c06c0eb6724307baa26d3993af12a572640215,46,9,5,9449,,,0,"Non-ascii volume type name fix

User can create a volume type name using non-ascii charaters
successfully, but when that data is displayed in Horizon, it
breaks the page.
The problem is the volume type name is also used as 'name' parameter
in the setattr call, inside _add_details function in the cinderclient
class Resource, and 'name' can't have non-ascii characteres.
Then, this patch removes the non-ascii characters for 'name',
without affecting the correct display of non-ascii characters in
in Horizon.

Change-Id: Ic8209b3ac0931507c71c4efebb188d6587c46a6b
Closes-Bug: #1314352
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/16/92116/2 && git format-patch -1 --stdout FETCH_HEAD,['cinderclient/base.py'],1,41d871f7497a6b20e74acaa18f9634aa85683d9b,bug/1314352," setattr(self, k.encode('utf-8'), v)"," setattr(self, k, v)",1,1
openstack%2Fpython-cinderclient~master~Ia5967a64088375d2108d229fe7d62736fea58825,openstack/python-cinderclient,master,Ia5967a64088375d2108d229fe7d62736fea58825,Some filters added to CLI cinder list,ABANDONED,2014-04-28 20:01:23.000000000,2014-12-12 01:26:15.000000000,,"[{'_account_id': 3}, {'_account_id': 5538}, {'_account_id': 7198}, {'_account_id': 8072}]","[{'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/a503fbd463566663d9382573eadd8357533b10af', 'message': 'Some filters added to CLI cinder list\n\nAdded below filter keys:-\n1. tenant\n2. availability_zone\n3. host\n4. volume_type\n5. size\n\nThis patch depends on below cinder patch:-\nhttps://review.openstack.org/#/c/61549/\n\nCloses-Bug: #1249173\nChange-Id: Ia5967a64088375d2108d229fe7d62736fea58825\n'}, {'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': ['cinderclient/tests/v2/test_shell.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/test_shell.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b416e2b2f9bdedf584a24fb22d4cbd2440604d8b', 'message': 'Some filters added to CLI cinder list\n\nAdded below filter keys:-\n1. tenant\n2. availability_zone\n3. host\n4. volume_type\n5. size\n\nThis patch depends on below cinder patch:-\nhttps://review.openstack.org/#/c/61549/\n\nCloses-Bug: #1249173\nChange-Id: Ia5967a64088375d2108d229fe7d62736fea58825\n'}]",0,61551,b416e2b2f9bdedf584a24fb22d4cbd2440604d8b,15,4,2,8072,,,0,"Some filters added to CLI cinder list

Added below filter keys:-
1. tenant
2. availability_zone
3. host
4. volume_type
5. size

This patch depends on below cinder patch:-
https://review.openstack.org/#/c/61549/

Closes-Bug: #1249173
Change-Id: Ia5967a64088375d2108d229fe7d62736fea58825
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/51/61551/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/tests/v2/test_shell.py', 'cinderclient/v1/shell.py', 'cinderclient/tests/v1/test_shell.py', 'cinderclient/v2/shell.py']",4,a503fbd463566663d9382573eadd8357533b10af,master,"@utils.arg('--tenant', metavar='<tenant_id>', default=None, help='Filter results by tenant (Admin only).') @utils.arg('--availability_zone', metavar='<availability_zone>', default=None, help='Filter results by availability_zone') @utils.arg('--host', metavar='<hostname>', default=None, help='Filter volumes by host to which they are assigned.') @utils.arg('--volume_type', metavar='<volume_type>', default=None, help='Filter volumes by type.') @utils.arg('--size', metavar='<volume_size>', default=None, help='Filter volumes by size.') if args.tenant: all_tenants = 1 'project_id': args.tenant, 'availability_zone': args.availability_zone, 'host': args.host, 'volume_type': args.volume_type, 'size': args.size,",,94,0
openstack%2Fpython-cinderclient~master~I06310ce5fc36dd6cd284b12cf9f7446c533e1b10,openstack/python-cinderclient,master,I06310ce5fc36dd6cd284b12cf9f7446c533e1b10,Add Read Only option for volumes.,ABANDONED,2014-04-28 20:01:23.000000000,2014-12-12 01:09:59.000000000,,"[{'_account_id': 3}, {'_account_id': 2243}, {'_account_id': 6506}, {'_account_id': 6509}, {'_account_id': 6772}]","[{'number': 2, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/78e56a5e44189c95eaecce6b346ac6b4db925ed4', 'message': 'Add volume permissions like Unix file permissions.\n\nSupporting volume permissions like file permissions in Unix systems:\ncreating volume with volume permissions,\nshowing/updating volume permissions.\nSupporting Read Only mode for volumes:\nshowing read_only option in detailed volume info.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}, {'number': 3, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/853859e42c2c675be87d28d097e15edcd120c3a9', 'message': 'Add volume permissions like Unix file permissions.\n\nSupporting volume permissions like file permissions in Unix systems:\ncreating volume with volume permissions,\nshowing/updating volume permissions.\nSupporting Read Only mode for volumes:\nshowing read_only option in detailed volume info.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}, {'number': 1, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/d2540d91003c1d6782823dedeb28e50b870cf77d', 'message': 'Add support of Read Only mode for volumes.\n\nSupporting Read Only mode for volumes.\nUnit-tests are added too.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}, {'number': 6, 'created': '2014-04-28 20:01:23.000000000', 'files': ['cinderclient/v1/shell.py', 'cinderclient/v2/shell.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/b6fae4642851351c30c3182a5f57df0514a96bcc', 'message': 'Add Read Only option for volumes.\n\nAdd Read Only column for volumes.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}, {'number': 4, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/26161f2baf10a0beeb1f0f65e80dc1c8733411de', 'message': 'Add volume permissions like Unix file permissions.\n\nSupporting volume permissions like file permissions in Unix systems:\ncreating volume with volume permissions,\nshowing/updating volume permissions.\nSupporting Read Only mode for volumes:\nshowing read_only option in detailed volume info.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}, {'number': 5, 'created': '2014-04-28 20:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/f05a72a5d2b621bf0753d280be8c74f0e89b8767', 'message': 'Add Read Only option for volumes.\n\nblueprint read-only-volumes\n\nChange-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10\n'}]",0,34720,b6fae4642851351c30c3182a5f57df0514a96bcc,33,5,6,6506,,,0,"Add Read Only option for volumes.

Add Read Only column for volumes.

blueprint read-only-volumes

Change-Id: I06310ce5fc36dd6cd284b12cf9f7446c533e1b10
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/20/34720/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v1/shell.py', 'cinderclient/v1/volumes.py', 'cinderclient/v2/volumes.py', 'cinderclient/v2/shell.py', 'cinderclient/utils.py']",5,78e56a5e44189c95eaecce6b346ac6b4db925ed4,bp/read-only-volumes," def _rwx_to_num(rwx): return str(sum(int(pow(2, 'rwx'[::-1].find(letter))) for letter in rwx)) def rwx(arg): s = arg.strip().lower() if re.match(r'[0-7]{3}', s): return s str_one_rwx = r'[r-][w-][x-]?' str_rwx = (r'(%s)' % str_one_rwx) * 3 m = re.match(r'^%s$' % str_rwx, s) if m: return ''.join(_rwx_to_num(rwx) for rwx in m.groups()) if re.match(r'^%s$' % str_one_rwx, s): return _rwx_to_num(s) * 3 raise exceptions.CommandError(""\""%s\"" doesn't match rwx permissions."" % s)",,73,4
openstack%2Fpython-cinderclient~master~If5a82fc30fb4f767233f79608f45561160eda371,openstack/python-cinderclient,master,If5a82fc30fb4f767233f79608f45561160eda371,set_metadata throws AttributeError: id,ABANDONED,2014-05-05 20:18:20.000000000,2014-12-12 01:03:49.000000000,,"[{'_account_id': 3}, {'_account_id': 5538}, {'_account_id': 9449}, {'_account_id': 9450}]","[{'number': 1, 'created': '2014-05-05 20:18:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bea73e0530562155c033c9c58ca8265422d0a07b', 'message': 'set_metadata throws AttributeError: id\n\nWhen cinderclient set metadata it makes a post request to cinder\nto the url ""volume/<uuid>/metadata"", and cinder instead of\nreturning a volume information it return the updated metadata.\n\nDue to the fact that the documentation does not specify that a Volume\nshould return from the API call, the return statement is remove.\n\nCloses-Bug: #1315175\nChange-Id: If5a82fc30fb4f767233f79608f45561160eda371\n'}, {'number': 2, 'created': '2014-07-30 07:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/bfbc185852b88862f4b7331cd602afa6fb317f30', 'message': 'set_metadata throws AttributeError: id\n\nWhen cinderclient set metadata it makes a post request to cinder\nto the url ""volume/<uuid>/metadata"", and cinder instead of\nreturning a volume information it return the updated metadata.\n\nDue to the fact that the documentation does not specify that a Volume\nshould return from the API call, the return statement is remove.\n\nCloses-Bug: #1315175\nChange-Id: If5a82fc30fb4f767233f79608f45561160eda371\n'}, {'number': 3, 'created': '2014-08-02 00:49:34.000000000', 'files': ['cinderclient/tests/v2/test_volumes.py', 'cinderclient/tests/v1/test_volumes.py', 'cinderclient/v2/volumes.py', 'cinderclient/v1/volumes.py'], 'web_link': 'https://opendev.org/openstack/python-cinderclient/commit/e4a0fca0b2cbee01f935c32c7390a3e0626b388d', 'message': 'set_metadata throws AttributeError: id\n\nWhen cinderclient set metadata it makes a post request to cinder\nto the url ""volume/<uuid>/metadata"", and cinder instead of\nreturning a volume information it return the updated metadata.\n\nDue to the fact that the documentation does not specify that a Volume\nshould return from the API call, the return statement is remove.\n\nCloses-Bug: #1315175\nChange-Id: If5a82fc30fb4f767233f79608f45561160eda371\n'}]",4,92199,e4a0fca0b2cbee01f935c32c7390a3e0626b388d,17,4,3,9450,,,0,"set_metadata throws AttributeError: id

When cinderclient set metadata it makes a post request to cinder
to the url ""volume/<uuid>/metadata"", and cinder instead of
returning a volume information it return the updated metadata.

Due to the fact that the documentation does not specify that a Volume
should return from the API call, the return statement is remove.

Closes-Bug: #1315175
Change-Id: If5a82fc30fb4f767233f79608f45561160eda371
",git fetch https://review.opendev.org/openstack/python-cinderclient refs/changes/99/92199/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinderclient/v1/volumes.py', 'cinderclient/v2/volumes.py']",2,bea73e0530562155c033c9c58ca8265422d0a07b,bug/1315175," self._create(""/volumes/%s/metadata"" % base.getid(volume), body, ""metadata"", return_raw=True)"," return self._create(""/volumes/%s/metadata"" % base.getid(volume), body, ""metadata"")",4,4
openstack%2Fdevstack-gate~master~I10cdc1c6081aa2f66e924d65a8151e3bd118c7a2,openstack/devstack-gate,master,I10cdc1c6081aa2f66e924d65a8151e3bd118c7a2,"Revert ""Temporarily disable testing lbaas, fwaas, and vpnaas""",MERGED,2014-12-10 23:26:52.000000000,2014-12-12 00:43:40.000000000,2014-12-12 00:43:40.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 4146}, {'_account_id': 5196}, {'_account_id': 5263}, {'_account_id': 6995}, {'_account_id': 8871}, {'_account_id': 10980}]","[{'number': 1, 'created': '2014-12-10 23:26:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/621f28ea2d5dc47f610a303c60d33ad00cb1c15c', 'message': 'Revert ""Temporarily disable testing lbaas, fwaas, and vpnaas""\n\nThe advanced services migration has finished let\'s re-enable the \ntemporarily disabled testing and services.\n\nThis reverts commit 5358740468554afcf4fbef0aa16b6f76bf68cae9.\n\nChange-Id: I10cdc1c6081aa2f66e924d65a8151e3bd118c7a2\n'}, {'number': 2, 'created': '2014-12-11 15:49:21.000000000', 'files': ['features.yaml', 'test-features.sh', 'devstack-vm-gate.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/f8c5d29a6cd4e4090c2cb0cf6a29c93e3bb4628b', 'message': 'Revert ""Temporarily disable testing lbaas, fwaas, and vpnaas""\n\nThe advanced services migration has finished let\'s re-enable the\ntemporarily disabled testing and services.\n\nThis reverts commit 5358740468554afcf4fbef0aa16b6f76bf68cae9.\n\nChange-Id: I10cdc1c6081aa2f66e924d65a8151e3bd118c7a2\n'}]",0,140864,f8c5d29a6cd4e4090c2cb0cf6a29c93e3bb4628b,43,10,2,5196,,,0,"Revert ""Temporarily disable testing lbaas, fwaas, and vpnaas""

The advanced services migration has finished let's re-enable the
temporarily disabled testing and services.

This reverts commit 5358740468554afcf4fbef0aa16b6f76bf68cae9.

Change-Id: I10cdc1c6081aa2f66e924d65a8151e3bd118c7a2
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/64/140864/1 && git format-patch -1 --stdout FETCH_HEAD,"['features.yaml', 'test-features.sh', 'devstack-vm-gate.sh']",3,621f28ea2d5dc47f610a303c60d33ad00cb1c15c,bug/1400370,," # NOTE(mtreinish): This is only temporary and needed for the advanced # services split. It will eventually break tempest on stable branches # when new extension tests are added. The real way to do this is in # progress as part of bp branchless-tempest-extensions NET_API_EXT=""agent,allowed-address-pairs,binding,"" NET_API_EXT+=""dhcp_agent_scheduler,dvr,ext-gw-mode,external-net,"" NET_API_EXT+=""extra_dhcp_opt,extraroute,l3-ha,l3_agent_scheduler,"" NET_API_EXT+=""metering,multi-provider,provider,quotas,router,"" NET_API_EXT+=""security-group,service-type"" echo ""NETWORK_API_EXTENSIONS=$NET_API_EXT"" >>""$localrc_file""",3,13
openstack%2Fhorizon~master~I5269d947716854274a9b6c27b903b01606a787d3,openstack/horizon,master,I5269d947716854274a9b6c27b903b01606a787d3,update/cleanup bootstrap 3 icon usage,MERGED,2014-09-10 18:03:41.000000000,2014-12-12 00:43:31.000000000,2014-12-12 00:43:29.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6637}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 9981}, {'_account_id': 11881}, {'_account_id': 13325}]","[{'number': 1, 'created': '2014-09-10 18:03:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/82fa4db8bd4ad7d807dbaf618e3d1c4a1d970132', 'message': ""update/cleanup bootstrap 3 icon usage\n\nThere are some old instances of <i class='icon-ok'></i> in the code.\nWe should be using the new way instead:\n(<span class='glyphicon glyphicon-ok'></span>).\n\nChange-Id: I5269d947716854274a9b6c27b903b01606a787d3\nCloses-Bug: #1367476\n""}, {'number': 2, 'created': '2014-09-16 00:45:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/73a5d32d69a2c40fddc72ba6a906200846dc092e', 'message': ""update/cleanup bootstrap 3 icon usage\n\nThere are some old instances of <i class='icon-ok'></i> in the code.\nWe are also moving away from bootstrap 3 glyphicons icons to\nfont-awesome icons instead.\nWIP\n\n- replace sort icons with font-awesome, profile editor icons\ninstead of using standalone icons in /img folder\n\nChange-Id: I5269d947716854274a9b6c27b903b01606a787d3\nCloses-Bug: #1367476\n""}, {'number': 3, 'created': '2014-09-16 01:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e6ba4f373e45d0352906e39168f8f6298a59d75d', 'message': ""update/cleanup bootstrap 3 icon usage\n\nThere are some old instances of <i class='icon-ok'></i> in the code.\nWe are also moving away from bootstrap 3 glyphicons icons to\nfont-awesome icons instead.\nWIP\n\n- replace sort icons with font-awesome, profile editor icons\ninstead of using standalone icons in /img folder\n\nChange-Id: I5269d947716854274a9b6c27b903b01606a787d3\nCloses-Bug: #1367476\n""}, {'number': 4, 'created': '2014-09-16 01:13:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d45a48fd354ad20ef4fa0e81b7793e41b8b31272', 'message': ""update/cleanup bootstrap 3 icon usage\n\nThere are some old instances of <i class='icon-ok'></i> in the code.\nWe are also moving away from bootstrap 3 glyphicons icons to\nfont-awesome icons instead.\nWIP\n\n- replace sort icons with font-awesome, profile editor icons\ninstead of using standalone icons in /img folder\n\nChange-Id: I5269d947716854274a9b6c27b903b01606a787d3\nCloses-Bug: #1367476\n""}, {'number': 5, 'created': '2014-12-03 18:30:26.000000000', 'files': ['horizon/templates/horizon/client_side/_membership.html', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/index.html', 'openstack_dashboard/dashboards/project/routers/templates/routers/extensions/routerrules/grid.html', 'horizon/templates/horizon/common/_data_table.html', 'openstack_dashboard/templates/_header.html', 'horizon/templates/horizon/common/_form_field.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0edef60ff282825ef62c695473dd8b97314ba27', 'message': ""update/cleanup bootstrap 3 icon usage\n\nThere are some old instances of <i class='icon-ok'></i>\nand glyphicon in the code.\nWe should be using font-awesome icons instead.\n\nChange-Id: I5269d947716854274a9b6c27b903b01606a787d3\nCloses-Bug: #1367476\n""}]",0,120499,a0edef60ff282825ef62c695473dd8b97314ba27,26,9,5,9622,,,0,"update/cleanup bootstrap 3 icon usage

There are some old instances of <i class='icon-ok'></i>
and glyphicon in the code.
We should be using font-awesome icons instead.

Change-Id: I5269d947716854274a9b6c27b903b01606a787d3
Closes-Bug: #1367476
",git fetch https://review.opendev.org/openstack/horizon refs/changes/99/120499/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/templates/horizon/client_side/_membership.html', 'openstack_dashboard/dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/_tag_form.html', 'openstack_dashboard/dashboards/project/data_processing/cluster_templates/templates/data_processing.cluster_templates/cluster_node_groups_template.html', 'openstack_dashboard/dashboards/project/data_processing/data_image_registry/templates/data_processing.data_image_registry/image_registry.html', 'openstack_dashboard/dashboards/project/network_topology/templates/network_topology/index.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss', 'openstack_dashboard/dashboards/project/routers/templates/routers/extensions/routerrules/grid.html']",7,82fa4db8bd4ad7d807dbaf618e3d1c4a1d970132,bug/1367476," <span class=""glyphicon glyphicon-ban-circle""></span> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><span class=""glyphicon glyphicon-random""></span></button></center> <span class=""glyphicon glyphicon-ok""></span> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><span class=""glyphicon glyphicon-random""></span></button> Clicking the <span class=""glyphicon glyphicon-random""></span> button in the intersection will install a rule to switch the traffic behavior.<br/>"," <i class=""icon-ban-circle""></i> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><i class=""icon-random""></i></button></center> <i class=""icon-ok""></i> <button type=""submit"" class=""btn btn-default btn-xs"" href=""#""><i class=""icon-random""></i></button> Clicking the <i class=""icon-random""></i> button in the intersection will install a rule to switch the traffic behavior.<br/>",14,16
openstack%2Fsahara~master~I3c19598c4416deb74536f826544820d6f23ed9c8,openstack/sahara,master,I3c19598c4416deb74536f826544820d6f23ed9c8,Use first_run to Start Services,MERGED,2014-11-14 09:09:15.000000000,2014-12-12 00:25:23.000000000,2014-12-11 17:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 6786}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 13662}]","[{'number': 1, 'created': '2014-11-14 09:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7a283576343f26108d13e39996ad740445157d87', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 2, 'created': '2014-11-14 10:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/7340d531901c4c969f48e902148f1d88f8560309', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 3, 'created': '2014-11-18 13:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/5b58344a1c116070e69764f55a7eb68a82fc329e', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 4, 'created': '2014-11-24 08:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/d51b45e379b8cc6354790e49296397ab7ab55f93', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 5, 'created': '2014-12-03 12:53:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/1911392f952fd452f3100caac007f35c62a086f6', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices. If first_run fails, the fail child command exception\nmessage will be raised.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 6, 'created': '2014-12-03 13:09:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/bdb4708692df0220eceb05baa27a51e70a5365ee', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices. If first_run fails, the fail child command exception\nmessage will be raised.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 7, 'created': '2014-12-05 17:02:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/c182ecca2c6366fb18adfbcca558a814bf798135', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices. If first_run fails, the fail child command exception\nmessage will be raised.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 8, 'created': '2014-12-10 16:59:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/8f34f7214cbea0c4b1a3983c4824649fe6c3f0be', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices. If first_run fails, the fail child command exception\nmessage will be raised.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}, {'number': 9, 'created': '2014-12-11 03:05:19.000000000', 'files': ['sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/cloudera_utils.py', 'sahara/plugins/cdh/utils.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/24b6949e943b0fcfd1de200c59bbdd5c0eb3fc89', 'message': 'Use first_run to Start Services\n\nIn CDH plugin, change to use cm_api first_run method start all\nservices. If first_run fails, the fail child command exception\nmessage will be raised.\n\nimplements bp: first-run-api-usage\n\nChange-Id: I3c19598c4416deb74536f826544820d6f23ed9c8\n'}]",1,134471,24b6949e943b0fcfd1de200c59bbdd5c0eb3fc89,100,8,9,13662,,,0,"Use first_run to Start Services

In CDH plugin, change to use cm_api first_run method start all
services. If first_run fails, the fail child command exception
message will be raised.

implements bp: first-run-api-usage

Change-Id: I3c19598c4416deb74536f826544820d6f23ed9c8
",git fetch https://review.opendev.org/openstack/sahara refs/changes/71/134471/9 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/deploy.py', 'sahara/plugins/cdh/cloudera_utils.py']",2,7a283576343f26108d13e39996ad740445157d87,bp/first-run-api-usage,@cloudera_cmd def first_run(cluster): cm_cluster = get_cloudera_cluster(cluster) yield cm_cluster.first_run() 'SPARK_YARN_HISTORY_SERVER': 'SHS'," 'SPARK_YARN_HISTORY_SERVER': 'SHS',def format_namenode(hdfs_service): for nn in hdfs_service.get_roles_by_type('NAMENODE'): yield hdfs_service.format_hdfs(nn.name)[0] @cloudera_cmd @cloudera_cmd def create_yarn_job_history_dir(yarn_service): yield yarn_service.create_yarn_job_history_dir() @cloudera_cmd def create_oozie_db(oozie_service): yield oozie_service.create_oozie_db() @cloudera_cmd def install_oozie_sharelib(oozie_service): yield oozie_service.install_oozie_sharelib() @cloudera_cmd def create_hive_metastore_db(hive_service): yield hive_service.create_hive_metastore_tables() @cloudera_cmd def create_hive_dirs(hive_service): yield hive_service.create_hive_userdir() yield hive_service.create_hive_warehouse()",8,108
openstack%2Fmagnum~master~Iaeb574b9754fe2635a2b082a99216337130a19f9,openstack/magnum,master,Iaeb574b9754fe2635a2b082a99216337130a19f9,Rename backend to conductor,MERGED,2014-12-11 20:04:12.000000000,2014-12-12 00:21:19.000000000,2014-12-12 00:21:19.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2014-12-11 20:04:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9b779d38a623e10e9cb3768cdd6f021d0eccabc9', 'message': 'Rename backend to conductor\n\nThe backend is a bad name for a process, so instead call it the conductor.\n\nChange-Id: Iaeb574b9754fe2635a2b082a99216337130a19f9\n'}, {'number': 2, 'created': '2014-12-11 23:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dee77ba09715e3c1fca5d6b93eb40faacab536d5', 'message': 'Rename backend to conductor\n\nThe backend is a bad name for a process, so instead call it the conductor.\n\nChange-Id: Iaeb574b9754fe2635a2b082a99216337130a19f9\n'}, {'number': 3, 'created': '2014-12-11 23:51:13.000000000', 'files': ['magnum/backend/manager.py', 'magnum/conductor/handlers/bay_ironic.py', 'magnum/api/controllers/v1/bay.py', 'magnum/conductor/handlers/k8s.py', 'magnum/tests/api/controllers/v1/test_all_objects.py', 'magnum/cmd/conductor.py', 'doc/source/dev/dev-quickstart.rst', 'magnum/conductor/api.py', 'magnum/backend/__init__.py', 'magnum/backend/handlers/__init__.py', 'magnum/conductor/config.py', 'magnum/conductor/handlers/docker.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/magnum/commit/9d46b771c51dac6311c2f4baf16d26871a1e98e0', 'message': 'Rename backend to conductor\n\nThe backend is a bad name for a process, so instead call it the conductor.\n\nChange-Id: Iaeb574b9754fe2635a2b082a99216337130a19f9\n'}]",0,141150,9d46b771c51dac6311c2f4baf16d26871a1e98e0,10,2,3,2834,,,0,"Rename backend to conductor

The backend is a bad name for a process, so instead call it the conductor.

Change-Id: Iaeb574b9754fe2635a2b082a99216337130a19f9
",git fetch https://review.opendev.org/openstack/magnum refs/changes/50/141150/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/backend/manager.py', 'magnum/conductor/handlers/bay_ironic.py', 'magnum/api/controllers/v1/bay.py', 'magnum/conductor/handlers/k8s.py', 'magnum/cmd/conductor.py', 'doc/source/dev/dev-quickstart.rst', 'magnum/conductor/api.py', 'magnum/backend/__init__.py', 'magnum/backend/handlers/__init__.py', 'magnum/conductor/config.py', 'magnum/conductor/handlers/docker.py', 'setup.cfg']",12,9b779d38a623e10e9cb3768cdd6f021d0eccabc9,, magnum-conductor = magnum.cmd.conductor:main, magnum-backend = magnum.cmd.backend:main,24,104
