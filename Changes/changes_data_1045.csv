id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fopenstack-manuals~master~I11cbb15d6e28fb7305924ed31a5db2869080d037,openstack/openstack-manuals,master,I11cbb15d6e28fb7305924ed31a5db2869080d037,[config-ref] Improvements for hp-msa-driver,MERGED,2015-12-12 12:14:36.000000000,2015-12-12 23:26:29.000000000,2015-12-12 23:26:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-12 12:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f00097a57115373be0220bfd6b801734e795b161', 'message': '[config-ref] Improvements for hp-msa-driver\n\nChange-Id: I11cbb15d6e28fb7305924ed31a5db2869080d037\n'}, {'number': 2, 'created': '2015-12-12 14:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/92cb93eda4567b69109089957435c97370afe518', 'message': '[config-ref] Improvements for hp-msa-driver\n\nChange-Id: I11cbb15d6e28fb7305924ed31a5db2869080d037\n'}, {'number': 3, 'created': '2015-12-12 14:55:10.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/hp-msa-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/51a82dad2e6f7b3760d9dee3fdd821e7d8e6e514', 'message': '[config-ref] Improvements for hp-msa-driver\n\nImplements: blueprint config-ref-rst\nChange-Id: I11cbb15d6e28fb7305924ed31a5db2869080d037\n'}]",3,256939,51a82dad2e6f7b3760d9dee3fdd821e7d8e6e514,12,3,3,16237,,,0,"[config-ref] Improvements for hp-msa-driver

Implements: blueprint config-ref-rst
Change-Id: I11cbb15d6e28fb7305924ed31a5db2869080d037
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/39/256939/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/block-storage/drivers/hp-msa-driver.rst'],1,f00097a57115373be0220bfd6b801734e795b161,mark,"2040 or 1040 arrays to be used for Block Storage in OpenStack deployments. System requirements by options specified in a ``key=value`` format. array, or a name that shared among multiple storage pools to let the array: the appropriate Cinder driver name; IP address or host name of the In the examples below, two back-ends are defined, one for pool A and one for that you added in the ``cinder.conf`` file. The example below assumes that the same ``volume_backend_name=hpmsa-array`` option was specified in all of the entries, and specifies that the volume type ``hpmsa`` can be used to#. After modifying the ``cinder.conf`` file, restart the cinder-volume service.","2040 or 1040 arrays to be used for block storage in OpenStack deployments. System Requirements by options specified in ``key=value`` format. array, or a name that's shared among multiple storage pools to let the array: the appropriate Cinder driver name; IP address or hostname of the In the examples below, two back ends are defined, one for pool A and one for that you added to ``cinder.conf``. The example below assumes that the same ``volume_backend_name=hpmsa-array`` option was specified in all of the entries, and specifies that the volume type ``hpmsa`` can be used to#. After modifying ``cinder.conf``, restart the cinder-volume service.",11,11
openstack%2Fpython-neutronclient~master~Iaa83626b81a3d8369b16e2b4f394e2bc4628998a,openstack/python-neutronclient,master,Iaa83626b81a3d8369b16e2b4f394e2bc4628998a,Fix H405 violations,MERGED,2015-12-03 07:48:15.000000000,2015-12-12 23:25:05.000000000,2015-12-12 23:25:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6524}, {'_account_id': 7448}, {'_account_id': 7787}, {'_account_id': 14605}, {'_account_id': 16352}, {'_account_id': 16788}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-12-03 07:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/c05cd6d6146680dd29ee0e03ace22d6c6dc9e585', 'message': 'Fix H405 violations for remaining\n\nThere is a lot of H405 violation codes.\nWe need to fix the code for avoiding more violations.\n\nThis patch fixes these violations for remaining.\n\nChange-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a\nCloses-Bug: #1521899\n'}, {'number': 2, 'created': '2015-12-07 02:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/cb4ca79e8704efaff99c90a47fe42171d83d0d91', 'message': 'Fix H405 violations\n\nThere are a lot of H405 violation codes.\nWe need to fix the code for avoiding more violations.\n\nChange-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a\nCloses-Bug: #1521899\n'}, {'number': 3, 'created': '2015-12-07 08:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/af0a9381d8ce34fd59814f7c094936134363002c', 'message': 'Fix H405 violations\n\nThere are a lot of H405 violation codes.\nWe need to fix the code for avoiding more violations.\n\nChange-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a\nCloses-Bug: #1521899\n'}, {'number': 4, 'created': '2015-12-11 02:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/d228bad30f9d3c3a18b04594e1d853f1cddd94b9', 'message': 'Fix H405 violations\n\nThere are a lot of H405 violation codes.\nWe need to fix the code for avoiding more violations.\n\nChange-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a\nCloses-Bug: #1521899\n'}, {'number': 5, 'created': '2015-12-12 20:49:01.000000000', 'files': ['neutronclient/tests/unit/lb/v2/test_cli20_member.py', 'neutronclient/tests/functional/core/test_readonly_neutron.py', 'neutronclient/tests/unit/test_cli20_nsx_queue.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/floatingip.py', 'neutronclient/tests/unit/vpn/test_cli20_endpoint_group.py', 'neutronclient/common/exceptions.py', 'neutronclient/tests/unit/lb/v2/test_cli20_loadbalancer.py', 'neutronclient/tests/unit/lb/v2/test_cli20_pool.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/test_client_extension.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/tests/unit/test_cli20_address_scope.py', 'neutronclient/tests/unit/lb/v2/test_cli20_listener.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py', 'neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/tests/unit/qos/test_cli20_rule.py', 'neutronclient/tests/unit/test_cli20_subnetpool.py', 'neutronclient/tests/unit/test_http.py', 'neutronclient/tests/unit/test_cli20_agents.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/test_cli20_subnet.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/tests/unit/test_cli20_network.py', 'neutronclient/tests/functional/adv-svcs/test_readonly_neutron_vpn.py', 'neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/tests/unit/qos/test_cli20_policy.py', 'neutronclient/tests/unit/test_cli20_metering.py', 'neutronclient/tests/unit/test_cli20_rbac.py', 'neutronclient/tests/unit/test_cli20_router.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py', 'neutronclient/tests/unit/lb/v2/test_cli20_healthmonitor.py', 'neutronclient/shell.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/ec4e4827317f5d9e2b5e4bc7f0774664c098da70', 'message': 'Fix H405 violations\n\nThere are a lot of H405 violation codes.\nWe need to fix the code for avoiding more violations.\n\nChange-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a\nCloses-Bug: #1521899\n'}]",30,252802,ec4e4827317f5d9e2b5e4bc7f0774664c098da70,31,11,5,16352,,,0,"Fix H405 violations

There are a lot of H405 violation codes.
We need to fix the code for avoiding more violations.

Change-Id: Iaa83626b81a3d8369b16e2b4f394e2bc4628998a
Closes-Bug: #1521899
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/02/252802/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/functional/core/test_readonly_neutron.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/floatingip.py', 'neutronclient/tests/unit/vpn/test_cli20_endpoint_group.py', 'neutronclient/common/exceptions.py', 'neutronclient/tests/unit/lb/v2/test_cli20_loadbalancer.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/tests/unit/test_cli20_address_scope.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py', 'neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/tests/unit/test_cli20_subnetpool.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/test_cli20_subnet.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/tests/unit/test_cli20_network.py', 'neutronclient/tests/functional/adv-svcs/test_readonly_neutron_vpn.py', 'neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/tests/unit/qos/test_cli20_policy.py', 'neutronclient/tests/unit/test_cli20_rbac.py', 'neutronclient/tests/unit/test_cli20_router.py', 'neutronclient/shell.py', 'tox.ini']",29,c05cd6d6146680dd29ee0e03ace22d6c6dc9e585,bug/1521899,,# H405 multi line docstring summary not separated with an empty line # (mutli line docstring is used in unit tests frequently) ignore = H405,109,69
openstack%2Fhorizon~master~I8641697db604a7c91f980107a227dcc542ba4879,openstack/horizon,master,I8641697db604a7c91f980107a227dcc542ba4879,Imported Translations from Zanata,MERGED,2015-12-11 06:19:19.000000000,2015-12-12 23:19:10.000000000,2015-12-12 23:19:08.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 12826}]","[{'number': 1, 'created': '2015-12-11 06:19:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e5795a5134a00e80e49c4d39d980fd78d1b26d9e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8641697db604a7c91f980107a227dcc542ba4879\n'}, {'number': 2, 'created': '2015-12-12 06:28:08.000000000', 'files': ['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/django.pot', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/djangojs.pot', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/31c505071f12bf4e80502650c031cb6c63e68343', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I8641697db604a7c91f980107a227dcc542ba4879\n'}]",0,256232,31c505071f12bf4e80502650c031cb6c63e68343,15,3,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I8641697db604a7c91f980107a227dcc542ba4879
",git fetch https://review.opendev.org/openstack/horizon refs/changes/32/256232/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/django.pot', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/sr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/nl_NL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/hi/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po']",33,e5795a5134a00e80e49c4d39d980fd78d1b26d9e,zanata/translations,"""POT-Creation-Date: 2015-12-10 16:21+0000\n""","""POT-Creation-Date: 2015-12-09 02:55+0000\n""""Create IKE Policy for current project.\n"" ""\n"" ""Assign a name and description for the IKE Policy. "" msgstr """" ""Criar Política IKE para o projeto atual.\n"" ""\n"" ""Atribua um nome e uma descrição para a Política IKE."" msgid """" ""Create IPSec Policy for current project.\n"" ""\n"" ""Assign a name and description for the IPSec Policy. "" msgstr """" ""Criar Política IPSec para o projeto atual.\n"" ""\n"" ""Atribua um nome e descrição para a Política IPSec."" msgid """"msgid """" ""Create VPN Service for current project.\n"" ""\n"" ""Specify a name, description, router, and subnet for the VPN Service. Admin "" ""State is Up (checked) by default."" msgstr """" ""Criar serviço VPN para project. atual Especifique um nome, descrição, "" ""roteador e sub-rede para o serviço de VPN. Estado Admin é Up (marcada) por "" ""padrão."" msgid """" ""Currently only images available via an HTTP/HTTPS URL are supported. The "" ""image location must be accessible to the Image Service. Compressed image "" ""binaries are supported (.zip and .tar.gz.)"" msgstr """" ""Atualmente somente imagens disponíveis via URL HTTP/HTTPS são suportadas. O "" ""local da imagem deve ser acessível ao serviço de Imagem. Binários de imagem "" ""comprimidos são suportados (.zip e .tar.gz.)"" msgid ""Download OpenStack RC File"" msgstr ""Baixar Arquivo OpenStack RC"" msgid ""The state to start in."" msgstr ""O estado a iniciar em."" ",207,1294
openstack%2Fhorizon~master~Icf09b2a70e63f610e34212ddc4d74f077a07b089,openstack/horizon,master,Icf09b2a70e63f610e34212ddc4d74f077a07b089,Fix duplicate Image URL validation message,MERGED,2015-12-11 11:04:08.000000000,2015-12-12 23:04:59.000000000,2015-12-12 23:04:57.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 8871}, {'_account_id': 9622}, {'_account_id': 17172}]","[{'number': 1, 'created': '2015-12-11 11:04:08.000000000', 'files': ['openstack_dashboard/dashboards/project/images/images/forms.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/bb66ec17b1ec4c70813a95236d0479c3de658c26', 'message': 'Fix duplicate Image URL validation message\n\nURLField already have a default_validator of URLValidator,\ndefining another validator appends to the default_validator\ncausing duplicate message.\n\nWe should override the default_validator for restricting the\nurl schema rather than appending another URLValidator.\n\nChange-Id: Icf09b2a70e63f610e34212ddc4d74f077a07b089\nCloses-bug: #1525100\n'}]",0,256346,bb66ec17b1ec4c70813a95236d0479c3de658c26,14,7,1,1941,,,0,"Fix duplicate Image URL validation message

URLField already have a default_validator of URLValidator,
defining another validator appends to the default_validator
causing duplicate message.

We should override the default_validator for restricting the
url schema rather than appending another URLValidator.

Change-Id: Icf09b2a70e63f610e34212ddc4d74f077a07b089
Closes-bug: #1525100
",git fetch https://review.opendev.org/openstack/horizon refs/changes/46/256346/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/images/images/forms.py'],1,bb66ec17b1ec4c70813a95236d0479c3de658c26,bug/1525100,"class ImageURLField(forms.URLField): default_validators = [validators.URLValidator(schemes=[""http"", ""https""])] image_url = ImageURLField(label=_(""Image Location""), help_text=_(""An external (HTTP/HTTPS) URL to "" ""load the image from.""), widget=forms.TextInput(attrs={ 'class': 'switched', 'data-switch-on': 'source', 'data-source-url': _('Image Location'), 'ng-model': 'copyFrom', 'ng-change': 'ctrl.selectImageFormat(copyFrom)'}), required=False)"," image_url = forms.URLField(label=_(""Image Location""), help_text=_(""An external (HTTP/HTTPS) URL to "" ""load the image from.""), widget=forms.TextInput(attrs={ 'class': 'switched', 'data-switch-on': 'source', 'data-source-url': _('Image Location'), 'ng-model': 'copyFrom', 'ng-change': 'ctrl.selectImageFormat(copyFrom)'}), validators=[validators.URLValidator( schemes=[""http"", ""https""])], required=False)",15,13
openstack%2Fhorizon~master~I97d0ce728e44777635bf6590e312fb00d1684582,openstack/horizon,master,I97d0ce728e44777635bf6590e312fb00d1684582,Adding tests for ng identity basePath constant,MERGED,2015-09-09 14:42:05.000000000,2015-12-12 22:54:00.000000000,2015-12-12 22:53:58.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 12071}, {'_account_id': 15742}, {'_account_id': 17013}, {'_account_id': 17089}]","[{'number': 1, 'created': '2015-09-09 14:42:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5f8ba1b26a8d3720b9109b0c7c63614972b35033', 'message': 'Adding tests for ng identity basePath constant\n\nThis patch improves test coverage for the agular identity\ndashboard by adding tests for the basePath constant definition.\nA minor consistency issue in the module file is also addressed.\n\nChange-Id: I97d0ce728e44777635bf6590e312fb00d1684582\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 2, 'created': '2015-09-10 14:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d573990d47a023e34de7c21b25ebe8a06b44d6c5', 'message': 'Adding tests for ng identity basePath constant\n\nThis patch improves test coverage for the agular identity\ndashboard by adding tests for the basePath constant definition.\nA minor consistency issue in the module file is also addressed.\n\nChange-Id: I97d0ce728e44777635bf6590e312fb00d1684582\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 3, 'created': '2015-10-21 01:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4ef8a05b279be2d2e3e151d8587d8046a296ccd2', 'message': 'Adding tests for ng identity basePath constant\n\nThis patch improves test coverage for the agular identity\ndashboard by adding tests for the basePath constant definition.\nA minor consistency issue in the module file is also addressed.\n\nChange-Id: I97d0ce728e44777635bf6590e312fb00d1684582\nPartially-Implements: blueprint angularize-identity-tables\n'}, {'number': 4, 'created': '2015-12-01 17:44:10.000000000', 'files': ['openstack_dashboard/dashboards/identity/static/dashboard/identity/identity.module.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/identity.module.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/859195d44c6b7b956f9cac402b0a24bbd0aa1d0a', 'message': 'Adding tests for ng identity basePath constant\n\nThis patch improves test coverage for the agular identity\ndashboard by adding tests for the basePath constant definition.\nA minor consistency issue in the module file is also addressed.\n\nChange-Id: I97d0ce728e44777635bf6590e312fb00d1684582\nPartially-Implements: blueprint angularize-identity-tables\n'}]",4,221804,859195d44c6b7b956f9cac402b0a24bbd0aa1d0a,23,7,4,15742,,,0,"Adding tests for ng identity basePath constant

This patch improves test coverage for the agular identity
dashboard by adding tests for the basePath constant definition.
A minor consistency issue in the module file is also addressed.

Change-Id: I97d0ce728e44777635bf6590e312fb00d1684582
Partially-Implements: blueprint angularize-identity-tables
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/221804/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/identity/static/dashboard/identity/identity.module.spec.js', 'openstack_dashboard/dashboards/identity/static/dashboard/identity/identity.module.js']",2,5f8ba1b26a8d3720b9109b0c7c63614972b35033,bp/angularize-identity-tables," config.$inject = [ '$provide', '$windowProvider' ];"," config.$inject = ['$provide', '$windowProvider'];",22,1
openstack%2Foslo.middleware~master~Ib19bcc47909621260902be31eb14e8240155c7d0,openstack/oslo.middleware,master,Ib19bcc47909621260902be31eb14e8240155c7d0,[fix-compat] More definitions for oslo.middleware,MERGED,2015-12-11 23:38:28.000000000,2015-12-12 21:23:45.000000000,2015-12-12 21:23:44.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-11 23:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/23796c6b0f6d954a769eaf969a55794acbe6b55c', 'message': '[fix-compat] More definitions for oslo.middleware\n\nPlease see I04739bc3987786b4bc1fefc70fabaa69b3de52b4 for\ncontext. Adding the modules is not enough. We need\nto expose additional classes in the __init__.py for\noslo.middleware package for grenade to work properly\n\nChange-Id: Ib19bcc47909621260902be31eb14e8240155c7d0\n'}, {'number': 2, 'created': '2015-12-12 19:18:34.000000000', 'files': ['oslo/middleware/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/439940ac8631e0452dc7294e7e35e63e873aba5c', 'message': '[fix-compat] More definitions for oslo.middleware\n\nPlease see I04739bc3987786b4bc1fefc70fabaa69b3de52b4 for\ncontext. Adding the modules is not enough. We need\nto expose additional classes in the __init__.py for\noslo.middleware package for grenade to work properly\n\nChange-Id: Ib19bcc47909621260902be31eb14e8240155c7d0\n'}]",0,256887,439940ac8631e0452dc7294e7e35e63e873aba5c,14,2,2,5638,,,0,"[fix-compat] More definitions for oslo.middleware

Please see I04739bc3987786b4bc1fefc70fabaa69b3de52b4 for
context. Adding the modules is not enough. We need
to expose additional classes in the __init__.py for
oslo.middleware package for grenade to work properly

Change-Id: Ib19bcc47909621260902be31eb14e8240155c7d0
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/87/256887/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo/middleware/__init__.py'],1,23796c6b0f6d954a769eaf969a55794acbe6b55c,,sys.modules['oslo.middleware.sizelimit'] = sizelimit from oslo_middleware.catch_errors import CatchErrors from oslo_middleware.correlation_id import CorrelationId from oslo_middleware.cors import CORS from oslo_middleware.debug import Debug from oslo_middleware.healthcheck import Healthcheck from oslo_middleware.http_proxy_to_wsgi import HTTPProxyToWSGI from oslo_middleware.request_id import RequestId from oslo_middleware.sizelimit import RequestBodySizeLimiter from oslo_middleware.ssl import SSLMiddleware,sys.modules['oslo.middleware.sizelimit'] = sizelimit,11,1
openstack%2Foslo.vmware~master~Ie443a63c1864d9aa652b5f4db737dcba6a5dbfd9,openstack/oslo.vmware,master,Ie443a63c1864d9aa652b5f4db737dcba6a5dbfd9,Updated from global requirements,MERGED,2015-12-11 15:24:45.000000000,2015-12-12 21:14:11.000000000,2015-12-12 21:14:10.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 8119}, {'_account_id': 9008}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:24:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.vmware/commit/e50f28089ce5046e2ae6aa563263bc5c9c935a57', 'message': 'Updated from global requirements\n\nChange-Id: Ie443a63c1864d9aa652b5f4db737dcba6a5dbfd9\n'}]",0,256512,e50f28089ce5046e2ae6aa563263bc5c9c935a57,14,5,1,11131,,,0,"Updated from global requirements

Change-Id: Ie443a63c1864d9aa652b5f4db737dcba6a5dbfd9
",git fetch https://review.opendev.org/openstack/oslo.vmware refs/changes/12/256512/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e50f28089ce5046e2ae6aa563263bc5c9c935a57,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.cache~master~I1eacb700c9f6fc8106a4bf3d26a638c7e4f6c017,openstack/oslo.cache,master,I1eacb700c9f6fc8106a4bf3d26a638c7e4f6c017,Updated from global requirements,MERGED,2015-12-11 15:23:42.000000000,2015-12-12 21:13:00.000000000,2015-12-12 21:13:00.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-11 15:23:42.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/9be1dd1c09965f194d6ee17811d36305d4c9679f', 'message': 'Updated from global requirements\n\nChange-Id: I1eacb700c9f6fc8106a4bf3d26a638c7e4f6c017\n'}]",0,256499,9be1dd1c09965f194d6ee17811d36305d4c9679f,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I1eacb700c9f6fc8106a4bf3d26a638c7e4f6c017
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/99/256499/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9be1dd1c09965f194d6ee17811d36305d4c9679f,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.reports~master~I9e7c935b46ecc94f92441ffb769b6a7e5bf88300,openstack/oslo.reports,master,I9e7c935b46ecc94f92441ffb769b6a7e5bf88300,Updated from global requirements,MERGED,2015-12-11 15:24:30.000000000,2015-12-12 21:03:35.000000000,2015-12-12 21:03:34.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:24:30.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.reports/commit/763f7dbc6eccb6283712079090ccef3e5b7da80f', 'message': 'Updated from global requirements\n\nChange-Id: I9e7c935b46ecc94f92441ffb769b6a7e5bf88300\n'}]",0,256508,763f7dbc6eccb6283712079090ccef3e5b7da80f,10,3,1,11131,,,0,"Updated from global requirements

Change-Id: I9e7c935b46ecc94f92441ffb769b6a7e5bf88300
",git fetch https://review.opendev.org/openstack/oslo.reports refs/changes/08/256508/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,763f7dbc6eccb6283712079090ccef3e5b7da80f,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.messaging~master~Ifd78016c067740477a82dbe06d74d5944ba91893,openstack/oslo.messaging,master,Ifd78016c067740477a82dbe06d74d5944ba91893,Updated from global requirements,MERGED,2015-12-11 15:24:06.000000000,2015-12-12 21:00:49.000000000,2015-12-12 21:00:47.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:24:06.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a5d78891745b6b9e5827271dc305f00acae1392f', 'message': 'Updated from global requirements\n\nChange-Id: Ifd78016c067740477a82dbe06d74d5944ba91893\n'}]",0,256503,a5d78891745b6b9e5827271dc305f00acae1392f,12,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ifd78016c067740477a82dbe06d74d5944ba91893
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/03/256503/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,a5d78891745b6b9e5827271dc305f00acae1392f,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.log~master~I2b1ec8436e643fd13cbdef728efef07842fc758f,openstack/oslo.log,master,I2b1ec8436e643fd13cbdef728efef07842fc758f,Updated from global requirements,MERGED,2015-12-11 15:24:02.000000000,2015-12-12 20:46:43.000000000,2015-12-12 20:46:41.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-11 15:24:02.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/9ed395912d1f5563b1679eb72e8576ee03754325', 'message': 'Updated from global requirements\n\nChange-Id: I2b1ec8436e643fd13cbdef728efef07842fc758f\n'}]",0,256502,9ed395912d1f5563b1679eb72e8576ee03754325,7,2,1,11131,,,0,"Updated from global requirements

Change-Id: I2b1ec8436e643fd13cbdef728efef07842fc758f
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/02/256502/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,9ed395912d1f5563b1679eb72e8576ee03754325,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fpython-searchlightclient~master~I1efe914e9665d437afc7fdaf689c64674ea30be1,openstack/python-searchlightclient,master,I1efe914e9665d437afc7fdaf689c64674ea30be1,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:31:18.000000000,2015-12-12 20:44:19.000000000,2015-12-12 20:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 11356}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:31:18.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-searchlightclient/commit/855619f579eadfe254b42f0a3d284de1e89c377f', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I1efe914e9665d437afc7fdaf689c64674ea30be1\n'}]",0,256824,855619f579eadfe254b42f0a3d284de1e89c377f,8,5,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I1efe914e9665d437afc7fdaf689c64674ea30be1
",git fetch https://review.opendev.org/openstack/python-searchlightclient refs/changes/24/256824/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,855619f579eadfe254b42f0a3d284de1e89c377f,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fironic~master~I47a41fcb1e6b5ee7c8fb7fd4f895e60d43f36286,openstack/ironic,master,I47a41fcb1e6b5ee7c8fb7fd4f895e60d43f36286,Use 'service_type' of 'network'. Not 'neutron',MERGED,2015-12-11 14:03:50.000000000,2015-12-12 20:40:39.000000000,2015-12-12 20:40:38.000000000,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 14629}, {'_account_id': 14760}, {'_account_id': 17130}]","[{'number': 1, 'created': '2015-12-11 14:03:50.000000000', 'files': ['ironic/dhcp/neutron.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/f4a7a847b7c3cd1aa43ec600c6d4cd51ed796145', 'message': ""Use 'service_type' of 'network'. Not 'neutron'\n\n'neutron' is not a 'service_type' in keystone. 'network' is the correct\n'service_type' to use.\n\nCloses-Bug: #1525222\nChange-Id: I47a41fcb1e6b5ee7c8fb7fd4f895e60d43f36286\n""}]",0,256420,f4a7a847b7c3cd1aa43ec600c6d4cd51ed796145,21,7,1,14760,,,0,"Use 'service_type' of 'network'. Not 'neutron'

'neutron' is not a 'service_type' in keystone. 'network' is the correct
'service_type' to use.

Closes-Bug: #1525222
Change-Id: I47a41fcb1e6b5ee7c8fb7fd4f895e60d43f36286
",git fetch https://review.opendev.org/openstack/ironic refs/changes/20/256420/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/dhcp/neutron.py'],1,f4a7a847b7c3cd1aa43ec600c6d4cd51ed796145,, params['endpoint_url'] = ( CONF.neutron.url or keystone.get_service_url(service_type='network')), params['endpoint_url'] = (CONF.neutron.url or keystone.get_service_url('neutron')),3,2
openstack%2Foslo.versionedobjects~stable%2Fliberty~Ie8eea76672a2d7235c6cb3a42876cfe2f6287afe,openstack/oslo.versionedobjects,stable/liberty,Ie8eea76672a2d7235c6cb3a42876cfe2f6287afe,Updated from global requirements,MERGED,2015-12-10 18:40:51.000000000,2015-12-12 20:37:14.000000000,2015-12-12 20:37:14.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-10 18:40:51.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/30f17e013e7a80dede51f55d3f1548f23765e0ea', 'message': 'Updated from global requirements\n\nChange-Id: Ie8eea76672a2d7235c6cb3a42876cfe2f6287afe\n'}]",0,256048,30f17e013e7a80dede51f55d3f1548f23765e0ea,13,4,1,11131,,,0,"Updated from global requirements

Change-Id: Ie8eea76672a2d7235c6cb3a42876cfe2f6287afe
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/48/256048/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,30f17e013e7a80dede51f55d3f1548f23765e0ea,openstack/requirements,"oslo.messaging!=1.17.0,!=1.17.1,!=2.6.0,!=2.6.1,!=2.7.0,!=2.8.0,!=2.8.1,!=2.9.0,!=3.1.0,>=1.16.0 # Apache-2.0","oslo.messaging!=1.17.0,!=1.17.1,!=2.6.0,!=2.6.1,!=2.7.0,!=2.8.0,!=2.8.1,!=2.9.0,>=1.16.0 # Apache-2.0",1,1
openstack%2Fproject-config~master~I9999089905d68533531c219c84625d29002665f0,openstack/project-config,master,I9999089905d68533531c219c84625d29002665f0,Increase Python jobs timeout for Gnocchi,ABANDONED,2015-12-09 10:35:38.000000000,2015-12-12 20:28:34.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2813}, {'_account_id': 6537}, {'_account_id': 6547}, {'_account_id': 7729}, {'_account_id': 11564}]","[{'number': 1, 'created': '2015-12-09 10:35:38.000000000', 'files': ['jenkins/jobs/gnocchi.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/64ebec3178c7707576aa45fde63dae639741058e', 'message': ""Increase Python jobs timeout for Gnocchi\n\nGnocchi Python jobs runs the whole test suite several time for different\nindex and storage back-ends, which takes around 40 minutes. This was\npicked because having ~6 Python jobs was considered too much.\n\nBut the default timeout of 40 minutes is a just and sometimes our job\nfails because of that. Let's be generous.\n\nChange-Id: I9999089905d68533531c219c84625d29002665f0\n""}]",0,255196,64ebec3178c7707576aa45fde63dae639741058e,11,8,1,1669,,,0,"Increase Python jobs timeout for Gnocchi

Gnocchi Python jobs runs the whole test suite several time for different
index and storage back-ends, which takes around 40 minutes. This was
picked because having ~6 Python jobs was considered too much.

But the default timeout of 40 minutes is a just and sometimes our job
fails because of that. Let's be generous.

Change-Id: I9999089905d68533531c219c84625d29002665f0
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/255196/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/gnocchi.yaml'],1,64ebec3178c7707576aa45fde63dae639741058e,jd/gnocchi-more-timeout, - job-template: name: '{pipeline}-gnocchi-python27' wrappers: - build-timeout: timeout: 60 - job-template: name: '{pipeline}-gnocchi-python34' wrappers: - build-timeout: timeout: 60,,14,0
openstack%2Fsearchlight~master~Ia7db13132a94d55ebef99fd27bed62f1d75f63b1,openstack/searchlight,master,Ia7db13132a94d55ebef99fd27bed62f1d75f63b1,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:34:36.000000000,2015-12-12 20:19:45.000000000,2015-12-12 20:19:45.000000000,"[{'_account_id': 3}, {'_account_id': 7665}, {'_account_id': 11356}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:34:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/3fae02ffdfc4fdb18765f47b11ab8263e9d73fb1', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ia7db13132a94d55ebef99fd27bed62f1d75f63b1\n'}]",0,256832,3fae02ffdfc4fdb18765f47b11ab8263e9d73fb1,8,4,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ia7db13132a94d55ebef99fd27bed62f1d75f63b1
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/32/256832/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,3fae02ffdfc4fdb18765f47b11ab8263e9d73fb1,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Foslo.concurrency~master~I2f5de70cc6086af4b74c8c5a1266d06c60728a9d,openstack/oslo.concurrency,master,I2f5de70cc6086af4b74c8c5a1266d06c60728a9d,Updated from global requirements,MERGED,2015-12-11 15:23:47.000000000,2015-12-12 20:01:49.000000000,2015-12-12 20:01:48.000000000,"[{'_account_id': 3}, {'_account_id': 708}]","[{'number': 1, 'created': '2015-12-11 15:23:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/0c81dd6b5ea2b9d1270513ea0cc022c59dd9f9ad', 'message': 'Updated from global requirements\n\nChange-Id: I2f5de70cc6086af4b74c8c5a1266d06c60728a9d\n'}]",0,256500,0c81dd6b5ea2b9d1270513ea0cc022c59dd9f9ad,9,2,1,11131,,,0,"Updated from global requirements

Change-Id: I2f5de70cc6086af4b74c8c5a1266d06c60728a9d
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/00/256500/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,0c81dd6b5ea2b9d1270513ea0cc022c59dd9f9ad,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.policy~master~I7e199987321c528d8f13998020507755a17a2c29,openstack/oslo.policy,master,I7e199987321c528d8f13998020507755a17a2c29,Make sure item of policy_dirs is directory,MERGED,2015-12-08 08:25:17.000000000,2015-12-12 19:37:27.000000000,2015-12-12 19:37:26.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 5638}, {'_account_id': 6482}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-08 08:25:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/a475547465bb70b5fdf979553595579d9b9e700d', 'message': 'Make sure item of policy_dirs is directory\n\nCheck item of policy_dirs is directory, if not raise\nValueError.\n\nCloses-Bug: #1401302\nChange-Id: I7e199987321c528d8f13998020507755a17a2c29\n'}, {'number': 2, 'created': '2015-12-12 06:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/21d898a96a608e605ef830061ce16941b433593d', 'message': ""Make sure item of policy_dirs is directory\n\nWe skip path which was not found in config option policy_dirs, but don't check if the path is a directory. If path is not directory, a confusing  exception StopIteration,  This commit checks that and raise ValueError if path is not a directory.\n\nCloses-Bug: #1401302\nChange-Id: I7e199987321c528d8f13998020507755a17a2c29\n""}, {'number': 3, 'created': '2015-12-12 06:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/6f122b9b8f802fd18321d638c14ae26f21086b9c', 'message': ""Make sure item of policy_dirs is directory\n\nWe skip path which was not found in config option policy_dirs, but don't\ncheck if the path is a directory. If path is not directory, a confusing\nexception StopIteration,  This commit checks that and raise ValueError\nif path is not a directory.\n\nCloses-Bug: #1401302\nChange-Id: I7e199987321c528d8f13998020507755a17a2c29\n""}, {'number': 4, 'created': '2015-12-12 07:27:19.000000000', 'files': ['oslo_policy/policy.py', 'oslo_policy/tests/test_policy.py'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/01e4c3628ba72a5674baec75e69db1389303715a', 'message': ""Make sure item of policy_dirs is directory\n\nWe skip path which was not found in config option policy_dirs, but don't\ncheck if the path is a directory. If path is not directory, a confusing\nexception StopIteration,  This commit checks that and raise ValueError\nif path is not a directory.\n\nCloses-Bug: #1401302\nChange-Id: I7e199987321c528d8f13998020507755a17a2c29\n""}]",8,254607,01e4c3628ba72a5674baec75e69db1389303715a,17,5,4,9796,,,0,"Make sure item of policy_dirs is directory

We skip path which was not found in config option policy_dirs, but don't
check if the path is a directory. If path is not directory, a confusing
exception StopIteration,  This commit checks that and raise ValueError
if path is not a directory.

Closes-Bug: #1401302
Change-Id: I7e199987321c528d8f13998020507755a17a2c29
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/07/254607/3 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_policy/policy.py', 'oslo_policy/tests/test_policy.py']",2,a475547465bb70b5fdf979553595579d9b9e700d,bug/1401302," def test_load_policy_dirs_with_non_directory(self): self.create_config_file('policy.d/a.conf', POLICY_A_CONTENTS) self.conf.set_override('policy_dirs', ['policy.d/a.conf'], group='oslo_policy') self.assertRaises(ValueError, self.enforcer.load_rules, True) ",,9,0
openstack%2Foslo.config~master~Ie7b03cc85c8e170be5cb7756b01bb3801ca172fa,openstack/oslo.config,master,Ie7b03cc85c8e170be5cb7756b01bb3801ca172fa,Correct the docstring parameters for PortOpt,MERGED,2015-12-10 23:33:48.000000000,2015-12-12 19:05:34.000000000,2015-12-12 19:05:33.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 8119}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-10 23:33:48.000000000', 'files': ['oslo_config/cfg.py'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/1298badaea6fd4a609e2434e6b4d482cd02f69ee', 'message': 'Correct the docstring parameters for PortOpt\n\nThe docs for PortOpt are misleading.  The min and max values are\nnot actually parameters.  They are statically set and do not permit\nan override.  Also, the newly added choices parameter is missing\nfrom the doc.\n\nChange-Id: Ie7b03cc85c8e170be5cb7756b01bb3801ca172fa\n'}]",0,256137,1298badaea6fd4a609e2434e6b4d482cd02f69ee,14,4,1,8119,,,0,"Correct the docstring parameters for PortOpt

The docs for PortOpt are misleading.  The min and max values are
not actually parameters.  They are statically set and do not permit
an override.  Also, the newly added choices parameter is missing
from the doc.

Change-Id: Ie7b03cc85c8e170be5cb7756b01bb3801ca172fa
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/37/256137/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_config/cfg.py'],1,1298badaea6fd4a609e2434e6b4d482cd02f69ee,invalid_docs, :param choices: Optional sequence of valid values., :param min: minimum port number the option can take :param max: maximum port number the option can take,1,2
openstack%2Foslo-incubator~master~Idd2c840a2b3d9fb939b5450c40cea2cbf0302edb,openstack/oslo-incubator,master,Idd2c840a2b3d9fb939b5450c40cea2cbf0302edb,Updated from global requirements,MERGED,2015-12-11 15:23:39.000000000,2015-12-12 18:49:47.000000000,2015-12-12 18:49:47.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-11 15:23:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo-incubator/commit/c2d39c896ca5e49349a2836403b52b39857c4d18', 'message': 'Updated from global requirements\n\nChange-Id: Idd2c840a2b3d9fb939b5450c40cea2cbf0302edb\n'}]",0,256498,c2d39c896ca5e49349a2836403b52b39857c4d18,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Idd2c840a2b3d9fb939b5450c40cea2cbf0302edb
",git fetch https://review.opendev.org/openstack/oslo-incubator refs/changes/98/256498/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c2d39c896ca5e49349a2836403b52b39857c4d18,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fceilometer~master~I52febba468bbdbaa4e501b9bb61374fa6ab45e9e,openstack/ceilometer,master,I52febba468bbdbaa4e501b9bb61374fa6ab45e9e,messaging: stop using RequestContextSerializer,MERGED,2015-11-30 08:42:14.000000000,2015-12-12 18:14:44.000000000,2015-12-12 18:14:42.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2284}, {'_account_id': 2472}, {'_account_id': 2813}, {'_account_id': 3012}, {'_account_id': 4491}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7478}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 9562}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 13560}, {'_account_id': 15843}, {'_account_id': 16949}]","[{'number': 1, 'created': '2015-11-30 08:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/19f6d2bc9c2d2f8042ca140dc03bf49fb45a3b59', 'message': ""messaging: stop using RequestContextSerializer\n\nThis has been deprecated from oslo.messaging, let's explicitly use it.\n\nChange-Id: I52febba468bbdbaa4e501b9bb61374fa6ab45e9e\n""}, {'number': 2, 'created': '2015-11-30 11:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/131bd98ad1d4c1eb3bc404e8fa3b79324fca7fc0', 'message': ""messaging: stop using RequestContextSerializer\n\nThis has been deprecated from oslo.messaging, let's explicitly use it.\n\nChange-Id: I52febba468bbdbaa4e501b9bb61374fa6ab45e9e\n""}, {'number': 3, 'created': '2015-12-01 13:22:36.000000000', 'files': ['ceilometer/messaging.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/e74ba770d033fd9e3feafaa0b28e5b5cb5a39e51', 'message': ""messaging: stop using RequestContextSerializer\n\nThis has been deprecated from oslo.messaging, let's explicitly use it.\n\nChange-Id: I52febba468bbdbaa4e501b9bb61374fa6ab45e9e\n""}]",0,251241,e74ba770d033fd9e3feafaa0b28e5b5cb5a39e51,17,19,3,1669,,,0,"messaging: stop using RequestContextSerializer

This has been deprecated from oslo.messaging, let's explicitly use it.

Change-Id: I52febba468bbdbaa4e501b9bb61374fa6ab45e9e
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/41/251241/3 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/messaging.py'],1,19f6d2bc9c2d2f8042ca140dc03bf49fb45a3b59,jd/remove-req-context-serializer,"# Copyright 2013-2015 eNovance <licensing@enovance.com>from oslo_context import contextclass RequestContextSerializer(oslo_messaging.Serializer): def __init__(self, base): self._base = base def serialize_entity(self, context, entity): if not self._base: return entity return self._base.serialize_entity(context, entity) def deserialize_entity(self, context, entity): if not self._base: return entity return self._base.deserialize_entity(context, entity) def serialize_context(self, context): return context.to_dict() def deserialize_context(self, context): return context.RequestContext.from_dict(context) serializer = RequestContextSerializer( serializer = RequestContextSerializer( serializer = RequestContextSerializer(",# Copyright 2013 eNovance <licensing@enovance.com> serializer = oslo_serializer.RequestContextSerializer( serializer = oslo_serializer.RequestContextSerializer( serializer = oslo_serializer.RequestContextSerializer(,27,4
openstack%2Foslo.config~master~I47ffde7bca5e4e345544cb930382e711ac79dc3e,openstack/oslo.config,master,I47ffde7bca5e4e345544cb930382e711ac79dc3e,Removes MANIFEST.in as it is not needed explicitely by PBR,MERGED,2015-12-11 09:33:46.000000000,2015-12-12 17:07:29.000000000,2015-12-12 17:07:28.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 8119}, {'_account_id': 15699}]","[{'number': 1, 'created': '2015-12-11 09:33:46.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/oslo.config/commit/cf7583e0fac7068ef03554298d52dda222716f0c', 'message': 'Removes MANIFEST.in as it is not needed explicitely by PBR\n\nThis patch removes `MANIFEST.in` file as pbr generates a sensible\nmanifest from git files and some standard files and it removes\nthe need for an explicit `MANIFEST.in` file.\n\nChange-Id: I47ffde7bca5e4e345544cb930382e711ac79dc3e\n'}]",0,256305,cf7583e0fac7068ef03554298d52dda222716f0c,14,5,1,15699,,,0,"Removes MANIFEST.in as it is not needed explicitely by PBR

This patch removes `MANIFEST.in` file as pbr generates a sensible
manifest from git files and some standard files and it removes
the need for an explicit `MANIFEST.in` file.

Change-Id: I47ffde7bca5e4e345544cb930382e711ac79dc3e
",git fetch https://review.opendev.org/openstack/oslo.config refs/changes/05/256305/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,cf7583e0fac7068ef03554298d52dda222716f0c,DROP_MANIFEST,,include AUTHORS include ChangeLog include LICENSE include README.rst include tox.ini .testr.conf recursive-include tests * recursive-include tools * recursive-include doc * exclude .gitignore exclude .gitreview global-exclude *.pyc ,0,13
openstack%2Fapi-site~master~Id9068dd49a97b282466242f06e765b532f150a72,openstack/api-site,master,Id9068dd49a97b282466242f06e765b532f150a72,Add detailed info to instance and server name,MERGED,2015-12-10 13:15:19.000000000,2015-12-12 16:48:14.000000000,2015-12-12 16:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 6062}, {'_account_id': 16237}, {'_account_id': 17207}]","[{'number': 1, 'created': '2015-12-10 13:15:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/bc1b7b04cb8574dbf718746f1070ed0cbc2c29cf', 'message': ""Add detailed info to instance and server name\n\nInstance and server name is different from nova perspective, but\nend user might don't know it, add more into to both of the fields.\n\nChange-Id: Id9068dd49a97b282466242f06e765b532f150a72\nPartial-Bug: #1515222\n""}, {'number': 2, 'created': '2015-12-12 01:38:40.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/1f5711bf13535c6890e349a7da2b52822b10ae8b', 'message': ""Add detailed info to instance and server name\n\nInstance and server name is different from nova perspective, but\nend user might don't know it, add more into to both of the fields.\n\nChange-Id: Id9068dd49a97b282466242f06e765b532f150a72\nPartial-Bug: #1515222\n""}]",2,255868,1f5711bf13535c6890e349a7da2b52822b10ae8b,16,5,2,6062,,,0,"Add detailed info to instance and server name

Instance and server name is different from nova perspective, but
end user might don't know it, add more into to both of the fields.

Change-Id: Id9068dd49a97b282466242f06e765b532f150a72
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/68/255868/2 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/common.ent'],1,bc1b7b04cb8574dbf718746f1070ed0cbc2c29cf,fix-compute-api-ref," <para>The server name, it is set by user.</para> <para>The instance name, it is set by nova generated from instance name template.</para>", <para>The server name.</para> <para>The instance name.</para>,2,2
openstack%2Fheat~master~Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c,openstack/heat,master,Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c,Use specified client service name for client usage,MERGED,2015-11-27 09:07:39.000000000,2015-12-12 16:30:58.000000000,2015-12-12 16:30:56.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 8289}, {'_account_id': 8833}, {'_account_id': 12363}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 13720}]","[{'number': 1, 'created': '2015-11-27 09:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/09d538cc37ae1ab1f1acbe722e6770a5e87011a3', 'message': 'Use single specified-service name for client usage\n\nCreate SERVICE_NAME for every client, which can be used to replace seperated\nstring for service name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 2, 'created': '2015-11-27 09:08:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1923c055735bc0edeae56bd83e53d8870692131a', 'message': 'Use specified service name for client usage\n\nCreate SERVICE_NAME for every client, which can be used to replace seperated\nstring for service name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 3, 'created': '2015-11-27 10:48:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/a98d6388f9da82d527cd4f3e439acfb16999e119', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 4, 'created': '2015-11-29 14:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ed0f59cc5bd04f7dbb9859b8e4f53af6ccb07e80', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 5, 'created': '2015-12-09 13:54:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f874bf385e4c132400e543f918a08505990c8f3c', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 6, 'created': '2015-12-09 15:14:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/4847433a925f9a5ce6b68188b80998a0b2627a48', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 7, 'created': '2015-12-10 13:06:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/67b28c7bc81500691c5da36a5ec74e349d9b429d', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}, {'number': 8, 'created': '2015-12-11 02:12:14.000000000', 'files': ['heat/engine/clients/os/heat_plugin.py', 'heat/engine/clients/os/swift.py', 'heat/engine/clients/os/zaqar.py', 'heat/engine/clients/os/senlin.py', 'heat/engine/clients/os/ceilometer.py', 'heat/engine/clients/os/manila.py', 'heat/engine/clients/os/glance.py', 'heat/engine/clients/os/monasca.py', 'heat/engine/clients/os/cinder.py', 'heat/engine/clients/os/designate.py', 'heat/engine/clients/os/keystone.py', 'heat/engine/clients/os/mistral.py', 'heat/engine/clients/os/neutron/lbaas_constraints.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/barbican.py', 'heat/engine/clients/os/magnum.py', 'heat/engine/clients/os/neutron/neutron_constraints.py', 'heat/engine/clients/os/sahara.py', 'heat/engine/clients/os/trove.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/bed7e1f7c969945a50c51cb1a9c2dbfd43cf1cd9', 'message': 'Use specified client service name for client usage\n\nCreate CLIENT_NAME for every client, which can be used to replace seperated\nstring for service client name.\n\nChange-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c\n'}]",7,250687,bed7e1f7c969945a50c51cb1a9c2dbfd43cf1cd9,48,8,8,12404,,,0,"Use specified client service name for client usage

Create CLIENT_NAME for every client, which can be used to replace seperated
string for service client name.

Change-Id: Id8425e8cca3ad9cea5f7364fdf057260e1d8f27c
",git fetch https://review.opendev.org/openstack/heat refs/changes/87/250687/8 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/heat_plugin.py', 'heat/engine/clients/os/swift.py', 'heat/engine/clients/os/zaqar.py', 'heat/engine/clients/os/senlin.py', 'heat/engine/clients/os/ceilometer.py', 'heat/engine/clients/os/manila.py', 'heat/engine/clients/os/glance.py', 'heat/engine/clients/os/cinder.py', 'heat/engine/clients/os/designate.py', 'heat/engine/clients/os/mistral.py', 'heat/engine/clients/os/neutron/lbaas_constraints.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/barbican.py', 'heat/engine/clients/os/magnum.py', 'heat/engine/clients/os/neutron/neutron_constraints.py', 'heat/engine/clients/os/sahara.py', 'heat/engine/clients/os/trove.py']",17,09d538cc37ae1ab1f1acbe722e6770a5e87011a3,specified-client-service-name," endpoint_type = self._get_client_option(SERVICE_NAME, 'endpoint_type') 'cacert': self._get_client_option(SERVICE_NAME, 'ca_file'), 'insecure': self._get_client_option(SERVICE_NAME, 'insecure'),"," endpoint_type = self._get_client_option('trove', 'endpoint_type') 'cacert': self._get_client_option('trove', 'ca_file'), 'insecure': self._get_client_option('trove', 'insecure'),",70,50
openstack%2Fmonasca-api~master~I43be2125e56a93381aa626aea6903a64a9353779,openstack/monasca-api,master,I43be2125e56a93381aa626aea6903a64a9353779,Revert back to try-with-resources statement,MERGED,2015-12-10 20:12:42.000000000,2015-12-12 16:20:14.000000000,2015-12-12 16:20:11.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}]","[{'number': 1, 'created': '2015-12-10 20:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/5812223df6639b87fa5ee05369d589c7cc2c85ed', 'message': 'Revert back to try-with-resources statement\n\nRevert changes that attempted to make sure that DB\nconnections are closed. The original code used the\njava try-with-resources statement which automatically\ncalls close() on the resource in the try call.\n\nChange-Id: I43be2125e56a93381aa626aea6903a64a9353779\n'}, {'number': 2, 'created': '2015-12-10 20:20:06.000000000', 'files': ['java/src/main/java/monasca/api/infrastructure/persistence/vertica/StatisticVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/AlarmStateHistoryVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/MetricDefinitionVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/MeasurementVerticaRepoImpl.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/962bdd6effd6b4cd8f74bd3ced203a71e01d6a32', 'message': 'Revert back to try-with-resources statement\n\nRevert changes that attempted to make sure that DB\nconnections are closed. The original code used the\njava try-with-resources statement which automatically\ncalls close() on the resource in the try call.\n\nChange-Id: I43be2125e56a93381aa626aea6903a64a9353779\n'}]",0,256080,962bdd6effd6b4cd8f74bd3ced203a71e01d6a32,8,4,2,12512,,,0,"Revert back to try-with-resources statement

Revert changes that attempted to make sure that DB
connections are closed. The original code used the
java try-with-resources statement which automatically
calls close() on the resource in the try call.

Change-Id: I43be2125e56a93381aa626aea6903a64a9353779
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/80/256080/2 && git format-patch -1 --stdout FETCH_HEAD,"['java/src/main/java/monasca/api/infrastructure/persistence/vertica/StatisticVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/AlarmStateHistoryVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/MetricDefinitionVerticaRepoImpl.java', 'java/src/main/java/monasca/api/infrastructure/persistence/vertica/MeasurementVerticaRepoImpl.java']",4,5812223df6639b87fa5ee05369d589c7cc2c85ed,bug/fix-db-close-overcorrection, try (Handle h = db.open()) {, Handle h = null; try { h = db.open(); } finally { if (null != h) { h.close(); },9,44
openstack%2Fmagnum~master~I48bfb0043dd15b4e76a9c354144786d710e64440,openstack/magnum,master,I48bfb0043dd15b4e76a9c354144786d710e64440,Add Kubernetes podmaster,MERGED,2015-11-12 23:03:27.000000000,2015-12-12 15:42:19.000000000,2015-12-12 15:42:18.000000000,"[{'_account_id': 3}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 12385}]","[{'number': 1, 'created': '2015-11-12 23:03:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a92f9b0901c04a0a2156889b566ae790766450b3', 'message': 'Add Kubernetes podmaster\n\nFor HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)\npodmaster need to run at every master node\n\nChange-Id: I48bfb0043dd15b4e76a9c354144786d710e64440\nPartially-Implements: blueprint run-kube-as-container\n'}, {'number': 2, 'created': '2015-11-12 23:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d9626028669ae4d83729718dd0f96a4de57efde5', 'message': '[WIP] Add Kubernetes podmaster\n\nFor HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)\npodmaster need to run at every master node\n\nChange-Id: I48bfb0043dd15b4e76a9c354144786d710e64440\nPartially-Implements: blueprint run-kube-as-container\n'}, {'number': 3, 'created': '2015-11-29 18:32:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6ccd2f48d3c26b6829a19580ee22b3b9d6b722a6', 'message': '[WIP] Add Kubernetes podmaster\n\nFor HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)\npodmaster need to run at every master node\n\nChange-Id: I48bfb0043dd15b4e76a9c354144786d710e64440\nPartially-Implements: blueprint run-kube-as-container\n'}, {'number': 4, 'created': '2015-12-01 01:21:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3e902a88c5e9bb364bc5ea4201cbf81def5ed96b', 'message': 'Add Kubernetes podmaster\n\nFor HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)\npodmaster need to run at every master node\n\nChange-Id: I48bfb0043dd15b4e76a9c354144786d710e64440\nPartially-Implements: blueprint run-kube-as-container\n'}, {'number': 5, 'created': '2015-12-09 07:31:07.000000000', 'files': ['magnum/templates/kubernetes/fragments/enable-kube-podmaster.sh', 'magnum/templates/kubernetes/fragments/kube-system-namespace-service.sh', 'magnum/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/templates/kubernetes/fragments/enable-services-master.sh', 'magnum/templates/kubernetes/kubemaster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/8a9f340d48e3a4a722ef3262c27eba0fdd084764', 'message': 'Add Kubernetes podmaster\n\nFor HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)\npodmaster need to run at every master node\n\nChange-Id: I48bfb0043dd15b4e76a9c354144786d710e64440\nPartially-Implements: blueprint run-kube-as-container\n'}]",30,244907,8a9f340d48e3a4a722ef3262c27eba0fdd084764,43,7,5,8143,,,0,"Add Kubernetes podmaster

For HA (http://kubernetes.io/v1.0/docs/admin/high-availability.html)
podmaster need to run at every master node

Change-Id: I48bfb0043dd15b4e76a9c354144786d710e64440
Partially-Implements: blueprint run-kube-as-container
",git fetch https://review.opendev.org/openstack/magnum refs/changes/07/244907/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/templates/kubernetes/fragments/enable-services-master.sh', 'magnum/templates/kubernetes/kubemaster.yaml', 'magnum/templates/kubernetes/fragments/podmaster.yaml']",4,a92f9b0901c04a0a2156889b566ae790766450b3,bp/run-kube-as-container,"#cloud-config merge_how: dict(recurse_array)+list(append) write_files: - path: /srv/kubernetes/podmaster.yaml owner: ""root:root"" permissions: ""0644"" content: | apiVersion: v1 kind: Pod metadata: name: scheduler-master spec: hostNetwork: true containers: - name: scheduler-elector image: gcr.io/google_containers/podmaster:1.1 command: - /podmaster - --etcd-servers=http://127.0.0.1:4001 - --key=scheduler - --source-file=/kubernetes/kube-scheduler.manifest - --dest-file=/manifests/kube-scheduler.manifest volumeMounts: - mountPath: /kubernetes name: k8s readOnly: true - mountPath: /manifests name: manifests - name: controller-manager-elector image: gcr.io/google_containers/podmaster:1.1 command: - /podmaster - --etcd-servers=http://127.0.0.1:4001 - --key=controller - --source-file=/kubernetes/kube-controller-manager.manifest - --dest-file=/manifests/kube-controller-manager.manifest terminationMessagePath: /dev/termination-log volumeMounts: - mountPath: /kubernetes name: k8s readOnly: true - mountPath: /manifests name: manifests volumes: - hostPath: path: /srv/kubernetes name: k8s - hostPath: path: /etc/kubernetes/manifests name: manifests",,65,1
openstack%2Frally~master~I6cbad849b8ed7013ff02e67737e3b182ee6376fd,openstack/rally,master,I6cbad849b8ed7013ff02e67737e3b182ee6376fd,[feature request] Add possibility to specify concurrency for Tempest,MERGED,2015-12-11 13:09:39.000000000,2015-12-12 14:36:46.000000000,2015-12-12 14:36:45.000000000,"[{'_account_id': 3}, {'_account_id': 6509}, {'_account_id': 7428}, {'_account_id': 8851}, {'_account_id': 9545}, {'_account_id': 14356}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-12-11 13:09:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/1fa9023a1d0826e349ef61c89b84e6a2d690e00e', 'message': '[feature request] Add possibility to specify concurrency for Tempest\n\nUser should be able to set concurrency for Tempest tests.\n\nChange-Id: I6cbad849b8ed7013ff02e67737e3b182ee6376fd\n'}, {'number': 2, 'created': '2015-12-11 13:12:04.000000000', 'files': ['doc/feature_request/add_possibility_to_specify_concurrency_for_tempest.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/ad1ea0defe0a043ce1129dbd5f12cf9948850ccc', 'message': '[feature request] Add possibility to specify concurrency for Tempest\n\nUser should be able to set concurrency for Tempest tests.\n\nChange-Id: I6cbad849b8ed7013ff02e67737e3b182ee6376fd\n'}]",0,256397,ad1ea0defe0a043ce1129dbd5f12cf9948850ccc,25,7,2,8851,,,0,"[feature request] Add possibility to specify concurrency for Tempest

User should be able to set concurrency for Tempest tests.

Change-Id: I6cbad849b8ed7013ff02e67737e3b182ee6376fd
",git fetch https://review.opendev.org/openstack/rally refs/changes/97/256397/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/feature_request/add_possibility_to_specify_concurrency_for_tempest.rst'],1,1fa9023a1d0826e349ef61c89b84e6a2d690e00e,,"======================================== Running Tempest using custom concurrency ======================================== Use case -------- User might want to use specific concurrency for running tests based on his deployment and available resources. Problem description ------------------- # ""rally verify start"" command does not allow to specify concurrency # for tempest tests. And they always run using concurrency equal # to amount of CPU cores. Possible solution ----------------- #. Add ``--concurrency`` option to ""rally verify start"" command. ",,24,0
openstack%2Fmagnum~master~Iac20023f0448aab313302c174e3743b95cd42d7a,openstack/magnum,master,Iac20023f0448aab313302c174e3743b95cd42d7a,The type of number_of_masters should be int not string,MERGED,2015-12-10 02:08:19.000000000,2015-12-12 14:21:30.000000000,2015-12-12 14:21:28.000000000,"[{'_account_id': 3}, {'_account_id': 7049}, {'_account_id': 7494}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 10263}, {'_account_id': 12175}, {'_account_id': 18386}]","[{'number': 1, 'created': '2015-12-10 02:08:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9db6ac3ce3fc37331798b1c407b84bea19cfcb29', 'message': 'The type of number_of_masters should be int not string\n\nThe type of number_of_master should be int not string.\n\nChange-Id: Iac20023f0448aab313302c174e3743b95cd42d7a\nCloses-Bug: #1524236\n'}, {'number': 2, 'created': '2015-12-10 10:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/f6bfbd12cd935d3ed9bed4e1eb60b231b5456cb1', 'message': 'The type of number_of_masters should be int not string\n\nnumber_of_masters, number_of_minions and number_of_nodes should be number, not string.\n\nChange-Id: Iac20023f0448aab313302c174e3743b95cd42d7a\nCloses-Bug: #1524236\n'}, {'number': 3, 'created': '2015-12-10 10:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/33b5f6148f8a5552274c9d253d4dba317b46df8a', 'message': 'The type of number_of_masters should be int not string\n\nnumber_of_masters, number_of_minions and number_of_nodes\n should be number, not string.\n\nChange-Id: Iac20023f0448aab313302c174e3743b95cd42d7a\nCloses-Bug: #1524236\n'}, {'number': 4, 'created': '2015-12-10 10:41:21.000000000', 'files': ['magnum/templates/kubernetes/kubecluster-fedora-ironic.yaml', 'magnum/templates/kubernetes/kubecluster.yaml', 'magnum/templates/kubernetes/kubecluster-coreos.yaml', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/tests/unit/conductor/handlers/test_k8s_bay_conductor.py', 'magnum/tests/unit/conductor/handlers/test_mesos_bay_conductor.py', 'magnum/conductor/template_definition.py', 'magnum/tests/unit/conductor/handlers/test_swarm_bay_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/c5fc62ed28ea6cead11c19947400c968eed3cb72', 'message': 'The type of number_of_masters should be int not string\n\nnumber_of_masters, number_of_minions and number_of_nodes\nshould be number, not string.\n\nChange-Id: Iac20023f0448aab313302c174e3743b95cd42d7a\nCloses-Bug: #1524236\n'}]",1,255638,c5fc62ed28ea6cead11c19947400c968eed3cb72,23,8,4,12053,,,0,"The type of number_of_masters should be int not string

number_of_masters, number_of_minions and number_of_nodes
should be number, not string.

Change-Id: Iac20023f0448aab313302c174e3743b95cd42d7a
Closes-Bug: #1524236
",git fetch https://review.opendev.org/openstack/magnum refs/changes/38/255638/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/templates/kubernetes/kubecluster-fedora-ironic.yaml', 'magnum/templates/kubernetes/kubecluster.yaml', 'magnum/templates/kubernetes/kubecluster-coreos.yaml', 'magnum/templates/swarm/swarmcluster.yaml', 'magnum/tests/unit/conductor/handlers/test_k8s_bay_conductor.py', 'magnum/tests/unit/conductor/handlers/test_mesos_bay_conductor.py', 'magnum/conductor/template_definition.py', 'magnum/tests/unit/conductor/handlers/test_swarm_bay_conductor.py']",8,9db6ac3ce3fc37331798b1c407b84bea19cfcb29,bug/1524236," 'number_of_masters': 1, 'number_of_nodes': 1, 'number_of_masters': 1, 'number_of_nodes': 1,"," 'number_of_masters': '1', 'number_of_nodes': '1', 'number_of_masters': '1', 'number_of_nodes': '1',",28,32
openstack%2Fopenstack-manuals~master~Idec36d89b68534b48fbebac61e97caa8550ad3a5,openstack/openstack-manuals,master,Idec36d89b68534b48fbebac61e97caa8550ad3a5,[config-ref] Improvements for dell-equallogic-driver,MERGED,2015-12-12 09:17:52.000000000,2015-12-12 13:04:29.000000000,2015-12-12 13:04:27.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-12 09:17:52.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/dell-equallogic-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db86d92fe68fce55629ff8f5eb8ccb0d5f0834a9', 'message': '[config-ref] Improvements for dell-equallogic-driver\n\nChange-Id: Idec36d89b68534b48fbebac61e97caa8550ad3a5\n'}]",0,256921,db86d92fe68fce55629ff8f5eb8ccb0d5f0834a9,7,3,1,16237,,,0,"[config-ref] Improvements for dell-equallogic-driver

Change-Id: Idec36d89b68534b48fbebac61e97caa8550ad3a5
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/21/256921/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/block-storage/drivers/dell-equallogic-driver.rst'],1,db86d92fe68fce55629ff8f5eb8ccb0d5f0834a9,fix-devp," [DEFAULT] # Required settings volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver san_ip = IP_EQLX san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL # Optional settings san_thin_provision = true|false eqlx_use_chap = true|false eqlx_chap_login = EQLX_UNAME eqlx_chap_password = EQLX_PW eqlx_cli_max_retries = 5 san_ssh_port = 22 ssh_conn_timeout = 30 san_private_key = SAN_KEY_PATH ssh_min_pool_conn = 1 ssh_max_pool_conn = 5Multiple back-end configuration ------------------------------- enabled_backends = backend1,backend2 san_ssh_port = 22 ssh_conn_timeout = 30 san_thin_provision = true [backend1] volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver volume_backend_name = backend1 san_ip = IP_EQLX1 san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL [backend2] volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver volume_backend_name = backend2 san_ip = IP_EQLX2 san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL"," [DEFAULT] # Required settings volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver san_ip = IP_EQLX san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL # Optional settings san_thin_provision = true|false eqlx_use_chap = true|false eqlx_chap_login = EQLX_UNAME eqlx_chap_password = EQLX_PW eqlx_cli_max_retries = 5 san_ssh_port = 22 ssh_conn_timeout = 30 san_private_key = SAN_KEY_PATH ssh_min_pool_conn = 1 ssh_max_pool_conn = 5Multi back-end configuration ---------------------------- enabled_backends = backend1,backend2 san_ssh_port = 22 ssh_conn_timeout = 30 san_thin_provision = true [backend1] volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver volume_backend_name = backend1 san_ip = IP_EQLX1 san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL [backend2] volume_driver = cinder.volume.drivers.eqlx.DellEQLSanISCSIDriver volume_backend_name = backend2 san_ip = IP_EQLX2 san_login = SAN_UNAME san_password = SAN_PW eqlx_group_name = EQLX_GROUP eqlx_pool = EQLX_POOL",41,41
openstack%2Fgnocchi~master~I80c5ed0f6b1c9eef25095048b1fa4dd2b1a7ef90,openstack/gnocchi,master,I80c5ed0f6b1c9eef25095048b1fa4dd2b1a7ef90,retrieve resource with metric only when needed,MERGED,2015-11-30 19:27:05.000000000,2015-12-12 12:32:49.000000000,2015-12-12 12:32:48.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 6924}, {'_account_id': 8358}]","[{'number': 1, 'created': '2015-11-30 19:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/6414edb66e165ec725028230a30d4e23bd163ab1', 'message': 'retrieve resource with metric only when needed\n\nthere appears to be no reason for retrieve resource details\nalong with metric info when calling get_metrics. this patch\navoids retrieving resource data to minimise query load.\n\nChange-Id: I80c5ed0f6b1c9eef25095048b1fa4dd2b1a7ef90\n'}, {'number': 2, 'created': '2015-11-30 23:38:10.000000000', 'files': ['gnocchi/indexer/__init__.py', 'gnocchi/indexer/sqlalchemy.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/55535ccca5008127ee5f79273245885a6be2dcfa', 'message': 'retrieve resource with metric only when needed\n\nthere appears to be no reason for retrieve resource details\nalong with metric info when calling get_metrics. this patch\navoids retrieving resource data to minimise query load.\n\nChange-Id: I80c5ed0f6b1c9eef25095048b1fa4dd2b1a7ef90\n'}]",0,251512,55535ccca5008127ee5f79273245885a6be2dcfa,14,5,2,6537,,,0,"retrieve resource with metric only when needed

there appears to be no reason for retrieve resource details
along with metric info when calling get_metrics. this patch
avoids retrieving resource data to minimise query load.

Change-Id: I80c5ed0f6b1c9eef25095048b1fa4dd2b1a7ef90
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/12/251512/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/indexer/sqlalchemy.py'],1,6414edb66e165ec725028230a30d4e23bd163ab1,minimise-query," def get_metrics(self, uuids, active_only=True, with_resource=False): query = session.query(Metric).filter(Metric.id.in_(uuids)) if with_resource: query = query.options(sqlalchemy.orm.joinedload('resource'))"," def get_metrics(self, uuids, active_only=True): query = session.query(Metric).filter(Metric.id.in_(uuids)).options( sqlalchemy.orm.joinedload('resource'))",4,3
openstack%2Fopenstack-manuals~master~I6cf1f45f53610026c9e5e095a9cc4bb3599a415b,openstack/openstack-manuals,master,I6cf1f45f53610026c9e5e095a9cc4bb3599a415b,[config-ref] Improvements in the emc-vnx-driver.rst,MERGED,2015-12-11 13:35:38.000000000,2015-12-12 12:27:38.000000000,2015-12-12 12:27:36.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6772}, {'_account_id': 10497}, {'_account_id': 14962}, {'_account_id': 17832}]","[{'number': 1, 'created': '2015-12-11 13:35:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/3ba7a621d68ab075b7d44b34e4383dab8abfc0c0', 'message': '[config-ref] Improvements in the emc-vnx-driver.rst\n\nChange-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b\n'}, {'number': 2, 'created': '2015-12-11 13:53:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/13aa1cd09a7fda840afd63f643191a0932430bce', 'message': '[config-ref] Improvements in the emc-vnx-driver.rst\n\nChange-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b\n'}, {'number': 3, 'created': '2015-12-11 16:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/69683cc6ef7ea84fb02ff85e659e82182268776c', 'message': '[config-ref] Improvements in the emc-vnx-driver.rst\n\nChange-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b\n'}, {'number': 4, 'created': '2015-12-12 00:38:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/dfb777acb3fe412c1a51113363b96bfd46d6db41', 'message': '[config-ref] Improvements in the emc-vnx-driver.rst\n\nChange-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b\n'}, {'number': 5, 'created': '2015-12-12 08:05:41.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/emc-vnx-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2e9222bb434ed1bad668cbec18f7e113088da13b', 'message': '[config-ref] Improvements in the emc-vnx-driver.rst\n\nChange-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b\n'}]",24,256409,2e9222bb434ed1bad668cbec18f7e113088da13b,20,6,5,16237,,,0,"[config-ref] Improvements in the emc-vnx-driver.rst

Change-Id: I6cf1f45f53610026c9e5e095a9cc4bb3599a415b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/09/256409/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/block-storage/drivers/emc-vnx-driver.rst'],1,3ba7a621d68ab075b7d44b34e4383dab8abfc0c0,fix-dev,"and ``FCDriver`` defined in the Block Storage.executing Navisphere CLI (NaviSecCLI) which is a command-line interface used- VNX Snapshot and Thin Provisioning license should be activated for VNX. $ /opt/Navisphere/bin/naviseccli security -certificate -setLevel lowpage of :guilabel:`Storage System Properties`. Here is how it looks like:For the FC Driver, FC zoning is properly configured between the hosts and the VNX. Check :ref:`register-fc-port-with-vnx` for reference.Here is a sample of a minimum back-end configuration. See the following [DEFAULT] enabled_backends = vnx_array1 [vnx_array1] san_ip = 10.10.72.41 san_login = sysadmin san_password = sysadmin naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = TrueHere is a sample of a multi-backend configuration. See the following [DEFAULT] enabled_backends = backendA, backendB [backendA] storage_vnx_pool_names = Pool_01_SAS, Pool_02_FLASH san_ip = 10.10.72.41 storage_vnx_security_file_dir = /etc/secfile/array1 naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = True [backendB] storage_vnx_pool_names = Pool_02_SAS san_ip = 10.10.26.101 san_login = username san_password = password naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = True san_ip = <IP of VNX Storage Processor A> san_secondary_ip = <IP of VNX Storage Processor B> naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver volume_driver = cinder.volume.drivers.emc.emc_cli_iscsi.EMCCLIISCSIDriver storage_vnx_pool_names = pool 1, pool 2the ``cinder.conf`` file. io_port_list = a-1,B-3 io_port_list = a-1-0,B-3-0 - Rather than de-registered, the registered ports will be simply bypassed whatever they are in ``io_port_list`` or not. - The driver will raise an exception if ports in ``io_port_list`` are not existed in VNX during startup.section, the driver will move the volumes out of the storage groups and then delete them if the user tries to delete the volumes that remain in storage group on the VNX array.Over subscription allows that the sum of all volume's capacity (provisioned(using compute node's host name as storage group's name). All the volumes attached to the VM instances in a Compute node will be put into the storageThe EMC VNX FC driver supports FC SAN auto zoning when ``ZoneManager`` isThe key name (``host1`` in the example) should be the output of :command:`hostname` command. iscsi_initiators = {""host1"":[""10.0.0.1"", ""10.0.0.2""],""host2"":[""10.0.0.3""]}The default value for this option is ``infinite``. default_timeout = 10The ``max_luns_per_storage_group`` specify the maximum number of LUNs in a storage group. Default value is 255. It is also the maximum value supported by VNX.If ``ignore_pool_full_threshold`` is set to ``True``, driver will force LUNThe Block Storage scheduler will use extra specs to find the suitable back end for the volume and the Block Storage driver will create the volume based on theUse the following command to create a volume type: $ cinder type-create ""demoVolumeType"" Use the following command to update the extra spec of a volume type: $ cinder type-key ""demoVolumeType"" set provisioning:type=thin Run the following commands to create a ``thick`` volume type: $ cinder type-create ""ThickVolumeType"" $ cinder type-key ""ThickVolumeType"" set provisioning:type=thick thick_provisioning_support='<is> True' Run the following commands to create a ``thin`` volume type: $ cinder type-create ""ThinVolumeType"" $ cinder type-key ""ThinVolumeType"" set provisioning:type=thin thin_provisioning_support='<is> True' go to VNX to configure the system level deduplication settings. To Run the following commands to create a ``deduplicated`` volume type: $ cinder type-create ""DeduplicatedVolumeType"" $ cinder type-key ""DeduplicatedVolumeType"" set provisioning:type=deduplicated deduplication_support='<is> True' a compressed volume, the VNX Compression license must be activated on VNX, and use ``compression_support=True`` to let Block Storage scheduler Run the following commands to create a ``compressed`` volume type: ``provisioning:type`` replaces the old spec key ``storagetype:provisioning``. The latter one will be obsoleted in the next release. If both ``provisioning:type`` and ``storagetype:provisioning`` are set in the volume type, the value of ``provisioning:type`` will be used.- Possible values:Run the following commands to create a volume type with tiering policy: $ cinder type-create ""ThinVolumeOnLowestAvaibleTier"" $ cinder type-key ""CompressedVolumeOnLowestAvaibleTier"" set provisioning:type=thin storagetype:tiering=Auto fast_support='<is> True' Tiering policy can not be applied to a deduplicated volume. Tiering policy of the deduplicated LUN align with the settings of the pool.- Possible values:- Possible values:By default, the driver will do full data copy while creating a volume from aand mount it as a volume for the two types of operations which will be instant $ cinder type-create ""SnapCopy"" $ cinder type-key ""SnapCopy"" set copytype:snap=True $ cinder metadata-show <volume>- Possible values: name of the storage pool managed by cinderRun the following commands to create the volume type: $ cinder type-create ""HighPerf"" $ cinder type-key ""HighPerf"" set pool_name=Pool_02_SASFLASH volume_backend_name=vnx_41 $ cinder readonly-mode-update <volume> True#. Install ``multipath-tools``, ``sysfsutils`` and ``sg3-utils`` on the#. Specify ``use_multipath_for_image_xfer=true`` in the ``cinder.conf`` file for each FC/iSCSI back end. #. Specify ``iscsi_use_multipath=True`` in ``libvirt`` section of the ``nova.conf`` file. This option is valid for both iSCSI and FC driver.``/etc/multipath.conf`` file. blacklist { # Skip the files under /dev that are definitely not FC/iSCSI devices # Different system may need different customization devnode ""^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"" devnode ""^hd[a-z][0-9]*"" devnode ""^cciss!c[0-9]d[0-9]*[p[0-9]*]"" # Skip LUNZ device from VNX device { vendor ""DGC"" product ""LUNZ"" } } defaults { user_friendly_names no flush_on_last_del yes } devices { # Device attributed for EMC CLARiiON and VNX series ALUA device { vendor ""DGC"" product "".*"" product_blacklist ""LUNZ"" path_grouping_policy group_by_prio path_selector ""round-robin 0"" path_checker emc_clariion features ""1 queue_if_no_path"" hardware_handler ""1 alua"" prio alua failback immediate } } When multipath is used in OpenStack, multipath faulty devices may come out in Nova-Compute nodes due to different issues (`Bug 1336683 <https://bugs.launchpad.net/nova/+bug/1336683>`__ is a typical example).configured by ``periodic_interval`` in the ``cinder.conf`` file) before any volume attachment operation after changing the iSCSI port configurations. Otherwise the attachment may fail because the old iSCSI port configurations were used.add the compute node's or Block Storage node's registered initiators into the for example, FC and iSCSI.Credentials in ``global``, ``local`` and ``ldap`` scopes are supported. There are two approaches to provide the credentials.#. Find out the Linux user id of the ``cinder-volume`` processes. Assuming the#. In ``/etc/passwd`` file, change ``cinder:x:113:120::/var/lib/cinder:/bin/false`` ``cinder:x:113:120::/var/lib/cinder:/bin/false`` in ``/etc/passwd`` file. ``storage_vnx_authentication_type`` from ``cinder.conf`` file. (normally it is ``/etc/cinder/cinder.conf`` file). Add option ``storage_vnx_security_file_dir`` and set its value to the directory path of your security file generated in step 4. Omit this option if ``-secfilepath`` is not used in step 4.To access VNX storage, the Compute nodes should be registered on VNX first ifTo perform ``Copy Image to Volume`` and ``Copy Volume to Image`` operations, the nodes running the ``cinder-volume`` service (Block Storage nodes) must beThe steps mentioned below are for the Compute nodes. Follow the same FC initiator port name of the compute node whose host name and IP are#. Login to :guilabel:`Unisphere`, go to :guilabel:`FNM0000000000`->:guilabel:`Hosts`->:guilabel:`Initiators`.#. Click the :guilabel:`Register` button, select :guilabel:`CLARiiON/VNX` and enter the host name (which is the output of the :command:`hostname` command) and IP address: - Click :guilabel:`Register`. #. Then host ``10.10.61.1`` will appear under :guilabel:`Hosts`->:guilabel:`Host` List as well. #. Register the ``wwn`` with more ports if needed.To perform ``Copy Image to Volume`` and ``Copy Volume to Image`` operations, the nodes running the ``cinder-volume`` service (Block Storage nodes) must be#. On the compute node with IP address ``10.10.61.1`` and host name ``myhost1``, #. Enter the ``/etc/iscsi`` file: #. Find out the ``iqn`` of the node:#. Login to :guilabel:`VNX` from the compute node using the target corresponding to the SPA port: #. Login to :guilabel:`Unisphere`, go to :guilabel:`FNM0000000000`->:guilabel:`Hosts`->:guilabel:`Initiators`. #. Click the :guilabel:`Register` button, select :guilabel:`CLARiiON/VNX` and enter the host name - Click :guilabel:`Register`. #. Then host ``10.10.61.1`` will appear under :guilabel:`Hosts`->:guilabel:`Host` List as well. #. Logout :guilabel:`iSCSI` on the node:#. Login to :guilabel:`VNX` from the compute node using the target corresponding to the SPB#. In ``Unisphere``, register the initiator with the SPB port. #. Logout :guilabel:`iSCSI` on the node:#. Register the ``iqn`` with more ports if needed.","and ``FCDriver`` defined in Block Storage.executing Navisphere CLI (NaviSecCLI) which is a command line interface used- VNX Snapshot and Thin Provisioning license should be activated for VNX. $ /opt/Navisphere/bin/naviseccli security -certificate -setLevel lowpage of :guilabel:`""Storage System Properties`. Here is how it looks like:For the FC Driver, FC zoning is properly configured between hosts and VNX. Check :ref:`register-fc-port-with-vnx` for reference.Here is a sample of a minimum back-end configuration. See following [DEFAULT] enabled_backends = vnx_array1 [vnx_array1] san_ip = 10.10.72.41 san_login = sysadmin san_password = sysadmin naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = TrueHere is a sample of a multi-back-end configuration. See following [DEFAULT] enabled_backends = backendA, backendB [backendA] storage_vnx_pool_names = Pool_01_SAS, Pool_02_FLASH san_ip = 10.10.72.41 storage_vnx_security_file_dir = /etc/secfile/array1 naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = True [backendB] storage_vnx_pool_names = Pool_02_SAS san_ip = 10.10.26.101 san_login = username san_password = password naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration = True san_ip = <IP of VNX Storage Processor A> san_secondary_ip = <IP of VNX Storage Processor B> naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver volume_driver = cinder.volume.drivers.emc.emc_cli_iscsi.EMCCLIISCSIDriver storage_vnx_pool_names = pool 1, pool 2``cinder.conf``. io_port_list = a-1,B-3 io_port_list = a-1-0,B-3-0 - Rather than de-registered, the registered ports will be simply bypassed whatever they are in ``io_port_list`` or not. - The driver will raise an exception if ports in ``io_port_list`` are not existed in VNX during startup.section, the driver will move the volumes out of storage groups and then delete them if the user tries to delete the volumes that remain in storage group on the VNX array.Over subscription allows that the sum of all volumes' capacity (provisioned(using compute node's hostname as storage group's name). All the volumes attached to the VM instances in a compute node will be put into the storageThe EMC VNX FC driver supports FC SAN auto zoning when ZoneManager isThe key name (``host1`` in the example) should be the output of the command :command:`hostname`. iscsi_initiators = {""host1"":[""10.0.0.1"", ""10.0.0.2""],""host2"":[""10.0.0.3""]}The default value for this option is infinite. default_timeout = 10``max_luns_per_storage_group`` specify the max number of LUNs in a storage group. Default value is 255. It is also the max value supportedby VNX.if ``ignore_pool_full_threshold`` is set to ``True``, driver will force LUNThe Block storage scheduler will use extra specs to find the suitable back end for the volume and the Block storage driver will create the volume based on theUse following command to create a volume type: $ cinder type-create ""demoVolumeType"" Use following command to update the extra spec of a volume type: $ cinder type-key ""demoVolumeType"" set provisioning:type=thin Run the foloowing command to create a ``thick`` volume type: $ cinder type-create ""ThickVolumeType"" $ cinder type-key ""ThickVolumeType"" set provisioning:type=thick thick_provisioning_support='<is> True' Run the following command to create a ``thin`` volume type: $ cinder type-create ""ThinVolumeType"" $ cinder type-key ""ThinVolumeType"" set provisioning:type=thin thin_provisioning_support='<is> True' go to VNX to configure the system level deduplication settings. To Run the following command to create a ``deduplicated`` volume type: $ cinder type-create ""DeduplicatedVolumeType"" $ cinder type-key ""DeduplicatedVolumeType"" set provisioning:type=deduplicated deduplication_support='<is> True' a compressed volume, the VNX Compression license must be activated on VNX , and use ``compression_support=True`` to let Block Storage scheduler Run the following command to create a ``compressed`` volume type: ``provisioning:type`` replaces the old spec key ``storagetype:provisioning``. The latter one will be obsoleted in the next release. If both ``provisioning:type`` and ``storagetype:provisioning`` are set in the volume type, the value of ``provisioning:type`` will be used.- Possible Values:Run the following command to create a volume type with tiering policy: $ cinder type-create ""ThinVolumeOnLowestAvaibleTier"" $ cinder type-key ""CompressedVolumeOnLowestAvaibleTier"" set provisioning:type=thin storagetype:tiering=Auto fast_support='<is> True' Tiering policy can not be applied to a deduplicated volume. Tiering policy of the deduplicated LUN align with the settings of the pool.- Possible Values:- Possible Values:By default, the driver will do full data copy when creating a volume from aand mount it as a volume for the 2 kinds of operations which will be instant $ cinder type-create ""SnapCopy"" $ cinder type-key ""SnapCopy"" set copytype:snap=True $ cinder metadata-show <volume>- Possible Values: name of the storage pool managed by cinderRun the following command to create the volume type: $ cinder type-create ""HighPerf"" $ cinder type-key ""HighPerf"" set pool_name=Pool_02_SASFLASH volume_backend_name=vnx_41 $ cinder readonly-mode-update <volume> True#. Install ``multipath-tools``, ``sysfsutils`` and ``sg3-utils`` on#. Specify ``use_multipath_for_image_xfer=true`` in ``cinder.conf`` for each FC/iSCSI back end. #. Specify ``iscsi_use_multipath=True`` in ``libvirt`` section of ``nova.conf``. This option is valid for both iSCSI and FC driver.``/etc/multipath.conf``. blacklist { # Skip the files under /dev that are definitely not FC/iSCSI devices # Different system may need different customization devnode ""^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"" devnode ""^hd[a-z][0-9]*"" devnode ""^cciss!c[0-9]d[0-9]*[p[0-9]*]"" # Skip LUNZ device from VNX device { vendor ""DGC"" product ""LUNZ"" } } defaults { user_friendly_names no flush_on_last_del yes } devices { # Device attributed for EMC CLARiiON and VNX series ALUA device { vendor ""DGC"" product "".*"" product_blacklist ""LUNZ"" path_grouping_policy group_by_prio path_selector ""round-robin 0"" path_checker emc_clariion features ""1 queue_if_no_path"" hardware_handler ""1 alua"" prio alua failback immediate } } When multipath is used in OpenStack, multipath faulty devices may come out in Nova-Compute nodes due to different issues (`Bug 1336683 <https://bugs.launchpad.net/nova/+bug/1336683>`__ is a typical example).configured by ``periodic_interval`` in ``cinder.conf``) before any volume attachment operation after changing the iSCSI port configurations. Otherwise the attachment may fail because the old iSCSI port configurations were used.add the compute node's or Block Storage nodes' registered initiators into the ex, FC and iSCSI.Credentials in global, local and ldap scopes are supported. There are two approaches to provide the credentials.#. Find out the Linux user id of the ``cinder-volume` processes. Assuming the#. In ``/etc/passwd``, change ``cinder:x:113:120::/var/lib/cinder:/bin/false`` ``cinder:x:113:120::/var/lib/cinder:/bin/false`` in ``/etc/passwd`` ``storage_vnx_authentication_type`` from cinder.conf. (normally it is ``/etc/cinder/cinder.conf``). Add option ``storage_vnx_security_file_dir`` and set its value to the directory path of your security file generated in step 4. Omit this option if ``-secfilepath`` is not used in step 4.To access VNX storage, the compute nodes should be registered on VNX first ifTo perform ""Copy Image to Volume"" and ""Copy Volume to Image"" operations, the nodes running the ``cinder-volume`` service (Block Storage nodes) must beThe steps mentioned below are for the compute nodes. Follow the same FC initiator port name of the compute node whose hostname and IP are#. Login to Unisphere, go to FNM0000000000->Hosts->Initiators.#. Click the Register button, select CLARiiON/VNX and enter the hostname (which is the output of the :command:`hostname` command) and IP address: - Click Register. #. Then host ``10.10.61.1`` will appear under Hosts->Host List as well. #. Register the wwn with more ports if needed.To perform ""Copy Image to Volume"" and ""Copy Volume to Image"" operations, the nodes running the ``cinder-volume`` service (Block Storage nodes) must be#. On the compute node with IP address ``10.10.61.1`` and hostname ``myhost1``, #. Enter ``/etc/iscsi``: #. Find out the iqn of the node:#. Login to VNX from the compute node using the target corresponding to the SPA port: #. Login to Unisphere, go to FNM0000000000->Hosts->Initiators. #. Click the Register button, select CLARiiON/VNX and enter the hostname - Click Register #. Then host ``10.10.61.1`` will appear under Hosts->Host List as well. #. Logout iSCSI on the node:#. Login to VNX from the compute node using the target corresponding to the SPB#. In Unisphere register the initiator with the SPB port. #. Logout iSCSI on the node:#. Register the iqn with more ports if needed.",197,188
openstack%2Fsenlin-dashboard~master~I89746f71854c44c4ea393d22368c094ea02bba00,openstack/senlin-dashboard,master,I89746f71854c44c4ea393d22368c094ea02bba00,Update node detail page and use breadcrumb,MERGED,2015-12-11 14:43:27.000000000,2015-12-12 11:56:59.000000000,2015-12-12 11:56:58.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 17130}]","[{'number': 1, 'created': '2015-12-11 14:43:27.000000000', 'files': ['senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/nodes/templates/nodes/detail.html', 'senlin_dashboard/cluster/nodes/templates/nodes/_detail_overview.html', 'senlin_dashboard/cluster/nodes/tests.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/dc7881493eae059eab97b19f8674185cad9158ef', 'message': 'Update node detail page and use breadcrumb\n\nChange-Id: I89746f71854c44c4ea393d22368c094ea02bba00\n'}]",0,256442,dc7881493eae059eab97b19f8674185cad9158ef,9,5,1,6763,,,0,"Update node detail page and use breadcrumb

Change-Id: I89746f71854c44c4ea393d22368c094ea02bba00
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/42/256442/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/nodes/templates/nodes/detail.html', 'senlin_dashboard/cluster/nodes/templates/nodes/_detail_overview.html', 'senlin_dashboard/cluster/nodes/tests.py']",4,dc7881493eae059eab97b19f8674185cad9158ef,refactor_node_detail_page," self.assertTemplateUsed(res, 'horizon/common/_detail.html')"," self.assertTemplateUsed(res, 'cluster/nodes/detail.html')",12,27
openstack%2Fneutron-specs~master~I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714,openstack/neutron-specs,master,I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714,Introducing Tap-as-a-Service,ABANDONED,2014-05-28 12:05:48.000000000,2015-12-12 11:31:19.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 162}, {'_account_id': 261}, {'_account_id': 287}, {'_account_id': 333}, {'_account_id': 490}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1923}, {'_account_id': 1935}, {'_account_id': 2592}, {'_account_id': 3217}, {'_account_id': 6469}, {'_account_id': 6524}, {'_account_id': 6598}, {'_account_id': 6772}, {'_account_id': 6785}, {'_account_id': 6854}, {'_account_id': 6932}, {'_account_id': 7021}, {'_account_id': 7278}, {'_account_id': 7591}, {'_account_id': 7776}, {'_account_id': 8279}, {'_account_id': 8449}, {'_account_id': 9375}, {'_account_id': 10068}, {'_account_id': 10318}, {'_account_id': 10780}, {'_account_id': 11208}, {'_account_id': 11578}, {'_account_id': 11674}, {'_account_id': 11682}, {'_account_id': 11731}, {'_account_id': 12057}, {'_account_id': 13263}, {'_account_id': 13350}]","[{'number': 1, 'created': '2014-05-28 12:05:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/afde3fa2bb9f30b6606caaa4d93c8ffd7e3b44e6', 'message': 'This is a specification for introducing Tap-as-a-Service in\nopenstack neutron.\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 2, 'created': '2014-05-28 21:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/36e922c2a3d10f6d30bb376045b9e4f2d99cbf46', 'message': 'This is a specification for introducing Tap-as-a-Service in\nopenstack neutron.\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nAddressing the review comments from Marios Andreou.\n\n    Changes made:\n    1. Removed all trailing white spaces.\n    2. Added text to the performance impact section.\n    3. Added text indicating further uses of the destination port\n       of the service in the future under proposed changes section.\n    4. Added text to indicated future usage of the service to mirror\n       traffic from all the ports of a tenant virtual network in the\n       description section.\n    5. Other small editorial changes.\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 3, 'created': '2014-06-01 12:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/df36dde9c036b93de6a7dda515b0a519e7a8768e', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: https://blueprints.launchpad.net/neutron/+spec/port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 4, 'created': '2014-06-03 15:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/3d3ccabdebf2781d46c00836e2acfebe0ef80a76', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: https://blueprints.launchpad.net/neutron/+spec/port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 5, 'created': '2014-06-10 15:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/462d6145637d04fddbff95a08095cc2747218166', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: https://blueprints.launchpad.net/neutron/+spec/port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 6, 'created': '2014-06-25 13:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/9d75351dbed821c3aabdcbda6a44a1775df55e92', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: blueprint port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 7, 'created': '2014-12-10 13:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/e99285d240c338632b12cfdcf106d1845ca3a7bf', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: blueprint port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}, {'number': 8, 'created': '2014-12-12 17:17:09.000000000', 'files': ['specs/juno/tap-as-a-service.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/054aa9d9b7f376fc94bbdcaca47f700c2bf3ff33', 'message': 'Introducing Tap-as-a-Service\n\nThis specification aims to add port mirroring capability for tenant\nnetworks in Neutron. The specification covers the description of the\nservice along with its intended usecase. The specification also includes\nthe data model and REST API changes.\n\nImplements: blueprint port-mirroring\n\nChange-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714\n'}]",296,96149,054aa9d9b7f376fc94bbdcaca47f700c2bf3ff33,171,38,8,11674,,,0,"Introducing Tap-as-a-Service

This specification aims to add port mirroring capability for tenant
networks in Neutron. The specification covers the description of the
service along with its intended usecase. The specification also includes
the data model and REST API changes.

Implements: blueprint port-mirroring

Change-Id: I087d9d2a802ea39c02259f17d2b8c4e2f6d8d714
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/49/96149/8 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/tap-as-a-service.rst'],1,afde3fa2bb9f30b6606caaa4d93c8ffd7e3b44e6,bp/port-mirroring,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================ Tap-as-a-Service for neutron ============================ URL of the launchpad blueprint: https://blueprints.launchpad.net/neutron/+spec/port-mirroring The above mentioned blueprint aims to add port mirroring capabilities in neutron. Port mirroring allows sending a copy of packets ingressing or egressing (or both) one port to another port (usually distinct from the packet’s destination). From the source VM’s perspective, mirrored ingress packets are captured after passing the inbound Security Group filter. Mirrored egress packets are captured before passing the outbound Security Group filter. All captured packets are forwarded to the mirror’s destination port without passing through its inbound filter. The proposed port mirroring capability shall be introduced in neutron as an service called 'Tap-as-a-Service'. Problem description =================== Neutron currently does not support the functionality of port mirroring in tenant networks. This features could be benefit the tenant who would like to debug their virtual networks. This neutron spec proposes to introduce the feature of port mirroring by adding a new service called Tap-as-a-Service. The use-case is to debug network traffic by “tapping” or ""mirroring"" packets traversing a network element. This neutron spec focuses on mirroring traffic from one VM to another so that it can be useful to both administrators and tenants; future versions may address mirroring from a VM to an arbitrary interface on a compute host or on the network controller, or to the Neutron CLI. Mirroring traffic has many uses, it provides visibility into VM network traffic which can be used for monitoring, debugging and analyzing network traffic ingressing and egressing a VM. (ex. IDS). Different usage scenarios for the service are listed below: 1. Tapping/Mirroring network traffic ingressing, egressing or both from a particular neutron port. 2. Tapping/Mirroring all network traffic on an entire tenant network. Proposed change =============== The proposal is to add a new neutron service 'Tap-as-a-Service' in order to enable the functionality of tapping/mirroring traffic inside tenant networks in neutron. This service will be modeled similar to other services in neutron like the firewall, loadbalancer, l3 router etc. The proposed service would allow the tenants to create a tap service instance to which they can add neutron ports that need to be mirrored by creating tap flows. The tap service itself will be a neutron port, which will be the destination port for the mirrored traffic. The destination Tap-as-a-Service neutron port will be created on a network owned by the tenant who is requesting for the service. The ports to be mirrored that are added to the service can belong to any network owned by the tenant. This allow the tenant to mirror traffic from port(s) belonging to any networks that they own on to the same Tap-as-a-Serivce nuetron port. In the first version of this service, the tenants can launch a VM on the neutron port that was created by instantiating the tap service to capture or analyze the mirrored traffic. The following would be the work flow for using this service from a tenants point of view 1. Create an instance of the tap service (creation of the service return back with a neutron port UUID). 2. Launch a monitoring or traffic analysis VM on the port returned by the tap service while creating the service. 3. Create a tap flow by associating a neutron port that needs to be mirrored with an already created tap service instance. Alternatives ------------ As an alternative to introducing port mirroring functionality under neutron services, it could be added as an extension to the existing neutron v2 APIs. Data model impact ----------------- Tap-as-a-Service introduces the following data models into neutron as database schemas. 1. TapService +-----------+--------+----------+-----------+---------------+-------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | (CRUD) | Value | Conversion | | +===========+========+==========+===========+===============+=========================+ | id | UUID | CR, all | generated | N/A | UUID of the tap | | | | | | | service inst. | +-----------+--------+----------+-----------+---------------+-------------------------+ | tenant_id | UUID | CR, all | N/A | UUID of a | UUID of the | | | | | | valid | tenant creating | | | | | | tenant | the service | +-----------+--------+----------+-----------+---------------+-------------------------+ | port_id | UUID + R, all | N/A | UUID of a | A neutron port | | | | | | valid neutron | is created by the | | | | | | port | service for destination | | | | | | | of mirrored traffic | +-----------+--------+----------+-----------+---------------+-------------------------+ 2. TapFlow +-------------+--------+----------+-----------+---------------+-------------------------+ | Attribute | Type | Access | Default | Validation/ | Description | | Name | | (CRUD) | Value | Conversion | | +=============+========+==========+===========+===============+=========================+ | id | UUID | CR, all | generated | N/A | UUID of the | | | | | | | TapFlow instance. | +-------------+--------+----------+-----------+---------------+-------------------------+ | tap_id | UUID | CR, all | N/A | Valid tap | UUID of the tap | | | | | | service UUID | service instance. | +-------------+--------+----------+-----------+---------------+-------------------------+ | source_port | UUID | CR, all | N/A | UUID of a | UUID of the neutron | | | | | | valid neutron | port that needed to be | | | | | | port | mirrored | +-------------+--------+----------+-----------+---------------+-------------------------+ | direction | ENUM | CRU, all | BOTH | | Whether to mirror the | | | (IN, | | | | traffic leaving or | | | OUT, | | | | arriving at the | | | BOTH) | | | | source port | +-------------+--------+----------+-----------+---------------+-------------------------+ REST API impact --------------- The Tap-as-a-Serivice shall be offered over the RESTFull API interface under the following namespace: http://wiki.openstack.org/Neutron/TaaS/API_1.0 The resource attribute map for the TaaS is provided below: .. code-block:: python direction_enum = [None, 'IN', 'OUT', 'BI'] RESOURCE_ATTRIBUTE_MAP = { TapService: { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tenant_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'port_id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True}, }, TapFlow: { 'id': {'allow_post': False, 'allow_put': False, 'validate': {'type:uuid': None}, 'is_visible': True, 'primary_key': True}, 'tap_id': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': None}, 'required_by_policy': True, 'is_visible': True}, 'source_port': {'allow_post': True, 'allow_put': False, 'validate': {'type:uuid': None}, 'required_by_policy': True, 'is_visible': True}, 'direction': {'allow_post': True, 'allow_put': False, 'validate': {'type:string': direction_enum}, 'is_visible': True}, } } Security impact --------------- The port(s) on which the TaaS runs should be able to forward mirrored packets to the VM attached to it without filtering it out. The mirrored traffic usually is destined to a VM that is not the same as the VM attached on the port that belongs to TaaS (mirror destination port). Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- This will be a new API, and will not affect existing API. Implementation ============== The reference implementation for this service will be based on the OVS driver. The implementation will leverage the port mirroring feature in OVS to accomplish this. To transfer mirrored data across OVS switches in different physical server, an out of band GRE tunnel will be used. Assignee(s) ----------- Vinay Yadhav Work Items ---------- * TaaS API and data model implementation. * TaaS OVS driver. * OVS agent changes for port mirroring. Dependencies ============ None Testing ======= * Unit Tests to be added. * API Tests in Tempest to be added. * Functional tests in tempest to be added. Documentation Impact ==================== Both, API and, Admin guide will be updated. References ========== ",,254,0
openstack%2Fhorizon~master~Id54a915b59d19592dddde390652d4d5513309822,openstack/horizon,master,Id54a915b59d19592dddde390652d4d5513309822,Fix the Split button to enable the dropdown toggle,MERGED,2015-12-08 23:40:31.000000000,2015-12-12 10:48:04.000000000,2015-12-12 10:48:02.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 10442}, {'_account_id': 11778}, {'_account_id': 13805}, {'_account_id': 14124}, {'_account_id': 17013}, {'_account_id': 17327}]","[{'number': 1, 'created': '2015-12-08 23:40:31.000000000', 'files': ['horizon/static/framework/widgets/action-list/menu-item.html', 'horizon/static/framework/widgets/action-list/split-button.html'], 'web_link': 'https://opendev.org/openstack/horizon/commit/348312fa558e8c27914ed3b436f4a1fa431d29b6', 'message': ""Fix the Split button to enable the dropdown toggle\n\nThe split button template needs to have the\n'dropdown-toggle' directive to allow it to be clicked\nto show the menu options.\n\nCo-Authored-By: Kyle Olivo<keolivo@thoughtworks.com>\n\nChange-Id: Id54a915b59d19592dddde390652d4d5513309822\nCloses-Bug: #1524115\n""}]",0,255004,348312fa558e8c27914ed3b436f4a1fa431d29b6,23,11,1,17013,,,0,"Fix the Split button to enable the dropdown toggle

The split button template needs to have the
'dropdown-toggle' directive to allow it to be clicked
to show the menu options.

Co-Authored-By: Kyle Olivo<keolivo@thoughtworks.com>

Change-Id: Id54a915b59d19592dddde390652d4d5513309822
Closes-Bug: #1524115
",git fetch https://review.opendev.org/openstack/horizon refs/changes/04/255004/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/action-list/menu-item.html', 'horizon/static/framework/widgets/action-list/split-button.html']",2,348312fa558e8c27914ed3b436f4a1fa431d29b6,bp/ng-flavors,"<button class=""split-caret dropdown-toggle"" dropdown-toggle","<button class=""split-caret dropdown-toggle""",3,3
openstack%2Fproject-config~master~I58bb6493232b7d6192fac804f169ae5f87b46f47,openstack/project-config,master,I58bb6493232b7d6192fac804f169ae5f87b46f47,Change ACLs for stable branches of fuel projects,MERGED,2015-12-03 13:03:31.000000000,2015-12-12 10:36:57.000000000,2015-12-12 10:36:55.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-03 13:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/550e322a81ee1b8dd76d8a0cf4c2a51b461d9018', 'message': 'Change ACLs for stable branches of fuel projects\n\nstable/6.1 and stable/7.0 branches of some fuel-* repos have\nexclusive Workflow permissions, this patch adds an option\nfor change owner to set Workflow -1..+0 which is not inherited from\nAll-Projects ACL\n\nChange-Id: I58bb6493232b7d6192fac804f169ae5f87b46f47\nCloses-Bug: #1522387\n'}, {'number': 2, 'created': '2015-12-03 13:19:33.000000000', 'files': ['gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/fuel-mirror.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/264d0f33d66ccd8cbbfef7d187851e2758697577', 'message': 'Change ACLs for stable branches of fuel projects\n\nstable/6.1 and stable/7.0 branches of some fuel-* repos have\nexclusive Workflow permissions, this patch adds an option\nfor change owner to set Workflow -1..+0 which is not inherited from\nAll-Projects ACL\n\nChange-Id: I58bb6493232b7d6192fac804f169ae5f87b46f47\nCloses-Bug: #1522387\n'}]",0,252936,264d0f33d66ccd8cbbfef7d187851e2758697577,9,3,2,13505,,,0,"Change ACLs for stable branches of fuel projects

stable/6.1 and stable/7.0 branches of some fuel-* repos have
exclusive Workflow permissions, this patch adds an option
for change owner to set Workflow -1..+0 which is not inherited from
All-Projects ACL

Change-Id: I58bb6493232b7d6192fac804f169ae5f87b46f47
Closes-Bug: #1522387
",git fetch https://review.opendev.org/openstack/project-config refs/changes/36/252936/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/openstack/fuel-library.config', 'gerrit/acls/openstack/fuel-main.config', 'gerrit/acls/openstack/fuel-mirror.config', 'gerrit/acls/openstack/fuel-astute.config', 'gerrit/acls/openstack/fuel-ostf.config', 'gerrit/acls/openstack/fuel-agent.config', 'gerrit/acls/openstack/fuel-menu.config', 'gerrit/acls/openstack/python-fuelclient.config', 'gerrit/acls/openstack/fuel-nailgun-agent.config']",9,550e322a81ee1b8dd76d8a0cf4c2a51b461d9018,bug/1522387,label-Workflow = -1..+0 group Change Owner,,14,0
openstack%2Fproject-config~master~I6acd66a0a4c43e2af3889928a9751ae3b4993793,openstack/project-config,master,I6acd66a0a4c43e2af3889928a9751ae3b4993793,Enable devstack-plugin-ceph NV jobs for glance and nova,MERGED,2015-12-11 11:20:21.000000000,2015-12-12 10:34:33.000000000,2015-12-12 10:34:32.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 4146}, {'_account_id': 6133}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 6968}, {'_account_id': 6984}, {'_account_id': 10796}]","[{'number': 1, 'created': '2015-12-11 11:20:21.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d72908b48fbcea05443850942f8a4bcedb146948', 'message': ""Enable devstack-plugin-ceph NV jobs for glance and nova\n\nCommit a53859db32475c948ee68ce1f838b20e773b8687 enabled the\ndevstack-plugin-ceph NV job for cinder only as we didn't\nwant to load the infra during the Mitaka-1 release rush. This\npatch now adds the job to glance and nova projects.\n\nThis patch is part of a larger effort of moving the devstack-ceph\nCI job from devstack hook -> plugin method.\n\nChange-Id: I6acd66a0a4c43e2af3889928a9751ae3b4993793\n""}]",0,256359,d72908b48fbcea05443850942f8a4bcedb146948,8,9,1,10796,,,0,"Enable devstack-plugin-ceph NV jobs for glance and nova

Commit a53859db32475c948ee68ce1f838b20e773b8687 enabled the
devstack-plugin-ceph NV job for cinder only as we didn't
want to load the infra during the Mitaka-1 release rush. This
patch now adds the job to glance and nova projects.

This patch is part of a larger effort of moving the devstack-ceph
CI job from devstack hook -> plugin method.

Change-Id: I6acd66a0a4c43e2af3889928a9751ae3b4993793
",git fetch https://review.opendev.org/openstack/project-config refs/changes/59/256359/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,d72908b48fbcea05443850942f8a4bcedb146948,, - gate-tempest-dsvm-full-devstack-plugin-ceph-nv - gate-tempest-dsvm-full-devstack-plugin-ceph-nv,,2,0
openstack%2Fproject-config~master~I70b82070fb9f4a4a3a633b000a8eea6240736586,openstack/project-config,master,I70b82070fb9f4a4a3a633b000a8eea6240736586,split gnocchi tests by indexer to avoid timeouts,MERGED,2015-12-10 19:19:46.000000000,2015-12-12 10:34:25.000000000,2015-12-12 10:34:23.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6133}, {'_account_id': 6537}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-10 19:19:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/42e84f8c0a03e40dc3e4bbc16de35800c0afa617', 'message': 'split gnocchi unit tests by indexer\n\nwe currently have 6 test runs under py27 to handle each combination\nof indexer+storage pairs. for each test added, it is run 6 times across\neach pair causing it to exceed timeout length.\n\nthis patch breaks the tests so we group the tests by indexer so that all\nmysql tests are run together and all postgresql tests are run together.\n\nChange-Id: I70b82070fb9f4a4a3a633b000a8eea6240736586\n'}, {'number': 2, 'created': '2015-12-10 20:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/113e4a4a2912243194d4435e2f94f5ddd29f1ecc', 'message': 'split gnocchi tests by indexer\n\nwe currently have 6 test runs under py27 to handle each combination\nof indexer+storage pairs. for each test added, it is run 6 times across\neach pair causing it to exceed timeout length.\n\nthis patch breaks the tests so we group the tests by indexer so that all\nmysql tests are run together and all postgresql tests are run together.\n\nChange-Id: I70b82070fb9f4a4a3a633b000a8eea6240736586'}, {'number': 3, 'created': '2015-12-11 02:27:56.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/3e008506223f01167c7a8c63f48453031ffd2c78', 'message': 'split gnocchi tests by indexer to avoid timeouts\n\nwe currently have 6 test runs under py27 to handle each combination\nof indexer+storage pairs. for each test added, it is run 6 times across\neach pair causing it to exceed timeout length.\n\nthis patch breaks the tests so we group the tests by indexer so that all\nmysql tests are run together and all postgresql tests are run together.\n\nChange-Id: I70b82070fb9f4a4a3a633b000a8eea6240736586'}]",0,256063,3e008506223f01167c7a8c63f48453031ffd2c78,14,5,3,6537,,,0,"split gnocchi tests by indexer to avoid timeouts

we currently have 6 test runs under py27 to handle each combination
of indexer+storage pairs. for each test added, it is run 6 times across
each pair causing it to exceed timeout length.

this patch breaks the tests so we group the tests by indexer so that all
mysql tests are run together and all postgresql tests are run together.

Change-Id: I70b82070fb9f4a4a3a633b000a8eea6240736586",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/256063/2 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml']",2,42e84f8c0a03e40dc3e4bbc16de35800c0afa617,gnocchi-timeout, - gate-gnocchi-pep8 - gate-gnocchi-docs - gate-gnocchi-tox-py27-mysql - gate-gnocchi-tox-py27-postgresql - gate-gnocchi-tox-py34-mysql - gate-gnocchi-tox-py34-postgresql - gate-gnocchi-pep8 - gate-gnocchi-docs - gate-gnocchi-tox-py27-mysql - gate-gnocchi-tox-py27-postgresql - gate-gnocchi-tox-py34-mysql - gate-gnocchi-tox-py34-postgresql post: - gnocchi-branch-tarball, - name: python-jobs - name: python3-jobs,20,2
openstack%2Fproject-config~master~I1fbf0c977784eca6457de277993a6becca85f291,openstack/project-config,master,I1fbf0c977784eca6457de277993a6becca85f291,add requirements job to aodh,MERGED,2015-12-11 13:29:06.000000000,2015-12-12 10:31:49.000000000,2015-12-12 10:31:48.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 13:29:06.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ecf735d9af3b3d0157edff6e16bfa8656f6d2971', 'message': 'add requirements job to aodh\n\nmissed this entry when adding requirements job to aodh\n\nChange-Id: I1fbf0c977784eca6457de277993a6becca85f291\n'}]",0,256407,ecf735d9af3b3d0157edff6e16bfa8656f6d2971,8,4,1,6537,,,0,"add requirements job to aodh

missed this entry when adding requirements job to aodh

Change-Id: I1fbf0c977784eca6457de277993a6becca85f291
",git fetch https://review.opendev.org/openstack/project-config refs/changes/07/256407/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,ecf735d9af3b3d0157edff6e16bfa8656f6d2971,requirements, - name: check-requirements,,1,0
openstack%2Fproject-config~master~I93edaff6daed68f1eb0f289eae1f9bd0342eaf2f,openstack/project-config,master,I93edaff6daed68f1eb0f289eae1f9bd0342eaf2f,Python 3.4 support - add py34 gate,MERGED,2015-12-11 15:24:10.000000000,2015-12-12 10:31:41.000000000,2015-12-12 10:31:40.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 11809}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 15:24:10.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2055c91200a015ffc82e9155a4e397bddbbe931d', 'message': 'Python 3.4 support - add py34 gate\n\nAs we just upgraded our codebase to work on Python 3.4, we would\nlike to make sure that each new patchset pass the tests on both\npy27 and py34 environments.\n\nChange-Id: I93edaff6daed68f1eb0f289eae1f9bd0342eaf2f\n'}]",0,256504,2055c91200a015ffc82e9155a4e397bddbbe931d,9,5,1,18971,,,0,"Python 3.4 support - add py34 gate

As we just upgraded our codebase to work on Python 3.4, we would
like to make sure that each new patchset pass the tests on both
py27 and py34 environments.

Change-Id: I93edaff6daed68f1eb0f289eae1f9bd0342eaf2f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/04/256504/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,2055c91200a015ffc82e9155a4e397bddbbe931d,watcher/python34-gate, - name: python3-jobs,,1,0
openstack%2Fproject-config~master~Ibe73df693b59569a89d728ecf6fd9b7d9194b782,openstack/project-config,master,Ibe73df693b59569a89d728ecf6fd9b7d9194b782,Add check-requirements template to murano-agent,MERGED,2015-12-11 15:57:55.000000000,2015-12-12 10:31:32.000000000,2015-12-12 10:31:31.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 15168}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 15:57:55.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e92949798b2d1111609692d77c17d527aa6a1da4', 'message': 'Add check-requirements template to murano-agent\n\n- Remove non-voting requirements job from murano-agent\n- Use template check-requirements for murano-agent repo\n\nChange-Id: Ibe73df693b59569a89d728ecf6fd9b7d9194b782\n'}]",0,256554,e92949798b2d1111609692d77c17d527aa6a1da4,9,5,1,13962,,,0,"Add check-requirements template to murano-agent

- Remove non-voting requirements job from murano-agent
- Use template check-requirements for murano-agent repo

Change-Id: Ibe73df693b59569a89d728ecf6fd9b7d9194b782
",git fetch https://review.opendev.org/openstack/project-config refs/changes/54/256554/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e92949798b2d1111609692d77c17d527aa6a1da4,, - name: check-requirements check:, - name: gate-murano-agent-requirements voting: false check: - gate-murano-agent-requirements,1,4
openstack%2Fproject-config~master~Iaf5a55f66830e91a8a1e13ff5230da84830af6ab,openstack/project-config,master,Iaf5a55f66830e91a8a1e13ff5230da84830af6ab,Skip Tempest tests for monasca-api doc only changes,MERGED,2015-12-11 15:51:59.000000000,2015-12-12 10:30:17.000000000,2015-12-12 10:30:16.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 14517}]","[{'number': 1, 'created': '2015-12-11 15:51:59.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b17b9c7e0cfadff7d46e3d1de1f606c416aa4688', 'message': 'Skip Tempest tests for monasca-api doc only changes\n\nChange-Id: Iaf5a55f66830e91a8a1e13ff5230da84830af6ab\n'}]",0,256551,b17b9c7e0cfadff7d46e3d1de1f606c416aa4688,8,5,1,11809,,,0,"Skip Tempest tests for monasca-api doc only changes

Change-Id: Iaf5a55f66830e91a8a1e13ff5230da84830af6ab
",git fetch https://review.opendev.org/openstack/project-config refs/changes/51/256551/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,b17b9c7e0cfadff7d46e3d1de1f606c416aa4688,, - project: ^openstack/monasca-api all-files-match-any: - ^.*\.md$,,3,0
openstack%2Fproject-config~master~Ibcb1498f49873749a2994ad4921f26aa1e351d93,openstack/project-config,master,Ibcb1498f49873749a2994ad4921f26aa1e351d93,ansible-role-jenkins-job-builder voting for centos7,MERGED,2015-12-12 01:39:58.000000000,2015-12-12 10:23:25.000000000,2015-12-12 10:23:24.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-12 01:39:58.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1147bbf8c3256aa758e2767470b29c7f702e6e3d', 'message': 'ansible-role-jenkins-job-builder voting for centos7\n\nChange-Id: Ibcb1498f49873749a2994ad4921f26aa1e351d93\nSigned-off-by: Paul Belanger <pabelanger@redhat.com>\n'}]",0,256896,1147bbf8c3256aa758e2767470b29c7f702e6e3d,7,3,1,4162,,,0,"ansible-role-jenkins-job-builder voting for centos7

Change-Id: Ibcb1498f49873749a2994ad4921f26aa1e351d93
Signed-off-by: Paul Belanger <pabelanger@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/256896/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1147bbf8c3256aa758e2767470b29c7f702e6e3d,temp/ansible-role-jjb, - name: ansible-role-functional-jobs, - gate-ansible-role-jenkins-job-builder-dsvm-functional-centos7-nv,1,1
openstack%2Fproject-config~master~I3eebbcc6332ef514f352f8f5ca0f549ce06d36ab,openstack/project-config,master,I3eebbcc6332ef514f352f8f5ca0f549ce06d36ab,Add python3 and requirements jobs to Kosmos,MERGED,2015-12-09 22:41:33.000000000,2015-12-12 10:22:50.000000000,2015-12-12 10:22:49.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 8099}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-09 22:41:33.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e7c8061fe3ba028b20e94dbc2733cf5f205fce94', 'message': 'Add python3 and requirements jobs to Kosmos\n\nChange-Id: I3eebbcc6332ef514f352f8f5ca0f549ce06d36ab\n'}]",0,255576,e7c8061fe3ba028b20e94dbc2733cf5f205fce94,8,5,1,10980,,,0,"Add python3 and requirements jobs to Kosmos

Change-Id: I3eebbcc6332ef514f352f8f5ca0f549ce06d36ab
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/255576/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,e7c8061fe3ba028b20e94dbc2733cf5f205fce94,new-kosmos-jobs, - name: check-requirements - name: python3-jobs,,2,0
openstack%2Fproject-config~master~I6d2a4658da64a109e1342b103c3183b95dd37570,openstack/project-config,master,I6d2a4658da64a109e1342b103c3183b95dd37570,fix monasca job config error in rally.yaml,MERGED,2015-12-12 00:21:25.000000000,2015-12-12 10:22:22.000000000,2015-12-12 10:22:21.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 4428}, {'_account_id': 6133}, {'_account_id': 6172}, {'_account_id': 6547}, {'_account_id': 6577}, {'_account_id': 6835}, {'_account_id': 7132}, {'_account_id': 7369}, {'_account_id': 7428}, {'_account_id': 8576}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 13609}, {'_account_id': 13919}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-12 00:21:25.000000000', 'files': ['jenkins/jobs/rally.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d3370185909a65d090fc9fc283f6746910f7bdac', 'message': 'fix monasca job config error in rally.yaml\n\nChange-Id: I6d2a4658da64a109e1342b103c3183b95dd37570\n'}]",0,256890,d3370185909a65d090fc9fc283f6746910f7bdac,10,19,1,16558,,,0,"fix monasca job config error in rally.yaml

Change-Id: I6d2a4658da64a109e1342b103c3183b95dd37570
",git fetch https://review.opendev.org/openstack/project-config refs/changes/90/256890/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/jobs/rally.yaml'],1,d3370185909a65d090fc9fc283f6746910f7bdac,monasca-rally-jobs," export DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin monasca-api git://git.openstack.org/openstack/monasca-api"""," export DEVSTACK_LOCAL_CONFIG+= $'\n'""enable_plugin monasca-api git://git.openstack.org/openstack/monasca-api""",1,2
openstack%2Fpuppet-tripleo~master~I6f1ac659297b8cf6671e11ad23284f8f543568b0,openstack/puppet-tripleo,master,I6f1ac659297b8cf6671e11ad23284f8f543568b0,Adding MidoNet LoadBalancing options,MERGED,2015-11-27 12:35:13.000000000,2015-12-12 10:16:45.000000000,2015-12-12 10:16:45.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 6807}, {'_account_id': 7505}, {'_account_id': 8449}, {'_account_id': 11933}]","[{'number': 1, 'created': '2015-11-27 12:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/884bd76bff27ae1b79152db13be4b2dc54cc2a22', 'message': 'Adding MidoNet LoadBalancing options\n\nMidoNet API needs to be loadbalanced if the midonet environment is\nactivated.\n\nChange-Id: I6f1ac659297b8cf6671e11ad23284f8f543568b0\n'}, {'number': 2, 'created': '2015-12-01 14:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/696c7a0a2d7e2d687690fc0290aceeb9d0cb9b46', 'message': 'Adding MidoNet LoadBalancing options\n\nMidoNet API needs to be loadbalanced if the midonet environment is\nactivated.\n\nChange-Id: I6f1ac659297b8cf6671e11ad23284f8f543568b0\n'}, {'number': 3, 'created': '2015-12-11 11:47:13.000000000', 'files': ['manifests/loadbalancer.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/7d5decbfb667cd97bda0a7f363dda73dbf40988f', 'message': 'Adding MidoNet LoadBalancing options\n\nMidoNet API needs to be loadbalanced if the midonet environment is\nactivated.\n\nChange-Id: I6f1ac659297b8cf6671e11ad23284f8f543568b0\n'}]",6,250777,7d5decbfb667cd97bda0a7f363dda73dbf40988f,23,7,3,7505,,,0,"Adding MidoNet LoadBalancing options

MidoNet API needs to be loadbalanced if the midonet environment is
activated.

Change-Id: I6f1ac659297b8cf6671e11ad23284f8f543568b0
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/77/250777/3 && git format-patch -1 --stdout FETCH_HEAD,['manifests/loadbalancer.pp'],1,884bd76bff27ae1b79152db13be4b2dc54cc2a22,loadbalancer_midonet,"# [*midonet_api*] # (optional) Enable or not MidoNet API binding # Defaults to false # $midonet_api = false, $midonet_api_vip = hiera('midonet_api_vip', $controller_virtual_ip) $midonet_bind_opts = { ""${midonet_api_vip}:8081"" => [], ""${public_virtual_ip}:8081"" => [], } if $midonet_api { haproxy::listen { 'midonet_api': bind => $midonet_bind_opts, collect_exported => false, } haproxy::balancermember { 'midonet_api': listening_service => 'midonet_api', ports => '8081', ipaddresses => hiera('midonet_api_node_ips', $controller_hosts_real), server_names => $controller_hosts_names_real, options => ['check', 'inter 2000', 'rise 2', 'fall 5'], } }",,24,0
openstack%2Fcinder~master~I3b8e01e7a5fc1054110cecedf6a17fde3823a885,openstack/cinder,master,I3b8e01e7a5fc1054110cecedf6a17fde3823a885,Huawei: Refactor driver for the second time,ABANDONED,2015-12-10 06:35:53.000000000,2015-12-12 09:18:35.000000000,,"[{'_account_id': 3}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16862}, {'_account_id': 16883}, {'_account_id': 17852}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-12-10 06:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/eb42ad8e58ff25e9f3921ec7cffd62afc877bc8e', 'message': 'Huawei: Refactor driver for the second time\n\nAfter a few new features being added into drivers,\nwe found it hard to maintain the code. For further\nworking, we need to refactor our code. The work\ncontains the following:\n1. Define a new class, named HuaweiConf, to parse\nxml config file. We used an external xml file to\nstore SAN info. But we do config parsing anywhere\nin our code, even two different functions do the\nsame parsing.\n2. Adjust some function structures.\n3. Rename some functions & variables.\n\nDocImpact\nImplements: blueprint refactor-huawei-driver\n\nChange-Id: I3b8e01e7a5fc1054110cecedf6a17fde3823a885\n'}, {'number': 2, 'created': '2015-12-12 07:03:50.000000000', 'files': ['cinder/volume/drivers/huawei/huawei_conf.py', 'cinder/volume/drivers/huawei/fc_zone_helper.py', 'cinder/volume/drivers/huawei/smartx.py', 'cinder/tests/unit/var/test_huawei_drivers.py', 'cinder/tests/unit/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/rest_client.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/volume/drivers/huawei/hypermetro.py', 'cinder/volume/drivers/huawei/replication.py', 'cinder/volume/drivers/huawei/huawei_driver.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/0c4ea4121ea4d63734d5bf2ca3943ceb06c0dfb1', 'message': 'Huawei: Refactor driver for the second time\n\nAfter a few new features being added into drivers,\nwe found it hard to maintain the code. For further\nworking, we need to refactor our code. The work\ncontains the following:\n1. Define a new class, named HuaweiConf, to parse\nxml config file. We used an external xml file to\nstore SAN info. But we do config parsing anywhere\nin our code, even two different functions do the\nsame parsing.\n2. Adjust some function structures.\n3. Rename some functions & variables.\n\nDocImpact\nImplements: blueprint refactor-huawei-driver\nChange-Id: I3b8e01e7a5fc1054110cecedf6a17fde3823a885\n'}]",5,255692,0c4ea4121ea4d63734d5bf2ca3943ceb06c0dfb1,33,23,2,8202,,,0,"Huawei: Refactor driver for the second time

After a few new features being added into drivers,
we found it hard to maintain the code. For further
working, we need to refactor our code. The work
contains the following:
1. Define a new class, named HuaweiConf, to parse
xml config file. We used an external xml file to
store SAN info. But we do config parsing anywhere
in our code, even two different functions do the
same parsing.
2. Adjust some function structures.
3. Rename some functions & variables.

DocImpact
Implements: blueprint refactor-huawei-driver
Change-Id: I3b8e01e7a5fc1054110cecedf6a17fde3823a885
",git fetch https://review.opendev.org/openstack/cinder refs/changes/92/255692/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/huawei/huawei_conf.py', 'cinder/volume/drivers/huawei/fc_zone_helper.py', 'cinder/volume/drivers/huawei/smartx.py', 'cinder/tests/unit/test_huawei_drivers.py', 'cinder/volume/drivers/huawei/rest_client.py', 'cinder/volume/drivers/huawei/huawei_utils.py', 'cinder/volume/drivers/huawei/hypermetro.py', 'cinder/volume/drivers/huawei/replication.py', 'cinder/volume/drivers/huawei/huawei_driver.py']",9,eb42ad8e58ff25e9f3921ec7cffd62afc877bc8e,bp/refactor-huawei-driver,"from cinder import contextfrom cinder.volume.drivers.huawei import huawei_conf if not self.configuration: msg = _('Configuration is not found.') self.huawei_conf = huawei_conf.HuaweiConf(self.configuration) self.metro_flag = False # Set huawei private configuration into Configuration object. self.huawei_conf.update_config_value() # init local client self.client = rest_client.RestClient(self.configuration, self.configuration.san_address, self.configuration.san_user, self.configuration.san_password) self.client.login() # init remote client metro_san_address = self.configuration.safe_get(""metro_san_address"") metro_san_user = self.configuration.safe_get(""metro_san_user"") metro_san_password = self.configuration.safe_get(""metro_san_password"") if (metro_san_address and metro_san_user and metro_san_password): self.metro_flag = True metro_san_address = metro_san_address.split("";"") self.rmt_client = rest_client.RestClient(self.configuration, metro_san_address, metro_san_user, metro_san_password) self.rmt_client.login() pass """"""Get volume status and reload huawei config file."""""" self.huawei_conf.update_config_value() if self.metro_flag: self.rmt_client.get_all_pools() return self.client.update_volume_stats() def _get_volume_type(self, volume): volume_type = None type_id = volume['volume_type_id'] if type_id: ctxt = context.get_admin_context() volume_type = volume_types.get_volume_type(ctxt, type_id) return volume_type def _get_volume_params(self, volume_type): """"""Return the parameters for creating the volume."""""" specs = {} if volume_type: specs = dict(volume_type).get('extra_specs') opts = self._get_volume_params_from_specs(specs) return opts def _get_volume_params_from_specs(self, specs): """"""Return the volume parameters from extra specs."""""" opts_capability = { 'smarttier': False, 'smartcache': False, 'smartpartition': False, 'thin_provisioning_support': False, 'thick_provisioning_support': False, 'hypermetro': False, } opts_value = { 'policy': None, 'partitionname': None, 'cachename': None, } opts_associate = { 'smarttier': 'policy', 'smartcache': 'cachename', 'smartpartition': 'partitionname', } opts = self._get_opts_from_specs(opts_capability, opts_value, opts_associate, specs) opts = smartx.SmartX().get_smartx_specs_opts(opts) LOG.debug('volume opts %(opts)s.', {'opts': opts}) return opts def _get_opts_from_specs(self, opts_capability, opts_value, opts_associate, specs): """"""Get the well defined extra specs."""""" opts = {} opts.update(opts_capability) opts.update(opts_value) for key, value in specs.items(): # Get the scope, if is using scope format. scope = None key_split = key.split(':') if len(key_split) > 2 and key_split[0] != ""capabilities"": continue if len(key_split) == 1: key = key_split[0].lower() else: scope = key_split[0].lower() key = key_split[1].lower() if ((not scope or scope == 'capabilities') and key in opts_capability): words = value.split() if not (words and len(words) == 2 and words[0] == '<is>'): LOG.error(_LE(""Extra specs must be specified as "" ""capabilities:%s='<is> True' or "" ""'<is> true'.""), key) else: opts[key] = words[1].lower() if ((scope in opts_capability) and (key in opts_value) and (scope in opts_associate) and (opts_associate[scope] == key)): opts[key] = value return opts def _get_lun_params(self, volume, opts): pool_name = volume_utils.extract_host(volume['host'], level='pool') params = { 'TYPE': '11', 'NAME': huawei_utils.encode_name(volume['id']), 'PARENTTYPE': '216', 'PARENTID': self.client.get_pool_id(volume, pool_name), 'DESCRIPTION': volume['name'], 'ALLOCTYPE': opts.get('LUNType', self.configuration.lun_type), 'CAPACITY': huawei_utils.get_volume_size(volume), 'WRITEPOLICY': self.configuration.lun_write_type, 'MIRRORPOLICY': self.configuration.lun_mirror_switch, 'PREFETCHPOLICY': self.configuration.lun_prefetch_type, 'PREFETCHVALUE': self.configuration.lun_prefetch_value, 'DATATRANSFERPOLICY': opts.get('policy', self.configuration.lun_policy), 'READCACHEPOLICY': self.configuration.lun_read_cache_policy, 'WRITECACHEPOLICY': self.configuration.lun_write_cache_policy} LOG.info(_LI('volume: %(volume)s, lun params: %(params)s.'), {'volume': volume['id'], 'params': params}) return params def _create_volume(self, volume, lun_params): # Create LUN on the array. model_update = {} lun_info = self.client.create_lun(lun_params) model_update['provider_location'] = lun_info['ID'] metadata = huawei_utils.get_volume_metadata(volume) model_update['metadata'] = metadata return lun_info, model_update volume_type = self._get_volume_type(volume) opts = self._get_volume_params(volume_type) lun_params = self._get_lun_params(volume, opts) lun_info, model_update = self._create_volume(volume, lun_params) qos = smartx.SmartQos.get_qos_by_volume_type(volume_type) if qos: smart_qos = smartx.SmartQos(self.client) smart_qos.add(qos, lun_id) smartpartition = smartx.SmartPartition(self.client) smartcache = smartx.SmartCache(self.client) raise exception.VolumeBackendAPIException( data=_('Create volume error. Because %s.') % err) if opts.get('hypermetro'): metro = hypermetro.HuaweiHyperMetro(self.client, self.rmt_client, self.configuration, self.db) try: metro_info = metro.create_hypermetro(lun_id, lun_params) model_update['metadata'].update(metro_info) return model_update def _delete_volume(self, volume): lun_id = volume.get('provider_location', None) if not lun_id: return lun_group_ids = self.client.get_lungroupids_by_lunid(lun_id) if lun_group_ids and len(lun_group_ids) == 1: self.client.remove_lun_from_lungroup(lun_group_ids[0], lun_id) self.client.delete_lun(lun_id) lun_id = volume.get('provider_location', None) if not lun_id or not self.client.check_lun_exist(lun_id): qos_id = self.client.get_qosid_by_lunid(lun_id) if qos_id: smart_qos = smartx.SmartQos(self.client) smart_qos.remove(qos_id, lun_id) metadata = huawei_utils.get_volume_metadata(volume) if 'hypermetro_id' in metadata: metro = hypermetro.HuaweiHyperMetro(self.client, self.rmt_client, self.configuration, self.db) try: metro.delete_hypermetro(volume) except exception.VolumeBackendAPIException as err: LOG.exception(_LE('Delete hypermetro error: %s.'), err) self._delete_volume(volume) raise self._delete_volume(volume) def _delete_lun_with_check(self, lun_id): if not lun_id: return if self.client.check_lun_exist(lun_id): qos_id = self.client.get_qosid_by_lunid(lun_id) if qos_id: smart_qos = smartx.SmartQos(self.client) smart_qos.remove(qos_id, lun_id) self.client.delete_lun(lun_id) result = self.client.get_lun_migration_task() if 'data' not in result: return False for item in result['data']: if (src_id == item['PARENTID'] and dst_id == item['TARGETLUNID']): found_migration_task = True if constants.MIGRATION_COMPLETE == item['RUNNINGSTATUS']: return True if constants.MIGRATION_FAULT == item['RUNNINGSTATUS']: msg = _(""Lun migration error."") LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) result = self.client.get_lun_migration_task() self.client.create_lun_migration(src_id, dst_id) huawei_utils.wait_for_condition(_is_lun_migration_complete, wait_interval, self.configuration.lun_timeout) self.client.delete_lun_migration(src_id, dst_id) wait_interval = self.configuration.lun_ready_wait_interval result = self.client.get_lun_info(lun_id) huawei_utils.wait_for_condition(_volume_ready, return 'in-use' if volume.get('volume_attachment') else'available' lun_id = self.client.get_lun_id_by_name(current_name) try: self.client.rename_lun(lun_id, original_name) if target_device != self.client.device_id: protocol = self.configuration.san_protocol pools = self.client.get_all_pools() pool_info = self.client.get_pool_info(pool_name, pools) new_specs = new_type['extra_specs'] opts = self._get_volume_params_from_specs(new_specs) if 'LUNType' not in opts: opts['LUNType'] = self.configuration.lun_type qos = smartx.SmartQos.get_qos_by_volume_type(new_type) elif volume_type: qos = smartx.SmartQos.get_qos_by_volume_type(volume_type) opts = self._get_volume_params(volume_type) lun_info = self.client.get_lun_info(src_id) policy = lun_info['DATATRANSFERPOLICY'] if opts['policy']: policy = opts['policy'] lun_params = { 'NAME': dst_volume_name, 'PARENTID': pool_info['ID'], 'DESCRIPTION': lun_info['DESCRIPTION'], 'ALLOCTYPE': opts.get('LUNType', lun_info['ALLOCTYPE']), 'CAPACITY': lun_info['CAPACITY'], 'WRITEPOLICY': lun_info['WRITEPOLICY'], 'MIRRORPOLICY': lun_info['MIRRORPOLICY'], 'PREFETCHPOLICY': lun_info['PREFETCHPOLICY'], 'PREFETCHVALUE': lun_info['PREFETCHVALUE'], 'DATATRANSFERPOLICY': policy, 'READCACHEPOLICY': lun_info['READCACHEPOLICY'], 'WRITECACHEPOLICY': lun_info['WRITECACHEPOLICY'], 'OWNINGCONTROLLER': lun_info['OWNINGCONTROLLER']} lun_info = self.client.create_lun(lun_params) SmartQos = smartx.SmartQos(self.client) SmartQos.add(qos, lun_id) if opts: smartpartition = smartx.SmartPartition(self.client) smartcache = smartx.SmartCache(self.client) snapshot_id = self.client.get_snapshot_id_by_name(snapshotname) if snapshot_id is None: err_msg = (_( 'create_volume_from_snapshot: Snapshot %(name)s ' 'does not exist.') % {'name': snapshotname}) LOG.error(err_msg) raise exception.VolumeBackendAPIException(data=err_msg) model_update = self.create_volume(volume) tgt_lun_id = model_update['provider_location'] wait_interval = self.configuration.lun_ready_wait_interval result = self.client.get_lun_info(tgt_lun_id) huawei_utils.wait_for_condition(_volume_ready, return model_update if src_vref.get('provider_location', None) is None: msg = (_(""Can't find lun id from db, volume: %(id)s"") % {""id"": volume['id']}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) model_update = self.create_volume_from_snapshot(volume, snapshot) return model_update lun_id = volume.get('provider_location') if not lun_id: msg = (_(""Can't find lun id from db, volume: %(id)s"") % {""id"": volume['id']}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) old_size = huawei_utils.get_volume_size(volume) new_size = int(new_size) * units.Gi / 512 'Extend volume: %(volumename)s, ' 'oldsize: %(oldsize)s, newsize: %(newsize)s.'), 'oldsize': old_size, 'newsize': new_size}) lun_info = self.client.extend_lun(lun_id, new_size) return {'provider_location': lun_info['ID'], 'lun_info': lun_info} def create_snapshot(self, snapshot): volume = snapshot.get('volume') if not volume: msg = (_(""Can't find lun id from db, volume: %(id)s"") % {""id"": volume['id']}) LOG.error(msg) raise exception.VolumeBackendAPIException(data=msg) volume_name = huawei_utils.encode_name(snapshot['volume_id']) lun_id = self.client.get_lun_id(volume, volume_name) snapshot_name = huawei_utils.encode_name(snapshot['id']) snapshot_description = snapshot['id'] snapshot_info = self.client.create_snapshot(lun_id, snapshot_name, snapshot_description) self.client.activate_snapshot(snapshot_id) snapshot_id = self.client.get_snapshot_id_by_name(snapshotname) if self.client.check_snapshot_exist(snapshot_id): self.client.stop_snapshot(snapshot_id) self.client.delete_snapshot(snapshot_id) self.client.remove_lun_from_partition(lun_id, old_id) if new_id: self.client.add_lun_to_partition(lun_id, new_id) self.client.remove_lun_from_cache(lun_id, old_id) if new_id: self.client.add_lun_to_cache(lun_id, new_id) self.client.change_lun_smarttier(lun_id, new_policy) smart_qos = smartx.SmartQos(self.client) smart_qos.remove(old_qos_id, lun_id) if new_qos: smart_qos = smartx.SmartQos(self.client) smart_qos.add(new_qos, lun_id) lun_info = self.client.get_lun_info(lun_id) if lun_info.get('DATATRANSFERPOLICY'): if lun_info.get('SMARTCACHEPARTITIONID'): if lun_info.get('CACHEPARTITIONID'): new_opts = self._get_volume_params_from_specs(new_specs) if 'LUNType' not in new_opts: new_opts['LUNType'] = self.configuration.lun_type new_cache_id = self.client.get_cache_id_by_name(new_cache_name) new_partition_id = self.client.get_partition_id_by_name( cache_info = self.client.get_cache_info_by_id(old_cache_id) partition_info = self.client.get_partition_info_by_id( new_qos = smartx.SmartQos.get_qos_by_volume_type(new_type) old_qos_id = self.client.get_qosid_by_lunid(lun_id) qos_info = self.client.get_qos_info(qos_id) luncopy_id = self.client.create_luncopy(copy_name, src_lun, tgt_lun) wait_interval = self.configuration.lun_copy_wait_interval self.client.start_luncopy(luncopy_id) luncopy_info = self.client.get_luncopy_info(luncopy_id) huawei_utils.wait_for_condition(_luncopy_complete, wait_interval, self.configuration.lun_timeout) self.client.delete_luncopy(luncopy_id) self.client.delete_luncopy(luncopy_id) portgroup_id) = self.client.get_iscsi_params(connector) original_host_name = connector['host'] host_name = huawei_utils.encode_host_name(original_host_name) host_id = self.client.add_host_with_check(host_name, original_host_name) self.client.ensure_initiator_added(initiator_name, host_id) hostgroup_id = self.client.add_host_to_hostgroup(host_id) lun_id = self.client.get_lun_id(volume, volume_name) self.client.do_mapping(lun_id, hostgroup_id, host_id, portgroup_id) hostlun_id = self.client.get_host_lun_id(host_id, lun_id) chapinfo = self.client.find_chap_info(self.configuration.iscsi_info, initiator_name) for ini in self.configuration.iscsi_info: portgroup_id = self.client.get_tgt_port_group(portgroup) host_name = huawei_utils.encode_host_name(host_name) host_id = self.client.get_host_id_by_name(host_name) view_id = self.client.find_mapping_view(mapping_view_name) if view_id: lungroup_id = self.client.find_lungroup_from_map(view_id) if lun_id and self.client.check_lun_exist(lun_id): if lungroup_id: lungroup_ids = self.client.get_lungroupids_by_lunid(lun_id) if lungroup_id in lungroup_ids: self.client.remove_lun_from_lungroup(lungroup_id, lun_id) left_lunnum = self.client.get_lunnum_from_lungroup(lungroup_id) if self.client.is_portgroup_associated_to_view(view_id, portgroup_id): self.client.delete_portgroup_mapping_view(view_id, portgroup_id) if view_id and (int(left_lunnum) <= 0): self.client.remove_chap(initiator_name) if self.client.lungroup_associated(view_id, lungroup_id): self.client.delete_lungroup_mapping_view(view_id, lungroup_id) self.client.delete_lungroup(lungroup_id) if self.client.is_initiator_associated_to_host(initiator_name): self.client.remove_iscsi_from_host(initiator_name) hostgroup_id = self.client.find_hostgroup(hostgroup_name) if hostgroup_id: if self.client.hostgroup_associated(view_id, hostgroup_id): self.client.delete_hostgoup_mapping_view(view_id, hostgroup_id) self.client.remove_host_from_hostgroup(hostgroup_id, host_id) self.client.delete_hostgroup(hostgroup_id) self.client.remove_host(host_id) self.client.delete_mapping_view(view_id) """"""FC driver for Huawei OceanStor 18000 storage arrays. lun_id = self.client.get_lun_id(volume, volume_name) original_host_name = connector['host'] host_name = huawei_utils.encode_host_name(original_host_name) host_id = self.client.add_host_with_check(host_name, original_host_name) host_id = self.client.add_host_with_check( host_name, original_host_name) self.fcsan_lookup_service, self.client) self.client.ensure_fc_initiator_added(ini, host_id) host_id = self.client.add_host_with_check( host_name, original_host_name) self.client.get_host_online_fc_initiators(host_id)) online_free_wwns = self.client.get_online_free_wwns() self.client.get_host_fc_initiators(host_id)) self.client.get_host_iscsi_initiators(host_id)) if not wwns_in_host and not iqns_in_host: self.client.remove_host(host_id) self.client.add_fc_port_to_host(host_id, wwn) self.client.get_init_targ_map(wwns)) hostgroup_id = self.client.add_host_to_hostgroup(host_id) map_info = self.client.do_mapping(lun_id, hostgroup_id, host_id) host_lun_id = self.client.get_host_lun_id(host_id, lun_id) hyperm = hypermetro.HuaweiHyperMetro(self.client, self.client.change_hostlun_id(loc_map_info, same_host_id) @utils.synchronized('huawei', external=True) host_name = huawei_utils.encode_host_name(host_name) host_id = self.client.get_host_id_by_name(host_name) view_id = self.client.find_mapping_view(mapping_view_name) if view_id: lungroup_id = self.client.find_lungroup_from_map(view_id) if (lun_id is not None and self.client.check_lun_exist(lun_id)): if lungroup_id: lungroup_ids = self.client.get_lungroupids_by_lunid(lun_id) if lungroup_id in lungroup_ids: self.client.remove_lun_from_lungroup(lungroup_id, lun_id) left_lunnum = self.client.get_lunnum_from_lungroup(lungroup_id) self.fcsan_lookup_service, self.client) self.client.get_init_targ_map(wwns)) if self.client.is_fc_initiator_associated_to_host(wwn): self.client.remove_fc_from_host(wwn) if lungroup_id: if view_id and self.client.lungroup_associated( view_id, lungroup_id): self.client.delete_lungroup_mapping_view(view_id, lungroup_id) self.client.delete_lungroup(lungroup_id) hostgroup_id = self.client.find_hostgroup(hostgroup_name) if hostgroup_id: if view_id and self.client.hostgroup_associated( view_id, hostgroup_id): self.client.delete_hostgoup_mapping_view( self.client.remove_host_from_hostgroup( self.client.delete_hostgroup(hostgroup_id) if not self.client.check_fc_initiators_exist_in_host( host_id): self.client.remove_host(host_id) self.client.delete_mapping_view(view_id) hyperm = hypermetro.HuaweiHyperMetro(self.client,"," self.configuration = kwargs.get('configuration') if not self.configuration: msg = _('_instantiate_driver: configuration not found.') self.xml_file_path = self.configuration.cinder_huawei_conf_file self.hypermetro_devices = self.configuration.hypermetro_devices self.restclient = rest_client.RestClient(self.configuration) return self.restclient.login() """"""Check configuration file."""""" return huawei_utils.check_conf_file(self.xml_file_path) """"""Get volume status."""""" return self.restclient.update_volume_stats() @utils.synchronized('huawei', external=True) opts = huawei_utils.get_volume_params(volume) smartx_opts = smartx.SmartX().get_smartx_specs_opts(opts) params = huawei_utils.get_lun_params(self.xml_file_path, smartx_opts) pool_name = volume_utils.extract_host(volume['host'], level='pool') pools = self.restclient.find_all_pools() pool_info = self.restclient.find_pool_info(pool_name, pools) if not pool_info: # The following code is to keep compatibility with old version of # Huawei driver. pool_names = huawei_utils.get_pools(self.xml_file_path) for pool_name in pool_names.split("";""): pool_info = self.restclient.find_pool_info(pool_name, pools) if pool_info: break volume_name = huawei_utils.encode_name(volume['id']) volume_description = volume['name'] volume_size = huawei_utils.get_volume_size(volume) LOG.info(_LI( 'Create volume: %(volume)s, size: %(size)s.'), {'volume': volume_name, 'size': volume_size}) params['pool_id'] = pool_info['ID'] params['volume_size'] = volume_size params['volume_description'] = volume_description # Prepare LUN parameters. lun_param = huawei_utils.init_lun_parameters(volume_name, params) # Create LUN on the array. lun_info = self.restclient.create_volume(lun_param) qos = huawei_utils.get_volume_qos(volume) if qos: smart_qos = smartx.SmartQos(self.restclient) smart_qos.create_qos(qos, lun_id) smartpartition = smartx.SmartPartition(self.restclient) smartcache = smartx.SmartCache(self.restclient) raise exception.InvalidInput( reason=_('Create volume error. Because %s.') % err) # Update the metadata. LOG.info(_LI('Create volume option: %s.'), opts) metadata = huawei_utils.get_volume_metadata(volume) if opts.get('hypermetro'): hyperm = hypermetro.HuaweiHyperMetro(self.restclient, None, self.configuration) try: metro_id, remote_lun_id = hyperm.create_hypermetro(lun_id, lun_param) LOG.info(_LI(""Hypermetro id: %(metro_id)s. "" ""Remote lun id: %(remote_lun_id)s.""), {'metro_id': metro_id, 'remote_lun_id': remote_lun_id}) metadata.update({'hypermetro_id': metro_id, 'remote_lun_id': remote_lun_id}) return {'provider_location': lun_id, 'ID': lun_id, 'metadata': metadata} @utils.synchronized('huawei', external=True) name = huawei_utils.encode_name(volume['id']) lun_id = volume.get('provider_location') LOG.info(_LI('Delete volume: %(name)s, array lun id: %(lun_id)s.'), {'name': name, 'lun_id': lun_id},) if lun_id: if self.restclient.check_lun_exist(lun_id): qos_id = self.restclient.get_qosid_by_lunid(lun_id) if qos_id: self.remove_qos_lun(lun_id, qos_id) metadata = huawei_utils.get_volume_metadata(volume) if 'hypermetro_id' in metadata: hyperm = hypermetro.HuaweiHyperMetro(self.restclient, None, self.configuration) try: hyperm.delete_hypermetro(volume) except exception.VolumeBackendAPIException as err: LOG.exception(_LE('Delete hypermetro error: %s.'), err) self.restclient.delete_lun(lun_id) raise self.restclient.delete_lun(lun_id) else: def remove_qos_lun(self, lun_id, qos_id): lun_list = self.restclient.get_lun_list_in_qos(qos_id) lun_count = len(lun_list) if lun_count <= 1: qos = smartx.SmartQos(self.restclient) qos.delete_qos(qos_id) else: self.restclient.remove_lun_from_qos(lun_id, lun_list, qos_id) def _delete_lun_with_check(self, lun_id): if lun_id: if self.restclient.check_lun_exist(lun_id): qos_id = self.restclient.get_qosid_by_lunid(lun_id) if qos_id: self.remove_qos_lun(lun_id, qos_id) self.restclient.delete_lun(lun_id) result = self.restclient.get_lun_migration_task() if 'data' in result: for item in result['data']: if (src_id == item['PARENTID'] and dst_id == item['TARGETLUNID']): found_migration_task = True if constants.MIGRATION_COMPLETE == item['RUNNINGSTATUS']: return True if constants.MIGRATION_FAULT == item['RUNNINGSTATUS']: err_msg = _(""Lun migration error."") LOG.error(err_msg) raise exception.VolumeBackendAPIException(data=err_msg) result = self.restclient.get_lun_migration_task() self.restclient.create_lun_migration(src_id, dst_id) huawei_utils.wait_for_condition(self.xml_file_path, _is_lun_migration_complete, wait_interval) self.restclient.delete_lun_migration(src_id, dst_id) event_type = 'LUNReadyWaitInterval' wait_interval = huawei_utils.get_wait_interval(self.xml_file_path, event_type) result = self.restclient.get_lun_info(lun_id) huawei_utils.wait_for_condition(self.xml_file_path, _volume_ready, if not volume['volume_attachment']: return 'available' else: return 'in-use' lun_id = self.restclient.get_volume_by_name(current_name) try: self.restclient.rename_lun(lun_id, original_name) if target_device != self.restclient.device_id: protocol = huawei_utils.get_protocol(self.xml_file_path) pools = self.restclient.find_all_pools() pool_info = self.restclient.find_pool_info(pool_name, pools) src_lun_params = self.restclient.get_lun_info(src_id) opts = huawei_utils._get_extra_spec_value( new_type['extra_specs']) opts = smartx.SmartX().get_smartx_specs_opts(opts) if 'LUNType' not in opts: opts['LUNType'] = huawei_utils.find_luntype_in_xml( self.xml_file_path) qos = huawei_utils.get_qos_by_volume_type(new_type) elif volume_type: qos = huawei_utils.get_qos_by_volume_type(volume_type) opts = huawei_utils.get_volume_params(volume) opts = smartx.SmartX().get_smartx_specs_opts(opts) lun_info = self._create_lun_with_extra_feature(pool_info, dst_volume_name, src_lun_params, opts) SmartQos = smartx.SmartQos(self.restclient) SmartQos.create_qos(qos, lun_id) if opts: smartpartition = smartx.SmartPartition(self.restclient) smartcache = smartx.SmartCache(self.restclient) def _create_lun_with_extra_feature(self, pool_info, lun_name, lun_params, spec_opts): LOG.info(_LI('Create a new lun %s for migration.'), lun_name) # Prepare lun parameters. lunparam = {""TYPE"": '11', ""NAME"": lun_name, ""PARENTTYPE"": '216', ""PARENTID"": pool_info['ID'], ""ALLOCTYPE"": lun_params['ALLOCTYPE'], ""CAPACITY"": lun_params['CAPACITY'], ""WRITEPOLICY"": lun_params['WRITEPOLICY'], ""MIRRORPOLICY"": lun_params['MIRRORPOLICY'], ""PREFETCHPOLICY"": lun_params['PREFETCHPOLICY'], ""PREFETCHVALUE"": lun_params['PREFETCHVALUE'], ""DATATRANSFERPOLICY"": '0', ""READCACHEPOLICY"": lun_params['READCACHEPOLICY'], ""WRITECACHEPOLICY"": lun_params['WRITECACHEPOLICY'], ""OWNINGCONTROLLER"": lun_params['OWNINGCONTROLLER'], } if 'LUNType' in spec_opts: lunparam['ALLOCTYPE'] = spec_opts['LUNType'] if spec_opts['policy']: lunparam['DATATRANSFERPOLICY'] = spec_opts['policy'] lun_info = self.restclient.create_volume(lunparam) return lun_info snapshot_id = self.restclient.get_snapshotid_by_name(snapshotname) if snapshot_id is None: err_msg = (_( 'create_volume_from_snapshot: Snapshot %(name)s ' 'does not exist.') % {'name': snapshotname}) LOG.error(err_msg) raise exception.VolumeBackendAPIException(data=err_msg) lun_info = self.create_volume(volume) tgt_lun_id = lun_info['ID'] event_type = 'LUNReadyWaitInterval' wait_interval = huawei_utils.get_wait_interval(self.xml_file_path, event_type) result = self.restclient.get_lun_info(tgt_lun_id) huawei_utils.wait_for_condition(self.xml_file_path, _volume_ready, return {'ID': lun_info['ID'], 'lun_info': lun_info} lun_info = self.create_volume_from_snapshot(volume, snapshot) return {'provider_location': lun_info['ID'], 'lun_info': lun_info} @utils.synchronized('huawei', external=True) volume_size = huawei_utils.get_volume_size(volume) new_volume_size = int(new_size) * units.Gi / 512 'Extend volume: %(volumename)s, oldsize:' ' %(oldsize)s newsize: %(newsize)s.'), 'oldsize': volume_size, 'newsize': new_volume_size},) lun_id = self.restclient.get_lunid(volume, volume_name) luninfo = self.restclient.extend_volume(lun_id, new_volume_size) return {'provider_location': luninfo['ID'], 'lun_info': luninfo} @utils.synchronized('huawei', external=True) def create_snapshot(self, snapshot): snapshot_info = self.restclient.create_snapshot(snapshot) self.restclient.activate_snapshot(snapshot_id) @utils.synchronized('huawei', external=True) snapshot_id = self.restclient.get_snapshotid_by_name(snapshotname) if self.restclient.check_snapshot_exist(snapshot_id): self.restclient.stop_snapshot(snapshot_id) self.restclient.delete_snapshot(snapshot_id) self.restclient.remove_lun_from_partition(lun_id, old_id) if new_id: self.restclient.add_lun_to_partition(lun_id, new_id) self.restclient.remove_lun_from_cache(lun_id, old_id) if new_id: self.restclient.add_lun_to_cache(lun_id, new_id) self.restclient.change_lun_smarttier(lun_id, new_policy) self.remove_qos_lun(lun_id, old_qos_id) if new_qos: smart_qos = smartx.SmartQos(self.restclient) smart_qos.create_qos(new_qos, lun_id) lun_info = self.restclient.get_lun_info(lun_id) if lun_info['DATATRANSFERPOLICY']: if lun_info['SMARTCACHEPARTITIONID']: if lun_info['CACHEPARTITIONID']: new_opts = huawei_utils._get_extra_spec_value(new_specs) new_opts = smartx.SmartX().get_smartx_specs_opts(new_opts) if 'LUNType' not in new_opts: new_opts['LUNType'] = huawei_utils.find_luntype_in_xml( self.xml_file_path) new_cache_id = self.restclient.get_cache_id_by_name(new_cache_name) new_partition_id = self.restclient.get_partition_id_by_name( cache_info = self.restclient.get_cache_info_by_id(old_cache_id) partition_info = self.restclient.get_partition_info_by_id( new_qos = huawei_utils.get_qos_by_volume_type(new_type) old_qos_id = self.restclient.get_qosid_by_lunid(lun_id) qos_info = self.restclient.get_qos_info(qos_id) luncopy_id = self.restclient.create_luncopy(copy_name, src_lun, tgt_lun) event_type = 'LUNcopyWaitInterval' wait_interval = huawei_utils.get_wait_interval(self.xml_file_path, event_type) self.restclient.start_luncopy(luncopy_id) luncopy_info = self.restclient.get_luncopy_info(luncopy_id) huawei_utils.wait_for_condition(self.xml_file_path, _luncopy_complete, wait_interval) self.restclient.delete_luncopy(luncopy_id) self.restclient.delete_luncopy(luncopy_id) portgroup_id) = self.restclient.get_iscsi_params(self.xml_file_path, connector) host_name = connector['host'] host_name_before_hash = None if host_name and (len(host_name) > constants.MAX_HOSTNAME_LENGTH): host_name_before_hash = host_name host_name = six.text_type(hash(host_name)) host_id = self.restclient.add_host_with_check(host_name, host_name_before_hash) self.restclient.ensure_initiator_added(self.xml_file_path, initiator_name, host_id) hostgroup_id = self.restclient.add_host_into_hostgroup(host_id) lun_id = self.restclient.get_lunid(volume, volume_name) self.restclient.do_mapping(lun_id, hostgroup_id, host_id, portgroup_id) hostlun_id = self.restclient.find_host_lun_id(host_id, lun_id) iscsi_conf = huawei_utils.get_iscsi_conf(self.xml_file_path) chapinfo = self.restclient.find_chap_info(iscsi_conf, initiator_name) iscsi_conf = huawei_utils.get_iscsi_conf(self.xml_file_path) for ini in iscsi_conf['Initiator']: portgroup_id = self.restclient.find_tgt_port_group(portgroup) if host_name and (len(host_name) > constants.MAX_HOSTNAME_LENGTH): host_name = six.text_type(hash(host_name)) host_id = self.restclient.find_host(host_name) view_id = self.restclient.find_mapping_view(mapping_view_name) if view_id: lungroup_id = self.restclient.find_lungroup_from_map(view_id) if lun_id and self.restclient.check_lun_exist(lun_id): if lungroup_id: lungroup_ids = self.restclient.get_lungroupids_by_lunid(lun_id) if lungroup_id in lungroup_ids: self.restclient.remove_lun_from_lungroup(lungroup_id, lun_id) left_lunnum = self.restclient.get_lunnum_from_lungroup(lungroup_id) if self.restclient.is_portgroup_associated_to_view(view_id, portgroup_id): self.restclient.delete_portgroup_mapping_view(view_id, portgroup_id) if view_id and (int(left_lunnum) <= 0): self.restclient.remove_chap(initiator_name) if self.restclient.lungroup_associated(view_id, lungroup_id): self.restclient.delete_lungroup_mapping_view(view_id, lungroup_id) self.restclient.delete_lungroup(lungroup_id) if self.restclient.is_initiator_associated_to_host(initiator_name): self.restclient.remove_iscsi_from_host(initiator_name) hostgroup_id = self.restclient.find_hostgroup(hostgroup_name) if hostgroup_id: if self.restclient.hostgroup_associated(view_id, hostgroup_id): self.restclient.delete_hostgoup_mapping_view(view_id, hostgroup_id) self.restclient.remove_host_from_hostgroup(hostgroup_id, host_id) self.restclient.delete_hostgroup(hostgroup_id) self.restclient.remove_host(host_id) self.restclient.delete_mapping_view(view_id) """"""FC driver for Huawei storage arrays. lun_id = self.restclient.get_lunid(volume, volume_name) host_name_before_hash = None host_name = connector['host'] if host_name and (len(host_name) > constants.MAX_HOSTNAME_LENGTH): host_name_before_hash = host_name host_name = six.text_type(hash(host_name)) host_id = self.restclient.add_host_with_check( host_name, host_name_before_hash) self.fcsan_lookup_service, self.restclient) self.restclient.ensure_fc_initiator_added(ini, host_id) host_id = self.restclient.add_host_with_check( host_name, host_name_before_hash) self.restclient.get_host_online_fc_initiators(host_id)) online_free_wwns = self.restclient.get_online_free_wwns() self.restclient.get_host_fc_initiators(host_id)) self.restclient.get_host_iscsi_initiators(host_id)) if not wwns_in_host and not iqns_in_host: self.restclient.remove_host(host_id) self.restclient.add_fc_port_to_host(host_id, wwn) self.restclient.get_init_targ_map(wwns)) hostgroup_id = self.restclient.add_host_into_hostgroup(host_id) map_info = self.restclient.do_mapping(lun_id, hostgroup_id, host_id) host_lun_id = self.restclient.find_host_lun_id(host_id, lun_id) hyperm = hypermetro.HuaweiHyperMetro(self.restclient, None, self.restclient.change_hostlun_id(loc_map_info, same_host_id) if host_name and len(host_name) > constants.MAX_HOSTNAME_LENGTH: host_name = six.text_type(hash(host_name)) host_id = self.restclient.find_host(host_name) view_id = self.restclient.find_mapping_view(mapping_view_name) if view_id: lungroup_id = self.restclient.find_lungroup_from_map(view_id) if lun_id and self.restclient.check_lun_exist(lun_id): if lungroup_id: lungroup_ids = self.restclient.get_lungroupids_by_lunid(lun_id) if lungroup_id in lungroup_ids: self.restclient.remove_lun_from_lungroup(lungroup_id, lun_id) left_lunnum = self.restclient.get_lunnum_from_lungroup(lungroup_id) self.fcsan_lookup_service, self.restclient) self.restclient.get_init_targ_map(wwns)) if self.restclient.is_fc_initiator_associated_to_host(wwn): self.restclient.remove_fc_from_host(wwn) if lungroup_id: if view_id and self.restclient.lungroup_associated( view_id, lungroup_id): self.restclient.delete_lungroup_mapping_view(view_id, lungroup_id) self.restclient.delete_lungroup(lungroup_id) hostgroup_id = self.restclient.find_hostgroup(hostgroup_name) if hostgroup_id: if view_id and self.restclient.hostgroup_associated( view_id, hostgroup_id): self.restclient.delete_hostgoup_mapping_view( self.restclient.remove_host_from_hostgroup( self.restclient.delete_hostgroup(hostgroup_id) if not self.restclient.check_fc_initiators_exist_in_host( host_id): self.restclient.remove_host(host_id) self.restclient.delete_mapping_view(view_id) hyperm = hypermetro.HuaweiHyperMetro(self.restclient, None,",1752,1817
openstack%2Fopenstack-manuals~master~I57137516d14cfff42de6a9f96a6c2ecda48cc7b5,openstack/openstack-manuals,master,I57137516d14cfff42de6a9f96a6c2ecda48cc7b5,[config-ref] Convert KVM backing storage to RST,MERGED,2015-12-11 19:54:13.000000000,2015-12-12 08:29:21.000000000,2015-12-12 08:29:19.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 19:54:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/defe9d9710c126d48ed3a8300c52edf6c882f956', 'message': '[config-ref] Convert KVM backing storage to RST\n\nAdd the content to the parent file to avoid includes.\n\nChange-Id: I57137516d14cfff42de6a9f96a6c2ecda48cc7b5\nImplements: blueprint config-ref-rst\n'}, {'number': 2, 'created': '2015-12-12 06:56:24.000000000', 'files': ['doc/config-ref-rst/source/compute/hypervisor-kvm.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/df27acf940f83fa2438a22131cbf8260625c0646', 'message': '[config-ref] Convert KVM backing storage to RST\n\nAdd the content to the parent file to avoid includes.\n\nChange-Id: I57137516d14cfff42de6a9f96a6c2ecda48cc7b5\nImplements: blueprint config-ref-rst\n'}]",1,256643,df27acf940f83fa2438a22131cbf8260625c0646,11,4,2,7923,,,0,"[config-ref] Convert KVM backing storage to RST

Add the content to the parent file to avoid includes.

Change-Id: I57137516d14cfff42de6a9f96a6c2ecda48cc7b5
Implements: blueprint config-ref-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/43/256643/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/compute/hypervisor-kvm.rst'],1,defe9d9710c126d48ed3a8300c52edf6c882f956,bp/config-ref-rst,"Configure Compute backing storage ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Backing Storage is the storage used to provide the expanded operating system image, and any ephemeral storage. Inside the virtual machine, this is normally presented as two virtual hard disks (for example, ``/dev/vda`` and ``/dev/vdb`` respectively). However, inside OpenStack, this can be derived from one of three methods: LVM, QCOW or RAW, chosen using the ``images_type`` option in ``nova.conf`` on the compute node. QCOW is the default backing store. It uses a copy-on-write philosophy to delay allocation of storage until it is actually needed. This means that the space required for the backing of an image can be significantly less on the real disk than what seems available in the virtual machine operating system. RAW creates files without any sort of file formatting, effectively creating files with the plain binary one would normally see on a real disk. This can increase performance, but means that the entire size of the virtual disk is reserved on the physical disk. Local `LVM volumes <http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)>`__ can also be used. Set ``images_volume_group = nova_local`` where ``nova_local`` is the name of the LVM group you have created. ",,25,0
openstack%2Foslo.versionedobjects~master~I76c5eba2f3cd39ec55390ea69071e0545858f68c,openstack/oslo.versionedobjects,master,I76c5eba2f3cd39ec55390ea69071e0545858f68c,Updated from global requirements,MERGED,2015-12-11 15:24:43.000000000,2015-12-12 07:50:53.000000000,2015-12-12 07:50:52.000000000,"[{'_account_id': 3}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:24:43.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.versionedobjects/commit/193dd3032f55ffbfb24677738b8ad09cb1c5ad1e', 'message': 'Updated from global requirements\n\nChange-Id: I76c5eba2f3cd39ec55390ea69071e0545858f68c\n'}]",0,256511,193dd3032f55ffbfb24677738b8ad09cb1c5ad1e,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I76c5eba2f3cd39ec55390ea69071e0545858f68c
",git fetch https://review.opendev.org/openstack/oslo.versionedobjects refs/changes/11/256511/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,193dd3032f55ffbfb24677738b8ad09cb1c5ad1e,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Foslo.messaging~master~I508787c0db4dcec2c0027b89eb4e65c4f98022b9,openstack/oslo.messaging,master,I508787c0db4dcec2c0027b89eb4e65c4f98022b9,Move to debug a too verbose log,MERGED,2015-12-11 10:03:28.000000000,2015-12-12 07:37:31.000000000,2015-12-12 07:37:30.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 9796}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-12-11 10:03:28.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/17ccb2306d03a74304c57d31716a54ba2b3b4311', 'message': 'Move to debug a too verbose log\n\nWhen a client is gone (died/restart) and somes replies cannot be sent because\nthe the exchange of this client will never comeback. We log one message per\nreply every 0.25 messages during 60 seconds. When the only useful log\nis the one where we decide to drop this replies.\n\nThis change moves the less important message to debug level.\n\nChange-Id: I508787c0db4dcec2c0027b89eb4e65c4f98022b9\nRelated-bug: #1524418\n'}]",0,256312,17ccb2306d03a74304c57d31716a54ba2b3b4311,9,6,1,2813,,,0,"Move to debug a too verbose log

When a client is gone (died/restart) and somes replies cannot be sent because
the the exchange of this client will never comeback. We log one message per
reply every 0.25 messages during 60 seconds. When the only useful log
is the one where we decide to drop this replies.

This change moves the less important message to debug level.

Change-Id: I508787c0db4dcec2c0027b89eb4e65c4f98022b9
Related-bug: #1524418
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/12/256312/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/amqpdriver.py'],1,17ccb2306d03a74304c57d31716a54ba2b3b4311,bug/1524418," LOG.debug((""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})"," LOG.info(_LI(""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})",5,5
openstack%2Foslo.privsep~master~Ib2794c412466305193418c9fac10c44d68ec488e,openstack/oslo.privsep,master,Ib2794c412466305193418c9fac10c44d68ec488e,Updated from global requirements,MERGED,2015-12-11 15:24:21.000000000,2015-12-12 07:34:43.000000000,2015-12-12 07:34:42.000000000,"[{'_account_id': 3}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:24:21.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.privsep/commit/213eec8c097d8bacd125b23dac9aec0173b98098', 'message': 'Updated from global requirements\n\nChange-Id: Ib2794c412466305193418c9fac10c44d68ec488e\n'}]",0,256507,213eec8c097d8bacd125b23dac9aec0173b98098,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: Ib2794c412466305193418c9fac10c44d68ec488e
",git fetch https://review.opendev.org/openstack/oslo.privsep refs/changes/07/256507/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,213eec8c097d8bacd125b23dac9aec0173b98098,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ffuel-main~master~I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991,openstack/fuel-main,master,I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991,Align fuel packages version schema with perestroika,MERGED,2015-12-09 15:55:44.000000000,2015-12-12 07:31:41.000000000,2015-12-12 07:31:39.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 9582}, {'_account_id': 10474}, {'_account_id': 12817}]","[{'number': 1, 'created': '2015-12-09 15:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/01d70d3fd979c9b93c16179e120206fa60abd793', 'message': '[WIP] Align packaging schema with perestroika\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 2, 'created': '2015-12-09 20:36:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/606de80b372e3d3a55346d764749a6fc9fc92282', 'message': '[WIP] Align packaging schema with perestroika\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 3, 'created': '2015-12-10 12:35:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/606675816cea0946500b7b348613be04e27f5638', 'message': 'Align packaging schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 4, 'created': '2015-12-10 12:41:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/0b1e1b9748355c8867fb90ed5f763f28bc10f5e6', 'message': 'Align packaging schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 5, 'created': '2015-12-10 14:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a1267614851f4ba88b8b2e1942882636de35db9f', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 6, 'created': '2015-12-10 15:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a5a9527e7f2cae260f0fa9f17be7829b419df53b', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 7, 'created': '2015-12-10 16:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/71f80affd04dc8b4f8a107ccb40e0a773ea814d3', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 8, 'created': '2015-12-10 16:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/896593cdf1d3803fce7c73193ff5d5a9a5220524', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 9, 'created': '2015-12-10 16:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fdaca0937812d188b4fa20b115af919cfabc489a', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 10, 'created': '2015-12-10 20:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6511c583a23202f22b2b742b03387177a74da1bb', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 11, 'created': '2015-12-11 11:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/881061ff5064147de0cd8f9d9575277016791fb1', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 12, 'created': '2015-12-11 15:21:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5b8232293e64f0048ee4e05ff1269f2a01b93838', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}, {'number': 13, 'created': '2015-12-11 15:30:21.000000000', 'files': ['repos.mk', 'packages/deb/module.mk', 'packages/module.mk', 'packages/rpm/module.mk'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/7702258023b34e67e94594aef0d679a67fd844c5', 'message': 'Align fuel packages version schema with perestroika\n\nFuel packages should be aligned to the same versioning schema\nas we have in perestroika and specs [1]\n\n[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \\\n    8.0/separate-mos-from-centos.rst\n\nCloses-bug: #1524758\n\nChange-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991\n'}]",2,255335,7702258023b34e67e94594aef0d679a67fd844c5,38,6,13,12817,,,0,"Align fuel packages version schema with perestroika

Fuel packages should be aligned to the same versioning schema
as we have in perestroika and specs [1]

[1] https://github.com/openstack/fuel-specs/blob/master/specs/ \
    8.0/separate-mos-from-centos.rst

Closes-bug: #1524758

Change-Id: I1b5bd2617b6d388b2c4852d5f74ae3adf84f8991
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/35/255335/7 && git format-patch -1 --stdout FETCH_HEAD,"['repos.mk', 'packages/deb/module.mk', 'packages/module.mk']",3,01d70d3fd979c9b93c16179e120206fa60abd793,255335,# RELEASE=1.mos${commit_num} echo RELEASE=1.mos`git -C $3 rev-list --no-merges $4 --count` >> $$(VERSIONFILE) \,"# if gerrit commit is given then # RELEASE=${commit_num}.0.gerrit${request_number}.${patchset_number}.git${git_sha} # else # RELEASE=${commit_num}.1.git${git_sha} test -z $(GERRIT_BRANCH) && echo -n RELEASE=`git -C $3 rev-list --no-merges $4 --count` >> $$(VERSIONFILE) \ || echo -n RELEASE=`git -C $3 rev-list --no-merges $(GERRIT_BRANCH) --count` >> $$(VERSIONFILE) test -z $(GERRIT_BRANCH) && echo -n "".1"" >> $$(VERSIONFILE) \ || echo -n "".2.gerrit""`echo $5 | sed 's].*\/.*\/\(.*\/.*\)]\1]' | sed 's/\//./'` >> $$(VERSIONFILE) test -z $(GERRIT_BRANCH) && echo "".git`git -C $3 rev-parse --short $4`"" >> $$(VERSIONFILE) \ || echo "".git`git -C $3 rev-parse --short $(GERRIT_BRANCH)`"" >> $$(VERSIONFILE)",3,20
openstack%2Fopenstack-manuals~stable%2Fliberty~Ia81789e278629c653be9d56695d4473f2b6f3d89,openstack/openstack-manuals,stable/liberty,Ia81789e278629c653be9d56695d4473f2b6f3d89,Imported Translations from Zanata,MERGED,2015-12-12 06:26:16.000000000,2015-12-12 06:47:53.000000000,2015-12-12 06:47:53.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-12 06:26:16.000000000', 'files': ['doc/common-rst/source/locale/zh_CN/LC_MESSAGES/common-rst.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po', 'doc/common-rst/source/locale/ko_KR/LC_MESSAGES/common-rst.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a20ffe040d7320b39165f4ad2fc02c1bde139290', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ia81789e278629c653be9d56695d4473f2b6f3d89\n'}]",0,256913,a20ffe040d7320b39165f4ad2fc02c1bde139290,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ia81789e278629c653be9d56695d4473f2b6f3d89
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/13/256913/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common-rst/source/locale/zh_CN/LC_MESSAGES/common-rst.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po', 'doc/common-rst/source/locale/ko_KR/LC_MESSAGES/common-rst.po']",3,a20ffe040d7320b39165f4ad2fc02c1bde139290,zanata/translations,"""PO-Revision-Date: 2015-12-12 03:14+0000\n""msgid ""**Instance errors**"" msgstr ""**인스턴스 오류**"" ""A great way to get answers and insights is to post your question or "" ""problematic scenario to the OpenStack mailing list. You can learn from and "" ""help others who might have similar issues. To subscribe or view the "" ""archives, go to http://lists.openstack.org/cgi-bin/mailman/listinfo/"" ""openstack. You might be interested in the other mailing lists for specific "" ""projects or development, which you can find `on the wiki <https://wiki."" ""openstack.org/wiki/MailingLists>`__. A description of all mailing lists is "" ""available at https://wiki.openstack.org/wiki/MailingLists."" msgstr """" ""답변 및 통찰을 얻는 정말 좋은 방법으로는 질문 또는 문제가 있는 시나리오를 "" ""OpenStack 메일링리스트에 올리는 것입니다. 비슷한 이슈를 겪었을지도 모르는 다"" ""른 사람들로부터 배우거나 그 분들에게 도움을 줄 수 있습니다. 구독하거나 보관"" ""된 내용을 보려면, http://lists.openstack.org/cgi-bin/mailman/listinfo/"" ""openstack 을 살펴 봅니다. 구체적인 프로젝트 또는 다른 메일링리스트에 관심이 "" ""있을 수도 있습니다. 이 경우, `위키에서 <https://wiki.openstack.org/wiki/"" ""MailingLists>`__ 찾을 수 있습니다. 모든 메일링리스트에 대한 설명은 https://"" ""wiki.openstack.org/wiki/MailingLists 에서 확인 가능합니다."" msgid """"msgid ""An L2 network segment within Networking."" msgstr ""네트워킹 내 L2 네트워크 세그먼트"" msgid """" ""Any deployment-specific information is helpful, such as whether you are "" ""using Ubuntu 14.04 or are performing a multi-node installation."" msgstr """" ""Ubuntu 14.04를 사용한다든지 멀티 노드 설치를 수행하고 있다는 것과 같이 개발"" ""에 구체적인 어떠한 정보라도 도움이 됩니다."" msgid """" ""Be sure to include the software and package versions that you are using, "" ""especially if you are using a development branch, such as, ``\""Kilo release"" ""\"" vs git commit bc79c3ecc55929bac585d04a03475b72e06a3208``."" msgstr """" ""특히, ``\""Kilo 릴리즈\"" vs git commit "" ""bc79c3ecc55929bac585d04a03475b72e06a3208`` 와 같은 개발 브랜치를 사용하고 있"" ""는 경우에는, 사용하고 있는 소프트웨어 및 패키지 버전을 포함하였는지 확인합니"" ""다."" msgid ""Compute service logging"" msgstr ""Compute 서비스 로깅"" msgid ""Conventions"" msgstr ""통용 규칙"" msgid ""Disable live snapshotting"" msgstr ""라이브 Snapshotting 비활성화"" ""During the set up or testing of OpenStack, you might have questions about "" ""how a specific task is completed or be in a situation where a feature does "" ""not work correctly. Use the `ask.openstack.org <https://ask.openstack."" ""org>`__ site to ask questions and get answers. When you visit the https://"" ""ask.openstack.org site, scan the recently asked questions to see whether "" ""your question has already been answered. If not, ask a new question. Be sure "" ""to give a clear, concise summary in the title and provide as much detail as "" ""possible in the description. Paste in your command output or stack traces, "" ""links to screen shots, and any other information which might be useful."" msgstr """" ""OpenStack을 셋업 또는 테스트를 하는 동안, 어떻게 구체적인 작업이 완료되는지 "" ""또는 어떤 기능이 정상적으로 동작하지 않는 상황에 대한 질문이 있을 수 있습니"" ""다. `ask.openstack.org <https://ask.openstack.org>`__ 사이트를 사용하여 질문"" ""을 하고 답을 얻을 수 있습니다. https://ask.openstack.org 사이트에 방문하여, "" ""최근 문의되었던 질문을 살펴봄으로써 해당 질문이 이미 답변이 얻어졌는지를 살펴"" ""볼 수 있습니다. 그렇지 않은 경우, 새로운 질문을 문의하십시오. 제목에 명확하"" ""고 간결한 요약을 주었는지 그리고 설명 내에는 가능한 많은 세부 사항을 포함하였"" ""는지 확인합니다. 명령어 결과 또는 stack trace, 스크린샷에 대한 링크, 그리고 "" ""유용할 수 있는 다른 정보를 붙여 넣으십시오."" msgid """"msgid ""Give a clear, concise summary."" msgstr ""명확하고, 간결한 요약을 제시합니다."" msgid ""Manual method"" msgstr ""수동 방식"" msgid ""Notices"" msgstr ""공지"" msgid ""Notices take these forms:"" msgstr ""공지 사항은 해당 형태를 따릅니다:"" msgid """" ""Provide as much detail as possible in the description. Paste in your command "" ""output or stack traces, links to screen shots, and any other information "" ""which might be useful."" msgstr """" ""설명 내에 가능한 많은 세부 사항을 제공합니다. 명령어 결과 또는 stack trace, "" ""스크린샷에 대한 링크, 그리고 유용할 수 있는 다른 정보를 붙여 넣으십시오."" msgid ""Script method"" msgstr ""스크립트 방식"" msgid """" ""The OpenStack community lives in the #openstack IRC channel on the Freenode "" ""network. You can hang out, ask questions, or get immediate feedback for "" ""urgent and pressing issues. To install an IRC client or use a browser-based "" ""client, go to `https://webchat.freenode.net/ <https://webchat.freenode."" ""net>`__. You can also use Colloquy (Mac OS X, http://colloquy.info/), mIRC "" ""(Windows, http://www.mirc.com/), or XChat (Linux). When you are in the IRC "" ""channel and want to share code or command output, the generally accepted "" ""method is to use a Paste Bin. The OpenStack project has one at http://paste."" ""openstack.org. Just paste your longer amounts of text or logs in the web "" ""form and you get a URL that you can paste into the channel. The OpenStack "" ""IRC channel is ``#openstack`` on ``irc.freenode.net``. You can find a list "" ""of all OpenStack IRC channels at https://wiki.openstack.org/wiki/IRC."" msgstr """" ""OpenStack 커뮤니티는 Freenode 네트워크에서 #openstack IRC 채널 내에 상주하고 "" ""있습니다. 해당 채널에서 많은 시간을 보내거나, 질문에 대해 문의하거나, 또는 다"" ""급하거나 긴급한 이슈에 대해서는 즉각적인 피드백을 얻을 수 있습니다. IRC 클라"" ""이언트를 설치하거나, `https://webchat.freenode.net/ <https://webchat."" ""freenode.net>`__ 에 접속하여 브라우저 기반의 클라이언트를 사용합니다. "" ""Colloquy (Mac OS X, http://colloquy.info/), mIRC (Windows, http://www.mirc."" ""com/), 또는 XChat (Linux)을 사용할 수도 있습니다. IRC 채널 내에 있고 코드 또"" ""는 명령어 결과를 공유하고자 할 때는, 일반적으로 허용하는 방법은 Paste Bin을 "" ""사용하는 것입니다. OpenStack 프로젝트는 http://paste.openstack.org 를 보유하"" ""고 있습니다. 웹 폼에서 길이가 긴 분량의 텍스트 또는 로그를 붙여넣으면 채널에 "" ""붙여넣을 수 있는 URL을 얻습니다. OpenStack IRC 채널은 ``irc.freenode.net`` 상"" ""의 ``#openstack`` 입니다. OpenStack IRC 채널에 대한 모든 목록은 https://wiki."" ""openstack.org/wiki/IRC 에서 찾을 수 있습니다."" msgid """" ""The OpenStack community values your set up and testing efforts and wants "" ""your feedback. To log a bug, you must sign up for a Launchpad account at "" ""https://launchpad.net/+login. You can view existing bugs and report bugs in "" ""the Launchpad Bugs area. Use the search feature to determine whether the bug "" ""has already been reported or already been fixed. If it still seems like your "" ""bug is unreported, fill out a bug report."" msgstr """" "" OpenStack 커뮤니티는 셋업 및 테스트 노력과 함께 피드백에 가치를 부여합니다. "" ""버그를 기록하기 위해서는, https://launchpad.net/+login 에서 Launchpad 계정에 "" ""대한 회원 가입을 해야 합니다. 현재 존재하는 버그를 살펴볼 수 있으며 "" ""Launchpad Bugs 부분에서 버그를 보고할 수 있습니다. 검색 기능을 사용하여 해당 "" ""버그가 이미 보고되었는지 또는 이미 수정되었는지를 살펴볼 수 있습니다. 만약 해"" ""당 버그가 보고되지 않은 상태인 것으로 보일 때는, 버그 보고를 작성합니다."" msgid ""The OpenStack documentation uses several typesetting conventions."" msgstr ""OpenStack 문서는 몇몇 조판을 위한 통용 규칙을 사용합니다."" ""The `OpenStack wiki <https://wiki.openstack.org/>`__ contains a broad range "" ""of topics but some of the information can be difficult to find or is a few "" ""pages deep. Fortunately, the wiki search feature enables you to search by "" ""title or content. If you search for specific information, such as about "" ""networking or OpenStack Compute, you can find a large amount of relevant "" ""material. More is being added all the time, so be sure to check back often. "" ""You can find the search box in the upper-right corner of any OpenStack wiki "" ""page."" msgstr """" ""`OpenStack 위키 <https://wiki.openstack.org/>`__ 는 넒은 범위의 주제를 포함"" ""하고 있지만 몇몇 정보는 찾기 어려울 수 있거나 몇 페이지 깊게 들어가야 합니"" ""다. 다행히도, 위치 검색 기능은 제목 또는 내용으로 검색을 가능하게 합니다. 네"" ""트워킹 또는 OpenStack Compute에 관한 것과 같이 구체적인 정보를 찾고자 하는 경"" ""우, 많은 양의 적절한 자료를 찾을 수 있습니다. 더 많은 내용은 항상 추가되고 있"" ""습니다. 따라서, 자주 돌아와 확인하십시오. 모든 OpenStack 위키 페이지의 우측 "" ""상단 코너에 있는 검색 상자를 찾을 수 있을 것입니다."" msgid """"msgid ""The following Launchpad Bugs areas are available:"" msgstr ""다름 Launchpad Bugs 영역에 대해 사용 가능합니다:"" msgid ""VLAN network"" msgstr ""VLAN 네트워크"" msgid ""Virtual Network Computing (VNC)"" msgstr ""Virtual Network Computing (VNC)"" msgid ""Virtual Network InterFace (VIF)"" msgstr ""Virtual Network InterFace (VIF)"" msgid ""Xen Cloud Platform (XCP)"" msgstr ""Xen Cloud Platform (XCP)"" msgid ""Xen Storage Manager Volume Driver"" msgstr ""Xen 스토리지 관리자 볼륨 드라이버"" msgid ""virtual IP"" msgstr ""가상 IP"" msgid ""virtual VLAN"" msgstr ""가상 VLAN"" msgid ""virtual network"" msgstr ""가상 네트워크"" msgid ""virtual networking"" msgstr ""가상 네트워킹"" msgid ""virtual port"" msgstr ""가상 포트"" msgid ""virtual private network (VPN)"" msgstr ""가상 사설망 (VPN)"" msgid ""virtual server"" msgstr ""가상 서버"" msgid ""virtual switch (vSwitch)"" msgstr ""가상 스위치 (vSwitch)"" msgid ""weight"" msgstr ""weight"" msgid ""weighted cost"" msgstr ""weight 비용"" msgid ""weighting"" msgstr ""weighting"" msgid ""worker"" msgstr ""worker"" ","""PO-Revision-Date: 2015-12-05 02:54+0000\n""",435,8
openstack%2Fnetworking-sfc~master~Ia4a16d85862fd64d9841f479987f6bc6c857052d,openstack/networking-sfc,master,Ia4a16d85862fd64d9841f479987f6bc6c857052d,Updated from global requirements,MERGED,2015-12-01 06:06:34.000000000,2015-12-12 06:47:47.000000000,2015-12-12 06:47:46.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 9375}, {'_account_id': 9396}, {'_account_id': 14605}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-12-01 06:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/1e54945cf06b6d75cb4e92a60802383078df48f2', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 2, 'created': '2015-12-06 10:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/23e07a4a1331a72b6c7d6f30019c9bf68306dda0', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 3, 'created': '2015-12-08 02:07:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/0ec2e33effe7e50945f3e99876e79db23446f630', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 4, 'created': '2015-12-08 02:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/05bd013da03bd52a7b97a2538534c8af684d21bd', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 5, 'created': '2015-12-08 10:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/5feab7e0bf3d0d160d38aab2e859b23ef1ef6721', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 6, 'created': '2015-12-08 12:36:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/2cdf33a7ae0dc7420a1d8c827515b6b43ee92902', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 7, 'created': '2015-12-09 21:57:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/15ab93888869a6fb008e9ce9f542731393bc40ad', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 8, 'created': '2015-12-11 15:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/43c6bae794d26268b041facbcaa3222999191f8c', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}, {'number': 9, 'created': '2015-12-11 22:50:08.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/5becf250c7f71692b289c28a906ff2eaa3cb2697', 'message': 'Updated from global requirements\n\nChange-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d\n'}]",0,251654,5becf250c7f71692b289c28a906ff2eaa3cb2697,34,6,9,11131,,,0,"Updated from global requirements

Change-Id: Ia4a16d85862fd64d9841f479987f6bc6c857052d
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/54/251654/8 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1e54945cf06b6d75cb4e92a60802383078df48f2,openstack/requirements,requests-mock>=0.7.0 # Apache-2.0,requests-mock>=0.6.0 # Apache-2.0,1,1
openstack%2Fopenstack-manuals~master~Ic441185e27e74cc5df7580c0446c55aaeb63dea6,openstack/openstack-manuals,master,Ic441185e27e74cc5df7580c0446c55aaeb63dea6,Include the backing storage section in compute chapter,MERGED,2015-12-11 19:37:14.000000000,2015-12-12 06:25:26.000000000,2015-12-12 06:25:24.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 19:37:14.000000000', 'files': ['doc/config-reference/compute/section_hypervisor_kvm.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4d9325b517f385711b1fba205734ab7232630b27', 'message': 'Include the backing storage section in compute chapter\n\nThis file has been added without a proper inclusion. This patch tries to\nmake use of it.\n\nChange-Id: Ic441185e27e74cc5df7580c0446c55aaeb63dea6\n'}]",0,256637,4d9325b517f385711b1fba205734ab7232630b27,8,4,1,7923,,,0,"Include the backing storage section in compute chapter

This file has been added without a proper inclusion. This patch tries to
make use of it.

Change-Id: Ic441185e27e74cc5df7580c0446c55aaeb63dea6
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/37/256637/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_hypervisor_kvm.xml'],1,4d9325b517f385711b1fba205734ab7232630b27,backing-storage," <xi:include href=""section_compute-configure-backing-storage.xml""/> ",,2,0
openstack%2Fopenstack-manuals~master~Ib22dec33ed1989e98d8d31e670634f6bf4604e4c,openstack/openstack-manuals,master,Ib22dec33ed1989e98d8d31e670634f6bf4604e4c,[config-ref] Convert the Dell drivers to RST,MERGED,2015-12-11 19:21:39.000000000,2015-12-12 06:25:17.000000000,2015-12-12 06:25:16.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 19:21:39.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/dell-equallogic-driver.rst', 'doc/config-ref-rst/source/block-storage/drivers/dell-storagecenter-driver.rst', 'doc/config-ref-rst/source/block-storage/block-storage-sample-configuration-files.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/15efd258511664d72d935fa70304761699aff29f', 'message': '[config-ref] Convert the Dell drivers to RST\n\nChange-Id: Ib22dec33ed1989e98d8d31e670634f6bf4604e4c\nImplements: blueprint config-ref-rst\n'}]",0,256633,15efd258511664d72d935fa70304761699aff29f,8,4,1,7923,,,0,"[config-ref] Convert the Dell drivers to RST

Change-Id: Ib22dec33ed1989e98d8d31e670634f6bf4604e4c
Implements: blueprint config-ref-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/33/256633/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-ref-rst/source/block-storage/drivers/dell-equallogic-driver.rst', 'doc/config-ref-rst/source/block-storage/drivers/dell-storagecenter-driver.rst', 'doc/config-ref-rst/source/block-storage/block-storage-sample-configuration-files.rst']",3,15efd258511664d72d935fa70304761699aff29f,bp/config-ref-rst,.. _block-storage-sample-configuration-file: ,,194,64
openstack%2Fopenstack-manuals~master~I0c817fde44629bb3f99a3560b916f8d7db9e19be,openstack/openstack-manuals,master,I0c817fde44629bb3f99a3560b916f8d7db9e19be,[config-ref] Convert the NetApp cinder driver to RST,MERGED,2015-12-08 20:35:08.000000000,2015-12-12 06:24:52.000000000,2015-12-12 06:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6635}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14396}, {'_account_id': 14643}, {'_account_id': 14962}, {'_account_id': 16237}, {'_account_id': 17832}]","[{'number': 1, 'created': '2015-12-08 20:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1398065485f876bcb04465ab5e07cf13b1588904', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}, {'number': 2, 'created': '2015-12-09 05:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ac98fd49c6ce5ccae9c38a66ad53196eae246346', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}, {'number': 3, 'created': '2015-12-09 19:18:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0de3c7c202e7d0df5596384e87ee5b96df646156', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}, {'number': 4, 'created': '2015-12-10 07:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2dfdaa8b6b165c654e380888764ef359bea7babc', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}, {'number': 5, 'created': '2015-12-11 10:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/4f08af4cdf13820fe5d4724168c8d8f33c059569', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}, {'number': 6, 'created': '2015-12-11 18:38:48.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/netapp-volume-driver.rst', 'doc/config-ref-rst/source/conf.py', 'doc/config-ref-rst/source/tables/manual/cinder-netapp_cdot_extraspecs.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/139b6acff71b625dba383e5eb388321fd8258621', 'message': '[config-ref] Convert the NetApp cinder driver to RST\n\nChange-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be\nImplements: blueprint config-ref-rst\n'}]",51,254948,139b6acff71b625dba383e5eb388321fd8258621,38,11,6,7923,,,0,"[config-ref] Convert the NetApp cinder driver to RST

Change-Id: I0c817fde44629bb3f99a3560b916f8d7db9e19be
Implements: blueprint config-ref-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/48/254948/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-ref-rst/source/block-storage/drivers/netapp-volume-driver.rst', 'doc/config-ref-rst/source/conf.py', 'doc/config-ref-rst/source/tables/manual/cinder-netapp_cdot_extraspecs.rst', 'doc/install-guide/source/index.rst']",4,1398065485f876bcb04465ab5e07cf13b1588904,bp/config-ref-rst,.. title:: OpenStack Installation Guide for openSUSE and SUSE Linux Enterprise .. toctree:: :maxdepth: 2 common/conventions.rst overview.rst environment.rst keystone.rst glance.rst nova.rst neutron.rst horizon.rst cinder.rst swift.rst heat.rst ceilometer.rst launch-instance.rst common/app_support.rst common/glossary.rst,.. title:: OpenStack Installation Guide.. only:: obs or rdo or ubuntu .. toctree:: :maxdepth: 2 common/conventions.rst overview.rst environment.rst keystone.rst glance.rst nova.rst neutron.rst horizon.rst cinder.rst swift.rst heat.rst ceilometer.rst launch-instance.rst common/app_support.rst common/glossary.rst .. only:: debian .. toctree:: :maxdepth: 2 common/conventions.rst overview.rst environment.rst debconf/debconf.rst keystone.rst glance.rst nova.rst neutron.rst horizon.rst cinder.rst swift.rst heat.rst ceilometer.rst launch-instance.rst common/app_support.rst common/glossary.rst,620,43
openstack%2Ftaskflow~master~I52648a275f536f895cf5b9e98b9e5b3ccaeff6d8,openstack/taskflow,master,I52648a275f536f895cf5b9e98b9e5b3ccaeff6d8,Add engine followup state to do post-analysis work,ABANDONED,2015-12-12 03:13:55.000000000,2015-12-12 06:21:40.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-12-12 03:13:55.000000000', 'files': ['taskflow/engines/action_engine/builder.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/deddb8358bc65556fa7f44d1962d89947dd2fa3f', 'message': 'Add engine followup state to do post-analysis work\n\nChange-Id: I52648a275f536f895cf5b9e98b9e5b3ccaeff6d8\n'}]",0,256904,deddb8358bc65556fa7f44d1962d89947dd2fa3f,3,1,1,1297,,,0,"Add engine followup state to do post-analysis work

Change-Id: I52648a275f536f895cf5b9e98b9e5b3ccaeff6d8
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/04/256904/1 && git format-patch -1 --stdout FETCH_HEAD,['taskflow/engines/action_engine/builder.py'],1,deddb8358bc65556fa7f44d1962d89947dd2fa3f,,"import collectionsFINDING_NEXT = 'FINDING_NEXT' META_STATES = (GAME_OVER, UNDEFINED, FINDING_NEXT)FOLLOW_UP = 'follow_up' self.follow_up = collections.deque() +--------------+------------------+--------------+----------+---------+ | Start | Event | End | On Enter | On Exit | +--------------+------------------+--------------+----------+---------+ | ANALYZING | completed | GAME_OVER | . | . | | ANALYZING | follow_up | FINDING_NEXT | . | . | | ANALYZING | wait_finished | WAITING | . | . | | FAILURE[$] | . | . | . | . | | FINDING_NEXT | schedule_next | SCHEDULING | . | . | | GAME_OVER | failed | FAILURE | . | . | | GAME_OVER | reverted | REVERTED | . | . | | GAME_OVER | success | SUCCESS | . | . | | GAME_OVER | suspended | SUSPENDED | . | . | | RESUMING | schedule_next | SCHEDULING | . | . | | REVERTED[$] | . | . | . | . | | SCHEDULING | wait_finished | WAITING | . | . | | SUCCESS[$] | . | . | . | . | | SUSPENDED[$] | . | . | . | . | | UNDEFINED[^] | start | RESUMING | . | . | | WAITING | examine_finished | ANALYZING | . | . | +--------------+------------------+--------------+----------+---------+ def scan(old_state, new_state, event): # This reaction function performs post analysis work of atoms # that were completed, finding there next ready successors # or predecessors (or dies trying to do that). next_up = set() while memory.follow_up: atom = memory.follow_up.popleft() try: for next_atom in iter_next_atoms(atom=atom): next_up.add(next_atom) except Exception: memory.failures.append(failure.Failure()) LOG.exception(""Engine '%s' atom post-completion"" "" next atom searching failed"", atom) memory.next_up.update(next_up) return SCHEDULE memory.follow_up.append(atom) if is_runnable() and memory.follow_up and not memory.failures: return FOLLOW_UP m.add_state(FINDING_NEXT, **watchers) m.add_transition(st.ANALYZING, FINDING_NEXT, FOLLOW_UP) m.add_transition(FINDING_NEXT, st.SCHEDULING, SCHEDULE) m.add_reaction(FINDING_NEXT, FOLLOW_UP, scan)","META_STATES = (GAME_OVER, UNDEFINED) +--------------+------------------+------------+----------+---------+ | Start | Event | End | On Enter | On Exit | +--------------+------------------+------------+----------+---------+ | ANALYZING | completed | GAME_OVER | . | . | | ANALYZING | schedule_next | SCHEDULING | . | . | | ANALYZING | wait_finished | WAITING | . | . | | FAILURE[$] | . | . | . | . | | GAME_OVER | failed | FAILURE | . | . | | GAME_OVER | reverted | REVERTED | . | . | | GAME_OVER | success | SUCCESS | . | . | | GAME_OVER | suspended | SUSPENDED | . | . | | RESUMING | schedule_next | SCHEDULING | . | . | | REVERTED[$] | . | . | . | . | | SCHEDULING | wait_finished | WAITING | . | . | | SUCCESS[$] | . | . | . | . | | SUSPENDED[$] | . | . | . | . | | UNDEFINED[^] | start | RESUMING | . | . | | WAITING | examine_finished | ANALYZING | . | . | +--------------+------------------+------------+----------+---------+ next_up = set() try: more_work = set(iter_next_atoms(atom=atom)) except Exception: memory.failures.append(failure.Failure()) LOG.exception(""Engine '%s' atom post-completion"" "" next atom searching failed"", atom) else: next_up.update(more_work) if is_runnable() and next_up and not memory.failures: memory.next_up.update(next_up) return SCHEDULE m.add_transition(st.ANALYZING, st.SCHEDULING, SCHEDULE)",49,33
openstack%2Fapi-site~master~Id2dbc9f35014954bf5b297bd4ebed4d37d0d14f1,openstack/api-site,master,Id2dbc9f35014954bf5b297bd4ebed4d37d0d14f1,Update Object API v1 to spellcheck and make other changes,MERGED,2015-12-12 02:12:04.000000000,2015-12-12 06:17:07.000000000,2015-12-12 06:17:05.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-12 02:12:04.000000000', 'files': ['api-ref/src/wadls/object-api/src/samples/account-containers-list-http-request-json.txt', 'api-ref/src/wadls/object-api/src/samples/objects-list-response.xml', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-response.xml', 'api-ref/src/wadls/object-api/src/samples/objects-list-http-response-xml.txt', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-response-xml.txt', 'api-ref/src/wadls/object-api/src/samples/objects-list-http-response-json.txt', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-request-xml.txt', 'api-ref/src/wadls/object-api/src/samples/capabilities-list-response.json', 'api-ref/src/wadls/object-api/src/samples/containers-list-http-response.txt', 'api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl', 'api-ref/src/wadls/object-api/src/samples/objects-list-response.json', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-response.json', 'api-ref/src/wadls/object-api/src/samples/containers-list-http-request.txt', 'api-ref/src/wadls/object-api/src/samples/endpoints-list-response.json', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-response-json.txt', 'api-ref/src/wadls/object-api/src/samples/endpoints-list-response-headers.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/2999c9829205ae26e8a9b8b37d58d375b5d247d6', 'message': 'Update Object API v1 to spellcheck and make other changes\n\n- Remove passive voice from api-site\n- Renamed api-ref/src/wadls/object-api/src/v1/api_samples\n  to .../samples\n- Renamed code samples using this naming convention:\n  <resource>-<action>-request.json or <resource>-<action>-response.json.\n  For example, volume-create-request.json and volume-create-response.json.\n- Removed unused code samples\n- Made method names consistent throughout - use list<resource> for list\n  operations, show<resource> for show operations, and so on.\n\nChange-Id: Id2dbc9f35014954bf5b297bd4ebed4d37d0d14f1\nPartial-Bug: #1521244\n'}]",0,256901,2999c9829205ae26e8a9b8b37d58d375b5d247d6,7,3,1,2448,,,0,"Update Object API v1 to spellcheck and make other changes

- Remove passive voice from api-site
- Renamed api-ref/src/wadls/object-api/src/v1/api_samples
  to .../samples
- Renamed code samples using this naming convention:
  <resource>-<action>-request.json or <resource>-<action>-response.json.
  For example, volume-create-request.json and volume-create-response.json.
- Removed unused code samples
- Made method names consistent throughout - use list<resource> for list
  operations, show<resource> for show operations, and so on.

Change-Id: Id2dbc9f35014954bf5b297bd4ebed4d37d0d14f1
Partial-Bug: #1521244
",git fetch https://review.opendev.org/openstack/api-site refs/changes/01/256901/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/object-api/src/samples/account-containers-list-http-request-json.txt', 'api-ref/src/wadls/object-api/src/samples/objects-list-response.xml', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-response.xml', 'api-ref/src/wadls/object-api/src/samples/objects-list-http-response-xml.txt', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-response-xml.txt', 'api-ref/src/wadls/object-api/src/samples/objects-list-http-response-json.txt', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-request-xml.txt', 'api-ref/src/wadls/object-api/src/samples/capabilities-list-response.json', 'api-ref/src/wadls/object-api/src/samples/containers-list-http-response.txt', 'api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl', 'api-ref/src/wadls/object-api/src/samples/objects-list-response.json', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-response.json', 'api-ref/src/wadls/object-api/src/samples/containers-list-http-request.txt', 'api-ref/src/wadls/object-api/src/samples/endpoints-list-response.json', 'api-ref/src/wadls/object-api/src/samples/account-containers-list-http-response-json.txt', 'api-ref/src/wadls/object-api/src/samples/endpoints-list-response-headers.json']",16,2999c9829205ae26e8a9b8b37d58d375b5d247d6,bug/1521244,,,23,21
openstack%2Fapi-site~master~Icbd0e6651615165f3185e048edf02e210ca0759e,openstack/api-site,master,Icbd0e6651615165f3185e048edf02e210ca0759e,Update Orchestration API v1 to spellcheck and make other changes,MERGED,2015-12-12 02:08:52.000000000,2015-12-12 06:16:29.000000000,2015-12-12 06:16:28.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-12 02:08:52.000000000', 'files': ['api-ref/src/wadls/orchestration-api/src/v1/samples/resource-type-template-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-validate-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployments-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-metadata-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-resume-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshot-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stacks-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/services-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-check-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-find-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/heat-versions-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/events-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-cancel-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-outputs-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-update-preview-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/build-info-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/event-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-abandon-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-snapshot-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-update-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-schema-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-output-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-suspend-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshot-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshots-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-metadata-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resources-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-validate-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-preview-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-types-list-response.json'], 'web_link': 'https://opendev.org/openstack/api-site/commit/1c379a797ebfefaabba22a983f6fbd8c853879f5', 'message': 'Update Orchestration API v1 to spellcheck and make other changes\n\n- Remove passive voice from api-site\n- Renamed api-ref/src/wadls/orchestration/src/v1/api_samples\n  to .../samples\n- Renamed code samples using this naming convention:\n  <resource>-<action>-request.json or <resource>-<action>-response.json.\n  For example, volume-create-request.json and volume-create-response.json.\n- Removed unused code samples\n- Made method names consistent throughout - use list<resource> for list\n  operations, show<resource> for show operations, and so on.\n\nChange-Id: Icbd0e6651615165f3185e048edf02e210ca0759e\nPartial-Bug: #1521244\n'}]",0,256899,1c379a797ebfefaabba22a983f6fbd8c853879f5,7,3,1,2448,,,0,"Update Orchestration API v1 to spellcheck and make other changes

- Remove passive voice from api-site
- Renamed api-ref/src/wadls/orchestration/src/v1/api_samples
  to .../samples
- Renamed code samples using this naming convention:
  <resource>-<action>-request.json or <resource>-<action>-response.json.
  For example, volume-create-request.json and volume-create-response.json.
- Removed unused code samples
- Made method names consistent throughout - use list<resource> for list
  operations, show<resource> for show operations, and so on.

Change-Id: Icbd0e6651615165f3185e048edf02e210ca0759e
Partial-Bug: #1521244
",git fetch https://review.opendev.org/openstack/api-site refs/changes/99/256899/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/orchestration-api/src/v1/samples/resource-type-template-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-validate-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployments-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-metadata-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-resume-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshot-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stacks-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/services-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-check-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-find-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/heat-versions-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/events-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-cancel-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-outputs-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-update-preview-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/build-info-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/event-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-abandon-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-snapshot-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-update-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-schema-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-show-output-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-action-suspend-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshot-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-snapshots-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-show-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-adopt-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/config-create-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-metadata-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resources-list-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/template-validate-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-update-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/deployment-create-request.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/stack-preview-response.json', 'api-ref/src/wadls/orchestration-api/src/v1/samples/resource-types-list-response.json']",47,1c379a797ebfefaabba22a983f6fbd8c853879f5,bug/1521244,,,75,65
openstack%2Fnova~master~I08ba11bb1c5388bc4611cea581274ac5d724c8d9,openstack/nova,master,I08ba11bb1c5388bc4611cea581274ac5d724c8d9,Report compute-api bugs against nova,MERGED,2015-12-10 08:36:52.000000000,2015-12-12 06:03:33.000000000,2015-12-11 15:11:47.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6062}, {'_account_id': 6547}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16237}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17722}]","[{'number': 1, 'created': '2015-12-10 08:36:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3658b923428c291877430325fbd62cf1ace9e60e', 'message': 'Report compute-api bugs against openstack-api-site\n\nFor compute-api set the launchpad project users report bugs\nagainst to ""openstack-api-site"".\n\nThis variable will be used by the next openstackdocstheme update.\n\nCloses-Bug: #1524476\nChange-Id: I08ba11bb1c5388bc4611cea581274ac5d724c8d9\n'}, {'number': 2, 'created': '2015-12-10 09:22:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0e32ce8d187f72bfee290df6f89f55451f828e7d', 'message': 'Report compute-api bugs against openstack-api-site\n\nFor compute-api set the launchpad project users report bugs\nagainst to ""openstack-api-site"".\n\nThis variable will be used by the next openstackdocstheme update.\n\nCloses-Bug: #1524476\nChange-Id: I08ba11bb1c5388bc4611cea581274ac5d724c8d9\n'}, {'number': 3, 'created': '2015-12-10 14:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/244cec98b888b8d5b5eef044195526997312784d', 'message': 'Report compute-api bugs against nova\n\nFor compute-api set the launchpad project users report bugs\nagainst to ""nova"". Users can report bugs using the ""bug icon"" that will\ndirectly link to the launchpad project, it currently goes to\n""openstack-manuals"" which is wrong for this content.\n\nThis variable will be used by the next openstackdocstheme update.\n\nCloses-Bug: #1524476\nChange-Id: I08ba11bb1c5388bc4611cea581274ac5d724c8d9\n'}, {'number': 4, 'created': '2015-12-11 06:01:28.000000000', 'files': ['api-guide/source/conf.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a54834df23e26f2255578dffb16fdac023fd495e', 'message': 'Report compute-api bugs against nova\n\nFor compute-api set the launchpad project users report bugs\nagainst to ""nova"". Users can report bugs using the ""bug icon"" that will\ndirectly link to the launchpad project, it currently goes to\n""openstack-manuals"" which is wrong for this content.\n\nThis variable is used by openstackdocstheme 1.2.6.\n\nCloses-Bug: #1524476\nChange-Id: I08ba11bb1c5388bc4611cea581274ac5d724c8d9\n'}]",2,255729,a54834df23e26f2255578dffb16fdac023fd495e,63,18,4,6547,,,0,"Report compute-api bugs against nova

For compute-api set the launchpad project users report bugs
against to ""nova"". Users can report bugs using the ""bug icon"" that will
directly link to the launchpad project, it currently goes to
""openstack-manuals"" which is wrong for this content.

This variable is used by openstackdocstheme 1.2.6.

Closes-Bug: #1524476
Change-Id: I08ba11bb1c5388bc4611cea581274ac5d724c8d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/29/255729/4 && git format-patch -1 --stdout FETCH_HEAD,['api-guide/source/conf.py'],1,3658b923428c291877430325fbd62cf1ace9e60e,bug/1524476,"# bug_project: Project to file bugs against. ""giturl"": giturl, ""bug_project"" = ""openstack-api-site""}"," ""giturl"": giturl}",3,1
openstack%2Fproject-config~master~I300857d50c1dc010dba569c5978e45e76a90162c,openstack/project-config,master,I300857d50c1dc010dba569c5978e45e76a90162c,Only update nodepool images on Tuesdays,MERGED,2015-12-11 22:30:59.000000000,2015-12-12 05:59:52.000000000,2015-12-12 05:59:52.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 22:30:59.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/2c90e47fa933f80c5214121959eafee39b35bbe3', 'message': ""Only update nodepool images on Tuesdays\n\nUntil the regression in tox 2.3.0 is resolved through a new release,\nonly update nodepool images on Tuesdays so we don't need to delete\nthem every day (hopefully it will be fixed by Tuesday!).\n\nhttps://bitbucket.org/hpk42/tox/issues/294\n\nChange-Id: I300857d50c1dc010dba569c5978e45e76a90162c\n""}]",0,256821,2c90e47fa933f80c5214121959eafee39b35bbe3,7,3,1,5263,,,0,"Only update nodepool images on Tuesdays

Until the regression in tox 2.3.0 is resolved through a new release,
only update nodepool images on Tuesdays so we don't need to delete
them every day (hopefully it will be fixed by Tuesday!).

https://bitbucket.org/hpk42/tox/issues/294

Change-Id: I300857d50c1dc010dba569c5978e45e76a90162c
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/256821/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,2c90e47fa933f80c5214121959eafee39b35bbe3,tox-2.3, image-update: '14 14 * * 2', image-update: '14 14 * * *',1,1
openstack%2Fzaqar~master~I70517e6a3122b529b9d337dd6472761aedebcf47,openstack/zaqar,master,I70517e6a3122b529b9d337dd6472761aedebcf47,Fix duplicate auth_section issue,MERGED,2015-12-03 21:19:36.000000000,2015-12-12 05:42:33.000000000,2015-12-04 00:48:56.000000000,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 6484}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-12-03 21:19:36.000000000', 'files': ['zaqar/transport/auth.py'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/0e3c7463cd2763db93ddb2227a44519fa06fb178', 'message': ""Fix duplicate auth_section issue\n\nDue to the keystonemiddleware upgrade, now we're running into a\ngate failure. This is just a workaround, we will upgrade to\nkeystoneauth1 soon.\n\nChange-Id: I70517e6a3122b529b9d337dd6472761aedebcf47\n""}]",0,253220,0e3c7463cd2763db93ddb2227a44519fa06fb178,13,4,1,6484,,,0,"Fix duplicate auth_section issue

Due to the keystonemiddleware upgrade, now we're running into a
gate failure. This is just a workaround, we will upgrade to
keystoneauth1 soon.

Change-Id: I70517e6a3122b529b9d337dd6472761aedebcf47
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/20/253220/1 && git format-patch -1 --stdout FETCH_HEAD,['zaqar/transport/auth.py'],1,0e3c7463cd2763db93ddb2227a44519fa06fb178,fix_dup_auth_option,,"from keystoneclient import auth auth.register_conf_options(conf, cls.OPT_GROUP_NAME)",0,2
openstack%2Ftooz~master~I6aa1d9767f5da59c88b940f6ca7ed56abff41166,openstack/tooz,master,I6aa1d9767f5da59c88b940f6ca7ed56abff41166,Updated from global requirements,MERGED,2015-12-11 15:27:11.000000000,2015-12-12 05:36:38.000000000,2015-12-12 05:36:37.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 15:27:11.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/tooz/commit/5f0be849f3822d2d847326900fbe40169a1b4149', 'message': 'Updated from global requirements\n\nChange-Id: I6aa1d9767f5da59c88b940f6ca7ed56abff41166\n'}]",0,256535,5f0be849f3822d2d847326900fbe40169a1b4149,12,3,1,11131,,,0,"Updated from global requirements

Change-Id: I6aa1d9767f5da59c88b940f6ca7ed56abff41166
",git fetch https://review.opendev.org/openstack/tooz refs/changes/35/256535/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5f0be849f3822d2d847326900fbe40169a1b4149,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fceilometer~master~Ia32b056f4b602bd274633780dc0142153e7801b9,openstack/ceilometer,master,Ia32b056f4b602bd274633780dc0142153e7801b9,improve keystoneclient session initialization,ABANDONED,2015-10-20 11:25:50.000000000,2015-12-12 05:23:42.000000000,,"[{'_account_id': 3}, {'_account_id': 6537}, {'_account_id': 8290}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-10-20 11:25:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/45c0412b703edfe4f6da5832b2d65c2a41f8b99d', 'message': 'improve keystoneclient session initialization\n\nkeystoneclient.session.Session.construct() is deprecated, the recommended\nway is by using its constructor.\n\nAnd we should apply http_timeout to the parameter list to improve\nrobustness.\n\nThis patch also extracts those code to a internal function to reduce\nduplicate code.\n\nChange-Id: Ia32b056f4b602bd274633780dc0142153e7801b9\nCloses-Bug: #1507997\n'}, {'number': 2, 'created': '2015-10-20 11:32:10.000000000', 'files': ['ceilometer/keystone_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/eeb4458ea69586c787b06f11e3caa373cd3594da', 'message': 'improve keystoneclient session initialization\n\nkeystoneclient.session.Session.construct() is deprecated, the recommended\nway is by using its constructor.\n\nAnd we should apply http_timeout to the parameter list to improve\nrobustness.\n\nThis patch also extracts those code to a internal function to reduce\nduplicate code.\n\nChange-Id: Ia32b056f4b602bd274633780dc0142153e7801b9\nCloses-Bug: #1507997\n'}]",0,237520,eeb4458ea69586c787b06f11e3caa373cd3594da,13,4,2,6676,,,0,"improve keystoneclient session initialization

keystoneclient.session.Session.construct() is deprecated, the recommended
way is by using its constructor.

And we should apply http_timeout to the parameter list to improve
robustness.

This patch also extracts those code to a internal function to reduce
duplicate code.

Change-Id: Ia32b056f4b602bd274633780dc0142153e7801b9
Closes-Bug: #1507997
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/20/237520/2 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/keystone_client.py'],1,45c0412b703edfe4f6da5832b2d65c2a41f8b99d,bug/1507997,"def _get_keystone_session(): if cfg.CONF.service_credentials.insecure: verify = True else: verify = cfg.CONF.service_credentials.os_cacert or False return ks_session.Session(verify=verify, timeout=cfg.CONF.http_timeout) session = _get_keystone_session() session = _get_keystone_session()"," session = ks_session.Session.construct({ 'cacert': cfg.CONF.service_credentials.os_cacert, 'insecure': cfg.CONF.service_credentials.insecure}) session = ks_session.Session.construct({ 'cacert': cfg.CONF.service_credentials.os_cacert, 'insecure': cfg.CONF.service_credentials.insecure}) ",11,8
openstack%2Fceilometer~master~I62ca50d91ece29628bad310097dec98ab7f8b4cc,openstack/ceilometer,master,I62ca50d91ece29628bad310097dec98ab7f8b4cc,using session to construct keystoneclient object,ABANDONED,2015-10-20 11:56:40.000000000,2015-12-12 04:30:56.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6676}, {'_account_id': 9526}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-10-20 11:56:40.000000000', 'files': ['ceilometer/keystone_client.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/6b42e3ad485ec5a28478d8149e1912ab783963e5', 'message': 'using session to construct keystoneclient object\n\nConstructing an instance of the keystoneclient.{v2_0,v3}.client.Client\nclass without a session is deprecated as of the 1.7.0 release and may\nbe removed in the 2.0.0 release.\n\nref: https://github.com/openstack/python-keystoneclient/blob/1.8.1/\\\nkeystoneclient/v2_0/client.py#L140\n\nChange-Id: I62ca50d91ece29628bad310097dec98ab7f8b4cc\nCloses-Bug: #1507884\n'}]",0,237531,6b42e3ad485ec5a28478d8149e1912ab783963e5,12,5,1,6676,,,0,"using session to construct keystoneclient object

Constructing an instance of the keystoneclient.{v2_0,v3}.client.Client
class without a session is deprecated as of the 1.7.0 release and may
be removed in the 2.0.0 release.

ref: https://github.com/openstack/python-keystoneclient/blob/1.8.1/\
keystoneclient/v2_0/client.py#L140

Change-Id: I62ca50d91ece29628bad310097dec98ab7f8b4cc
Closes-Bug: #1507884
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/31/237531/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilometer/keystone_client.py'],1,6b42e3ad485ec5a28478d8149e1912ab783963e5,bug/1507884,"from keystoneclient.auth.identity import v2 as v2_auth from keystoneclient.auth.identity import v3 as v3_auth session = _get_keystone_session() auth = v2_auth.Password( auth_url=cfg.CONF.service_credentials.os_auth_url, tenant_name=cfg.CONF.service_credentials.os_tenant_name,) return ks_client.Client( session=session, auth=auth, region_name=cfg.CONF.service_credentials.os_region_name,) session = _get_keystone_session() auth = v3_auth.Password( auth_url=auth_url, return ks_client_v3.Client( session=session, auth=auth, region_name=cfg.CONF.service_credentials.os_region_name,)"," return ks_client.Client( tenant_name=cfg.CONF.service_credentials.os_tenant_name, cacert=cfg.CONF.service_credentials.os_cacert, auth_url=cfg.CONF.service_credentials.os_auth_url, region_name=cfg.CONF.service_credentials.os_region_name, insecure=cfg.CONF.service_credentials.insecure, timeout=cfg.CONF.http_timeout,) return ks_client_v3.Client( cacert=cfg.CONF.service_credentials.os_cacert, auth_url=auth_url, region_name=cfg.CONF.service_credentials.os_region_name, insecure=cfg.CONF.service_credentials.insecure, timeout=cfg.CONF.http_timeout,",18,14
openstack%2Fmonasca-persister~master~Ief61149c2c094b8d3aee8912a26381e42f068cfe,openstack/monasca-persister,master,Ief61149c2c094b8d3aee8912a26381e42f068cfe,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:05:10.000000000,2015-12-12 04:22:39.000000000,2015-12-12 04:22:39.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:05:10.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/011469ebf0b3a4a7f496a98cda808cb40cd8a7a0', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ief61149c2c094b8d3aee8912a26381e42f068cfe\n'}]",0,256785,011469ebf0b3a4a7f496a98cda808cb40cd8a7a0,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ief61149c2c094b8d3aee8912a26381e42f068cfe
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/85/256785/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,011469ebf0b3a4a7f496a98cda808cb40cd8a7a0,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fmonasca-ui~master~I8002d1f029b63eecd3599907b6bc39f889a140d4,openstack/monasca-ui,master,I8002d1f029b63eecd3599907b6bc39f889a140d4,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 22:05:30.000000000,2015-12-12 04:17:31.000000000,2015-12-12 04:17:31.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 22:05:30.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/e2e66ba04caf640191cbae67419bf2a777f28cf4', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I8002d1f029b63eecd3599907b6bc39f889a140d4\n'}]",0,256786,e2e66ba04caf640191cbae67419bf2a777f28cf4,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I8002d1f029b63eecd3599907b6bc39f889a140d4
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/86/256786/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,e2e66ba04caf640191cbae67419bf2a777f28cf4,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fmonasca-ceilometer~master~I4d371b9b2c007892c6f5e2906960d0fac66ec980,openstack/monasca-ceilometer,master,I4d371b9b2c007892c6f5e2906960d0fac66ec980,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 20:19:42.000000000,2015-12-12 04:17:07.000000000,2015-12-12 04:17:07.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 20:19:42.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/178cbed72a0d47c54c09c0dbecfc4ea000046f8f', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I4d371b9b2c007892c6f5e2906960d0fac66ec980\n'}]",0,256696,178cbed72a0d47c54c09c0dbecfc4ea000046f8f,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I4d371b9b2c007892c6f5e2906960d0fac66ec980
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/96/256696/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,178cbed72a0d47c54c09c0dbecfc4ea000046f8f,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fdjango_openstack_auth~master~Idbbd741358ecabeb51de47cdece662b5019d2092,openstack/django_openstack_auth,master,Idbbd741358ecabeb51de47cdece662b5019d2092,Add domain initial value on login,MERGED,2015-12-08 15:53:04.000000000,2015-12-12 04:13:33.000000000,2015-12-12 04:13:32.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 4264}, {'_account_id': 5623}, {'_account_id': 8040}, {'_account_id': 13325}]","[{'number': 1, 'created': '2015-12-08 15:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/f6b0910e2a38515a1d5f98227d3f14ec38c3744a', 'message': ""Add domain initial value on login\n\nCurrently there is no default value for\ndomain field of login form.\nSince we already have\nOPENSTACK_KEYSTONE_DEFAULT_DOMAIN in Horizon,\nit would be nice to use its value for\npre-filling 'Domain' field value on login.\n\nCloses-Bug: #1523957\nChange-Id: Idbbd741358ecabeb51de47cdece662b5019d2092\n""}, {'number': 2, 'created': '2015-12-09 14:11:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/cf15420bcd659fd8f8e01a8df1da60f1a2b906db', 'message': ""Add domain initial value on login\n\nCurrently there is no default value for\ndomain field of login form.\nThis patch add saving last login domain\nname into coookies and pre-filling\n'Domain' field value on login with\nthis saved value from cookies.\n\nCloses-Bug: #1523957\nChange-Id: Idbbd741358ecabeb51de47cdece662b5019d2092\n""}, {'number': 3, 'created': '2015-12-09 15:35:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/fa18b5db087e06884d419dcef0a39a604a99b8dd', 'message': ""Add domain initial value on login\n\nCurrently there is no default value for\ndomain field of login form.\nThis patch add saving last login domain\nname into coookies and pre-filling\n'Domain' field value on login with\nthis saved value from cookies.\n\nCloses-Bug: #1523957\nChange-Id: Idbbd741358ecabeb51de47cdece662b5019d2092\n""}, {'number': 4, 'created': '2015-12-09 16:12:39.000000000', 'files': ['openstack_auth/forms.py', 'openstack_auth/views.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/ce52637f61fb28c6efcb7f52b0043ee41a9cd05c', 'message': ""Add domain initial value on login\n\nCurrently there is no default value for\ndomain field of login form.\nThis patch add saving last login domain\nname into coookies and pre-filling\n'Domain' field value on login with\nthis saved value from cookies.\n\nCloses-Bug: #1523957\nChange-Id: Idbbd741358ecabeb51de47cdece662b5019d2092\n""}]",4,254838,ce52637f61fb28c6efcb7f52b0043ee41a9cd05c,22,6,4,13325,,,0,"Add domain initial value on login

Currently there is no default value for
domain field of login form.
This patch add saving last login domain
name into coookies and pre-filling
'Domain' field value on login with
this saved value from cookies.

Closes-Bug: #1523957
Change-Id: Idbbd741358ecabeb51de47cdece662b5019d2092
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/38/254838/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/forms.py'],1,f6b0910e2a38515a1d5f98227d3f14ec38c3744a,bug/1523957," default_domain = getattr(settings, 'OPENSTACK_KEYSTONE_DEFAULT_DOMAIN', 'Default') initial=default_domain,",,4,0
openstack%2Fpython-monascaclient~master~I01a68d3ccacbd46998a0371eb9b0d4fbdd00a71a,openstack/python-monascaclient,master,I01a68d3ccacbd46998a0371eb9b0d4fbdd00a71a,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 20:25:36.000000000,2015-12-12 04:13:05.000000000,2015-12-12 04:13:05.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 20:25:36.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/b98bfd323f6c9f17f71633f47252ea1c0ecc9726', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I01a68d3ccacbd46998a0371eb9b0d4fbdd00a71a\n'}]",0,256713,b98bfd323f6c9f17f71633f47252ea1c0ecc9726,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I01a68d3ccacbd46998a0371eb9b0d4fbdd00a71a
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/13/256713/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b98bfd323f6c9f17f71633f47252ea1c0ecc9726,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fmonasca-notification~master~I54711ed40598e8ee4b0385199b14f743aa4e4f04,openstack/monasca-notification,master,I54711ed40598e8ee4b0385199b14f743aa4e4f04,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 20:19:57.000000000,2015-12-12 04:12:25.000000000,2015-12-12 04:12:24.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 20:19:57.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/a95852239d96526b79a27c37993323152cf91d4d', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: I54711ed40598e8ee4b0385199b14f743aa4e4f04\n'}]",0,256697,a95852239d96526b79a27c37993323152cf91d4d,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: I54711ed40598e8ee4b0385199b14f743aa4e4f04
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/97/256697/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a95852239d96526b79a27c37993323152cf91d4d,,,[tox:jenkins] downloadcache = ~/cache/pip ,0,3
openstack%2Fneutron~master~Ief93d46310466d524d251e370abfafce44b6a78e,openstack/neutron,master,Ief93d46310466d524d251e370abfafce44b6a78e,SIGHUP missed by child daemon process,ABANDONED,2015-12-10 14:58:58.000000000,2015-12-12 03:39:25.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 9681}, {'_account_id': 10153}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}, {'_account_id': 18289}]","[{'number': 1, 'created': '2015-12-10 14:58:58.000000000', 'files': ['neutron/tests/functional/test_server.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c40677da5c8bd505a1a931c20c638095cf486b26', 'message': 'SIGHUP missed by child daemon process\n\nThis issue might be due to the service process missing the\nSIGHUP because it is sent too early. This is deduced based\non the logs and code. Since this is not reproducible locally\nit is being tried out on the test server.\n\nThis is just to test the runs and see the success rate for\ntest_restart_l3_agent_on_sighup which fails intermittently.\n\nChange-Id: Ief93d46310466d524d251e370abfafce44b6a78e\nCloses-Bug: #1518921\n'}]",1,255920,c40677da5c8bd505a1a931c20c638095cf486b26,32,9,1,18289,,,0,"SIGHUP missed by child daemon process

This issue might be due to the service process missing the
SIGHUP because it is sent too early. This is deduced based
on the logs and code. Since this is not reproducible locally
it is being tried out on the test server.

This is just to test the runs and see the success rate for
test_restart_l3_agent_on_sighup which fails intermittently.

Change-Id: Ief93d46310466d524d251e370abfafce44b6a78e
Closes-Bug: #1518921
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/255920/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/functional/test_server.py'],1,c40677da5c8bd505a1a931c20c638095cf486b26,bug/1518921," utils.wait_until_true(self.health_checker, timeout=20, sleep=0.1, time.sleep(10)"," utils.wait_until_true(self.health_checker, timeout=10, sleep=0.1, time.sleep(5)",2,2
openstack%2Fhorizon~master~Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65,openstack/horizon,master,Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65,Add extensions to $q for resolving all promises,MERGED,2015-10-30 17:43:37.000000000,2015-12-12 03:11:44.000000000,2015-12-12 03:11:42.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 12281}, {'_account_id': 17004}, {'_account_id': 17013}, {'_account_id': 18508}]","[{'number': 1, 'created': '2015-10-30 17:43:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6bd01b8cd172500517e276f8471d779aa5fc4a7b', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 2, 'created': '2015-11-03 22:00:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/617edf2fb08e628a58dc686ea3ecf22b8a818716', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 3, 'created': '2015-11-19 06:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d46e764ce2f533d307b35abef5b5f965db432aa6', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 4, 'created': '2015-12-02 05:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c8b7e2641ff903946d77828c4c8fd149ba793106', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 5, 'created': '2015-12-09 23:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1c0e6095bd8198df46b2b593a579d573ce7bc129', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Kyle Olivo<keolivo@thoughtworks.com>\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 6, 'created': '2015-12-11 21:52:54.000000000', 'files': ['horizon/static/framework/widgets/action-list/actions.service.js', 'horizon/static/framework/util/util.module.js', 'horizon/static/framework/util/q/q.extensions.js', 'horizon/static/framework/util/q/q.module.js', 'horizon/static/framework/util/q/q.module.spec.js', 'horizon/static/framework/util/q/q.extensions.spec.js', 'horizon/static/framework/widgets/modal/delete-modal.service.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2d0e491d767961a316eddafc40e971441f2797a2', 'message': 'Add extensions to $q for resolving all promises\n\nThis patch provides an extension service for the $q\nservice which waits for all promises to settle and then\nreturn which promises fail and which promises pass.\n\nThis was a result of having similar looking code in\nhttps://review.openstack.org/#/c/231335/\nand\nhttps://review.openstack.org/#/c/234408/\n\nThe method name was inspired method which exists in $q\nfrom Kris Oswal but not in the Angular implementation of it.\nhttps://github.com/kriskowal/q/blob/v1/q.js#L1676\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Kyle Olivo<keolivo@thoughtworks.com>\n\nChange-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65\nPartially-Implements: blueprint angularize-images-table\n'}]",11,240589,2d0e491d767961a316eddafc40e971441f2797a2,29,8,6,17013,,,0,"Add extensions to $q for resolving all promises

This patch provides an extension service for the $q
service which waits for all promises to settle and then
return which promises fail and which promises pass.

This was a result of having similar looking code in
https://review.openstack.org/#/c/231335/
and
https://review.openstack.org/#/c/234408/

The method name was inspired method which exists in $q
from Kris Oswal but not in the Angular implementation of it.
https://github.com/kriskowal/q/blob/v1/q.js#L1676

Co-Authored-By: Errol Pais<epais@thoughtworks.com>
Co-Authored-By: Kyle Olivo<keolivo@thoughtworks.com>

Change-Id: Ic3d36bba1886e06d7e7aee50c1ddfa17b51a1a65
Partially-Implements: blueprint angularize-images-table
",git fetch https://review.opendev.org/openstack/horizon refs/changes/89/240589/4 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/util.module.js', 'horizon/static/framework/util/q/q.extensions.js', 'horizon/static/framework/util/q/q.module.js', 'horizon/static/framework/util/q/q.extensions.spec.js', 'horizon/static/framework/util/q/q.module.spec.js']",5,6bd01b8cd172500517e276f8471d779aa5fc4a7b,bp/angularize-images-table,"/* * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function () { 'use strict'; describe('horizon.framework.util.q module', function () { it('should have been defined', function () { expect(angular.module('horizon.framework.util.q')).toBeDefined(); }); }); })(); ",,260,2
openstack%2Fneutron-fwaas~master~I7f810f6ad3b15e2bd82b532fa874d9416e277364,openstack/neutron-fwaas,master,I7f810f6ad3b15e2bd82b532fa874d9416e277364,[WIP] Support logging configuration feature for FWaaS,ABANDONED,2015-07-22 08:05:59.000000000,2015-12-12 03:05:42.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 13702}, {'_account_id': 15226}, {'_account_id': 15330}, {'_account_id': 15444}, {'_account_id': 15471}, {'_account_id': 15905}, {'_account_id': 16788}]","[{'number': 1, 'created': '2015-07-22 08:05:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/d2719513a2de318b18ddadf18af05f5971047ba0', 'message': '[WIP] Support packet logging feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\n'}, {'number': 2, 'created': '2015-07-27 11:00:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/6eaa97d437da2c0816e45cdb2276285e848f853e', 'message': '[WIP] Support packet logging feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\n'}, {'number': 3, 'created': '2015-08-14 12:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/816f3a95c51037affaf8b54ce02ab14d8d7f31bc', 'message': '[WIP] Support logging configuration feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\n'}, {'number': 4, 'created': '2015-08-18 11:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/aff65b4c9153e6fddcbec7e06dc466f8709d05bc', 'message': '[WIP] Support logging configuration feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\n'}, {'number': 5, 'created': '2015-08-24 10:18:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/2b715166e394381a30dfcb57f5b5f2a38f6e65f9', 'message': '[WIP] Support logging configuration feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\n'}, {'number': 6, 'created': '2015-10-06 02:58:44.000000000', 'files': ['neutron_fwaas/services/firewall/drivers/linux/ulogd.py', 'etc/ulogd.conf', 'neutron_fwaas/services/firewall/agents/l3reference/firewall_l3_agent.py', 'neutron_fwaas/db/firewall/firewall_db.py', 'neutron_fwaas/db/migration/alembic_migrations/versions/HEAD', 'setup.cfg', 'neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/058e7683bee8393505b2bd1b608ab80189273631', 'message': '[WIP] Support logging configuration feature for FWaaS\n\nThis change along with [1], implements the RFE that is tracked by [2]\nand based on specification by [3]\n\n[1] https://review.openstack.org/204481\n[2] https://bugs.launchpad.net/neutron/+bug/1468366\n[3] https://review.openstack.org/#/c/203509/\n\nChange-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364\nCo-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>\nDepends-on: I44837e31a713b6f2d20aa07bc38ef67265543d1a\n'}]",8,204484,058e7683bee8393505b2bd1b608ab80189273631,42,13,6,15905,,,0,"[WIP] Support logging configuration feature for FWaaS

This change along with [1], implements the RFE that is tracked by [2]
and based on specification by [3]

[1] https://review.openstack.org/204481
[2] https://bugs.launchpad.net/neutron/+bug/1468366
[3] https://review.openstack.org/#/c/203509/

Change-Id: I7f810f6ad3b15e2bd82b532fa874d9416e277364
Co-Authored-By: Yushiro FURUKAWA <y.furukawa_2@jp.fujitsu.com>
Depends-on: I44837e31a713b6f2d20aa07bc38ef67265543d1a
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/84/204484/6 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ulogd.conf', 'neutron_fwaas/db/firewall/firewall_db.py', 'neutron_fwaas/services/firewall/fwaas_plugin.py', 'setup.cfg', 'neutron_fwaas/services/firewall/drivers/linux/iptables_fwaas.py']",5,d2719513a2de318b18ddadf18af05f5971047ba0,bug/1468366,"import subprocess #restart ulogd in network namespace if self.enable_logging: self._restart_ulogd(ipt_mgr.namespace) self.enable_logging = False if rule.get('logging', None): self.enable_logging = self._add_logging_rule(fwid, rule, ichain_name, ochain_name, table) def _add_logging_rule(self, fwid, rule, ichain_name, ochain_name, table): ilog_rule = self._logging_rule(fwid, rule, INGRESS_DIRECTION) olog_rule = self._logging_rule(fwid, rule, EGRESS_DIRECTION) table.add_rule(ichain_name, ilog_rule) table.add_rule(ochain_name, olog_rule) return True def _logging_rule(self, fwid, rule, direction): action = rule.get('action') if action == 'allow': target = ['-j NFLOG --nflog-prefix \""[fwaas]:[ %s A %s] \""' % (CHAIN_NAME_PREFIX[direction], fwid[:13])] else: target = ['-j NFLOG --nflog-prefix \""[fwaas]:[ %s D %s] \""' % (CHAIN_NAME_PREFIX[direction], fwid[:13])] args = [self._protocol_arg(rule.get('protocol')), self._port_arg('dport', rule.get('protocol'), rule.get('destination_port')), self._port_arg('sport', rule.get('protocol'), rule.get('source_port')), self._ip_prefix_arg('s', rule.get('source_ip_address')), self._ip_prefix_arg('d', rule.get('destination_ip_address'))] iptables_rule = ' '.join(args + target) return iptables_rule def _run_command(self, cmd): stdout = subprocess.PIPE proc = subprocess.Popen(cmd, stdout=stdout) output = proc.communicate()[0] if proc.returncode != 0: LOG.debug('[fwaas logging]: Command ""%s"" failed .\n %s', ' '.join(cmd), output) return (output, proc.returncode) def _restart_ulogd(self, namespace): cmd = ['sudo', 'ip', 'netns', 'exec', str(namespace), 'sh', '/etc/init.d/ulogd2', 'restart'] self._run_command(cmd)",,408,3
openstack%2Fneutron-fwaas~master~Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd,openstack/neutron-fwaas,master,Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd,Adding Brocade vyatta 5600 router support,ABANDONED,2015-10-01 06:15:07.000000000,2015-12-12 03:05:41.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 8124}, {'_account_id': 10692}, {'_account_id': 11753}, {'_account_id': 12525}, {'_account_id': 14605}, {'_account_id': 15330}, {'_account_id': 16788}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-10-01 06:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/032ebef261d60edf36b5b2ed64481946826dead6', 'message': 'Adding Brocade vyatta 5600 version support\n\nChange-Id: Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd\nCloses-Bug: #1501597\n'}, {'number': 2, 'created': '2015-10-01 10:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/62b4b662b8a14d31b453d359ac7f89dcb7e117f8', 'message': 'Adding Brocade vyatta 5600 version support\n\nChange-Id: Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd\nCloses-Bug: #1501597\n'}, {'number': 3, 'created': '2015-10-01 13:15:36.000000000', 'files': ['neutron_fwaas/services/firewall/agents/vyatta/firewall_service.py', 'neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/8bff6079771f78c8eb5612209342600dd95e123a', 'message': 'Adding Brocade vyatta 5600 router support\n\nChange-Id: Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd\nCloses-Bug: #1501597\n'}]",1,229737,8bff6079771f78c8eb5612209342600dd95e123a,28,10,3,16672,,,0,"Adding Brocade vyatta 5600 router support

Change-Id: Ie746b40ca4b6fe0ae5416c7d9f687345fdeeeafd
Closes-Bug: #1501597
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/37/229737/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/services/firewall/agents/vyatta/firewall_service.py', 'neutron_fwaas/services/firewall/agents/vyatta/vyatta_utils.py', 'neutron_fwaas/services/firewall/drivers/vyatta/vyatta_fwaas.py']",3,032ebef261d60edf36b5b2ed64481946826dead6,FW_5600_5400_support,"from networking_brocade.vyatta.fw import config as fw_config client.get_firewall_command('FW_NAME').format( parse.quote_plus(fw_name)))) client.get_firewall_command('FW_DESCRIPTION').format( if (client.does_firewall_command_exist('FW_ESTABLISHED_ACCEPT')): fw_cmd_list.append(vyatta_client.SetCmd(client.get_firewall_command( 'FW_ESTABLISHED_ACCEPT'))) if (client.does_firewall_command_exist('FW_RELATED_ACCEPT')): fw_cmd_list.append(vyatta_client.SetCmd(client.get_firewall_command( 'FW_RELATED_ACCEPT'))) fw_cmd_list += self._set_firewall_rule(client, fw_name, rule_num, rule) cmd_list.append(vyatta_client.DeleteCmd(client.get_zone_command( ""ZONE_POLICY""))) client.get_firewall_command('FW_NAME').format( parse.quote_plus(fw_name)))) if (client.does_firewall_command_exist('FIREWALL_STATE_POLICY')): # Delete firewall state policy cmd_list.append(vyatta_client.DeleteCmd(client.get_firewall_command( 'FIREWALL_STATE_POLICY'))) def _set_firewall_rule(self, client, fw_name, rule_num, rule): client.get_firewall_command('FW_RULE_DESCRIPTION').format( ('protocol', client.get_firewall_command( 'FW_RULE_PROTOCOL')), ('source_port', client.get_firewall_command( 'FW_RULE_SRC_PORT')), ('destination_port', client.get_firewall_command( 'FW_RULE_DEST_PORT')), ('source_ip_address', client.get_firewall_command( 'FW_RULE_SRC_ADDR')), ('destination_ip_address', client.get_firewall_command( 'FW_RULE_DEST_ADDR')), client.get_firewall_command('FW_RULE_ACTION').format(","FW_NAME = 'firewall/name/{0}' FW_DESCRIPTION = 'firewall/name/{0}/description/{1}' FW_ESTABLISHED_ACCEPT = 'firewall/state-policy/established/action/accept' FW_RELATED_ACCEPT = 'firewall/state-policy/related/action/accept' FW_RULE_DESCRIPTION = 'firewall/name/{0}/rule/{1}/description/{2}' FW_RULE_PROTOCOL = 'firewall/name/{0}/rule/{1}/protocol/{2}' FW_RULE_SRC_PORT = 'firewall/name/{0}/rule/{1}/source/port/{2}' FW_RULE_DEST_PORT = 'firewall/name/{0}/rule/{1}/destination/port/{2}' FW_RULE_SRC_ADDR = 'firewall/name/{0}/rule/{1}/source/address/{2}' FW_RULE_DEST_ADDR = 'firewall/name/{0}/rule/{1}/destination/address/{2}' FW_RULE_ACTION = 'firewall/name/{0}/rule/{1}/action/{2}' FW_NAME.format(parse.quote_plus(fw_name)))) FW_DESCRIPTION.format( fw_cmd_list.append(vyatta_client.SetCmd(FW_ESTABLISHED_ACCEPT)) fw_cmd_list.append(vyatta_client.SetCmd(FW_RELATED_ACCEPT)) fw_cmd_list += self._set_firewall_rule(fw_name, rule_num, rule) cmd_list.append(vyatta_client.DeleteCmd(""zone-policy"")) FW_NAME.format(parse.quote_plus(fw_name)))) # Delete firewall state policy cmd_list.append(vyatta_client.DeleteCmd(""firewall/state-policy"")) def _set_firewall_rule(self, fw_name, rule_num, rule): FW_RULE_DESCRIPTION.format( ('protocol', FW_RULE_PROTOCOL), ('source_port', FW_RULE_SRC_PORT), ('destination_port', FW_RULE_DEST_PORT), ('source_ip_address', FW_RULE_SRC_ADDR), ('destination_ip_address', FW_RULE_DEST_ADDR), FW_RULE_ACTION.format(",45,41
openstack%2Fneutron~master~I9356755bd9e54e47e75b6342b702eee31865a538,openstack/neutron,master,I9356755bd9e54e47e75b6342b702eee31865a538,WIP! DO NOT MERGE: refactor DVR local and edge router classes,ABANDONED,2015-10-23 15:32:36.000000000,2015-12-12 03:05:38.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 7016}, {'_account_id': 7448}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10692}, {'_account_id': 11682}, {'_account_id': 12444}, {'_account_id': 14039}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14571}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17500}]","[{'number': 1, 'created': '2015-10-23 15:32:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d6251e7c902ba162bcb105ac482fdb86ff0a0c70', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 2, 'created': '2015-10-23 15:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d12f6e867bea9c432a1192eedd28b1b41d6b3dbc', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 3, 'created': '2015-10-23 16:12:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dffd6273cf7f862d7ff907e7e1a58bc8606e940b', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 4, 'created': '2015-10-23 16:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b087a17596256fee357971f69b6b43973ff6b917', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 5, 'created': '2015-10-26 14:55:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/89b02286caad8c032d183a70e2491311eaacfbb4', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nTODO: figure out how to instantiate both distributed and\ncentralized classes when needed and have them coexist correctly\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 6, 'created': '2015-10-26 15:24:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6dcf89bf4e5187d29f767eb1507668098cc3e6fd', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nTODO: figure out how to instantiate both distributed and\ncentralized classes when needed and have them coexist correctly\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\n'}, {'number': 7, 'created': '2015-11-10 18:47:04.000000000', 'files': ['neutron/agent/l3/dvr_centralized_ha_router.py', 'neutron/agent/l3/agent.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/tests/unit/agent/l3/test_dvr_distributed_router.py', 'neutron/tests/unit/agent/l3/test_agent.py', 'neutron/agent/l3/dvr_centralized_router.py', 'neutron/agent/l3/dvr_router_base.py', 'neutron/agent/l3/dvr_distributed_router.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/462fd0b0cd061bb975db615c23174b8d6fd09a87', 'message': 'WIP! DO NOT MERGE: refactor DVR local and edge router classes\n\nRename DVR router classes to distributed and centralized to\nreflect their functionality. Refactor code between distributed\nrouter and DvrRouterBase classes to allow the centralized router\nclass to inherit from DvrRouterBase rather than from the\ndistributed router class.\n\nTODO: figure out how to instantiate both distributed and\ncentralized classes when needed and have them coexist correctly\n\nChange-Id: I9356755bd9e54e47e75b6342b702eee31865a538\nSigned-off-by: Ryan Moats <rmoats@us.ibm.com>\nCloses-Bug: 1458541\n'}]",2,238967,462fd0b0cd061bb975db615c23174b8d6fd09a87,79,22,7,11682,,,0,"WIP! DO NOT MERGE: refactor DVR local and edge router classes

Rename DVR router classes to distributed and centralized to
reflect their functionality. Refactor code between distributed
router and DvrRouterBase classes to allow the centralized router
class to inherit from DvrRouterBase rather than from the
distributed router class.

TODO: figure out how to instantiate both distributed and
centralized classes when needed and have them coexist correctly

Change-Id: I9356755bd9e54e47e75b6342b702eee31865a538
Signed-off-by: Ryan Moats <rmoats@us.ibm.com>
Closes-Bug: 1458541
",git fetch https://review.opendev.org/openstack/neutron refs/changes/67/238967/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/l3/dvr_centralized_ha_router.py', 'neutron/agent/l3/agent.py', 'neutron/agent/l3/dvr_centralized_router.py', 'neutron/agent/l3/dvr_distributed_router.py']",4,d6251e7c902ba162bcb105ac482fdb86ff0a0c70,bug/1458541,"class DvrDistributedRouter(dvr_router_base.DvrRouterBase): def __init__(self, agent, host, *args, **kwargs): super(DvrDistributedRouter, self).__init__(agent, host, *args, **kwargs) floating_ips = super(DvrDistributedRouter, self).get_floating_ips() super(DvrDistributedRouter, self).remove_floating_ip(device, ip_cidr) super(DvrDistributedRouter, self).internal_network_added(port) super(DvrDistributedRouter, self).internal_network_removed(port) super(DvrDistributedRouter, self).process_external(agent) super(DvrDistributedRouter, self).process(agent)","class DvrLocalRouter(dvr_router_base.DvrRouterBase): def __init__(self, agent, host, *args, **kwargs): super(DvrLocalRouter, self).__init__(agent, host, *args, **kwargs) floating_ips = super(DvrLocalRouter, self).get_floating_ips() super(DvrLocalRouter, self).remove_floating_ip(device, ip_cidr) super(DvrLocalRouter, self).internal_network_added(port) super(DvrLocalRouter, self).internal_network_removed(port) super(DvrLocalRouter, self).process_external(agent) super(DvrLocalRouter, self).process(agent)",39,34
openstack%2Fneutron~master~Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87,openstack/neutron,master,Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87,Trunk port: DB models and service plugin,ABANDONED,2015-08-07 10:32:22.000000000,2015-12-12 03:05:36.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1561}, {'_account_id': 1923}, {'_account_id': 4187}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7249}, {'_account_id': 7278}, {'_account_id': 8313}, {'_account_id': 8911}, {'_account_id': 9562}, {'_account_id': 9681}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11097}, {'_account_id': 11343}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14323}, {'_account_id': 14352}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15361}, {'_account_id': 15444}, {'_account_id': 15554}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-08-07 10:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ff3a5f963a4d70548b7e799cea619e40e5aebb5e', 'message': 'Trunk port: DB model for trunk ports\n\nMapped class, db mixin and alembic migration script.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nCo-Authored-By: Bence Romsics <bence.romsics@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 2, 'created': '2015-08-07 12:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/49bae2820f2a56c9e445c05ccc2b32296c3bd32e', 'message': 'Trunk port: DB model for trunk ports\n\nMapped class, db mixin and alembic migration script.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nCo-Authored-By: Bence Romsics <bence.romsics@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 3, 'created': '2015-08-10 09:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/776f70d5111e588bd5966be5ccffcdb57ab7c834', 'message': 'Trunk port: DB model for trunk ports\n\nMapped class, db mixin and alembic migration script.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nCo-Authored-By: Bence Romsics <bence.romsics@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 4, 'created': '2015-08-10 12:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d39eb8c806b56e4236055a43b7c3e4c27ec2bd1', 'message': 'Trunk port: DB model for trunk ports\n\nMapped class, db mixin and alembic migration script.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 5, 'created': '2015-08-12 15:04:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dd0d6eb30b1dfe46ac26674af01e9d042a764a46', 'message': 'Trunk port: DB model for trunk ports\n\nMapped class, db mixin and alembic migration script.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 6, 'created': '2015-08-13 12:36:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/d8a6842d2505b9031a7cf1d1883b7f686b2c3c39', 'message': 'Trunk port: DB models and service plugin\n\nMapped classes, db mixins and alembic migration scripts.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 7, 'created': '2015-08-18 13:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/55badab96c5a13cb57d5ae8e56ec883d5e05831c', 'message': 'Trunk port: DB models and service plugin\n\nMapped classes, db mixins and alembic migration scripts.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 8, 'created': '2015-08-24 13:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c5a3632cff70575ae2c190a3e448e015c35b9248', 'message': 'Trunk port: DB models and service plugin\n\nMapped classes, db mixins, alembic migration scripts and unit tests.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}, {'number': 9, 'created': '2015-08-25 12:01:39.000000000', 'files': ['neutron/db/migration/models/head.py', 'neutron/db/trunk_port_sub.py', 'neutron/db/trunk_port_trunk.py', 'neutron/db/trunk_port_models.py', 'neutron/tests/unit/extensions/test_trunk_port.py', 'neutron/db/migration/alembic_migrations/versions/HEADS', 'neutron/services/trunk_port/plugin.py', 'neutron/db/migration/alembic_migrations/versions/liberty/expand/b6fcda956b37_trunk_port.py', 'neutron/tests/unit/db/test_trunk_port_trunk.py', 'neutron/services/trunk_port/__init__.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fd1bbda2b1fd416d341941e0b9510b77b556911b', 'message': 'Trunk port: DB models and service plugin\n\nMapped classes, db mixins, alembic migration scripts and unit tests.\n\nCo-Authored-By: Lajos Katona <lajos.katona@ericsson.com>\nChange-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87\nPartially-Implements: blueprint vlan-aware-vms\n'}]",24,210310,fd1bbda2b1fd416d341941e0b9510b77b556911b,208,41,9,15554,,,0,"Trunk port: DB models and service plugin

Mapped classes, db mixins, alembic migration scripts and unit tests.

Co-Authored-By: Lajos Katona <lajos.katona@ericsson.com>
Change-Id: Ie0bb5c142fc6a25d8c7a8f84bbe9a88a49ac3b87
Partially-Implements: blueprint vlan-aware-vms
",git fetch https://review.opendev.org/openstack/neutron refs/changes/10/210310/9 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/trunk_port_trunk.py', 'neutron/db/migration/alembic_migrations/versions/liberty/expand/368086136746_trunk_port_trunk.py']",2,ff3a5f963a4d70548b7e799cea619e40e5aebb5e,bp/vlan-aware-vms,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """"""Trunk port: trunk_ports table """""" # revision identifiers, used by Alembic. revision = '368086136746' down_revision = '1b4c6e320f79' from alembic import op import sqlalchemy as sa from neutron.api.v2 import attributes as attr def upgrade(): op.create_table( 'trunk_ports', sa.Column('admin_state_up', sa.Boolean(), nullable=False), sa.Column('default_mac_address', sa.String(length=32), nullable=False, unique=True), sa.Column('device_id', sa.String(length=255), nullable=False), sa.Column('device_owner', sa.String(length=255), nullable=False), sa.Column('id', sa.String(length=36), nullable=False), sa.Column('name', sa.String(length=attr.NAME_MAX_LEN), nullable=True), sa.Column('status', sa.String(length=16), nullable=False), sa.Column('tenant_id', sa.String(length=255), nullable=True), sa.PrimaryKeyConstraint('id') ) ",,247,0
openstack%2Fpython-neutronclient~master~Ie22081ecba2b58c86f21ef124271993e91ace93e,openstack/python-neutronclient,master,Ie22081ecba2b58c86f21ef124271993e91ace93e,Use os-client-config to construct the Client,ABANDONED,2015-11-05 14:51:38.000000000,2015-12-12 03:05:34.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 16788}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-11-05 14:51:38.000000000', 'files': ['neutronclient/tests/unit/test_shell.py', 'neutronclient/neutron/client.py', 'neutronclient/common/clientmanager.py', 'neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/030d2173f59f1b3d6e8910dea1ae7bc290fd3ae0', 'message': 'Use os-client-config to construct the Client\n\nos-client-config knows how to properly turn a CloudConfig into a\nworking client object with all of the arguments passed properly.\n\nDepends-On: I1934cb086f905850941c06e0e79189f7642652d6\nChange-Id: Ie22081ecba2b58c86f21ef124271993e91ace93e\n'}]",8,242097,030d2173f59f1b3d6e8910dea1ae7bc290fd3ae0,7,4,1,2,,,0,"Use os-client-config to construct the Client

os-client-config knows how to properly turn a CloudConfig into a
working client object with all of the arguments passed properly.

Depends-On: I1934cb086f905850941c06e0e79189f7642652d6
Change-Id: Ie22081ecba2b58c86f21ef124271993e91ace93e
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/97/242097/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_shell.py', 'neutronclient/neutron/client.py', 'neutronclient/common/clientmanager.py', 'neutronclient/shell.py']",4,030d2173f59f1b3d6e8910dea1ae7bc290fd3ae0,clouds-yaml," cloud=self.options.os_cloud, argparse=self.options) self.client_manager = clientmanager.OpenStackClientManager( cloud_config=cloud_config, log_credentials=False)","from keystoneauth1 import session self.api_version = apiversion if arg in self.commands[self.api_version]: if command_pos == -1: command_pos = index argparse=self.options) verify, cert = cloud_config.get_requests_verify_args() auth = cloud_config.get_auth() auth_session = session.Session( auth=auth, verify=verify, cert=cert, timeout=self.options.http_timeout) self.client_manager = clientmanager.ClientManager( session=auth_session, region_name=cloud_config.get_region_name(), api_version=cloud_config.get_api_version('network'), service_type=cloud_config.get_service_type('network'), service_name=cloud_config.get_service_name('network'), endpoint_type=cloud_config.get_interface('network'), auth=auth, log_credentials=True) return self.api_version = {'network': self.api_version} ",76,52
openstack%2Fpython-neutronclient~master~I10dee3a2ef2b459b481208efb21dd044e3ab84dc,openstack/python-neutronclient,master,I10dee3a2ef2b459b481208efb21dd044e3ab84dc,Pluggable neutronclient authentication,ABANDONED,2015-02-20 17:01:14.000000000,2015-12-12 03:05:33.000000000,,"[{'_account_id': 3}, {'_account_id': 642}, {'_account_id': 748}, {'_account_id': 5127}, {'_account_id': 6854}, {'_account_id': 8124}, {'_account_id': 16788}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-02-20 17:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/96282e740e7f4a2f23a0719a69607d07d647521d', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: blueprint Pluggable Authentication for Python-Neutronclient\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}, {'number': 2, 'created': '2015-02-20 17:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4a90c5bb5d6aad54b0ddbe6bee266967d46a6930', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: pluggable-neutronclient-auth\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}, {'number': 3, 'created': '2015-02-20 17:09:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/2e87a8b4bae6e8aebba53031964f5f47792d8473', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: blueprint pluggable-neutronclient-auth\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}, {'number': 4, 'created': '2015-02-20 17:33:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/4d2af7a483cb437494e967758d21aa069866628e', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: blueprint pluggable-neutronclient-auth\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}, {'number': 5, 'created': '2015-02-20 20:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e4bbe10385846a047b5ee8d357d61a851b27668f', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: blueprint pluggable-neutronclient-auth\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}, {'number': 6, 'created': '2015-02-20 20:34:42.000000000', 'files': ['neutronclient/client.py', 'neutronclient/common/auth_plugin.py', 'neutronclient/tests/unit/test_shell.py', 'neutronclient/neutron/client.py', 'neutronclient/common/clientmanager.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/common/exceptions.py', 'neutronclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/01f788c776eb85419b68c0b38a9d5984a02f0a64', 'message': 'Pluggable neutronclient authentication\n\nProvides for pluggable authentication similar to novaclient.\n\nImplements: blueprint pluggable-neutronclient-auth\nChange-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc\n'}]",28,157870,01f788c776eb85419b68c0b38a9d5984a02f0a64,20,8,6,7037,,,0,"Pluggable neutronclient authentication

Provides for pluggable authentication similar to novaclient.

Implements: blueprint pluggable-neutronclient-auth
Change-Id: I10dee3a2ef2b459b481208efb21dd044e3ab84dc
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/70/157870/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/client.py', 'neutronclient/tests/unit/test_shell.py', 'neutronclient/auth_plugin.py', 'neutronclient/neutron/client.py', 'neutronclient/common/clientmanager.py', 'neutronclient/tests/unit/test_ssl.py', 'neutronclient/common/exceptions.py', 'neutronclient/shell.py']",8,96282e740e7f4a2f23a0719a69607d07d647521d,bp/pluggable-neutronclient-auth,"from neutronclient import auth_plugin _os_auth_str = self.options.os_auth_strategy _auth_plugin = None if _os_auth_str == 'keystone': if _os_auth_str and _os_auth_str != 'keystone': try: _auth_plugin = auth_plugin.load_plugin(_os_auth_str) except exc.AuthSystemNotFound: raise elif not self.options.os_url: auth_plugin=_auth_plugin,", if self.options.os_auth_strategy == 'keystone': if not self.options.os_url:,200,6
openstack%2Fneutron~master~I76cbe99ad356ceafb6954e52e6a393796d694f93,openstack/neutron,master,I76cbe99ad356ceafb6954e52e6a393796d694f93,Adds support to provide udpcsum option for Linux Bridge,ABANDONED,2015-11-11 04:37:33.000000000,2015-12-12 03:05:31.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 6951}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10068}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11114}, {'_account_id': 12860}, {'_account_id': 14208}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-11-11 04:37:33.000000000', 'files': ['neutron/plugins/ml2/drivers/linuxbridge/agent/common/config.py', 'neutron/plugins/ml2/drivers/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f65e3f2741502d259898a41f48c624181617e5a1', 'message': 'Adds support to provide udpcsum option for Linux Bridge\n\nChange-Id: I76cbe99ad356ceafb6954e52e6a393796d694f93\nCloses-bug:  #1515069\nRelated-Bug: #1492111\nSigned-off-by: Takashi Okamoto <okamoto_takashi_p3@lab.ntt.co.jp>\n'}]",7,243943,f65e3f2741502d259898a41f48c624181617e5a1,20,20,1,19225,,,0,"Adds support to provide udpcsum option for Linux Bridge

Change-Id: I76cbe99ad356ceafb6954e52e6a393796d694f93
Closes-bug:  #1515069
Related-Bug: #1492111
Signed-off-by: Takashi Okamoto <okamoto_takashi_p3@lab.ntt.co.jp>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/243943/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/linuxbridge/agent/common/config.py', 'neutron/plugins/ml2/drivers/linuxbridge/agent/linuxbridge_neutron_agent.py', 'neutron/agent/linux/ip_lib.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py']",4,f65e3f2741502d259898a41f48c624181617e5a1,bug/1515069," def test_add_vxlan_udpcsum(self): retval = ip_lib.IPWrapper().add_vxlan('vxlan0', 'vni0', group='group0', dev='dev0', udpcsum=True) self.assertIsInstance(retval, ip_lib.IPDevice) self.assertEqual(retval.name, 'vxlan0') self.execute.assert_called_once_with([], 'link', ['add', 'vxlan0', 'type', 'vxlan', 'id', 'vni0', 'group', 'group0', 'dev', 'dev0', 'udpcsum'], run_as_root=True, namespace=None, log_fail_as_error=True) ",,24,1
openstack%2Fneutron~master~I20da2214d5a906ca4fe22f5fe391dbb77d9a69db,openstack/neutron,master,I20da2214d5a906ca4fe22f5fe391dbb77d9a69db,Add verification for device_owner when missing the port_security attr,ABANDONED,2015-08-24 08:23:13.000000000,2015-12-12 03:05:25.000000000,,"[{'_account_id': 3}, {'_account_id': 704}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 4395}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 6816}, {'_account_id': 6854}, {'_account_id': 7249}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 11114}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15444}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-08-24 08:23:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2efc0bf9ada01457f867cee437562bd2ec0fb1bd', 'message': ""Add verification for device_owner when missing the port_security attr\n\nport dict extending process will extend the port_security to be True when no\nsuch key found(not use port_sec extension last time). But for port's\ndevice_owner that start with 'network:', like router gateway and dhcp ports,\nthis attribute should be False.\n\nRelated-Bug: 1483315\n\nChange-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db\n""}, {'number': 2, 'created': '2015-08-24 08:29:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c207a243347346712be21bc3d3345b094a2ffa1e', 'message': ""Add verification for device_owner when missing the port_security attr\n\nport dict extending process will extend the port_security to be True when no\nsuch key found(not use port_sec extension last time). But for port's\ndevice_owner that start with 'network:', like router gateway and dhcp ports,\nthis attribute should be False.\n\nRelated-Bug: 1483315\n\nChange-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db\n""}, {'number': 3, 'created': '2015-08-25 02:28:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eba766c81b23ddf07b9c4cd280a5400fc6e150f7', 'message': ""Add verification for device_owner when missing the port_security attr\n\nport dict extending process will extend the port_security to be True when no\nsuch key found(not use port_sec extension last time). But for port's\ndevice_owner that start with 'network:', like router gateway and dhcp ports,\nthis attribute should be False.\n\nRelated-Bug: 1483315\n\nChange-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db\n""}, {'number': 4, 'created': '2015-09-14 10:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a8fb4778ea9c45fcea9c61f332151fd798d1057b', 'message': ""Add verification for device_owner when missing the port_security attr\n\nport dict extending process will extend the port_security to be True when no\nsuch key found(not use port_sec extension last time). But for port's\ndevice_owner that start with 'network:', like router gateway and dhcp ports,\nthis attribute should be False.\n\nRelated-Bug: 1483315\n\nChange-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db\n""}, {'number': 5, 'created': '2015-11-12 16:10:47.000000000', 'files': ['neutron/tests/unit/extensions/test_portsecurity.py', 'neutron/plugins/ml2/extensions/port_security.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/83658d042333361255510b56c56a5ed530d65c90', 'message': ""Add verification for device_owner when missing the port_security attr\n\nport dict extending process will extend the port_security to be True when no\nsuch key found(not use port_sec extension last time). But for port's\ndevice_owner that start with 'network:', like router gateway and dhcp ports,\nthis attribute should be False.\n\nRelated-Bug: 1483315\n\nChange-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db\n""}]",8,216143,83658d042333361255510b56c56a5ed530d65c90,68,29,5,11114,,,0,"Add verification for device_owner when missing the port_security attr

port dict extending process will extend the port_security to be True when no
such key found(not use port_sec extension last time). But for port's
device_owner that start with 'network:', like router gateway and dhcp ports,
this attribute should be False.

Related-Bug: 1483315

Change-Id: I20da2214d5a906ca4fe22f5fe391dbb77d9a69db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/43/216143/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/extensions/port_security.py'],1,2efc0bf9ada01457f867cee437562bd2ec0fb1bd,bug/1483315," if self._check_device_owner(db_data): response_data[psec.PORTSECURITY] = False else: response_data[psec.PORTSECURITY] = ( psec.EXTENDED_ATTRIBUTES_2_0['networks'] [psec.PORTSECURITY]['default']) def _check_device_owner(self, port): return (port.get('device_owner') and port['device_owner'].startswith('network:')) if self._check_device_owner(port):", response_data[psec.PORTSECURITY] = ( psec.EXTENDED_ATTRIBUTES_2_0['networks'] [psec.PORTSECURITY]['default']) if (port.get('device_owner') and port['device_owner'].startswith('network:')):,12,5
openstack%2Fneutron~master~I1b16e20a3159405f40c228f60bc458c744a0f0fc,openstack/neutron,master,I1b16e20a3159405f40c228f60bc458c744a0f0fc,Fix hardcode for IP Version v4 and v6,ABANDONED,2015-10-30 10:19:30.000000000,2015-12-12 03:05:24.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 4656}, {'_account_id': 5170}, {'_account_id': 7037}, {'_account_id': 7293}, {'_account_id': 7715}, {'_account_id': 7787}, {'_account_id': 7805}, {'_account_id': 8124}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 11682}, {'_account_id': 12860}, {'_account_id': 12942}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 14611}, {'_account_id': 15752}, {'_account_id': 17211}, {'_account_id': 17500}, {'_account_id': 17776}, {'_account_id': 18085}, {'_account_id': 18369}, {'_account_id': 18573}]","[{'number': 1, 'created': '2015-10-30 10:19:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/36744cbfdeab95630339f1564e8a7cc3df227a2c', 'message': 'Fix small nit about hardcode in ipset_manager\n\nIn ipset_manager.py, ip_version and IPv6 is hardcoded, this patch\nuse constants which had already defined in neutron/common/constants.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 2, 'created': '2015-10-31 09:23:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/bebfe1689fa0b973fe3bbad94c313646aefffc99', 'message': 'Fix hardcode for IP Verion v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 is hardcoded 4 and 6, this patch\nuse constants which had already defined in neutron/common/constants.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 3, 'created': '2015-10-31 14:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/01de389d1311b159a15d0654dfab679d6f931f25', 'message': 'Fix hardcode for IP Version v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch\nusing constants which had already defined in neutron/common/constants\nmodule.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 4, 'created': '2015-11-01 12:06:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8904eec05dc952075b9e34ed5234ee97876296b2', 'message': 'Fix hardcode for IP Version v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch\nusing constants which had already defined in neutron/common/constants\nmodule.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 5, 'created': '2015-11-01 15:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c805a7bcd591f98a1a4a95e95f4b4feb5efc023b', 'message': 'Fix hardcode for IP Version v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch\nusing constants which had already defined in neutron/common/constants\nmodule.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 6, 'created': '2015-11-02 07:48:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a7cd454ad6f05ee3a04ad5d8dff3caba3989ed06', 'message': 'Fix hardcode for IP Version v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch\nusing constants which had already defined in neutron/common/constants\nmodule.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}, {'number': 7, 'created': '2015-11-02 10:27:50.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py', 'neutron/tests/api/test_networks.py', 'neutron/db/ipam_backend_mixin.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/agent/linux/iptables_firewall.py', 'neutron/tests/unit/agent/linux/test_ip_lib.py', 'neutron/agent/linux/iptables_manager.py', 'neutron/common/utils.py', 'neutron/tests/api/test_routers.py', 'neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py', 'neutron/debug/debug_agent.py', 'neutron/tests/api/test_routers_negative.py', 'neutron/tests/unit/plugins/ml2/drivers/openvswitch/agent/test_ovs_neutron_agent.py', 'neutron/agent/dhcp/agent.py', 'neutron/ipam/requests.py', 'neutron/common/ipv6_utils.py', 'neutron/db/securitygroups_rpc_base.py', 'neutron/tests/api/base.py', 'neutron/tests/api/test_metering_extensions.py', 'neutron/tests/functional/agent/test_l3_agent.py', 'neutron/agent/linux/ipset_manager.py', 'neutron/plugins/ml2/drivers/linuxbridge/agent/arp_protect.py', 'neutron/agent/linux/ra.py', 'neutron/agent/linux/interface.py', 'neutron/agent/linux/ip_lib.py', 'neutron/plugins/ml2/drivers/openvswitch/agent/ovs_dvr_neutron_agent.py', 'neutron/tests/unit/extensions/test_l3.py', 'neutron/agent/l3/router_info.py', 'neutron/tests/api/test_ports.py', 'neutron/db/l3_db.py', 'neutron/tests/unit/extensions/test_dns.py', 'neutron/tests/api/test_extra_dhcp_options.py', 'neutron/api/v2/attributes.py', 'neutron/agent/l3/dvr_local_router.py', 'neutron/tests/common/l3_test_common.py', 'neutron/tests/common/net_helpers.py', 'neutron/ipam/utils.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/51ab9deca528b36b213e4755f19b2046e00e7839', 'message': 'Fix hardcode for IP Version v4 and v6\n\nIn some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch\nusing constants which had already defined in neutron/common/constants\nmodule.\n\nChange-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc\n'}]",29,240499,51ab9deca528b36b213e4755f19b2046e00e7839,122,32,7,12860,,,0,"Fix hardcode for IP Version v4 and v6

In some Neutron code, IPv4 and IPv6 are hardcoded 4 and 6, this patch
using constants which had already defined in neutron/common/constants
module.

Change-Id: I1b16e20a3159405f40c228f60bc458c744a0f0fc
",git fetch https://review.opendev.org/openstack/neutron refs/changes/99/240499/7 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/ipset_manager.py'],1,36744cbfdeab95630339f1564e8a7cc3df227a2c,fix/small_hardcode_for_IPv6,from neutron.common import constants if(ip.version == constants.IP_VERSION_4): elif (ip.version == constants.IP_VERSION_6): return 'inet6' if ethertype == constants.IPv6 else 'inet', if(ip.version == 4): elif (ip.version == 6): return 'inet6' if ethertype == 'IPv6' else 'inet',4,3
openstack%2Fneutron~master~I191f65172f17fdce02a5827443d6f0f973a6d02d,openstack/neutron,master,I191f65172f17fdce02a5827443d6f0f973a6d02d,DO NOT MERGE: examine AlwaysPoll path,ABANDONED,2015-09-10 12:39:42.000000000,2015-12-12 03:05:21.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 5170}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 9681}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17500}, {'_account_id': 18369}]","[{'number': 1, 'created': '2015-09-10 12:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0986508dd6d7baf648708f5f47d29ff5f1d74cc5', 'message': 'DO NOT MERGE: examine AlwaysPoll path\n\nChange-Id: I191f65172f17fdce02a5827443d6f0f973a6d02d\n'}, {'number': 2, 'created': '2015-11-09 10:07:49.000000000', 'files': ['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/4c14bf91c540a04c48900a929a6f6aaa15724bf2', 'message': 'DO NOT MERGE: examine AlwaysPoll path\n\nChange-Id: I191f65172f17fdce02a5827443d6f0f973a6d02d\n'}]",0,222170,4c14bf91c540a04c48900a929a6f6aaa15724bf2,37,22,2,6854,,,0,"DO NOT MERGE: examine AlwaysPoll path

Change-Id: I191f65172f17fdce02a5827443d6f0f973a6d02d
",git fetch https://review.opendev.org/openstack/neutron refs/changes/70/222170/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/plugins/ml2/drivers/openvswitch/agent/ovs_neutron_agent.py'],1,0986508dd6d7baf648708f5f47d29ff5f1d74cc5,," minimize_polling=False,"," minimize_polling=config.AGENT.minimize_polling,",1,1
openstack%2Fneutron~master~I54b70062739ae6e0bdb4d075ad87254d4489d5db,openstack/neutron,master,I54b70062739ae6e0bdb4d075ad87254d4489d5db,Do not update ACTIVE ports back to BUILD status,ABANDONED,2015-09-12 14:05:46.000000000,2015-12-12 03:05:19.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 5948}, {'_account_id': 9361}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10635}, {'_account_id': 11682}, {'_account_id': 13667}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-09-12 14:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ae57224770c24d0d5cd39c2d884509068383e372', 'message': 'WIP: Test\n\nChange-Id: I54b70062739ae6e0bdb4d075ad87254d4489d5db\n'}, {'number': 2, 'created': '2015-09-14 10:14:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e8a63254af6944f579fb00ec675b04bbc488e33c', 'message': 'WIP: Test\n\nChange-Id: I54b70062739ae6e0bdb4d075ad87254d4489d5db\n'}, {'number': 3, 'created': '2015-09-14 13:35:42.000000000', 'files': ['neutron/common/constants.py', 'neutron/plugins/ml2/rpc.py', 'neutron/tests/unit/plugins/ml2/test_rpc.py', 'neutron/plugins/ml2/plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/98a33cfc720de6bb8cee09ce29a83209e2b38afd', 'message': 'Do not update ACTIVE ports back to BUILD status\n\nStatus update (ACTIVE-BUILD-ACTIVE) may trigger a bunch of\nunneeded RPC communications between neutron server and l3\ndvr agents which may overload server fatally.\nUpdated ports will be put in PENDING_BUILD status right after\ndb update to distinguish real port update and cases when agents\nare just restarted and syncing with server.\n\nChange-Id: I54b70062739ae6e0bdb4d075ad87254d4489d5db\n'}]",0,222863,98a33cfc720de6bb8cee09ce29a83209e2b38afd,73,21,3,5948,,,0,"Do not update ACTIVE ports back to BUILD status

Status update (ACTIVE-BUILD-ACTIVE) may trigger a bunch of
unneeded RPC communications between neutron server and l3
dvr agents which may overload server fatally.
Updated ports will be put in PENDING_BUILD status right after
db update to distinguish real port update and cases when agents
are just restarted and syncing with server.

Change-Id: I54b70062739ae6e0bdb4d075ad87254d4489d5db
",git fetch https://review.opendev.org/openstack/neutron refs/changes/63/222863/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/rpc.py', 'neutron/plugins/ml2/plugin.py']",2,ae57224770c24d0d5cd39c2d884509068383e372,test, if binding['status'] != status: binding['status'] = status binding.update(binding) updated = True return updated, binding['status'] = status binding.update(binding) updated = True return port['id'],11,6
openstack%2Fpython-senlinclient~master~Id5f94e2260a0ea488543be742646f1063b5d6931,openstack/python-senlinclient,master,Id5f94e2260a0ea488543be742646f1063b5d6931,Updated from global requirements,MERGED,2015-12-11 15:26:16.000000000,2015-12-12 03:04:31.000000000,2015-12-12 03:04:31.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-12-11 15:26:16.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/f024ca64d87bc237b4f8c274b6942c521af93662', 'message': 'Updated from global requirements\n\nChange-Id: Id5f94e2260a0ea488543be742646f1063b5d6931\n'}]",0,256529,f024ca64d87bc237b4f8c274b6942c521af93662,8,3,1,11131,,,0,"Updated from global requirements

Change-Id: Id5f94e2260a0ea488543be742646f1063b5d6931
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/29/256529/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f024ca64d87bc237b4f8c274b6942c521af93662,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fhorizon~master~I4c48c09a0f20f971588b1e920a555f12e7ed4498,openstack/horizon,master,I4c48c09a0f20f971588b1e920a555f12e7ed4498,"Add API services for Create a Volume, get QoS and tenant limits",MERGED,2015-10-12 18:22:29.000000000,2015-12-12 03:00:02.000000000,2015-12-12 03:00:00.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8871}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 10442}, {'_account_id': 11941}, {'_account_id': 12071}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 17013}, {'_account_id': 17040}, {'_account_id': 17327}, {'_account_id': 18508}]","[{'number': 1, 'created': '2015-10-12 18:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/54a9f22114d1053379b1b9d6b2e1d31fc2f7eb6c', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 2, 'created': '2015-10-13 20:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8ed27e0d0522953709e84966e447884acd3ab4ea', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 3, 'created': '2015-10-16 18:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4cff82ee498569b662b9c82823e4a44ba2ffedac', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 4, 'created': '2015-10-16 18:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/36f4c4945018f8aac255c6529efc6c9512d8a466', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 5, 'created': '2015-10-16 23:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e3d9417537a9947f042fa7922f31feabd045a2ac', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 6, 'created': '2015-10-20 00:22:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/aebed9878ea6d3a3a04e3a87e567d2fd8de03136', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 7, 'created': '2015-10-20 00:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/7789f86be5d377b95cd564ca6bce76283942ae91', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 8, 'created': '2015-10-26 17:14:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/93cb2fc057fdb08b64e6259658a6e64b859be7d4', 'message': 'WIP: Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint ng-volumes\n'}, {'number': 9, 'created': '2015-10-27 22:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a2dde12002441f1c92c46c2e4837cc74e082dfea', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 10, 'created': '2015-10-29 16:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/be563854cc427153c07840477261700dfcdf86ea', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 11, 'created': '2015-11-02 23:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/76c555331e71c3fc386a7962f707d2399df41c4d', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 12, 'created': '2015-11-04 07:49:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4e10e3ae6f1c1cfd3f16fdd2653791dad1122ecd', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 13, 'created': '2015-11-04 19:31:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c259926ec6c8716117494631b40752d10ad50ced', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 14, 'created': '2015-11-04 22:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e7d6617010e04fffb4b27ec43df436ccbb8db060', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 15, 'created': '2015-11-13 22:41:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4d131663164ac36dfc1cdf7fc1e035e3a195d105', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 16, 'created': '2015-11-18 18:40:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/bbbebf3258aea37b8f3966878a974bf22fabd10c', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 17, 'created': '2015-12-01 05:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2ab1935c55959f9e757915c6febd48d53bb5f1a2', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 18, 'created': '2015-12-01 05:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c520dfb96af42ac971ce9d407b733be37c3e639c', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 19, 'created': '2015-12-01 19:24:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/13c0acce9f9aa0df74123f8712e2ac72a34ec40e', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 20, 'created': '2015-12-02 00:45:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8be91675e7ec6ff1de950d26264a5cdc95c48da9', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 21, 'created': '2015-12-02 05:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2dc261c89e4ac51aa2f5b79929b517ff28a4dc9c', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 22, 'created': '2015-12-02 23:37:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/575cf453da43829630e9d14764a9361f39bd9b04', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 23, 'created': '2015-12-04 22:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e66816dc84dd7061656a65f822e504ed8619586e', 'message': 'Add API services for angular Volumes panel\n\nAdding the cinder services for volumes and volume snapshots to the\nangular panel for Volumes.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit 2ab1935c55959f9e757915c6febd48d53bb5f1a2)\n'}, {'number': 24, 'created': '2015-12-04 22:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/c988cbbcaf0bf9903f374b8351919eaaf0939526', 'message': 'Add API services for angular images panel\n\nAdding cinder services to create and update volumes and volume snapshots,\nreturn Quality of Service and tenant absolute limits.\n\nThis is to support dependent patches that will create volumes for Images\nfrom the angular panel for Images.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n'}, {'number': 25, 'created': '2015-12-08 23:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/517ca37af4976936a6e63af8d26507539b853638', 'message': 'Add API services for Create a Volume, get QoS and tenant limits\n\nAdding cinder services to create and update volumes and volume snapshots,\nreturn Quality of Service and tenant absolute limits.\n\nThis is to support dependent patches that will create volumes for Images\nfrom the angular panel for Images.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit c988cbbcaf0bf9903f374b8351919eaaf0939526)\n'}, {'number': 26, 'created': '2015-12-09 00:04:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b8e1093465ee8bbc092cd0057683ba8886042334', 'message': 'Add API services for Create a Volume, get QoS and tenant limits\n\nAdding cinder services to create and update volumes and volume snapshots,\nreturn Quality of Service and tenant absolute limits.\n\nThis is to support dependent patches that will create volumes for Images\nfrom the angular panel for Images.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\nPartially-Implements: blueprint angularize-images-table\n(cherry picked from commit c988cbbcaf0bf9903f374b8351919eaaf0939526)\n'}, {'number': 27, 'created': '2015-12-09 00:42:58.000000000', 'files': ['openstack_dashboard/api/rest/cinder.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/test/api_tests/cinder_rest_tests.py', 'openstack_dashboard/static/app/core/openstack-service-api/cinder.service.js', 'openstack_dashboard/static/app/core/openstack-service-api/cinder.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/56e34bdf0c031d41bb413413542c396bd473f6cb', 'message': 'Add API services for Create a Volume, get QoS and tenant limits\n\nAdding cinder services to create and update volumes and volume snapshots,\nreturn Quality of Service and tenant absolute limits.\n\nThis is to support dependent patches that will create volumes for Images\nfrom the angular panel for Images.\n\nCo-Authored-By: Errol Pais<epais@thoughtworks.com>\nCo-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>\n\nPartially-Implements: blueprint angularize-images-table\nChange-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498\n'}]",18,233760,56e34bdf0c031d41bb413413542c396bd473f6cb,76,16,27,17040,,,0,"Add API services for Create a Volume, get QoS and tenant limits

Adding cinder services to create and update volumes and volume snapshots,
return Quality of Service and tenant absolute limits.

This is to support dependent patches that will create volumes for Images
from the angular panel for Images.

Co-Authored-By: Errol Pais<epais@thoughtworks.com>
Co-Authored-By: Nathan Zeplowitz<nzeplowi@thoughtworks.com>

Partially-Implements: blueprint angularize-images-table
Change-Id: I4c48c09a0f20f971588b1e920a555f12e7ed4498
",git fetch https://review.opendev.org/openstack/horizon refs/changes/60/233760/25 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/cinder.py', 'openstack_dashboard/api/cinder.py', 'openstack_dashboard/test/api_tests/cinder_rest_tests.py', 'openstack_dashboard/static/app/core/openstack-service-api/cinder.service.js', 'openstack_dashboard/static/app/core/openstack-service-api/cinder.service.spec.js']",5,54a9f22114d1053379b1b9d6b2e1d31fc2f7eb6c,bp/angularize-images-table," testInput: [ 'config' ] }, error: 'Unable to retrieve the volumes.' }, { func: 'getVolume', method: 'get', path: '/api/cinder/volumes/1', error: 'Unable to retrieve the volume.', testInput: [ 1 ] }, error: 'Unable to retrieve the volume snapshots.' }, testInput: [ 'config' ] }, { func: 'getVolumeTypes', method: 'get', path: '/api/cinder/volumetypes/', data: {}, error: 'Unable to retrieve the volume types.' }, { func: 'getVolumeTypes', method: 'get', path: '/api/cinder/volumetypes/', data: { params: 'config' }, error: 'Unable to retrieve the volume types.', testInput: [ 'config' ] }, { func: 'createVolume', method: 'post', path: '/api/cinder/volumes/', data: { params: 'config' }, error: 'Unable to create the volume.', testInput: [ { params: 'config' } ] }, { func: 'getQoSSpecs', method: 'get', path: '/api/cinder/qosspecs/', data: {}, error: 'Unable to retrieve the QoS Specs.' }, { func: 'getQoSSpecs', method: 'get', path: '/api/cinder/qosspecs/', data: { params: 'config' }, error: 'Unable to retrieve the QoS Specs.', testInput: [ 'config' ] }];"," testInput: [ 'config' ] }, error: 'Unable to retrieve the volumes.' }, error: 'Unable to retrieve the volume snapshots.' }, testInput: [ 'config' ] } ] ;",270,9
openstack%2Fpython-openstackclient~master~Ie88d50a9c1539ad24e0f8dae8ee5155ad467a0c0,openstack/python-openstackclient,master,Ie88d50a9c1539ad24e0f8dae8ee5155ad467a0c0,Updated from global requirements,MERGED,2015-12-11 15:26:02.000000000,2015-12-12 02:42:59.000000000,2015-12-12 02:42:58.000000000,"[{'_account_id': 3}, {'_account_id': 1941}]","[{'number': 1, 'created': '2015-12-11 15:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/935056e7aa84d9bc6d0ac34087cd32fdd7e0115f', 'message': 'Updated from global requirements\n\nChange-Id: Ie88d50a9c1539ad24e0f8dae8ee5155ad467a0c0\n'}, {'number': 2, 'created': '2015-12-11 22:53:44.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/cb812322540db78a2412d32e94fc82ec09eb48c7', 'message': 'Updated from global requirements\n\nChange-Id: Ie88d50a9c1539ad24e0f8dae8ee5155ad467a0c0\n'}]",0,256526,cb812322540db78a2412d32e94fc82ec09eb48c7,8,2,2,11131,,,0,"Updated from global requirements

Change-Id: Ie88d50a9c1539ad24e0f8dae8ee5155ad467a0c0
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/26/256526/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,935056e7aa84d9bc6d0ac34087cd32fdd7e0115f,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fsenlin~master~I15d8cbc4e59b28351f21026f60b1131083540112,openstack/senlin,master,I15d8cbc4e59b28351f21026f60b1131083540112,"Fix ""report a bug"" launchpad project",MERGED,2015-12-11 16:20:18.000000000,2015-12-12 02:13:24.000000000,2015-12-12 02:13:23.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 16:20:18.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/ccfebac43b580862324809203808907d8fe13787', 'message': 'Fix ""report a bug"" launchpad project\n\nFor docs set the launchpad project users report bugs\nagainst to ""senlin"". Users can report bugs\nusing the ""bug icon"" that will\ndirectly link to the launchpad project, it currently goes to\n""openstack-manuals"" which is wrong for this content.\n\nThis variable is used by openstackdocstheme 1.2.6.\n\nAlso, update comments for the variables passed to\nopenstackdocstheme.\n\nChange-Id: I15d8cbc4e59b28351f21026f60b1131083540112\nRelated-Bug: #1524476\n'}]",0,256565,ccfebac43b580862324809203808907d8fe13787,8,4,1,6547,,,0,"Fix ""report a bug"" launchpad project

For docs set the launchpad project users report bugs
against to ""senlin"". Users can report bugs
using the ""bug icon"" that will
directly link to the launchpad project, it currently goes to
""openstack-manuals"" which is wrong for this content.

This variable is used by openstackdocstheme 1.2.6.

Also, update comments for the variables passed to
openstackdocstheme.

Change-Id: I15d8cbc4e59b28351f21026f60b1131083540112
Related-Bug: #1524476
",git fetch https://review.opendev.org/openstack/senlin refs/changes/65/256565/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,ccfebac43b580862324809203808907d8fe13787,bug/1524476,"# A few variables have to be set for the log-a-bug feature. # giturl: The location of conf.py on Git. Must be set manually. # gitsha: The SHA checksum of the bug description. Extracted from git log. # bug_tag: Tag for categorizing the bug. Must be set manually. # bug_project: Launchpad project to file bugs against. # These variables are passed to the logabug code via html_context.html_context = {""pwd"": pwd, ""gitsha"": gitsha, ""bug_tag"": bug_tag, ""giturl"": giturl, ""bug_project"": ""senlin""} ","# We ask git for the SHA checksum # The git SHA checksum is used by ""log-a-bug"" # tag that reported bugs will be tagged with when using the ""log a bug"" # clickthrough on each page, such as user-guide or install-guidehtml_context = {""pwd"": pwd, ""gitsha"": gitsha, ""bug_tag"": bug_tag}",12,6
openstack%2Fnetworking-sfc~master~Ia1fba4b68e7ee341216d57e62176ada969e8e472,openstack/networking-sfc,master,Ia1fba4b68e7ee341216d57e62176ada969e8e472,add /etc/neutron/rootwrap.d to support devstack,MERGED,2015-11-25 22:51:04.000000000,2015-12-12 02:10:10.000000000,2015-12-12 02:10:09.000000000,"[{'_account_id': 3}, {'_account_id': 6854}, {'_account_id': 7776}, {'_account_id': 9375}, {'_account_id': 9396}, {'_account_id': 11313}, {'_account_id': 14605}, {'_account_id': 16707}, {'_account_id': 17540}]","[{'number': 1, 'created': '2015-11-25 22:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/bdd4444a343244b23803f711e9bb3731175efb22', 'message': 'add /etc/neutron/rootwrap.d to support devstack\n\nChange-Id: Ia1fba4b68e7ee341216d57e62176ada969e8e472\n'}, {'number': 2, 'created': '2015-12-11 22:07:55.000000000', 'files': ['etc/neutron/rootwrap.d/networking-sfc.filters'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/f71269baa1c68d050f0ef6ee81bdbc564b2fa7e0', 'message': ""add /etc/neutron/rootwrap.d to support devstack\n\nDevstack fails if the rootwrap.d file is missing.\nWe don't need any rootwrap filters at this time but we need to supply the\nfile in order to allow Devstack to run successfully.\n\nChange-Id: Ia1fba4b68e7ee341216d57e62176ada969e8e472\n""}]",3,250049,f71269baa1c68d050f0ef6ee81bdbc564b2fa7e0,14,9,2,11907,,,0,"add /etc/neutron/rootwrap.d to support devstack

Devstack fails if the rootwrap.d file is missing.
We don't need any rootwrap filters at this time but we need to supply the
file in order to allow Devstack to run successfully.

Change-Id: Ia1fba4b68e7ee341216d57e62176ada969e8e472
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/49/250049/2 && git format-patch -1 --stdout FETCH_HEAD,['etc/neutron/rootwrap.d/networking-sfc.filters'],1,bdd4444a343244b23803f711e9bb3731175efb22,networking-sfc,"# neutron-rootwrap command filters for nodes on which neutron is # expected to control network # # This file should be owned by (and only-writeable by) the root user # format seems to be # cmd-name: filter-name, raw-command, user, args [Filters] ",,9,0
openstack%2Fapi-site~master~I9fe99fa541e52117b43c116d1e0a6095f9b8ca87,openstack/api-site,master,I9fe99fa541e52117b43c116d1e0a6095f9b8ca87,Update Orchestration API v1 to spellcheck and make other changes,ABANDONED,2015-12-12 01:58:01.000000000,2015-12-12 02:06:38.000000000,,[],"[{'number': 1, 'created': '2015-12-12 01:58:01.000000000', 'files': ['api-ref/src/docbkx/ch_orchestration-v1.xml', 'api-ref/src/wadls/orchestration-api/src/v1/wadl/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/43ac401914555d9d9215cf3be14270764ed92ad8', 'message': 'Update Orchestration API v1 to spellcheck and make other changes\n\n- Remove passive voice from api-site\n- Renamed api-ref/src/wadls/orchestration/src/v1/api_samples\n  to .../samples\n- Renamed code samples using this naming convention:\n  <resource>-<action>-request.json or <resource>-<action>-response.json.\n  For example, volume-create-request.json and volume-create-response.json.\n- Removed unused code samples\n- Made method names consistent throughout - use list<resource> for list\n  operations, show<resource> for show operations, and so on.\n\nChange-Id: I9fe99fa541e52117b43c116d1e0a6095f9b8ca87\nPartial-Bug: #1521244\n'}]",0,256898,43ac401914555d9d9215cf3be14270764ed92ad8,2,0,1,2448,,,0,"Update Orchestration API v1 to spellcheck and make other changes

- Remove passive voice from api-site
- Renamed api-ref/src/wadls/orchestration/src/v1/api_samples
  to .../samples
- Renamed code samples using this naming convention:
  <resource>-<action>-request.json or <resource>-<action>-response.json.
  For example, volume-create-request.json and volume-create-response.json.
- Removed unused code samples
- Made method names consistent throughout - use list<resource> for list
  operations, show<resource> for show operations, and so on.

Change-Id: I9fe99fa541e52117b43c116d1e0a6095f9b8ca87
Partial-Bug: #1521244
",git fetch https://review.opendev.org/openstack/api-site refs/changes/98/256898/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/docbkx/ch_orchestration-v1.xml', 'api-ref/src/wadls/orchestration-api/src/v1/wadl/orchestration-api.wadl', 'api-ref/src/wadls/orchestration-api/src/v1/common.ent']",3,43ac401914555d9d9215cf3be14270764ed92ad8,bug/1521244,"<!ENTITY tenant_idTemplateParameter ' <param xmlns=""http://wadl.dev.java.net/2009/02"" name=""tenant_id"" style=""template""> <wadl:doc xmlns=""http://docbook.org/ns/docbook"" xmlns:wadl=""http://wadl.dev.java.net/2009/02"" xml:lang=""EN""> <para> The ID of the tenant. A tenant is also known as an account or project. </para> </wadl:doc> </param>'>",,117,109
openstack%2Fpython-keystoneclient~master~I0e1b377cbe7b351f301e6c5e6eb4fdbfbfc12bcf,openstack/python-keystoneclient,master,I0e1b377cbe7b351f301e6c5e6eb4fdbfbfc12bcf,Delete keystoneclient.middleware,ABANDONED,2015-12-12 01:39:50.000000000,2015-12-12 02:06:01.000000000,,[],"[{'number': 1, 'created': '2015-12-12 01:39:50.000000000', 'files': ['keystoneclient/middleware/memcache_crypt.py', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'keystoneclient/middleware/s3_token.py', 'keystoneclient/middleware/auth_token.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/971510f56902baf69c4215707c473e92ee718a49', 'message': 'Delete keystoneclient.middleware\n\nDelete the keystoneclient.middleware module as it has been deprecated\nand not tested in gate outside of unit tests in a measurable way.\n\nChange-Id: I0e1b377cbe7b351f301e6c5e6eb4fdbfbfc12bcf\nbp: removed-in-mitaka\n'}]",0,256895,971510f56902baf69c4215707c473e92ee718a49,2,0,1,2903,,,0,"Delete keystoneclient.middleware

Delete the keystoneclient.middleware module as it has been deprecated
and not tested in gate outside of unit tests in a measurable way.

Change-Id: I0e1b377cbe7b351f301e6c5e6eb4fdbfbfc12bcf
bp: removed-in-mitaka
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/95/256895/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/middleware/memcache_crypt.py', 'keystoneclient/tests/unit/test_auth_token_middleware.py', 'keystoneclient/tests/unit/test_s3_token_middleware.py', 'keystoneclient/middleware/__init__.py', 'keystoneclient/middleware/s3_token.py', 'keystoneclient/tests/unit/test_memcache_crypt.py', 'keystoneclient/middleware/auth_token.py']",7,971510f56902baf69c4215707c473e92ee718a49,bp/removed-in-mitaka,,"# Copyright 2010-2012 OpenStack Foundation # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. """""" TOKEN-BASED AUTH MIDDLEWARE .. warning:: This module is DEPRECATED. The auth_token middleware has been moved to the `keystonemiddleware repository <http://docs.openstack.org/developer/keystonemiddleware/>`_. This WSGI component: * Verifies that incoming client requests have valid tokens by validating tokens with the auth service. * Rejects unauthenticated requests UNLESS it is in 'delay_auth_decision' mode, which means the final decision is delegated to the downstream WSGI component (usually the OpenStack service) * Collects and forwards identity information based on a valid token such as user name, tenant, etc HEADERS ------- * Headers starting with HTTP\_ is a standard http header * Headers starting with HTTP_X is an extended http header Coming in from initial call from client or customer ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_AUTH_TOKEN The client token being passed in. HTTP_X_STORAGE_TOKEN The client token being passed in (legacy Rackspace use) to support swift/cloud files Used for communication between components ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ WWW-Authenticate HTTP header returned to a user indicating which endpoint to use to retrieve a new token What we add to the request for use by the OpenStack service ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ HTTP_X_IDENTITY_STATUS 'Confirmed' or 'Invalid' The underlying service will only see a value of 'Invalid' if the Middleware is configured to run in 'delay_auth_decision' mode HTTP_X_DOMAIN_ID Identity service managed unique identifier, string. Only present if this is a domain-scoped v3 token. HTTP_X_DOMAIN_NAME Unique domain name, string. Only present if this is a domain-scoped v3 token. HTTP_X_PROJECT_ID Identity service managed unique identifier, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_NAME Project name, unique within owning domain, string. Only present if this is a project-scoped v3 token, or a tenant-scoped v2 token. HTTP_X_PROJECT_DOMAIN_ID Identity service managed unique identifier of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_PROJECT_DOMAIN_NAME Name of owning domain of project, string. Only present if this is a project-scoped v3 token. If this variable is set, this indicates that the PROJECT_NAME can only be assumed to be unique within this domain. HTTP_X_USER_ID Identity-service managed unique identifier, string HTTP_X_USER_NAME User identifier, unique within owning domain, string HTTP_X_USER_DOMAIN_ID Identity service managed unique identifier of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_USER_DOMAIN_NAME Name of owning domain of user, string. If this variable is set, this indicates that the USER_NAME can only be assumed to be unique within this domain. HTTP_X_ROLES Comma delimited list of case-sensitive role names HTTP_X_SERVICE_CATALOG json encoded keystone service catalog (optional). For compatibility reasons this catalog will always be in the V2 catalog format even if it is a v3 token. HTTP_X_TENANT_ID *Deprecated* in favor of HTTP_X_PROJECT_ID Identity service managed unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_TENANT_NAME *Deprecated* in favor of HTTP_X_PROJECT_NAME Project identifier, unique within owning domain, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_NAME HTTP_X_TENANT *Deprecated* in favor of HTTP_X_TENANT_ID and HTTP_X_TENANT_NAME Keystone-assigned unique identifier, string. For v3 tokens, this will be set to the same value as HTTP_X_PROJECT_ID HTTP_X_USER *Deprecated* in favor of HTTP_X_USER_ID and HTTP_X_USER_NAME User name, unique within owning domain, string HTTP_X_ROLE *Deprecated* in favor of HTTP_X_ROLES Will contain the same values as HTTP_X_ROLES. OTHER ENVIRONMENT VARIABLES --------------------------- keystone.token_info Information about the token discovered in the process of validation. This may include extended information returned by the Keystone token validation call, as well as basic information about the tenant and user. """""" import contextlib import datetime import logging import os import stat import tempfile import time import netaddr from oslo_config import cfg from oslo_serialization import jsonutils from oslo_utils import timeutils import requests import six from six.moves import urllib from keystoneclient import access from keystoneclient.common import cms from keystoneclient import exceptions from keystoneclient.middleware import memcache_crypt from keystoneclient.openstack.common import memorycache from keystoneclient import utils # alternative middleware configuration in the main application's # configuration file e.g. in nova.conf # [keystone_authtoken] # auth_host = 127.0.0.1 # auth_port = 35357 # auth_protocol = http # admin_tenant_name = admin # admin_user = admin # admin_password = badpassword # when deploy Keystone auth_token middleware with Swift, user may elect # to use Swift memcache instead of the local Keystone memcache. Swift memcache # is passed in from the request environment and its identified by the # 'swift.cache' key. However it could be different, depending on deployment. # To use Swift memcache, you must set the 'cache' option to the environment # key where the Swift cache object is stored. # NOTE(jamielennox): A number of options below are deprecated however are left # in the list and only mentioned as deprecated in the help string. This is # because we have to provide the same deprecation functionality for arguments # passed in via the conf in __init__ (from paste) and there is no way to test # that the default value was set or not in CONF. # Also if we were to remove the options from the CONF list (as typical CONF # deprecation works) then other projects will not be able to override the # options via CONF. opts = [ cfg.StrOpt('auth_admin_prefix', default='', help='Prefix to prepend at the beginning of the path. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_host', default='127.0.0.1', help='Host providing the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.IntOpt('auth_port', default=35357, help='Port of the admin Identity API endpoint. ' 'Deprecated, use identity_uri.'), cfg.StrOpt('auth_protocol', default='https', help='Protocol of the admin Identity API endpoint ' '(http or https). Deprecated, use identity_uri.'), cfg.StrOpt('auth_uri', default=None, # FIXME(dolph): should be default='http://127.0.0.1:5000/v2.0/', # or (depending on client support) an unversioned, publicly # accessible identity endpoint (see bug 1207517) help='Complete public Identity API endpoint'), cfg.StrOpt('identity_uri', default=None, help='Complete admin Identity API endpoint. This should ' 'specify the unversioned root endpoint ' 'e.g. https://localhost:35357/'), cfg.StrOpt('auth_version', default=None, help='API version of the admin Identity API endpoint'), cfg.BoolOpt('delay_auth_decision', default=False, help='Do not handle authorization requests within the' ' middleware, but delegate the authorization decision to' ' downstream WSGI components'), cfg.BoolOpt('http_connect_timeout', default=None, help='Request timeout value for communicating with Identity' ' API server.'), cfg.IntOpt('http_request_max_retries', default=3, help='How many times are we trying to reconnect when' ' communicating with Identity API Server.'), cfg.StrOpt('admin_token', secret=True, help='This option is deprecated and may be removed in a future' ' release. Single shared secret with the Keystone configuration' ' used for bootstrapping a Keystone installation, or otherwise' ' bypassing the normal authentication process. This option' ' should not be used, use `admin_user` and `admin_password`' ' instead.'), cfg.StrOpt('admin_user', help='Keystone account username'), cfg.StrOpt('admin_password', secret=True, help='Keystone account password'), cfg.StrOpt('admin_tenant_name', default='admin', help='Keystone service account tenant name to validate' ' user tokens'), cfg.StrOpt('cache', default=None, help='Env key for the swift cache'), cfg.StrOpt('certfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('keyfile', help='Required if Keystone server requires client certificate'), cfg.StrOpt('cafile', default=None, help='A PEM encoded Certificate Authority to use when ' 'verifying HTTPs connections. Defaults to system CAs.'), cfg.BoolOpt('insecure', default=False, help='Verify HTTPS connections.'), cfg.StrOpt('signing_dir', help='Directory used to cache files related to PKI tokens'), cfg.ListOpt('memcached_servers', deprecated_name='memcache_servers', help='Optionally specify a list of memcached server(s) to' ' use for caching. If left undefined, tokens will instead be' ' cached in-process.'), cfg.IntOpt('token_cache_time', default=300, help='In order to prevent excessive effort spent validating' ' tokens, the middleware caches previously-seen tokens for a' ' configurable duration (in seconds). Set to -1 to disable' ' caching completely.'), cfg.IntOpt('revocation_cache_time', default=10, help='Determines the frequency at which the list of revoked' ' tokens is retrieved from the Identity service (in seconds). A' ' high number of revocation events combined with a low cache' ' duration may significantly reduce performance.'), cfg.StrOpt('memcache_security_strategy', default=None, help='(optional) if defined, indicate whether token data' ' should be authenticated or authenticated and encrypted.' ' Acceptable values are MAC or ENCRYPT. If MAC, token data is' ' authenticated (with HMAC) in the cache. If ENCRYPT, token' ' data is encrypted and authenticated in the cache. If the' ' value is not one of these options or empty, auth_token will' ' raise an exception on initialization.'), cfg.StrOpt('memcache_secret_key', default=None, secret=True, help='(optional, mandatory if memcache_security_strategy is' ' defined) this string is used for key derivation.'), cfg.BoolOpt('include_service_catalog', default=True, help='(optional) indicate whether to set the X-Service-Catalog' ' header. If False, middleware will not ask for service' ' catalog on token validation and will not set the' ' X-Service-Catalog header.'), cfg.StrOpt('enforce_token_bind', default='permissive', help='Used to control the use and type of token binding. Can' ' be set to: ""disabled"" to not check token binding.' ' ""permissive"" (default) to validate binding information if the' ' bind type is of a form known to the server and ignore it if' ' not. ""strict"" like ""permissive"" but if the bind type is' ' unknown the token will be rejected. ""required"" any form of' ' token binding is needed to be allowed. Finally the name of a' ' binding method that must be present in tokens.'), cfg.BoolOpt('check_revocations_for_cached', default=False, help='If true, the revocation list will be checked for cached' ' tokens. This requires that PKI tokens are configured on the' ' Keystone server.'), cfg.ListOpt('hash_algorithms', default=['md5'], help='Hash algorithms to use for hashing PKI tokens. This may' ' be a single algorithm or multiple. The algorithms are those' ' supported by Python standard hashlib.new(). The hashes will' ' be tried in the order given, so put the preferred one first' ' for performance. The result of the first hash will be stored' ' in the cache. This will typically be set to multiple values' ' only while migrating from a less secure algorithm to a more' ' secure one. Once all the old tokens are expired this option' ' should be set to a single value for better performance.'), ] CONF = cfg.CONF CONF.register_opts(opts, group='keystone_authtoken') LIST_OF_VERSIONS_TO_ATTEMPT = ['v2.0', 'v3.0'] CACHE_KEY_TEMPLATE = 'tokens/%s' class BIND_MODE(object): DISABLED = 'disabled' PERMISSIVE = 'permissive' STRICT = 'strict' REQUIRED = 'required' KERBEROS = 'kerberos' def will_expire_soon(expiry): """"""Determines if expiration is about to occur. :param expiry: a datetime of the expected expiration :returns: boolean : true if expiration is within 30 seconds """""" soon = (timeutils.utcnow() + datetime.timedelta(seconds=30)) return expiry < soon def _token_is_v2(token_info): return ('access' in token_info) def _token_is_v3(token_info): return ('token' in token_info) def confirm_token_not_expired(data): if not data: raise InvalidUserToken('Token authorization failed') if _token_is_v2(data): timestamp = data['access']['token']['expires'] elif _token_is_v3(data): timestamp = data['token']['expires_at'] else: raise InvalidUserToken('Token authorization failed') expires = timeutils.parse_isotime(timestamp) expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow >= expires: raise InvalidUserToken('Token authorization failed') return utils.isotime(at=expires, subsecond=True) def _v3_to_v2_catalog(catalog): """"""Convert a catalog to v2 format. X_SERVICE_CATALOG must be specified in v2 format. If you get a token that is in v3 convert it. """""" v2_services = [] for v3_service in catalog: # first copy over the entries we allow for the service v2_service = {'type': v3_service['type']} try: v2_service['name'] = v3_service['name'] except KeyError: pass # now convert the endpoints. Because in v3 we specify region per # URL not per group we have to collect all the entries of the same # region together before adding it to the new service. regions = {} for v3_endpoint in v3_service.get('endpoints', []): region_name = v3_endpoint.get('region') try: region = regions[region_name] except KeyError: region = {'region': region_name} if region_name else {} regions[region_name] = region interface_name = v3_endpoint['interface'].lower() + 'URL' region[interface_name] = v3_endpoint['url'] v2_service['endpoints'] = list(regions.values()) v2_services.append(v2_service) return v2_services def safe_quote(s): """"""URL-encode strings that are not already URL-encoded."""""" return urllib.parse.quote(s) if s == urllib.parse.unquote(s) else s def _conf_values_type_convert(conf): """"""Convert conf values into correct type."""""" if not conf: return {} _opts = {} opt_types = dict((o.dest, getattr(o, 'type', str)) for o in opts) for k, v in six.iteritems(conf): try: if v is None: _opts[k] = v else: _opts[k] = opt_types[k](v) except KeyError: _opts[k] = v except ValueError as e: raise ConfigurationError( 'Unable to convert the value of %s option into correct ' 'type: %s' % (k, e)) return _opts class InvalidUserToken(Exception): pass class ServiceError(Exception): pass class ConfigurationError(Exception): pass class NetworkError(Exception): pass class MiniResp(object): def __init__(self, error_message, env, headers=[]): # The HEAD method is unique: it must never return a body, even if # it reports an error (RFC-2616 clause 9.4). We relieve callers # from varying the error responses depending on the method. if env['REQUEST_METHOD'] == 'HEAD': self.body = [''] else: self.body = [error_message] self.headers = list(headers) self.headers.append(('Content-type', 'text/plain')) class AuthProtocol(object): """"""Auth Middleware that handles authenticating client calls."""""" def __init__(self, app, conf): self.LOG = logging.getLogger(conf.get('log_name', __name__)) self.LOG.info('Starting keystone auth_token middleware') self.LOG.warning( 'This middleware module is deprecated as of v0.10.0 in favor of ' 'keystonemiddleware.auth_token - please update your WSGI pipeline ' 'to reference the new middleware package.') # NOTE(wanghong): If options are set in paste file, all the option # values passed into conf are string type. So, we should convert the # conf value into correct type. self.conf = _conf_values_type_convert(conf) self.app = app # delay_auth_decision means we still allow unauthenticated requests # through and we let the downstream service make the final decision self.delay_auth_decision = (self._conf_get('delay_auth_decision') in (True, 'true', 't', '1', 'on', 'yes', 'y')) # where to find the auth service (we use this to validate tokens) self.identity_uri = self._conf_get('identity_uri') self.auth_uri = self._conf_get('auth_uri') # NOTE(jamielennox): it does appear here that our defaults arguments # are backwards. We need to do it this way so that we can handle the # same deprecation strategy for CONF and the conf variable. if not self.identity_uri: self.LOG.warning('Configuring admin URI using auth fragments. ' 'This is deprecated, use \'identity_uri\'' ' instead.') auth_host = self._conf_get('auth_host') auth_port = int(self._conf_get('auth_port')) auth_protocol = self._conf_get('auth_protocol') auth_admin_prefix = self._conf_get('auth_admin_prefix') if netaddr.valid_ipv6(auth_host): # Note(dzyu) it is an IPv6 address, so it needs to be wrapped # with '[]' to generate a valid IPv6 URL, based on # http://www.ietf.org/rfc/rfc2732.txt auth_host = '[%s]' % auth_host self.identity_uri = '%s://%s:%s' % (auth_protocol, auth_host, auth_port) if auth_admin_prefix: self.identity_uri = '%s/%s' % (self.identity_uri, auth_admin_prefix.strip('/')) else: self.identity_uri = self.identity_uri.rstrip('/') if self.auth_uri is None: self.LOG.warning( 'Configuring auth_uri to point to the public identity ' 'endpoint is required; clients may not be able to ' 'authenticate against an admin endpoint') # FIXME(dolph): drop support for this fallback behavior as # documented in bug 1207517. # NOTE(jamielennox): we urljoin '/' to get just the base URI as # this is the original behaviour. self.auth_uri = urllib.parse.urljoin(self.identity_uri, '/') self.auth_uri = self.auth_uri.rstrip('/') # SSL self.cert_file = self._conf_get('certfile') self.key_file = self._conf_get('keyfile') self.ssl_ca_file = self._conf_get('cafile') self.ssl_insecure = self._conf_get('insecure') # signing self.signing_dirname = self._conf_get('signing_dir') if self.signing_dirname is None: self.signing_dirname = tempfile.mkdtemp(prefix='keystone-signing-') self.LOG.info('Using %s as cache directory for signing certificate', self.signing_dirname) self.verify_signing_dir() val = '%s/signing_cert.pem' % self.signing_dirname self.signing_cert_file_name = val val = '%s/cacert.pem' % self.signing_dirname self.signing_ca_file_name = val val = '%s/revoked.pem' % self.signing_dirname self.revoked_file_name = val # Credentials used to verify this component with the Auth service since # validating tokens is a privileged call self.admin_token = self._conf_get('admin_token') if self.admin_token: self.LOG.warning( ""The admin_token option in the auth_token middleware is "" ""deprecated and should not be used. The admin_user and "" ""admin_password options should be used instead. The "" ""admin_token option may be removed in a future release."") self.admin_token_expiry = None self.admin_user = self._conf_get('admin_user') self.admin_password = self._conf_get('admin_password') self.admin_tenant_name = self._conf_get('admin_tenant_name') memcache_security_strategy = ( self._conf_get('memcache_security_strategy')) self._token_cache = TokenCache( self.LOG, cache_time=int(self._conf_get('token_cache_time')), hash_algorithms=self._conf_get('hash_algorithms'), env_cache_name=self._conf_get('cache'), memcached_servers=self._conf_get('memcached_servers'), memcache_security_strategy=memcache_security_strategy, memcache_secret_key=self._conf_get('memcache_secret_key')) self._token_revocation_list = None self._token_revocation_list_fetched_time = None self.token_revocation_list_cache_timeout = datetime.timedelta( seconds=self._conf_get('revocation_cache_time')) http_connect_timeout_cfg = self._conf_get('http_connect_timeout') self.http_connect_timeout = (http_connect_timeout_cfg and int(http_connect_timeout_cfg)) self.auth_version = None self.http_request_max_retries = ( self._conf_get('http_request_max_retries')) self.include_service_catalog = self._conf_get( 'include_service_catalog') self.check_revocations_for_cached = self._conf_get( 'check_revocations_for_cached') def _conf_get(self, name): # try config from paste-deploy first if name in self.conf: return self.conf[name] else: return CONF.keystone_authtoken[name] def _choose_api_version(self): """"""Determine the api version that we should use."""""" # If the configuration specifies an auth_version we will just # assume that is correct and use it. We could, of course, check # that this version is supported by the server, but in case # there are some problems in the field, we want as little code # as possible in the way of letting auth_token talk to the # server. if self._conf_get('auth_version'): version_to_use = self._conf_get('auth_version') self.LOG.info('Auth Token proceeding with requested %s apis', version_to_use) else: version_to_use = None versions_supported_by_server = self._get_supported_versions() if versions_supported_by_server: for version in LIST_OF_VERSIONS_TO_ATTEMPT: if version in versions_supported_by_server: version_to_use = version break if version_to_use: self.LOG.info('Auth Token confirmed use of %s apis', version_to_use) else: self.LOG.error( 'Attempted versions [%s] not in list supported by ' 'server [%s]', ', '.join(LIST_OF_VERSIONS_TO_ATTEMPT), ', '.join(versions_supported_by_server)) raise ServiceError('No compatible apis supported by server') return version_to_use def _get_supported_versions(self): versions = [] response, data = self._json_request('GET', '/') if response.status_code == 501: self.LOG.warning('Old keystone installation found...assuming v2.0') versions.append('v2.0') elif response.status_code != 300: self.LOG.error('Unable to get version info from keystone: %s', response.status_code) raise ServiceError('Unable to get version info from keystone') else: try: for version in data['versions']['values']: versions.append(version['id']) except KeyError: self.LOG.error( 'Invalid version response format from server') raise ServiceError('Unable to parse version response ' 'from keystone') self.LOG.debug('Server reports support for api versions: %s', ', '.join(versions)) return versions def __call__(self, env, start_response): """"""Handle incoming request. Authenticate send downstream on success. Reject request if we can't authenticate. """""" self.LOG.debug('Authenticating user token') self._token_cache.initialize(env) try: self._remove_auth_headers(env) user_token = self._get_user_token_from_header(env) token_info = self._validate_user_token(user_token, env) env['keystone.token_info'] = token_info user_headers = self._build_user_headers(token_info) self._add_headers(env, user_headers) return self.app(env, start_response) except InvalidUserToken: if self.delay_auth_decision: self.LOG.info( 'Invalid user token - deferring reject downstream') self._add_headers(env, {'X-Identity-Status': 'Invalid'}) return self.app(env, start_response) else: self.LOG.info('Invalid user token - rejecting request') return self._reject_request(env, start_response) except ServiceError as e: self.LOG.critical('Unable to obtain admin token: %s', e) resp = MiniResp('Service unavailable', env) start_response('503 Service Unavailable', resp.headers) return resp.body def _remove_auth_headers(self, env): """"""Remove headers so a user can't fake authentication. :param env: wsgi request environment """""" auth_headers = ( 'X-Identity-Status', 'X-Domain-Id', 'X-Domain-Name', 'X-Project-Id', 'X-Project-Name', 'X-Project-Domain-Id', 'X-Project-Domain-Name', 'X-User-Id', 'X-User-Name', 'X-User-Domain-Id', 'X-User-Domain-Name', 'X-Roles', 'X-Service-Catalog', # Deprecated 'X-User', 'X-Tenant-Id', 'X-Tenant-Name', 'X-Tenant', 'X-Role', ) self.LOG.debug('Removing headers from request environment: %s', ','.join(auth_headers)) self._remove_headers(env, auth_headers) def _get_user_token_from_header(self, env): """"""Get token id from request. :param env: wsgi request environment :return token id :raises InvalidUserToken if no token is provided in request """""" token = self._get_header(env, 'X-Auth-Token', self._get_header(env, 'X-Storage-Token')) if token: return token else: if not self.delay_auth_decision: self.LOG.warning('Unable to find authentication token' ' in headers') self.LOG.debug('Headers: %s', env) raise InvalidUserToken('Unable to find token in headers') def _reject_request(self, env, start_response): """"""Redirect client to auth server. :param env: wsgi request environment :param start_response: wsgi response callback :returns HTTPUnauthorized http response """""" headers = [('WWW-Authenticate', 'Keystone uri=\'%s\'' % self.auth_uri)] resp = MiniResp('Authentication required', env, headers) start_response('401 Unauthorized', resp.headers) return resp.body def get_admin_token(self): """"""Return admin token, possibly fetching a new one. if self.admin_token_expiry is set from fetching an admin token, check it for expiration, and request a new token is the existing token is about to expire. :return admin token id :raise ServiceError when unable to retrieve token from keystone """""" if self.admin_token_expiry: if will_expire_soon(self.admin_token_expiry): self.admin_token = None if not self.admin_token: (self.admin_token, self.admin_token_expiry) = self._request_admin_token() return self.admin_token def _http_request(self, method, path, **kwargs): """"""HTTP request helper used to make unspecified content type requests. :param method: http method :param path: relative request url :return (http response object, response body) :raise ServerError when unable to communicate with keystone """""" url = '%s/%s' % (self.identity_uri, path.lstrip('/')) kwargs.setdefault('timeout', self.http_connect_timeout) if self.cert_file and self.key_file: kwargs['cert'] = (self.cert_file, self.key_file) elif self.cert_file or self.key_file: self.LOG.warning('Cannot use only a cert or key file. ' 'Please provide both. Ignoring.') kwargs['verify'] = self.ssl_ca_file or True if self.ssl_insecure: kwargs['verify'] = False RETRIES = self.http_request_max_retries retry = 0 while True: try: response = requests.request(method, url, **kwargs) break except Exception as e: if retry >= RETRIES: self.LOG.error('HTTP connection exception: %s', e) raise NetworkError('Unable to communicate with keystone') # NOTE(vish): sleep 0.5, 1, 2 self.LOG.warning('Retrying on HTTP connection exception: %s', e) time.sleep(2.0 ** retry / 2) retry += 1 return response def _json_request(self, method, path, body=None, additional_headers=None): """"""HTTP request helper used to make json requests. :param method: http method :param path: relative request url :param body: dict to encode to json as request body. Optional. :param additional_headers: dict of additional headers to send with http request. Optional. :return (http response object, response body parsed as json) :raise ServerError when unable to communicate with keystone """""" kwargs = { 'headers': { 'Content-type': 'application/json', 'Accept': 'application/json', }, } if additional_headers: kwargs['headers'].update(additional_headers) if body: kwargs['data'] = jsonutils.dumps(body) response = self._http_request(method, path, **kwargs) try: data = jsonutils.loads(response.text) except ValueError: self.LOG.debug('Keystone did not return json-encoded body') data = {} return response, data def _request_admin_token(self): """"""Retrieve new token as admin user from keystone. :return token id upon success :raises ServerError when unable to communicate with keystone Irrespective of the auth version we are going to use for the user token, for simplicity we always use a v2 admin token to validate the user token. """""" params = { 'auth': { 'passwordCredentials': { 'username': self.admin_user, 'password': self.admin_password, }, 'tenantName': self.admin_tenant_name, } } response, data = self._json_request('POST', '/v2.0/tokens', body=params) try: token = data['access']['token']['id'] expiry = data['access']['token']['expires'] if not (token and expiry): raise AssertionError('invalid token or expire') datetime_expiry = timeutils.parse_isotime(expiry) return (token, timeutils.normalize_time(datetime_expiry)) except (AssertionError, KeyError): self.LOG.warning( 'Unexpected response from keystone service: %s', data) raise ServiceError('invalid json response') except (ValueError): data['access']['token']['id'] = '<SANITIZED>' self.LOG.warning( 'Unable to parse expiration time from token: %s', data) raise ServiceError('invalid json response') def _validate_user_token(self, user_token, env, retry=True): """"""Authenticate user token :param user_token: user's token id :param retry: Ignored, as it is not longer relevant :return uncrypted body of the token if the token is valid :raise InvalidUserToken if token is rejected :no longer raises ServiceError since it no longer makes RPC """""" token_id = None try: token_ids, cached = self._token_cache.get(user_token) token_id = token_ids[0] if cached: data = cached if self.check_revocations_for_cached: # A token stored in Memcached might have been revoked # regardless of initial mechanism used to validate it, # and needs to be checked. for tid in token_ids: is_revoked = self._is_token_id_in_revoked_list(tid) if is_revoked: self.LOG.debug( 'Token is marked as having been revoked') raise InvalidUserToken( 'Token authorization failed') elif cms.is_pkiz(user_token): verified = self.verify_pkiz_token(user_token, token_ids) data = jsonutils.loads(verified) elif cms.is_asn1_token(user_token): verified = self.verify_signed_token(user_token, token_ids) data = jsonutils.loads(verified) else: data = self.verify_uuid_token(user_token, retry) expires = confirm_token_not_expired(data) self._confirm_token_bind(data, env) self._token_cache.store(token_id, data, expires) return data except NetworkError: self.LOG.debug('Token validation failure.', exc_info=True) self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') except Exception: self.LOG.debug('Token validation failure.', exc_info=True) if token_id: self._token_cache.store_invalid(token_id) self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') def _build_user_headers(self, token_info): """"""Convert token object into headers. Build headers that represent authenticated user - see main doc info at start of file for details of headers to be defined. :param token_info: token object returned by keystone on authentication :raise InvalidUserToken when unable to parse token object """""" auth_ref = access.AccessInfo.factory(body=token_info) roles = ','.join(auth_ref.role_names) if _token_is_v2(token_info) and not auth_ref.project_id: raise InvalidUserToken('Unable to determine tenancy.') rval = { 'X-Identity-Status': 'Confirmed', 'X-Domain-Id': auth_ref.domain_id, 'X-Domain-Name': auth_ref.domain_name, 'X-Project-Id': auth_ref.project_id, 'X-Project-Name': auth_ref.project_name, 'X-Project-Domain-Id': auth_ref.project_domain_id, 'X-Project-Domain-Name': auth_ref.project_domain_name, 'X-User-Id': auth_ref.user_id, 'X-User-Name': auth_ref.username, 'X-User-Domain-Id': auth_ref.user_domain_id, 'X-User-Domain-Name': auth_ref.user_domain_name, 'X-Roles': roles, # Deprecated 'X-User': auth_ref.username, 'X-Tenant-Id': auth_ref.project_id, 'X-Tenant-Name': auth_ref.project_name, 'X-Tenant': auth_ref.project_name, 'X-Role': roles, } self.LOG.debug('Received request from user: %s with project_id : %s' ' and roles: %s ', auth_ref.user_id, auth_ref.project_id, roles) if self.include_service_catalog and auth_ref.has_service_catalog(): catalog = auth_ref.service_catalog.get_data() if _token_is_v3(token_info): catalog = _v3_to_v2_catalog(catalog) rval['X-Service-Catalog'] = jsonutils.dumps(catalog) return rval def _header_to_env_var(self, key): """"""Convert header to wsgi env variable. :param key: http header name (ex. 'X-Auth-Token') :return wsgi env variable name (ex. 'HTTP_X_AUTH_TOKEN') """""" return 'HTTP_%s' % key.replace('-', '_').upper() def _add_headers(self, env, headers): """"""Add http headers to environment."""""" for (k, v) in six.iteritems(headers): env_key = self._header_to_env_var(k) env[env_key] = v def _remove_headers(self, env, keys): """"""Remove http headers from environment."""""" for k in keys: env_key = self._header_to_env_var(k) try: del env[env_key] except KeyError: pass def _get_header(self, env, key, default=None): """"""Get http header from environment."""""" env_key = self._header_to_env_var(key) return env.get(env_key, default) def _invalid_user_token(self, msg=False): # NOTE(jamielennox): use False as the default so that None is valid if msg is False: msg = 'Token authorization failed' raise InvalidUserToken(msg) def _confirm_token_bind(self, data, env): bind_mode = self._conf_get('enforce_token_bind') if bind_mode == BIND_MODE.DISABLED: return try: if _token_is_v2(data): bind = data['access']['token']['bind'] elif _token_is_v3(data): bind = data['token']['bind'] else: self._invalid_user_token() except KeyError: bind = {} # permissive and strict modes don't require there to be a bind permissive = bind_mode in (BIND_MODE.PERMISSIVE, BIND_MODE.STRICT) if not bind: if permissive: # no bind provided and none required return else: self.LOG.info('No bind information present in token.') self._invalid_user_token() # get the named mode if bind_mode is not one of the predefined if permissive or bind_mode == BIND_MODE.REQUIRED: name = None else: name = bind_mode if name and name not in bind: self.LOG.info('Named bind mode %s not in bind information', name) self._invalid_user_token() for bind_type, identifier in six.iteritems(bind): if bind_type == BIND_MODE.KERBEROS: if not env.get('AUTH_TYPE', '').lower() == 'negotiate': self.LOG.info('Kerberos credentials required and ' 'not present.') self._invalid_user_token() if not env.get('REMOTE_USER') == identifier: self.LOG.info('Kerberos credentials do not match ' 'those in bind.') self._invalid_user_token() self.LOG.debug('Kerberos bind authentication successful.') elif bind_mode == BIND_MODE.PERMISSIVE: self.LOG.debug('Ignoring Unknown bind for permissive mode: ' '%(bind_type)s: %(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) else: self.LOG.info('Couldn`t verify unknown bind: %(bind_type)s: ' '%(identifier)s.', {'bind_type': bind_type, 'identifier': identifier}) self._invalid_user_token() def verify_uuid_token(self, user_token, retry=True): """"""Authenticate user token with keystone. :param user_token: user's token id :param retry: flag that forces the middleware to retry user authentication when an indeterminate response is received. Optional. :returns: token object received from keystone on success :raise InvalidUserToken: if token is rejected :raise ServiceError: if unable to authenticate token """""" # Determine the highest api version we can use. if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': headers = {'X-Auth-Token': self.get_admin_token(), 'X-Subject-Token': safe_quote(user_token)} path = '/v3/auth/tokens' if not self.include_service_catalog: # NOTE(gyee): only v3 API support this option path = path + '?nocatalog' response, data = self._json_request( 'GET', path, additional_headers=headers) else: headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request( 'GET', '/v2.0/tokens/%s' % safe_quote(user_token), additional_headers=headers) if response.status_code == 200: return data if response.status_code == 404: self.LOG.warning('Authorization failed for token') raise InvalidUserToken('Token authorization failed') if response.status_code == 401: self.LOG.info( 'Keystone rejected admin token, resetting') self.admin_token = None else: self.LOG.error('Bad response code while validating token: %s', response.status_code) if retry: self.LOG.info('Retrying validation') return self.verify_uuid_token(user_token, False) else: self.LOG.warning('Invalid user token. Keystone response: %s', data) raise InvalidUserToken() def is_signed_token_revoked(self, token_ids): """"""Indicate whether the token appears in the revocation list."""""" for token_id in token_ids: if self._is_token_id_in_revoked_list(token_id): self.LOG.debug('Token is marked as having been revoked') return True return False def _is_token_id_in_revoked_list(self, token_id): """"""Indicate whether the token_id appears in the revocation list."""""" revocation_list = self.token_revocation_list revoked_tokens = revocation_list.get('revoked', None) if not revoked_tokens: return False revoked_ids = (x['id'] for x in revoked_tokens) return token_id in revoked_ids def cms_verify(self, data, inform=cms.PKI_ASN1_FORM): """"""Verifies the signature of the provided data's IAW CMS syntax. If either of the certificate files might be missing, fetch them and retry. """""" def verify(): try: return cms.cms_verify(data, self.signing_cert_file_name, self.signing_ca_file_name, inform=inform).decode('utf-8') except cms.subprocess.CalledProcessError as err: self.LOG.warning('Verify error: %s', err) raise try: return verify() except exceptions.CertificateConfigError: # the certs might be missing; unconditionally fetch to avoid racing self.fetch_signing_cert() self.fetch_ca_cert() try: # retry with certs in place return verify() except exceptions.CertificateConfigError as err: # if this is still occurring, something else is wrong and we # need err.output to identify the problem self.LOG.error('CMS Verify output: %s', err.output) raise def verify_signed_token(self, signed_text, token_ids): """"""Check that the token is unrevoked and has a valid signature."""""" if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') formatted = cms.token_to_cms(signed_text) verified = self.cms_verify(formatted) return verified def verify_pkiz_token(self, signed_text, token_ids): if self.is_signed_token_revoked(token_ids): raise InvalidUserToken('Token has been revoked') try: uncompressed = cms.pkiz_uncompress(signed_text) verified = self.cms_verify(uncompressed, inform=cms.PKIZ_CMS_FORM) return verified # TypeError If the signed_text is not zlib compressed except TypeError: raise InvalidUserToken(signed_text) def verify_signing_dir(self): if os.path.exists(self.signing_dirname): if not os.access(self.signing_dirname, os.W_OK): raise ConfigurationError( 'unable to access signing_dir %s' % self.signing_dirname) uid = os.getuid() if os.stat(self.signing_dirname).st_uid != uid: self.LOG.warning( 'signing_dir is not owned by %s', uid) current_mode = stat.S_IMODE(os.stat(self.signing_dirname).st_mode) if current_mode != stat.S_IRWXU: self.LOG.warning( 'signing_dir mode is %s instead of %s', oct(current_mode), oct(stat.S_IRWXU)) else: os.makedirs(self.signing_dirname, stat.S_IRWXU) @property def token_revocation_list_fetched_time(self): if not self._token_revocation_list_fetched_time: # If the fetched list has been written to disk, use its # modification time. if os.path.exists(self.revoked_file_name): mtime = os.path.getmtime(self.revoked_file_name) fetched_time = datetime.datetime.utcfromtimestamp(mtime) # Otherwise the list will need to be fetched. else: fetched_time = datetime.datetime.min self._token_revocation_list_fetched_time = fetched_time return self._token_revocation_list_fetched_time @token_revocation_list_fetched_time.setter def token_revocation_list_fetched_time(self, value): self._token_revocation_list_fetched_time = value @property def token_revocation_list(self): timeout = (self.token_revocation_list_fetched_time + self.token_revocation_list_cache_timeout) list_is_current = timeutils.utcnow() < timeout if list_is_current: # Load the list from disk if required if not self._token_revocation_list: open_kwargs = {'encoding': 'utf-8'} if six.PY3 else {} with open(self.revoked_file_name, 'r', **open_kwargs) as f: self._token_revocation_list = jsonutils.loads(f.read()) else: self.token_revocation_list = self.fetch_revocation_list() return self._token_revocation_list def _atomic_write_to_signing_dir(self, file_name, value): # In Python2, encoding is slow so the following check avoids it if it # is not absolutely necessary. if isinstance(value, six.text_type): value = value.encode('utf-8') def _atomic_write(destination, data): with tempfile.NamedTemporaryFile(dir=self.signing_dirname, delete=False) as f: f.write(data) os.rename(f.name, destination) try: _atomic_write(file_name, value) except (OSError, IOError): self.verify_signing_dir() _atomic_write(file_name, value) @token_revocation_list.setter def token_revocation_list(self, value): """"""Save a revocation list to memory and to disk. :param value: A json-encoded revocation list """""" self._token_revocation_list = jsonutils.loads(value) self.token_revocation_list_fetched_time = timeutils.utcnow() self._atomic_write_to_signing_dir(self.revoked_file_name, value) def fetch_revocation_list(self, retry=True): headers = {'X-Auth-Token': self.get_admin_token()} response, data = self._json_request('GET', '/v2.0/tokens/revoked', additional_headers=headers) if response.status_code == 401: if retry: self.LOG.info( 'Keystone rejected admin token, resetting admin token') self.admin_token = None return self.fetch_revocation_list(retry=False) if response.status_code != 200: raise ServiceError('Unable to fetch token revocation list.') if 'signed' not in data: raise ServiceError('Revocation list improperly formatted.') return self.cms_verify(data['signed']) def _fetch_cert_file(self, cert_file_name, cert_type): if not self.auth_version: self.auth_version = self._choose_api_version() if self.auth_version == 'v3.0': if cert_type == 'signing': cert_type = 'certificates' path = '/v3/OS-SIMPLE-CERT/' + cert_type else: path = '/v2.0/certificates/' + cert_type response = self._http_request('GET', path) if response.status_code != 200: raise exceptions.CertificateConfigError(response.text) self._atomic_write_to_signing_dir(cert_file_name, response.text) def fetch_signing_cert(self): self._fetch_cert_file(self.signing_cert_file_name, 'signing') def fetch_ca_cert(self): self._fetch_cert_file(self.signing_ca_file_name, 'ca') class CachePool(list): """"""A lazy pool of cache references."""""" def __init__(self, cache, memcached_servers): self._environment_cache = cache self._memcached_servers = memcached_servers @contextlib.contextmanager def reserve(self): """"""Context manager to manage a pooled cache reference."""""" if self._environment_cache is not None: # skip pooling and just use the cache from the upstream filter yield self._environment_cache return # otherwise the context manager will continue! try: c = self.pop() except IndexError: # the pool is empty, so we need to create a new client c = memorycache.get_client(self._memcached_servers) try: yield c finally: self.append(c) class TokenCache(object): """"""Encapsulates the auth_token token cache functionality. auth_token caches tokens that it's seen so that when a token is re-used the middleware doesn't have to do a more expensive operation (like going to the identity server) to validate the token. initialize() must be called before calling the other methods. Store a valid token in the cache using store(); mark a token as invalid in the cache using store_invalid(). Check if a token is in the cache and retrieve it using get(). """""" _INVALID_INDICATOR = 'invalid' def __init__(self, log, cache_time=None, hash_algorithms=None, env_cache_name=None, memcached_servers=None, memcache_security_strategy=None, memcache_secret_key=None): self.LOG = log self._cache_time = cache_time self._hash_algorithms = hash_algorithms self._env_cache_name = env_cache_name self._memcached_servers = memcached_servers # memcache value treatment, ENCRYPT or MAC self._memcache_security_strategy = memcache_security_strategy if self._memcache_security_strategy is not None: self._memcache_security_strategy = ( self._memcache_security_strategy.upper()) self._memcache_secret_key = memcache_secret_key self._cache_pool = None self._initialized = False self._assert_valid_memcache_protection_config() def initialize(self, env): if self._initialized: return self._cache_pool = CachePool(env.get(self._env_cache_name), self._memcached_servers) self._initialized = True def get(self, user_token): """"""Check if the token is cached already. Returns a tuple. The first element is a list of token IDs, where the first one is the preferred hash. The second element is the token data from the cache if the token was cached, otherwise ``None``. :raises InvalidUserToken: if the token is invalid """""" if cms.is_asn1_token(user_token) or cms.is_pkiz(user_token): # user_token is a PKI token that's not hashed. token_hashes = list(cms.cms_hash_token(user_token, mode=algo) for algo in self._hash_algorithms) for token_hash in token_hashes: cached = self._cache_get(token_hash) if cached: return (token_hashes, cached) # The token wasn't found using any hash algorithm. return (token_hashes, None) # user_token is either a UUID token or a hashed PKI token. token_id = user_token cached = self._cache_get(token_id) return ([token_id], cached) def store(self, token_id, data, expires): """"""Put token data into the cache. Stores the parsed expire date in cache allowing quick check of token freshness on retrieval. """""" self.LOG.debug('Storing token in cache') self._cache_store(token_id, (data, expires)) def store_invalid(self, token_id): """"""Store invalid token in cache."""""" self.LOG.debug('Marking token as unauthorized in cache') self._cache_store(token_id, self._INVALID_INDICATOR) def _assert_valid_memcache_protection_config(self): if self._memcache_security_strategy: if self._memcache_security_strategy not in ('MAC', 'ENCRYPT'): raise ConfigurationError('memcache_security_strategy must be ' 'ENCRYPT or MAC') if not self._memcache_secret_key: raise ConfigurationError('memcache_secret_key must be defined ' 'when a memcache_security_strategy ' 'is defined') def _cache_get(self, token_id): """"""Return token information from cache. If token is invalid raise InvalidUserToken return token only if fresh (not expired). """""" if not token_id: # Nothing to do return if self._memcache_security_strategy is None: key = CACHE_KEY_TEMPLATE % token_id with self._cache_pool.reserve() as cache: serialized = cache.get(key) else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % ( memcache_crypt.get_cache_key(keys)) with self._cache_pool.reserve() as cache: raw_cached = cache.get(cache_key) try: # unprotect_data will return None if raw_cached is None serialized = memcache_crypt.unprotect_data(keys, raw_cached) except Exception: msg = 'Failed to decrypt/verify cache data' self.LOG.exception(msg) # this should have the same effect as data not # found in cache serialized = None if serialized is None: return None # Note that _INVALID_INDICATOR and (data, expires) are the only # valid types of serialized cache entries, so there is not # a collision with jsonutils.loads(serialized) == None. if not isinstance(serialized, six.string_types): serialized = serialized.decode('utf-8') cached = jsonutils.loads(serialized) if cached == self._INVALID_INDICATOR: self.LOG.debug('Cached Token is marked unauthorized') raise InvalidUserToken('Token authorization failed') data, expires = cached try: expires = timeutils.parse_isotime(expires) except ValueError: # Gracefully handle upgrade of expiration times from *nix # timestamps to ISO 8601 formatted dates by ignoring old cached # values. return expires = timeutils.normalize_time(expires) utcnow = timeutils.utcnow() if utcnow < expires: self.LOG.debug('Returning cached token') return data else: self.LOG.debug('Cached Token seems expired') raise InvalidUserToken('Token authorization failed') def _cache_store(self, token_id, data): """"""Store value into memcache. data may be _INVALID_INDICATOR or a tuple like (data, expires) """""" serialized_data = jsonutils.dumps(data) if isinstance(serialized_data, six.text_type): serialized_data = serialized_data.encode('utf-8') if self._memcache_security_strategy is None: cache_key = CACHE_KEY_TEMPLATE % token_id data_to_store = serialized_data else: secret_key = self._memcache_secret_key if isinstance(secret_key, six.string_types): secret_key = secret_key.encode('utf-8') security_strategy = self._memcache_security_strategy if isinstance(security_strategy, six.string_types): security_strategy = security_strategy.encode('utf-8') keys = memcache_crypt.derive_keys( token_id, secret_key, security_strategy) cache_key = CACHE_KEY_TEMPLATE % memcache_crypt.get_cache_key(keys) data_to_store = memcache_crypt.protect_data(keys, serialized_data) with self._cache_pool.reserve() as cache: cache.set(cache_key, data_to_store, time=self._cache_time) def filter_factory(global_conf, **local_conf): """"""Returns a WSGI filter app for use with paste.deploy."""""" conf = global_conf.copy() conf.update(local_conf) def auth_filter(app): return AuthProtocol(app, conf) return auth_filter def app_factory(global_conf, **local_conf): conf = global_conf.copy() conf.update(local_conf) return AuthProtocol(None, conf) if __name__ == '__main__': """"""Run this module directly to start a protected echo service:: $ python -m keystoneclient.middleware.auth_token When the ``auth_token`` module authenticates a request, the echo service will respond with all the environment variables presented to it by this module. """""" def echo_app(environ, start_response): """"""A WSGI application that echoes the CGI environment to the user."""""" start_response('200 OK', [('Content-Type', 'application/json')]) environment = dict((k, v) for k, v in six.iteritems(environ) if k.startswith('HTTP_X_')) yield jsonutils.dumps(environment) from wsgiref import simple_server # hardcode any non-default configuration here conf = {'auth_protocol': 'http', 'admin_token': 'ADMIN'} app = AuthProtocol(echo_app, conf) server = simple_server.make_server('', 8000, app) print('Serving on port 8000 (Ctrl+C to end)...') server.serve_forever() ",0,4421
openstack%2Fsenlin~master~Ic831027c7bb5e8775ddb434c6fe2f95d610eda51,openstack/senlin,master,Ic831027c7bb5e8775ddb434c6fe2f95d610eda51,Updated from global requirements,MERGED,2015-12-11 15:26:47.000000000,2015-12-12 02:05:19.000000000,2015-12-12 02:05:18.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-12-11 15:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/e0ba16a83fe5aebcd06c6262f310933c24e082af', 'message': 'Updated from global requirements\n\nChange-Id: Ic831027c7bb5e8775ddb434c6fe2f95d610eda51\n'}, {'number': 2, 'created': '2015-12-11 22:54:20.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin/commit/764fb9d6a16620a0796700148ccc9b428bd4fb0b', 'message': 'Updated from global requirements\n\nChange-Id: Ic831027c7bb5e8775ddb434c6fe2f95d610eda51\n'}]",0,256532,764fb9d6a16620a0796700148ccc9b428bd4fb0b,11,3,2,11131,,,0,"Updated from global requirements

Change-Id: Ic831027c7bb5e8775ddb434c6fe2f95d610eda51
",git fetch https://review.opendev.org/openstack/senlin refs/changes/32/256532/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,e0ba16a83fe5aebcd06c6262f310933c24e082af,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fpython-heatclient~master~Icc772ca70d6684b28c28fe0b32b2a2483e1e9e3a,openstack/python-heatclient,master,Icc772ca70d6684b28c28fe0b32b2a2483e1e9e3a,Updated from global requirements,MERGED,2015-12-11 15:25:18.000000000,2015-12-12 01:58:22.000000000,2015-12-12 01:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8833}]","[{'number': 1, 'created': '2015-12-11 15:25:18.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/aff3a997f164f319fc98bb66faed232a0d9c598a', 'message': 'Updated from global requirements\n\nChange-Id: Icc772ca70d6684b28c28fe0b32b2a2483e1e9e3a\n'}]",0,256517,aff3a997f164f319fc98bb66faed232a0d9c598a,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Icc772ca70d6684b28c28fe0b32b2a2483e1e9e3a
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/17/256517/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,aff3a997f164f319fc98bb66faed232a0d9c598a,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ftraining-guides~master~I9613e9777aab2730e2d91d2673711090da35363d,openstack/training-guides,master,I9613e9777aab2730e2d91d2673711090da35363d,Add python versions for classifier in setup.cfg,ABANDONED,2015-12-11 10:16:22.000000000,2015-12-12 01:25:36.000000000,,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 10:16:22.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ebbb1cdbbbe6275a33dfee20c01dfeecf770c85e', 'message': 'Add python versions for classifier in setup.cfg\n\nChange-Id: I9613e9777aab2730e2d91d2673711090da35363d\n'}]",0,256320,ebbb1cdbbbe6275a33dfee20c01dfeecf770c85e,4,2,1,16237,,,0,"Add python versions for classifier in setup.cfg

Change-Id: I9613e9777aab2730e2d91d2673711090da35363d
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/20/256320/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ebbb1cdbbbe6275a33dfee20c01dfeecf770c85e,add-py, Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 3 Programming Language :: Python :: 3.3 Programming Language :: Python :: 3.4,,6,0
openstack%2Foslo.middleware~master~I4ddb91d4659d045ad5c5ea1b0de95ca09056a53c,openstack/oslo.middleware,master,I4ddb91d4659d045ad5c5ea1b0de95ca09056a53c,Updated from global requirements,MERGED,2015-12-11 15:24:10.000000000,2015-12-12 01:20:15.000000000,2015-12-12 01:20:14.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-12-11 15:24:10.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/b412943065706e2181e5846601d7259370d9dd22', 'message': 'Updated from global requirements\n\nChange-Id: I4ddb91d4659d045ad5c5ea1b0de95ca09056a53c\n'}]",0,256505,b412943065706e2181e5846601d7259370d9dd22,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I4ddb91d4659d045ad5c5ea1b0de95ca09056a53c
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/05/256505/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b412943065706e2181e5846601d7259370d9dd22,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ftripleo-puppet-elements~master~I72f21036fda795b54312a7d39f04c30bbf16c41b,openstack/tripleo-puppet-elements,master,I72f21036fda795b54312a7d39f04c30bbf16c41b,Remove Cassandra repository for MidoNet element,MERGED,2015-11-30 14:48:00.000000000,2015-12-12 01:14:39.000000000,2015-12-12 01:14:39.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6807}, {'_account_id': 7505}, {'_account_id': 8449}, {'_account_id': 11933}]","[{'number': 1, 'created': '2015-11-30 14:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/3163a69595e9650b22a00ff68090b9f5b3b51b98', 'message': ""Remove Cassandra repository for MidoNet element\n\nAfter testing and modifying puppet-tripleo to use locp-cassandra instead\nof midonet-cassandra,\n\nhttps://review.openstack.org/#/c/251319/\n\nwe don't need to clone this module anymore.\n\nChange-Id: I72f21036fda795b54312a7d39f04c30bbf16c41b\n""}, {'number': 2, 'created': '2015-12-08 19:19:47.000000000', 'files': ['elements/overcloud-network-midonet/environment.d/02-midonet-envs.bash', 'elements/overcloud-network-midonet/source-repository-overcloud-network-midonet'], 'web_link': 'https://opendev.org/openstack/tripleo-puppet-elements/commit/19b3df6fdbb74a97869823b43e8bd258e4d0e838', 'message': ""Remove Cassandra repository for MidoNet element\n\nAfter testing and modifying puppet-tripleo to use locp-cassandra instead\nof midonet-cassandra,\n\nhttps://review.openstack.org/#/c/251319/\n\nwe don't need to clone this module anymore.\n\nChange-Id: I72f21036fda795b54312a7d39f04c30bbf16c41b\n""}]",0,251401,19b3df6fdbb74a97869823b43e8bd258e4d0e838,28,8,2,7505,,,0,"Remove Cassandra repository for MidoNet element

After testing and modifying puppet-tripleo to use locp-cassandra instead
of midonet-cassandra,

https://review.openstack.org/#/c/251319/

we don't need to clone this module anymore.

Change-Id: I72f21036fda795b54312a7d39f04c30bbf16c41b
",git fetch https://review.opendev.org/openstack/tripleo-puppet-elements refs/changes/01/251401/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/overcloud-network-midonet/source-repository-overcloud-network-midonet'],1,3163a69595e9650b22a00ff68090b9f5b3b51b98,locd_cassandra,,midonet-cassandra git /opt/stack/puppet-midonet/cassandra https://github.com/midonet/puppet-cassandra.git 09dd80b226e14e66968509051a02b143fbb6bcc3,0,1
openstack%2Fnetworking-ovn~master~I4b89f93c174f8460e49619cd5164e002035467fb,openstack/networking-ovn,master,I4b89f93c174f8460e49619cd5164e002035467fb,doc: Fix some doc errors.,MERGED,2015-12-11 20:30:38.000000000,2015-12-12 01:14:05.000000000,2015-12-12 01:14:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}]","[{'number': 1, 'created': '2015-12-11 20:30:38.000000000', 'files': ['doc/source/faq.rst', 'doc/source/testing.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9e1a82c194a2ceb63ab8e26a0185df92e2ba3f11', 'message': 'doc: Fix some doc errors.\n\nFix a few minor errors.  Remove a stray ""::"" and fix links to other\ndocuments.\n\nChange-Id: I4b89f93c174f8460e49619cd5164e002035467fb\nSigned-off-by: Russell Bryant <rbryant@redhat.com>\n'}]",0,256734,9e1a82c194a2ceb63ab8e26a0185df92e2ba3f11,7,3,1,1561,,,0,"doc: Fix some doc errors.

Fix a few minor errors.  Remove a stray ""::"" and fix links to other
documents.

Change-Id: I4b89f93c174f8460e49619cd5164e002035467fb
Signed-off-by: Russell Bryant <rbryant@redhat.com>
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/34/256734/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/faq.rst', 'doc/source/testing.rst']",2,9e1a82c194a2ceb63ab8e26a0185df92e2ba3f11,deployment-integration-guide,"If you run into any problems, take a look at our :doc:`troubleshooting` page.See the documentation and other references linked from the :doc:`readme` page.",":: If you run into any problems, take a look at our troubleshooting_ page.See the documentation and other references linked from the readme_ page.",3,5
openstack%2Fcinder~master~I40b28327e13821d6fb45f89b15267b21ed4c2e8c,openstack/cinder,master,I40b28327e13821d6fb45f89b15267b21ed4c2e8c,Retype functionality in Tintri driver,MERGED,2015-12-09 19:25:29.000000000,2015-12-12 00:59:27.000000000,2015-12-11 03:20:39.000000000,"[{'_account_id': 3}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14305}, {'_account_id': 14377}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16834}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-12-09 19:25:29.000000000', 'files': ['cinder/tests/unit/test_tintri.py', 'cinder/volume/drivers/tintri.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/918d33eee9fdeedb143f316fd7df42c3ae23cab6', 'message': 'Retype functionality in Tintri driver\n\nAt this point default retype behavior is as follows. If a volume changes\ntype on the same backend then that volume will be migrated. Since Tintri\nVMstore does not differentiate between volume types, we can avoid this\nmigration by implementing retype functionality.\n\nChange-Id: I40b28327e13821d6fb45f89b15267b21ed4c2e8c\ncloses-bug: 1524435\n'}]",2,255449,918d33eee9fdeedb143f316fd7df42c3ae23cab6,59,32,1,14377,,,0,"Retype functionality in Tintri driver

At this point default retype behavior is as follows. If a volume changes
type on the same backend then that volume will be migrated. Since Tintri
VMstore does not differentiate between volume types, we can avoid this
migration by implementing retype functionality.

Change-Id: I40b28327e13821d6fb45f89b15267b21ed4c2e8c
closes-bug: 1524435
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/255449/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_tintri.py', 'cinder/volume/drivers/tintri.py']",2,918d33eee9fdeedb143f316fd7df42c3ae23cab6,bug/1524435," def retype(self, context, volume, new_type, diff, host): """"""Retype from one volume type to another. At this point Tintri VMstore does not differentiate between volume types on the same array. This is a no-op for us. """""" return True, None ",,14,0
openstack%2Foslo.i18n~master~I7df908cfd02bbe0978ecf4ee41cf4d2546436e37,openstack/oslo.i18n,master,I7df908cfd02bbe0978ecf4ee41cf4d2546436e37,Trival: Remove 'MANIFEST.in',MERGED,2015-12-05 04:09:17.000000000,2015-12-12 00:58:21.000000000,2015-12-12 00:58:21.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2874}, {'_account_id': 6601}]","[{'number': 1, 'created': '2015-12-05 04:09:17.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/oslo.i18n/commit/59bb7070f38850bd51e87cb14210b7de6ac44aca', 'message': ""Trival: Remove 'MANIFEST.in'\n\nEverything in this file is automatically generated by pbr. There\nappears to be no good reason to keep it around.\n\nChange-Id: I7df908cfd02bbe0978ecf4ee41cf4d2546436e37\n""}]",0,253775,59bb7070f38850bd51e87cb14210b7de6ac44aca,8,4,1,9796,,,0,"Trival: Remove 'MANIFEST.in'

Everything in this file is automatically generated by pbr. There
appears to be no good reason to keep it around.

Change-Id: I7df908cfd02bbe0978ecf4ee41cf4d2546436e37
",git fetch https://review.opendev.org/openstack/oslo.i18n refs/changes/75/253775/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,59bb7070f38850bd51e87cb14210b7de6ac44aca,rm_man,,include AUTHORS include ChangeLog exclude .gitignore exclude .gitreview global-exclude *.pyc,0,6
openstack%2Foslo.serialization~master~I8b116b194760bfe6ef6fdb10b099d51bbda35c8d,openstack/oslo.serialization,master,I8b116b194760bfe6ef6fdb10b099d51bbda35c8d,Updated from global requirements,MERGED,2015-12-11 15:24:36.000000000,2015-12-12 00:54:43.000000000,2015-12-12 00:54:42.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-12-11 15:24:36.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.serialization/commit/f4a136ecacc73762387be9ec03342ad9592ace4b', 'message': 'Updated from global requirements\n\nChange-Id: I8b116b194760bfe6ef6fdb10b099d51bbda35c8d\n'}]",0,256509,f4a136ecacc73762387be9ec03342ad9592ace4b,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I8b116b194760bfe6ef6fdb10b099d51bbda35c8d
",git fetch https://review.opendev.org/openstack/oslo.serialization refs/changes/09/256509/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f4a136ecacc73762387be9ec03342ad9592ace4b,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fi18n~master~Ifc0c71ac5121f6857706c51281d75f359c488650,openstack/i18n,master,Ifc0c71ac5121f6857706c51281d75f359c488650,Drop py26 from setup.cfg,ABANDONED,2015-12-11 10:08:59.000000000,2015-12-12 00:54:43.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-12-11 10:08:59.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/i18n/commit/88b5fc681121f7e602b77ecc227d81bd8415ef15', 'message': 'Drop py26 from setup.cfg\n\nChange-Id: Ifc0c71ac5121f6857706c51281d75f359c488650\n'}]",0,256316,88b5fc681121f7e602b77ecc227d81bd8415ef15,3,1,1,16237,,,0,"Drop py26 from setup.cfg

Change-Id: Ifc0c71ac5121f6857706c51281d75f359c488650
",git fetch https://review.opendev.org/openstack/i18n refs/changes/16/256316/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,88b5fc681121f7e602b77ecc227d81bd8415ef15,drop-py26,, Programming Language :: Python :: 2.6,0,1
openstack%2Foslo.policy~master~I0d653df68c2db025f73b3020d9cff7ecb62b8cbd,openstack/oslo.policy,master,I0d653df68c2db025f73b3020d9cff7ecb62b8cbd,Updated from global requirements,MERGED,2015-12-11 15:24:13.000000000,2015-12-12 00:54:20.000000000,2015-12-12 00:54:19.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-12-11 15:24:13.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/oslo.policy/commit/c9c96f5319407a40e85a6b381866fa61a3789633', 'message': 'Updated from global requirements\n\nChange-Id: I0d653df68c2db025f73b3020d9cff7ecb62b8cbd\n'}]",0,256506,c9c96f5319407a40e85a6b381866fa61a3789633,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I0d653df68c2db025f73b3020d9cff7ecb62b8cbd
",git fetch https://review.opendev.org/openstack/oslo.policy refs/changes/06/256506/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c9c96f5319407a40e85a6b381866fa61a3789633,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ftaskflow~master~I9d1dfc610b5ce755a89440a7e1714b559bd30237,openstack/taskflow,master,I9d1dfc610b5ce755a89440a7e1714b559bd30237,Updated from global requirements,MERGED,2015-12-11 15:27:01.000000000,2015-12-12 00:53:36.000000000,2015-12-12 00:53:34.000000000,"[{'_account_id': 3}, {'_account_id': 1297}]","[{'number': 1, 'created': '2015-12-11 15:27:01.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/b6fb5dcba612923ead80742898308c0ad4bd0944', 'message': 'Updated from global requirements\n\nChange-Id: I9d1dfc610b5ce755a89440a7e1714b559bd30237\n'}]",0,256533,b6fb5dcba612923ead80742898308c0ad4bd0944,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I9d1dfc610b5ce755a89440a7e1714b559bd30237
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/33/256533/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,b6fb5dcba612923ead80742898308c0ad4bd0944,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fneutron-fwaas~master~I699022b285594edf3c5db10fbdac2f904dc42928,openstack/neutron-fwaas,master,I699022b285594edf3c5db10fbdac2f904dc42928,Added constraints tox targets,MERGED,2015-11-26 13:55:37.000000000,2015-12-12 00:12:09.000000000,2015-12-12 00:12:08.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4656}, {'_account_id': 6659}, {'_account_id': 6995}, {'_account_id': 7244}, {'_account_id': 8124}, {'_account_id': 9656}, {'_account_id': 10692}, {'_account_id': 12612}, {'_account_id': 12999}, {'_account_id': 13995}, {'_account_id': 15330}]","[{'number': 1, 'created': '2015-11-26 13:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/7c5b1a0b9cf689e8a2cc218a1b2667cbe6cd7590', 'message': 'Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.  Made\ntox_install.sh use constraints file to install both the project and\nneutron dependency, if the file name is passed via\nUPPER_CONSTRAINTS_FILE variable.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\n'}, {'number': 2, 'created': '2015-11-26 14:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/187049fb5a043472432e98aa44c61c3ec70cb6f3', 'message': 'Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.  Made\ntox_install.sh use constraints file to install both the project and\nneutron dependency, if the file name is passed via\nUPPER_CONSTRAINTS_FILE variable.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\n'}, {'number': 3, 'created': '2015-11-26 14:14:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/6a517e514b3ddd35fb9c60a052a9217217e40a18', 'message': 'Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.  Made\ntox_install.sh use constraints file to install both the project and\nneutron dependency, if the file name is passed via\nUPPER_CONSTRAINTS_FILE variable.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\n'}, {'number': 4, 'created': '2015-12-02 20:11:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/5fda765875c1d98d780bb24730f08c7cb1cc5d94', 'message': 'Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.  Made\ntox_install.sh use constraints file to install both the project and\nneutron dependency, if the file name is passed via\nUPPER_CONSTRAINTS_FILE variable.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\n'}, {'number': 5, 'created': '2015-12-02 20:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c188d38750534658fc1efc8fd1ba43fed90e5b35', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project\nand neutron dependency, if the first argument is 'constrained'.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\n""}, {'number': 6, 'created': '2015-12-03 21:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/84c3b907d9ffc7ba47647cce0fbe4162116cf76a', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project\nand neutron dependency, if the first argument is 'constrained'.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\nPartial-Bug: #1522503\nDepends-On: I7d43cf950ec9c337da991b1e765b13743c4e18c2\n""}, {'number': 7, 'created': '2015-12-07 20:27:46.000000000', 'files': ['tools/tox_install.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f8e9f8bf84295b49d682751607918fb7919946ed', 'message': ""Added constraints tox targets\n\nThese are eventually going to be used in gate instead of unconstrained\njobs. There is some code duplication in commands definitions, but tox\ndoes not allow to inherit definitions with {posargs} substitution.\n\nMade tox_install.sh use constraints file to install both the project\nand neutron dependency, if the first argument is 'constrained'.\n\nChange-Id: I699022b285594edf3c5db10fbdac2f904dc42928\nPartial-Bug: #1522503\nDepends-On: I7d43cf950ec9c337da991b1e765b13743c4e18c2\n""}]",2,250390,f8e9f8bf84295b49d682751607918fb7919946ed,44,13,7,9656,,,0,"Added constraints tox targets

These are eventually going to be used in gate instead of unconstrained
jobs. There is some code duplication in commands definitions, but tox
does not allow to inherit definitions with {posargs} substitution.

Made tox_install.sh use constraints file to install both the project
and neutron dependency, if the first argument is 'constrained'.

Change-Id: I699022b285594edf3c5db10fbdac2f904dc42928
Partial-Bug: #1522503
Depends-On: I7d43cf950ec9c337da991b1e765b13743c4e18c2
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/90/250390/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/tox_install.sh', 'tox.ini']",2,7c5b1a0b9cf689e8a2cc218a1b2667cbe6cd7590,250390,setenv = constraints: {[testenv:common-constraints]setenv} VIRTUAL_ENV={envdir}[testenv:common-constraints] setenv = VIRTUAL_ENV={envdir} UPPER_CONSTRAINTS_FILE=https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt [testenv:pep8-constraints] commands = {[testenv:pep8]commands} whitelist_externals = {[testenv:pep8]whitelist_externals} [testenv:cover-constraints] commands = python setup.py testr --coverage --coverage-package-name=neutron_fwaas --testr-args='{posargs}' [testenv:venv-constraints] commands = {posargs} [testenv:docs-constraints] commands = {[testenv:docs]commands} [testenv:pylint-constraints] deps = {[testenv:pylint]deps} commands = pylint --rcfile=.pylintrc --output-format=colorized {posargs:neutron_fwaas} ,setenv = VIRTUAL_ENV={envdir},33,4
openstack%2Fneutron~master~I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c,openstack/neutron,master,I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c,Add address scope to ports in RPC response to L3 agent,MERGED,2015-06-09 21:26:39.000000000,2015-12-12 00:09:34.000000000,2015-12-12 00:09:32.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 5170}, {'_account_id': 7448}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9551}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9732}, {'_account_id': 9751}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10387}, {'_account_id': 10692}, {'_account_id': 11159}, {'_account_id': 11682}, {'_account_id': 12912}, {'_account_id': 13734}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14214}, {'_account_id': 14215}, {'_account_id': 14216}, {'_account_id': 14258}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15444}, {'_account_id': 15482}, {'_account_id': 15752}, {'_account_id': 15894}, {'_account_id': 17211}, {'_account_id': 17455}, {'_account_id': 17500}, {'_account_id': 18695}]","[{'number': 1, 'created': '2015-06-09 21:26:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/1cacc79838998ab4a81ccf4d78d9b9e48fc223fd', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 2, 'created': '2015-06-12 17:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6959203b28e6ce243ad9042e11d8fcecccb22580', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 3, 'created': '2015-08-10 20:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b4a06e6d3d4944667c14102ffb7a32fda308bb11', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 4, 'created': '2015-08-13 17:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a308e0896c74269591e2bed082c1a2c38991c598', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 5, 'created': '2015-08-28 21:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/dba16a5a20557426d428504ea3dfc1d56fdfc002', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 6, 'created': '2015-08-28 22:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c555607f691e9aa4b143f3b6aace99b624bc2c19', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 7, 'created': '2015-08-31 23:06:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a9fe1438f825f6bf8fb1184491a605b9d3d25a34', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 8, 'created': '2015-09-01 19:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f7f4d97cc5fdd1ac951a2c20210f6efe383b8395', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 9, 'created': '2015-10-07 18:43:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a911986f2bc27be8c7019012e515640211ca0b53', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 10, 'created': '2015-10-07 18:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a545d59097ed8efe4dec56073c32b7008968656', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 11, 'created': '2015-10-07 19:27:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6d92770fb54f7356be316b44d8d29ec0e102822a', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 12, 'created': '2015-10-07 19:56:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/67a55bf1306f731aee64ff402e440b6bf08bec43', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 13, 'created': '2015-10-07 20:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/f80087f0a6a8bab3ebf42fff18c75cd92951dad4', 'message': ""Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\nNeutron doesn't yet have a first class address scope, that will be\nadded by a different patch [1].  However, subnet pools are already\ndefined and can be treated as address scopes already.  This means that\nthe RPC changes can be defined and allow the L3 agent changes to be\ndeveloped indepently of the first class address scope support in the\nNeutron server.\n\n[1] https://review.openstack.org/#/c/189741/\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n""}, {'number': 14, 'created': '2015-10-07 20:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/871ebf4e05bb096c290f353fbd1856d34d67bba6', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 15, 'created': '2015-10-09 20:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/4d3981bc78ded4f076b8f25f08963385ef2e81b9', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 16, 'created': '2015-10-16 20:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ca8f5eb3e28766556e1bd80d47551ba148406126', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 17, 'created': '2015-10-16 20:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/0ce960f02741b9d9ddc1e63d56a37be205113043', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 18, 'created': '2015-10-22 23:31:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c95eb9a166bc9c90c48c1f5b8786057291eabb35', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 19, 'created': '2015-10-30 22:47:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/5cb360d2eac608302589303ce7327da0c410b857', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 20, 'created': '2015-11-10 17:04:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7a3db6c6b9f35e7c656de8d485ef1dc76ac92160', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 21, 'created': '2015-11-12 17:14:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/105fdb738bbc83ffdd90e67f1d4525ceb5b1d573', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 22, 'created': '2015-11-23 20:31:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e74a409fe7cbc1b82ccb86511e551b2439c72d29', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 23, 'created': '2015-11-23 22:59:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/613fd59db485fc257ecafe7ab6e4553d1ab80828', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nThis commit adds a devref for the address scopes and subnet pools\nfeatures.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 24, 'created': '2015-11-24 17:55:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ced44bd4484e00edd9a8128e97569d30145d29d3', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nThis commit adds a devref for the address scopes and subnet pools\nfeatures.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 25, 'created': '2015-12-03 19:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/392051d97d9f02b175f85029194d75420fa767a7', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nThis commit adds a devref for the address scopes and subnet pools\nfeatures.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 26, 'created': '2015-12-05 15:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/380d207fb1097a84c4b0022be783b84e1aae1d20', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nThis commit adds a devref for the address scopes and subnet pools\nfeatures.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}, {'number': 27, 'created': '2015-12-07 22:03:23.000000000', 'files': ['doc/source/devref/address_scopes.rst', 'neutron/db/l3_db.py', 'doc/source/devref/index.rst', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c7d0d2e5692b7a66599885f961035bca59c62402', 'message': 'Add address scope to ports in RPC response to L3 agent\n\nThe L3 agent needs to know the address scope of each port of each\nrouter it sets up in order to enforce isolation between scopes.\n\nThis commit adds a devref for the address scopes and subnet pools\nfeatures.\n\nChange-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c\nPartially-Implements: blueprint address-scopes\n'}]",99,189948,c7d0d2e5692b7a66599885f961035bca59c62402,447,45,27,7448,,,0,"Add address scope to ports in RPC response to L3 agent

The L3 agent needs to know the address scope of each port of each
router it sets up in order to enforce isolation between scopes.

This commit adds a devref for the address scopes and subnet pools
features.

Change-Id: I6a7b3708fadefff1919d70ab1b8bc345b3fbe81c
Partially-Implements: blueprint address-scopes
",git fetch https://review.opendev.org/openstack/neutron refs/changes/48/189948/5 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/l3_db.py'],1,1cacc79838998ab4a81ccf4d78d9b9e48fc223fd,bp/address-scopes,"from neutron.i18n import _LI, _LE, _LW 'network_id', 'ipv6_ra_mode', 'subnetpool_id'] port['address_scopes'] = scopes = {} for subnet in subnets_by_network[port['network_id']]: # TODO(Carl) true address scopes will come later. Using just # the subnetpool id for now. scope = subnet['subnetpool_id'] cidr = netaddr.IPNetwork(subnet['cidr']) if cidr.version in scopes and scopes[cidr.version] != scope: # I don't expect this to happen because we have code now # backported to Kilo to prevent it. But, there was a small # window where it could've happened. msg = _LW(""Network %(net)s has IPv%(version)d subnets "" ""from more than one address scope."") LOG.warn(msg, {'net': port['network_id'], 'version': cidr.version}) scopes[cidr.version] = scope prefixlen = cidr.prefixlen","from neutron.i18n import _LI, _LE 'network_id', 'ipv6_ra_mode'] for subnet in subnets_by_network[port['network_id']]: prefixlen = netaddr.IPNetwork( subnet['cidr']).prefixlen",20,4
openstack%2Fglance~master~I91e1cc9a273249fd88749cecf21200f3f5e2bab1,openstack/glance,master,I91e1cc9a273249fd88749cecf21200f3f5e2bab1,Replace oslo_utils.timeutils,MERGED,2015-12-04 14:21:58.000000000,2015-12-12 00:08:00.000000000,2015-12-12 00:07:59.000000000,"[{'_account_id': 3}, {'_account_id': 455}, {'_account_id': 1669}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 7575}, {'_account_id': 8871}, {'_account_id': 12000}, {'_account_id': 15054}, {'_account_id': 17116}, {'_account_id': 17976}]","[{'number': 1, 'created': '2015-12-04 14:21:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/eeeeb1eb6e94cdcc2e81f357fb322330fe2c83f1', 'message': ""Replace timeutils.isotime() with datetime.isoformat()\n\ntimeutils.isotime() has been deprecated for several versions and months now,\nlet's replace it with isoformat.\n\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}, {'number': 2, 'created': '2015-12-09 21:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9f7981dfb6ac4b384be3d5e6cc48fedbe23e5ac6', 'message': ""Replace oslo_utils.timeutils\n\nThis change introduces glance.common.timeutils that provides the\ntimeutils previously consumed from oslo_utils.\n\nOslo is deprecating some timeutils functionality which of Glance\ndepends on. Suggested replacement (isoformat) would break glance APIs\nso it's cleaner to carry this functionality in Glance rather than\nre-invent the wheel.\n\nCo-Authored-By: Erno Kuvaja <jokke@usr.fi>\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}, {'number': 3, 'created': '2015-12-09 21:27:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5e2577f18a402c298bd54ac1fc347b7ac238ae99', 'message': ""Replace oslo_utils.timeutils\n\nThis change introduces glance.common.timeutils that provides the\ntimeutils previously consumed from oslo_utils.\n\nOslo is deprecating some timeutils functionality which of Glance\ndepends on. Suggested replacement (isoformat) would break glance APIs\nso it's cleaner to carry this functionality in Glance rather than\nre-invent the wheel.\n\nCo-Authored-By: Erno Kuvaja <jokke@usr.fi>\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}, {'number': 4, 'created': '2015-12-09 23:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8f36686cce9738e267ab193de5bea26a3184971d', 'message': ""Replace oslo_utils.timeutils\n\nThis change introduces glance.common.timeutils that provides the\ntimeutils previously consumed from oslo_utils.\n\nOslo is deprecating some timeutils functionality which of Glance\ndepends on. Suggested replacement (isoformat) would break glance APIs\nso it's cleaner to carry this functionality in Glance rather than\nre-invent the wheel.\n\nCo-Authored-By: Erno Kuvaja <jokke@usr.fi>\nCo-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>\n\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}, {'number': 5, 'created': '2015-12-09 23:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c008da231c2d22f1bfec1c79823182aa63d30d73', 'message': ""Replace oslo_utils.timeutils\n\nThis change introduces glance.common.timeutils that provides the\ntimeutils previously consumed from oslo_utils.\n\nOslo is deprecating some timeutils functionality which of Glance\ndepends on. Suggested replacement (isoformat) would break glance APIs\nso it's cleaner to carry this functionality in Glance rather than\nre-invent the wheel.\n\nCo-Authored-By: Erno Kuvaja <jokke@usr.fi>\nCo-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>\n\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}, {'number': 6, 'created': '2015-12-10 10:58:17.000000000', 'files': ['glance/db/sqlalchemy/models_artifacts.py', 'glance/registry/api/v1/images.py', 'glance/tests/unit/test_migrations.py', 'glance/tests/functional/db/base.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/db/simple/api.py', 'glance/api/v2/tasks.py', 'glance/db/sqlalchemy/api.py', 'glance/domain/__init__.py', 'glance/tests/unit/test_auth.py', 'glance/tests/unit/common/test_timeutils.py', 'glance/tests/unit/v2/test_tasks_resource.py', 'glance/common/timeutils.py', 'glance/tests/unit/test_notifier.py', 'requirements.txt', 'glance/notifier.py', 'glance/api/v1/images.py', 'glance/common/wsme_utils.py', 'glance/tests/utils.py', 'glance/tests/integration/legacy_functional/test_v1_api.py', 'glance/cmd/cache_manage.py', 'glance/artifacts/domain/__init__.py', 'glance/db/sqlalchemy/models_metadef.py', 'glance/tests/unit/v2/test_registry_client.py', 'glance/common/rpc.py', 'glance/tests/integration/v2/test_tasks_api.py', 'glance/tests/unit/v1/test_api.py', 'glance/api/v2/image_members.py', 'glance/db/sqlalchemy/models.py', 'glance/tests/unit/test_domain.py', 'glance/tests/unit/v2/test_registry_api.py', 'glance/db/sqlalchemy/metadata.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/api/v2/images.py', 'glance/db/sqlalchemy/migrate_repo/versions/035_add_metadef_tables.py', 'glance/db/sqlalchemy/artifacts.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/4d5330088ff101c36fd8460dd72c7fd644938c7e', 'message': ""Replace oslo_utils.timeutils\n\nThis change introduces glance.common.timeutils that provides the\ntimeutils previously consumed from oslo_utils.\n\nOslo is deprecating some timeutils functionality which of Glance\ndepends on. Suggested replacement (isoformat) would break glance APIs\nso it's cleaner to carry this functionality in Glance rather than\nre-invent the wheel.\n\nCo-Authored-By: Erno Kuvaja <jokke@usr.fi>\nCo-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>\n\nChange-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1\n""}]",2,253517,4d5330088ff101c36fd8460dd72c7fd644938c7e,39,14,6,1669,,,0,"Replace oslo_utils.timeutils

This change introduces glance.common.timeutils that provides the
timeutils previously consumed from oslo_utils.

Oslo is deprecating some timeutils functionality which of Glance
depends on. Suggested replacement (isoformat) would break glance APIs
so it's cleaner to carry this functionality in Glance rather than
re-invent the wheel.

Co-Authored-By: Erno Kuvaja <jokke@usr.fi>
Co-Authored-By: Sabari Kumar Murugesan <smurugesan@vmware.com>

Change-Id: I91e1cc9a273249fd88749cecf21200f3f5e2bab1
",git fetch https://review.opendev.org/openstack/glance refs/changes/17/253517/1 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/functional/db/base.py', 'glance/tests/unit/v1/test_registry_api.py', 'glance/api/v2/tasks.py', 'glance/api/v2/model/metadef_resource_type.py', 'glance/tests/unit/v1/test_api.py', 'glance/tests/unit/v2/test_metadef_resources.py', 'glance/api/v2/image_members.py', 'glance/api/v2/model/metadef_tag.py', 'glance/api/v2/model/metadef_namespace.py', 'glance/tests/unit/v2/test_images_resource.py', 'glance/tests/unit/v2/test_tasks_resource.py', 'glance/api/v2/model/metadef_object.py', 'glance/tests/unit/test_notifier.py', 'glance/tests/unit/v2/test_image_members_resource.py', 'glance/tests/unit/v1/test_registry_client.py', 'glance/api/v2/images.py', 'glance/notifier.py', 'glance/common/wsme_utils.py', 'glance/tests/integration/legacy_functional/test_v1_api.py']",19,eeeeb1eb6e94cdcc2e81f357fb322330fe2c83f1,timeutils, yesterday = (timeutils.utcnow() - datetime.timedelta(1)).isoformat() tomorrow = (timeutils.utcnow() + datetime.timedelta(1)).isoformat(), yesterday = timeutils.isotime(timeutils.utcnow() - datetime.timedelta(1)) tomorrow = timeutils.isotime(timeutils.utcnow() + datetime.timedelta(1)),88,63
openstack%2Fnova~master~I83a25bda681daa249ffca8bc1f38edcd70dd7cc5,openstack/nova,master,I83a25bda681daa249ffca8bc1f38edcd70dd7cc5,Add SIGHUP handlers for compute rpcapi to console and conductor,MERGED,2015-12-10 16:37:04.000000000,2015-12-12 00:07:21.000000000,2015-12-12 00:07:17.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-10 16:37:04.000000000', 'files': ['nova/tests/unit/console/test_console.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/console/manager.py', 'nova/consoleauth/manager.py', 'nova/tests/unit/consoleauth/test_consoleauth.py', 'nova/conductor/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a14ec9182b1450c22ce670704f02ef99f640618e', 'message': 'Add SIGHUP handlers for compute rpcapi to console and conductor\n\nThis adds SIGHUP handlers to console, consoleauth, and conductor\nservices to reload the compute_rpcapi. This is required for auto\nversion pinning to be dynamic at runtime.\n\nRelated to blueprint service-version-behavior\n\nChange-Id: I83a25bda681daa249ffca8bc1f38edcd70dd7cc5\n'}]",0,255972,a14ec9182b1450c22ce670704f02ef99f640618e,24,14,1,4393,,,0,"Add SIGHUP handlers for compute rpcapi to console and conductor

This adds SIGHUP handlers to console, consoleauth, and conductor
services to reload the compute_rpcapi. This is required for auto
version pinning to be dynamic at runtime.

Related to blueprint service-version-behavior

Change-Id: I83a25bda681daa249ffca8bc1f38edcd70dd7cc5
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/255972/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/console/test_console.py', 'nova/console/manager.py', 'nova/tests/unit/conductor/test_conductor.py', 'nova/consoleauth/manager.py', 'nova/tests/unit/consoleauth/test_consoleauth.py', 'nova/conductor/manager.py']",6,a14ec9182b1450c22ce670704f02ef99f640618e,okay-we-got-it,"from nova.i18n import _, _LE, _LI, _LW def reset(self): LOG.info(_LI('Reloading compute RPC API')) compute_rpcapi.LAST_VERSION = None self.compute_rpcapi = compute_rpcapi.ComputeAPI() ","from nova.i18n import _, _LE, _LW",41,1
openstack%2Fdevstack~stable%2Fliberty~I97c7896ef38b275aacb4f933fc849acee1bab858,openstack/devstack,stable/liberty,I97c7896ef38b275aacb4f933fc849acee1bab858,create apt_get_update to try to work around broken mirrors,MERGED,2015-12-11 15:16:01.000000000,2015-12-12 00:03:50.000000000,2015-12-12 00:03:49.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 10118}]","[{'number': 1, 'created': '2015-12-11 15:16:01.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/6313bf8452173f19dd69287330df86d18d401486', 'message': ""create apt_get_update to try to work around broken mirrors\n\nUbuntu's apt mirroring mechanism produces inconsistent mirrors pretty\nregularly. The devstack-gate apt-get update model seems to have been\nmore effective getting past this than what we did in devstack. Adopt\nthat method for our updates.\n\nChange-Id: I97c7896ef38b275aacb4f933fc849acee1bab858\n(cherry picked from commit 88ee8ce4684e13865123636dd5d2baa5d6a44ef7)\n""}]",0,256468,6313bf8452173f19dd69287330df86d18d401486,8,4,1,2750,,,0,"create apt_get_update to try to work around broken mirrors

Ubuntu's apt mirroring mechanism produces inconsistent mirrors pretty
regularly. The devstack-gate apt-get update model seems to have been
more effective getting past this than what we did in devstack. Adopt
that method for our updates.

Change-Id: I97c7896ef38b275aacb4f933fc849acee1bab858
(cherry picked from commit 88ee8ce4684e13865123636dd5d2baa5d6a44ef7)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/256468/1 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,6313bf8452173f19dd69287330df86d18d401486,,"# Wrapper for ``apt-get update`` to try multiple times on the update # to address bad package mirrors (which happen all the time). function apt_get_update { # only do this once per run if [[ ""$REPOS_UPDATED"" == ""True"" && ""$RETRY_UPDATE"" != ""True"" ]]; then return fi # bail if we are offline [[ ""$OFFLINE"" = ""True"" ]] && return local sudo=""sudo"" [[ ""$(id -u)"" = ""0"" ]] && sudo=""env"" local proxies=""http_proxy=${http_proxy:-} https_proxy=${https_proxy:-} no_proxy=${no_proxy:-} "" local update_cmd=""$sudo $proxies apt-get update"" if ! timeout 300 sh -c ""while ! $update_cmd; do sleep 30; done""; then die $LINENO ""Failed to update apt repos, we're dead now"" fi REPOS_UPDATED=True } apt_get_update"," local xtrace=$(set +o | grep xtrace) set +o xtrace if [[ ""$REPOS_UPDATED"" != ""True"" || ""$RETRY_UPDATE"" = ""True"" ]]; then # if there are transient errors pulling the updates, that's fine. # It may be secondary repositories that we don't really care about. apt_get update || /bin/true REPOS_UPDATED=True fi $xtrace",24,9
openstack%2Fastara~master~I4cda75137001337a222ab270f2707981b07998f7,openstack/astara,master,I4cda75137001337a222ab270f2707981b07998f7,Updated from global requirements,MERGED,2015-12-11 22:47:14.000000000,2015-12-12 00:03:08.000000000,2015-12-12 00:00:07.000000000,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-12-11 22:47:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/astara/commit/bec3b2d66e8166188d3a800d7889abc4a16be126', 'message': 'Updated from global requirements\n\nChange-Id: I4cda75137001337a222ab270f2707981b07998f7\n'}]",0,256851,bec3b2d66e8166188d3a800d7889abc4a16be126,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I4cda75137001337a222ab270f2707981b07998f7
",git fetch https://review.opendev.org/openstack/astara refs/changes/51/256851/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,bec3b2d66e8166188d3a800d7889abc4a16be126,openstack/requirements,oslo.db>=4.1.0 # Apache-2.0,oslo.db>=3.2.0 # Apache-2.0,1,1
openstack%2Foslosphinx~master~I38b985cc915cbccfa6ba83ae0cffbd72128f146e,openstack/oslosphinx,master,I38b985cc915cbccfa6ba83ae0cffbd72128f146e,Removes MANIFEST.in as it is not needed explicitely by PBR,MERGED,2015-12-11 10:55:26.000000000,2015-12-11 23:58:47.000000000,2015-12-11 23:58:47.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}]","[{'number': 1, 'created': '2015-12-11 10:55:26.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/oslosphinx/commit/ea01f15dfeab37fad774d736eafff402575eb115', 'message': 'Removes MANIFEST.in as it is not needed explicitely by PBR\n\nThis patch removes `MANIFEST.in` file as pbr generates a sensible\nmanifest from git files and some standard files and it removes\nthe need for an explicit `MANIFEST.in` file.\n\nChange-Id: I38b985cc915cbccfa6ba83ae0cffbd72128f146e\n'}]",0,256337,ea01f15dfeab37fad774d736eafff402575eb115,7,3,1,15699,,,0,"Removes MANIFEST.in as it is not needed explicitely by PBR

This patch removes `MANIFEST.in` file as pbr generates a sensible
manifest from git files and some standard files and it removes
the need for an explicit `MANIFEST.in` file.

Change-Id: I38b985cc915cbccfa6ba83ae0cffbd72128f146e
",git fetch https://review.opendev.org/openstack/oslosphinx refs/changes/37/256337/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,ea01f15dfeab37fad774d736eafff402575eb115,DROP_MANIFEST,,recursive-include oslosphinx *.html *.css *.js *.conf *.jpg *.gif include AUTHORS include HACKING.rst include ChangeLog ,0,4
openstack%2Fopenstackdocstheme~master~Ic89af2a7dd05629a00a9dd4857866f6028afc9d5,openstack/openstackdocstheme,master,Ic89af2a7dd05629a00a9dd4857866f6028afc9d5,Deprecated tox -downloadcache option removed,MERGED,2015-12-11 20:22:47.000000000,2015-12-11 23:50:57.000000000,2015-12-11 23:50:57.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 20:22:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/de938fd2ede7902e6d7a7a43f03bca76fe943071', 'message': 'Deprecated tox -downloadcache option removed\n\nCaching is enabled by default from pip version 6.0\n\nMore info:\nhttps://testrun.org/tox/latest/config.html#confval-downloadcache=path\nhttps://pip.pypa.io/en/stable/reference/pip_install/#caching\n\nChange-Id: Ic89af2a7dd05629a00a9dd4857866f6028afc9d5\n'}]",0,256701,de938fd2ede7902e6d7a7a43f03bca76fe943071,7,3,1,16896,,,0,"Deprecated tox -downloadcache option removed

Caching is enabled by default from pip version 6.0

More info:
https://testrun.org/tox/latest/config.html#confval-downloadcache=path
https://pip.pypa.io/en/stable/reference/pip_install/#caching

Change-Id: Ic89af2a7dd05629a00a9dd4857866f6028afc9d5
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/01/256701/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,de938fd2ede7902e6d7a7a43f03bca76fe943071,,,downloadcache = {toxworkdir}/_download,0,1
openstack%2Fmanila~master~I67b8d0e15fa6c68ab59774864165941051ab8649,openstack/manila,master,I67b8d0e15fa6c68ab59774864165941051ab8649,Fix wrong check message,MERGED,2015-12-10 04:10:56.000000000,2015-12-11 23:25:43.000000000,2015-12-11 21:07:49.000000000,"[{'_account_id': 3}, {'_account_id': 7040}, {'_account_id': 8851}, {'_account_id': 9207}, {'_account_id': 9796}, {'_account_id': 10515}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 14567}, {'_account_id': 15100}, {'_account_id': 16237}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}]","[{'number': 1, 'created': '2015-12-10 04:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/2104c3c2b7c4b6a9b6d0a8b27ffa28a2a81d5c64', 'message': 'Fix wrong check message\n\nFrom the hacking guidelines, the numbers should be M3xx. N333\nshould be M333. Fix it.\n\nChange-Id: I67b8d0e15fa6c68ab59774864165941051ab8649\n'}, {'number': 2, 'created': '2015-12-10 12:37:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1ff5f6dec7f3ddb5d3596624e3fb002817ecc66b', 'message': 'Fix wrong check message\n\nFrom the hacking guidelines, the numbers should be M3xx. N333\nshould be M333. Fix it.\n\nChange-Id: I67b8d0e15fa6c68ab59774864165941051ab8649\nCloses-Bug: #1524808\n'}, {'number': 3, 'created': '2015-12-10 13:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ed807d7b8a9d24554fddff05cad971e209c7d735', 'message': 'Fix wrong check message\n\nFrom the hacking guidelines, the numbers should be M3xx. N333\nshould be M333. Fix it.\n\nChange-Id: I67b8d0e15fa6c68ab59774864165941051ab8649\nCloses-Bug: #1524808\n'}, {'number': 4, 'created': '2015-12-10 13:31:42.000000000', 'files': ['manila/hacking/checks.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/manila/commit/5bd39bad8bedda75e7c363d926fe49e367773a14', 'message': 'Fix wrong check message\n\nFrom the hacking guidelines, the numbers should be M3xx. N333\nshould be M333. Fix it.\n\nChange-Id: I67b8d0e15fa6c68ab59774864165941051ab8649\nCloses-Bug: #1524808\n'}]",5,255662,5bd39bad8bedda75e7c363d926fe49e367773a14,68,19,4,10515,,,0,"Fix wrong check message

From the hacking guidelines, the numbers should be M3xx. N333
should be M333. Fix it.

Change-Id: I67b8d0e15fa6c68ab59774864165941051ab8649
Closes-Bug: #1524808
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/255662/2 && git format-patch -1 --stdout FETCH_HEAD,['manila/hacking/checks.py'],1,2104c3c2b7c4b6a9b6d0a8b27ffa28a2a81d5c64,bug/1524808," msg = (""M333: '%s' must be used instead of '%s'."") % ("," msg = (""N333: '%s' must be used instead of '%s'."") % (",1,1
openstack%2Fastara~master~I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4,openstack/astara,master,I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4,Doc updates: akanda->astara,MERGED,2015-12-03 01:23:02.000000000,2015-12-11 23:24:18.000000000,2015-12-11 23:24:17.000000000,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 6287}, {'_account_id': 6843}]","[{'number': 1, 'created': '2015-12-03 01:23:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/23eb415d31c317c46d594863e1a300cca02cd521', 'message': 'Doc updates: akanda->astara\n\nThis finishes removing akanda references in docs in favor\nof astara.\n\nChange-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4\n'}, {'number': 2, 'created': '2015-12-07 18:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/ec27ebf8338166f3d1e58451a4ee069cc0d0f0e5', 'message': 'Doc updates: akanda->astara\n\nThis finishes removing akanda references in docs in favor\nof astara.\n\nChange-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4\n'}, {'number': 3, 'created': '2015-12-07 19:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/56da778f9b61ee9fff2e1f61ab3fd4925e09adaf', 'message': 'Doc updates: akanda->astara\n\nThis finishes removing akanda references in docs in favor\nof astara.\n\nChange-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4\n'}, {'number': 4, 'created': '2015-12-09 19:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/astara/commit/189805b597fbd048e87e4711dde2f31a826a0f5f', 'message': 'Doc updates: akanda->astara\n\nThis finishes removing akanda references in docs in favor\nof astara.\n\nChange-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4\n'}, {'number': 5, 'created': '2015-12-10 19:56:30.000000000', 'files': ['docs/source/reference.rst', 'docs/source/appliance.rst', 'docs/source/conf.py', 'docs/source/contribute.rst', 'docs/source/index.rst', 'docs/source/orchestrator.rst', 'docs/source/operation.rst'], 'web_link': 'https://opendev.org/openstack/astara/commit/2c7bb801c95275f5591ca6d723af499bc57e34f2', 'message': 'Doc updates: akanda->astara\n\nThis finishes removing akanda references in docs in favor\nof astara.\n\nChange-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4\n'}]",6,252699,2c7bb801c95275f5591ca6d723af499bc57e34f2,28,5,5,1420,,,0,"Doc updates: akanda->astara

This finishes removing akanda references in docs in favor
of astara.

Change-Id: I5bed2cbada12ccc9e6756d0692eb55bcd3f1a4d4
",git fetch https://review.opendev.org/openstack/astara refs/changes/99/252699/5 && git format-patch -1 --stdout FETCH_HEAD,"['docs/source/reference.rst', 'docs/source/appliance.rst', 'docs/source/conf.py', 'docs/source/contribute.rst', 'docs/source/index.rst', 'docs/source/orchestrator.rst', 'docs/source/operation.rst']",7,23eb415d31c317c46d594863e1a300cca02cd521,252699," $ pip install -e git://github.com/openstack/astara.git@stable/liberty#egg=astara After installing :py:mod:`astara`, it can be invoked as:: $ astara-orchestrator --config-file /etc/akanda-rug/rug.ini The :py:mod:`astara-orchestrator` service is intended to run on a management network (aa running :py:mod:`astara-orchestrator` via AMQP:: $ astara-ctl browse $ astara-ctl poll $ astara-ctl router rebuild <router-id> $ astara-ctl router update <router-id> $ astara-ctl router debug <router-id> $ astara-ctl router manage <router-id> it back under astara-orchestrator management. $ astara-ctl tenant debug <tenant-id> $ astara-ctl tenant manage <tenant-id> and places the tenant back under astara-orchestrator management. $ astara-ctl ssh <router-id> $ astara-ctl workers debug:program:`astara-orchestrator` also exposes an RPC API on the management network, which allows non-interactive `astara-ctl` commands to be issued via HTTP, e.g.,astara-debug-router:program:`astara-debug-router` is a diagnostic tool which can be used toand understanding the nature of the :py:mod:`astara-orchestrator` state machine, but it's $ astara-ctl router debug <router-id> $ astara-debug-router --router-id <router-id>"," $ pip install -e git://github.com/stackforge/akanda-rug.git@stable/kilo#egg=akanda-rug After installing :py:mod:`akanda.rug`, it can be invoked as:: $ akanda-rug-service --config-file /etc/akanda-rug/rug.ini The :py:mod:`akanda.rug` service is intended to run on a management network (aa running :py:mod:`akanda.rug` via AMQP:: $ rug-ctl browse $ rug-ctl poll $ rug-ctl router rebuild <router-id> $ rug-ctl router update <router-id> $ rug-ctl router debug <router-id> $ rug-ctl router manage <router-id> it back under akanda-rug management. $ rug-ctl tenant debug <tenant-id> $ rug-ctl tenant manage <tenant-id> and places the tenant back under akanda-rug management. $ rug-ctl ssh <router-id> $ rug-ctl workers debug:program:`akanda-rug` also exposes an RPC API on the management network, which allows non-interactive `rug-ctl` commands to be issued via HTTP, e.g.,akanda-debug-router:program:`akanda-debug-router` is a diagnostic tool which can be used toand understanding the nature of the :py:mod:`akanda.rug` state machine, but it's $ rug-ctl router debug <router-id> $ akanda-debug-router --router-id <router-id>",76,87
openstack%2Ftacker~master~I87bc90078b831535e7875b2f548904799ad766cf,openstack/tacker,master,I87bc90078b831535e7875b2f548904799ad766cf,Func test cases for vnf and vnfd param,MERGED,2015-10-15 10:15:26.000000000,2015-12-11 23:23:41.000000000,2015-12-04 18:00:32.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 10182}, {'_account_id': 13380}, {'_account_id': 13485}, {'_account_id': 16511}, {'_account_id': 17952}]","[{'number': 1, 'created': '2015-10-15 10:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/9df5d9fcc27202dbac8344b81e5aad55d8b0508b', 'message': 'Func test cases for vnf and vnfd param\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 2, 'created': '2015-11-23 08:23:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/9e2f79b250b6cb99c816c5c0f7534f3c819fe9c1', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 3, 'created': '2015-11-23 08:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/22379389f78685696ffcbb6f25ce4cbf90d27c83', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 4, 'created': '2015-11-28 10:51:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/c0b4d071f68a22ba874c9fe622e1ce71aa9128f9', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 5, 'created': '2015-11-28 10:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/460ce594bb4a59e019c20b4214027d629906ad50', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 6, 'created': '2015-11-29 05:52:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/0331a0df1aaadb96e21e36762afde1442514ac34', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 7, 'created': '2015-12-03 02:15:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/91e2ecfc309f7292127e1ff0e388568f2f530485', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 8, 'created': '2015-12-03 02:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/e5ed3c4360a593103af382b5c50d93dcc93fcc51', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\nDepends-On: I08d9eb1880eceb7e0b59271a43f7c716159cfe66\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 9, 'created': '2015-12-03 02:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/7fbae0cad41a1e0aafc97713201804a75c21287e', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\nDepends-On: I08d9eb1880eceb7e0b59271a43f7c716159cfe66\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}, {'number': 11, 'created': '2015-12-04 00:07:49.000000000', 'files': ['tacker/tests/functional/vnfm/test_vnfm_param.py', 'tacker/tests/etc/samples/sample_cirros_vnf_values.yaml', 'tacker/tests/etc/samples/sample_cirros_vnf_param.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/c56b9555fa751cc8c77116a885b9e955d8110f96', 'message': 'Func test cases for vnf and vnfd param\n\nAdding functional test for create and delete vnfd and vnf\nwith parameterization\n\nCloses-Bug: 1495825\nDepends-On: I08d9eb1880eceb7e0b59271a43f7c716159cfe66\n\nChange-Id: I87bc90078b831535e7875b2f548904799ad766cf\n'}]",22,235227,c56b9555fa751cc8c77116a885b9e955d8110f96,38,7,10,17778,,,0,"Func test cases for vnf and vnfd param

Adding functional test for create and delete vnfd and vnf
with parameterization

Closes-Bug: 1495825
Depends-On: I08d9eb1880eceb7e0b59271a43f7c716159cfe66

Change-Id: I87bc90078b831535e7875b2f548904799ad766cf
",git fetch https://review.opendev.org/openstack/tacker refs/changes/27/235227/8 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/etc/samples/sample_cirros_vnf_values.yaml', 'tacker/tests/functional/vnfd/test_vnfd_param.py', 'tacker/tests/etc/samples/sample_cirros_vnf_param.yaml', 'tacker/tests/functional/vnfd/test_vnf_param.py']",4,9df5d9fcc27202dbac8344b81e5aad55d8b0508b,bug/1495825,"# Copyright 2015 Brocade Communications System, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from oslo_config import cfg from tacker.tests.functional.vnfd import base from tacker.tests.utils import read_file CONF = cfg.CONF class VnfTestParam(base.BaseTackerTest): def test_vnf_scenarios(self): # Create Vnf Scenario # Reading the yaml file and creating it as a dictionary yaml_input = dict() yaml_input['tosca'] = read_file('sample_cirros_vnf_param.yaml') toscal = yaml_input['tosca'] req_dict = {'vnfd': {'attributes': {'vnfd': toscal}}} # Using tacker client passing the request dictionary # to create a vnfd_instance vnfd_instance = self.client.create_vnfd(body=req_dict) self.assertIsNotNone(vnfd_instance) # For creating VNF we need name , vnfd_id and param file vnf_name = ""funcTest"" vnfd_id = vnfd_id = vnfd_instance['vnfd']['id'] self.assertIsNotNone(vnfd_id) values_str = read_file('sample_cirros_vnf_values.yaml') self.assertIsNotNone(values_str) # passing request dctionary to create vnf vnf_dict = () vnf_dict = {'vnf': {'vnfd_id': vnfd_id, 'name': vnf_name, 'attributes': {'param_values': values_str}}} vnf_instance = self.client.create_vnf(body=vnf_dict) self.assertIsNotNone(vnf_instance) self.assertIsNotNone(vnf_instance['vnf']['id']) self.assertIsNotNone(vnf_instance['vnf']['instance_id']) self.assertEqual(vnf_instance['vnf']['vnfd_id'], vnfd_instance[ 'vnfd']['id']) VNF_CIRROS_CREATE_TIMEOUT = 120 vnf_id = vnf_instance['vnf']['id'] self.wait_until_vnf_active(vnf_id, VNF_CIRROS_CREATE_TIMEOUT) self.assertEqual(self.client.show_vnf(vnf_id)['vnf']['status'], 'ACTIVE') # List vnf Scenario # Using list_vnfs method from tacker client to list all vnfs vnf_list = self.client.list_vnfs().get('vnfs') self.assertIsNotNone(vnf_list, ""List of vnfs are Empty \ after Creation"") # Delete Vnf Scenario try: self.client.delete_vnf(vnf_id) except Exception: assert False, ""vnf Delete failed"" ##Delete vnfd_instance try: self.client.delete_vnfd(vnfd_id) except Exception: assert False, ""vnfd Delete failed"" ",,179,0
openstack%2Fopenstacksdk~master~Ica464a6c1e2281f4acbd25a121a399b6b0c81376,openstack/openstacksdk,master,Ica464a6c1e2281f4acbd25a121a399b6b0c81376,Add admonition to telemetry code,MERGED,2015-12-09 20:08:15.000000000,2015-12-11 23:21:00.000000000,2015-12-11 23:21:00.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8410}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-09 20:08:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7865481c2099f76eb02cec0e3e5b3964f26b591d', 'message': ""Add admonition to telemetry code\n\nThis code is subject to change in the near future.  The alarm\nclass is probably moving out of here and many of the resource\nproperty have aliases.  We have agreed not to support the old\naliases going forward, because it doesn't work well.  The\nadmonition can be pulled after these issues are fixed.\n\nCloses-Bug: #1468086\nChange-Id: Ica464a6c1e2281f4acbd25a121a399b6b0c81376\n""}, {'number': 2, 'created': '2015-12-11 21:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/ca09936b48bbc63e07f7131134b09036b7e07cae', 'message': ""Add admonition to telemetry code\n\nThis code is subject to change in the near future.  The alarm\nclass is probably moving out of here and many of the resource\nproperty have aliases.  We have agreed not to support the old\naliases going forward, because it doesn't work well.  The\nadmonition can be pulled after these issues are fixed.\n\nCloses-Bug: #1468086\nChange-Id: Ica464a6c1e2281f4acbd25a121a399b6b0c81376\n""}, {'number': 3, 'created': '2015-12-11 21:05:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/dd6bf088a65babb6b9a8f714100440f1bea342ae', 'message': ""Add admonition to telemetry code\n\nThis code is subject to change in the near future.  The alarm\nclass is probably moving out of here and many of the resource\nproperty have aliases.  We have agreed not to support the old\naliases going forward, because it doesn't work well.  The\nadmonition can be pulled after these issues are fixed.\n\nCloses-Bug: #1468086\nChange-Id: Ica464a6c1e2281f4acbd25a121a399b6b0c81376\n""}, {'number': 4, 'created': '2015-12-11 21:05:46.000000000', 'files': ['openstack/telemetry/v2/sample.py', 'openstack/telemetry/v2/_proxy.py', 'openstack/telemetry/v2/alarm_change.py', 'openstack/telemetry/v2/statistics.py', 'doc/source/users/guides/telemetry.rst', 'openstack/telemetry/v2/capability.py', 'openstack/telemetry/v2/resource.py', 'doc/source/users/proxies/telemetry.rst', 'openstack/telemetry/v2/meter.py', 'openstack/telemetry/v2/alarm.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/355945c7f50821584455f594f9924f94b5455447', 'message': ""Add admonition to telemetry code\n\nThis code is subject to change in the near future.  The alarm\nclass is probably moving out of here and many of the resource\nproperty have aliases.  We have agreed not to support the old\naliases going forward, because it doesn't work well.  The\nadmonition can be pulled after these issues are fixed.\n\nCloses-Bug: #1468086\nChange-Id: Ica464a6c1e2281f4acbd25a121a399b6b0c81376\n""}]",0,255465,355945c7f50821584455f594f9924f94b5455447,14,4,4,8736,,,0,"Add admonition to telemetry code

This code is subject to change in the near future.  The alarm
class is probably moving out of here and many of the resource
property have aliases.  We have agreed not to support the old
aliases going forward, because it doesn't work well.  The
admonition can be pulled after these issues are fixed.

Closes-Bug: #1468086
Change-Id: Ica464a6c1e2281f4acbd25a121a399b6b0c81376
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/65/255465/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/telemetry/v2/sample.py', 'openstack/telemetry/v2/_proxy.py', 'openstack/telemetry/v2/alarm_change.py', 'openstack/telemetry/v2/statistics.py', 'openstack/telemetry/v2/capability.py', 'openstack/telemetry/v2/resource.py', 'openstack/telemetry/v2/meter.py', 'openstack/telemetry/v2/alarm.py']",8,7865481c2099f76eb02cec0e3e5b3964f26b591d,bug/1468086," class Alarm(resource.Resource): """""".. caution:: This API is a work in progress and is subject to change.""""""",class Alarm(resource.Resource):,9,0
openstack%2Ftacker~stable%2Fliberty~Idb7affa4c570952a1c295234e58b7a157878dab6,openstack/tacker,stable/liberty,Idb7affa4c570952a1c295234e58b7a157878dab6,Add Tacker monitor test with new template,MERGED,2015-12-07 22:09:55.000000000,2015-12-11 23:08:57.000000000,2015-12-11 23:08:56.000000000,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 9375}, {'_account_id': 13380}, {'_account_id': 16511}]","[{'number': 1, 'created': '2015-12-07 22:09:55.000000000', 'files': ['tacker/tests/functional/vnfm/test_vnf_monitoring.py', 'tacker/tests/etc/samples/sample-vnfd-single-vdu-monitoring-new-template.yaml', 'tacker/tests/etc/samples/sample-vnfd-single-vdu-monitoring.yaml'], 'web_link': 'https://opendev.org/openstack/tacker/commit/07729a48c6577bf97cb662667c0b6c338e4e9421', 'message': 'Add Tacker monitor test with new template\n\nAdding tacker functional test for monitoring using new tosca template\n\nCloses-Bug: 1518138\n\nChange-Id: Idb7affa4c570952a1c295234e58b7a157878dab6\n(cherry picked from commit 26bb93d9ff71420f809c44958d5a67f45771bec2)\n'}]",0,254406,07729a48c6577bf97cb662667c0b6c338e4e9421,7,5,1,17952,,,0,"Add Tacker monitor test with new template

Adding tacker functional test for monitoring using new tosca template

Closes-Bug: 1518138

Change-Id: Idb7affa4c570952a1c295234e58b7a157878dab6
(cherry picked from commit 26bb93d9ff71420f809c44958d5a67f45771bec2)
",git fetch https://review.opendev.org/openstack/tacker refs/changes/06/254406/1 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/tests/functional/vnfm/test_vnf_monitoring.py', 'tacker/tests/etc/samples/sample-vnfd-single-vdu-monitoring-new-template.yaml', 'tacker/tests/etc/samples/sample-vnfd-single-vdu-monitoring.yaml']",3,07729a48c6577bf97cb662667c0b6c338e4e9421,,template_name: sample-vnfd-monitoring,template_name: sample-vnfd-nonparam-respawn,17,5
openstack%2Ffuel-web~master~I8a040503113cf5187204927176b3583c88677689,openstack/fuel-web,master,I8a040503113cf5187204927176b3583c88677689,Fixed deploy old environments in nailgun,MERGED,2015-12-11 21:18:21.000000000,2015-12-11 23:01:41.000000000,2015-12-11 22:45:00.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8766}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 13505}]","[{'number': 1, 'created': '2015-12-11 21:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c44d835ac55c3e103944138ed8f4605b94be2288', 'message': 'Fixed deploy old environments in nailgun\n\nChange-Id: I8a040503113cf5187204927176b3583c88677689\nCloses-Bug: #1525403\n'}, {'number': 2, 'created': '2015-12-11 21:34:44.000000000', 'files': ['nailgun/nailgun/objects/cluster.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e993a9a64d97c525764e7ca51f5397f175cf455d', 'message': 'Fixed deploy old environments in nailgun\n\nChange-Id: I8a040503113cf5187204927176b3583c88677689\nCloses-Bug: #1525403\n'}]",1,256747,e993a9a64d97c525764e7ca51f5397f175cf455d,21,9,2,18205,,,0,"Fixed deploy old environments in nailgun

Change-Id: I8a040503113cf5187204927176b3583c88677689
Closes-Bug: #1525403
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/47/256747/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/objects/cluster.py'],1,c44d835ac55c3e103944138ed8f4605b94be2288,bug/1525403," return attrs.get['common'].get('task_deploy', {}).get('value')", return attrs['common']['task_deploy']['value'],1,1
openstack%2Ffuel-web~master~Ie030855428cf94e3e1ed613571aa2b45eff0fcba,openstack/fuel-web,master,Ie030855428cf94e3e1ed613571aa2b45eff0fcba,Introduced Task Based Deployment,MERGED,2015-12-01 16:45:06.000000000,2015-12-11 23:00:24.000000000,2015-12-11 22:43:44.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 18205}, {'_account_id': 19158}]","[{'number': 1, 'created': '2015-12-01 16:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a5e85168e7cbff6c86bce4d5f72cff30c6c28495', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 2, 'created': '2015-12-01 17:31:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c855c567998d0b6a50b2fa5d307be65d468cdd06', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 3, 'created': '2015-12-01 17:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/e19dbd54a12e0985bc1ce3d604cbaf78ce537d45', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 4, 'created': '2015-12-01 20:29:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/62facf07ae9709cbd02635d229e6056fcfcc5edb', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 5, 'created': '2015-12-01 20:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/383dc021eb31bab41a2b40522234aa32a82770d4', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 6, 'created': '2015-12-02 15:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8615eb1a35d12737221f2f76b3d4abd1cf07fcd7', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 7, 'created': '2015-12-02 16:47:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/224f60a4aa20af435f86537b8be579b544dc95ae', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 8, 'created': '2015-12-03 10:55:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b56b32b68efec4a6a9fd399a6ebcbd1a76cece46', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 9, 'created': '2015-12-03 18:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/7303bc5e66fe73407900ebdc623db6c0579b3018', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 10, 'created': '2015-12-04 08:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9c51c531cb3ef740aaf6ef5e667a5f2aaa2c193e', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 11, 'created': '2015-12-04 10:25:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/23240e7d464b352c87c980e363b9a66c1f2fb71d', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 12, 'created': '2015-12-04 15:17:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/1c66d0bf9a64421d8bf4794ebc3435ac1c0ae95c', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 13, 'created': '2015-12-07 15:00:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/552f0210ba0929c833776531d9c6e7e3f8ac5e19', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 14, 'created': '2015-12-08 12:00:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/277b8bba3713dd1ac486c72434f67942eaf7f0a6', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 15, 'created': '2015-12-08 16:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f3dcbe1950dc7a52cb13f9ff5205396df1ad4a00', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 16, 'created': '2015-12-08 17:26:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f50423a6286025b6c9909f3ec4625b50406bedd3', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 17, 'created': '2015-12-10 13:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/19f3958d7c86f94471c7cd26bd7897534934ff85', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 18, 'created': '2015-12-10 20:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/86ea86bde0dd0af335203175f6d45cec369fd754', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 19, 'created': '2015-12-11 12:46:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d67c094de2e7e0a2762049e9bdff1c7844f48e65', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 20, 'created': '2015-12-11 13:28:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9b803acb71e5b6f515938bde3cbe75596918b0e8', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 21, 'created': '2015-12-11 16:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/76bb8cb24cf807f95fc3c19a75a4e7b3f013355f', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 22, 'created': '2015-12-11 16:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6eed0387aefa19e2563c44915c1625222b4c60e5', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 23, 'created': '2015-12-11 18:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/812d4fe2896c0ded3ab5377f427533d0014cf555', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 24, 'created': '2015-12-11 19:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9e78ecbe001837a64f3afc326fbc1cebc58cd5a2', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}, {'number': 25, 'created': '2015-12-11 19:28:10.000000000', 'files': ['nailgun/nailgun/statistics/fuel_statistics/installation_info.py', 'nailgun/nailgun/orchestrator/tasks_serializer.py', 'nailgun/nailgun/fixtures/openstack.yaml', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/test/unit/test_task_based_deploy.py', 'nailgun/nailgun/task/task.py', 'nailgun/nailgun/test/integration/test_task_deploy.py', 'nailgun/nailgun/errors/__init__.py', 'nailgun/nailgun/objects/cluster.py', 'nailgun/nailgun/task/fake.py', 'nailgun/nailgun/orchestrator/tasks_templates.py', 'nailgun/nailgun/orchestrator/task_based_deploy.py', 'nailgun/nailgun/test/unit/test_role_resolver.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b94ba3cb94f59b1dc696366494364cb8238419ee', 'message': 'Introduced Task Based Deployment\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba\n'}]",97,251958,b94ba3cb94f59b1dc696366494364cb8238419ee,213,9,25,18205,,,0,"Introduced Task Based Deployment

implements blueprint: task-based-deployment-astute

Change-Id: Ie030855428cf94e3e1ed613571aa2b45eff0fcba
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/58/251958/11 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/orchestrator/base_serializers.py', 'nailgun/nailgun/task/task.py', 'nailgun/nailgun/orchestrator/deployment_serializers.py', 'nailgun/nailgun/errors/__init__.py', 'nailgun/nailgun/orchestrator/tasks_serializer.py', 'nailgun/nailgun/task/fake.py', 'nailgun/nailgun/consts.py']",7,a5e85168e7cbff6c86bce4d5f72cff30c6c28495,bp/task-based-deployment-astute,POLICY_ALL = 'all' POLICY_ANY = 'any' TASK_CROSS_DEPENDENCY = '2.0.0',,213,39
openstack%2Fneutron~master~Ia21387eeaed71f38822356e22e4adbd237c1e64c,openstack/neutron,master,Ia21387eeaed71f38822356e22e4adbd237c1e64c,Decompose OFAgent mechanism driver from neutron tree completely,MERGED,2015-12-09 22:50:39.000000000,2015-12-11 22:47:54.000000000,2015-12-11 22:37:01.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 6524}, {'_account_id': 6854}, {'_account_id': 7715}, {'_account_id': 8124}, {'_account_id': 8344}, {'_account_id': 9681}, {'_account_id': 10153}, {'_account_id': 10386}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-12-09 22:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a3dc913edf20ea43442601a0dbf1cae1d7f737fe', 'message': 'Decompose OFAgent mechanism driver from neutron tree completely\n\nAll 3rd-party code is required to be removed from the neutron tree.\nThis change removes definition for ofagent mechanism driver from\nneutron repository.\n\nChange-Id: Ia21387eeaed71f38822356e22e4adbd237c1e64c\nCloses-Bug: #1524164\nDepends-On: I04c741daf12e7628e2c1e2d1b81b2b2ce1310542\n'}, {'number': 2, 'created': '2015-12-09 23:43:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a774d1625d95969e1777d188f894f0ca7526f2b0', 'message': 'Decompose OFAgent mechanism driver from neutron tree completely\n\nAll 3rd-party code is required to be removed from the neutron tree.\nThis change removes definition for ofagent mechanism driver from\nneutron repository.\n\nChange-Id: Ia21387eeaed71f38822356e22e4adbd237c1e64c\nCloses-Bug: #1524164\nDepends-On: I04c741daf12e7628e2c1e2d1b81b2b2ce1310542\n'}, {'number': 3, 'created': '2015-12-10 11:18:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c861f415776ccbaf777c4ecae3cfeee2ddff5141', 'message': 'Decompose OFAgent mechanism driver from neutron tree completely\n\nAll 3rd-party code is required to be removed from the neutron tree.\nThis change removes definition for ofagent mechanism driver from\nneutron repository.\n\nChange-Id: Ia21387eeaed71f38822356e22e4adbd237c1e64c\nCloses-Bug: #1524164\nDepends-On: I04c741daf12e7628e2c1e2d1b81b2b2ce1310542\n'}, {'number': 4, 'created': '2015-12-10 13:45:28.000000000', 'files': ['etc/neutron/plugins/ml2/.placeholder', 'neutron/plugins/ml2/drivers/ofagent/driver.py', 'setup.cfg', 'etc/neutron/plugins/ml2/ml2_conf_ofa.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee78b063c7652d52be81fcc8eb41dbf24d459ecc', 'message': 'Decompose OFAgent mechanism driver from neutron tree completely\n\nAll 3rd-party code is required to be removed from the neutron tree.\nThis change removes definition for ofagent mechanism driver from\nneutron repository.\n\nChange-Id: Ia21387eeaed71f38822356e22e4adbd237c1e64c\nCloses-Bug: #1524164\nDepends-On: I04c741daf12e7628e2c1e2d1b81b2b2ce1310542\n'}]",4,255579,ee78b063c7652d52be81fcc8eb41dbf24d459ecc,55,14,4,8344,,,0,"Decompose OFAgent mechanism driver from neutron tree completely

All 3rd-party code is required to be removed from the neutron tree.
This change removes definition for ofagent mechanism driver from
neutron repository.

Change-Id: Ia21387eeaed71f38822356e22e4adbd237c1e64c
Closes-Bug: #1524164
Depends-On: I04c741daf12e7628e2c1e2d1b81b2b2ce1310542
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/255579/4 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/ofagent/driver.py', 'neutron/plugins/ml2/drivers/ofagent/__init__.py', 'setup.cfg', 'etc/neutron/plugins/ml2/ml2_conf_ofa.ini']",4,a3dc913edf20ea43442601a0dbf1cae1d7f737fe,bug/1524164,,"# Defines configuration options specific to the OpenFlow Agent Mechanism Driver [ovs] # Please refer to configuration options to the OpenvSwitch [agent] # (IntOpt) Number of seconds to retry acquiring an Open vSwitch datapath. # This is an optional parameter, default value is 60 seconds. # # get_datapath_retry_times = # Example: get_datapath_retry_times = 30 # Please refer to configuration options to the OpenvSwitch else the above. ",0,35
openstack%2Fshade~master~I0951765193459300f08b0ab804e6ca327c6fa57d,openstack/shade,master,I0951765193459300f08b0ab804e6ca327c6fa57d,Bug fix: delete_object() returns True/False,MERGED,2015-12-11 20:47:01.000000000,2015-12-11 22:47:48.000000000,2015-12-11 22:47:47.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2015-12-11 20:47:01.000000000', 'files': ['shade/tests/unit/test_object.py', 'releasenotes/notes/delete-obj-return-a3ecf0415b7a2989.yaml', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/8d5abfbf56a5620d1326d44dee8ffdc9dfba1c62', 'message': 'Bug fix: delete_object() returns True/False\n\nOur delete APIs return True if the delete succeeded, or False if\nthe thing being deleted was not found. delete_object() was not doing\nthis, so this makes it consistent with the other delete API calls.\n\nAlso adds missing unit tests for this method.\n\nChange-Id: I0951765193459300f08b0ab804e6ca327c6fa57d\n'}]",0,256741,8d5abfbf56a5620d1326d44dee8ffdc9dfba1c62,6,2,1,3099,,,0,"Bug fix: delete_object() returns True/False

Our delete APIs return True if the delete succeeded, or False if
the thing being deleted was not found. delete_object() was not doing
this, so this makes it consistent with the other delete API calls.

Also adds missing unit tests for this method.

Change-Id: I0951765193459300f08b0ab804e6ca327c6fa57d
",git fetch https://review.opendev.org/openstack/shade refs/changes/41/256741/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_object.py', 'releasenotes/notes/delete-obj-return-a3ecf0415b7a2989.yaml', 'shade/openstackcloud.py']",3,8d5abfbf56a5620d1326d44dee8ffdc9dfba1c62,coverage," """"""Delete an object from a container. :param string container: Name of the container holding the object. :param string name: Name of the object to delete. :returns: True if delete succeeded, False if the object was not found. :raises: OpenStackCloudException on operation error. """""" if not self.get_object_metadata(container, name): return False return True"," if not self.get_object_metadata(container, name): return",50,1
openstack%2Fnetworking-odl~master~I82c036ed028fadff608b38d839db3b8b67d790a8,openstack/networking-odl,master,I82c036ed028fadff608b38d839db3b8b67d790a8,Update Oracle's JDK url to 1.8.0_66.,MERGED,2015-12-07 23:04:25.000000000,2015-12-11 22:45:09.000000000,2015-12-11 22:45:08.000000000,"[{'_account_id': 3}, {'_account_id': 333}, {'_account_id': 2874}, {'_account_id': 10386}, {'_account_id': 11952}, {'_account_id': 17377}]","[{'number': 1, 'created': '2015-12-07 23:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/3521e6f7c633517d162742d0d521d019f838160f', 'message': 'Update download url for Oracle JDK 8.\n\nChange-Id: I82c036ed028fadff608b38d839db3b8b67d790a8\n'}, {'number': 2, 'created': '2015-12-08 02:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/7c017c471025795a8d464bb8e2a7dfe7529c8103', 'message': 'Update download url for Oracle JDK 8.\n\nChange-Id: I82c036ed028fadff608b38d839db3b8b67d790a8\n'}, {'number': 3, 'created': '2015-12-08 05:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/cb133981f39a6cf4eceb96e98f4b44941e80137c', 'message': 'Update download url for Oracle JDK 8.\n\nChange-Id: I82c036ed028fadff608b38d839db3b8b67d790a8\n'}, {'number': 4, 'created': '2015-12-08 16:47:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/31e9772d76e74b2d7847e2c0d63775ef6a32395f', 'message': ""Update Oracle's JDK url to 1.8.0_66.\n\nChange-Id: I82c036ed028fadff608b38d839db3b8b67d790a8\n""}, {'number': 5, 'created': '2015-12-11 09:13:11.000000000', 'files': ['devstack/setup_java.sh'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/20226b3e9f85c6b1b985733f511c2c651fa7ac26', 'message': ""Update Oracle's JDK url to 1.8.0_66.\n\nChange-Id: I82c036ed028fadff608b38d839db3b8b67d790a8\n""}]",2,254432,20226b3e9f85c6b1b985733f511c2c651fa7ac26,23,6,5,17377,,,0,"Update Oracle's JDK url to 1.8.0_66.

Change-Id: I82c036ed028fadff608b38d839db3b8b67d790a8
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/32/254432/5 && git format-patch -1 --stdout FETCH_HEAD,['devstack/setup_java.sh'],1,3521e6f7c633517d162742d0d521d019f838160f,bug/1467949,"ORACLE_JAVA8_URL=""${LAST_ORACLE_JAVA8_URL:-$ORACLE_JAVA_URL/8u66-b17/jdk-8u66}"" ORACLE_JAVA8_NAME=""jdk1.8.0_66""","ORACLE_JAVA8_URL=""${LAST_ORACLE_JAVA8_URL:-$ORACLE_JAVA_URL/8u60-b27/jdk-8u60}"" ORACLE_JAVA8_NAME=""jdk1.8.0_60""",2,2
openstack%2Fneutron-vpnaas~master~I4a6094b8218dfd320d05bfb1e3bc121e8930c551,openstack/neutron-vpnaas,master,I4a6094b8218dfd320d05bfb1e3bc121e8930c551,Automatically generate neutron VPNaaS configuration files,MERGED,2015-12-04 09:16:00.000000000,2015-12-11 22:43:34.000000000,2015-12-11 22:43:33.000000000,"[{'_account_id': 3}, {'_account_id': 6524}, {'_account_id': 6659}, {'_account_id': 7293}, {'_account_id': 8655}, {'_account_id': 9515}, {'_account_id': 9551}, {'_account_id': 10692}, {'_account_id': 12403}]","[{'number': 1, 'created': '2015-12-04 09:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/eca1201a05d6f18452d2cae3f2029345623b7e7f', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 2, 'created': '2015-12-04 10:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/936b145bcba99e879df5c942ac822dbe3d59109a', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 3, 'created': '2015-12-07 16:11:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/014383a9e7a610aea175a4c500b57b18afb75e89', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 4, 'created': '2015-12-08 12:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/738fda929c09a1e7ce5cca2cc9f2cf35d48e7a73', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nDocImpact: Update the docs that VPNaaS no longer includes static example\nconfiguration files. Instead, use tools/generate_config_file_samples.sh\nto generate them and the files generated now end with .sample extension.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 5, 'created': '2015-12-08 18:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/ee074c3cd99b1a74fe012a8d6d0d04886acd8193', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nDocImpact: Update the docs that VPNaaS no longer includes static example\nconfiguration files. Instead, use tools/generate_config_file_samples.sh\nto generate them and the files generated now end with .sample extension.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 6, 'created': '2015-12-10 12:06:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/2e15afbb72f67c584ce4f68c80f8ebf981a38207', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nDocImpact: Update the docs that VPNaaS no longer includes static example\nconfiguration files. Instead, use tools/generate_config_file_samples.sh\nto generate them and the files generated now end with .sample extension.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 7, 'created': '2015-12-10 15:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/f5f5ac6d7a4d3fad11cedf055b67edaed955e478', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nDocImpact: Update the docs that VPNaaS no longer includes static example\nconfiguration files. Instead, use tools/generate_config_file_samples.sh\nto generate them and the files generated now end with .sample extension.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}, {'number': 8, 'created': '2015-12-11 11:04:37.000000000', 'files': ['.gitignore', 'neutron_vpnaas/opts.py', 'etc/oslo-config-generator/vpn_agent.ini', 'etc/README.txt', 'devstack/plugin.sh', 'releasenotes/notes/config-file-generation-0dcf19f5d8baaf5d.yaml', 'tools/generate_config_file_samples.sh', 'etc/oslo-config-generator/neutron_vpnaas.conf', 'neutron_vpnaas/services/vpn/agent.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'setup.cfg', 'tox.ini', 'tools/configure_for_vpn_func_testing.sh'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/5c8941eeed6dabc9c467c8b9b11df79a25dd2c71', 'message': 'Automatically generate neutron VPNaaS configuration files\n\nThis adds a new tox environment, genconfig, which generates sample\nneutron VPNaaS configuration file using oslo-config-generator.\n\nUpdates to some configuration option help messages to reflect useful\ndetails that were missing in the code but were present in config files.\n\nDocImpact: Update the docs that VPNaaS no longer includes static example\nconfiguration files. Instead, use tools/generate_config_file_samples.sh\nto generate them and the files generated now end with .sample extension.\n\nPartially-Implements: blueprint autogen-neutron-conf-file\n\nChange-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551\nPartial-bug: #1199963\n'}]",21,253399,5c8941eeed6dabc9c467c8b9b11df79a25dd2c71,54,9,8,9551,,,0,"Automatically generate neutron VPNaaS configuration files

This adds a new tox environment, genconfig, which generates sample
neutron VPNaaS configuration file using oslo-config-generator.

Updates to some configuration option help messages to reflect useful
details that were missing in the code but were present in config files.

DocImpact: Update the docs that VPNaaS no longer includes static example
configuration files. Instead, use tools/generate_config_file_samples.sh
to generate them and the files generated now end with .sample extension.

Partially-Implements: blueprint autogen-neutron-conf-file

Change-Id: I4a6094b8218dfd320d05bfb1e3bc121e8930c551
Partial-bug: #1199963
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/99/253399/8 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'tools/generate_config_file_samples.sh', 'neutron_vpnaas/opts.py', 'etc/oslo-config-generator/vpn_agent.ini', 'etc/README.txt', 'setup.cfg', 'tox.ini']",7,eca1201a05d6f18452d2cae3f2029345623b7e7f,bp/autogen-neutron-conf-file, {[testenv:genconfig]commands} [testenv:genconfig] commands = {toxinidir}/tools/generate_config_file_samples.sh,,77,0
openstack%2Fswift~master~Ibe53c79cf49330332112001c02a2a6b078764130,openstack/swift,master,Ibe53c79cf49330332112001c02a2a6b078764130,Update versioned_writes doc,MERGED,2015-12-11 06:57:54.000000000,2015-12-11 22:41:24.000000000,2015-12-11 22:41:22.000000000,"[{'_account_id': 3}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 12261}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-12-11 06:57:54.000000000', 'files': ['swift/common/middleware/versioned_writes.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/19c7dbc0ba49ff7e1f59190a7ead9ae9d3d80238', 'message': 'Update versioned_writes doc\n\nChange-Id: Ibe53c79cf49330332112001c02a2a6b078764130\n'}]",0,256250,19c7dbc0ba49ff7e1f59190a7ead9ae9d3d80238,14,5,1,12261,,,0,"Update versioned_writes doc

Change-Id: Ibe53c79cf49330332112001c02a2a6b078764130
",git fetch https://review.opendev.org/openstack/swift refs/changes/50/256250/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/versioned_writes.py'],1,19c7dbc0ba49ff7e1f59190a7ead9ae9d3d80238,doc,"gone from 'versions' container and back in 'container' container:: curl -i -XGET -H ""X-Auth-Token: <token>"" \ http://<storage_url>/container/myobject",gone::,3,1
openstack%2Frequirements~master~I5e49bf8e178f5ded04b68589f36858f693db7b69,openstack/requirements,master,I5e49bf8e178f5ded04b68589f36858f693db7b69,Updated oslo.db to 4.1.0,MERGED,2015-12-08 09:21:06.000000000,2015-12-11 22:40:39.000000000,2015-12-11 22:40:38.000000000,"[{'_account_id': 3}, {'_account_id': 2592}, {'_account_id': 5638}, {'_account_id': 9569}]","[{'number': 1, 'created': '2015-12-08 09:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/76dc4f09053daf7b93bb8b7a9ee783ada19fb1ab', 'message': 'Updated oslo.db to 4.1.0\n\nNew version of oslo.db needed in Nova\nfor enginefacade.\n\nChange-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69\n'}, {'number': 2, 'created': '2015-12-08 09:21:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/cc9b1308c7753b0662b51eadf7a72cd6f4a24e46', 'message': 'Updated oslo.db to 4.1.0\n\nNew version of oslo.db is needed in Nova\nfor enginefacade.\n\nChange-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69\n'}, {'number': 3, 'created': '2015-12-08 09:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/5ad931ba1daf5e1219375a5460cc54d5bcea1c9f', 'message': 'Updated oslo.db to 4.1.0\n\nNew version of oslo.db is needed in Nova for enginefacade.\n\nChange-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69\n'}, {'number': 4, 'created': '2015-12-09 11:04:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/ed2ca9d8776d03e5cd8b351c3c142e1655c8880e', 'message': 'Updated oslo.db to 4.1.0\n\nNew version of oslo.db is needed in Nova for enginefacade.\n\nChange-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69\n'}, {'number': 5, 'created': '2015-12-11 07:22:30.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b72dd8c781507b12c54e81465d5aa78358d672a7', 'message': ""Updated oslo.db to 4.1.0\n\nNew version of oslo.db is needed in Nova for enginefacade.\nNew annotation 'allow_async' from oslo.db needed in this\npatch I339a50e53652e5690ece33ee711fbea2cca61f65.\n\nChange-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69\n""}]",0,254624,b72dd8c781507b12c54e81465d5aa78358d672a7,18,4,5,9569,,,0,"Updated oslo.db to 4.1.0

New version of oslo.db is needed in Nova for enginefacade.
New annotation 'allow_async' from oslo.db needed in this
patch I339a50e53652e5690ece33ee711fbea2cca61f65.

Change-Id: I5e49bf8e178f5ded04b68589f36858f693db7b69
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/254624/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,76dc4f09053daf7b93bb8b7a9ee783ada19fb1ab,oslo.db-4.1,oslo.db>=4.1.0 # Apache-2.0,oslo.db>=3.2.0 # Apache-2.0,1,1
openstack%2Fhorizon~master~I753fa8f2d4728ea43d5bb7fa389ce6ed2f0a5341,openstack/horizon,master,I753fa8f2d4728ea43d5bb7fa389ce6ed2f0a5341,Add swift REST API,ABANDONED,2015-12-10 23:42:09.000000000,2015-12-11 22:31:01.000000000,,"[{'_account_id': 3}, {'_account_id': 7665}]","[{'number': 1, 'created': '2015-12-10 23:42:09.000000000', 'files': ['openstack_dashboard/api/rest/__init__.py', 'openstack_dashboard/api/rest/swift.py', 'openstack_dashboard/static/app/core/openstack-service-api/swift.service.js', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/static/app/core/openstack-service-api/swift.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/2349b96898946c0435a846a8d6f3adcd9ebe762b', 'message': 'Add swift REST API\n\nAdd REST API to support angular Swift interface.\n\nChange-Id: I753fa8f2d4728ea43d5bb7fa389ce6ed2f0a5341\nCo-Author: Neill Cox <neill@ingenious.com.au>\n'}]",0,256139,2349b96898946c0435a846a8d6f3adcd9ebe762b,4,2,1,12071,,,0,"Add swift REST API

Add REST API to support angular Swift interface.

Change-Id: I753fa8f2d4728ea43d5bb7fa389ce6ed2f0a5341
Co-Author: Neill Cox <neill@ingenious.com.au>
",git fetch https://review.opendev.org/openstack/horizon refs/changes/39/256139/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/api/rest/__init__.py', 'openstack_dashboard/api/rest/swift.py', 'openstack_dashboard/static/app/core/openstack-service-api/swift.service.js', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/static/app/core/openstack-service-api/swift.service.spec.js']",5,2349b96898946c0435a846a8d6f3adcd9ebe762b,swift-api,"/* * (c) Copyright 2015 Copyright 2015, Rackspace, US, Inc. * * Licensed under the Apache License, Version 2.0 (the ""License""); * you may not use this file except in compliance with the License. * You may obtain a copy of the License at * * http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */ (function() { 'use strict'; describe('Swift API', function() { var testCall, service; var apiService = {}; var toastService = {}; beforeEach( module('horizon.mock.openstack-service-api', function($provide, initServices) { testCall = initServices($provide, apiService, toastService); }) ); beforeEach(module('horizon.app.core.openstack-service-api')); beforeEach(inject(['horizon.app.core.openstack-service-api.swift', function(swiftAPI) { service = swiftAPI; }])); it('defines the service', function() { expect(service).toBeDefined(); }); var tests = [ { ""func"": ""getVersion"", ""method"": ""get"", ""path"": ""/api/swift/version/"", ""error"": ""Unable to get the Swift service version."" } ]; // Iterate through the defined tests and apply as Jasmine specs. angular.forEach(tests, function(params) { it('defines the ' + params.func + ' call properly', function() { var callParams = [apiService, service, toastService, params]; testCall.apply(this, callParams); }); }); it('supresses the error if instructed for getNamespaces', function() { spyOn(apiService, 'get').and.returnValue(""promise""); expect(service.getNamespaces(""whatever"", true)).toBe(""promise""); }); }); })(); ",,462,0
openstack%2Fhorizon~master~I53bd0c2f553752fe22f531100dbe83c3eeb1673c,openstack/horizon,master,I53bd0c2f553752fe22f531100dbe83c3eeb1673c,Add test for the Heat Service validate method,MERGED,2015-10-19 22:46:05.000000000,2015-12-11 22:30:42.000000000,2015-12-11 22:30:40.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 9576}, {'_account_id': 9622}, {'_account_id': 12071}, {'_account_id': 14124}, {'_account_id': 17004}, {'_account_id': 17013}]","[{'number': 1, 'created': '2015-10-19 22:46:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/af433d0468c6055f0b6cf1cae4e6716d2778e569', 'message': 'Add test for the Heat Service validate method\n\nThe suppressError condition for the validate method\nis not being tested.\n\nChange-Id: I53bd0c2f553752fe22f531100dbe83c3eeb1673c\nParital-bug: #1506891\n'}, {'number': 2, 'created': '2015-11-19 07:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e617a3a3f96ffea18ecc06ebaa651ee6282a5c9f', 'message': 'Add test for the Heat Service validate method\n\nThe suppressError condition for the validate method\nis not being tested.\n\nChange-Id: I53bd0c2f553752fe22f531100dbe83c3eeb1673c\nParital-bug: #1506891\n'}, {'number': 3, 'created': '2015-12-09 16:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/289266daaad5bfa7a54cf8961bdf65de610a4873', 'message': 'Add test for the Heat Service validate method\n\nThe suppressError condition for the validate method\nis not being tested.\n\nChange-Id: I53bd0c2f553752fe22f531100dbe83c3eeb1673c\nParital-bug: #1506891\n'}, {'number': 4, 'created': '2015-12-09 23:48:04.000000000', 'files': ['openstack_dashboard/static/app/core/openstack-service-api/heat.service.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/56e4a599eb2b7b99d285fdac0c3390c99633be34', 'message': 'Add test for the Heat Service validate method\n\nThe suppressError condition for the validate method\nis not being tested.\n\nChange-Id: I53bd0c2f553752fe22f531100dbe83c3eeb1673c\nParital-bug: #1506891\n'}]",2,237272,56e4a599eb2b7b99d285fdac0c3390c99633be34,22,9,4,17013,,,0,"Add test for the Heat Service validate method

The suppressError condition for the validate method
is not being tested.

Change-Id: I53bd0c2f553752fe22f531100dbe83c3eeb1673c
Parital-bug: #1506891
",git fetch https://review.opendev.org/openstack/horizon refs/changes/72/237272/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/static/app/core/openstack-service-api/heat.service.spec.js'],1,af433d0468c6055f0b6cf1cae4e6716d2778e569,bug/1506891," it('supresses the error if instructed for validate', function() { spyOn(apiService, 'post').and.returnValue(""promise""); expect(service.validate(""whatever"", true)).toBe(""promise""); }); ",,5,0
openstack%2Fceilometer~master~Iaa6fa9ef099f617da30cc7af74aa74a845064489,openstack/ceilometer,master,Iaa6fa9ef099f617da30cc7af74aa74a845064489,Correct the host field of instance metadata,MERGED,2015-10-16 02:11:27.000000000,2015-12-11 22:29:12.000000000,2015-12-11 22:29:10.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 6924}, {'_account_id': 7729}, {'_account_id': 8290}, {'_account_id': 9526}, {'_account_id': 10987}, {'_account_id': 11564}, {'_account_id': 15843}, {'_account_id': 18137}]","[{'number': 1, 'created': '2015-10-16 02:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/b8b5518d9d53201c387711ede767dafbc4f7c059', 'message': ""Correct the host field of instance metadata\n\nFow now, the 'host' field of instance resource medata is instance.hostId,\nwhich is a hash string based on project id and hypervisor name, it is\nunfriendly to end users. This patch change it to the host name the\ninstance running on.\n\nChange-Id: Iaa6fa9ef099f617da30cc7af74aa74a845064489\nCloses-Bug: #1506610\n""}, {'number': 2, 'created': '2015-11-05 12:23:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/87398b90c4e3c3e060957946e13cef4ae1356ef8', 'message': ""Correct the host field of instance metadata\n\nFow now, the 'host' field of instance resource medata is instance.hostId,\nwhich is a hash string based on project id and hypervisor name, it is\nunfriendly to end users. This patch change it to the host name the\ninstance running on.\n\nChange-Id: Iaa6fa9ef099f617da30cc7af74aa74a845064489\nCloses-Bug: #1506610\n""}, {'number': 3, 'created': '2015-12-07 02:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/74c577301be64fd291710eb42947a4219402da05', 'message': 'Correct the host field of instance metadata\n\nFow now, the \'host\' field of instance resource medata is instance.hostId,\nwhich is a hash string based on project id and hypervisor name, it is\nhard to indicate which host the instance running on. This change add a new\nattribute ""instance_host"" to indicate the hostname of the host the\ninstance running on.\n\nChange-Id: Iaa6fa9ef099f617da30cc7af74aa74a845064489\nCloses-Bug: #1506610\n'}, {'number': 4, 'created': '2015-12-07 02:04:09.000000000', 'files': ['ceilometer/tests/unit/compute/pollsters/test_location_metadata.py', 'ceilometer/compute/pollsters/util.py', 'ceilometer/tests/unit/compute/pollsters/test_net.py'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/de5ff7303d6f278ef37149297bbb7d2e77f45a0d', 'message': 'Correct the host field of instance metadata\n\nFow now, the \'host\' field of instance resource medata is instance.hostId,\nwhich is a hash string based on project id and hypervisor name, it is\nhard to indicate which host the instance running on. This change add a new\ninstance metadata field ""instance_host"" to indicate the hostname of the\nhost the instance running on.\n\nChange-Id: Iaa6fa9ef099f617da30cc7af74aa74a845064489\nCloses-Bug: #1506610\n'}]",0,235702,de5ff7303d6f278ef37149297bbb7d2e77f45a0d,46,12,4,8290,,,0,"Correct the host field of instance metadata

Fow now, the 'host' field of instance resource medata is instance.hostId,
which is a hash string based on project id and hypervisor name, it is
hard to indicate which host the instance running on. This change add a new
instance metadata field ""instance_host"" to indicate the hostname of the
host the instance running on.

Change-Id: Iaa6fa9ef099f617da30cc7af74aa74a845064489
Closes-Bug: #1506610
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/02/235702/3 && git format-patch -1 --stdout FETCH_HEAD,"['ceilometer/tests/unit/compute/pollsters/test_location_metadata.py', 'ceilometer/compute/pollsters/util.py', 'ceilometer/tests/unit/compute/pollsters/test_net.py']",3,b8b5518d9d53201c387711ede767dafbc4f7c059,bug/1506610," 'OS-EXT-SRV-ATTR:host': 'host-test',"," 'hostId': '1234-5678',",4,4
openstack%2Fmonasca-ceilometer~master~I98ad72337ed50b2f6703afc2e7c4e4689590b2c7,openstack/monasca-ceilometer,master,I98ad72337ed50b2f6703afc2e7c4e4689590b2c7,Implements groupby for statistics API,MERGED,2015-12-07 19:12:22.000000000,2015-12-11 22:26:20.000000000,2015-12-11 22:26:20.000000000,"[{'_account_id': 3}, {'_account_id': 7052}, {'_account_id': 13560}]","[{'number': 1, 'created': '2015-12-07 19:12:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/24e0f3118b910fb8e7943ff6bdca220058be858f', 'message': 'Implements groupby for statistics API\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 2, 'created': '2015-12-07 23:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/1bcd9fea328f1bf8e4b1a192824212a0c827d1aa', 'message': 'Implements groupby for statistics API\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 3, 'created': '2015-12-08 01:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/4a52e5a54827643e1f680011cf1576e3750c5871', 'message': 'Implements groupby for statistics API\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 4, 'created': '2015-12-08 19:25:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/c8176d8462d4c8a4e73cfff5dc622f563aa9cd3f', 'message': 'Implements groupby for statistics API\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 5, 'created': '2015-12-09 00:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/e74246f3705e17dc56c08698c74572e27c372911', 'message': 'Implements groupby for statistics API\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 6, 'created': '2015-12-09 07:02:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/9b6f033b3e8c9354923792774036e2b0ee6884e4', 'message': 'Implements groupby for statistics API\n\nQueries for metrics to obtain all dimensions\nbefore quering for statistics with merge_metrics\nas False, which returns response with dimensions.\n\nThe statistics response with dimensions is used to\nperform in-memory computations based on the groupby\ndimension. Only a single groupby is supported.\n\nThe current implementation is memory-intensive and\ncan be improved further to constrain memory usage.\nThis patch is an initial step in that direction.\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 7, 'created': '2015-12-09 18:40:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/eb04dfac7699fbe7168e3bbc98d56bb086040e38', 'message': 'Implements groupby for statistics API\n\nQueries for metrics to obtain all dimensions\nbefore quering for statistics with merge_metrics\nas False, which returns response with dimensions.\n\nThe statistics response with dimensions is used to\nperform in-memory computations based on the groupby\ndimension. Only a single groupby is supported.\n\nThe current implementation is memory-intensive and\ncan be improved further to constrain memory usage.\nThis patch is an initial step in that direction.\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}, {'number': 8, 'created': '2015-12-11 17:07:08.000000000', 'files': ['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/b704e3f9c75bcad3ebe1ebffe551b47cbc7ec1a2', 'message': 'Implements groupby for statistics API\n\nQueries for metrics to obtain all dimensions\nbefore quering for statistics with merge_metrics\nas False, which returns response with dimensions.\n\nThe statistics response with dimensions is used to\nperform in-memory computations based on the groupby\ndimension. Only a single groupby is supported.\n\nThe current implementation is memory-intensive and\ncan be improved further to constrain memory usage.\nThis patch is an initial step in that direction.\n\nChange-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7\n'}]",0,254352,b704e3f9c75bcad3ebe1ebffe551b47cbc7ec1a2,28,3,8,13560,,,0,"Implements groupby for statistics API

Queries for metrics to obtain all dimensions
before quering for statistics with merge_metrics
as False, which returns response with dimensions.

The statistics response with dimensions is used to
perform in-memory computations based on the groupby
dimension. Only a single groupby is supported.

The current implementation is memory-intensive and
can be improved further to constrain memory usage.
This patch is an initial step in that direction.

Change-Id: I98ad72337ed50b2f6703afc2e7c4e4689590b2c7
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/52/254352/8 && git format-patch -1 --stdout FETCH_HEAD,"['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py']",2,24e0f3118b910fb8e7943ff6bdca220058be858f,statistics/groupby," self.assertRaisesWithMessage(""Groupby message_id not implemented"", groupby=['message_id'])))"," self.assertRaisesWithMessage(""Groupby not implemented"", groupby=""resource_id"")))",185,42
openstack%2Fmonasca-ceilometer~master~Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91,openstack/monasca-ceilometer,master,Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91,Handles input aggregate for statistics,MERGED,2015-12-07 06:56:22.000000000,2015-12-11 22:26:14.000000000,2015-12-11 22:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 7052}, {'_account_id': 12637}, {'_account_id': 17287}]","[{'number': 1, 'created': '2015-12-07 06:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/2b4e44836218148f119b64582187c42965397bca', 'message': 'Handles input aggregate for statistics\n\nWhen statistics API is used with custom\naggregates as input, there is an attribute\nerror in client as it expects an aggregate\ndict in response.\n\nThis adds the aggregate dict in response\nwhen input has an aggregate function.\n\nChange-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91\n'}, {'number': 2, 'created': '2015-12-08 01:23:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/457a1c743bd46c433adf6a42082f5fe4f06c0a9e', 'message': 'Handles input aggregate for statistics\n\nWhen statistics API is used with custom\naggregates as input, there is an attribute\nerror in client as it expects an aggregate\ndict in response.\n\nThis adds the aggregate dict in response\nwhen input has an aggregate function.\n\nChange-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91\n'}, {'number': 3, 'created': '2015-12-08 02:03:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/a8f63e4ec315e95b67cdb05af578dce5dc9ecb08', 'message': 'Handles input aggregate for statistics\n\nWhen statistics API is used with custom\naggregates as input, there is an attribute\nerror in client as it expects an aggregate\ndict in response.\n\nThis adds the aggregate dict in response\nwhen input has an aggregate function.\n\nChange-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91\n'}, {'number': 4, 'created': '2015-12-08 19:24:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/88bc18563d54c9a8f12ccf09dabae773ee2ad40c', 'message': 'Handles input aggregate for statistics\n\nWhen statistics API is used with custom\naggregates as input, there is an attribute\nerror in client as it expects an aggregate\ndict in response.\n\nThis adds the aggregate dict in response\nwhen input has an aggregate function.\n\nChange-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91\n'}, {'number': 5, 'created': '2015-12-11 17:06:45.000000000', 'files': ['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/9c2c1e878eaa7663b50fd90f7ed5d78181840fbc', 'message': 'Handles input aggregate for statistics\n\nWhen statistics API is used with custom\naggregates as input, there is an attribute\nerror in client as it expects an aggregate\ndict in response.\n\nThis adds the aggregate dict in response\nwhen input has an aggregate function.\n\nChange-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91\n'}]",0,254034,9c2c1e878eaa7663b50fd90f7ed5d78181840fbc,16,4,5,13560,,,0,"Handles input aggregate for statistics

When statistics API is used with custom
aggregates as input, there is an attribute
error in client as it expects an aggregate
dict in response.

This adds the aggregate dict in response
when input has an aggregate function.

Change-Id: Ide13f5d16b6e4ef11cdcb9c98d85200efaf0cb91
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/34/254034/1 && git format-patch -1 --stdout FETCH_HEAD,['ceilosca/ceilometer/storage/impl_monasca.py'],1,2b4e44836218148f119b64582187c42965397bca,statistics/aggregate," if aggregate: stats_dict['aggregate'] = {} for a in aggregate: key = '%s%s' % (a.func, '/%s' % a.param if a.param else '') stats_dict['aggregate'][key] = stats_dict.get(key) ",,7,0
openstack%2Fmonasca-ceilometer~master~I67055a661478fc15a06c3714f431c484f303658c,openstack/monasca-ceilometer,master,I67055a661478fc15a06c3714f431c484f303658c,Fixes statistics API when timestamp is specified,MERGED,2015-12-05 01:42:40.000000000,2015-12-11 22:25:43.000000000,2015-12-11 22:25:42.000000000,"[{'_account_id': 3}, {'_account_id': 7052}, {'_account_id': 12637}, {'_account_id': 19354}]","[{'number': 1, 'created': '2015-12-05 01:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/63aea93babab5992d92f7a49ee97ee94b93756bb', 'message': 'Fixes statistics API when timestamp is specified\n\nWhen timestamp/timestamp range is specified,\nstatistics API fails because timestamps are not\nbeing converted to ISO 8601 formatted times, also\nwhen parsing the response, the timezone offsets are\nnot being dropped.\n\nThis patch fixes that so that statistics API works\nwhen timestamps are specified in input filter.\n\nChange-Id: I67055a661478fc15a06c3714f431c484f303658c\n'}, {'number': 2, 'created': '2015-12-11 17:01:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/3f6c9816f34e47d3203d604faed2e156dd40b523', 'message': 'Fixes statistics API when timestamp is specified\n\nWhen timestamp/timestamp range is specified,\nstatistics API fails because timestamps are not\nbeing converted to ISO 8601 formatted times, also\nwhen parsing the response, the timezone offsets are\nnot being dropped.\n\nMonasca API expects timestamps in ISO 8601 format\nand ceilometer statistics API expects timestamp in\nresponse in a timezone-naive format.\n\nThis patch fixes that so that statistics API works\nwhen timestamps are specified in input filter.\n\nChange-Id: I67055a661478fc15a06c3714f431c484f303658c\n'}, {'number': 3, 'created': '2015-12-11 17:04:09.000000000', 'files': ['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/948d96f76cd871d0668d346a8bf6fd8bd1c02921', 'message': 'Fixes statistics API when timestamp is specified\n\nWhen timestamp/timestamp range is specified,\nstatistics API fails because timestamps are not\nbeing converted to ISO 8601 formatted times, also\nwhen parsing the response, the timezone offsets are\nnot being dropped.\n\nMonasca API expects timestamps in ISO 8601 format\nand ceilometer statistics API expects timestamp in\nresponse in a timezone-naive format.\n\nThis patch fixes that so that statistics API works\nwhen timestamps are specified in input filter.\n\nChange-Id: I67055a661478fc15a06c3714f431c484f303658c\n'}]",0,253761,948d96f76cd871d0668d346a8bf6fd8bd1c02921,10,4,3,13560,,,0,"Fixes statistics API when timestamp is specified

When timestamp/timestamp range is specified,
statistics API fails because timestamps are not
being converted to ISO 8601 formatted times, also
when parsing the response, the timezone offsets are
not being dropped.

Monasca API expects timestamps in ISO 8601 format
and ceilometer statistics API expects timestamp in
response in a timezone-naive format.

This patch fixes that so that statistics API works
when timestamps are specified in input filter.

Change-Id: I67055a661478fc15a06c3714f431c484f303658c
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/61/253761/2 && git format-patch -1 --stdout FETCH_HEAD,"['ceilosca/ceilometer/storage/impl_monasca.py', 'ceilosca/ceilometer/tests/unit/storage/test_impl_monasca.py']",2,63aea93babab5992d92f7a49ee97ee94b93756bb,fix/statistics/api," sf.start_timestamp = timeutils.parse_isotime( '2014-10-24T12:12:42').replace(tzinfo=None) self.assertEqual('2014-10-24T12:12:42', self.assertEqual('2014-10-24T12:52:42',"," self.assertEqual('2014-10-24T12:12:42+00:00', self.assertEqual('2014-10-24T12:52:42+00:00',",13,4
openstack%2Fheat~master~Id6b4ab7a56b6a6339263dd45363b0867b46777fa,openstack/heat,master,Id6b4ab7a56b6a6339263dd45363b0867b46777fa,Add cmd_resource option to NeutronClient.resolve,ABANDONED,2015-11-02 22:21:13.000000000,2015-12-11 22:20:33.000000000,,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 7128}, {'_account_id': 7404}, {'_account_id': 8289}, {'_account_id': 11832}, {'_account_id': 18389}]","[{'number': 1, 'created': '2015-11-02 22:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/6895250ed31ddc7734f457237cd6927ef8e27ee2', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving resources multiple version of resources which\nhave are not compatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 2, 'created': '2015-11-03 20:21:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8f0c67a9b34014832628a5987d1551b7bda674f2', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving resources multiple version of resources which\nhave are not compatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 3, 'created': '2015-11-09 22:30:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/e3f33ad370363301706c38759259e3f5139c1863', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 4, 'created': '2015-11-11 22:10:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ef0196553d02a0ff4bb744b5b5973096975df4a9', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 5, 'created': '2015-11-13 15:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/5aa497c40014daa5ca106601697301845c66fc3c', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 6, 'created': '2015-11-20 16:15:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/42e5897c8df579e37846a0762cd0a24b111fb291', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 7, 'created': '2015-12-01 15:47:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/0c5973f5d09f53928f678650528a5e0a808d5d4b', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 8, 'created': '2015-12-01 16:08:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/f422cc8af2bf34cf025c668a55210004f475c302', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 9, 'created': '2015-12-02 19:14:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/8e24ca5688075642cba4ca3384c6d469bf0e0709', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 10, 'created': '2015-12-07 17:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/23628b0802ac63e188e82eaf9244a984d75ab80c', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 11, 'created': '2015-12-09 20:09:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/cd3a80f04a4b67f15a1c337cfe0279adc08abf7c', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}, {'number': 12, 'created': '2015-12-09 21:52:11.000000000', 'files': ['heat/tests/clients/test_neutron_client.py', 'heat/tests/openstack/neutron/test_neutron_vpnservice.py', 'heat/engine/resources/openstack/neutron/subnetpool.py', 'heat/engine/clients/os/neutron/lbaas_constraints.py', 'heat/tests/openstack/neutron/test_neutron_net.py', 'heat/engine/resources/openstack/neutron/subnet.py', 'heat/tests/openstack/neutron/test_neutron_subnet.py', 'heat/tests/openstack/neutron/test_neutron_floating_ip.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/tests/openstack/neutron/test_neutron_router.py', 'heat/engine/clients/os/neutron/neutron_constraints.py', 'heat/tests/openstack/neutron/test_neutron_network_gateway.py', 'heat/tests/openstack/neutron/test_neutron_port.py', 'heat/tests/openstack/neutron/test_neutron_loadbalancer.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/91cf0ce219a612c416283c1d2f585e9ffd3f2403', 'message': ""Add cmd_resource option to NeutronClient.resolve\n\nThis option needs to be added to the NeutronClient _resolve method\nto allow for resolving multiple version of resources which are not\ncompatible.\n\nFor example, the lbaas v1 pool and lbaas v2 pools are incompatible,\nand must be differentiated when making requests. The v1 pool can be\nfound without specifying any cmd_resource, while the v2 pool will\nneed cmd_resource to be set to 'lbaas_pool'.\n\nBlueprint: lbaasv2-suport\n\nChange-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa\n""}]",2,241008,91cf0ce219a612c416283c1d2f585e9ffd3f2403,37,7,12,11832,,,0,"Add cmd_resource option to NeutronClient.resolve

This option needs to be added to the NeutronClient _resolve method
to allow for resolving multiple version of resources which are not
compatible.

For example, the lbaas v1 pool and lbaas v2 pools are incompatible,
and must be differentiated when making requests. The v1 pool can be
found without specifying any cmd_resource, while the v2 pool will
need cmd_resource to be set to 'lbaas_pool'.

Blueprint: lbaasv2-suport

Change-Id: Id6b4ab7a56b6a6339263dd45363b0867b46777fa
",git fetch https://review.opendev.org/openstack/heat refs/changes/08/241008/12 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/clients/test_neutron_client.py', 'heat/tests/neutron/test_neutron_vpnservice.py', 'heat/engine/clients/os/neutron/lbaas.py', 'heat/tests/neutron/test_neutron_floating_ip.py', 'heat/tests/neutron/test_neutron_loadbalancer.py', 'heat/tests/neutron/test_neutron_port.py', 'heat/tests/neutron/test_neutron_subnet.py', 'heat/tests/neutron/test_neutron_router.py', 'heat/tests/neutron/test_neutron_network_gateway.py', 'heat/tests/neutron/test_neutron_net.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/engine/clients/os/neutron/neutron.py']",12,6895250ed31ddc7734f457237cd6927ef8e27ee2,bp/lbaasv2-suport," neutron_client, 'network', value, cmd_resource=None) neutron_client, 'port', value, cmd_resource=None) neutron_client, 'router', value, cmd_resource=None) neutron_client, 'subnet', value, cmd_resource=None)"," neutron_client, 'network', value) neutron_client, 'port', value) neutron_client, 'router', value) neutron_client, 'subnet', value)",167,89
openstack%2Fapi-site~master~Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7,openstack/api-site,master,Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7,[Dataprocessing-API] Documented the Response parameters of APIs,MERGED,2015-12-01 18:51:05.000000000,2015-12-11 22:04:59.000000000,2015-12-11 22:04:58.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 10497}, {'_account_id': 16237}, {'_account_id': 17207}]","[{'number': 1, 'created': '2015-12-01 18:51:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/82837923c7f382e26db9c0a4a7c6727f78599133', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 2, 'created': '2015-12-02 00:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/db03e9c2e5d8d65880e66384c6fb5b9bb3c0d5e9', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 3, 'created': '2015-12-02 01:00:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/6d08f3801aa7873250e859891275ba587cb73781', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 4, 'created': '2015-12-02 01:18:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/ec7cd351264f227c4d8fc04c6ffbc09350431c47', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 5, 'created': '2015-12-03 01:42:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/cfece2bbaf7faa516c3d07f344bd516137b768d0', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 6, 'created': '2015-12-08 01:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/28600eb41534690170fff3f3ccd5bebae4e7b0d2', 'message': '[WIP][Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 7, 'created': '2015-12-08 01:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/86acc71ff7ed47397a5826ff0c2b81ee2494a199', 'message': '[Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 8, 'created': '2015-12-11 14:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/47b529b9fadf28956de927df076268b64401d864', 'message': '[Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 9, 'created': '2015-12-11 14:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/api-site/commit/c8bbb0443ff72b78228ec1c6fc2b6f0c349605a3', 'message': '[Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}, {'number': 10, 'created': '2015-12-11 21:34:52.000000000', 'files': ['api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/data-sources.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/plugins.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/clusters.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/cluster-templates.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/event-log.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-executions.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/node-group-template.wadl', 'api-ref/src/docbkx/ch_data-processing-v1.1.xml', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/common.ent', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/image-registry.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-binaries.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-binary-internals.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/jobs.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-types.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/119062d3fde5d0a9b9b011a1f0832f7ef35192e1', 'message': '[Dataprocessing-API] Documented the Response parameters of APIs\n\nChange-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7\nCloses-Bug: #1521435\nCloses-Bug: #1521434\n'}]",5,252016,119062d3fde5d0a9b9b011a1f0832f7ef35192e1,35,5,10,16237,,,0,"[Dataprocessing-API] Documented the Response parameters of APIs

Change-Id: Iddc77a8bdaf5a1a3ff05c6c932a7e80742bb48a7
Closes-Bug: #1521435
Closes-Bug: #1521434
",git fetch https://review.opendev.org/openstack/api-site refs/changes/16/252016/10 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/data-sources.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/plugins.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/clusters.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/cluster-templates.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-executions.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/node-group-template.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/common.ent', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/image-registry.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-binaries.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-binary-internals.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/jobs.wadl', 'api-ref/src/wadls/dataprocessing-api/src/v1.1/wadl/job-types.wadl']",12,82837923c7f382e26db9c0a4a7c6727f78599133,bug/1521435, &jobtypesResponseParameters; &pluginResponseParameters;,,1376,0
openstack%2Fapi-site~master~If98ca9975a7c39217116d94d98bf6bc16be28bc2,openstack/api-site,master,If98ca9975a7c39217116d94d98bf6bc16be28bc2,Fix a response code for show object metadata,MERGED,2015-12-09 09:01:02.000000000,2015-12-11 22:04:23.000000000,2015-12-11 22:04:22.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 16237}, {'_account_id': 17207}]","[{'number': 1, 'created': '2015-12-09 09:01:02.000000000', 'files': ['api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/e5fc44c1a61f5d6ebaa58353c9899541f84d4abf', 'message': 'Fix a response code for show object metadata\n\nWhen show object metadata succeeded, the response code is 200 but\napi-ref description is 204. So this patch fixes the response code\nfrom 204 to 200.\n\nChange-Id: If98ca9975a7c39217116d94d98bf6bc16be28bc2\nCloses-Bug: #1524159\n'}]",0,255139,e5fc44c1a61f5d6ebaa58353c9899541f84d4abf,9,4,1,12193,,,0,"Fix a response code for show object metadata

When show object metadata succeeded, the response code is 200 but
api-ref description is 204. So this patch fixes the response code
from 204 to 200.

Change-Id: If98ca9975a7c39217116d94d98bf6bc16be28bc2
Closes-Bug: #1524159
",git fetch https://review.opendev.org/openstack/api-site refs/changes/39/255139/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/object-api/src/os-object-api-1.0.wadl'],1,e5fc44c1a61f5d6ebaa58353c9899541f84d4abf,bug/1524159," <code>200</code> response code.</para> <response status=""200""> &Last-Modified-ResponseHeader;"," <code>204</code> response code.</para> <response status=""204""> &Last-Modified-ResponseHeader;",2,2
openstack%2Fapi-site~master~I6b60ca5b4334943b6b6ef008e11d981a49ec6f0d,openstack/api-site,master,I6b60ca5b4334943b6b6ef008e11d981a49ec6f0d,create volume and create snapshot returns 200,MERGED,2015-12-08 09:49:28.000000000,2015-12-11 22:04:21.000000000,2015-12-11 22:04:20.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 2448}, {'_account_id': 8556}]","[{'number': 1, 'created': '2015-12-08 09:49:28.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volumes-v2.1.wadl'], 'web_link': 'https://opendev.org/openstack/api-site/commit/9bdbabbdfa17f9826c88eb7eb90f47e3e8a739c2', 'message': 'create volume and create snapshot returns 200\n\nThe current doc mentioned return 201, instead it returns\n200 in the code\n\nChange-Id: I6b60ca5b4334943b6b6ef008e11d981a49ec6f0d\nPartial-Bug: #1515222\n'}]",0,254642,9bdbabbdfa17f9826c88eb7eb90f47e3e8a739c2,9,4,1,6062,,,0,"create volume and create snapshot returns 200

The current doc mentioned return 201, instead it returns
200 in the code

Change-Id: I6b60ca5b4334943b6b6ef008e11d981a49ec6f0d
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/42/254642/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/wadl/os-volumes-v2.1.wadl'],1,9bdbabbdfa17f9826c88eb7eb90f47e3e8a739c2,fix-compute-api-ref," <response status=""200""> <response status=""200"">"," <response status=""201""> <response status=""201"">",2,2
openstack%2Fapi-site~master~Ie4c3c17fbbe914318345a7f56917060c0622c520,openstack/api-site,master,Ie4c3c17fbbe914318345a7f56917060c0622c520,The tenant id response is not optional,MERGED,2015-12-10 14:10:17.000000000,2015-12-11 22:04:12.000000000,2015-12-11 22:04:11.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 14:10:17.000000000', 'files': ['api-ref/src/wadls/compute-api/src/v2.1/common.ent'], 'web_link': 'https://opendev.org/openstack/api-site/commit/a5cf7ad510f2a59ffdfeeb8579c515f986a8575c', 'message': 'The tenant id response is not optional\n\nthe response is not optional.\n\nChange-Id: Ie4c3c17fbbe914318345a7f56917060c0622c520\nPartial-Bug: #1515222\n'}]",0,255890,a5cf7ad510f2a59ffdfeeb8579c515f986a8575c,7,3,1,6062,,,0,"The tenant id response is not optional

the response is not optional.

Change-Id: Ie4c3c17fbbe914318345a7f56917060c0622c520
Partial-Bug: #1515222
",git fetch https://review.opendev.org/openstack/api-site refs/changes/90/255890/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/wadls/compute-api/src/v2.1/common.ent'],1,a5cf7ad510f2a59ffdfeeb8579c515f986a8575c,nova-api-compute-server-response-not-optional," required=""true""",,1,0
openstack%2Fopenstack-health~master~I467513cc62b6605ac3f8d1719bf042b133f14116,openstack/openstack-health,master,I467513cc62b6605ac3f8d1719bf042b133f14116,Don't fix run_time to 2 decimal places,MERGED,2015-12-11 21:12:20.000000000,2015-12-11 21:59:55.000000000,2015-12-11 21:59:55.000000000,"[{'_account_id': 3}, {'_account_id': 17001}]","[{'number': 1, 'created': '2015-12-11 21:12:20.000000000', 'files': ['app/js/controllers/test.js'], 'web_link': 'https://opendev.org/openstack/openstack-health/commit/f522a85d8ea4a81b0f4be2155fdbecc6c9860e72', 'message': ""Don't fix run_time to 2 decimal places\n\nThe per test pages were fixing the run_time value to 2 decimal places,\nthis was likely in an attempt to make the any written numbers be more\nconcise and readable. However when graphing the data, doing truncation\nlike that on the values makes things just look weird. Since we're not\nactually printing any numbers we can just drop this. If we do need to\nrender text with the run_times in the future we can just do the\ntruncation in the html.\n\nChange-Id: I467513cc62b6605ac3f8d1719bf042b133f14116\n""}]",0,256746,f522a85d8ea4a81b0f4be2155fdbecc6c9860e72,6,2,1,5196,,,0,"Don't fix run_time to 2 decimal places

The per test pages were fixing the run_time value to 2 decimal places,
this was likely in an attempt to make the any written numbers be more
concise and readable. However when graphing the data, doing truncation
like that on the values makes things just look weird. Since we're not
actually printing any numbers we can just drop this. If we do need to
render text with the run_times in the future we can just do the
truncation in the html.

Change-Id: I467513cc62b6605ac3f8d1719bf042b133f14116
",git fetch https://review.opendev.org/openstack/openstack-health refs/changes/46/256746/1 && git format-patch -1 --stdout FETCH_HEAD,['app/js/controllers/test.js'],1,f522a85d8ea4a81b0f4be2155fdbecc6c9860e72,(HEAD, y: parseFloat(test.run_time) y: parseFloat(test.avg_run_time), y: parseFloat(test.run_time.toFixed(2)) y: parseFloat(test.avg_run_time.toFixed(2)),2,2
openstack%2Ffuel-library~master~I8ede075c35c25aeb8a5957e7a10dcd2a2804413a,openstack/fuel-library,master,I8ede075c35c25aeb8a5957e7a10dcd2a2804413a,Split neutron tasks for task-based deployment,MERGED,2015-12-11 18:27:23.000000000,2015-12-11 21:47:27.000000000,2015-12-11 21:46:49.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-11 18:27:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5d4d1afa31b428ecbc819b6180d44b6286dc44d9', 'message': 'Split neutron tasks for task-based deployment\n\nThis commit wraps up tasks definitions for\nneutron to be able to run several tasks in\norchestrated cross-node mode. This commit\nis compatible with both tasks format.\n\nThis commit runs primary-.* tasks on primary\ncontroller and others on non primary-cnt nodes\nthus doing the same job as role-based deployment\ndoes.\n\nIt has been tested against neutron VLAN scenario\nand passed required tests at the custom environment\nwith task-based deployment\n\nChange-Id: I8ede075c35c25aeb8a5957e7a10dcd2a2804413a\nImplements: blueprint task-based-deployment-astute\n'}, {'number': 2, 'created': '2015-12-11 18:33:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1b7c5d48c548aec8b842059f1dc49b4d63632f2b', 'message': 'Split neutron tasks for task-based deployment\n\nThis commit wraps up tasks definitions for\nneutron to be able to run several tasks in\norchestrated cross-node mode. This commit\nis compatible with both tasks format.\n\nThis commit runs primary-.* tasks on primary\ncontroller and others on non primary-cnt nodes\nthus doing the same job as role-based deployment\ndoes.\n\nIt has been tested against neutron VLAN scenario\nand passed required tests at the custom environment\nwith task-based deployment\n\nChange-Id: I8ede075c35c25aeb8a5957e7a10dcd2a2804413a\nImplements: blueprint task-based-deployment-astute\n'}, {'number': 3, 'created': '2015-12-11 20:01:33.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d25b18529fd811a7c30d4aadc905add1f197e7b6', 'message': 'Split neutron tasks for task-based deployment\n\nThis commit wraps up tasks definitions for\nneutron to be able to run several tasks in\norchestrated cross-node mode. This commit\nis compatible with both tasks format.\n\nThis commit runs primary-.* tasks on primary\ncontroller and others on non primary-cnt nodes\nthus doing the same job as role-based deployment\ndoes.\n\nIt has been tested against neutron VLAN scenario\nand passed required tests at the custom environment\nwith task-based deployment\n\nChange-Id: I8ede075c35c25aeb8a5957e7a10dcd2a2804413a\nImplements: blueprint task-based-deployment-astute\n'}]",0,256624,d25b18529fd811a7c30d4aadc905add1f197e7b6,41,8,3,8786,,,0,"Split neutron tasks for task-based deployment

This commit wraps up tasks definitions for
neutron to be able to run several tasks in
orchestrated cross-node mode. This commit
is compatible with both tasks format.

This commit runs primary-.* tasks on primary
controller and others on non primary-cnt nodes
thus doing the same job as role-based deployment
does.

It has been tested against neutron VLAN scenario
and passed required tests at the custom environment
with task-based deployment

Change-Id: I8ede075c35c25aeb8a5957e7a10dcd2a2804413a
Implements: blueprint task-based-deployment-astute
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/24/256624/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml'],1,5d4d1afa31b428ecbc819b6180d44b6286dc44d9,bp/task-based-deployment-astute,"- id: primary-openstack-network-plugins-l2 groups: [primary-controller] - id: openstack-network-plugins-l2 type: puppet groups: [controller,compute,ironic] required_for: [openstack-network-end] requires: [openstack-network-common-config, openstack-network-server-config] refresh_on: [neutron_plugin_ml2, neutron_agent_ovs, neutron_config, neutron_api_config] cross-depends: - name: primary-openstack-network-plugins-l2 parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/openstack-network/plugins/ml2.pp puppet_modules: /etc/puppet/modules timeout: 1800 requires: [primary-openstack-network-plugins-l2]- id: primary-openstack-network-agents-l3 type: puppet groups: [primary-controller] required_for: [openstack-network-end] requires: [openstack-network-networks, openstack-network-routers, primary-openstack-network-plugins-l2, openstack-network-plugins-l2] refresh_on: [neutron_l3_agent_config] parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/openstack-network/agents/l3.pp puppet_modules: /etc/puppet/modules timeout: 1800 groups: [controller,compute] requires: [openstack-network-networks, openstack-network-routers, primary-openstack-network-plugins-l2, openstack-network-plugins-l2] cross-depends: - name: /(primary-)?openstack-network-plugins-l2/ - name: primary-openstack-network-agents-l3 cross-depends: - name: /(primary-)?openstack-network-agents-l3/ - name: /(primary-)?openstack-network-plugins-l2/- id: primary-openstack-network-agents-dhcp groups: [primary-controller] cross-depends: - name: /(primary-)?openstack-network-plugins-l2/ - id: openstack-network-agents-dhcp groups: [controller] required_for: [openstack-network-end] requires: [openstack-network-common-config,openstack-network-server-nova,openstack-network-agents-l3] refresh_on: [neutron_dhcp_agent_config] cross-depends: - name: primary-openstack-network-agents-dhcp - name: /(primary-)?openstack-network-plugins-l2/ parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/openstack-network/agents/dhcp.pp puppet_modules: /etc/puppet/modules timeout: 1800 - id: primary-openstack-network-agents-metadata type: puppet groups: [primary-controller] cross-depends: - name: /(primary-)?openstack-network-plugins-l2/ - name: /(primary-)?openstack-network-agents-l3/ parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/openstack-network/agents/metadata.pp puppet_modules: /etc/puppet/modules timeout: 1800 - id: openstack-network-agents-metadata type: puppet groups: [controller,compute] required_for: [openstack-network-end] requires: [openstack-network-common-config,openstack-network-server-nova,openstack-network-agents-l3] refresh_on: [neutron_metadata_agent_config] cross-depends: - name: primary-openstack-network-agents-metadata - name: /(primary-)?openstack-network-plugins-l2/ cross-depends: - name: (primary-)?openstack-network-plugins-l2","- id: openstack-network-plugins-l2 groups: [primary-controller,controller,compute,ironic] requires: [openstack-network-plugins-l2] groups: [primary-controller,controller,compute] requires: [openstack-network-networks, openstack-network-routers, openstack-network-plugins-l2]- id: openstack-network-agents-dhcp groups: [primary-controller,controller]- id: openstack-network-agents-metadata groups: [primary-controller,controller,compute]",78,9
openstack%2Fneutron-specs~master~Ic1e2796cf1e0a433c1b1ea25afa96f5ff7a2f03f,openstack/neutron-specs,master,Ic1e2796cf1e0a433c1b1ea25afa96f5ff7a2f03f,Move guru reports to mitaka,MERGED,2015-12-10 01:38:56.000000000,2015-12-11 21:39:48.000000000,2015-12-11 21:39:48.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6524}, {'_account_id': 9656}, {'_account_id': 14605}, {'_account_id': 18573}]","[{'number': 1, 'created': '2015-12-10 01:38:56.000000000', 'files': ['specs/mitaka/adopt-oslo-guru-reports.rst'], 'web_link': 'https://opendev.org/openstack/neutron-specs/commit/bf9c27767c4f722bc431e4825ac8b73ba1bbfe4c', 'message': 'Move guru reports to mitaka\n\nChange-Id: Ic1e2796cf1e0a433c1b1ea25afa96f5ff7a2f03f\n'}]",0,255628,bf9c27767c4f722bc431e4825ac8b73ba1bbfe4c,9,6,1,748,,,0,"Move guru reports to mitaka

Change-Id: Ic1e2796cf1e0a433c1b1ea25afa96f5ff7a2f03f
",git fetch https://review.opendev.org/openstack/neutron-specs refs/changes/28/255628/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/mitaka/adopt-oslo-guru-reports.rst'],1,bf9c27767c4f722bc431e4825ac8b73ba1bbfe4c,move-guru,,,0,0
openstack%2Fkolla~master~Iac424a88a747772a37b2ff2ae94f302a988f7201,openstack/kolla,master,Iac424a88a747772a37b2ff2ae94f302a988f7201,Fix owner of horizon docroot,MERGED,2015-12-11 16:17:53.000000000,2015-12-11 21:33:56.000000000,2015-12-11 21:33:54.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-12-11 16:17:53.000000000', 'files': ['docker/horizon/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/9f604456be6efa7bda3973bf3fdb9019ec350297', 'message': 'Fix owner of horizon docroot\n\nHorizon starts WSGI deamon from user ""horizon"", its docroot has ""root"" user.\n\nChange-Id: Iac424a88a747772a37b2ff2ae94f302a988f7201\nCloses-Bug: 1525296\n'}]",0,256564,9f604456be6efa7bda3973bf3fdb9019ec350297,7,3,1,18652,,,0,"Fix owner of horizon docroot

Horizon starts WSGI deamon from user ""horizon"", its docroot has ""root"" user.

Change-Id: Iac424a88a747772a37b2ff2ae94f302a988f7201
Closes-Bug: 1525296
",git fetch https://review.opendev.org/openstack/kolla refs/changes/64/256564/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/horizon/Dockerfile.j2'],1,9f604456be6efa7bda3973bf3fdb9019ec350297,bug/1525296, && chown -R horizon: /etc/openstack-dashboard /usr/share/openstack-dashboard \ && chown -R apache: /usr/share/openstack-dashboard/static, && chown -R apache: /usr/share/openstack-dashboard/static \ && chown -R horizon: /etc/openstack-dashboard,2,2
openstack%2Fkolla~master~Id65f2bc765828054bf5d5562de27255031254821,openstack/kolla,master,Id65f2bc765828054bf5d5562de27255031254821,Change nova-compute upgrade level to auto,MERGED,2015-12-07 20:37:08.000000000,2015-12-11 21:25:20.000000000,2015-12-11 21:25:18.000000000,"[{'_account_id': 3}, {'_account_id': 3098}, {'_account_id': 4715}, {'_account_id': 7488}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-12-07 20:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/24de8b0fc88717bb3858e076dbd214c0be2b89f2', 'message': 'Change nova-compute upgrade level to auto\n\nAs part of upgrade process we need new services to detect what is the oldest\nversion running on compute nodes.\n\nChange-Id: Id65f2bc765828054bf5d5562de27255031254821\nPartially-Implements: blueprint upgrade-nova\n'}, {'number': 2, 'created': '2015-12-07 21:36:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/82346aea2e49b034278c407cd7bf419038c374fa', 'message': 'Change nova-compute upgrade level to auto\n\nAs part of upgrade process we need new services to detect what is the oldest\nversion running on compute nodes.\n\nChange-Id: Id65f2bc765828054bf5d5562de27255031254821\nPartially-Implements: blueprint upgrade-nova\n'}, {'number': 3, 'created': '2015-12-10 19:23:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/29e072dfd975569a7562812605859aa6b325142c', 'message': 'Change nova-compute upgrade level to auto\n\nAs part of upgrade process we need new services to detect what is the oldest\nversion running on compute nodes.\n\nChange-Id: Id65f2bc765828054bf5d5562de27255031254821\nPartially-Implements: blueprint upgrade-nova\n'}, {'number': 4, 'created': '2015-12-11 17:02:54.000000000', 'files': ['ansible/roles/nova/templates/nova.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a02bcdcacc593d709f7a25b729d931f6f8708dc1', 'message': 'Change nova-compute upgrade level to auto\n\nAs part of upgrade process we need new services to detect what is the oldest\nversion running on compute nodes.\n\nChange-Id: Id65f2bc765828054bf5d5562de27255031254821\nPartially-Implements: blueprint upgrade-nova\n'}]",0,254376,a02bcdcacc593d709f7a25b729d931f6f8708dc1,14,5,4,10787,,,0,"Change nova-compute upgrade level to auto

As part of upgrade process we need new services to detect what is the oldest
version running on compute nodes.

Change-Id: Id65f2bc765828054bf5d5562de27255031254821
Partially-Implements: blueprint upgrade-nova
",git fetch https://review.opendev.org/openstack/kolla refs/changes/76/254376/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/nova/templates/nova.conf.j2'],1,24de8b0fc88717bb3858e076dbd214c0be2b89f2,bp/upgrade-nova, [upgrade_levels] compute = auto,,3,0
openstack%2Fmonasca-api~master~Ief8ed514d15934b31e9315bf7cd5fe137262d611,openstack/monasca-api,master,Ief8ed514d15934b31e9315bf7cd5fe137262d611,Adding liberty versions of oslo to requirements.txt,MERGED,2015-12-10 22:48:45.000000000,2015-12-11 21:24:03.000000000,2015-12-11 21:24:01.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 14273}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-12-10 22:48:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/f264536d4a22abc6ea7ab2ea0848c792bf64a286', 'message': 'Adding liberty versions of oslo to requirements.txt\n\nChange-Id: Ief8ed514d15934b31e9315bf7cd5fe137262d611\n'}]",0,256126,f264536d4a22abc6ea7ab2ea0848c792bf64a286,17,4,1,14273,,,0,"Adding liberty versions of oslo to requirements.txt

Change-Id: Ief8ed514d15934b31e9315bf7cd5fe137262d611
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/26/256126/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f264536d4a22abc6ea7ab2ea0848c792bf64a286,,oslo.config<2.5.0 oslo.i18n<=2.6.0 oslo.log<1.12.0 oslo.middleware<2.9.0 oslo.serialization<1.10.0 oslo.utils<2.6.0 ,"oslo.config>=1.2.1,<=2.6.0 oslo.middleware oslo.log oslo.serialization oslo.utils",7,5
openstack%2Ffuel-library~master~I80ae231ca64e2a903b0968d36ba0e85ca9cc9891,openstack/fuel-library,master,I80ae231ca64e2a903b0968d36ba0e85ca9cc9891,Add ability to disable HA for RabbitMQ queues,MERGED,2015-11-24 12:44:09.000000000,2015-12-11 20:48:37.000000000,2015-12-11 20:47:47.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6926}, {'_account_id': 7109}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13343}]","[{'number': 1, 'created': '2015-11-24 12:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3da5d2ff98498839fccd2a0703c833eb515abb3e', 'message': 'Disable HA for non-Ceilometer queues\n\nDocImpact: TBD\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 2, 'created': '2015-12-04 12:21:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5402e4b7cea4f6c75ff84ebcea39b0ca14dbf571', 'message': 'Add abilitay to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affect\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact: ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 3, 'created': '2015-12-04 12:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1a2eeb7583219e2de7094fed8dd0055a7383c65e', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact: ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 4, 'created': '2015-12-07 16:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ebb227d02be4a0b5c39cd3cf91b67ff2434de860', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact: ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 5, 'created': '2015-12-07 18:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2cd171144a87493c6b784f1a51e26c0718893923', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact: ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 6, 'created': '2015-12-07 21:09:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c641a23f8bab8a523e55bb413acd812d1000fcf9', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 7, 'created': '2015-12-08 16:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7a6989ece24f5f05553c8861de2b5860c7110688', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 8, 'created': '2015-12-08 17:50:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/950af20f31d478ecc10e44e51b7650ed25d96ccc', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 9, 'created': '2015-12-08 22:25:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/378371d88f8f2f670a931dadf0fdc814d0c5fbbc', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 10, 'created': '2015-12-09 10:32:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dd3b4fe57df121a9a5e897b6cf423543689fc4c2', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed.\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 11, 'created': '2015-12-09 14:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0316567b02eaeef6346eaab7955edb027c228bf3', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed. Here is the pull\nrequest: https://github.com/rabbitmq/rabbitmq-server/pull/478\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 12, 'created': '2015-12-10 22:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d4a42bad801b683c9a33b7f48b716db05c37090d', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed. Here is the pull\nrequest: https://github.com/rabbitmq/rabbitmq-server/pull/478\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 13, 'created': '2015-12-11 09:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2cbd3c9a15a742a795c34f8c5d3f4038c49d7007', 'message': 'Add ability to disable HA for non-Ceilometer queues\n\nAdd a flag enable_rpc_ha which enables queue mirroring for all queues.\nSetting this flag to false disables mirroring for RPC queues. Note\nthat it does not affect mirroring for Ceilometer queues, which are\nalways mirrored.\n\nSince the feature is experimental, the flag is set to true by default\nto preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around\n   the upstream one. It defines a new enable_rpc_ha parameter and\n   passes its value to the upstream script.\n * we add our policy file, where we use the enable_rpc_ha parameter\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script will be pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed. Here is the pull\nrequest: https://github.com/rabbitmq/rabbitmq-server/pull/478\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring for RPC queues. This could be\ndone by executing the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nThis will not affect Ceilometer queues, as they are always mirrored.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 14, 'created': '2015-12-11 13:31:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/066c9d7e8928e0c04f59b70a5e6f9186b7811d20', 'message': 'Add ability to disable HA for RabbitMQ queues\n\nAdd two flags:\n * enable_rpc_ha which enables queue mirroring for RPC queues\n * enable_notifications_ha which enables queue mirroring for\n   Ceilometer queues\n\nSince the feature is experimental, both flags are set to true by\ndefault to preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around the\n   upstream one. It defines a new enable_rpc_ha and\n   enable_notifications_ha parameter and passes their value to the\n   upstream script.\n * we add our policy file, where we use the introduced parameters\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script is pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed. Here are the\ncorresponding pull requests:\n  https://github.com/rabbitmq/rabbitmq-server/pull/480\n  https://github.com/rabbitmq/rabbitmq-server/pull/482\n(both are already merged)\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring. This could be done separately\nfor RPC queues and Ceilometer ones. To disable mirroring for RPC\nqueues, execute the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nTo disable mirroring for Ceilometer queues, execute the following\ncommand on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_notifications_ha --parameter-value false\n\nIn order for any of the changes to take effect, RabbitMQ service\nshould be restarted. To do that, first execute\n\n    pcs resource disable master_p_rabbitmq-server\n\nThen monitor RabbitMQ state using command\n\n    pcs resource\n\nuntil it shows that all RabbitMQ nodes are stopped. Once they are,\nexecute the following command to start RabbitMQ:\n\n    pcs resource enable master_p_rabbitmq-server\n\nBeware: during restart all messages accumulated in RabbitMQ will be\nlost. Also, OpenStack will stop functioning until RabbitMQ is up\nagain, so plan accordingly.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}, {'number': 15, 'created': '2015-12-11 17:24:34.000000000', 'files': ['deployment/puppet/pacemaker_wrappers/manifests/rabbitmq.pp', 'files/fuel-ha-utils/ocf/rabbitmq-fuel', 'deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq.pp', 'debian/rules', 'files/fuel-ha-utils/ocf/set_rabbitmq_policy.sh', 'specs/fuel-library8.0.spec', 'files/fuel-ha-utils/ocf/rabbitmq'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7e96ef47caeae03cf9696a67817e1756e1b63f4a', 'message': 'Add ability to disable HA for RabbitMQ queues\n\nAdd two flags:\n * enable_rpc_ha which enables queue mirroring for RPC queues\n * enable_notifications_ha which enables queue mirroring for\n   Ceilometer queues\n\nSince the feature is experimental, both flags are set to true by\ndefault to preserve current behaviour.\n\nThe change is implemented in several steps:\n * the upstream script changed so that it allows to extend the\n   list of parameters and uses a policy file to define RabbitMQ\n   policies.\n * we add our own version of OCF script which wraps around the\n   upstream one. It defines a new enable_rpc_ha and\n   enable_notifications_ha parameter and passes their value to the\n   upstream script.\n * we add our policy file, where we use the introduced parameters\n   to decide which policies we should set.\n\nSo we will have two OCF scripts for RabbitMQ in our deployment:\n * rabbitmq-server-upstream - the upstream version\n * rabbitmq-server - our extention, which will be used in the\n   environment\n\nThe upstream version of the script is pushed to the upstream\nalong with empty policy file, so that other users can define their\nown policies or extend the script if needed. Here are the\ncorresponding pull requests:\n  https://github.com/rabbitmq/rabbitmq-server/pull/480\n  https://github.com/rabbitmq/rabbitmq-server/pull/482\n(both are already merged)\n\nText for Operations Guide\n\nIt is possible to significantly reduce load which OpenStack puts on\nRabbitMQ by disabling queue mirroring. This could be done separately\nfor RPC queues and Ceilometer ones. To disable mirroring for RPC\nqueues, execute the following command on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_rpc_ha --parameter-value false\n\nTo disable mirroring for Ceilometer queues, execute the following\ncommand on one of the controllers:\n\n    crm_resource --resource p_rabbitmq-server --set-parameter \\\n        enable_notifications_ha --parameter-value false\n\nIn order for any of the changes to take effect, RabbitMQ service\nshould be restarted. To do that, first execute\n\n    pcs resource disable master_p_rabbitmq-server\n\nThen monitor RabbitMQ state using command\n\n    pcs resource\n\nuntil it shows that all RabbitMQ nodes are stopped. Once they are,\nexecute the following command to start RabbitMQ:\n\n    pcs resource enable master_p_rabbitmq-server\n\nBeware: during restart all messages accumulated in RabbitMQ will be\nlost. Also, OpenStack will stop functioning until RabbitMQ is up\nagain, so plan accordingly.\n\nNote that it is not yet well tested how this configuration affects\nfailover when some cluster nodes go down. Hence it is experimental,\nuse at your own risk!\n\nDocImpact:  ops-guide\n\nImplements: blueprint rabbitmq-disable-mirroring-for-rpc\nChange-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891\n'}]",15,249180,7e96ef47caeae03cf9696a67817e1756e1b63f4a,197,10,15,7109,,,0,"Add ability to disable HA for RabbitMQ queues

Add two flags:
 * enable_rpc_ha which enables queue mirroring for RPC queues
 * enable_notifications_ha which enables queue mirroring for
   Ceilometer queues

Since the feature is experimental, both flags are set to true by
default to preserve current behaviour.

The change is implemented in several steps:
 * the upstream script changed so that it allows to extend the
   list of parameters and uses a policy file to define RabbitMQ
   policies.
 * we add our own version of OCF script which wraps around the
   upstream one. It defines a new enable_rpc_ha and
   enable_notifications_ha parameter and passes their value to the
   upstream script.
 * we add our policy file, where we use the introduced parameters
   to decide which policies we should set.

So we will have two OCF scripts for RabbitMQ in our deployment:
 * rabbitmq-server-upstream - the upstream version
 * rabbitmq-server - our extention, which will be used in the
   environment

The upstream version of the script is pushed to the upstream
along with empty policy file, so that other users can define their
own policies or extend the script if needed. Here are the
corresponding pull requests:
  https://github.com/rabbitmq/rabbitmq-server/pull/480
  https://github.com/rabbitmq/rabbitmq-server/pull/482
(both are already merged)

Text for Operations Guide

It is possible to significantly reduce load which OpenStack puts on
RabbitMQ by disabling queue mirroring. This could be done separately
for RPC queues and Ceilometer ones. To disable mirroring for RPC
queues, execute the following command on one of the controllers:

    crm_resource --resource p_rabbitmq-server --set-parameter \
        enable_rpc_ha --parameter-value false

To disable mirroring for Ceilometer queues, execute the following
command on one of the controllers:

    crm_resource --resource p_rabbitmq-server --set-parameter \
        enable_notifications_ha --parameter-value false

In order for any of the changes to take effect, RabbitMQ service
should be restarted. To do that, first execute

    pcs resource disable master_p_rabbitmq-server

Then monitor RabbitMQ state using command

    pcs resource

until it shows that all RabbitMQ nodes are stopped. Once they are,
execute the following command to start RabbitMQ:

    pcs resource enable master_p_rabbitmq-server

Beware: during restart all messages accumulated in RabbitMQ will be
lost. Also, OpenStack will stop functioning until RabbitMQ is up
again, so plan accordingly.

Note that it is not yet well tested how this configuration affects
failover when some cluster nodes go down. Hence it is experimental,
use at your own risk!

DocImpact:  ops-guide

Implements: blueprint rabbitmq-disable-mirroring-for-rpc
Change-Id: I80ae231ca64e2a903b0968d36ba0e85ca9cc9891
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/80/249180/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/rabbitmq'],1,3da5d2ff98498839fccd2a0703c833eb515abb3e,bp/rabbitmq-disable-mirroring-for-rpc," ${OCF_RESKEY_ctl} set_policy ha-notif ""^(event|metering|notifications)\."" '{""ha-mode"":""all"", ""ha-sync-mode"":""automatic""}' --apply-to all --priority 0 ${OCF_RESKEY_ctl} set_policy heat_rpc_expire ""^heat-engine-listener\\."" '{""expires"":3600000}' --apply-to all --priority 1 ${OCF_RESKEY_ctl} set_policy results_expire ""^results\\."" '{""expires"":3600000}' --apply-to all --priority 1 ${OCF_RESKEY_ctl} set_policy tasks_expire ""^tasks\\."" '{""expires"":3600000}' --apply-to all --priority 1"," ${OCF_RESKEY_ctl} set_policy ha-all ""."" '{""ha-mode"":""all"", ""ha-sync-mode"":""automatic""}' --apply-to all --priority 0 ${OCF_RESKEY_ctl} set_policy heat_rpc_expire ""^heat-engine-listener\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 ${OCF_RESKEY_ctl} set_policy results_expire ""^results\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1 ${OCF_RESKEY_ctl} set_policy tasks_expire ""^tasks\\."" '{""expires"":3600000,""ha-mode"":""all"",""ha-sync-mode"":""automatic""}' --apply-to all --priority 1",4,4
openstack%2Fapi-site~master~I23f3f2bf8695d8f8930d9434b6c8c2058b112a1a,openstack/api-site,master,I23f3f2bf8695d8f8930d9434b6c8c2058b112a1a,Fixes path indicator for method removeFloatingIp,MERGED,2015-12-11 17:40:20.000000000,2015-12-11 20:43:24.000000000,2015-12-11 20:43:23.000000000,"[{'_account_id': 3}, {'_account_id': 2448}, {'_account_id': 19670}]","[{'number': 1, 'created': '2015-12-11 17:40:20.000000000', 'files': ['api-ref/src/docbkx/ch_compute-v2.1.xml'], 'web_link': 'https://opendev.org/openstack/api-site/commit/f5cbc92abb5225b66c5f1fb937e690e559461f8c', 'message': 'Fixes path indicator for method removeFloatingIp\n\nChange-Id: I23f3f2bf8695d8f8930d9434b6c8c2058b112a1a\nCloses-Bug: #1524565\n'}]",0,256603,f5cbc92abb5225b66c5f1fb937e690e559461f8c,7,3,1,15293,,,0,"Fixes path indicator for method removeFloatingIp

Change-Id: I23f3f2bf8695d8f8930d9434b6c8c2058b112a1a
Closes-Bug: #1524565
",git fetch https://review.opendev.org/openstack/api-site refs/changes/03/256603/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/src/docbkx/ch_compute-v2.1.xml'],1,f5cbc92abb5225b66c5f1fb937e690e559461f8c,bug/1524565," <wadl:method href=""#removeFloatingIp""/>"," <wadl:method href=""removeFloatingIp""/>",1,1
openstack%2Fpython-openstackclient~master~I9d21904c41c11ee1fa107f985744878a1dc2f970,openstack/python-openstackclient,master,I9d21904c41c11ee1fa107f985744878a1dc2f970,"Router: Add ""router list"" command using SDK",MERGED,2015-12-11 09:46:20.000000000,2015-12-11 20:42:23.000000000,2015-12-11 20:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}]","[{'number': 1, 'created': '2015-12-11 09:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4b902d992ae91d130b219a1f28c578dbf71ca3aa', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha.\n\nWith ""--long"" option, it will also print project id and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nCloses-bug: #1523258\n'}, {'number': 2, 'created': '2015-12-11 14:16:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/8ab2a4572b9e6c90dca494354d0c67902148556b', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha.\n\nWith ""--long"" option, it will also print project id and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 3, 'created': '2015-12-11 17:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/c5a02c8e76685cf65be19404340fd27283e7c0c4', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha and project id.\n\nWith ""--long"" option, it will also print routes and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 4, 'created': '2015-12-11 17:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/05e82e6d2291509df6b1fd190b608f29b82fc651', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha and project id.\n\nWith ""--long"" option, it will also print routes and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 5, 'created': '2015-12-11 17:52:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/d3252079aedd651adb4ee6276230f20ec66088b8', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha and project id.\n\nWith ""--long"" option, it will also print routes and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 6, 'created': '2015-12-11 18:07:47.000000000', 'files': ['openstackclient/network/v2/router.py', 'doc/source/commands.rst', 'doc/source/command-objects/router.rst', 'setup.cfg', 'openstackclient/tests/network/v2/test_router.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3278b3a022c34b1abe28e1ed7b16ed60a059a441', 'message': 'Router: Add ""router list"" command using SDK\n\nAdd ""router list"" command. It takes one ""--long"" option.\n\nBy default, the command will print router id, name, status,\nadmin state up, distributed, ha and project id.\n\nWith ""--long"" option, it will also print routes and\nexternal gateway info.\n\nChange-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970\nImplements: blueprint neutron-client\nPartial-bug: #1519503\n'}]",14,256309,3278b3a022c34b1abe28e1ed7b16ed60a059a441,21,5,6,14937,,,0,"Router: Add ""router list"" command using SDK

Add ""router list"" command. It takes one ""--long"" option.

By default, the command will print router id, name, status,
admin state up, distributed, ha and project id.

With ""--long"" option, it will also print routes and
external gateway info.

Change-Id: I9d21904c41c11ee1fa107f985744878a1dc2f970
Implements: blueprint neutron-client
Partial-bug: #1519503
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/09/256309/6 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/commands.rst', 'openstackclient/network/v2/router.py', 'setup.cfg', 'openstackclient/tests/network/v2/test_router.py']",4,4b902d992ae91d130b219a1f28c578dbf71ca3aa,bp/neutron-client,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. # import mock from openstackclient.network.v2 import router from openstackclient.tests.network.v2 import fakes as network_fakes class TestRouter(network_fakes.TestNetworkV2): def setUp(self): super(TestRouter, self).setUp() # Get a shortcut to the network client self.network = self.app.client_manager.network class TestListRouter(TestRouter): # The routers going to be listed up. routers = network_fakes.FakeRouter.create_routers(count=3) columns = ( 'ID', 'Name', 'Status', 'State', 'Distributed', 'HA', ) columns_long = columns + ( 'Project', 'External gateway info', ) data = [] for r in routers: data.append(( r.id, r.name, r.status, router._format_admin_state(r.admin_state_up), r.distributed, r.ha, )) data_long = [] for i in range(0, len(routers)): r = routers[i] data_long.append( data[i] + ( r.tenant_id, router._format_external_gateway_info(r), ) ) def setUp(self): super(TestListRouter, self).setUp() # Get the command object to test self.cmd = router.ListRouter(self.app, self.namespace) self.network.routers = mock.Mock(return_value=self.routers) def test_router_list_no_options(self): arglist = [] verifylist = [ ('long', False), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) self.network.routers.assert_called_with() self.assertEqual(self.columns, columns) self.assertEqual(self.data, list(data)) def test_router_list_long(self): arglist = [ '--long', ] verifylist = [ ('long', True), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) # DisplayCommandBase.take_action() returns two tuples columns, data = self.cmd.take_action(parsed_args) self.network.routers.assert_called_with() self.assertEqual(self.columns_long, columns) self.assertEqual(self.data_long, list(data)) ",,198,0
openstack%2Fzaqar~master~If688fe0c73b057aca8c43514f1f88de98492455d,openstack/zaqar,master,If688fe0c73b057aca8c43514f1f88de98492455d,Updated from global requirements,MERGED,2015-12-11 15:27:39.000000000,2015-12-11 20:39:28.000000000,2015-12-11 20:39:27.000000000,"[{'_account_id': 3}, {'_account_id': 6484}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-12-11 15:27:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/zaqar/commit/cec45e27a13d2f22e8cda4bba3312bbdc0a4d2d2', 'message': 'Updated from global requirements\n\nChange-Id: If688fe0c73b057aca8c43514f1f88de98492455d\n'}]",0,256537,cec45e27a13d2f22e8cda4bba3312bbdc0a4d2d2,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: If688fe0c73b057aca8c43514f1f88de98492455d
",git fetch https://review.opendev.org/openstack/zaqar refs/changes/37/256537/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,cec45e27a13d2f22e8cda4bba3312bbdc0a4d2d2,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fironic-python-agent~master~I9d5383b1f97a95da847a5bf896260919fd9d09c5,openstack/ironic-python-agent,master,I9d5383b1f97a95da847a5bf896260919fd9d09c5,Updated from global requirements,MERGED,2015-12-08 02:29:22.000000000,2015-12-11 20:39:12.000000000,2015-12-11 20:39:10.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-12-08 02:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1e2779ee2a2dc48025b7abc3f6c7402b9e9c0862', 'message': 'Updated from global requirements\n\nChange-Id: I9d5383b1f97a95da847a5bf896260919fd9d09c5\n'}, {'number': 2, 'created': '2015-12-08 06:47:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/11b6e0e52c5f2b32f9baeb85313cb7a2bd4cf654', 'message': 'Updated from global requirements\n\nChange-Id: I9d5383b1f97a95da847a5bf896260919fd9d09c5\n'}, {'number': 3, 'created': '2015-12-09 18:13:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3249d25098acdd882c0573a4582ed6190f6366ce', 'message': 'Updated from global requirements\n\nChange-Id: I9d5383b1f97a95da847a5bf896260919fd9d09c5\n'}, {'number': 4, 'created': '2015-12-11 15:19:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/84fc428d6f9b0d3e6fe29042531b15b6b7bf1bdb', 'message': 'Updated from global requirements\n\nChange-Id: I9d5383b1f97a95da847a5bf896260919fd9d09c5\n'}]",0,254495,84fc428d6f9b0d3e6fe29042531b15b6b7bf1bdb,18,3,4,11131,,,0,"Updated from global requirements

Change-Id: I9d5383b1f97a95da847a5bf896260919fd9d09c5
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/95/254495/4 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,1e2779ee2a2dc48025b7abc3f6c7402b9e9c0862,openstack/requirements,oslo.service>=1.0.0 # Apache-2.0,oslo.service>=0.12.0 # Apache-2.0,1,1
openstack%2Ffuel-library~master~Id9fdfc345f30606773ac0d5d510670b02fc70dd4,openstack/fuel-library,master,Id9fdfc345f30606773ac0d5d510670b02fc70dd4,Wrong process name in controller_post modular test,MERGED,2015-12-11 15:03:23.000000000,2015-12-11 20:32:54.000000000,2015-12-11 20:32:07.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2015-12-11 15:03:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a68d9813523163b8b62ec8e4b76f395064e3977c', 'message': ""Wrong process name in controller_post modular test\n\nThis commit fix wrong process 'ceilometer-agent-central'.\n\nChange-Id: Id9fdfc345f30606773ac0d5d510670b02fc70dd4\nCloses-Bug: #1524701\n""}, {'number': 2, 'created': '2015-12-11 15:14:19.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/ceilometer/controller_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b583a5a0fbc299118f6ef3ef91ec42d1a5cbdbf2', 'message': ""Wrong process name in controller_post modular test\n\nThis commit fix wrong process name 'ceilometer-agent-central'.\n\nChange-Id: Id9fdfc345f30606773ac0d5d510670b02fc70dd4\nCloses-Bug: #1524701\n""}]",0,256455,b583a5a0fbc299118f6ef3ef91ec42d1a5cbdbf2,32,11,2,14200,,,0,"Wrong process name in controller_post modular test

This commit fix wrong process name 'ceilometer-agent-central'.

Change-Id: Id9fdfc345f30606773ac0d5d510670b02fc70dd4
Closes-Bug: #1524701
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/55/256455/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/ceilometer/controller_post.rb'],1,a68d9813523163b8b62ec8e4b76f395064e3977c,bug/1524701,ceilometer-polling,ceilometer-agent-central,1,1
openstack%2Fgnocchi~stable%2F1.3~Ifc85a9004e864d14d42fd482ec144e4d27dd615b,openstack/gnocchi,stable/1.3,Ifc85a9004e864d14d42fd482ec144e4d27dd615b,Checks percent_of_overlap when one boundary is set,MERGED,2015-12-10 09:54:15.000000000,2015-12-11 20:28:51.000000000,2015-12-11 20:28:50.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 6537}]","[{'number': 1, 'created': '2015-12-10 09:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/16b29de3ad5a80ba0d8d5a246d75a7408a0cf81c', 'message': ""Checks percent_of_overlap when one boundary is set\n\nAggregation across metrics have different behavior depending\non if boundary are set and if needed_percent_of_overlap is set.\n\nIf boundaries are not set, Carbonara makes the aggregation only with points\nat timestamp present in all timeseries.\n\nBut when boundaries are set, Carbonara expects that we have certain\npercent of timestamps common between timeseries, this percent is controlled\nby needed_percent_of_overlap (defaulted with 100%).\n\nThis change fixes a weird behavior when only one boundary is set,\nthe needed_percent_of_overlap wasn't checked.\n\nChange-Id: Ifc85a9004e864d14d42fd482ec144e4d27dd615b\nCloses-bug: #1522434\n(cherry picked from commit 444656dcb2dbdb9d3d8fc5c4c83cecf687fe5a13)\n""}, {'number': 2, 'created': '2015-12-10 13:08:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/762e0716a936a816ca7643fe2c94499cefbb5e54', 'message': ""Checks percent_of_overlap when one boundary is set\n\nAggregation across metrics have different behavior depending\non if boundary are set and if needed_percent_of_overlap is set.\n\nIf boundaries are not set, Carbonara makes the aggregation only with points\nat timestamp present in all timeseries.\n\nBut when boundaries are set, Carbonara expects that we have certain\npercent of timestamps common between timeseries, this percent is controlled\nby needed_percent_of_overlap (defaulted with 100%).\n\nThis change fixes a weird behavior when only one boundary is set,\nthe needed_percent_of_overlap wasn't checked.\n\nChange-Id: Ifc85a9004e864d14d42fd482ec144e4d27dd615b\nCloses-bug: #1522434\n(cherry picked from commit 444656dcb2dbdb9d3d8fc5c4c83cecf687fe5a13)\n""}, {'number': 3, 'created': '2015-12-10 14:11:23.000000000', 'files': ['gnocchi/tests/test_carbonara.py', 'gnocchi/carbonara.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/abf9ce3c201fa16b6bd96b226ac78ec77ff836ec', 'message': ""Checks percent_of_overlap when one boundary is set\n\nAggregation across metrics have different behavior depending\non if boundary are set and if needed_percent_of_overlap is set.\n\nIf boundaries are not set, Carbonara makes the aggregation only with points\nat timestamp present in all timeseries.\n\nBut when boundaries are set, Carbonara expects that we have certain\npercent of timestamps common between timeseries, this percent is controlled\nby needed_percent_of_overlap (defaulted with 100%).\n\nThis change fixes a weird behavior when only one boundary is set,\nthe needed_percent_of_overlap wasn't checked.\n\nChange-Id: Ifc85a9004e864d14d42fd482ec144e4d27dd615b\nCloses-bug: #1522434\n(cherry picked from commit 444656dcb2dbdb9d3d8fc5c4c83cecf687fe5a13)\n""}]",0,255764,abf9ce3c201fa16b6bd96b226ac78ec77ff836ec,22,4,3,1669,,,0,"Checks percent_of_overlap when one boundary is set

Aggregation across metrics have different behavior depending
on if boundary are set and if needed_percent_of_overlap is set.

If boundaries are not set, Carbonara makes the aggregation only with points
at timestamp present in all timeseries.

But when boundaries are set, Carbonara expects that we have certain
percent of timestamps common between timeseries, this percent is controlled
by needed_percent_of_overlap (defaulted with 100%).

This change fixes a weird behavior when only one boundary is set,
the needed_percent_of_overlap wasn't checked.

Change-Id: Ifc85a9004e864d14d42fd482ec144e4d27dd615b
Closes-bug: #1522434
(cherry picked from commit 444656dcb2dbdb9d3d8fc5c4c83cecf687fe5a13)
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/64/255764/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/tests/test_carbonara.py', 'gnocchi/carbonara.py']",2,16b29de3ad5a80ba0d8d5a246d75a7408a0cf81c,bug/1522434, if to_timestamp is not None or from_timestamp is not None:, if to_timestamp is not None and from_timestamp is not None:,7,8
openstack%2Fbandit~master~Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56,openstack/bandit,master,Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56,Adding bandit-baseline tool,MERGED,2015-12-08 00:51:49.000000000,2015-12-11 20:25:16.000000000,2015-12-11 20:25:14.000000000,"[{'_account_id': 3}, {'_account_id': 1528}, {'_account_id': 4190}, {'_account_id': 8119}, {'_account_id': 10670}, {'_account_id': 11029}, {'_account_id': 11716}, {'_account_id': 11861}, {'_account_id': 12000}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-12-08 00:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/2f9f1383ab88b2a0755b5ff4afde9360c44536f1', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 2, 'created': '2015-12-08 23:03:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/305faff4f055344b1b123a2a09ed5ecfb9212e13', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 3, 'created': '2015-12-09 00:43:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/fb307e6a8725e5fd4fc85618062642f27f675f1c', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 4, 'created': '2015-12-09 01:04:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/49f98a43135dcb04d49f3fb9f729609986c99836', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 5, 'created': '2015-12-09 01:06:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/6d0a90869a9dd5534fc311b48932da71bb072661', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 6, 'created': '2015-12-09 14:38:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/d06b7729d17d6b22712158463950868d4dc5b4f8', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 7, 'created': '2015-12-09 14:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/fda51c5cb060227d07e2256199405a6d2b0bac35', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 8, 'created': '2015-12-09 17:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/a154b3bfbcd7dee8e926c697d18ebd07409368c1', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 9, 'created': '2015-12-09 17:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/90d826f451486d6b6e4426cfb266568616e1c116', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 10, 'created': '2015-12-09 17:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/f9b8f973f44bef4c79932c9b1481007a35b8f34f', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 11, 'created': '2015-12-09 21:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/41da34917cf6eb1968e37c73f8fb9734768ec31e', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 12, 'created': '2015-12-10 00:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/b1f84c611693048a6db40d979636573e73493495', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 13, 'created': '2015-12-10 16:04:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/de4120b202b44f8428098a459f9046c414291a05', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 14, 'created': '2015-12-10 20:31:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/cd00e0127d05815bdc42ddf381df0a5cf98c49b6', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 15, 'created': '2015-12-10 20:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/182a8bfddbd8f2971db5a0bb8cae152a28814ad9', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 16, 'created': '2015-12-10 20:50:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/36fc9b79e766c8cd15854a298e27e8bda439b4d2', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 17, 'created': '2015-12-10 20:58:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/1a6c692464e2e9ac07040abb9edeb1d5221d20a3', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 18, 'created': '2015-12-10 21:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/0cb8eb886afacd59dabfd7acfcac3610aef248e1', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 19, 'created': '2015-12-10 21:25:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/ea73bb87fa9bc3220229f83d9eddb1b97332eed1', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 20, 'created': '2015-12-10 21:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/1d0cbf798bd3e56bc5b4ffe141c8a3aa692c87e9', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 21, 'created': '2015-12-10 21:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bandit/commit/a24e4c816f269c6007a2b9103fe4a1fde6bfa621', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}, {'number': 22, 'created': '2015-12-10 23:50:57.000000000', 'files': ['requirements.txt', 'bandit/bandit_baseline.py', 'tests/unit/test_bandit_baseline.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/bandit/commit/00d59dee2c720709074f20122274a58755e14ada', 'message': ""Adding bandit-baseline tool\n\nThis commit adds a tool which will run Bandit against the parent\ncommit of a current branch, and then run Bandit in baseline mode\nusing the parent's results as the baseline.  Any options that are\nsupplied to the script will be passed as options to Bandit (for\nexample severity filters, targets, etc).\n\nBy including this tool we can allow projects to run Bandit\nbaseline as part of their existing tox jobs.\n\nChange-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56\n""}]",63,254455,00d59dee2c720709074f20122274a58755e14ada,73,10,22,11861,,,0,"Adding bandit-baseline tool

This commit adds a tool which will run Bandit against the parent
commit of a current branch, and then run Bandit in baseline mode
using the parent's results as the baseline.  Any options that are
supplied to the script will be passed as options to Bandit (for
example severity filters, targets, etc).

By including this tool we can allow projects to run Bandit
baseline as part of their existing tox jobs.

Change-Id: Iaa1314aa348c7c5ca03c5c8b7dcfee456f279e56
",git fetch https://review.opendev.org/openstack/bandit refs/changes/55/254455/19 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tools/bandit_baseline.sh']",2,2f9f1383ab88b2a0755b5ff4afde9360c44536f1,add-baseline-util-script,"if [ -e ""bandit_baseline_results.html"" ] then echo ""File 'bandit_baseline_results.html' already exists!"" exit 1 fi rm _bandit_baseline_run.json_ # get the current branch name ORIGINAL_BRANCH=`git rev-parse --abbrev-ref HEAD` # find the commit ID of the parent commit PARENT_ID=`git log -2 --first-parent --pretty=oneline | cut -d "" "" -f1 | sed -n 2p` # checkout parent branch git checkout $PARENT_ID # run Bandit baseline with whatever paremeters were passed bandit $@ -f json -o _bandit_baseline_run.json_ # run Bandit on original branch and generate baseline results git checkout $ORIGINAL_BRANCH bandit $@ -b _bandit_baseline_run.json_ -f html -o bandit_baseline_results.html ",,25,0
openstack%2Fopenstack-ansible~liberty~I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93,openstack/openstack-ansible,liberty,I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93,Fixes playbook runtime issues with ldap,MERGED,2015-12-09 11:14:01.000000000,2015-12-11 20:22:47.000000000,2015-12-11 20:22:45.000000000,"[{'_account_id': 3}, {'_account_id': 2799}, {'_account_id': 7353}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-12-09 11:14:01.000000000', 'files': ['playbooks/roles/os_aodh/tasks/aodh_service_add.yml', 'playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_swift/tasks/swift_service_setup.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/tasks/glance_service_setup.yml', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_aodh/defaults/main.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_ceilometer/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_keystone/defaults/main.yml', 'playbooks/roles/os_keystone/tasks/keystone_service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b6c8ed850c48ec0595374135b486607723f676e4', 'message': 'Fixes playbook runtime issues with ldap\n\nWhen using an LDAP backend the plabooks fail when ""ensuring.*""\nwhich is a keystone client action. The reason for the failure is\nrelated to how ldap backend, and is triggered when the service\nusers are within the ldap and not SQL. To resolve the issue a boolean\nconditional was created on the various OS_.* roles to skip specific\ntasks when the service users have already been added into LDAP.\n\nChange-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit 2559ed4f13cd242c9f02cd023a7242db56650b0d)\n'}]",0,255204,b6c8ed850c48ec0595374135b486607723f676e4,10,4,1,6816,,,0,"Fixes playbook runtime issues with ldap

When using an LDAP backend the plabooks fail when ""ensuring.*""
which is a keystone client action. The reason for the failure is
related to how ldap backend, and is triggered when the service
users are within the ldap and not SQL. To resolve the issue a boolean
conditional was created on the various OS_.* roles to skip specific
tasks when the service users have already been added into LDAP.

Change-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93
Closes-Bug: #1518351
Closes-Bug: #1519174
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit 2559ed4f13cd242c9f02cd023a7242db56650b0d)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/04/255204/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_aodh/tasks/aodh_service_add.yml', 'playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_swift/tasks/swift_service_setup.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/tasks/glance_service_setup.yml', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_aodh/defaults/main.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_ceilometer/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_keystone/defaults/main.yml', 'playbooks/roles/os_keystone/tasks/keystone_service_setup.yml']",19,b6c8ed850c48ec0595374135b486607723f676e4,, when: not keystone_service_in_ldap | bool when: not keystone_service_in_ldap | bool when: not keystone_service_in_ldap | bool,,60,7
openstack%2Fpython-openstackclient~master~I9b87c6c95282902c3a829da51229a35d4265a1e4,openstack/python-openstackclient,master,I9b87c6c95282902c3a829da51229a35d4265a1e4,"Router: Add class FakeRouter to test ""router xxx"" command",MERGED,2015-12-11 09:46:20.000000000,2015-12-11 20:19:19.000000000,2015-12-11 20:19:17.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}]","[{'number': 1, 'created': '2015-12-11 09:46:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e6de46221e226e0b2d396b04ef9df92a053fe601', 'message': 'Router: Add class FakeRouter to test ""router xxx"" command\n\nA unit test class similar to FakeServer, which is able to fake one\nor more routers. It will be used by the router CRUD patches.\n\nChange-Id: I9b87c6c95282902c3a829da51229a35d4265a1e4\nImplements: blueprint neutron-client\nCloses-bug: #1523258\n'}, {'number': 2, 'created': '2015-12-11 14:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/9ee165fdbda3c52c898cc559c4da2b5a47ecc6d4', 'message': 'Router: Add class FakeRouter to test ""router xxx"" command\n\nA unit test class similar to FakeServer, which is able to fake one\nor more routers. It will be used by the router CRUD patches.\n\nChange-Id: I9b87c6c95282902c3a829da51229a35d4265a1e4\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 3, 'created': '2015-12-11 17:24:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/40fd3857d50500c77ba0a1db1c55686a68fec62c', 'message': 'Router: Add class FakeRouter to test ""router xxx"" command\n\nA unit test class similar to FakeServer, which is able to fake one\nor more routers. It will be used by the router CRUD patches.\n\nChange-Id: I9b87c6c95282902c3a829da51229a35d4265a1e4\nImplements: blueprint neutron-client\nCloses-bug: #1519503\n'}, {'number': 4, 'created': '2015-12-11 17:52:19.000000000', 'files': ['openstackclient/tests/network/v2/fakes.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/185412f28c6eea825760617548e4256ac35003bb', 'message': 'Router: Add class FakeRouter to test ""router xxx"" command\n\nA unit test class similar to FakeServer, which is able to fake one\nor more routers. It will be used by the router CRUD patches.\n\nChange-Id: I9b87c6c95282902c3a829da51229a35d4265a1e4\nImplements: blueprint neutron-client\nPartial-bug: #1519503\n'}]",4,256308,185412f28c6eea825760617548e4256ac35003bb,17,5,4,14937,,,0,"Router: Add class FakeRouter to test ""router xxx"" command

A unit test class similar to FakeServer, which is able to fake one
or more routers. It will be used by the router CRUD patches.

Change-Id: I9b87c6c95282902c3a829da51229a35d4265a1e4
Implements: blueprint neutron-client
Partial-bug: #1519503
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/08/256308/4 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/tests/network/v2/fakes.py'],1,e6de46221e226e0b2d396b04ef9df92a053fe601,bp/neutron-client," class FakeRouter(object): """"""Fake one or more routers."""""" @staticmethod def create_one_router(attrs={}, methods={}): """"""Create a fake router. :param Dictionary attrs: A dictionary with all attributes :param Dictionary methods: A dictionary with all methods :return: A FakeResource object, with id, name, admin_state_up, status, tenant_id """""" # Set default attributes. router_attrs = { 'id': 'router-id-' + uuid.uuid4().hex, 'name': 'router-name-' + uuid.uuid4().hex, 'status': 'ACTIVE', 'admin_state_up': True, 'distributed': False, 'ha': False, 'tenant_id': 'project-id-' + uuid.uuid4().hex, 'external_gateway_info': {}, } # Overwrite default attributes. router_attrs.update(attrs) # Set default methods. router_methods = {} # Overwrite default methods. router_methods.update(methods) router = fakes.FakeResource(info=copy.deepcopy(router_attrs), methods=copy.deepcopy(router_methods), loaded=True) return router @staticmethod def create_routers(attrs={}, methods={}, count=2): """"""Create multiple fake routers. :param Dictionary attrs: A dictionary with all attributes :param Dictionary methods: A dictionary with all methods :param int count: The number of routers to fake :return: A list of FakeResource objects faking the routers """""" routers = [] for i in range(0, count): routers.append(FakeRouter.create_one_router(attrs, methods)) return routers @staticmethod def get_routers(routers=None, count=2): """"""Get an iterable MagicMock object with a list of faked routers. If routers list is provided, then initialize the Mock object with the list. Otherwise create one. :param List routers: A list of FakeResource objects faking routers :param int count: The number of routers to fake :return: An iterable Mock object with side_effect set to a list of faked routers """""" if routers is None: routers = FakeRouter.create_routers(count) return mock.MagicMock(side_effect=routers)",,80,0
openstack%2Fpython-glanceclient~master~I82b6811a187f2f96a89e587756c62b90b960053a,openstack/python-glanceclient,master,I82b6811a187f2f96a89e587756c62b90b960053a,Updated from global requirements,MERGED,2015-12-11 15:25:14.000000000,2015-12-11 20:13:52.000000000,2015-12-11 20:13:51.000000000,"[{'_account_id': 3}, {'_account_id': 6159}]","[{'number': 1, 'created': '2015-12-11 15:25:14.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/96f62fe7a04ebe7a2a8450d16e5ea6c60e56ac90', 'message': 'Updated from global requirements\n\nChange-Id: I82b6811a187f2f96a89e587756c62b90b960053a\n'}]",0,256516,96f62fe7a04ebe7a2a8450d16e5ea6c60e56ac90,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I82b6811a187f2f96a89e587756c62b90b960053a
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/16/256516/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,96f62fe7a04ebe7a2a8450d16e5ea6c60e56ac90,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fmonasca-api~master~Ie0746d66ffd2a4e114f318794e885950a25766e7,openstack/monasca-api,master,Ie0746d66ffd2a4e114f318794e885950a25766e7,Fix bug in creating metric with Java API,MERGED,2015-12-03 19:29:40.000000000,2015-12-11 20:13:10.000000000,2015-12-11 20:13:09.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 18179}, {'_account_id': 18286}]","[{'number': 1, 'created': '2015-12-03 19:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/cf01b7905d6043468225646a10a56f6a4ce71d84', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 2, 'created': '2015-12-04 00:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/169bcaf560a890cfb428033d17de5dc45a9a77a8', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 3, 'created': '2015-12-05 01:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/3bfe1e941669a6ae34dec5125d22e2c213085b93', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 4, 'created': '2015-12-09 01:39:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/2d81b52e7f47182d6b1745848e6cfa89e3c4ce0e', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 5, 'created': '2015-12-09 04:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7d14e30141c5ddbd901a873e54a0c8c526e92fcb', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\nAdd unit test: shouldErrorOnCreateWithoutValue\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 6, 'created': '2015-12-09 04:18:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/1641013270d56a4cd52facf2e800d92df862fc25', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\nAdd unit test: shouldErrorOnCreateWithoutValue\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}, {'number': 7, 'created': '2015-12-09 22:05:01.000000000', 'files': ['java/src/main/java/monasca/api/resource/exception/JsonMappingExceptionManager.java', 'java/src/test/resources/fixtures/metricWithoutValue.json', 'java/src/test/java/monasca/api/resource/MetricResourceTest.java', 'java/src/main/java/monasca/api/app/command/CreateMetricCommand.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/b3ac0c30edb104ac87cc2b0c3609e6c4f3f2216f', 'message': 'Fix bug in creating metric with Java API\n\nIn Java API when creating a metric with timestamp\nis None/Null, it fills the timestamp using current timestamp.\nInstead, it should return an UnprocessableEntity Exception.\nAdd unit test: shouldErrorOnCreateWithoutValue\n\nChange-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7\n'}]",12,253158,b3ac0c30edb104ac87cc2b0c3609e6c4f3f2216f,35,8,7,18179,,,0,"Fix bug in creating metric with Java API

In Java API when creating a metric with timestamp
is None/Null, it fills the timestamp using current timestamp.
Instead, it should return an UnprocessableEntity Exception.
Add unit test: shouldErrorOnCreateWithoutValue

Change-Id: Ie0746d66ffd2a4e114f318794e885950a25766e7
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/58/253158/2 && git format-patch -1 --stdout FETCH_HEAD,"['java/src/test/java/monasca/api/resource/MetricResourceTest.java', 'java/src/main/java/monasca/api/app/command/CreateMetricCommand.java']",2,cf01b7905d6043468225646a10a56f6a4ce71d84,bug/create_metric," @NotNull Long timestamp, double value, @Nullable Map<String, String> valueMeta) { this.timestamp = timestamp;"," @Nullable Long timestamp, double value, @Nullable Map<String, String> valueMeta) { setTimestamp(timestamp); @JsonProperty public void setTimestamp(Long timestamp) { this.timestamp = timestamp == null || timestamp.longValue() == 0L ? System.currentTimeMillis() : timestamp.longValue(); } ",6,15
openstack%2Fironic~master~I7d2310d94e40b1c9c76957382ab19c0076bf42cd,openstack/ironic,master,I7d2310d94e40b1c9c76957382ab19c0076bf42cd,Fix iPXE template for whole disk image,MERGED,2015-12-09 16:34:47.000000000,2015-12-11 20:13:01.000000000,2015-12-11 20:12:59.000000000,"[{'_account_id': 3}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10419}, {'_account_id': 11076}, {'_account_id': 13039}, {'_account_id': 13362}, {'_account_id': 13636}, {'_account_id': 14629}, {'_account_id': 14923}]","[{'number': 1, 'created': '2015-12-09 16:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/fd8e06252b10434d851d51e44a7b70e46247901a', 'message': 'Fix iPXE template for whole disk image\n\nThe goto :boot_whole_disk section in the iPXE template is bogus, the\n""kernel"" command is being used to chain the ""chain.c32"" file, that\ncommand should be ""chain"" and the ""append"" command is not a valid iPXE\ncommand.\n\nThis patch replaces those commands with the ""sanboot"" command from iPXE\nwhich is used to chain the boot process to the local disk.\n\nCloses-Bug: #1524403\nChange-Id: I7d2310d94e40b1c9c76957382ab19c0076bf42cd\n'}, {'number': 2, 'created': '2015-12-10 20:18:14.000000000', 'files': ['ironic/tests/unit/drivers/ipxe_config.template', 'releasenotes/notes/fix-ipxe-template-for-whole-disk-image-943da0311ca7aeb5.yaml', 'ironic/drivers/modules/ipxe_config.template'], 'web_link': 'https://opendev.org/openstack/ironic/commit/952d5c5a06f35181768e52dd660afe548bc6fa60', 'message': 'Fix iPXE template for whole disk image\n\nThe goto :boot_whole_disk section in the iPXE template is bogus, the\n""kernel"" command is being used to chain the ""chain.c32"" file, that\ncommand should be ""chain"" and the ""append"" command is not a valid iPXE\ncommand.\n\nThis patch replaces those commands with the ""sanboot"" command from iPXE\nwhich is (among other things) used to chain the boot process to the\nlocal disk.\n\nCloses-Bug: #1524403\nChange-Id: I7d2310d94e40b1c9c76957382ab19c0076bf42cd\n'}]",7,255362,952d5c5a06f35181768e52dd660afe548bc6fa60,29,12,2,6773,,,0,"Fix iPXE template for whole disk image

The goto :boot_whole_disk section in the iPXE template is bogus, the
""kernel"" command is being used to chain the ""chain.c32"" file, that
command should be ""chain"" and the ""append"" command is not a valid iPXE
command.

This patch replaces those commands with the ""sanboot"" command from iPXE
which is (among other things) used to chain the boot process to the
local disk.

Closes-Bug: #1524403
Change-Id: I7d2310d94e40b1c9c76957382ab19c0076bf42cd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/62/255362/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/ipxe_config.template', 'releasenotes/notes/fix-ipxe-template-for-whole-disk-image-943da0311ca7aeb5.yaml', 'ironic/drivers/modules/ipxe_config.template']",3,fd8e06252b10434d851d51e44a7b70e46247901a,bug/1524403,sanboot --no-describe,kernel chain.c32 append mbr:{{ DISK_IDENTIFIER }} boot,6,6
openstack%2Fnova~master~I37415b89b733c021daa38040fee447cf3934b821,openstack/nova,master,I37415b89b733c021daa38040fee447cf3934b821,default host to service name instead of uuid,MERGED,2015-12-10 16:44:01.000000000,2015-12-11 20:08:19.000000000,2015-12-11 20:08:15.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-10 16:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aff9d803fa2e780a5ff6c3dca8da3de0ed8b1d5e', 'message': 'remove duplicate _setup function\n\nThere is no reason for this test class to override the setup function\nfrom the parent class, it works with the default one. This is part of\nsimplifying the samples code for understandability.\n\nChange-Id: I37415b89b733c021daa38040fee447cf3934b821\n'}, {'number': 2, 'created': '2015-12-10 18:06:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d82237b78b200fe297e8dbd16097c8b50c235c69', 'message': 'default host to service name instead of uuid\n\nThe host associated with a service looks like it really should be a\nhostname and not a uuid in the current code. This changes it to\ndefault to the name of the service started if nothing else is\nspecified in the test fixture. It then updates all samples to expect a\nthing that looks like a name, and not a uuid.\n\nThis also allows us to drop the special casing of this function for\naggregate testing.\n\nChange-Id: I37415b89b733c021daa38040fee447cf3934b821\n'}, {'number': 3, 'created': '2015-12-10 19:05:24.000000000', 'files': ['nova/tests/functional/api_sample_tests/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-index-get-resp.json.tpl', 'nova/tests/fixtures.py', 'nova/tests/functional/api_samples_test_base.py', 'nova/tests/functional/api_sample_tests/test_availability_zone.py', 'nova/tests/functional/api_sample_tests/test_instance_usage_audit_log.py', 'nova/tests/functional/api_sample_tests/api_samples/os-instance-usage-audit-log/inst-usage-audit-log-show-get-resp.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/1431cb6503ab628b7842b75680763be3f1d8b5a5', 'message': 'default host to service name instead of uuid\n\nThe host associated with a service looks like it really should be a\nhostname and not a uuid in the current code. This changes it to\ndefault to the name of the service started if nothing else is\nspecified in the test fixture. It then updates all samples to expect a\nthing that looks like a name, and not a uuid.\n\nThis also allows us to drop the special casing of this function for\naggregate testing.\n\nChange-Id: I37415b89b733c021daa38040fee447cf3934b821\n'}]",4,255976,1431cb6503ab628b7842b75680763be3f1d8b5a5,22,8,3,2750,,,0,"default host to service name instead of uuid

The host associated with a service looks like it really should be a
hostname and not a uuid in the current code. This changes it to
default to the name of the service started if nothing else is
specified in the test fixture. It then updates all samples to expect a
thing that looks like a name, and not a uuid.

This also allows us to drop the special casing of this function for
aggregate testing.

Change-Id: I37415b89b733c021daa38040fee447cf3934b821
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/255976/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/api_sample_tests/test_availability_zone.py'],1,aff9d803fa2e780a5ff6c3dca8da3de0ed8b1d5e,api_samples_2,," def _setup_services(self): self.conductor = self.start_service('conductor', host='conductor', manager=CONF.conductor.manager) self.compute = self.start_service('compute', host='compute') self.cert = self.start_service('cert', host='cert') self.consoleauth = self.start_service('consoleauth', host='consoleauth') self.network = self.start_service('network', host='network') self.scheduler = self.start_service('scheduler', host='scheduler') self.cells = self.start_service('cells', host='cells', manager=CONF.cells.manager) ",0,12
openstack%2Fpuppet-openstack-integration~master~I2b30700dfd64f6e365822035fe2e62d173f4d26f,openstack/puppet-openstack-integration,master,I2b30700dfd64f6e365822035fe2e62d173f4d26f,CI test - do not merge,ABANDONED,2015-12-11 20:03:22.000000000,2015-12-11 20:03:46.000000000,,[],"[{'number': 1, 'created': '2015-12-11 20:03:22.000000000', 'files': ['test'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/99163a3814bb1c0689a6180f80076023fd0162d3', 'message': ""CI test - do not merge\n\nThe goal is to test https://review.openstack.org/#/c/256644/ and makes\nsure we don't break the gate.\n\nChange-Id: I2b30700dfd64f6e365822035fe2e62d173f4d26f\nDepends-On: Ifa464b2c45e7b1d4260ad2c8cac19a6447b257e8\n""}]",0,256662,99163a3814bb1c0689a6180f80076023fd0162d3,2,0,1,3153,,,0,"CI test - do not merge

The goal is to test https://review.openstack.org/#/c/256644/ and makes
sure we don't break the gate.

Change-Id: I2b30700dfd64f6e365822035fe2e62d173f4d26f
Depends-On: Ifa464b2c45e7b1d4260ad2c8cac19a6447b257e8
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/62/256662/1 && git format-patch -1 --stdout FETCH_HEAD,['test'],1,99163a3814bb1c0689a6180f80076023fd0162d3,ci-test,test ,,1,0
openstack%2Ffuel-library~master~Idbbf7696b09aec585d2fa0730e9e27b5b668d805,openstack/fuel-library,master,Idbbf7696b09aec585d2fa0730e9e27b5b668d805,Change wrong field name in openssl config,MERGED,2015-12-11 17:18:57.000000000,2015-12-11 19:59:19.000000000,2015-12-11 19:56:28.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14057}, {'_account_id': 14495}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-11 17:18:57.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/astute/openssl.cnf'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3ea2f4be65a11e879c3b3d48772c0af2286275d9', 'message': ""Change wrong field name in openssl config\n\nUS should be used as 'C'ountry field, not as 'C'ommon 'N'ame.\n\nChange-Id: Idbbf7696b09aec585d2fa0730e9e27b5b668d805\nCloses-Bug: #1525330\n""}]",0,256595,3ea2f4be65a11e879c3b3d48772c0af2286275d9,20,12,1,11827,,,0,"Change wrong field name in openssl config

US should be used as 'C'ountry field, not as 'C'ommon 'N'ame.

Change-Id: Idbbf7696b09aec585d2fa0730e9e27b5b668d805
Closes-Bug: #1525330
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/95/256595/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/astute/openssl.cnf'],1,3ea2f4be65a11e879c3b3d48772c0af2286275d9,,C = US,CN = US,1,1
openstack%2Fnova~master~I9affc046300295cdf3e284ccc736019ccaffb9f2,openstack/nova,master,I9affc046300295cdf3e284ccc736019ccaffb9f2,Use testscenarios to set attributes directly,MERGED,2015-12-09 21:00:16.000000000,2015-12-11 19:56:57.000000000,2015-12-11 19:56:54.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-09 21:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6c5630d38d4f0306c0edf205bd8ebdc295beda03', 'message': 'WIP: refactor API samples for clarity\n\nChange-Id: I9affc046300295cdf3e284ccc736019ccaffb9f2\n'}, {'number': 2, 'created': '2015-12-10 14:17:07.000000000', 'files': ['nova/tests/functional/api_sample_tests/test_extension_info.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/functional/api_sample_tests/test_keypairs.py', 'nova/tests/functional/api_sample_tests/test_fixed_ips.py', 'nova/tests/functional/api_sample_tests/test_limits.py', 'nova/tests/functional/api_sample_tests/test_remote_consoles.py', 'nova/tests/functional/api_sample_tests/test_access_ips.py', 'nova/tests/functional/api_sample_tests/test_services.py', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/tests/functional/wsgi/test_secgroup.py', 'nova/tests/functional/api_sample_tests/test_used_limits.py', 'nova/tests/functional/api_samples_test_base.py', 'nova/tests/functional/api_sample_tests/test_virtual_interfaces.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ede70a1973533dca2a38a501d246012eda74c739', 'message': 'Use testscenarios to set attributes directly\n\ntestscenarios was previously used to set an intermediary symbol, which\nthen set additional attributes. This got really complicated to figure\nout what scenarios were really doing, and how to add more (or bypass\nthem in tests).\n\nThis clarifies that usage, unwinds the testscenarios simplifying what\ngets set up.\n\nIt also starts making calls to API v2.1 on the v2.1 url. This is\nsupported with existing API samples docs with a mechanism to update\nlinks if they exist in the docs.\n\nChange-Id: I9affc046300295cdf3e284ccc736019ccaffb9f2\n'}]",20,255519,ede70a1973533dca2a38a501d246012eda74c739,26,10,2,2750,,,0,"Use testscenarios to set attributes directly

testscenarios was previously used to set an intermediary symbol, which
then set additional attributes. This got really complicated to figure
out what scenarios were really doing, and how to add more (or bypass
them in tests).

This clarifies that usage, unwinds the testscenarios simplifying what
gets set up.

It also starts making calls to API v2.1 on the v2.1 url. This is
supported with existing API samples docs with a mechanism to update
links if they exist in the docs.

Change-Id: I9affc046300295cdf3e284ccc736019ccaffb9f2
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/255519/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/api_samples/os-user-data/userdata-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_limits.py', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_remote_consoles.py', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/server-get-resp.json.tpl', 'nova/tests/functional/wsgi/test_secgroup.py', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/v2-version-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_used_limits.py', 'nova/tests/functional/api_sample_tests/api_samples/os-availability-zone/availability-zone-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-create-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-manage/flavor-create-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/image-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_services.py', 'nova/tests/functional/api_sample_tests/api_samples/images/images-details-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/images-list-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_extension_info.py', 'nova/tests/functional/api_sample_tests/api_sample_base.py', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers-sort/server-sort-keys-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-update-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-details-resp.json.tpl', 'nova/tests/functional/api_samples_test_base.py', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-scheduler-hints/scheduler-hints-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_virtual_interfaces.py', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/list-servers-detail-get.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-show-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_keypairs.py', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild-preserve-ephemeral-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_fixed_ips.py', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/versions-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-no-resv-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/server-get-resp.json.tpl']",84,6c5630d38d4f0306c0edf205bd8ebdc295beda03,api_samples_2," ""href"": ""%(host)s/%(api_vers)s/openstack/servers/%(uuid)s"","," ""href"": ""%(host)s/v2/openstack/servers/%(uuid)s"",",232,166
openstack%2Ffuel-library~master~Ib9f179d27bd640379dddec6efffcf8ee24c4ad15,openstack/fuel-library,master,Ib9f179d27bd640379dddec6efffcf8ee24c4ad15,Remove openstack-network from ironic nodes,MERGED,2015-12-10 13:59:01.000000000,2015-12-11 19:48:08.000000000,2015-12-11 19:47:28.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12559}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-10 13:59:01.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/24888bc81b9f41d0cb163d693eb88d2d1bfbd047', 'message': 'Remove openstack-network from ironic nodes\n\nSince Neutron should not bind ports for baremetal instances, openstack-network\nis not required on ironic nodes.\n\nChange-Id: Ib9f179d27bd640379dddec6efffcf8ee24c4ad15\nPartial-bug: #1492272\n'}]",0,255886,24888bc81b9f41d0cb163d693eb88d2d1bfbd047,23,11,1,8259,,,0,"Remove openstack-network from ironic nodes

Since Neutron should not bind ports for baremetal instances, openstack-network
is not required on ironic nodes.

Change-Id: Ib9f179d27bd640379dddec6efffcf8ee24c4ad15
Partial-bug: #1492272
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/86/255886/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml'],1,24888bc81b9f41d0cb163d693eb88d2d1bfbd047,bug/1492272," groups: [primary-controller,controller,compute] requires: [neutron-keystone, neutron-db, netconfig, openstack-controller, top-role-compute] groups: [primary-controller,controller,compute] groups: [primary-controller,controller,compute] groups: [primary-controller,controller,compute]"," groups: [primary-controller,controller,compute,ironic] requires: [neutron-keystone, neutron-db, netconfig, openstack-controller, top-role-compute, ironic-compute] groups: [primary-controller,controller,compute,ironic] groups: [primary-controller,controller,compute,ironic] groups: [primary-controller,controller,compute,ironic]",5,5
openstack%2Fpython-novaclient~master~I810adfef5817fad05b840349473dee220cf2aec2,openstack/python-novaclient,master,I810adfef5817fad05b840349473dee220cf2aec2,Updated from global requirements,MERGED,2015-12-11 15:25:56.000000000,2015-12-11 19:47:47.000000000,2015-12-11 19:47:46.000000000,"[{'_account_id': 3}, {'_account_id': 679}]","[{'number': 1, 'created': '2015-12-11 15:25:56.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/c6dd7c7ba9e9fc3dfa45fa568c26529a63b03431', 'message': 'Updated from global requirements\n\nChange-Id: I810adfef5817fad05b840349473dee220cf2aec2\n'}]",0,256525,c6dd7c7ba9e9fc3dfa45fa568c26529a63b03431,8,2,1,11131,,,0,"Updated from global requirements

Change-Id: I810adfef5817fad05b840349473dee220cf2aec2
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/25/256525/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c6dd7c7ba9e9fc3dfa45fa568c26529a63b03431,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ffuel-library~master~I96c8e38e6be2fa865c870908cbbaf0d95034a952,openstack/fuel-library,master,I96c8e38e6be2fa865c870908cbbaf0d95034a952,Add memcached_addresses variable to hiera,MERGED,2015-12-09 13:26:24.000000000,2015-12-11 19:45:50.000000000,2015-12-11 19:45:07.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12080}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-09 13:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a17944130732a52e8dd7c295f15a05f9c8a8ac15', 'message': 'Add memcached_addresses variable to hiera\n\nIntroduce new variable to have an ability for easy override memcache servers\naddresses.\n\nCloses-Bug: #1524275\nChange-Id: I96c8e38e6be2fa865c870908cbbaf0d95034a952\n'}, {'number': 2, 'created': '2015-12-10 09:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e290cb81d94524eb48b6f1b33ec284835caff9af', 'message': 'Add memcached_addresses variable to hiera\n\nIntroduce new variable to have an ability for easy override memcache servers\naddresses.\n\nCloses-Bug: #1524275\nChange-Id: I96c8e38e6be2fa865c870908cbbaf0d95034a952\n'}, {'number': 3, 'created': '2015-12-10 11:40:49.000000000', 'files': ['tests/noop/astute.yaml/neut_vlan.compute.nossl.yaml', 'tests/noop/spec/hosts/horizon/horizon_spec.rb', 'tests/noop/spec/hosts/roles/ironic-compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb', 'deployment/puppet/osnailyfacter/modular/roles/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/openstack-controller/openstack-controller.pp', 'tests/noop/spec/hosts/roles/compute_spec.rb', 'tests/noop/spec/hosts/openstack-controller/openstack-controller_spec.rb', 'deployment/puppet/osnailyfacter/modular/horizon/horizon.pp', 'tests/noop/astute.yaml/neut_vxlan_dvr.murano.sahara-primary-controller.yaml', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/modular/roles/compute.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a0792cfc77edda553a96c6a39e474ebce0322245', 'message': 'Add memcached_addresses variable to hiera\n\nIntroduce new variable to have an ability for easy override memcache servers\naddresses.\n\nCloses-Bug: #1524275\nChange-Id: I96c8e38e6be2fa865c870908cbbaf0d95034a952\n'}]",2,255254,a0792cfc77edda553a96c6a39e474ebce0322245,48,13,3,11827,,,0,"Add memcached_addresses variable to hiera

Introduce new variable to have an ability for easy override memcache servers
addresses.

Closes-Bug: #1524275
Change-Id: I96c8e38e6be2fa865c870908cbbaf0d95034a952
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/54/255254/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/noop/astute.yaml/neut_vlan.compute.nossl.yaml', 'tests/noop/spec/hosts/horizon/horizon_spec.rb', 'tests/noop/spec/hosts/roles/ironic-compute_spec.rb', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb', 'deployment/puppet/osnailyfacter/modular/roles/ironic-compute.pp', 'deployment/puppet/osnailyfacter/modular/openstack-controller/openstack-controller.pp', 'tests/noop/spec/hosts/roles/compute_spec.rb', 'tests/noop/spec/hosts/openstack-controller/openstack-controller_spec.rb', 'deployment/puppet/osnailyfacter/modular/horizon/horizon.pp', 'tests/noop/astute.yaml/neut_vxlan_dvr.murano.sahara-primary-controller.yaml', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/modular/roles/compute.pp']",14,a17944130732a52e8dd7c295f15a05f9c8a8ac15,memcache_lookup,"$memcached_server = hiera('memcached_addresses') $memcached_port = hiera('memcache_server_port', '11211') cache_server_ip => $memcached_server, cache_server_port => $memcached_port,","$memcache_nodes = get_nodes_hash_by_roles(hiera('network_metadata'), hiera('memcache_roles')) $memcache_ipaddrs = ipsort(values(get_node_to_ipaddr_map_by_network_role($memcache_nodes,'mgmt/memcache'))) cache_server_ip => $memcache_ipaddrs,",184,63
openstack%2Ffuel-library~master~I785ed4fd34e51d88bef5de7b0b9058dcc6fe5002,openstack/fuel-library,master,I785ed4fd34e51d88bef5de7b0b9058dcc6fe5002,Specify Keystone API version for os_privileged_user_auth_url,MERGED,2015-12-09 11:49:21.000000000,2015-12-11 19:45:50.000000000,2015-12-11 19:45:16.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12080}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-09 11:49:21.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89d47f652be9aece838506a984bdb81a9c8246e8', 'message': 'Specify Keystone API version for os_privileged_user_auth_url\n\nCurrently os_privileged_user_auth_url parameter should has specified\nKeystone API version.\n\nChange-Id: I785ed4fd34e51d88bef5de7b0b9058dcc6fe5002\nCloses-bug: #1517424\n'}]",0,255216,89d47f652be9aece838506a984bdb81a9c8246e8,22,8,1,7745,,,0,"Specify Keystone API version for os_privileged_user_auth_url

Currently os_privileged_user_auth_url parameter should has specified
Keystone API version.

Change-Id: I785ed4fd34e51d88bef5de7b0b9058dcc6fe5002
Closes-bug: #1517424
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/16/255216/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb']",3,89d47f652be9aece838506a984bdb81a9c8246e8,bug/1517424," auth_uri = ""#{internal_auth_protocol}://#{keystone_auth_host}:5000/"" identity_uri = ""#{internal_auth_protocol}://#{keystone_auth_host}:5000/"" privileged_auth_uri = ""#{internal_auth_protocol}://#{keystone_auth_host}:5000/v2.0/"" should contain_cinder_config('DEFAULT/os_privileged_user_auth_url').with_value(privileged_auth_uri)"," auth_uri = ""#{internal_auth_protocol}://#{keystone_auth_host}:5000/"" identity_uri = ""#{internal_auth_protocol}://#{keystone_auth_host}:5000/"" should contain_cinder_config('DEFAULT/os_privileged_user_auth_url').with_value(""#{internal_auth_protocol}://#{keystone_auth_host}:5000/"")",12,7
openstack%2Ffuel-library~master~I3dbeaf71b8d0613fb608bf7f997421aabdac6746,openstack/fuel-library,master,I3dbeaf71b8d0613fb608bf7f997421aabdac6746,Allow ssh on master node only from admin interface,MERGED,2015-12-10 08:42:02.000000000,2015-12-11 19:44:54.000000000,2015-12-11 19:44:17.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10489}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12080}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-10 08:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2a6173561274c0db0a894c426b4f7f54eb75cba4', 'message': 'Allow ssh on master node only from admin interface\n\nChange-Id: I3dbeaf71b8d0613fb608bf7f997421aabdac6746\nCloses-Bug: 1523445\n'}, {'number': 2, 'created': '2015-12-10 09:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/b8ce00b307927c043865b5f0f6df2720388bbb3a', 'message': 'Allow to ssh to master node only from admin interface\n\nChange-Id: I3dbeaf71b8d0613fb608bf7f997421aabdac6746\nCloses-Bug: 1523445'}, {'number': 3, 'created': '2015-12-11 08:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f40d8d0bd1db511c6ae407cb455019a0426db793', 'message': 'Allow ssh on master node only from admin interface\n\nDocImpact\nChange-Id: I3dbeaf71b8d0613fb608bf7f997421aabdac6746\nCloses-Bug: 1523445\n'}, {'number': 4, 'created': '2015-12-11 10:19:09.000000000', 'files': ['deployment/puppet/osnailyfacter/manifests/ssh.pp', 'deployment/puppet/nailgun/examples/host-only.pp', 'deployment/puppet/nailgun/manifests/iptables.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aed46b3e842117376d0b63d1d2d74d15e73103ac', 'message': 'Allow ssh on master node only from admin interface\n\nDocImpact\nCloses-Bug: 1523445\nChange-Id: I3dbeaf71b8d0613fb608bf7f997421aabdac6746\n'}]",2,255734,aed46b3e842117376d0b63d1d2d74d15e73103ac,65,12,4,13948,,,0,"Allow ssh on master node only from admin interface

DocImpact
Closes-Bug: 1523445
Change-Id: I3dbeaf71b8d0613fb608bf7f997421aabdac6746
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/34/255734/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/nailgun/manifests/iptables.pp'],1,2a6173561274c0db0a894c426b4f7f54eb75cba4,bug/1500825," port => $ssh_port, proto => 'tcp', iniface => $admin_iface, action => 'accept',"," port => $ssh_port, proto => 'tcp', action => 'accept',",4,3
openstack%2Ffuel-library~master~If065e81c91d5d8a665070540c54ca6f795d862a6,openstack/fuel-library,master,If065e81c91d5d8a665070540c54ca6f795d862a6,Globals cleanup for IP-based Apache VirtualHosts configuration,MERGED,2015-12-11 14:15:09.000000000,2015-12-11 19:44:44.000000000,2015-12-11 19:44:04.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-11 14:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8facf48962208054e0ac3f6183285c5bc6c5e7ed', 'message': 'Globals cleanup for IP-based Apache VirtualHosts configuration\n\nThis commit removes unused keystone_api_address from globals.\n\nChange-Id: If065e81c91d5d8a665070540c54ca6f795d862a6\n'}, {'number': 2, 'created': '2015-12-11 15:23:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3034a14a4d55e6716ffd51c1b5da2325fb12d46a', 'message': 'Globals cleanup for IP-based Apache VirtualHosts configuration\n\nThis commit removes unused keystone_api_address from globals.\n\nChange-Id: If065e81c91d5d8a665070540c54ca6f795d862a6\nCloses-Bug: #1523418'}, {'number': 3, 'created': '2015-12-11 15:25:19.000000000', 'files': ['deployment/puppet/osnailyfacter/templates/globals_yaml.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/777a8b3f6238b8080196aa4f5f6d7b011800ccc3', 'message': 'Globals cleanup for IP-based Apache VirtualHosts configuration\n\nThis commit removes unused keystone_api_address from globals.\n\nChange-Id: If065e81c91d5d8a665070540c54ca6f795d862a6\nRelated-bug: #1523418'}]",0,256425,777a8b3f6238b8080196aa4f5f6d7b011800ccc3,41,7,3,14200,,,0,"Globals cleanup for IP-based Apache VirtualHosts configuration

This commit removes unused keystone_api_address from globals.

Change-Id: If065e81c91d5d8a665070540c54ca6f795d862a6
Related-bug: #1523418",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/25/256425/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/templates/globals_yaml.erb'],1,8facf48962208054e0ac3f6183285c5bc6c5e7ed,bug/1523418,,"<% globals.store ""keystone_api_address"", @keystone_api_address -%>",0,1
openstack%2Fsahara~master~Id44cfe42c26ee4871c96464a64360dfee0db7e23,openstack/sahara,master,Id44cfe42c26ee4871c96464a64360dfee0db7e23,Add missing i18n module into CDH plugin edp_engine,MERGED,2015-12-11 11:16:09.000000000,2015-12-11 19:43:22.000000000,2015-12-11 19:43:20.000000000,"[{'_account_id': 3}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 12038}, {'_account_id': 13953}, {'_account_id': 18399}]","[{'number': 1, 'created': '2015-12-11 11:16:09.000000000', 'files': ['sahara/plugins/cdh/v5_4_0/edp_engine.py', 'sahara/plugins/cdh/v5_3_0/edp_engine.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/52c362ce69a8b2fd1c7831743a37ba5f021e70ee', 'message': 'Add missing i18n module into CDH plugin edp_engine\n\nIn CDH plugin 5.3.0 and 5.4.0, i18n is not imported and result in\n""global name \'_\' is not defined"". Add missing module.\n\nChange-Id: Id44cfe42c26ee4871c96464a64360dfee0db7e23\nCloses-Bug: #1525172\n'}]",0,256354,52c362ce69a8b2fd1c7831743a37ba5f021e70ee,12,6,1,18399,,,0,"Add missing i18n module into CDH plugin edp_engine

In CDH plugin 5.3.0 and 5.4.0, i18n is not imported and result in
""global name '_' is not defined"". Add missing module.

Change-Id: Id44cfe42c26ee4871c96464a64360dfee0db7e23
Closes-Bug: #1525172
",git fetch https://review.opendev.org/openstack/sahara refs/changes/54/256354/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/cdh/v5_4_0/edp_engine.py', 'sahara/plugins/cdh/v5_3_0/edp_engine.py']",2,52c362ce69a8b2fd1c7831743a37ba5f021e70ee,bug/1525172,from sahara.i18n import _,,2,0
openstack%2Ffuel-library~master~I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514,openstack/fuel-library,master,I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514,Unblock installation rpm on centos7    This patch allows passing CI tests on Centos 7. Support SystemD will be added later because package need only on nodes (not at fuel-master),MERGED,2015-12-11 15:17:02.000000000,2015-12-11 19:42:55.000000000,2015-12-11 19:41:33.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7562}, {'_account_id': 7613}, {'_account_id': 8777}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 10474}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12817}, {'_account_id': 13895}, {'_account_id': 14348}, {'_account_id': 14985}, {'_account_id': 16574}]","[{'number': 1, 'created': '2015-12-11 15:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/eb68e56ed0356d97a6718ce831b7f98bb80581ba', 'message': 'Unblock installation rpm on centos7\n   This path allows passing CI tests on Centos 7. Support SystemD will be added later because package need only on nodes (not at fuel-master)\n\nChange-Id: I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514\nRelated-bug:1525269\n'}, {'number': 2, 'created': '2015-12-11 15:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/96fc9c689160b14eca64a9144a25c755b0ea3536', 'message': 'Unblock installation rpm on centos7\n   This path allows passing CI tests on Centos 7. Support SystemD will\nbe added later because package need only on nodes (not at fuel-master)\n\nChange-Id: I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514\nRelated-bug:1525269\n'}, {'number': 3, 'created': '2015-12-11 15:19:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f7a6bdb40d6b12f9e447d97330db5e87789b1d3a', 'message': 'Unblock installation rpm on centos7\n   This patch allows passing CI tests on Centos 7. Support SystemD will\nbe added later because package need only on nodes (not at fuel-master)\n\nChange-Id: I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514\nRelated-bug:1525269\n'}, {'number': 4, 'created': '2015-12-11 17:06:56.000000000', 'files': ['specs/fuel-library8.0.spec'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/37b133ec06b40bd51056343a50f8f78f56f25f9c', 'message': 'Unblock installation rpm on centos7\n   This patch allows passing CI tests on Centos 7. Support SystemD will\nbe added later because package need only on nodes (not at fuel-master)\n\nChange-Id: I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514\nRelated-bug:1525269\n'}]",0,256470,37b133ec06b40bd51056343a50f8f78f56f25f9c,61,16,4,14316,,,0,"Unblock installation rpm on centos7
   This patch allows passing CI tests on Centos 7. Support SystemD will
be added later because package need only on nodes (not at fuel-master)

Change-Id: I9d6ed3bcac58ecec00cf63f7b3c6d840a9801514
Related-bug:1525269
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/70/256470/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/fuel-library8.0.spec'],1,eb68e56ed0356d97a6718ce831b7f98bb80581ba,bug/1525269,,Requires: upstart,0,1
openstack%2Ffuel-library~master~Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188,openstack/fuel-library,master,Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188,Allign tasks for Task-Based Deployment,MERGED,2015-12-01 12:21:31.000000000,2015-12-11 19:40:53.000000000,2015-12-11 19:40:14.000000000,"[{'_account_id': 3}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-01 12:21:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/501c10a28456c8da0c5e97b51171cfcada3a236d', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 2, 'created': '2015-12-01 18:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0fa3c8e16df06d916b31f8751633278263048d6b', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 3, 'created': '2015-12-07 13:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0fd78373f1e4add78cf5e7b4c6f215585589ddc6', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 4, 'created': '2015-12-07 14:40:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/59d1404de06a2d0d480f7635e986861cb53fe4ea', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 5, 'created': '2015-12-07 16:49:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f0254c96f8766f082123d6b1561ee3bc1566c2a9', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 6, 'created': '2015-12-08 15:07:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/510b08192f2bb02aeacb0ec8f069723533ae94c6', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 7, 'created': '2015-12-08 20:03:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f4a9eb2115a738bf0d91ffe726473566a8a4ab4d', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 8, 'created': '2015-12-09 13:31:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2159c80395bea981dc26a4f64d8902b3ca378a9d', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 9, 'created': '2015-12-09 19:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cf03be87956ed51763d51cf0f966cf534ef68f2f', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 10, 'created': '2015-12-10 15:17:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4d42ea05c800878c5bfc0106c1786d0c8efa0e33', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 11, 'created': '2015-12-10 15:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5f0d17460b71ad6f5e2e1b606a2f35017283860a', 'message': 'Create sample modification of YAMLs for Task-Based Deployment\n\nThis is a WIP commit to test current graph serializer for\ntask-based deployment in Astute\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 12, 'created': '2015-12-10 15:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f8e6270fc53d009eca0658f0c44a28990d95ea27', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 13, 'created': '2015-12-10 17:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7be1beb5a707054b05b3c1579072349fa75f1a35', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 14, 'created': '2015-12-10 19:20:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/46c1ee7a86ae87af6b1af852bf9c433426d44cad', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 15, 'created': '2015-12-10 19:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ad1df6182870fda4b172087e5d2cfe04c37c7e82', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 16, 'created': '2015-12-11 10:22:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7944d26fa49c66b6905214c161d8b1bce5f06dfa', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 17, 'created': '2015-12-11 10:45:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ee1a26bfabd52a58315b60ac7b19ad3d73f87d9f', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}, {'number': 18, 'created': '2015-12-11 16:28:41.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/murano/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/cluster/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-haproxy/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/glance/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ironic/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/cluster-haproxy/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/virtual_ips/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ntp/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/swift/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ceilometer/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/heat/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/keystone/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-cinder/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/rabbitmq/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/cluster-vrouter/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/database/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/sahara/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-network/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/roles/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/dns/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/openstack-controller/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bf66477be53b9a0d19630ecd36ae918dee57dea8', 'message': 'Allign tasks for Task-Based Deployment\n\nThis commit introduces cross-nodes dependencies\nto new graph serializer for task-based deployment\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188\n'}]",13,251833,bf66477be53b9a0d19630ecd36ae918dee57dea8,204,6,18,8786,,,0,"Allign tasks for Task-Based Deployment

This commit introduces cross-nodes dependencies
to new graph serializer for task-based deployment

Implements blueprint: task-based-deployment-astute

Change-Id: Idefeb7ba3d42f783f35bc818fef43cc1aa2b0188
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/33/251833/17 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/cluster/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/database/tasks.yaml']",2,501c10a28456c8da0c5e97b51171cfcada3a236d,bp/task-based-deployment-astute," cross-depends: - name: primary-database parameters: puppet_manifest: /etc/puppet/modules/osnailyfacter/modular/database/database.pp puppet_modules: /etc/puppet/modules timeout: 3600 test_pre: cmd: ruby /etc/puppet/modules/osnailyfacter/modular/database/database_pre.rb test_post: cmd: ruby /etc/puppet/modules/osnailyfacter/modular/database/database_post.rb - id: primary-database type: puppet groups: [controller] required_for: [openstack-controller] requires: [deploy_start, openstack-haproxy]",,32,2
openstack%2Fpython-cueclient~master~Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835,openstack/python-cueclient,master,Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835,Updated from global requirements,MERGED,2015-11-27 22:41:47.000000000,2015-12-11 19:40:24.000000000,2015-12-11 19:40:24.000000000,"[{'_account_id': 3}, {'_account_id': 1925}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-11-27 22:41:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cueclient/commit/5689a72a2b4d9f046604bd1909d7f8b3e718b960', 'message': 'Updated from global requirements\n\nChange-Id: Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835\n'}, {'number': 2, 'created': '2015-11-29 02:37:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-cueclient/commit/ca96c30750e352a8977fd6a9df9224999320e1b0', 'message': 'Updated from global requirements\n\nChange-Id: Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835\n'}, {'number': 3, 'created': '2015-12-01 06:09:40.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-cueclient/commit/e51179e8ae8b93cb2ef0af4a706db8cd1f3c8706', 'message': 'Updated from global requirements\n\nChange-Id: Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835\n'}]",0,250968,e51179e8ae8b93cb2ef0af4a706db8cd1f3c8706,13,3,3,11131,,,0,"Updated from global requirements

Change-Id: Ie3c4df8ede6f3e8b5a361a5131f8a8e15d43d835
",git fetch https://review.opendev.org/openstack/python-cueclient refs/changes/68/250968/3 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5689a72a2b4d9f046604bd1909d7f8b3e718b960,openstack/requirements,requests>=2.8.1,"requests!=2.8.0,>=2.5.2",1,1
openstack%2Ffuel-library~master~I8b51651adc2634544f510de8838ebaabcd1e7d43,openstack/fuel-library,master,I8b51651adc2634544f510de8838ebaabcd1e7d43,Get rid of usage of node role in manifests,MERGED,2015-12-10 17:16:55.000000000,2015-12-11 19:38:11.000000000,2015-12-11 19:36:31.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-10 17:16:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/aac170b567f8048e04865f735c06535949420a9a', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 2, 'created': '2015-12-10 17:17:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7b4d04fb38cd1140b095cb3ffc273bf24ff9ec17', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 3, 'created': '2015-12-10 17:49:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/91d5624ac0091a863f2f6c14603ff6f1611ec0ac', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 4, 'created': '2015-12-10 18:03:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/112989d042921c7f45c20aff05380f0dfe8d5670', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 5, 'created': '2015-12-10 18:04:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ee8ae64e4ad7ff10cde3151ac8178dc5e3002541', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 6, 'created': '2015-12-10 19:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f2938ebcd015df1d873ad3e0a8b86f882b0a2663', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 7, 'created': '2015-12-10 19:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f9c7204f7693157e8f74aebb08ce5a92269e387a', 'message': 'Get rid of usage of node role in Ceph manifests [WIP]\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 8, 'created': '2015-12-10 19:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c81076921ef4e45ce20be84b2f556f45ff9f439e', 'message': 'Get rid of usage of node role in Ceph manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 9, 'created': '2015-12-10 19:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8b665c6d98c84e6a8eac4802f37623f616dc7d54', 'message': 'Get rid of usage of node role in Ceph manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 10, 'created': '2015-12-10 20:33:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ac7f131dea60a5751ef884ebf6c3ee1bc496aee5', 'message': 'Get rid of usage of node role in Ceph manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 11, 'created': '2015-12-10 20:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/fece9f3ab6b1d23fd8604d33f6d20588a72f4fe9', 'message': 'Get rid of usage of node role in all manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 12, 'created': '2015-12-10 22:17:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/838a97728505d48a4f619ced767a4aed758c8478', 'message': 'Get rid of usage of node role in all manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 13, 'created': '2015-12-11 11:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0dd0bdd7a7fa30ef38d680356c44dcef9265440f', 'message': 'Get rid of usage of node role in manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 14, 'created': '2015-12-11 11:06:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/93d047221813743abd865798b67b5f7f168391e7', 'message': 'Get rid of usage of node role in manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}, {'number': 15, 'created': '2015-12-11 12:19:33.000000000', 'files': ['deployment/puppet/ceph/manifests/init.pp', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/generate_vips.rb', 'deployment/puppet/osnailyfacter/modular/openstack-network/agents/l3.pp', 'deployment/puppet/osnailyfacter/modular/openstack-network/plugins/ml2.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/modular/cluster/health.pp', 'deployment/puppet/osnailyfacter/modular/openstack-network/agents/metadata.pp', 'deployment/puppet/osnailyfacter/modular/murano/murano.pp', 'deployment/puppet/osnailyfacter/modular/cluster/cluster.pp', 'deployment/puppet/osnailyfacter/modular/roles/mongo.pp', 'deployment/puppet/osnailyfacter/spec/functions/roles_include_spec.rb', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/lib/puppet/parser/functions/roles_include.rb', 'deployment/puppet/osnailyfacter/modular/virtual_ips/virtual_ips.pp', 'deployment/puppet/osnailyfacter/modular/vmware/compute-vmware.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2f57d51324c776062a15898033929a39ec3913e4', 'message': 'Get rid of usage of node role in manifests\n\nChange-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43\nImplements: task-based-deployment-astute\n'}]",3,255996,2f57d51324c776062a15898033929a39ec3913e4,157,9,15,8786,,,0,"Get rid of usage of node role in manifests

Change-Id: I8b51651adc2634544f510de8838ebaabcd1e7d43
Implements: task-based-deployment-astute
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/96/255996/12 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/ceph/manifests/init.pp'],1,aac170b567f8048e04865f735c06535949420a9a,bp/task-based-deployment-astute," $node_roles=hiera('node_roles') if member($node_roles, 'primary-controller') or member($node_roles, 'controller') or member($node_roles,'ceph-mon') or member($node_roles,'ceph-osd') or member($node_roles, 'compute') or member($node_roles, 'cinder'){ if member($node_roles, 'primary-controller') or member($node_roles, 'controller') or member($node_roles,'ceph-mon') or member($node_roles,'ceph-osd'){ if member($node_roles, 'primary-controller') or member($node_roles, 'controller') or member($node_roles,'ceph-mon') { if member($node_roles, 'ceph-osd') {"," if hiera('role') =~ /controller|ceph|compute|cinder/ { if hiera('role') =~ /controller|ceph/ { case hiera('role') { 'primary-controller', 'controller', 'ceph-mon': { 'ceph-osd': { default: {} }",7,8
openstack%2Fopenstack-manuals~master~I1664dc166a4f20c79eff151f57efd09c33df238c,openstack/openstack-manuals,master,I1664dc166a4f20c79eff151f57efd09c33df238c,Remove unused section_compute-configure-backing-storage.xml,ABANDONED,2015-12-08 19:33:51.000000000,2015-12-11 19:37:51.000000000,,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 7923}]","[{'number': 1, 'created': '2015-12-08 19:33:51.000000000', 'files': ['doc/config-reference/compute/section_compute-configure-backing-storage.xml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ffb45d9016d1398bb9f6841abc3ae2ac5e01f1c8', 'message': 'Remove unused section_compute-configure-backing-storage.xml\n\nChange-Id: I1664dc166a4f20c79eff151f57efd09c33df238c\n'}]",0,254923,ffb45d9016d1398bb9f6841abc3ae2ac5e01f1c8,6,4,1,7923,,,0,"Remove unused section_compute-configure-backing-storage.xml

Change-Id: I1664dc166a4f20c79eff151f57efd09c33df238c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/254923/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/compute/section_compute-configure-backing-storage.xml'],1,ffb45d9016d1398bb9f6841abc3ae2ac5e01f1c8,backing-storage-rm,,"<section xmlns=""http://docbook.org/ns/docbook"" xmlns:xi=""http://www.w3.org/2001/XInclude"" xmlns:xlink=""http://www.w3.org/1999/xlink"" version=""5.0"" xml:id=""section_configure-backing-storage""> <title>Configure Compute backing storage</title> <para> Backing Storage is the storage used to provide the expanded operating system image, and any ephemeral storage. Inside the virtual machine, this is normally presented as two virtual hard disks (for example, <filename>/dev/vda</filename> and <filename>/dev/vdb</filename> respectively). However, inside OpenStack, this can be derived from one of three methods: LVM, QCOW or RAW, chosen using the <literal>images_type</literal> option in <filename>nova.conf</filename> on the compute node. </para> <para> QCOW is the default backing store. It uses a copy-on-write philosophy to delay allocation of storage until it is actually needed. This means that the space required for the backing of an image can be significantly less on the real disk than what seems available in the virtual machine operating system. </para> <para> RAW creates files without any sort of file formatting, effectively creating files with the plain binary one would normally see on a real disk. This can increase performance, but means that the entire size of the virtual disk is reserved on the physical disk. </para> <para> Local <link xlink:href=""http://en.wikipedia.org/wiki/Logical_Volume_Manager_(Linux)"" >LVM volumes</link> can also be used. Set <literal>images_volume_group = nova_local</literal> where <literal>nova_local</literal> is the name of the LVM group you have created. </para> </section> ",0,38
openstack%2Fkolla~master~I685ddbc6bb6e0fe25c308c35a7581785eebe3629,openstack/kolla,master,I685ddbc6bb6e0fe25c308c35a7581785eebe3629,Pass environment variables of proxy to tox,MERGED,2015-12-11 00:18:07.000000000,2015-12-11 19:36:41.000000000,2015-12-11 19:36:40.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-12-11 00:18:07.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/kolla/commit/c3c7ee429af2e5c7a8d0b6e6fab2045f291cdef0', 'message': 'Pass environment variables of proxy to tox\n\nWhen a development environment is under a proxy, tox is failed even if\nenvironment variables of the proxy are set.\n\nThis patch fixes this problem.\n\nChange-Id: I685ddbc6bb6e0fe25c308c35a7581785eebe3629\n'}]",0,256158,c3c7ee429af2e5c7a8d0b6e6fab2045f291cdef0,8,4,1,18238,,,0,"Pass environment variables of proxy to tox

When a development environment is under a proxy, tox is failed even if
environment variables of the proxy are set.

This patch fixes this problem.

Change-Id: I685ddbc6bb6e0fe25c308c35a7581785eebe3629
",git fetch https://review.opendev.org/openstack/kolla refs/changes/58/256158/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,c3c7ee429af2e5c7a8d0b6e6fab2045f291cdef0,,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,,1,0
openstack%2Ffuel-library~master~Id041f73d96f24322a9317267b632b9f6d63ac5c8,openstack/fuel-library,master,Id041f73d96f24322a9317267b632b9f6d63ac5c8,Check for Mysql wss constraints among online nodes,MERGED,2015-12-10 13:05:22.000000000,2015-12-11 19:36:11.000000000,2015-12-11 19:35:27.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 14985}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-10 13:05:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0c76e6565defb36a8197a763cb47595ddbe074c4', 'message': 'Check for Mysql wss constraints among online nodes\n\nThis commit introduces additional check into\nget_possible_masters() function that also checks\nif an online node from quorate partitions is\neligible to run mysql resource.\n\nChange-Id: Id041f73d96f24322a9317267b632b9f6d63ac5c8\nCloses-bug: #1524826\nimplements: task-based-deployment-astute\n'}, {'number': 2, 'created': '2015-12-10 15:20:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/67c24acdeef59111377e4b2760370513f54ae26e', 'message': 'Check for Mysql wss constraints among online nodes\n\nThis commit introduces additional check into\nget_possible_masters() function that also checks\nif an online node from quorate partitions is\neligible to run mysql resource.\n\nChange-Id: Id041f73d96f24322a9317267b632b9f6d63ac5c8\nCloses-bug: #1524826\nimplements: task-based-deployment-astute\n'}, {'number': 3, 'created': '2015-12-11 16:58:09.000000000', 'files': ['files/fuel-ha-utils/ocf/mysql-wss'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7050f07fe155e00fd1d3bcbf2658de56c3b25387', 'message': 'Check for Mysql wss constraints among online nodes\n\nThis commit introduces additional check into\nget_possible_masters() function that also checks\nif an online node from quorate partitions is\neligible to run mysql resource.\n\nChange-Id: Id041f73d96f24322a9317267b632b9f6d63ac5c8\nCloses-bug: #1524826\nimplements: task-based-deployment-astute\n'}]",1,255862,7050f07fe155e00fd1d3bcbf2658de56c3b25387,45,11,3,8786,,,0,"Check for Mysql wss constraints among online nodes

This commit introduces additional check into
get_possible_masters() function that also checks
if an online node from quorate partitions is
eligible to run mysql resource.

Change-Id: Id041f73d96f24322a9317267b632b9f6d63ac5c8
Closes-bug: #1524826
implements: task-based-deployment-astute
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/62/255862/1 && git format-patch -1 --stdout FETCH_HEAD,['files/fuel-ha-utils/ocf/mysql-wss'],1,0c76e6565defb36a8197a763cb47595ddbe074c4,bp/task-based-deployment-astute," if [ -z $MASTER ] then ocf_log error ""No master picked."" fi NODE_SCORE=`crm_simulate -Ls | grep ${OCF_RESOURCE_INSTANCE} | grep clone_color | grep -v ""${OCF_RESOURCE_INSTANCE}:"" | grep $NODE | sed -r -e 's/.*score on (.*)/\1/' | awk -F ':' '{print $2}' | tr -d '[:space:]'` if [[ $NODE_SCORE =~ ^-?[0-9]+$ && $NODE_SCORE -le 0 || $NODE_SCORE = ""-INFINITY"" || -z $NODE_SCORE ]] then ocf_log info ""Skipping node $NODE as it is not eligible for running the resource. Its score is ${NODE_SCORE:-NULL}"" continue fi update_node_gtid",,11,1
openstack%2Fnova~master~I1a92077d6c820b4c727b440438d4c06fc20e58e2,openstack/nova,master,I1a92077d6c820b4c727b440438d4c06fc20e58e2,Add Castellan to requirements,ABANDONED,2015-12-10 19:29:04.000000000,2015-12-11 19:35:55.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-10 19:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c099d39ba3ecd2062804e4df019cae1e0e0f9080', 'message': ""Add Castellan to requirements\n\nThis change adds Castellan, a python library\nfor interfacing with a key manager, to Nova's\nrequirements\n\nChange-Id: I1a92077d6c820b4c727b440438d4c06fc20e58e2\nImplements: blueprint nova-support-image-signing\n""}, {'number': 2, 'created': '2015-12-11 15:24:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/5498e037eca4f106dfde5bb2a87c47d33f1ec687', 'message': ""Add Castellan to requirements\n\nThis change adds Castellan, a python library\nfor interfacing with a key manager, to Nova's\nrequirements\n\nChange-Id: I1a92077d6c820b4c727b440438d4c06fc20e58e2\nImplements: blueprint nova-support-image-signing\n""}]",1,256066,5498e037eca4f106dfde5bb2a87c47d33f1ec687,18,8,2,15524,,,0,"Add Castellan to requirements

This change adds Castellan, a python library
for interfacing with a key manager, to Nova's
requirements

Change-Id: I1a92077d6c820b4c727b440438d4c06fc20e58e2
Implements: blueprint nova-support-image-signing
",git fetch https://review.opendev.org/openstack/nova refs/changes/66/256066/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c099d39ba3ecd2062804e4df019cae1e0e0f9080,bp/nova-support-image-signing,castellan>=0.2.0 # Apache-2.0,,1,0
openstack%2Ffuel-library~master~Idc39ebac4c2f1999f1179456990d12cef5e26776,openstack/fuel-library,master,Idc39ebac4c2f1999f1179456990d12cef5e26776,Wrong process name in compute_post modular test,MERGED,2015-12-11 15:13:37.000000000,2015-12-11 19:28:37.000000000,2015-12-11 19:27:15.000000000,"[{'_account_id': 3}, {'_account_id': 7195}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 9439}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13344}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2015-12-11 15:13:37.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/ceilometer/compute_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9a5bbe027ee9c7e39b94b0f205a7343e4869f178', 'message': ""Wrong process name in compute_post modular test\n\nThis commit fix wrong process name 'ceilometer-agent-compute'.\n\nChange-Id: Idc39ebac4c2f1999f1179456990d12cef5e26776\nCloses-Bug: #1524733\n""}]",0,256463,9a5bbe027ee9c7e39b94b0f205a7343e4869f178,20,12,1,14200,,,0,"Wrong process name in compute_post modular test

This commit fix wrong process name 'ceilometer-agent-compute'.

Change-Id: Idc39ebac4c2f1999f1179456990d12cef5e26776
Closes-Bug: #1524733
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/63/256463/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/ceilometer/compute_post.rb'],1,9a5bbe027ee9c7e39b94b0f205a7343e4869f178,bug/1524733,ceilometer-polling,ceilometer-agent-compute,1,1
openstack%2Fmanila~master~Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5,openstack/manila,master,Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5,Updated from global requirements,MERGED,2015-12-08 02:07:07.000000000,2015-12-11 19:25:42.000000000,2015-12-11 18:14:07.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 9207}, {'_account_id': 10621}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 16272}, {'_account_id': 16643}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}]","[{'number': 1, 'created': '2015-12-08 02:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f6bb2075ac7cf827b9e04d70b2a5a3b7f9777b9c', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 2, 'created': '2015-12-08 02:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/34a0b6ba94d7c4f03b6995cceb9f4a4e9419b15b', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 3, 'created': '2015-12-08 10:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/19377dfbf9cc719fca0902f07ced352f8cf2430c', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 4, 'created': '2015-12-09 02:49:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/698b8e6d16c825982f38af48e3135d1698c6e6f7', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 5, 'created': '2015-12-09 18:14:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/3e75b52698b7edad9934c1f9f3f2d03d80304ce7', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 6, 'created': '2015-12-09 21:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/f2e4b71448c839f6d1bd187768386dcdee4a076b', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 7, 'created': '2015-12-11 10:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/909cb73e6593786b4e0e6ced96229b968127d1ca', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}, {'number': 8, 'created': '2015-12-11 15:20:18.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/manila/commit/f416b301890daf93d291f0f75d9888dc8e104201', 'message': 'Updated from global requirements\n\nChange-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5\n'}]",0,254474,f416b301890daf93d291f0f75d9888dc8e104201,88,17,8,11131,,,0,"Updated from global requirements

Change-Id: Iffcf1cc94003c3bfeb0ed1ec9859d55307c9bbc5
",git fetch https://review.opendev.org/openstack/manila refs/changes/74/254474/8 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f6bb2075ac7cf827b9e04d70b2a5a3b7f9777b9c,openstack/requirements,keystonemiddleware>=4.0.0,"keystonemiddleware!=2.4.0,>=2.0.0",1,1
openstack%2Ftooz~master~Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246,openstack/tooz,master,Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246,Create ectd driver with lock support,ABANDONED,2015-01-29 23:19:45.000000000,2015-12-11 19:22:18.000000000,,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 1669}, {'_account_id': 7450}, {'_account_id': 10035}, {'_account_id': 10263}]","[{'number': 1, 'created': '2015-01-29 23:19:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/9bef025ae3bb1ed1ff5a056bdd3fec76e4c12f14', 'message': 'Create basic etcd driver\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nThis requires the python-etcd library. Making sure this library is\nviable before requesting this to be added to global-requirements.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}, {'number': 2, 'created': '2015-01-30 00:14:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/f51d534df80e27c8d121770190319f6c47567ef8', 'message': 'Create basic etcd driver\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nThis requires the python-etcd library. Making sure this library is\nviable before requesting this to be added to global-requirements.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}, {'number': 3, 'created': '2015-02-03 03:18:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/daf61b6d949f3b6d74da397c2cb45b48578f891b', 'message': 'WIP: Create ectd driver with lock support\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}, {'number': 4, 'created': '2015-02-03 04:45:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/9de86e85aad675a3c6da550c59b6aa147262f515', 'message': 'WIP: Create ectd driver with lock support\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}, {'number': 5, 'created': '2015-02-03 04:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/58aa39e1f017663211d970b23dd8dbd5f1b1aeeb', 'message': 'WIP: Create ectd driver with lock support\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}, {'number': 6, 'created': '2015-02-03 20:48:33.000000000', 'files': ['tooz/tests/test_coordination.py', 'tooz/drivers/etcd.py', 'requirements.txt', 'setup-etcd-env.sh', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tooz/commit/a281d40c59a621cd11bb2a23da4c468e1b88eda6', 'message': 'Create ectd driver with lock support\n\nCreating the skeleton and locking implementation for an etcd driver.\n\nChange-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246\n'}]",8,151463,a281d40c59a621cd11bb2a23da4c468e1b88eda6,20,6,6,10035,,,0,"Create ectd driver with lock support

Creating the skeleton and locking implementation for an etcd driver.

Change-Id: Ic9fca3314ecd70cc2d3dabb6324cb1575d2e2246
",git fetch https://review.opendev.org/openstack/tooz refs/changes/63/151463/1 && git format-patch -1 --stdout FETCH_HEAD,"['tooz/drivers/etcd.py', 'setup-etcd-env.sh', 'setup.cfg', 'tox.ini']",4,9bef025ae3bb1ed1ff5a056bdd3fec76e4c12f14,feature/etc-plugin,"[testenv:py27-etcd] commands = {toxinidir}/setup-etcd-env.sh python setup.py testr --slowest --testr-args=""{posargs}"" [testenv:py34-etcd] deps = {[testenv:py34]deps} basepython = python3.4 commands = {toxinidir}/setup-etcd-env.sh python setup.py testr --slowest --testr-args=""{posargs}"" ",,107,0
openstack%2Ffuel-library~master~Iaf9dfe1305da75ade57bf378ac447a4f4ca56d53,openstack/fuel-library,master,Iaf9dfe1305da75ade57bf378ac447a4f4ca56d53,Fix rabbitmq_post user check command,MERGED,2015-12-11 13:18:27.000000000,2015-12-11 19:21:05.000000000,2015-12-11 19:20:18.000000000,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14200}]","[{'number': 1, 'created': '2015-12-11 13:18:27.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq_post.rb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1cddb9b2a000391d8518780ead6c6d2ea9aafc71', 'message': 'Fix rabbitmq_post user check command\n\nFixed Ruby syntax error causing rabbitmq_post.rb to\nfail.\n\nChange-Id: Iaf9dfe1305da75ade57bf378ac447a4f4ca56d53\nCloses-Bug: #1523554\n'}]",0,256400,1cddb9b2a000391d8518780ead6c6d2ea9aafc71,20,5,1,7195,,,0,"Fix rabbitmq_post user check command

Fixed Ruby syntax error causing rabbitmq_post.rb to
fail.

Change-Id: Iaf9dfe1305da75ade57bf378ac447a4f4ca56d53
Closes-Bug: #1523554
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/00/256400/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/osnailyfacter/modular/rabbitmq/rabbitmq_post.rb'],1,1cddb9b2a000391d8518780ead6c6d2ea9aafc71,bug/1524894," cmd = ""ps haxo user,cmd | egrep -v su | egrep \""rabbitmq|beam|epmd\"" | egrep -v ^#{RABBITMQ_USER}"""," cmd = 'ps haxo user,cmd | egrep -v ""su |grep ""| egrep ""rabbitmq|beam|epmd"" | egrep -v ""^' RABBITMQ_USER '""'",1,1
openstack%2Ftap-as-a-service~master~I9b39a8285b03f7849a10bf1e178df8a9a14cb9b1,openstack/tap-as-a-service,master,I9b39a8285b03f7849a10bf1e178df8a9a14cb9b1,Create specs directory,MERGED,2015-12-11 04:33:57.000000000,2015-12-11 19:20:06.000000000,2015-12-11 19:20:05.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 7776}, {'_account_id': 11578}, {'_account_id': 11674}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-12-11 04:33:57.000000000', 'files': ['specs/index.rst', 'doc/source/index.rst', 'doc/source/specs', 'specs/mitaka/.placeholder'], 'web_link': 'https://opendev.org/openstack/tap-as-a-service/commit/c6a42502bb1122ecefe39d8d2b7b8993a56fb987', 'message': 'Create specs directory\n\nChange-Id: I9b39a8285b03f7849a10bf1e178df8a9a14cb9b1\n'}]",0,256209,c6a42502bb1122ecefe39d8d2b7b8993a56fb987,11,6,1,6854,,,0,"Create specs directory

Change-Id: I9b39a8285b03f7849a10bf1e178df8a9a14cb9b1
",git fetch https://review.opendev.org/openstack/tap-as-a-service refs/changes/09/256209/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'specs/index.rst', 'doc/source/specs', 'specs/mitaka/.placeholder']",4,c6a42502bb1122ecefe39d8d2b7b8993a56fb987,specs,,,16,0
openstack%2Fironic~master~I147ea059f75720132dd82ff9e7cd3bfdff7fa584,openstack/ironic,master,I147ea059f75720132dd82ff9e7cd3bfdff7fa584,Add devstack plugin,MERGED,2015-12-10 13:47:30.000000000,2015-12-11 19:16:28.000000000,2015-12-11 19:16:26.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10697}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-12-10 13:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/7dcb36f48b971417a7c5190c2280c3e0637cda92', 'message': 'Add devstack plugin\n\nThis adds the actual devstack plugin, with a signal to devstack that the\nplugin is in use, and devstack should not run the ironic code in the\ndevstack tree.\n\nNote that this is not yet configured to run in the gate.\n\nChange-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}, {'number': 2, 'created': '2015-12-10 14:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5a49b136f40be88c11a45fd4454296d1b3a7b0b6', 'message': 'Add devstack plugin\n\nThis adds the actual devstack plugin, with a signal to devstack that the\nplugin is in use, and devstack should not run the ironic code in the\ndevstack tree.\n\nNote that this is not yet configured to run in the gate.\n\nChange-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}, {'number': 3, 'created': '2015-12-10 14:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/76fbd9ba06c91bf0bdc26e3299cdbc9eba78233d', 'message': 'Add devstack plugin\n\nThis adds the actual devstack plugin, with a signal to devstack that the\nplugin is in use, and devstack should not run the ironic code in the\ndevstack tree.\n\nThis is already enabled for the gate, so landing this turns it on\nimmediately.\n\nChange-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}, {'number': 4, 'created': '2015-12-10 15:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b09a9ccb020bffe37b806c682d494da07abdd0de', 'message': 'Add devstack plugin\n\nThis adds the actual devstack plugin, with a signal to devstack that the\nplugin is in use, and devstack should not run the ironic code in the\ndevstack tree.\n\nThis is already enabled for the gate, so landing this turns it on\nimmediately.\n\nChange-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}, {'number': 5, 'created': '2015-12-10 15:38:12.000000000', 'files': ['devstack/lib/ironic', 'devstack/override-defaults', 'devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a0dcef410e3a415c880e67d2d173a87f10110e10', 'message': 'Add devstack plugin\n\nThis adds the actual devstack plugin, with a signal to devstack that the\nplugin is in use, and devstack should not run the ironic code in the\ndevstack tree.\n\nNote that this is not yet configured to run in the gate.\n\nChange-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}]",14,255880,a0dcef410e3a415c880e67d2d173a87f10110e10,36,9,5,10343,,,0,"Add devstack plugin

This adds the actual devstack plugin, with a signal to devstack that the
plugin is in use, and devstack should not run the ironic code in the
devstack tree.

Note that this is not yet configured to run in the gate.

Change-Id: I147ea059f75720132dd82ff9e7cd3bfdff7fa584
",git fetch https://review.opendev.org/openstack/ironic refs/changes/80/255880/4 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/override_defaults', 'devstack/plugin.sh', 'devstack/settings']",3,7dcb36f48b971417a7c5190c2280c3e0637cda92,ironic-devstack-plugin,enable_service ironic ,,51,0
openstack%2Fpython-openstackclient~master~I13835fea1d0151ea0cd93e250b022c9daf74b537,openstack/python-openstackclient,master,I13835fea1d0151ea0cd93e250b022c9daf74b537,Trivial: Fix parameter name typo in network.rst,MERGED,2015-12-10 17:22:50.000000000,2015-12-11 19:09:52.000000000,2015-12-11 19:09:50.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 13111}, {'_account_id': 14937}]","[{'number': 1, 'created': '2015-12-10 17:22:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/12297410d6c281c14914fbae39f823482e241436', 'message': 'Trivial: Fix parameter name typo in network.rst\n\n1. ""network delete"" takes netowrk name or ID, not project\n2. ""network set/show"" takes network name or ID, not only name.\n   So use network, not name.\n\nChange-Id: I13835fea1d0151ea0cd93e250b022c9daf74b537\n'}, {'number': 2, 'created': '2015-12-11 07:31:34.000000000', 'files': ['doc/source/command-objects/network.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/4221bc282d80b99694f7cc57c90d4bbb9f310120', 'message': 'Trivial: Fix parameter name typo in network.rst\n\n1. ""network delete"" takes network name or ID, not project\n2. ""network set/show"" takes network name or ID, not only name.\n   So use network, not name.\n\nChange-Id: I13835fea1d0151ea0cd93e250b022c9daf74b537\n'}]",1,255998,4221bc282d80b99694f7cc57c90d4bbb9f310120,18,5,2,14937,,,0,"Trivial: Fix parameter name typo in network.rst

1. ""network delete"" takes network name or ID, not project
2. ""network set/show"" takes network name or ID, not only name.
   So use network, not name.

Change-Id: I13835fea1d0151ea0cd93e250b022c9daf74b537
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/98/255998/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/command-objects/network.rst'],1,12297410d6c281c14914fbae39f823482e241436,network-sdk-20151211,.. _network_delete-network:.. _network_set-network:.. _network_show-network:,.. _network_delete-project:.. _network_set-name:.. _network_show-name:,3,3
openstack%2Fnova~master~Ia1c58efa7105d32973f6921c2144b17c30b764c2,openstack/nova,master,Ia1c58efa7105d32973f6921c2144b17c30b764c2,Cache the automatic version pin to avoid repeated lookups,MERGED,2015-12-09 17:52:55.000000000,2015-12-11 19:07:40.000000000,2015-12-10 22:29:46.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4393}, {'_account_id': 5170}, {'_account_id': 6873}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-09 17:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1a2df4e34d7c94eff402d8970bc2a6de471696f9', 'message': 'Cut down the automatic RPC version messages to once per version\n\nThe compute rpc api module was logging every time it had to determine\nwhich version should be used automatically. This caches the last value\nand only logs if it changes.\n\nChange-Id: Ia1c58efa7105d32973f6921c2144b17c30b764c2\n'}, {'number': 2, 'created': '2015-12-09 17:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b91377547c18e68f30c3580b64375db765d58f90', 'message': 'Cut down the automatic RPC version messages to once per version\n\nThe compute rpc api module was logging every time it had to determine\nwhich version should be used automatically. This caches the last value\nand only logs if it changes.\n\nCloses-Bug: #1524444\nChange-Id: Ia1c58efa7105d32973f6921c2144b17c30b764c2\n'}, {'number': 3, 'created': '2015-12-10 16:37:04.000000000', 'files': ['nova/tests/unit/compute/test_rpcapi.py', 'nova/compute/manager.py', 'nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/242ee4b5e774ad12a001e5a1482fc4c2e592615f', 'message': ""Cache the automatic version pin to avoid repeated lookups\n\nThe compute rpcapi module was looking up the desired automatic\nversion pin each time it was initialized. Turns out, we create and\ndestroy this object too often, which means we do a lot of those\nlookups unnecessarily. That's a larger problem that will be harder\nto solve, but we can be smarter about the DB impact of that.\n\nThis adds a cache of the last version we discovered and avoids doing\nthe lookup when possible. It makes the reset() method invalidate the\ncache prior to reinitializing the object so that we will do the lookup\non SIGHUP as desired.\n\nCloses-Bug: #1524444\nChange-Id: Ia1c58efa7105d32973f6921c2144b17c30b764c2\n""}]",0,255404,242ee4b5e774ad12a001e5a1482fc4c2e592615f,37,14,3,4393,,,0,"Cache the automatic version pin to avoid repeated lookups

The compute rpcapi module was looking up the desired automatic
version pin each time it was initialized. Turns out, we create and
destroy this object too often, which means we do a lot of those
lookups unnecessarily. That's a larger problem that will be harder
to solve, but we can be smarter about the DB impact of that.

This adds a cache of the last version we discovered and avoids doing
the lookup when possible. It makes the reset() method invalidate the
cache prior to reinitializing the object so that we will do the lookup
on SIGHUP as desired.

Closes-Bug: #1524444
Change-Id: Ia1c58efa7105d32973f6921c2144b17c30b764c2
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/255404/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/rpcapi.py'],1,1a2df4e34d7c94eff402d8970bc2a6de471696f9,okay-we-got-it,"LAST_VERSION = None global LAST_VERSION if version_cap != LAST_VERSION: LAST_VERSION = version_cap LOG.info(_LI('Automatically selected compute RPC version %(rpc)s ' 'from minimum service version %(service)i'), {'rpc': version_cap, 'service': service_version})"," LOG.info(_LI('Automatically selected compute RPC version %(rpc)s ' 'from minimum service version %(service)i'), {'rpc': version_cap, 'service': service_version})",8,4
openstack%2Fceilometer~master~I3552bda5f405d5c526db6641012a457e0ae7fd8c,openstack/ceilometer,master,I3552bda5f405d5c526db6641012a457e0ae7fd8c,update policy.json,ABANDONED,2015-11-26 04:34:54.000000000,2015-12-11 19:04:23.000000000,,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 6676}, {'_account_id': 15843}]","[{'number': 1, 'created': '2015-11-26 04:34:54.000000000', 'files': ['etc/ceilometer/policy.json.sample', 'etc/ceilometer/policy.json'], 'web_link': 'https://opendev.org/openstack/ceilometer/commit/d3e911b1b459f39afccefff2713cc38dd1c7a75c', 'message': 'update policy.json\n\nCurrently our policy.json used by devstack allows all API requests\nwith full privileges, this patch adds rules and changes default to\ncontext_is_admin\n\nChange-Id: I3552bda5f405d5c526db6641012a457e0ae7fd8c\n'}]",0,250147,d3e911b1b459f39afccefff2713cc38dd1c7a75c,7,5,1,6676,,,0,"update policy.json

Currently our policy.json used by devstack allows all API requests
with full privileges, this patch adds rules and changes default to
context_is_admin

Change-Id: I3552bda5f405d5c526db6641012a457e0ae7fd8c
",git fetch https://review.opendev.org/openstack/ceilometer refs/changes/47/250147/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/ceilometer/policy.json.sample', 'etc/ceilometer/policy.json']",2,d3e911b1b459f39afccefff2713cc38dd1c7a75c,update-policy," ""default"": ""rule:context_is_admin"", ""telemetry:get_samples"": ""rule:context_is_project"", ""telemetry:get_sample"": ""rule:context_is_project"", ""telemetry:query_sample"": ""rule:context_is_project"", ""telemetry:create_samples"": ""rule:context_is_admin"", ""telemetry:compute_statistics"": ""rule:context_is_project"", ""telemetry:get_meters"": ""rule:context_is_project"", ""telemetry:get_resource"": ""rule:context_is_project"", ""telemetry:get_resources"": ""rule:context_is_project"", ""telemetry:events:index"": ""rule:context_is_project"", ""telemetry:events:show"": ""rule:context_is_project"""," ""default"": """"",16,19
openstack%2Fhorizon~master~Ifc0a091318296da06168f9701a280eb7357632c7,openstack/horizon,master,Ifc0a091318296da06168f9701a280eb7357632c7,Add version check for listing namespaces,MERGED,2015-11-17 16:25:51.000000000,2015-12-11 18:48:40.000000000,2015-11-20 01:23:49.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 7665}, {'_account_id': 9647}, {'_account_id': 12826}, {'_account_id': 17013}]","[{'number': 1, 'created': '2015-11-17 16:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d1fea69720836b17ae3e06e9356f05273c7b564a', 'message': 'Add version check for listing namespaces\n\nListing metadata definitions namespaces requires glance API version\n2. This adds a check that makes sure an empty array is returned if\nany version less than 2 is being used.\n\nCloses-Bug: #1516711\nChange-Id: Ifc0a091318296da06168f9701a280eb7357632c7\n'}, {'number': 2, 'created': '2015-11-18 03:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/d3c2c111a9ec3597ff016ba58292aa937f306c71', 'message': 'Add version check for listing namespaces\n\nListing metadata definitions namespaces requires glance API version\n2. This adds a check that makes sure an empty array is returned if\nany version less than 2 is being used.\n\nCloses-Bug: #1516711\nChange-Id: Ifc0a091318296da06168f9701a280eb7357632c7\n'}, {'number': 3, 'created': '2015-11-18 03:14:46.000000000', 'files': ['openstack_dashboard/test/api_tests/glance_tests.py', 'openstack_dashboard/test/helpers.py', 'openstack_dashboard/api/glance.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/0578023d881ab77fb6708ca39a99f772763ef1a6', 'message': 'Add version check for listing namespaces\n\nListing metadata definitions namespaces requires glance API version\n2. This adds a check that makes sure an empty array is returned if\nany version less than 2 is being used.\n\nCloses-Bug: #1516711\nPartially-Implements: blueprint horizon-glance-v2\nChange-Id: Ifc0a091318296da06168f9701a280eb7357632c7\n'}]",4,246486,0578023d881ab77fb6708ca39a99f772763ef1a6,15,6,3,9647,,,0,"Add version check for listing namespaces

Listing metadata definitions namespaces requires glance API version
2. This adds a check that makes sure an empty array is returned if
any version less than 2 is being used.

Closes-Bug: #1516711
Partially-Implements: blueprint horizon-glance-v2
Change-Id: Ifc0a091318296da06168f9701a280eb7357632c7
",git fetch https://review.opendev.org/openstack/horizon refs/changes/86/246486/3 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/test/api_tests/glance_tests.py', 'openstack_dashboard/test/helpers.py', 'openstack_dashboard/api/glance.py']",3,d1fea69720836b17ae3e06e9356f05273c7b564a,bp/edit-server-metadata," # Listing namespaces requires the v2 API. If not supported we return an # empty array so callers don't need to worry about version checking. if get_version() < 2: return [], False, False ",,47,1
openstack%2Ftrove~master~I70e6795bcf8a0311d1e0fd163e7693132fc12558,openstack/trove,master,I70e6795bcf8a0311d1e0fd163e7693132fc12558,Add all_tenants params ,ABANDONED,2015-07-30 08:15:23.000000000,2015-12-11 18:45:51.000000000,,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 14576}, {'_account_id': 16226}, {'_account_id': 16553}]","[{'number': 1, 'created': '2015-07-30 08:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/36f02b1e7ceb60ae554cb09aa74c36f56a18f8d6', 'message': 'add all_tenants params for trove list to list the instances beyond all tenants\n\nChange-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558\n'}, {'number': 2, 'created': '2015-07-30 08:16:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/4cff85ea87c2131aaa6d914bf4355bbebaf1a63e', 'message': 'Add all_tenants params for trove list\nTo list the instances belond all tenants\n\nChange-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558\n'}, {'number': 3, 'created': '2015-07-30 10:06:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/99c2fef2eb69065819611804ae2e0e0a529ab3d3', 'message': 'add all_tenants params for trove list to list the instances beyond all tenants\n\nChange-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558\n'}, {'number': 4, 'created': '2015-07-31 02:51:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/503bce70d1663a4033bf60c42df1143600a4bd3a', 'message': 'Add all_tenants params \nFor trove list to list the instances beyond all tenants\n\nChange-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558\n'}, {'number': 5, 'created': '2015-08-02 13:32:31.000000000', 'files': ['trove/instance/models.py', 'trove/instance/service.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/bd3aacc865481bb4f57c594d3c1d5efabf909ffa', 'message': 'Add all_tenants params \n\nFor trove list to list the instances beyond all tenants\n\nChange-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558\n'}]",0,207333,bd3aacc865481bb4f57c594d3c1d5efabf909ffa,25,7,5,16553,,,0,"Add all_tenants params 

For trove list to list the instances beyond all tenants

Change-Id: I70e6795bcf8a0311d1e0fd163e7693132fc12558
",git fetch https://review.opendev.org/openstack/trove refs/changes/33/207333/3 && git format-patch -1 --stdout FETCH_HEAD,"['trove/instance/models.py', 'trove/instance/service.py']",2,36f02b1e7ceb60ae554cb09aa74c36f56a18f8d6,patch," all_tenants = req.params.get('all_tenants',False) servers, marker = models.Instances.load(all_tenants, context, include_clustered)"," servers, marker = models.Instances.load(context, include_clustered)",27,9
openstack%2Ftrove-integration~master~If7134a5750fe26872cb1ef12db2fe0ec7f8cdf29,openstack/trove-integration,master,If7134a5750fe26872cb1ef12db2fe0ec7f8cdf29,incorect arg passed solved,ABANDONED,2015-10-19 11:54:23.000000000,2015-12-11 18:45:16.000000000,,"[{'_account_id': 3}, {'_account_id': 6413}, {'_account_id': 9664}, {'_account_id': 10068}, {'_account_id': 10215}, {'_account_id': 18834}]","[{'number': 1, 'created': '2015-10-19 11:54:23.000000000', 'files': ['scripts/redstack'], 'web_link': 'https://opendev.org/openstack/trove-integration/commit/7a3238dd4af1a7f0e1ca47e114ff4f077d70b94b', 'message': 'incorect arg passed solved\n\nChange-Id: If7134a5750fe26872cb1ef12db2fe0ec7f8cdf29\n'}]",8,236927,7a3238dd4af1a7f0e1ca47e114ff4f077d70b94b,9,6,1,18834,,,0,"incorect arg passed solved

Change-Id: If7134a5750fe26872cb1ef12db2fe0ec7f8cdf29
",git fetch https://review.opendev.org/openstack/trove-integration refs/changes/27/236927/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/redstack'],1,7a3238dd4af1a7f0e1ca47e114ff4f077d70b94b,TOPIC-BRANCH, apt-get update && sudo -E DEBIAN_FRONTEND=noninteractive $HTTP_PROXY $PKG_MGR $PKG_GET_ARGS install $@ yum check-update apt-get install -y -q package && sudo -E DEBIAN_FRONTEND=noninteractive $HTTP_PROXY $PKG_MGR $PKG_GET_ARGS update $@ yum check-update, sudo -E DEBIAN_FRONTEND=noninteractive $HTTP_PROXY $PKG_MGR $PKG_GET_ARGS install $@ sudo -E DEBIAN_FRONTEND=noninteractive $HTTP_PROXY $PKG_MGR $PKG_GET_ARGS update $@,4,2
openstack%2Ftrove~master~Ie40b249791a05bb49bf54f60b2121097dc136710,openstack/trove,master,Ie40b249791a05bb49bf54f60b2121097dc136710,Add all_tenants params to list all instances,ABANDONED,2015-07-30 14:20:19.000000000,2015-12-11 18:40:33.000000000,,"[{'_account_id': 3}, {'_account_id': 5293}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 14576}, {'_account_id': 16553}]","[{'number': 1, 'created': '2015-07-30 14:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/41c23e5d867315675610bbff72ad316794d5ad5a', 'message': 'add all_tenants params to list all instances\n\nChange-Id: Ie40b249791a05bb49bf54f60b2121097dc136710\n'}, {'number': 2, 'created': '2015-07-30 14:26:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/b9f41c44f3feb643bc24630532dbbce37aec960d', 'message': 'add all_tenants params to list all instances\n\nChange-Id: Ie40b249791a05bb49bf54f60b2121097dc136710\n'}, {'number': 3, 'created': '2015-07-30 14:32:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/6c1e91c139980f8c7892daef7ea873f0144987fa', 'message': 'add all_tenants params to list all instances\nWhen a user type ""trove configuration-list"",it should list\nthe configuration that belong itself\'s tenant,not all tenants,\neven if the user has the admin role,he also need to add \nsuch as ""all_tenants"" params.\n\nChange-Id: Ie40b249791a05bb49bf54f60b2121097dc136710\n'}, {'number': 4, 'created': '2015-07-30 14:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/ee12ce32615ee736ce4f8ee843f112ee456eb0cb', 'message': 'add all_tenants params to list all instances\nWhen a user type ""trove configuration-list"",it should list\nthe configuration that belong itself\'s tenant,not all tenants,\neven if the user has the admin role,he also need to add \nsuch as ""all_tenants"" params.\nIf not that,a configuraton is attached to a instance that\nnot belong this user.It\'s a absurdity\n\nChange-Id: Ie40b249791a05bb49bf54f60b2121097dc136710\n'}, {'number': 5, 'created': '2015-07-31 02:48:09.000000000', 'files': ['trove/configuration/service.py', 'trove/configuration/models.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/eabffe19dcd035ecfa0dfa8423f446ee31cad7de', 'message': 'Add all_tenants params to list all instances\n\nWhen a user type ""trove configuration-list"",it should list\nthe configuration that belong itself\'s tenant,not all \ntenants,even if the user has the admin role.he also need \nto add such as ""all_tenants"" params.\n\nIf not that,a configuraton will be attached to a instance that\nnot belong this user\n\nChange-Id: Ie40b249791a05bb49bf54f60b2121097dc136710\n'}]",0,207477,eabffe19dcd035ecfa0dfa8423f446ee31cad7de,16,6,5,16553,,,0,"Add all_tenants params to list all instances

When a user type ""trove configuration-list"",it should list
the configuration that belong itself's tenant,not all 
tenants,even if the user has the admin role.he also need 
to add such as ""all_tenants"" params.

If not that,a configuraton will be attached to a instance that
not belong this user

Change-Id: Ie40b249791a05bb49bf54f60b2121097dc136710
",git fetch https://review.opendev.org/openstack/trove refs/changes/77/207477/4 && git format-patch -1 --stdout FETCH_HEAD,"['trove/configuration/service.py', 'trove/configuration/models.py']",2,41c23e5d867315675610bbff72ad316794d5ad5a,config-all-tenants," def load(all_tenants,context): if all_tenants: db_info = DBConfiguration.find_all(deleted=False) if db_info.count() == 0: LOG.debug(""No configurations found for admin user"") else: db_info = DBConfiguration.find_all(tenant_id=context.tenant, deleted=False) if db_info.count() == 0: LOG.debug(""No configurations found for tenant %s"" % context.tenant) if db_info.count() == 0: LOG.debug(""No configurations found for tenant %s"" % context.tenant) "," def load(context): db_info = DBConfiguration.find_all(deleted=False) if db_info.count() == 0: LOG.debug(""No configurations found for admin user"") if db_info.count() == 0: LOG.debug(""No configurations found for tenant %s"" % context.tenant) ",17,9
openstack%2Ftrove~master~I3b30404cce2bece48764479c0a573e62a739fcef,openstack/trove,master,I3b30404cce2bece48764479c0a573e62a739fcef,Fixed the misused assertEqual,ABANDONED,2015-06-30 08:44:48.000000000,2015-12-11 18:39:57.000000000,,"[{'_account_id': 3}, {'_account_id': 4240}, {'_account_id': 5293}, {'_account_id': 6413}, {'_account_id': 7806}, {'_account_id': 9664}, {'_account_id': 9746}, {'_account_id': 12484}, {'_account_id': 14576}]","[{'number': 1, 'created': '2015-06-30 08:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/599263b956630398e0b9c00fe83ae0513eb91258', 'message': 'Fixed the misused assertEqual\n\nAt places assertEqual has been mis-used for following asserts:\n- self.assertEqual(None, ...)\n- self.assertEqual(False, ...)\n- self.assertEqual(True, ...)\n\nFixed these with the correct assert methods like assertIsNone,\nassertFalse, assertTrue.\n\nChange-Id: I3b30404cce2bece48764479c0a573e62a739fcef\nCloses-Bug: #1445131\n'}, {'number': 2, 'created': '2015-07-01 06:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/trove/commit/446eb1b7c429d3014b17f17a12361c34ef32991c', 'message': 'Fixed the misused assertEqual\n\nAt places assertEqual has been mis-used for following asserts:\n- self.assertEqual(None, ...)\n- self.assertEqual(False, ...)\n- self.assertEqual(True, ...)\n\nFixed these with the correct assert methods like assertIsNone,\nassertFalse, assertTrue.\n\nChange-Id: I3b30404cce2bece48764479c0a573e62a739fcef\nCloses-Bug: #1445131\n'}, {'number': 3, 'created': '2015-07-21 15:51:26.000000000', 'files': ['trove/tests/api/instances_resize.py', 'trove/tests/unittests/guestagent/test_mongodb_manager.py', 'trove/tests/unittests/taskmanager/test_clusters.py', 'trove/tests/unittests/mysql/test_user_controller.py', 'trove/tests/unittests/guestagent/test_configuration.py', 'trove/tests/unittests/secgroups/test_security_group.py', 'trove/tests/unittests/common/test_utils.py', 'trove/tests/unittests/api/common/test_limits.py', 'trove/tests/unittests/common/test_pagination.py'], 'web_link': 'https://opendev.org/openstack/trove/commit/e06d9e648f4cad6fe990c7f6bb1990523b2e76a0', 'message': 'Fixed the misused assertEqual\n\nAt places assertEqual has been mis-used for following asserts:\n- self.assertEqual(None, ...)\n- self.assertEqual(False, ...)\n- self.assertEqual(True, ...)\n\nFixed these with the correct assert methods like assertIsNone,\nassertFalse, assertTrue.\n\nChange-Id: I3b30404cce2bece48764479c0a573e62a739fcef\nCloses-Bug: #1445131\n'}]",0,196980,e06d9e648f4cad6fe990c7f6bb1990523b2e76a0,28,9,3,7806,,,0,"Fixed the misused assertEqual

At places assertEqual has been mis-used for following asserts:
- self.assertEqual(None, ...)
- self.assertEqual(False, ...)
- self.assertEqual(True, ...)

Fixed these with the correct assert methods like assertIsNone,
assertFalse, assertTrue.

Change-Id: I3b30404cce2bece48764479c0a573e62a739fcef
Closes-Bug: #1445131
",git fetch https://review.opendev.org/openstack/trove refs/changes/80/196980/1 && git format-patch -1 --stdout FETCH_HEAD,"['trove/tests/unittests/taskmanager/test_clusters.py', 'trove/tests/unittests/secgroups/test_security_group.py']",2,599263b956630398e0b9c00fe83ae0513eb91258,bug/1445131," self.assertIsNone(sec_mod.SecurityGroup.delete_for_instance( uuid.uuid4(), self.context)) self.assertIsNone(sec_mod.SecurityGroup.delete_for_instance( i_id, self.context)) self.assertIsNone(sec_mod.SecurityGroup.delete_for_instance( i_id, self.context))"," self.assertEqual(None, sec_mod.SecurityGroup.delete_for_instance( uuid.uuid4(), self.context)) self.assertEqual(None, sec_mod.SecurityGroup.delete_for_instance( i_id, self.context)) self.assertEqual(None, sec_mod.SecurityGroup.delete_for_instance( i_id, self.context))",12,15
openstack%2Fproject-config~master~I23a29bc540163a936da285ee3bf37ae2fecb7694,openstack/project-config,master,I23a29bc540163a936da285ee3bf37ae2fecb7694,remove grenade partial cpu from kilo,MERGED,2015-12-11 18:16:23.000000000,2015-12-11 18:39:55.000000000,2015-12-11 18:39:54.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 4146}]","[{'number': 1, 'created': '2015-12-11 18:16:23.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f14c99bb79eb4eb6b125402652a94dbc33f435e3', 'message': ""remove grenade partial cpu from kilo\n\nGrenade jobs shouldn't get run on kilo, this got missed in the juno\nsymbol cleanup because the regex was a little specialized.\n\nChange-Id: I23a29bc540163a936da285ee3bf37ae2fecb7694\n""}]",0,256621,f14c99bb79eb4eb6b125402652a94dbc33f435e3,7,3,1,2750,,,0,"remove grenade partial cpu from kilo

Grenade jobs shouldn't get run on kilo, this got missed in the juno
symbol cleanup because the regex was a little specialized.

Change-Id: I23a29bc540163a936da285ee3bf37ae2fecb7694
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/256621/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,f14c99bb79eb4eb6b125402652a94dbc33f435e3,kilofix," # # NOTE(sdague) when you remove the kilo branch, remove this line # as well. branch: ^stable/liberty$", branch: ^stable/(kilo|liberty)$,4,1
openstack%2Ftempest~master~I36b94d6b9f136ca65cb361a8af65966f21b86b03,openstack/tempest,master,I36b94d6b9f136ca65cb361a8af65966f21b86b03,Change docstring of compute client,MERGED,2015-12-07 07:23:35.000000000,2015-12-11 18:39:35.000000000,2015-12-11 18:39:33.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 18600}]","[{'number': 1, 'created': '2015-12-07 07:23:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/4168bc8a899c3780ec085d093ab5b7fe3db3087b', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}, {'number': 2, 'created': '2015-12-07 07:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/9095d4e01f8534692285c4d06b1de2aa8f3ff20a', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}, {'number': 3, 'created': '2015-12-08 01:16:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/fe88bec3e2308c196e54b9665754e70e1d302443', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}, {'number': 4, 'created': '2015-12-09 06:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d366a7e014f24a42e4a3f811e378b44f342e3df9', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nNOTE: This patch changes the methods which call ""/servers"" only.\n      The other methods like ""/servers/<id>/action/"" will be changed\n      with the other patches because servers_client is big and it is\n      difficult to change/review all of them in a single patch.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}, {'number': 5, 'created': '2015-12-09 07:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/45b8010f461845f6c676a2e47e7be6ba9e67520a', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nNOTE: This patch changes the methods which call ""/servers"" only.\n      The other methods like ""/servers/<id>/action/"" will be changed\n      with the other patches because servers_client is big and it is\n      difficult to change/review all of them in a single patch.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}, {'number': 6, 'created': '2015-12-10 07:39:44.000000000', 'files': ['tempest/services/compute/json/servers_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/db82105fd539792d250e919191b0ddcafe5bc590', 'message': 'Change docstring of compute client\n\nWe need to put the links to api-site for explaining what parameters\ncan be passed to Nova, then this patch adds them.\nIn addition, this patch changes docstring for the consistency.\n\nNOTE: This patch changes the methods which call ""/servers"" only.\n      The other methods like ""/servers/<id>/action/"" will be changed\n      with the other patches because servers_client is big and it is\n      difficult to change/review all of them in a single patch.\n\nPartially implements blueprint consistent-service-method-names\n\nChange-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03\n'}]",4,254043,db82105fd539792d250e919191b0ddcafe5bc590,61,12,6,6167,,,0,"Change docstring of compute client

We need to put the links to api-site for explaining what parameters
can be passed to Nova, then this patch adds them.
In addition, this patch changes docstring for the consistency.

NOTE: This patch changes the methods which call ""/servers"" only.
      The other methods like ""/servers/<id>/action/"" will be changed
      with the other patches because servers_client is big and it is
      difficult to change/review all of them in a single patch.

Partially implements blueprint consistent-service-method-names

Change-Id: I36b94d6b9f136ca65cb361a8af65966f21b86b03
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/254043/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/services/compute/json/servers_client.py'],1,4168bc8a899c3780ec085d093ab5b7fe3db3087b,bp/consistent-service-method-names," """"""Create server. Available params: see http://developer.openstack.org/ api-ref-compute-v2.1.html#createServer """"""Update server. Available params: see http://developer.openstack.org/ api-ref-compute-v2.1.html#updateServer """"""Get server details."""""" """"""Delete server."""""" """"""List servers."""""" """"""Removes the encrypted server password from the metadata server. Available params: see http://developer.openstack.org/ api-ref-compute-v2.1.html#rebuild Available params: see http://developer.openstack.org/ api-ref-compute-v2.1.html#resize """"""Attache a volume to a server instance."""""" """"""Detache a volume from a server instance."""""" """"""Return the list of volume attachments for a given instance."""""" """"""Add a security group to the server."""""" """"""Remove a security group from the server."""""" """"""This should be called with administrator privileges."""""" """"""Migrate a server to a new host."""""" """"""Lock the given server."""""" """"""UNlock the given server."""""" """"""Suspend the provided server."""""" """"""Un-suspend the provided server."""""" """"""Pause the provided server."""""" """"""Un-pause the provided server."""""" """"""Reset the state of a server to active/error."""""" """"""Shelve the provided server."""""" """"""Un-shelve the provided server."""""" """"""Return the action details of the provided server."""""" """"""Reset the Network of a server."""""" """"""Inject the Network Info into server."""""""," """"""Create server """"""Update server """"""Get server details"""""" """"""Delete server"""""" """"""List servers"""""" """"""Removes the encrypted server password from the metadata server """"""Attaches a volume to a server instance."""""" """"""Detaches a volume from a server instance."""""" """"""Returns the list of volume attachments for a given instance."""""" """"""Adds a security group to the server."""""" """"""Removes a security group from the server."""""" """"""This should be called with administrator privileges ."""""" """"""Migrates a server to a new host."""""" """"""Locks the given server."""""" """"""UNlocks the given server."""""" """"""Suspends the provided server."""""" """"""Un-suspends the provided server."""""" """"""Pauses the provided server."""""" """"""Un-pauses the provided server."""""" """"""Resets the state of a server to active/error."""""" """"""Shelves the provided server."""""" """"""Un-shelves the provided server."""""" """"""Returns the action details of the provided server."""""" """"""Resets the Network of a server"""""" """"""Inject the Network Info into server""""""",37,25
openstack%2Fmonasca-api~master~Id946090068fe2411951d437cc8f82f1722bd20b1,openstack/monasca-api,master,Id946090068fe2411951d437cc8f82f1722bd20b1,Add the rejected value into error message,MERGED,2015-12-07 22:15:16.000000000,2015-12-11 18:37:59.000000000,2015-12-11 18:37:57.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 11809}, {'_account_id': 12512}, {'_account_id': 14273}, {'_account_id': 14517}, {'_account_id': 15027}, {'_account_id': 18179}, {'_account_id': 18286}]","[{'number': 1, 'created': '2015-12-07 22:15:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/d911136a1989a9b136bb0f41a68287befe900cd1', 'message': 'Add the rejected value into error message\n\nChange-Id: Id946090068fe2411951d437cc8f82f1722bd20b1\n'}, {'number': 2, 'created': '2015-12-07 22:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/7f07f13c0bdbc59c551dfe0fbc0066d1a256dbed', 'message': 'Add the rejected value into error message\n\nIn error message, add the value which API \nrejected in it to show more information.\n\nChange-Id: Id946090068fe2411951d437cc8f82f1722bd20b1\n'}, {'number': 3, 'created': '2015-12-08 17:14:52.000000000', 'files': ['java/src/main/java/monasca/api/app/validation/Validation.java'], 'web_link': 'https://opendev.org/openstack/monasca-api/commit/29a53ac3ff4d618d22f849addc89abdfa12a718c', 'message': 'Add the rejected value into error message\n\nIn error message, add the value which API\nrejected in it to show more information.\n\nChange-Id: Id946090068fe2411951d437cc8f82f1722bd20b1\n'}]",0,254407,29a53ac3ff4d618d22f849addc89abdfa12a718c,16,9,3,18179,,,0,"Add the rejected value into error message

In error message, add the value which API
rejected in it to show more information.

Change-Id: Id946090068fe2411951d437cc8f82f1722bd20b1
",git fetch https://review.opendev.org/openstack/monasca-api refs/changes/07/254407/3 && git format-patch -1 --stdout FETCH_HEAD,['java/src/main/java/monasca/api/app/validation/Validation.java'],1,d911136a1989a9b136bb0f41a68287befe900cd1,bug/error_message," throw Exceptions.unprocessableEntity(""%s (%s) must be an ISO 8601 formatted time"", parameterName, date); throw Exceptions.unprocessableEntity(""%s (=%s) must be valid number"", parameterName, number); throw Exceptions.badRequest(""start_time (%s) must be before end_time (%s)"", startTime, endTime);"," throw Exceptions.unprocessableEntity(""%s must be an ISO 8601 formatted time"", parameterName); throw Exceptions.unprocessableEntity(""%s must be valid number"", parameterName); throw Exceptions.badRequest(""start_time must be before end_time"");",3,3
openstack%2Ftripleo-common~master~I9d456a157e4803f62a95fc69013f51e97b23dfa1,openstack/tripleo-common,master,I9d456a157e4803f62a95fc69013f51e97b23dfa1,Pin puppetlabs-mysql to get CI going,MERGED,2015-12-11 16:35:30.000000000,2015-12-11 18:37:32.000000000,2015-12-11 18:37:31.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 1926}, {'_account_id': 4328}, {'_account_id': 7505}]","[{'number': 1, 'created': '2015-12-11 16:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f005c9a0756f320110227eedc968f1e66a60d1a6', 'message': ""Pin puppetlabs-mysql to get CI going\n\nThe recent CI downtime is reportedly caused by update to\npuppetlabs-mysql. Let's pin it first and then un-pin together with a\nfix, or wait till puppetlabs-mysql is fixed. It's not yet obvious where\nthe fix should happen.\n\nChange-Id: I9d456a157e4803f62a95fc69013f51e97b23dfa1\nRelated-Bug: #1525314\n""}, {'number': 2, 'created': '2015-12-11 16:44:35.000000000', 'files': ['scripts/tripleo.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/aa7dc205bdaa3879890cc3374659f250eca4a0eb', 'message': ""Pin puppetlabs-mysql to get CI going\n\nThe recent CI downtime is reportedly caused by update to\npuppetlabs-mysql. Let's pin it first and then un-pin together with a\nfix, or wait till puppetlabs-mysql is fixed. It's not yet obvious where\nthe fix should happen.\n\nChange-Id: I9d456a157e4803f62a95fc69013f51e97b23dfa1\nRelated-Bug: #1525314\n""}]",2,256572,aa7dc205bdaa3879890cc3374659f250eca4a0eb,13,5,2,8042,,,0,"Pin puppetlabs-mysql to get CI going

The recent CI downtime is reportedly caused by update to
puppetlabs-mysql. Let's pin it first and then un-pin together with a
fix, or wait till puppetlabs-mysql is fixed. It's not yet obvious where
the fix should happen.

Change-Id: I9d456a157e4803f62a95fc69013f51e97b23dfa1
Related-Bug: #1525314
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/72/256572/1 && git format-patch -1 --stdout FETCH_HEAD,['scripts/tripleo.sh'],1,f005c9a0756f320110227eedc968f1e66a60d1a6,bug/1525314, # pin for https://bugs.launchpad.net/tripleo/+bug/1525314 DIB_REPOREF_puppetlabs_mysql=60393f7d4a42d96e67436249b940a2374bffbe77 # pin for https://bugs.launchpad.net/tripleo/+bug/1525314 DIB_REPOREF_puppetlabs_mysql=60393f7d4a42d96e67436249b940a2374bffbe77 ,,8,0
openstack%2Fsahara~master~Ie10ff480406b95da5cc38d29cd135dcca47f6652,openstack/sahara,master,Ie10ff480406b95da5cc38d29cd135dcca47f6652,Updated from global requirements,MERGED,2015-12-11 15:26:40.000000000,2015-12-11 18:37:24.000000000,2015-12-11 18:37:23.000000000,"[{'_account_id': 3}, {'_account_id': 7213}, {'_account_id': 12038}]","[{'number': 1, 'created': '2015-12-11 15:26:40.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/sahara/commit/5810e7107af486b516420d4af4e5eaf6c2dcd173', 'message': 'Updated from global requirements\n\nChange-Id: Ie10ff480406b95da5cc38d29cd135dcca47f6652\n'}]",0,256531,5810e7107af486b516420d4af4e5eaf6c2dcd173,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: Ie10ff480406b95da5cc38d29cd135dcca47f6652
",git fetch https://review.opendev.org/openstack/sahara refs/changes/31/256531/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5810e7107af486b516420d4af4e5eaf6c2dcd173,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fpython-tripleoclient~stable%2Fliberty~Idbf85d455f348ed2ab9b34fe1dc95faec427a13f,openstack/python-tripleoclient,stable/liberty,Idbf85d455f348ed2ab9b34fe1dc95faec427a13f,Remove parameter defaults,MERGED,2015-11-17 20:43:28.000000000,2015-12-11 18:37:22.000000000,2015-12-11 18:37:21.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 9979}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-11-17 20:43:28.000000000', 'files': ['tripleoclient/constants.py', 'doc/source/command-objects/overcloud.rst', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e07627b30e464172d402e6783a7bfe32a6e43ff0', 'message': 'Remove parameter defaults\n\nRemove parameters that have sane defaults in the Heat templates.\nIn order to change these, one should use an environment file rather\nthan passing args to the deploy command. These commands should now\nbe considered deprecated in favor of the environment file.\n\nChange-Id: Idbf85d455f348ed2ab9b34fe1dc95faec427a13f\nDepends-On: Ifd740c50ee0e48e0cf50d9ebd9cc282155cb3a6d\n'}]",0,246595,e07627b30e464172d402e6783a7bfe32a6e43ff0,22,6,1,9979,,,0,"Remove parameter defaults

Remove parameters that have sane defaults in the Heat templates.
In order to change these, one should use an environment file rather
than passing args to the deploy command. These commands should now
be considered deprecated in favor of the environment file.

Change-Id: Idbf85d455f348ed2ab9b34fe1dc95faec427a13f
Depends-On: Ifd740c50ee0e48e0cf50d9ebd9cc282155cb3a6d
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/95/246595/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/constants.py', 'doc/source/command-objects/overcloud.rst', 'tripleoclient/v1/overcloud_deploy.py']",3,e07627b30e464172d402e6783a7bfe32a6e43ff0,liberty," 'with arbitrary physical_network names. ' '(DEPRECATED)')) '(default: datacentre:br-ex) ' '(DEPRECATED)')) help=_('The network type for tenant networks. ' '(DEPRECATED)')) '(gre and/or vxlan). ' '(DEPRECATED)')) ""available for tenant network allocation "" ""(DEPRECATED)""),) ""available for tenant network allocation "" ""(DEPRECATED)""),) help=_('Disables tunneling. (DEPRECATED)')), '(ex: datacentre:1:1000) (DEPRECATED)')) 'neutron.ml2.extension_drivers namespace. ' '(DEPRECATED)')) help=_('The NTP for overcloud nodes. '))"," 'with arbitrary physical_network names.')) '(default: datacentre:br-ex)')) help=_('The network type for tenant networks.')) '(gre and/or vxlan).')) ""available for tenant network allocation""),) ""available for tenant network allocation""),) help=_('Disables tunneling.')), '(ex: datacentre:1:1000)')) 'neutron.ml2.extension_drivers namespace.')) help=_('The NTP for overcloud nodes.'))",42,60
openstack%2Fec2-api~master~I208ecdd5f06db6c6de76f3b52340d955d2a9bd38,openstack/ec2-api,master,I208ecdd5f06db6c6de76f3b52340d955d2a9bd38,test https endpoints with devstack-EXPERIMENTAL,ABANDONED,2015-10-27 20:51:04.000000000,2015-12-11 18:37:22.000000000,,"[{'_account_id': 3}, {'_account_id': 2607}, {'_account_id': 9312}, {'_account_id': 10224}, {'_account_id': 10234}, {'_account_id': 12609}]","[{'number': 1, 'created': '2015-10-27 20:51:04.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/cea6c51ebd4670aa98e3dc699107925b6b8aa70b', 'message': 'test https endpoints with devstack-EXPERIMENTAL\n\nChange-Id: I208ecdd5f06db6c6de76f3b52340d955d2a9bd38\n'}]",0,239752,cea6c51ebd4670aa98e3dc699107925b6b8aa70b,9,6,1,12609,,,0,"test https endpoints with devstack-EXPERIMENTAL

Change-Id: I208ecdd5f06db6c6de76f3b52340d955d2a9bd38
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/52/239752/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,cea6c51ebd4670aa98e3dc699107925b6b8aa70b,test-https-devstack," $service_id public ""https://$SERVICE_HOST:$port/"" $service_id admin ""https://$SERVICE_HOST:$port/"" $service_id internal ""https://$SERVICE_HOST:$port/"""," $service_id public ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/"" $service_id admin ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/"" $service_id internal ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/""",3,3
openstack%2Fcinder~master~Icf54dc63b8402963977f2aa6eca7ebe41b616c3e,openstack/cinder,master,Icf54dc63b8402963977f2aa6eca7ebe41b616c3e,db: Add support for snapshot_admin_metadata,ABANDONED,2015-07-21 09:39:37.000000000,2015-12-11 18:37:10.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 4190}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8247}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 10796}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12249}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 12924}, {'_account_id': 13203}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13915}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 17151}]","[{'number': 1, 'created': '2015-07-21 09:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/755660c7cc294c717bdb9d92abc9301cb26499f1', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}, {'number': 2, 'created': '2015-07-29 12:34:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/09be456f92867f262d948050a4c3d3bbce0dae1b', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}, {'number': 3, 'created': '2015-07-29 15:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/139937b372bf94ac05eae786e6e34b235321db76', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}, {'number': 4, 'created': '2015-07-30 10:41:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4c9263ca6a374cd65e69999c407c5aa14669fef6', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}, {'number': 5, 'created': '2015-08-02 07:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/588bf05020d3a9d4bfce9b5da13fe1e654f81aad', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}, {'number': 6, 'created': '2015-08-03 14:01:12.000000000', 'files': ['etc/cinder/policy.json', 'cinder/db/sqlalchemy/migrate_repo/versions/051_add_snapshot_admin_metadata_table.py', 'cinder/db/api.py', 'cinder/exception.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/test_migrations.py', 'cinder/objects/snapshot.py', 'cinder/db/sqlalchemy/models.py', 'cinder/tests/unit/objects/test_snapshot.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/704454a1f18858f9108ad2721bfc6f03d6e1d7fa', 'message': 'db: Add support for snapshot_admin_metadata\n\nIntroduce snapshot_admin_metadata table which can be used to store\nadmin metadata related to snapshots. This work is part of the\noverall assisted-snapshot-improvements blueprint.\n\nPartially Implements: blueprint assisted-snapshot-improvements\n\nChange-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e\n'}]",95,203979,704454a1f18858f9108ad2721bfc6f03d6e1d7fa,110,37,6,10796,,,0,"db: Add support for snapshot_admin_metadata

Introduce snapshot_admin_metadata table which can be used to store
admin metadata related to snapshots. This work is part of the
overall assisted-snapshot-improvements blueprint.

Partially Implements: blueprint assisted-snapshot-improvements

Change-Id: Icf54dc63b8402963977f2aa6eca7ebe41b616c3e
",git fetch https://review.opendev.org/openstack/cinder refs/changes/79/203979/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/db/sqlalchemy/migrate_repo/versions/049_add_snapshot_admin_metadata_table.py', 'cinder/db/api.py', 'cinder/exception.py', 'cinder/db/sqlalchemy/api.py', 'cinder/tests/unit/fake_snapshot.py', 'cinder/tests/unit/test_migrations.py', 'cinder/db/sqlalchemy/models.py', 'cinder/objects/snapshot.py', 'cinder/tests/unit/objects/test_snapshot.py']",9,755660c7cc294c717bdb9d92abc9301cb26499f1,bp/assisted-snapshot-improvements,"del fake_db_snapshot['admin_metadata'] snapshot.admin_metadata = {'key2': 'value2'} self.assertEqual({}, snapshot._orig_admin_metadata) snapshot.obj_reset_changes(['metadata', 'admin_metadata']) self.assertEqual({'key2': 'value2'}, snapshot._orig_admin_metadata) @mock.patch('cinder.db.snapshot_admin_metadata_update', return_value={'key2': 'value2'}) snapshot_metadata_update, snapshot_admin_metadata_update): snapshot.admin_metadata = {'key2': 'value2'} 'metadata': {'key1': 'value1'}, 'admin_metadata': {'key2': 'value2'}}, snapshot_admin_metadata_update.assert_called_once_with( self.context, '1', {'key2': 'value2'}, True) @mock.patch('cinder.db.snapshot_admin_metadata_delete') def test_delete_admin_metadata_key(self, snapshot_admin_metadata_delete): snapshot = objects.Snapshot(self.context, id=1) snapshot.admin_metadata = {'key1': 'value1', 'key2': 'value2'} self.assertEqual({}, snapshot._orig_admin_metadata) snapshot.delete_admin_metadata_key(self.context, 'key2') self.assertEqual({'key1': 'value1'}, snapshot.admin_metadata) snapshot_admin_metadata_delete.assert_called_once_with( self.context, '1', 'key2') "," snapshot.obj_reset_changes(['metadata']) snapshot_metadata_update): 'metadata': {'key1': 'value1'}},",286,5
openstack%2Fec2-api~master~I4ed4046ae950f56800255078a29d3c459fef1d3d,openstack/ec2-api,master,I4ed4046ae950f56800255078a29d3c459fef1d3d,test ec_scheme opt for https endpoint,ABANDONED,2015-10-27 22:53:11.000000000,2015-12-11 18:37:09.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-10-27 22:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/28cd3289d6bb8ca55728633307a47b29238aba18', 'message': 'test requests.request with verify false for https endpoint\n\nChange-Id: I4ed4046ae950f56800255078a29d3c459fef1d3d\n'}, {'number': 2, 'created': '2015-10-27 23:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/8540e25e0f51ac3fdcf0493d02af77da9edf669d', 'message': 'test requests.request with verify true for https endpoint\n\nChange-Id: I4ed4046ae950f56800255078a29d3c459fef1d3d\n'}, {'number': 3, 'created': '2015-10-28 04:48:36.000000000', 'files': ['devstack/plugin.sh', 'ec2api/api/availability_zone.py'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/2612a44f796edb47e15655540789e73ca4da31ae', 'message': 'test ec_scheme opt for https endpoint\n\nChange-Id: I4ed4046ae950f56800255078a29d3c459fef1d3d\n'}]",0,239768,2612a44f796edb47e15655540789e73ca4da31ae,7,1,3,12609,,,0,"test ec_scheme opt for https endpoint

Change-Id: I4ed4046ae950f56800255078a29d3c459fef1d3d
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/68/239768/1 && git format-patch -1 --stdout FETCH_HEAD,"['ec2api/api/__init__.py', 'devstack/plugin.sh']",2,28cd3289d6bb8ca55728633307a47b29238aba18,check-verify-ssl-false," $service_id public ""https://$SERVICE_HOST:$port/"" $service_id admin ""https://$SERVICE_HOST:$port/"" $service_id internal ""https://$SERVICE_HOST:$port/"""," $service_id public ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/"" $service_id admin ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/"" $service_id internal ""$SERVICE_PROTOCOL://$SERVICE_HOST:$port/""",4,4
openstack%2Fcinder~master~Ic719111913d5c1ccd6517fc035ac8681a91aa7c6,openstack/cinder,master,Ic719111913d5c1ccd6517fc035ac8681a91aa7c6,Add rootwrap daemon mode support,ABANDONED,2015-01-23 16:38:51.000000000,2015-12-11 18:36:14.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 7219}, {'_account_id': 8202}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11811}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12370}, {'_account_id': 12491}, {'_account_id': 12493}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13144}, {'_account_id': 13628}, {'_account_id': 13636}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15831}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 17103}, {'_account_id': 17405}, {'_account_id': 17444}, {'_account_id': 17492}, {'_account_id': 17852}]","[{'number': 1, 'created': '2015-01-23 16:38:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/03f56177ed13bf72cdca36723b244cea96b25c38', 'message': 'Add rootwrap daemon mode(WIP)\n\nAdd RootwrapProcessHelper and RootwrapDaemonHelper\nclasses to cinder utils.\n\nRootwrapProcessHelper - class helper for running\ncommand execution with root priviledges via\nprocessutils from oslo_concurrency, runs as usual.\nRootwrapDaemonHelper - for running commands with\nrootwrap daemon.\n\nTests are needded!\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n'}, {'number': 2, 'created': '2015-01-30 16:41:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/20d2c01e78145695d99e24093a8c70e35fae600c', 'message': 'Add rootwrap daemon mode\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nAdd two objects helper:\nRootwrapProcessHelper - class helper for running\ncommand execution with root priviledges via\nprocessutils from oslo_concurrency, runs as usual.\n\nRootwrapDaemonHelper - for running commands with\nrootwrap daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n'}, {'number': 3, 'created': '2015-01-30 16:47:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/409c2287879ad692bc0ff4e16bed5956ea978fdb', 'message': 'Add rootwrap daemon mode\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nAdd two objects helper:\nRootwrapProcessHelper - class helper for running\ncommand execution with root priviledges via\nprocessutils from oslo_concurrency, runs as usual.\n\nRootwrapDaemonHelper - for running commands with\nrootwrap daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n'}, {'number': 4, 'created': '2015-02-03 11:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e658a60840ad777f0f527723f2d67426a5501f5e', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 5, 'created': '2015-02-03 11:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/508fba12e4a73e7dd470056438987c4778d6f13b', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 6, 'created': '2015-02-03 14:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/14aa8756cdb3c2abd457ebe5425cc2c442d91209', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 7, 'created': '2015-02-03 15:33:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/61bebb78210cde80d3676050786f861864229464', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 8, 'created': '2015-08-12 12:56:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f2fd2f6138481c6e4538e908d3e690e3fd381e6e', 'message': ""WIP:Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 9, 'created': '2015-08-19 12:56:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/27f29564e0f3eeaa17abb5bb832d111a65d6e8e6', 'message': ""WIP:Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 10, 'created': '2015-08-25 14:41:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/e539af2ebcb4fb9a76932d8bcba4ef127c090752', 'message': ""WIP:Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 11, 'created': '2015-08-26 10:37:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/00fb0eefcd49bc6d43ec23a9b9304285d81b996b', 'message': ""WIP:Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 12, 'created': '2015-08-26 10:40:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d7296f62e93c01f85d6d230b6af5dd9328e88338', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 13, 'created': '2015-08-26 10:51:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/c65dbe74a6e6458d4c36a5d55a13a2c8a9b18324', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}, {'number': 14, 'created': '2015-08-26 13:10:42.000000000', 'files': ['cinder/common/config.py', 'setup.cfg', 'cinder/utils.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/65b5c208d4c3cf71e6053ce3175848f2def9c1fa', 'message': ""Add rootwrap daemon mode support\n\nPatch add rootwrap daemon mode support, to make feature works\njust turn on config variable use_rootwrap_daemon.\n\nThe patch introduces root helper classe:\n- 'RootwrapDaemonHelper' runs commands with a wrapper just as\nroot_helper option used to do.\nThis class would use one rootwrap client for all instances with\nsame rootwrap_config. Its 'execute' method would just call\n'execute' method of rootwrap client that would pass request to\nthe daemon.\n\nChange-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6\nImplements: blueprint rootwrap-daemon-mode\n""}]",6,149677,65b5c208d4c3cf71e6053ce3175848f2def9c1fa,172,50,14,13636,,,0,"Add rootwrap daemon mode support

Patch add rootwrap daemon mode support, to make feature works
just turn on config variable use_rootwrap_daemon.

The patch introduces root helper classe:
- 'RootwrapDaemonHelper' runs commands with a wrapper just as
root_helper option used to do.
This class would use one rootwrap client for all instances with
same rootwrap_config. Its 'execute' method would just call
'execute' method of rootwrap client that would pass request to
the daemon.

Change-Id: Ic719111913d5c1ccd6517fc035ac8681a91aa7c6
Implements: blueprint rootwrap-daemon-mode
",git fetch https://review.opendev.org/openstack/cinder refs/changes/77/149677/14 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/brick/local_dev/lvm.py', 'cinder/common/config.py', 'setup.cfg', 'cinder/utils.py']",4,03f56177ed13bf72cdca36723b244cea96b25c38,bp/rootwrap-daemon-mode,"import threadingfrom oslo_concurrency.processutils import ProcessExecutionErrorclass RootwrapProcessHelper(object): def __init__(self, rootwrap_config): self.rootwrap_config = rootwrap_config def execute(self, *cmd, **kwargs): kwargs['root_helper'] = 'sudo cinder-rootwrap %s' % self.rootwrap_config return processutils.execute(*cmd, **kwargs) class RootwrapDaemonHelper(RootwrapProcessHelper): _clients = {} _clients_mutex = threading.Lock() @classmethod def _get_client(cls, rootwrap_config): with cls._clients_mutex: try: return cls._clients[rootwrap_config] except KeyError: from oslo.rootwrap import client new_client = client.Client([ ""sudo"", ""cinder-rootwrap-daemon"", rootwrap_config]) cls._clients[rootwrap_config] = new_client return new_client def __init__(self, rootwrap_config): self.client = self._get_client(rootwrap_config) def execute(self, *cmd, **kwargs): cmd = [str(c) for c in cmd] process_input = kwargs.pop('process_input', None) env = kwargs.pop('env_variables', None) (pid, out, err) = self.client.execute(cmd, env, process_input) return (out, err) if 'run_as_root' in kwargs: if 'root_helper' in kwargs: root_helper = kwargs.pop('root_helper') else: root_helper = get_root_helper() return root_helper.execute(*cmd, **kwargs) if CONF.use_rootwrap_daemon: return RootwrapDaemonHelper(CONF.rootwrap_conf) return RootwrapProcessHelper(CONF.rootwrap_conf)", if 'run_as_root' in kwargs and 'root_helper' not in kwargs: kwargs['root_helper'] = get_root_helper() return 'sudo cinder-rootwrap %s' % CONF.rootwrap_config ,52,5
openstack%2Fcinder-specs~master~I80718ec57849e876ebe06fc225fe359be0c57d83,openstack/cinder-specs,master,I80718ec57849e876ebe06fc225fe359be0c57d83,Checking the existence of volume,ABANDONED,2015-04-17 11:25:28.000000000,2015-12-11 18:33:53.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 7173}, {'_account_id': 7198}, {'_account_id': 9003}, {'_account_id': 10058}, {'_account_id': 12924}, {'_account_id': 13868}, {'_account_id': 13997}, {'_account_id': 14305}, {'_account_id': 16708}]","[{'number': 1, 'created': '2015-04-17 11:25:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2ac60c3d7daceabfe8de98e5de16812ea92c72be', 'message': 'Сhecking the existence of volume\n\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 2, 'created': '2015-04-17 11:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0d3d4d398af0feff00e2d54805020499c2718333', 'message': 'Checking the existence of volume\n\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 3, 'created': '2015-04-20 09:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/aa505cb2bf376d35fa3d70f79e9398f170abe5c0', 'message': 'Checking the existence of volume\n\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 4, 'created': '2015-04-20 16:22:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/428e5be652ebd966895430d6d1bda2324ba35253', 'message': 'Checking the existence of volume\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 5, 'created': '2015-04-30 12:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0b4b75f16510198b7b26870203cb632a2780a820', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 6, 'created': '2015-07-07 10:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c78b87ca0f0364ee0387f04beacec099d9b7ab8f', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 7, 'created': '2015-07-07 12:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/af963b1ac7a4132b370bc6d7999797817d7d64fd', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 8, 'created': '2015-07-07 12:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/56aa2475c811380ca3f879cb7fff9c81e00c63fe', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 9, 'created': '2015-07-08 09:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/8132a704a53e28fd04473e84528670a9b0b8fe95', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}, {'number': 10, 'created': '2015-07-20 14:17:32.000000000', 'files': ['specs/liberty/check-volume-exists.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/090a3628e05ec09abe7a090320cff9f13fa4bc12', 'message': 'Checking the existence of volume\n\nAfter some fail or cinder-volume restart we want to try create/delete/resize\nvolume again. To make it more reliable volume drivers should check if backend\nalready created a volume. Create the method check_volume_exists to check if\na volume exists on the storage backend.\n\nRelated blueprint: check-volume-exists\nChange-Id: I80718ec57849e876ebe06fc225fe359be0c57d83\n'}]",47,174823,090a3628e05ec09abe7a090320cff9f13fa4bc12,43,14,10,14305,,,0,"Checking the existence of volume

After some fail or cinder-volume restart we want to try create/delete/resize
volume again. To make it more reliable volume drivers should check if backend
already created a volume. Create the method check_volume_exists to check if
a volume exists on the storage backend.

Related blueprint: check-volume-exists
Change-Id: I80718ec57849e876ebe06fc225fe359be0c57d83
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/23/174823/10 && git format-patch -1 --stdout FETCH_HEAD,['specs/liberty/check-volume-exists.rst'],1,2ac60c3d7daceabfe8de98e5de16812ea92c72be,bp/check-volume-exists,.. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================ Сhecking the existence of volume ================================ https://blueprints.launchpad.net/cinder/+spec/check-volume-exists Volume drivers should support checking the existence of volume. Provide a driver method to obtain the status of the given volume. Problem description =================== After some fail or cinder-volume restart we want to try create/delete/resize volume again. To make it more reliable volume drivers should check if backend already created a volume. Use Cases ========= Proposed change =============== The initial proposal is to create a method check_volume_exists to check if a volume exists. Alternatives ------------ Data model impact ----------------- None Cross-project impact -------------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Performance Impact ------------------ Other deployer impact --------------------- None Developer impact ---------------- Drivers developers should implement check_volume_exists method in their drivers. Implementation ============== Assignee(s) ----------- Primary assignee: * Yuriy Nesenenko (ynesenenko) ------------------------------ * Implement a driver method Dependencies ============ None Testing ======= Unit tests need to cover the code change. Documentation Impact ==================== The cinder API documentation will need to be updated to reflect the REST API changes. References ========== None ,,108,0
openstack%2Fcinder-specs~master~I60251ce673fce0863c5fb6fad8e6529723c2c391,openstack/cinder-specs,master,I60251ce673fce0863c5fb6fad8e6529723c2c391,Snapshot sharing,ABANDONED,2015-04-15 11:41:32.000000000,2015-12-11 18:33:53.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 5538}, {'_account_id': 6466}, {'_account_id': 13997}, {'_account_id': 16708}]","[{'number': 1, 'created': '2015-04-15 11:41:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/62fd02f77081b49451153a6be71a32f691db4e1b', 'message': 'Snapshot sharing\n\nChange-Id: I60251ce673fce0863c5fb6fad8e6529723c2c391\n'}, {'number': 2, 'created': '2015-04-15 12:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6331e93ded533a98617e0b028ac1808420fe6b6f', 'message': 'Snapshot sharing\n\nCo-Author: Tiantian Gao\n\nChange-Id: I60251ce673fce0863c5fb6fad8e6529723c2c391\n'}, {'number': 3, 'created': '2015-04-23 09:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/32c52b3f7e918b21c719c1501d368b0ac865a8b6', 'message': 'Snapshot sharing\n\nCo-Author: Tiantian Gao\n\nChange-Id: I60251ce673fce0863c5fb6fad8e6529723c2c391\n'}, {'number': 4, 'created': '2015-04-28 06:43:22.000000000', 'files': ['specs/liberty/snapshot-sharing.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/df0bf17dea13197df91b1f649140245c57ba236d', 'message': 'Snapshot sharing\n\nCo-Author: Tiantian Gao\n\nChange-Id: I60251ce673fce0863c5fb6fad8e6529723c2c391\n'}]",21,173779,df0bf17dea13197df91b1f649140245c57ba236d,21,7,4,5538,,,0,"Snapshot sharing

Co-Author: Tiantian Gao

Change-Id: I60251ce673fce0863c5fb6fad8e6529723c2c391
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/79/173779/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/snapshot-sharing.rst'],1,62fd02f77081b49451153a6be71a32f691db4e1b,snapshare,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================= Allow sharing of volume snapshots ================================= https://blueprints.launchpad.net/cinder/+spec/snapshot-sharing Even though Cinder snapshots are immutable, there is no way for a tenant to access a snapshot created by a different tenant and create a volume from it. This blueprint talks about allowing Cinder to share a snapshot, either publicly, or to specific tenants. A user in a tenant with whom the snapshot is shared, can create a new volume out of the shared snapshot. The snapshot will remain immutable. Problem description =================== Use cases: * An organization wants to have three separate accounts on the cloud, for development, testing and production environments respectively and they want to share an HDFS snapshot, or a snapshot of a database residing on a volume, efficiently. The team wants to take snapshots periodically, and occasionally share it with the other tenants. * The organization mentioned above wants to share a sample database to their customers publicly. * A government or an educational institution wants to publish their dataset. There is no way to achieve this in Cinder right now. Cinder has support for transferring a volume to another tenant, which can be used as a work-around: create a volume out of snapshot, and then transfer it, but if one has to share the snapshot with multiple tenants, the creator will have to create multiple identical volumes and create a transfer request for all of them. For making a snapshot public, one currently has to upload it to Glance, and then make it public there. Glance is a store for virtual machine images, and hence it logically is not the place to keep snapshots (say if the snapshot doesn't contain any VM image data, but HDFS information). Moreover, if the Glance backend is different than Cinder backend (e.g. Swift and LVM respectively), this workaround will involve a data-transfer, and potentially slower as a result. This will also mean additional cost of storage to Glance. In the proposed implementation, it will be just about setting a flag in a database table. Proposed change =============== We need to do following changes to support public snapshots: * Add field `is_public` (boolean) in `Snapshot` table in the DB. An index will be created on this column. Create additional table `SnapshotMember` which will hold the tenant IDs with whom the snapshot is shared. * Change cinder.database.api snapshot_get_all() to include all ""public"" and ""shared"" snapshots. * Change cinder.volume.api to support field `is_public`. * Create a new Cinder API to 'List shared snapshots', which will list all the snapshots shared with the user (including public snapshots) * Change cinder.api.v2.snapshots show(), index(), detail() to show `is_public` field. * Change cinder.api.v2.snapshots index(), detail() to support search by `is_public`. * Change cinder.api.v2.snapshots create(), update() to support specify `is_public` field. Note that a snapshot will not be modify-able. Also, the person with whom the snapshot is shared, cannot further thare that snapshot with others. That person will have to create a volume of his own from that snapshot before he/she wants to share it with others. Alternatives ------------ N/A Data model impact ----------------- Database schema needs following changes: * Add field `is_public` (boolean) in `Snapshot` table with default value as False. This table will have an index. * Add another table `SnapshotMember` which will have three primary fields: ID (UUID), snapshot ID (UUID) and tenant_id (UUID). REST API impact --------------- * Create, show, update snapshot, list snapshots will have `is_public` parameter in request and response. * A new API will be added to share a snapshot with tenant(s). * Another API 'make private' will make the snapshot private again. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Cinderclient and Python SDK will need to be updated to support the above mentioned operations Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Rushi Agrawal (rushiagr) (rushi.agrawal@ril.com) Work Items ---------- * Implement code in cinder. * Implement code in python-cinderclient. * Add testcases to tempest. * Update API doc. Dependencies ============ None Testing ======= Both unit and Tempest tests need to be created to cover the function mentioned above. Documentation Impact ==================== API document needs modification which mentioned in ""REST API impact"". References ========== None ",,179,0
openstack%2Frally~master~If4d093ad7b5d94e131706a666732986e49301b1f,openstack/rally,master,If4d093ad7b5d94e131706a666732986e49301b1f,Possibility to read OS_INSECURE and OS_CACERT env variables,MERGED,2015-12-10 12:48:52.000000000,2015-12-11 18:33:26.000000000,2015-12-11 18:33:24.000000000,"[{'_account_id': 3}, {'_account_id': 7428}, {'_account_id': 9545}, {'_account_id': 10475}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-12-10 12:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/10a99e70820c04f599d09553b5b757128569eb15', 'message': 'Possibility to read OS_CACERT env variable\n\nRally can create a deployment, using env variables like OS_USERNAME,\nOS_PASSWORD, etc. But OS_CACERT is missing for some reason. So this\npatch is intended to fix the issue.\n\nChange-Id: If4d093ad7b5d94e131706a666732986e49301b1f\n'}, {'number': 2, 'created': '2015-12-10 17:59:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a9213d080c89d61454f589e268352a2e980e4acc', 'message': 'Possibility to read OS_CACERT env variable\n\nRally can create a deployment, using env variables like OS_USERNAME,\nOS_PASSWORD, etc. But OS_CACERT is missing for some reason. So this\npatch is intended to fix the issue.\n\nChange-Id: If4d093ad7b5d94e131706a666732986e49301b1f\n'}, {'number': 3, 'created': '2015-12-10 18:00:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4e79e9c311e17f9bfe621dc2fe2aac00b0220bcb', 'message': 'Possibility to read OS_INSECURE and OS_CACERT env variables\n\nRally can create a deployment, using env variables like OS_USERNAME,\nOS_PASSWORD, etc. But OS_INSECURE and OS_CACERT are missing for some\nreason. So this patch is intended to fix the issue.\n\nChange-Id: If4d093ad7b5d94e131706a666732986e49301b1f\n'}, {'number': 4, 'created': '2015-12-10 18:20:54.000000000', 'files': ['tests/unit/cli/commands/test_deployment.py', 'rally/cli/commands/deployment.py', 'rally/osclients.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/043b2ae214474b2284fb743107956d2121cae9e6', 'message': 'Possibility to read OS_INSECURE and OS_CACERT env variables\n\nRally can create a deployment, using env variables like OS_USERNAME,\nOS_PASSWORD, etc. But OS_INSECURE and OS_CACERT are missing for some\nreason. So this patch is intended to fix the issue.\n\nChange-Id: If4d093ad7b5d94e131706a666732986e49301b1f\n'}]",5,255853,043b2ae214474b2284fb743107956d2121cae9e6,26,5,4,7428,,,0,"Possibility to read OS_INSECURE and OS_CACERT env variables

Rally can create a deployment, using env variables like OS_USERNAME,
OS_PASSWORD, etc. But OS_INSECURE and OS_CACERT are missing for some
reason. So this patch is intended to fix the issue.

Change-Id: If4d093ad7b5d94e131706a666732986e49301b1f
",git fetch https://review.opendev.org/openstack/rally refs/changes/53/255853/4 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/cli/commands/test_deployment.py', 'rally/cli/commands/deployment.py']",2,10a99e70820c04f599d09553b5b757128569eb15,," OS_CACERT }, ""https_cacert"": os.environ.get(""OS_CACERT"", """")", },6,2
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I6fc18f1ad876c5a25723710a3b20d8ec9519dcba,openstack/tripleo-heat-templates,stable/liberty,I6fc18f1ad876c5a25723710a3b20d8ec9519dcba,Bump further the stop/start timeout for pcmk/systemd services,MERGED,2015-12-10 15:56:31.000000000,2015-12-11 18:31:57.000000000,2015-12-11 18:31:56.000000000,"[{'_account_id': 3}, {'_account_id': 4328}]","[{'number': 1, 'created': '2015-12-10 15:56:31.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c6452f4347e65b3cd0aba9994c0c189b1c1765b0', 'message': 'Bump further the stop/start timeout for pcmk/systemd services\n\nThis bumps further up the stop/start timeout for the pcmk/systemd\nservices so that it matches the 100s default set in future pcmk\nversions [1].\n\n1. https://github.com/ClusterLabs/pacemaker/commit/17d65e9f44061a4fa14a9cddd6edc403b2d6d2b3\n\nChange-Id: I6fc18f1ad876c5a25723710a3b20d8ec9519dcba\n(cherry picked from commit 23333b2a339ad73dd40f320e7cce290ee566d6b7)\n'}]",0,255950,c6452f4347e65b3cd0aba9994c0c189b1c1765b0,10,2,1,8449,,,0,"Bump further the stop/start timeout for pcmk/systemd services

This bumps further up the stop/start timeout for the pcmk/systemd
services so that it matches the 100s default set in future pcmk
versions [1].

1. https://github.com/ClusterLabs/pacemaker/commit/17d65e9f44061a4fa14a9cddd6edc403b2d6d2b3

Change-Id: I6fc18f1ad876c5a25723710a3b20d8ec9519dcba
(cherry picked from commit 23333b2a339ad73dd40f320e7cce290ee566d6b7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/255950/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,c6452f4347e65b3cd0aba9994c0c189b1c1765b0,241572_245161_rebase," # FIXME(gfidente): sets 100secs as default start timeout op op_params => 'start timeout=100s stop timeout=100s', op_params => 'start timeout=120s stop timeout=100s', op_params => 'start timeout=100s stop timeout=100s monitor start-delay=10s', op_params => 'start timeout=100s stop timeout=100s monitor start-delay=10s', op_params => 'start timeout=100s stop timeout=100s monitor start-delay=10s', op_params => 'start timeout=100s stop timeout=100s monitor start-delay=10s', op_params => 'start timeout=100s stop timeout=100s monitor start-delay=10s',"," # FIXME(gfidente): sets 95secs as default start timeout op op_params => 'start timeout=95s stop timeout=95s', op_params => 'start timeout=120s stop timeout=95s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s',",8,8
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I04f691396a4118b456728a43d71d32ac9a556431,openstack/tripleo-heat-templates,stable/liberty,I04f691396a4118b456728a43d71d32ac9a556431,Set default start/stop timeout for pcmk services to 95s,MERGED,2015-12-10 15:56:31.000000000,2015-12-11 18:31:27.000000000,2015-12-11 18:31:26.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 8399}]","[{'number': 1, 'created': '2015-12-10 15:56:31.000000000', 'files': ['puppet/manifests/overcloud_controller_pacemaker.pp'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc1ed443fe3f7d7c9c25e89c484f7a871e60da8d', 'message': 'Set default start/stop timeout for pcmk services to 95s\n\nThis change will increase the default start/stop timeout for all\nthe non-ocf pcmk services to 95s to make sure it allows for at\nleast 90s to the systemd script to complete the start/stop.\n\nMore info at: https://bugzilla.redhat.com/show_bug.cgi?id=1275324\n\nChange-Id: I04f691396a4118b456728a43d71d32ac9a556431\n(cherry picked from commit 55810fcd97453d963d77d538a087795c33dabdae)\n'}]",0,255949,dc1ed443fe3f7d7c9c25e89c484f7a871e60da8d,11,3,1,8449,,,0,"Set default start/stop timeout for pcmk services to 95s

This change will increase the default start/stop timeout for all
the non-ocf pcmk services to 95s to make sure it allows for at
least 90s to the systemd script to complete the start/stop.

More info at: https://bugzilla.redhat.com/show_bug.cgi?id=1275324

Change-Id: I04f691396a4118b456728a43d71d32ac9a556431
(cherry picked from commit 55810fcd97453d963d77d538a087795c33dabdae)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/49/255949/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/manifests/overcloud_controller_pacemaker.pp'],1,dc1ed443fe3f7d7c9c25e89c484f7a871e60da8d,241572_245161_rebase," # FIXME(gfidente): sets 95secs as default start timeout op op_params => 'start timeout=95s stop timeout=95s', op_params => 'start timeout=120s stop timeout=95s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s', op_params => 'start timeout=95s stop timeout=95s monitor start-delay=10s',"," # FIXME(gfidente): sets 90secs as default start timeout op op_params => 'start timeout=90s', op_params => 'start timeout=120s', op_params => 'start timeout=90s monitor start-delay=10s', op_params => 'start timeout=90s monitor start-delay=10s', op_params => 'start timeout=90s monitor start-delay=10s', op_params => 'start timeout=90s monitor start-delay=10s', op_params => 'start timeout=90s monitor start-delay=10s',",8,8
openstack%2Fcinder-specs~master~I5c37ee6234a41bcc1426f0fa1409e298f4b9bee8,openstack/cinder-specs,master,I5c37ee6234a41bcc1426f0fa1409e298f4b9bee8,Get supported QoS Spec keys,ABANDONED,2015-01-28 22:59:27.000000000,2015-12-11 18:30:19.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 5997}, {'_account_id': 6825}, {'_account_id': 11592}, {'_account_id': 11941}]","[{'number': 1, 'created': '2015-01-28 22:59:27.000000000', 'files': ['specs/kilo/get-qos-specs.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/d1f73dc8b9c7c896d45275bd543fea6b098b8bcb', 'message': ""Get supported QoS Spec keys\n\nThe main purpose of this spec is to help improve Horizon's user\nexperience with the QoS spec management process. This spec\nproposes that Cinder provide a list of possible QoS spec keys\nfor user to choose from when creating or editing QoS spec\nkey/value pairs. The current process in Horizon provides no\nuseful help in terms of what the possible QoS spec keys and\nvalues might be.\n\nChange-Id: I5c37ee6234a41bcc1426f0fa1409e298f4b9bee8\nblueprint: get-qos-specs\n""}]",0,151029,d1f73dc8b9c7c896d45275bd543fea6b098b8bcb,9,7,1,11941,,,0,"Get supported QoS Spec keys

The main purpose of this spec is to help improve Horizon's user
experience with the QoS spec management process. This spec
proposes that Cinder provide a list of possible QoS spec keys
for user to choose from when creating or editing QoS spec
key/value pairs. The current process in Horizon provides no
useful help in terms of what the possible QoS spec keys and
values might be.

Change-Id: I5c37ee6234a41bcc1426f0fa1409e298f4b9bee8
blueprint: get-qos-specs
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/29/151029/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/get-qos-specs.rst'],1,d1f73dc8b9c7c896d45275bd543fea6b098b8bcb,qos-specs-enhancement,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Retrieve Supported QoS Specs ========================================== https://blueprints.launchpad.net/cinder/+spec/get-qos-specs The purpose of this spec is to modify the driver's ``get_volume_stats`` method to include in its return value a dictionary of QoS spec keys that each driver supports. The dictionary will be used to improve the QoS management process in Horizon. Problem description =================== The current implementation of the QoS spec management process in Horizon is error-prone. Administrators must manage QoS specs without having any any interactive guidance on what possible keys are available and what their values are. Having the ability to obtain the permissible QoS spec keys while creating or editing the specs will make this task easier and more user-friendly. Proposed change =============== The driver's ``get_volume_stats`` method will be modified to also return a dictionary of supported QoS spec keys. The dictionary will include information about the keys such as key description, possible values, value range, and value type. Once the get_volume_stats() method was modified, Horizon could call the existing ``scheduler_stats`` API call to get the dictionary and use it in the QoS spec creating or editing process. The new ``qos_specs`` dictionary will be included within the existing ``capabilities`` dictionary: Current json response of the ``scheduler_stats`` API call:: { ""pools"": [ { ""name"": ""ubuntu@lvm#backend_name"", ""capabilities"": { ""pool_name"": ""backend_name"", ""QoS_support"": false, ""location_info"": ""LVMVolumeDriver:ubuntu:stack-volumes:default:0"", ""timestamp"": ""2014-11-21T18:15:28.141161"", ""allocated_capacity_gb"": 0, ""volume_backend_name"": ""backend_name"", ""free_capacity_gb"": 7.01, ""driver_version"": ""2.0.0"", ""total_capacity_gb"": 10.01, ""reserved_percentage"": 0, ""vendor_name"": ""Open Source"", ""storage_protocol"": ""iSCSI"" } } ] } New json response of the ``scheduler_stats`` API call:: { ""pools"": [ { ""name"": ""ubuntu@lvm#backend_name"", ""capabilities"": { ""QoS_support"": false, ""allocated_capacity_gb"": 0, ""driver_version"": ""2.0.0"", ""free_capacity_gb"": 7.01, ""location_info"": ""LVMVolumeDriver:ubuntu:stack-volumes:default:0"", ""pool_name"": ""backend_name"", ""reserved_percentage"": 0, ""storage_protocol"": ""iSCSI"", ""timestamp"": ""2014-11-21T18:15:28.141161"", ""total_capacity_gb"": 10.01, ""vendor_name"": ""Open Source"", ""volume_backend_name"": ""backend_name"", ""qos_specs"": [ { ""description"": ""HP 3PAR Fibre Channel driver"", ""display_name"": ""HP3PARFCDriver"", ""namespace"": ""OS::Cinder::HP3PARFCDriver"", ""properties"": { ""hp3par:priority"": { ""description"": ""Scheduling Priority"", ""title"": ""Priority"", ""enum"": [ ""low"", ""normal"", ""high"" ], }, ""hp3par:minIOPS"": { ""description"": ""I/O issue count minimum goal (IOs/Sec)"", ""title"": ""Min IOPS"", ""type"": ""integer"" }, ""hp3par:maxIOPS"": { ""description"": ""I/O issue count maximum goal (IOs/Sec)"", ""title"": ""Max IOPS"", ""type"": ""integer"" }, ""hp3par:minBWS"": { ""description"": ""I/O issue bandwidth minimum goal (KBs/Sec)"", ""title"": ""Min Bandwidth"", ""type"": ""integer"" }, ""hp3par:maxBWS"": { ""description"": ""I/O issue bandwidth rate limit (KBs/Sec)"", ""title"": ""Max Bandwidth"", ""type"": ""integer"" }, ""hp3par:latency"": { ""description"": ""Latency I/O goal (ms)"", ""title"": ""Latency Goal"", ""type"": ""integer"" } } } ] } } ] } The properties attributes are defined using simple JSON schema notation. Please refer to the `JSON Schema documentation`_ for a complete definition. Alternatives ------------ The alternative of this proposal is the current Horizon process of managing the QoS specs which does not provide any helpful information to administrators regarding possible QoS spec keys and values. They have to know the exact spellings of the key/value pair that they want to set for each QoS spec ahead of time. Most of the time they have to look through the driver documentation or even the code to see what keys could be used in their situation. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Horizon will be updated to include the displaying of the supported QoS spec keys so users can select and set the values while creating or editing the QoS specs. Horizon will use the information about each key to set constraints for the value input field, which will help to screen out invalid values at a certain level. If the QoS spec has not been associated with a volume type or the associated volume type does not have any volume backend name associated with it, Horizon will show all QoS specs from all participating drivers. Note that either case, the administrator can still enter in key/value pairs of their own. This is the same behavior as the current process. If a driver does not publish the ``qos_specs`` dictionary, which will be the case for any drivers that do not get updated, then no client-side filtering will be performed, and the behavior will basically revert to the current situation where the administrator in horizon will need to know and enter the key/value pairs without any additional guidance. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Driver developers will need to add a dictionary of QoS spec keys that their drivers support to the return value of the get_volume_stats() method. The dictionary will contain information about the keys as mentioned in the proposed change section. It is completely up to the driver to decide how much information about its QoS spec keys to provide in the dictionary. The driver can also choose not to provide any QoS spec keys at all, which means that there would be no QoS specs for that particular driver to display in Horizon. But administrators would still be able to enter in key/value pairs of their own. This is the same behavior as the current process. Implementation ============== Assignee(s) ----------- Primary assignee: richard-hagarty (richard.hagarty@hp.com) Other contributors: gary-smith (gary.w.smith@hp.com) jgravel (julie.gravel@hp.com) Work Items ---------- * Add QoS spec dictionary to all supported drivers' ``get_volume_stats`` method Dependencies ============ Horizon blueprint that will depend on this spec: * https://blueprints.launchpad.net/horizon/+spec/qos-specs-describe Testing ======= Unit tests for all changed files Documentation Impact ==================== None References ========== `JSON Schema documentation`_ .. _JSON Schema documentation: http://json-schema.org/documentation.html ",,254,0
openstack%2Fcinder-specs~master~Ib07cfeb7918e08e6caa3159f6eae02ba4a040bc8,openstack/cinder-specs,master,Ib07cfeb7918e08e6caa3159f6eae02ba4a040bc8,Validate QoS Specs,ABANDONED,2015-01-30 00:31:06.000000000,2015-12-11 18:30:07.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 2243}, {'_account_id': 6825}, {'_account_id': 11592}]","[{'number': 1, 'created': '2015-01-30 00:31:06.000000000', 'files': ['specs/kilo/validate-qos-specs-key-value.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/ef58886af243a01a9124af6dbc9896d36deeffa5', 'message': ""Validate QoS Specs\n\nThe main purpose of this spec is to help improve Horizon's user\nexperience by providing QoS spec key/value pair validation. The\ncurrent process in Horizon provides no immediate feedback to the\nuser regarding the validity of the entered key/value pairs. Having\nthis feature will eliminate problems that won't be caught until\nvolume creation time and will be much harder to diagnose.\n\nChange-Id: Ib07cfeb7918e08e6caa3159f6eae02ba4a040bc8\nblueprint: qos-specs-validate\n""}]",1,151485,ef58886af243a01a9124af6dbc9896d36deeffa5,5,5,1,11941,,,0,"Validate QoS Specs

The main purpose of this spec is to help improve Horizon's user
experience by providing QoS spec key/value pair validation. The
current process in Horizon provides no immediate feedback to the
user regarding the validity of the entered key/value pairs. Having
this feature will eliminate problems that won't be caught until
volume creation time and will be much harder to diagnose.

Change-Id: Ib07cfeb7918e08e6caa3159f6eae02ba4a040bc8
blueprint: qos-specs-validate
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/85/151485/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/validate-qos-specs-key-value.rst'],1,ef58886af243a01a9124af6dbc9896d36deeffa5,qos-spec-validation,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Validate QoS Spec Key/Value Pairs ========================================== https://blueprints.launchpad.net/cinder/+spec/qos-spec-validation The purpose of this spec is to enhance the current API call for setting the QoS spec key/value pair by including the validation process of the new key/value pair. This enhancement will be used to improve the QoS spec management process in Horizon. Problem description =================== The current implementation of QoS spec management process in Horizon provides no validation of the specs key/value pair. Administrators have no way to get a response as to whether the QoS spec key/value pair they just created is valid or not. The validation of the key/value pair only happens during the volume creation process which is far too late by that point. Having a validation of the key/value pair done immediately within the QoS spec creation or edit process will significantly improve the usability and user experience of this task. Proposed change =============== The current REST API to set the QoS spec will be enhanced to perform the validation of the new key/value pair before adding the pair to the QoS spec. If the validation succeeds, the API will behave exactly as it was before. Otherwise, the API will report the failed validation with a reasonable explanation. Understanding that validation cannot be done easily in some cases, the API can provide a generic explanation as a starting point. More complex solutions can be discussed and worked on in a future enhancement. Data model impact ----------------- None REST API impact --------------- Current REST API to be enhanced: * ``POST /v2/{tenant_id}/qos_specs`` This administrator-only REST API has always been able to accept multiple key/value pairs in one call, and will continue to do so. When this API is invoked, the qos_specs will be validated by the relevant backends. If *all* relevant backends consider it to be valid, then the REST API will return a ``200``, and the qos_specs will be modified as is currently done. If *any* relevant backend considers it to be invalid, then the request will be rejected with an HTTP response that has error code ``400``, and it will include a json payload that indicates which qos_specs were rejected. The format of the error payload:: [{ ""key"": ""foo"", ""reason"": ""Key value 'foo' does not exist"" },{ ""key"": ""minIOPS"", ""reason"": ""value is too high"" }] If the validation fails, then none of the qos_specs will be updated in this call. In other words, if a REST call contains 3 key/value pairs and only one pair is invalid, then the other 2 will *not* be accepted and updated; either all will be updated (when valid) or none will be. Validation Details ------------------ The validation will be coordinated by the API layer. When the request is received, it will inspect the qos_specs to determine the intended backend via the ``volume_backend_name`` as defined by the associated volume type. If the ``volume_backend`` is not set in the associated volume type, or no volume volume type is associated, then *all* backends will be consulted. For each relevant backend, the API will invoke the ``validate`` function on each driver with the QoS specs dictionary from the API. It will then gather the results from the individual drivers and return the appropriate response as indicated in the previous section. The base driver class will provide an implementation of ``validate`` that simply returns ``None``, so that any drivers that do not implement their own version will revert to the current behavior of accepting all QoS specs. The ``validate`` function that each driver implements will accept a dictionary of key/value pairs. It will then return an array of dictionaries indicating the invalid entries. Returning ``None`` or an empty array indicates that all key/value pairs are valid. Each element in the array is a dictionary with two entries: ``key`` (containing the invalid key), and an optional ``reason`` containing a string that indicates the reason it is invalid. This is the same format as the REST call above. If the volume service is down and can't be reached, the validation will fail with a reason entry in the payload indicating the source of the failure if possible. The same behavior should be true if the driver takes too long to perform the validation. Alternatives ------------ Alternatives considered: * Passing the only one qos_spec key/value pair at a time to the driver's ``validate`` function. This makes the ``validate`` function a bit simpler, but requires additional RPC calls. * If the request has more than one key/value pair, accept (and set) those that are valid, and reject the invalid ones. One problem this raises is how to respond when one is accepted and one fails: there is no http response to indicate a partial success or partial failure; both a ``200`` and a ``400`` is likely to be misinterpreted by the administrator It seems more intuitive and simpler to implement to treat the validation/acceptance as an atomic operation. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- * When administrators set incorrect QoS spec key/value pairs, they will be rejected immediately, instead of waiting until a failure of the next volume creation or attachment request. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Driver developers will need to provide a new driver method, ``validate``, that performs the QoS spec key/value pair validation. It is completely up to the driver to decide how to validate each key/value pair. It can choose to do nothing and report a successful validation. It can choose to simply validate if the type of the value is as expected. It can also choose to validate against the array of supported values to ensure that the value is legitimate and usable. To support phasing in this change, the default implementation of ``validate`` in the base driver class will simply return ``None``. ``None`` indicates that all keys are valid, which is effectively the same behavior that exists currently. Implementation ============== Assignee(s) ----------- Primary assignee: rich-hagarty (richard.hagarty@hp.com) Other contributors: gary-smith (gary.w.smith@hp.com) jgravel (julie.gravel@hp.com) Work Items ---------- * Add logic to coordinate calling each driver's ``validate`` function * Add ``validate`` function to base volume driver * Add ``validate`` function to lvm driver Dependencies ============ Horizon blueprint that will depend on this spec: * https://blueprints.launchpad.net/horizon/+spec/qos-specs-validate Testing ======= Unit tests for all changed files Documentation Impact ==================== * The cinder API documentation will need to be updated to reflect the fact that the API may return a failure. References ========== None ",,209,0
openstack%2Fcinder-specs~master~I69969b4a69dc281b58863df7838a556db6b45aaf,openstack/cinder-specs,master,I69969b4a69dc281b58863df7838a556db6b45aaf,Add the possibility for admin to list volume-backend-names declared in cinder.conf.,ABANDONED,2015-03-02 16:54:50.000000000,2015-12-11 18:29:46.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 13587}]","[{'number': 1, 'created': '2015-03-02 16:54:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/411e945737be7308eb8508088058091fb69477d1', 'message': 'Add the possibility for admin to list volume-backend-names declared\nin cinder.conf.\n\nChange-Id: I69969b4a69dc281b58863df7838a556db6b45aaf\n'}, {'number': 2, 'created': '2015-03-02 17:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3f932df1695ff8cfc19cb87cf889fffcb8cc8f4d', 'message': 'Add the possibility for admin to list volume-backend-names declared\nin cinder.conf.\n\nChange-Id: I69969b4a69dc281b58863df7838a556db6b45aaf\n'}, {'number': 3, 'created': '2015-03-02 17:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6716f6dcdd62232fa42abfb73532e948b554af71', 'message': 'Add the possibility for admin to list volume-backend-names declared\nin cinder.conf.\n\nChange-Id: I69969b4a69dc281b58863df7838a556db6b45aaf\n'}, {'number': 4, 'created': '2015-03-09 16:41:29.000000000', 'files': ['specs/kilo/list-volume-backend-names.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/1b885e43ac2854a54ae78ef8cd5e334db5d3d118', 'message': 'Add the possibility for admin to list volume-backend-names declared\nin cinder.conf.\n\nChange-Id: I69969b4a69dc281b58863df7838a556db6b45aaf\n'}]",7,160416,1b885e43ac2854a54ae78ef8cd5e334db5d3d118,13,6,4,13587,,,0,"Add the possibility for admin to list volume-backend-names declared
in cinder.conf.

Change-Id: I69969b4a69dc281b58863df7838a556db6b45aaf
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/16/160416/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/list-volume-backend-names.rst'],1,411e945737be7308eb8508088058091fb69477d1,List-volume-backend-name,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== List volume backends names ========================================== To manage volume type and associate them to volume backends names, you need to know the names of the volume backends available. Problem description =================== In some use cases, there is a possibility where the sysadmin who manage the OpenStack plateform (in pure system view, the one who can modify cinder.conf for example) is different than the one who have the 'admin' username in keystone. The 'admin' user need to manage volume-type to associate them to volume_backend_names declared in conder.conf. $ cinder --os-username admin --os-tenant-name admin type-create lvm $ cinder --os-username admin --os-tenant-name admin type-key lvm set volume_backend_name=LVM_iSCSI To do it, you need to know LVM_iSCSI is a volume_backend_name. If you are not the one who manage cinder.conf, you don't have this information. Proposed change =============== Add an API call to provide this informations. $ cinder --os-username admin --os-tenant-name admin volume-backend-names-list +---------------------+ | volume_backend_name | +---------------------+ | LVM_iSCSI | | LVM_iSCSI_b | +---------------------+ Alternatives ------------ None Data model impact ----------------- No need to manage it in database. REST API impact --------------- * Specification for the method * List volume_backend_names * Method type GET * 200 * Expected error http response code(s) * 404: there is no volume_backend_name declared * URL: /v2/{tenant_id}/volume_backend_names * Parameters: None * {""volumeBackendNames"": [{""volumeBackendName"": ""LVM_iSCSI""}]} Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- See below Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- None Implementation ============== Assignee(s) ----------- None Work Items ---------- None Dependencies ============ None Testing ======= None Documentation Impact ==================== * Inser the new command in python-cinderclient * Adapt documentation like * http://developer.openstack.org/api-ref-blockstorage-v2.html * http://docs.openstack.org/admin-guide-cloud/content/multi_backend.html References ========== None ",,146,0
openstack%2Fcinder-specs~master~I6661b4c95b0f02a90c14867f8fc38a6335ea917a,openstack/cinder-specs,master,I6661b4c95b0f02a90c14867f8fc38a6335ea917a,Quota API and CLI improvements,ABANDONED,2014-12-17 13:46:07.000000000,2015-12-11 18:29:22.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 2759}, {'_account_id': 5538}, {'_account_id': 9214}]","[{'number': 1, 'created': '2014-12-17 13:46:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/9e0265d46b14ef747b1b5eba6db9fffa67a1ceb7', 'message': 'Quota API and CLI improvements\n\nBlueprint: quota-api-cli-default-tenant-improvements\nAPIImpact\n\nChange-Id: I6661b4c95b0f02a90c14867f8fc38a6335ea917a\n'}, {'number': 2, 'created': '2014-12-17 13:51:53.000000000', 'files': ['specs/kilo/quota-api-cli-default-tenant-improvements.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0e25b59d2038edb5bdeb4820edca80daa5a6d30f', 'message': 'Quota API and CLI improvements\n\nBlueprint: quota-api-cli-default-tenant-improvements\nAPIImpact\n\nChange-Id: I6661b4c95b0f02a90c14867f8fc38a6335ea917a\n'}]",5,142445,0e25b59d2038edb5bdeb4820edca80daa5a6d30f,9,6,2,5538,,,0,"Quota API and CLI improvements

Blueprint: quota-api-cli-default-tenant-improvements
APIImpact

Change-Id: I6661b4c95b0f02a90c14867f8fc38a6335ea917a
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/45/142445/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/quota-api-cli-default-tenant-improvements.rst'],1,9e0265d46b14ef747b1b5eba6db9fffa67a1ceb7,bp/quota-api-cli-default-tenant-improvements,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================= Quota API and CLI improvements for default tenant ================================================= https://blueprints.launchpad.net/cinder/+spec/quota-api-cli-default-tenant-improvements Quotas API and CLI requires tenant ID to be specified, even if one wants to view their own quota allocation, or usage. Moreover, a Tenant ID needs to be passed even if one wants to view the default quota, which in it's current form is a global value and not specific to any tenant. If an erroneous string is supplied instead of a tenant ID, API call returns information of the default user instead of raising an exception/a warning. This spec aims at removal of tenant ID as a mandatory parameter, and as a result suggests modifications to the ReST API as well as the CLI. Problem description =================== Current Quota APIs are the following. TID is tenant ID * GET /v2/TID/os-quota-sets/TID (lists quotas for tenant TID) GET /v2/TID/os-quota-sets/TID?usage=True (list quota usage) DELETE /v2/TID/os-quota-sets/TID (delete quota) Tenant ID is superfluous for the second time here. Also, this makes the tenant ID argument mandatory in the CLI. The API call succeeds even if 'somerandomstring' is passed instead of tenant ID, and returns value for the current tenant. * GET /v2/TID/os-quota-sets/TID/defaults lists default quotas of Cinder. Also, there are no defaults per tenant, but there are only global defaults in Cinder, making passing of tenant ID again all the more unnecessary. * PUT /v2/TID/os-quota-sets/TID with data (update quota) All the above problems, plus the fact that if an incorrect tenant ID is specified, e.g. 'blah', then an entry in the database will be created in quotas table with tenant ID as 'blah'. Proposed change =============== GET /v2/TID/os-quota-sets/TID (lists quotas for tenant TID) becomes GET /v2/TID/os-quota-sets/quotas?tenant_id=TID Where the part from '?' is required only to view quota for a different tenant GET /v2/TID/os-quota-sets/TID?usage=True (list quota usage) becomes GET /v2/TID/os-quota-sets/usages?tenant_id=TID DELETE /v2/TID/os-quota-sets/TID (delete quota) becomes DELETE /v2/TID/os-quota-sets/quotas GET /v2/TID/os-quota-sets/TID/defaults (default quota) becomes GET /v2/TID/os-quota-sets/defaults PUT /v2/TID/os-quota-sets/TID with data (update quota) becomes PUT /v2/TID/os-quota-sets/quotas For CLI, --tenant <tid> was a mandatory parameter. It will be made optional. Extra validation needs to be added to make sure a valid UUID is passed as a tenant ID in CLI. The API server should also throw a 404 error if an invalid tenant ID is passed. The scope is limited to usability/convenience improvements, and doesn't deal with other issues the quotas implementation have at present. Alternatives ------------ Can't think of any. Data model impact ----------------- None REST API impact --------------- As described in ""Proposed changes"" section. Everything else remains same for the quotas API. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- Python CLI for Cinder would be changed. Tenant ID will be an optional parameter for all the quota commands. Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Quotas API and CLI are changed. Implementation ============== Assignee(s) ----------- Primary assignee: rushiagr (Rushi Agrawal) Work Items ---------- * Make changes to quotas.py extension file, to work with new API definition. while ensuring backwards compatibility is maintained. * Add additional validation to quotas.py extension to make sure invalid tenant ID as an argument is catched and exception is thrown * Make <tenant> optional in Cinderclient CLI * Validation in CLI to ensure tenant, if provided is a UUID * Add tests to Tempest Dependencies ============ None Testing ======= Tempest tests will be added for all the ways one can interact with the new API. Documentation Impact ==================== API document for quotas should be updated. As we're ensuring changes will be backwards incompatible, we'll need to make sure both the ways of making an API call are documented. References ========== * Related blueprint: https://blueprints.launchpad.net/cinder/+spec/default-quota-template ",,168,0
openstack%2Fcinder-specs~master~Ia90f18e75c68282b3c702896a0d37a7a5f74084f,openstack/cinder-specs,master,Ia90f18e75c68282b3c702896a0d37a7a5f74084f,Blueprint volume status polling,ABANDONED,2014-10-31 12:21:34.000000000,2015-12-11 18:29:08.000000000,,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 5997}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 10851}, {'_account_id': 13933}]","[{'number': 1, 'created': '2014-10-31 12:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0cca41b1971aa04944599846e7c790b3db48a850', 'message': 'Implements: blueprint volume status polling\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 2, 'created': '2014-11-18 18:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/2496a7bb1e95a31ae3f7ab9f60679746d19ac3d0', 'message': 'Implements: blueprint volume status polling\n\nUpdated with details and connection to nova bp.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 3, 'created': '2014-12-12 15:21:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/72169ab5dc77292d866c1503c4594a1a478fbd83', 'message': 'Implements: blueprint volume status polling\n\nUpdated with a new idea after discussion in IRC.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 4, 'created': '2014-12-16 17:01:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/79d30e32f64ad533ec6e623c57176969cb176e4f', 'message': 'Implements: blueprint volume status polling\n\nUpdated with a new idea after discussion in IRC.\nAdded a new alternative.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 5, 'created': '2014-12-17 16:43:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/64c6542eadf04cc9ef83aeb13ace8ab6e2940a5a', 'message': 'Implements: blueprint volume status polling\n\nUpdated with a new idea after discussion in IRC.\nAdded a new alternative. Removed trailing whitespaces.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 6, 'created': '2014-12-18 13:52:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/c498e777d5fd04c8604a204a7aa23b3da308590f', 'message': 'Blueprint volume status polling\n\nUpdated with a new idea after discussion in IRC.\nAdded a new alternative. Removed trailing whitespaces.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}, {'number': 7, 'created': '2014-12-18 16:14:23.000000000', 'files': ['specs/kilo/volume-status-polling.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/38c046d2724501bf580f0acd880148496275d135', 'message': 'Blueprint volume status polling\n\nUpdated with a new idea after discussion in IRC.\nAdded a new alternative. Removed trailing whitespaces.\nUpdated with more details.\n\nChange-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f\n'}]",36,132225,38c046d2724501bf580f0acd880148496275d135,41,11,7,10851,,,0,"Blueprint volume status polling

Updated with a new idea after discussion in IRC.
Added a new alternative. Removed trailing whitespaces.
Updated with more details.

Change-Id: Ia90f18e75c68282b3c702896a0d37a7a5f74084f
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/25/132225/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/volume-status-polling.rst'],1,0cca41b1971aa04944599846e7c790b3db48a850,bp/volume,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ========================================== Volume Status Polling ========================================== https://blueprints.launchpad.net/cinder/+spec/volume-status-polling Parallel volume operations lead to inconsistencies between the OpenStack database and the deployed view on the centralized storage backend. Problem description =================== When performing multiple volume operation on a centralized storage backend it can come to timeouts on the OpenStack side. These timeouts can be the RPC timeout or e.g. in high availability scenarios, the HA proxy timeout. When nova wants to attach a volume, it triggers the status change from available to attaching and sends initialize_connection via cinderclient to cinder API via the REST API. Cinder API performs a synchronous CALL to cinder volume, then via the driver the centralized storage backend is contacted. When now a timeout occurs, nova triggers the database to change the volume status from attaching to available. Meanwhile the centralized storage backend performs what was originally requested. Here we can have a mismatch between database and the real view of the centralized storage backend. The described behaviour might be suitable for all CALLs. As the Cinder API is designed we see general problems with time consuming functions on centralized storage backends. Proposed change =============== It is proposed to change the initialize_connection and terminate_connection in the rpcapi of cinder volume from CALL to CAST. This change from synchronous to asynchronous is a key to change the timeout behaviour. As a consequence of this change the client has to implement a polling loop to check the status of the process. When receiving the CAST, cinder-volume will store an estimated timeout for this request in the database (in the metadata area). Cinder-volume implements an adaptive timeout estimater. Cinder-volume checks ongoing activities in the database and calculates the estimated duration and stores the results in the database accordingly. Cinder-volume also stores the connection info. The client has a polling loop to check the status of the request and the estimated timeout. The polling ends when the process succeeds or the timeout is reached. In case the client detects the status change from attaching to attached, the client sends the connection info to nova as in the design base. In case the timeout occurs, nova has to trigger a rollback to ensure database consistency. Alternatives ------------ Polling loop could be done in nova. Data model impact ----------------- When the needed data is stored in the metadata of the database, then there is no change in the data model. REST API impact --------------- As a result of the proposed change, the cinderclient has to poll the database to get information about the attachment/detachment process. Security impact --------------- - Notifications impact -------------------- - Other end user impact --------------------- - Performance Impact ------------------ The polling loop and the estimator have minor impact on the performance. Other deployer impact --------------------- - Developer impact ---------------- - Implementation ============== Assignee(s) ----------- Tobias Engelbert Work Items ---------- - CinderClient - CinderVolume Dependencies ============ - Testing ======= This change requires a certain amount of testing to verify that the problem does not occur any more. Documentation Impact ==================== - References ========== A A A A A A A A A A A A A A A A A A - ",,174,0
openstack%2Fastara-neutron~master~I16b569532f162d202b36c967ab349c8b98221039,openstack/astara-neutron,master,I16b569532f162d202b36c967ab349c8b98221039,Updated from global requirements,MERGED,2015-12-11 15:17:50.000000000,2015-12-11 18:29:06.000000000,2015-12-11 18:29:06.000000000,"[{'_account_id': 3}, {'_account_id': 1420}]","[{'number': 1, 'created': '2015-12-11 15:17:50.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/astara-neutron/commit/c24a9f75b427ef077ebe16eb6835c3d57e6a0472', 'message': 'Updated from global requirements\n\nChange-Id: I16b569532f162d202b36c967ab349c8b98221039\n'}]",0,256473,c24a9f75b427ef077ebe16eb6835c3d57e6a0472,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I16b569532f162d202b36c967ab349c8b98221039
",git fetch https://review.opendev.org/openstack/astara-neutron refs/changes/73/256473/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,c24a9f75b427ef077ebe16eb6835c3d57e6a0472,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fcinder-specs~master~I867622f407d236a289293c665adea4a18bee4fb1,openstack/cinder-specs,master,I867622f407d236a289293c665adea4a18bee4fb1,Initial draft of RPC version clamping,ABANDONED,2014-10-21 14:55:24.000000000,2015-12-11 18:28:04.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1207}, {'_account_id': 1736}, {'_account_id': 2243}, {'_account_id': 6491}, {'_account_id': 12716}]","[{'number': 1, 'created': '2014-10-21 14:55:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/453b9998290485e136339e2f5b0dbbc3e63a0ed9', 'message': 'Initial draft of RPC version clamping\n\nChange-Id: I867622f407d236a289293c665adea4a18bee4fb1\n'}, {'number': 2, 'created': '2015-01-07 15:13:10.000000000', 'files': ['specs/kilo/rpc-version-clamp.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/8feeac7f4457b20ecfd4904f509e7a607ae8ee4d', 'message': 'Initial draft of RPC version clamping\n\nChange-Id: I867622f407d236a289293c665adea4a18bee4fb1\n'}]",19,129927,8feeac7f4457b20ecfd4904f509e7a607ae8ee4d,14,7,2,1207,,,0,"Initial draft of RPC version clamping

Change-Id: I867622f407d236a289293c665adea4a18bee4fb1
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/27/129927/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/kilo/rpc-version-clamp.rst'],1,453b9998290485e136339e2f5b0dbbc3e63a0ed9,(detached,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ==================== RPC version clamping ==================== Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/cinder/+spec/example The addition of RPC versioning provided some of the tooling needed to support rolling upgrade, however it did not go far enough to make a rolling upgrade possible. This spec solves one part of the problem, RPC version clamping, a second spec for solving database live migration is also needed. Problem description =================== Suppose you have some cinder service running that supports the following RPC: class MyService(Manager): ... def foo(self, arg1, arg2): LOG.info(""%d"" arg1+arg2) Now, if we suddenly find that we want to add a third argument, arg3, to this RPC, then we currently create a new RPC version, but we don't have anything done for what old clients should do sending to new version services, or new version clients sending to old version servers - the two can't talk to each other. Proposed change =============== The proposed change is multi-fold, and the implementation details are not 100% fleshed out yet. 1. All new RPC changes need to leave the old version in place and functional - this might mean inserting blank / default values into new fields, etc. How long the old version(s) need to live needs to be decided - I'd suggest at least a full stable release to enable upgrade from release to release. 2. When adding a new RPC, the code must behave sensibly if that RPC is not received on the far side - the state machine work might help with this since things can be timed out / retried. In some cases admin action might be required, e.g. state reset APIS. This will vary from change to change. 3. On startup, a manager must query the db and see if there are any RPC version requirements in the DB that apply to it. If the requirements cannot be met, then it should exit witha suitable log message. If they can be met, then the requirement should be cached to avoid having to query the DB again. An RPC can be added to cause the cache to be updated without restarting the manager, if desired, however that won't be in the initial version. 4. When sending an RPC, the manager should check the cache for the max version it is allowed to send, and use that. Again, this requires the code to inherently support this kind of fallback, which is a new requirement. This should mean that an upgrade works as follows: 1. First signal (via a new RPC call or by restarting them) all managers to write their maximum supported RPC versions into the DB. This will be one record per RPC per manager. 2. Update one service. On startup, it works out the maximum RPC version it can currently send by looking at what other can receive and taking the minimum. It also updates the DB with what new versions it can handle, if any. 3. Rolling update more services. They update the DB as appropriate. 4. Either signal via RPC or restart all running services, they should now all see the new version RPCs are supported everywhere. Alternatives ------------ None considered Data model impact ----------------- DB changes to store the above RPC version limits and requirements, TBD REST API impact --------------- Admin API to cause managers to output their current RPC version details to the DB? Some admin APIs to inspect the RPC version DB table. Security impact --------------- None Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ Checking the DB before every RPC would significantly affect performance. The proposed cache is expected to mean there is negligable performance impact, however this should be benchmarked using a dummy service with empty RPCs. Other deployer impact --------------------- If live rolling deploy is desired, then this would singificantly affect the way a deploy is done and that needs to be worked out and documented. Deployers can continue to do things the old way with all of the problems that entails. Developer impact ---------------- Developers must write RPC changes in such a way that the old and new versions continue to work, which is a significant increase in effort in some cases. Reviewers will have to be aware of this requirement and purhaps insist on extra testing in this area. Implementation ============== Assignee(s) ----------- Primary assignee: Duncan Thomas <duncan.thomas@gmail.com> Other contributors: Any other help welcome Work Items ---------- * Write dummy RPC service and dummy consumer suitably annotated for benchmarking * Add RPC clamping into the mix and benchmark, without multiple versions * Add a second RPC version, test pre-migration * Finally release the clamp and test at the new RPC level Dependencies ============ None Testing ======= Beyond the benchmarking detailed above, testing strategy for this change is still under development. Repeated tempest runs before, during and after a migration as a minimum. Documentation Impact ==================== Significant documentation will be needed on how to do a live rolling upgrade, as there are a number of steps that must be done in the right order, and verified. Much of this can probably be automated into a suitable tool, given time. References ========== None ",,180,0
openstack%2Fcinder-specs~master~Ide651be008f233834546acb055ed52f069e3cb3e,openstack/cinder-specs,master,Ide651be008f233834546acb055ed52f069e3cb3e,Adding Sample Policy Spec,ABANDONED,2014-09-24 18:50:34.000000000,2015-12-11 18:27:58.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 5538}, {'_account_id': 5997}, {'_account_id': 10697}, {'_account_id': 10765}]","[{'number': 1, 'created': '2014-09-24 18:50:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/76070c7948c850614a0bcb5904c02eb8291d6a58', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint\n\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}, {'number': 2, 'created': '2014-09-24 19:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/effe73006d5804e124c5ef5adfa13f1373947f28', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint\n\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}, {'number': 3, 'created': '2014-09-24 19:24:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/be26324d8e5dc8ddb83c95360b2c4e6d4dc791b6', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint\n\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}, {'number': 4, 'created': '2014-09-30 12:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/6d70c7c7538e0201ee577bb05271d6515e7ea080', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint\n\nbp policy-sample\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}, {'number': 5, 'created': '2014-10-08 18:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/5f0bd622093bbd83675f241b223653522560ae63', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint in Kilo specs\n\nbp policy-sample\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}, {'number': 6, 'created': '2014-11-03 12:26:42.000000000', 'files': ['specs/kilo/policy-sample.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/0e0c2c05ce574fce13a15dccd75f2964d4476bfb', 'message': 'Adding Sample Policy Spec\n\nAdding spec for sample policy blueprint in Kilo specs\n\nRelated commit:\nGlance   - https://review.openstack.org/#/c/123216/\nNova     - https://review.openstack.org/#/c/123428/\nNeutron  - https://review.openstack.org/#/c/123440/\nKeystone - https://review.openstack.org/#/c/123509/\n\nbp policy-sample\n\nChange-Id: Ide651be008f233834546acb055ed52f069e3cb3e\n'}]",19,123813,0e0c2c05ce574fce13a15dccd75f2964d4476bfb,29,6,6,10765,,,0,"Adding Sample Policy Spec

Adding spec for sample policy blueprint in Kilo specs

Related commit:
Glance   - https://review.openstack.org/#/c/123216/
Nova     - https://review.openstack.org/#/c/123428/
Neutron  - https://review.openstack.org/#/c/123440/
Keystone - https://review.openstack.org/#/c/123509/

bp policy-sample

Change-Id: Ide651be008f233834546acb055ed52f069e3cb3e
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/13/123813/5 && git format-patch -1 --stdout FETCH_HEAD,['specs/juno/policy-sample.rst'],1,76070c7948c850614a0bcb5904c02eb8291d6a58,bp/policy-sample,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============= Policy Sample ============= https://blueprints.launchpad.net/cinder/+spec/policy-sample We are providing a sample policy with well defined roles across the main Openstack services. Problem description =================== Reading openstack policies in general, we think that the roles are quite complicated, we don't know which roles are appropriated for each user. For example, in many policies just the admin role is described. Our proposal is to clarify for the cloud user whats the role organizations, for example, cloud admin is the role for the admins, project_admin for the project admin and project_member a member with a role in a project but with no admin permissions. The ideia is create a policy.cloudsample.json, where was defined roles as a project_admin, cloud_admin and project_member and determine their permissions, making policies closer to the business reality. Proposed change =============== We propose to add a new policy in Cinder service, by copying the existing policy and rewriting it to support the new roles. The new roles are: ""cloud_admin"", the user that will manage the cloud, ""project_admin"" the user that has admin permissions in scope of projects and ""project_member"", the usual cloud user. We are proposing the same samples policy to the main services in Openstack: Cinder, Neutron, Keystone, Glance and Neutron. Alternatives ------------ The cloud admin could manually change the policies to support the roles cloud_admin, project_admin and project_member. The reason to use the policy porposed here is to take advantage of the provided roles and the configured policy in the main Openstack services. Data model impact ----------------- None REST API impact --------------- None Security impact --------------- The impact could be the policy bad usage/configuration, that could allow and user do perform actinos that he wasn't intended to have. Notifications impact -------------------- None Other end user impact --------------------- None Performance Impact ------------------ None Other deployer impact --------------------- The roles provided need to be added to the Openstack instantiation: cloud_admin, project_admin and project_member. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a blueprint where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: Thiago Paiva Brito (thiagop) Other contributors: Andre Aranha (afaranha) Work Items ---------- 1. Create the sample policy Dependencies ============ None Testing ======= None Documentation Impact ==================== What is the impact on the docs team of this change? Some changes might require donating resources to the docs team to have the documentation updated. Don't repeat details discussed above, but please reference them here. References ========== Github for sample policies project with tests: * https://github.com/andre-lsd/sample-policies-for-openstack ",,142,0
openstack%2Fcinder~stable%2Fkilo~I1210186689dea204601356f8d08805c6cb6f017c,openstack/cinder,stable/kilo,I1210186689dea204601356f8d08805c6cb6f017c,Remove force check from copy_volume_to_image,ABANDONED,2015-04-24 13:26:19.000000000,2015-12-11 18:26:40.000000000,,"[{'_account_id': 3}, {'_account_id': 170}, {'_account_id': 1955}, {'_account_id': 2243}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 10621}, {'_account_id': 11611}, {'_account_id': 12202}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12493}, {'_account_id': 12778}, {'_account_id': 12780}, {'_account_id': 13394}, {'_account_id': 13628}, {'_account_id': 13915}, {'_account_id': 14242}, {'_account_id': 14797}, {'_account_id': 15249}, {'_account_id': 15374}]","[{'number': 1, 'created': '2015-04-24 13:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5763d8f28c034bfc1c4c217c363af127dd8f0906', 'message': 'Remove force check from copy_volume_to_image\n\nThe upload_volume_to_image method allows a force parameter that will\nupload a volume even though the volume is attached/in-use. A user can\nget away with this with the LVM driver because the LVM backing is\nlocal to the Cinder worker node that\'s pushing the bits to Glance.\n\nThe problem is, this only works for local storage, it won\'t work\nwith any iSCSI devices because they can\'t do multi-attach. Also,\nthe reason we required that a volume NOT be in-use for this\noperation is because we have no way of keeping the guest Instance\nfrom writing to the volume while we\'re uploading, and corrupting the data.\n\nThis has been exposed like this for several releases, so removing it\nnow likely would not be a good user experience.  Instead, this\npatch add a config option to enable/disable it (default is to\ndisable), and deployers can choose whether they would like to\nallow the use of --force True or not.\n\nDocImpact Disables the --force option to copy-volume-to-image and\n          introduces ""allow_force_upload"" boolean option to re-enable\n\nChange-Id: I1210186689dea204601356f8d08805c6cb6f017c\nCloses-Bug: 1446954\n'}, {'number': 2, 'created': '2015-05-06 08:03:29.000000000', 'files': ['cinder/tests/api/contrib/test_volume_actions.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/8ea4724ff880a95deeecbf5e33b208fdb3dd3210', 'message': 'Remove force check from copy_volume_to_image\n\nThe upload_volume_to_image method allows a force parameter that will\nupload a volume even though the volume is attached/in-use. A user can\nget away with this with the LVM driver because the LVM backing is\nlocal to the Cinder worker node that\'s pushing the bits to Glance.\n\nThe problem is, this only works for local storage, it won\'t work\nwith any iSCSI devices because they can\'t do multi-attach. Also,\nthe reason we required that a volume NOT be in-use for this\noperation is because we have no way of keeping the guest Instance\nfrom writing to the volume while we\'re uploading, and corrupting the data.\n\nThis has been exposed like this for several releases, so removing it\nnow likely would not be a good user experience.  Instead, this\npatch add a config option to enable/disable it (default is to\ndisable), and deployers can choose whether they would like to\nallow the use of --force True or not.\n\nDocImpact Disables the --force option to copy-volume-to-image and\n          introduces ""allow_force_upload"" boolean option to re-enable\n\nChange-Id: I1210186689dea204601356f8d08805c6cb6f017c\nCloses-Bug: 1446954\n(cherry picked from commit fb2c434c2461a25193067104de766fc1142a6024)\n'}]",0,177258,8ea4724ff880a95deeecbf5e33b208fdb3dd3210,43,21,2,8300,,,0,"Remove force check from copy_volume_to_image

The upload_volume_to_image method allows a force parameter that will
upload a volume even though the volume is attached/in-use. A user can
get away with this with the LVM driver because the LVM backing is
local to the Cinder worker node that's pushing the bits to Glance.

The problem is, this only works for local storage, it won't work
with any iSCSI devices because they can't do multi-attach. Also,
the reason we required that a volume NOT be in-use for this
operation is because we have no way of keeping the guest Instance
from writing to the volume while we're uploading, and corrupting the data.

This has been exposed like this for several releases, so removing it
now likely would not be a good user experience.  Instead, this
patch add a config option to enable/disable it (default is to
disable), and deployers can choose whether they would like to
allow the use of --force True or not.

DocImpact Disables the --force option to copy-volume-to-image and
          introduces ""allow_force_upload"" boolean option to re-enable

Change-Id: I1210186689dea204601356f8d08805c6cb6f017c
Closes-Bug: 1446954
(cherry picked from commit fb2c434c2461a25193067104de766fc1142a6024)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/58/177258/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/api/contrib/test_volume_actions.py', 'cinder/volume/api.py']",2,5763d8f28c034bfc1c4c217c363af127dd8f0906,bug/1446954,"allow_force_upload = cfg.BoolOpt('enable_force_upload', default=False, help='Enables the Force option on ' 'upload_to_image. This enables ' 'running upload_volume on in-use ' 'volumes for backends that support it.')CONF.register_opt(allow_force_upload) if not CONF.enable_force_upload and force: LOG.info(_LI(""Force upload to image is disabled, "" ""Force option will be ignored.""), resource={'type': 'volume', 'id': volume['id']}) force = False ",,27,13
openstack%2Fdjango_openstack_auth~master~Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a,openstack/django_openstack_auth,master,Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a,Use set comprehension instead of converting lists to sets,MERGED,2015-08-24 22:08:21.000000000,2015-12-11 18:25:07.000000000,2015-12-11 18:25:06.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 8040}, {'_account_id': 9647}, {'_account_id': 10442}, {'_account_id': 13420}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-08-24 22:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/0cc9044830638c2e0a4b9640d61bd954775d1050', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch changes is_superusers function to take advantage\nof python set comprehensions syntax instead of constructing\na list and converting it to set later. Also takes advantage\nof .isdisjoint function, that returns True if two\nsets have a null intersection.\n\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 2, 'created': '2015-09-01 14:16:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/6916ee1b94035b1d6c004ca672ff11b22640982a', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch changes is_superusers function to take advantage\nof python set comprehensions syntax instead of constructing\na list and converting it to set later. Also takes advantage\nof .isdisjoint function, that returns True if two\nsets have a null intersection.\n\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 3, 'created': '2015-09-01 19:04:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/011030be625cf6f21575dc3a3c365dd4f2bcfbf1', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 4, 'created': '2015-09-11 10:08:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/23e0bac3ec28639d0e86dc55808b5383a03d18f8', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 5, 'created': '2015-09-28 13:56:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/e41397e24a9528293aeabed3e2539a244f339691', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 6, 'created': '2015-10-16 15:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/76141db195aa171b4b4017cbf1c5f43ecf5206ef', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nCloses-Bug: #1506925\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 7, 'created': '2015-10-16 15:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/d64ec823f29e1c5683b57406aeb7021b1e713303', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nCloses-Bug: #1506925\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}, {'number': 8, 'created': '2015-11-09 17:22:19.000000000', 'files': ['openstack_auth/user.py', 'openstack_auth/backend.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/885cdd96c630fa225a2e7417f541ddfeb335bd89', 'message': 'Use set comprehension instead of converting lists to sets\n\nThis patch takes advantage of python set comprehensions\nsyntax instead of constructing a list and converting\nit to set later.\nAlso takes advantage of .isdisjoint function,\nthat returns True if two sets have a null intersection.\nShould slightly improve performance and readability.\n\nCloses-Bug: #1506925\nChange-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a\n'}]",0,216441,885cdd96c630fa225a2e7417f541ddfeb335bd89,38,7,8,15168,,,0,"Use set comprehension instead of converting lists to sets

This patch takes advantage of python set comprehensions
syntax instead of constructing a list and converting
it to set later.
Also takes advantage of .isdisjoint function,
that returns True if two sets have a null intersection.
Should slightly improve performance and readability.

Closes-Bug: #1506925
Change-Id: Ia3d8b47efcf1b2280d7570e782fd196ce716ac8a
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/41/216441/6 && git format-patch -1 --stdout FETCH_HEAD,['openstack_auth/user.py'],1,0cc9044830638c2e0a4b9640d61bd954775d1050,, admin_roles = {role.lower() for role in getattr( ['admin'])} user_roles = {role['name'].lower() for role in self.roles} return not admin_roles.isdisjoint(user_roles), admin_roles = [role.lower() for role in getattr( ['admin'])] user_roles = [role['name'].lower() for role in self.roles] return True if set(admin_roles).intersection(user_roles) else False,4,4
openstack%2Fdjango_openstack_auth~master~If880022f447255e7d943915087e229778cc6acf8,openstack/django_openstack_auth,master,If880022f447255e7d943915087e229778cc6acf8,Move d-o-a auth library to keystoneauth,MERGED,2015-07-23 19:28:29.000000000,2015-12-11 18:22:09.000000000,2015-12-11 18:22:07.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8866}, {'_account_id': 9237}, {'_account_id': 9981}, {'_account_id': 10046}, {'_account_id': 14124}, {'_account_id': 15359}, {'_account_id': 15519}, {'_account_id': 15742}, {'_account_id': 17185}]","[{'number': 1, 'created': '2015-07-23 19:28:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/68d83b865d2e29bd2b25f14081c070e13a2fd480', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 2, 'created': '2015-07-29 15:16:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/325d1ac3b3be218af69d6632a24e1b6a8636a4fa', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystoneauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 3, 'created': '2015-07-31 13:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/3c6212b44757108d80f869e0b93d20f1e2a65b85', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 4, 'created': '2015-09-02 15:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/84252335d44b8ac32cf95c6c19964f5e81da20fe', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n'}, {'number': 5, 'created': '2015-09-02 20:18:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/b27aabb65c9e4dd35dd50049c2eeeff1a079a2a3', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n'}, {'number': 6, 'created': '2015-09-04 13:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/cd834e66a098c3a6e5955e8ad30d35af8ab4ca06', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n'}, {'number': 7, 'created': '2015-09-23 17:20:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/6938d217fd451738970ca9843bf0a4a2a6d31924', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n'}, {'number': 8, 'created': '2015-09-24 15:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/f78d6d319abdf76a18759d653155332ff28896bb', 'message': 'WIP Refactor d-o-a code to use keystoneauth library\n\nUpdated versions of access info objects needed for K2K\nfederation are implemented in keystoneauth library.\nd-o-a code should then be refatored to use keystoneauth\nin order to support K2K federation.\n\nThis patch is intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910/\nand depends on the keystonauth release.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 9, 'created': '2015-09-25 13:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/9d51a8eecc85beb7e101a441c3cf7dc80a2894c0', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nThis patch depends on the keystoneauth integration bugfix\nhttps://review.openstack.org/#/c/192438\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 10, 'created': '2015-09-25 17:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/3098888a131b6b9184e899248c09399fc48f7b60', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nThis patch depends on the keystoneauth integration bugfix\nhttps://review.openstack.org/#/c/192438\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 11, 'created': '2015-10-29 19:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/7a94065119688a3b86b51f9d02f992813e1a8dda', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nThis patch depends on the keystoneauth integration bugfix\nhttps://review.openstack.org/#/c/192438\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 12, 'created': '2015-11-09 20:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/61ed96cbfc05a0b25e002e971b4c95d707d25e57', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 13, 'created': '2015-11-10 13:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/da37eb83943c84a1471f2751139d9fe21ab85bdb', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 14, 'created': '2015-11-10 13:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/984a8ae26d0cd842e3f358c3e452ba5b6909a4bd', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nThis patch depends on the keystoneauth integration bugfix\nhttps://review.openstack.org/#/c/192438\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 15, 'created': '2015-11-11 13:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/e92c9a61e151032f2cdc27eb1d5fd3b865d1e99c', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 16, 'created': '2015-11-11 20:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/3fcacb571ee7e76da716bb8b6f4c1ff22a8fe8e9', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nThis patch depends on the keystoneauth integration bugfix\nhttps://review.openstack.org/#/c/192438\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 17, 'created': '2015-11-11 21:01:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/1cb640785fedf75da4888caf0514758a5e91cb49', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch https://review.openstack.org/#/c/159910 since the\nK2K plugin is implemented in keystoneauth. But with the keystoneauth\nrelease, it seems that the authentication library migration\nfrom keystoneclient to keystoneauth should happen eventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nDepends-On: I37e601cf0126ddae2a3e5ec255f4e4703ecf7682\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 18, 'created': '2015-11-30 13:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/43bff0bc9ddc2aed1e34f2ab0256a7e1c28c4609', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch since the K2K plugin is implemented in keystoneauth.\nBut with the keystoneauth release, it seems that the authentication\nlibrary migration from keystoneclient to keystoneauth should happen\neventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 19, 'created': '2015-11-30 18:48:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/71413739aa5a50b98bf3befc372ed6d4b7321809', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch since the K2K plugin is implemented in keystoneauth.\nBut with the keystoneauth release, it seems that the authentication\nlibrary migration from keystoneclient to keystoneauth should happen\neventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 20, 'created': '2015-12-03 14:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/c63360ecfc462dc96f668cb954f1479847055365', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch since the K2K plugin is implemented in keystoneauth.\nBut with the keystoneauth release, it seems that the authentication\nlibrary migration from keystoneclient to keystoneauth should happen\neventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint k2k-federation\n'}, {'number': 21, 'created': '2015-12-08 21:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/df3eea77180c236f82675804d96949de8f29a02f', 'message': 'Refactor d-o-a to use keystoneauth library\n\nThis patch was originally intended as a prereq to the Horizon K2K\nfederation patch since the K2K plugin is implemented in keystoneauth.\nBut with the keystoneauth release, it seems that the authentication\nlibrary migration from keystoneclient to keystoneauth should happen\neventually.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint keystoneauth-update\n'}, {'number': 22, 'created': '2015-12-09 13:37:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/ee1bd7a453c5e5c1f744f1744f26e45ff05af709', 'message': 'Move d-o-a auth library to keystoneauth\n\nWith the keystoneauth release, the authentication library\nshould move from keystoneclient to keystoneauth.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nPartially-Implements: blueprint keystoneauth-update\n'}, {'number': 23, 'created': '2015-12-09 13:46:45.000000000', 'files': ['openstack_auth/tests/tests.py', 'requirements.txt', 'openstack_auth/user.py', 'openstack_auth/plugin/token.py', 'openstack_auth/plugin/base.py', 'openstack_auth/plugin/password.py', 'openstack_auth/views.py', 'openstack_auth/backend.py', 'openstack_auth/tests/data_v3.py', 'openstack_auth/utils.py', 'openstack_auth/tests/data_v2.py'], 'web_link': 'https://opendev.org/openstack/django_openstack_auth/commit/8f1e5675c4d4efd49b0a79c80b6dda734ab8ee0f', 'message': 'Move d-o-a auth library to keystoneauth\n\nWith the keystoneauth release, the authentication library\nshould move from keystoneclient to keystoneauth.\n\nCo-Authored-By: Diego Adolfo <diegoado@gmail.com>\n\nChange-Id: If880022f447255e7d943915087e229778cc6acf8\nImplements: blueprint keystoneauth-update\n'}]",17,205251,8f1e5675c4d4efd49b0a79c80b6dda734ab8ee0f,88,12,23,15742,,,0,"Move d-o-a auth library to keystoneauth

With the keystoneauth release, the authentication library
should move from keystoneclient to keystoneauth.

Co-Authored-By: Diego Adolfo <diegoado@gmail.com>

Change-Id: If880022f447255e7d943915087e229778cc6acf8
Implements: blueprint keystoneauth-update
",git fetch https://review.opendev.org/openstack/django_openstack_auth refs/changes/51/205251/18 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_auth/user.py', 'openstack_auth/backend.py', 'openstack_auth/utils.py']",3,68d83b865d2e29bd2b25f14081c070e13a2fd480,bp/k2k-federation,from keystoneauth1.auth.identity import v2 as v2_auth from keystoneauth1.auth.identity import v3 as v3_auth,from keystoneclient.auth.identity import v2 as v2_auth from keystoneclient.auth.identity import v3 as v3_auth,11,11
openstack%2Fshade~master~I62a7d6de0a4890ca9f58aaa3de5090e395baf850,openstack/shade,master,I62a7d6de0a4890ca9f58aaa3de5090e395baf850,Bug fix: Allow name update for domains,MERGED,2015-12-08 20:20:44.000000000,2015-12-11 18:22:07.000000000,2015-12-11 18:22:06.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}]","[{'number': 1, 'created': '2015-12-08 20:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/3aa4e0de5541b372bdafbb909adfae3fb073b629', 'message': ""Bug fix: Allow name update for domains\n\nWe were not passing the 'name' argument through to the client for\nupdating a domain. Fix that and add tests to verify it is passed.\n\nAlso add missing domain API unit tests.\n\nChange-Id: I62a7d6de0a4890ca9f58aaa3de5090e395baf850\n""}, {'number': 2, 'created': '2015-12-08 20:28:22.000000000', 'files': ['shade/tests/unit/test_domains.py', 'shade/operatorcloud.py', 'shade/tests/functional/test_domain.py', 'releasenotes/notes/fix-update-domain-af47b066ac52eb7f.yaml'], 'web_link': 'https://opendev.org/openstack/shade/commit/d38af94bed473595155852f499c6aa56c5a33649', 'message': ""Bug fix: Allow name update for domains\n\nWe were not passing the 'name' argument through to the client for\nupdating a domain. Fix that and add tests to verify it is passed.\n\nAlso add missing domain API unit tests.\n\nChange-Id: I62a7d6de0a4890ca9f58aaa3de5090e395baf850\n""}]",0,254940,d38af94bed473595155852f499c6aa56c5a33649,9,4,2,3099,,,0,"Bug fix: Allow name update for domains

We were not passing the 'name' argument through to the client for
updating a domain. Fix that and add tests to verify it is passed.

Also add missing domain API unit tests.

Change-Id: I62a7d6de0a4890ca9f58aaa3de5090e395baf850
",git fetch https://review.opendev.org/openstack/shade refs/changes/40/254940/2 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_domains.py', 'shade/operatorcloud.py', 'shade/tests/functional/test_domain.py', 'releasenotes/notes/fix-update-domain-af47b066ac52eb7f.yaml']",4,3aa4e0de5541b372bdafbb909adfae3fb073b629,coverage,--- fixes: - Fix for update_domain() where 'name' was not updatable. ,,81,1
openstack%2Fpython-neutronclient~master~I88b0fdd65a649694252d5ff43a174e75026df5b1,openstack/python-neutronclient,master,I88b0fdd65a649694252d5ff43a174e75026df5b1,Remove XML support,MERGED,2014-12-30 11:06:53.000000000,2015-12-11 18:21:16.000000000,2015-12-11 18:21:14.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 5948}, {'_account_id': 6788}, {'_account_id': 6854}, {'_account_id': 7293}, {'_account_id': 8410}, {'_account_id': 9656}, {'_account_id': 12999}, {'_account_id': 14605}, {'_account_id': 17776}]","[{'number': 1, 'created': '2014-12-30 11:06:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/9a537d05d95442efc8fb8a570fba96628ae67f64', 'message': 'WIP: Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nRelated-Bug: #1380787\n'}, {'number': 2, 'created': '2014-12-30 11:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/51a58af6d6514b665f39aaf90cff5cf36341b9f4', 'message': 'WIP: Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nRelated-Bug: #1380787\n'}, {'number': 3, 'created': '2015-12-04 13:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/e07fc4d298ef991e469d1559da43b9305c6ef5f0', 'message': 'WIP: Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 4, 'created': '2015-12-04 13:52:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/982d8b1c179ec5a2987c79661d79561488bf9dee', 'message': 'WIP: Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 5, 'created': '2015-12-07 11:13:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/7e0c8628951d3c1ec5c8e1c508220e88cf5ec9d2', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and removed ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 6, 'created': '2015-12-07 13:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/20d65224fb451f41bed560e2c0993b3abd3dd1dc', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and deprecated ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 7, 'created': '2015-12-07 13:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/88aeba2f5665d4d0c6e9be1fc909bb8103b13f38', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and deprecated ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 8, 'created': '2015-12-07 13:13:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/020cf775b127ff043987c853ee97176a0a5a8e5b', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and deprecated ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 9, 'created': '2015-12-07 15:27:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/f942bb2f720e4a265a3351560c121b337e94fa48', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and deprecated ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}, {'number': 10, 'created': '2015-12-09 08:09:47.000000000', 'files': ['neutronclient/neutron/v2_0/router.py', 'neutronclient/tests/unit/test_cli20_agentschedulers.py', 'neutronclient/tests/unit/lb/v2/test_cli20_member.py', 'neutronclient/tests/unit/test_cli20_nsx_queue.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/neutron/v2_0/floatingip.py', 'neutronclient/neutron/v2_0/metering.py', 'neutronclient/tests/unit/lb/v2/test_cli20_loadbalancer.py', 'neutronclient/tests/unit/lb/v2/test_cli20_pool.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/neutron/v2_0/lb/pool.py', 'neutronclient/v2_0/client.py', 'neutronclient/neutron/v2_0/agentscheduler.py', 'neutronclient/tests/unit/test_cli20_servicetype.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/tests/unit/lb/v2/test_cli20_listener.py', 'neutronclient/common/serializer.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py', 'neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/tests/unit/test_http.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/test_cli20_nsx_networkgateway.py', 'neutronclient/tests/unit/test_cli20_subnet.py', 'neutronclient/neutron/v2_0/nsx/networkgateway.py', 'releasenotes/notes/drop-xml-support-41babecb1784d996.yaml', 'neutron_test.sh', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/neutron/v2_0/flavor/flavor.py', 'neutronclient/tests/unit/test_cli20_network.py', 'neutronclient/tests/unit/test_cli20_nuage_netpartition.py', 'neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/neutron/v2_0/fw/firewallpolicy.py', 'neutronclient/common/constants.py', 'neutronclient/neutron/v2_0/rbac.py', 'neutronclient/tests/unit/test_cli20_metering.py', 'neutronclient/tests/unit/test_cli20_router.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py', 'neutronclient/tests/unit/lb/v2/test_cli20_healthmonitor.py', 'neutronclient/neutron/v2_0/port.py', 'neutronclient/neutron/v2_0/lb/healthmonitor.py', 'neutronclient/neutron/v2_0/quota.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/54a4aea969fe06422f64005652ce23ac7b616d98', 'message': 'Remove XML support\n\nAs XML support has been removed from neutron, there is no need\nto keep it in client.\n\nDropped XML serializer and deserializer and deprecated ""request-format""\nCLI option, making JSON the default and the only supported request\nformat.\n\nDocImpact\n\nChange-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1\nCloses-Bug: #1380787\n'}]",23,144439,54a4aea969fe06422f64005652ce23ac7b616d98,47,11,10,7293,,,0,"Remove XML support

As XML support has been removed from neutron, there is no need
to keep it in client.

Dropped XML serializer and deserializer and deprecated ""request-format""
CLI option, making JSON the default and the only supported request
format.

DocImpact

Change-Id: I88b0fdd65a649694252d5ff43a174e75026df5b1
Closes-Bug: #1380787
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/39/144439/7 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/test_cli20_nsx_queue.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/__init__.py', 'neutronclient/tests/unit/test_cli20.py', 'neutronclient/tests/unit/fw/test_cli20_firewall.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/v2_0/client.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsec_site_connection.py', 'neutronclient/tests/unit/test_cli20_servicetype.py', 'neutronclient/tests/unit/lb/test_cli20_healthmonitor.py', 'neutronclient/tests/unit/fw/test_cli20_firewallpolicy.py', 'neutronclient/common/serializer.py', 'neutronclient/tests/unit/fw/test_cli20_firewallrule.py', 'neutronclient/tests/unit/lb/test_cli20_vip.py', 'neutronclient/tests/unit/test_cli20_floatingips.py', 'neutronclient/tests/unit/test_http.py', 'neutronclient/tests/unit/lb/test_cli20_member.py', 'neutronclient/tests/unit/test_cli20_nsx_networkgateway.py', 'neutronclient/tests/unit/test_cli20_subnet.py', 'neutronclient/tests/unit/lb/test_cli20_pool.py', 'neutronclient/tests/unit/test_cli20_network.py', 'neutronclient/tests/unit/test_cli20_nuage_netpartition.py', 'neutronclient/tests/unit/test_cli20_port.py', 'neutronclient/tests/unit/vpn/test_cli20_vpnservice.py', 'neutronclient/common/constants.py', 'neutronclient/tests/unit/test_cli20_metering.py', 'neutronclient/tests/unit/test_cli20_packetfilter.py', 'neutronclient/tests/unit/test_cli20_router.py', 'neutronclient/tests/unit/test_cli20_securitygroup.py', 'neutronclient/tests/unit/test_cli20_agenschedulers.py']",30,9a537d05d95442efc8fb8a570fba96628ae67f64,bug/1380787,, class CLITestV20LBaaSAgentSchedulerXML(CLITestV20LBaaSAgentScheduler): format = 'xml',20,452
openstack%2Fkolla~master~I73395afa2a2d8f3dc835e010e3b1959ec725da2a,openstack/kolla,master,I73395afa2a2d8f3dc835e010e3b1959ec725da2a,Improve ansible deployment failure reporting,MERGED,2015-12-11 07:48:40.000000000,2015-12-11 18:20:12.000000000,2015-12-11 18:20:11.000000000,"[{'_account_id': 3}, {'_account_id': 10787}, {'_account_id': 11105}, {'_account_id': 13039}]","[{'number': 1, 'created': '2015-12-11 07:48:40.000000000', 'files': ['tests/deploy_aio.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6190411d199b8c2e03c3a8d684a219ea99782737', 'message': 'Improve ansible deployment failure reporting\n\nChange-Id: I73395afa2a2d8f3dc835e010e3b1959ec725da2a\nCloses-Bug: #1525102\nCo-Authored-By: Paul Bourke <paul.bourke@oracle.com>\n'}]",0,256270,6190411d199b8c2e03c3a8d684a219ea99782737,8,4,1,13039,,,0,"Improve ansible deployment failure reporting

Change-Id: I73395afa2a2d8f3dc835e010e3b1959ec725da2a
Closes-Bug: #1525102
Co-Authored-By: Paul Bourke <paul.bourke@oracle.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/70/256270/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/deploy_aio.sh'],1,6190411d199b8c2e03c3a8d684a219ea99782737,bug/1525102," for failed in $(docker ps -a --format ""{{.Names}}"" --filter status=exited); do docker logs --tail=all $failed done", docker logs bootstrap_keystone,3,1
openstack%2Fshade~master~I75ab31ddeb731d192a0266712bfb95c5f21c8acb,openstack/shade,master,I75ab31ddeb731d192a0266712bfb95c5f21c8acb,Improve test coverage: network delete API,MERGED,2015-12-08 19:33:36.000000000,2015-12-11 18:20:07.000000000,2015-12-11 18:20:05.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 6488}]","[{'number': 1, 'created': '2015-12-08 19:33:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/8463d500b0638ec1f723451aa5e39b006d89dc20', 'message': 'Improve test coverage: network delete API\n\nAdd missing unit tests for delete_network() API method.\n\nChange-Id: I75ab31ddeb731d192a0266712bfb95c5f21c8acb\n'}, {'number': 2, 'created': '2015-12-08 20:28:16.000000000', 'files': ['shade/tests/unit/test_network.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/4c8cfe4b18bb17704d4e49af95a80d5ed04d5958', 'message': 'Improve test coverage: network delete API\n\nAdd missing unit tests for delete_network() API method.\n\nChange-Id: I75ab31ddeb731d192a0266712bfb95c5f21c8acb\n'}]",0,254922,4c8cfe4b18bb17704d4e49af95a80d5ed04d5958,10,4,2,3099,,,0,"Improve test coverage: network delete API

Add missing unit tests for delete_network() API method.

Change-Id: I75ab31ddeb731d192a0266712bfb95c5f21c8acb
",git fetch https://review.opendev.org/openstack/shade refs/changes/22/254922/2 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_network.py'],1,8463d500b0638ec1f723451aa5e39b006d89dc20,coverage,"import testtools @mock.patch.object(shade.OpenStackCloud, 'get_network') @mock.patch.object(shade.OpenStackCloud, 'neutron_client') def test_delete_network(self, mock_neutron, mock_get): mock_get.return_value = dict(id='net-id', name='test-net') self.assertTrue(self.cloud.delete_network('test-net')) mock_get.assert_called_once_with('test-net') mock_neutron.delete_network.assert_called_once_with(network='net-id') @mock.patch.object(shade.OpenStackCloud, 'get_network') def test_delete_network_not_found(self, mock_get): mock_get.return_value = None self.assertFalse(self.cloud.delete_network('test-net')) mock_get.assert_called_once_with('test-net') @mock.patch.object(shade.OpenStackCloud, 'get_network') @mock.patch.object(shade.OpenStackCloud, 'neutron_client') def test_delete_network_exception(self, mock_neutron, mock_get): mock_get.return_value = dict(id='net-id', name='test-net') mock_neutron.delete_network.side_effect = Exception() with testtools.ExpectedException( shade.OpenStackCloudException, ""Error deleting network test-net"" ): self.cloud.delete_network('test-net') mock_get.assert_called_once_with('test-net') mock_neutron.delete_network.assert_called_once_with(network='net-id')",,28,0
openstack%2Fpuppet-keystone~master~Ibe91ac643d620543c6f7205a8a1944a56431bf43,openstack/puppet-keystone,master,Ibe91ac643d620543c6f7205a8a1944a56431bf43,Switch Keystone to $::os_service_default,MERGED,2015-11-27 20:32:40.000000000,2015-12-11 18:18:46.000000000,2015-12-11 18:18:40.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 14007}, {'_account_id': 15519}, {'_account_id': 18795}]","[{'number': 1, 'created': '2015-11-27 20:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/b8b0ab82353e363e30e9d6f6e87555ed8859b967', 'message': 'Switch Keystone to $::os_service_default\n\nThis patch switches Keystone params, which have absent ensure, to\n$::os_service_default fact\n\nChange-Id: Ibe91ac643d620543c6f7205a8a1944a56431bf43\n'}, {'number': 2, 'created': '2015-12-07 18:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/3678b296e2f0df69cbbb5ea5f4c31fad44f622b3', 'message': 'Switch Keystone to $::os_service_default\n\nThis patch switches Keystone params, which have absent ensure, to\n$::os_service_default fact\n\nChange-Id: Ibe91ac643d620543c6f7205a8a1944a56431bf43\n'}, {'number': 3, 'created': '2015-12-10 17:41:55.000000000', 'files': ['spec/classes/keystone_spec.rb', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/c12fa3d6b6bdffd2a6cea0d4aeb31fbbf76c14f0', 'message': 'Switch Keystone to $::os_service_default\n\nThis patch switches Keystone params, which have absent ensure, to\n$::os_service_default fact\n\nChange-Id: Ibe91ac643d620543c6f7205a8a1944a56431bf43\n'}]",9,250945,c12fa3d6b6bdffd2a6cea0d4aeb31fbbf76c14f0,24,7,3,15519,,,0,"Switch Keystone to $::os_service_default

This patch switches Keystone params, which have absent ensure, to
$::os_service_default fact

Change-Id: Ibe91ac643d620543c6f7205a8a1944a56431bf43
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/45/250945/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/federation/identity_provider.pp', 'spec/classes/keystone_spec.rb', 'manifests/init.pp', 'spec/classes/keystone_federation_shibboleth.rb', 'manifests/federation/shibboleth.pp']",5,b8b0ab82353e363e30e9d6f6e87555ed8859b967,os_service_default," $module_plugin = $::os_service_default,"," $module_plugin = 'keystone.auth.plugins.mapped.Mapped',",139,170
openstack%2Ffuel-astute~master~Ibe24d047ab502b88ea0ae9f8c77f94440000d289,openstack/fuel-astute,master,Ibe24d047ab502b88ea0ae9f8c77f94440000d289,Task base deployment,MERGED,2015-12-01 14:19:24.000000000,2015-12-11 18:10:25.000000000,2015-12-11 18:09:48.000000000,"[{'_account_id': 3}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-01 14:19:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/873f21c497c4a3fef2a89e752e128bf78a5b8ffd', 'message': 'Base task deployment\n\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 2, 'created': '2015-12-01 18:21:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/e3db6d9f13500bad26d33a4bf84a64f971fb4399', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n\nCloses-Bug: #1506962\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 3, 'created': '2015-12-01 18:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/301fc817a474f80f00565bd58ac0fd612455b9d9', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 4, 'created': '2015-12-01 18:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/8c5009795f4cd22a960ee013735406b063d74078', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph.\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 5, 'created': '2015-12-01 18:56:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/4c6397ddac02dfd1860d6c2e011cf1229cee6bf9', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph.\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: blueprint task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 6, 'created': '2015-12-01 23:21:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/c2ff936e1469d71eb7cdc4ad817621e7d56875e0', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 7, 'created': '2015-12-02 00:44:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/4fbf9c55ec8736095eb2d76b080d5b64b7c4ea3d', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 8, 'created': '2015-12-02 19:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/c0b3c11a068018c01baa8bebd2709aeae1e74785', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nimplements: task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 9, 'created': '2015-12-02 19:27:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/0e3eb7dd6943c3fc4cf74f2fcb6babc1b72908cb', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nCloses-Bug: #1506962\nCloses-Bug: #1430470\nImplements: blueprint task-based-deployment-astute\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 10, 'created': '2015-12-02 19:27:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/0ba55a321ea2b105c0c58aeca47ae7c22c4b5ff8', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 11, 'created': '2015-12-03 20:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/9654684a4537e186c75168caedae387a1804a828', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 12, 'created': '2015-12-07 13:36:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/845ef4eba7d05d35b83e21af767b174181523a82', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 13, 'created': '2015-12-07 15:03:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/bd18b4ed21ab8132292fa078aef5ae6c570e6819', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 14, 'created': '2015-12-07 15:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/4b6cd8d681307cee0e7a4935be740a27518eaf42', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 15, 'created': '2015-12-08 17:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/94457d38f066f51c55aeab55e59ab08c6151989b', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 16, 'created': '2015-12-09 14:43:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/f3185225e51fd5878d998fec5da9b002a02dd6d0', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 17, 'created': '2015-12-10 11:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/e61729d4fb4440e5b2dacbccf420ad92b5ec0270', 'message': 'Base task deployment\n\n* all tasks now async, including shell;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 18, 'created': '2015-12-10 11:48:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/26a5c362049bc8f198fb2eba56ca66af66a90829', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 19, 'created': '2015-12-10 12:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/58cb97f4d6f4aae30e634dc78222ec60dd00e674', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 20, 'created': '2015-12-10 12:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/b013d2cd9c195adc5b8e4dc2f65e190555d2f87c', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 21, 'created': '2015-12-10 12:51:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/8da3c4355a81dea23761fe70ae5ff7bc6bec3e54', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 22, 'created': '2015-12-10 16:44:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/d4b7ca901d26c19ee3ec57cf6131e0ded5086023', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 23, 'created': '2015-12-10 21:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/ee79898939e02ccfb619149eb3e367e4b7edb03a', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 24, 'created': '2015-12-11 01:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/159892758c66b7d747fb37ee60b1674b7f39963f', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 25, 'created': '2015-12-11 14:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/b1827b7a0bcd1a513c3e6e4ef4a44596e482b549', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 26, 'created': '2015-12-11 16:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/533a4d9ce60006922092c448f8efaf97dccdb895', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}, {'number': 27, 'created': '2015-12-11 17:08:34.000000000', 'files': ['lib/astute/tasks/noop.rb', 'lib/astute/tasks/upload_files.rb', 'lib/astute/deploy_actions.rb', 'lib/astute/server/dispatcher.rb', 'lib/astute/context.rb', 'lib/astute/tasks/cobbler_sync.rb', 'lib/astute/exceptions.rb', 'lib/astute/puppet_task.rb', 'lib/astute/tasks/reboot.rb', 'lib/astute/config.rb', 'spec/unit/task_node_spec.rb', 'lib/astute/tasks/sync.rb', 'lib/astute/tasks/copy_files.rb', 'lib/astute/orchestrator.rb', 'lib/astute/task.rb', 'lib/astute/mclient.rb', 'lib/astute/tasks/upload_file.rb', 'spec/unit/orchestrator_spec.rb', 'lib/astute/task_deployment.rb', 'lib/astute/task_node.rb', 'lib/astute/tasks/puppet.rb', 'lib/astute/tasks/shell.rb', 'spec/unit/task_deployment_spec.rb', 'lib/astute.rb', 'spec/unit/mclient_spec.rb'], 'web_link': 'https://opendev.org/openstack/fuel-astute/commit/583d68b1cbac03a4f9b6bb9f15921fbbb38159ee', 'message': 'Task base deployment\n\n* async task: puppet, shell, cobbler, sync, noop and reboot;\n* not async: upload file, upload files, copy files;\n* new report format based on task progress instead of log;\n* support union graph deployment: pre/post tasks included in main graph;\n* plugins tasks also included in main graph;\n* support previous failt tollerance strategy (percent of failed nodes).\n* add tests.\n\nImplements: blueprint task-based-deployment-astute\nCloses-Bug: #1506962\nCloses-Bug: #1430470\n\nChange-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289\n'}]",103,251886,583d68b1cbac03a4f9b6bb9f15921fbbb38159ee,139,7,27,8776,,,0,"Task base deployment

* async task: puppet, shell, cobbler, sync, noop and reboot;
* not async: upload file, upload files, copy files;
* new report format based on task progress instead of log;
* support union graph deployment: pre/post tasks included in main graph;
* plugins tasks also included in main graph;
* support previous failt tollerance strategy (percent of failed nodes).
* add tests.

Implements: blueprint task-based-deployment-astute
Closes-Bug: #1506962
Closes-Bug: #1430470

Change-Id: Ibe24d047ab502b88ea0ae9f8c77f94440000d289
",git fetch https://review.opendev.org/openstack/fuel-astute refs/changes/86/251886/20 && git format-patch -1 --stdout FETCH_HEAD,"['lib/astute/nailgun_tasks/puppet.rb', 'lib/astute/nailgun_tasks/upload_file.rb', 'Gemfile', 'lib/astute/nailgun_tasks/upload_files.rb', 'lib/astute/exceptions.rb', 'lib/astute/nailgun_tasks/reboot.rb', 'lib/astute/puppet_task.rb', 'lib/astute/nailgun_tasks/sync.rb', 'lib/astute/nailgun_tasks/shell.rb', 'astute.gemspec', 'lib/astute/nailgun_task.rb', 'lib/astute/nailgun_task_deployment.rb', 'lib/astute/nailgun_tasks/copy_files.rb', 'lib/astute.rb', 'lib/astute/nailgun_tasks/cobbler_sync.rb', 'lib/astute/orchestrator.rb']",16,873f21c497c4a3fef2a89e752e128bf78a5b8ffd,bp/task-based-deployment-astute," def task_deploy(up_reporter, task_id, deployment_info) context = Context.new(task_id, up_reporter) Astute.logger.info ""Task based deployment will be used"" deploy_engine_instance.deploy(deployment_info, pre_deployment, post_deployment) context.status end ",,884,1
openstack%2Fopenstack-ansible~kilo~I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93,openstack/openstack-ansible,kilo,I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93,Fixes playbook runtime issues with ldap,MERGED,2015-12-04 19:22:25.000000000,2015-12-11 18:06:06.000000000,2015-12-11 18:06:04.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 13997}, {'_account_id': 14288}, {'_account_id': 14552}, {'_account_id': 15993}]","[{'number': 1, 'created': '2015-12-04 19:22:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ca51a2eec4eebcc40ea82b9c0c76a09fccfbd70e', 'message': 'Fixes playbook runtime issues with ldap\n\nWhen using an LDAP backend the plabooks fail when ""ensuring.*""\nwhich is a keystone client action. The reason for the failure is\nrelated to how ldap backend, and is triggered when the service\nusers are within the ldap and not SQL. To resolve the issue a boolean\nconditional was created on the various OS_.* roles to skip specific\ntasks when the service users have already been added into LDAP.\n\nChange-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit 283a89afa8d9d6840f77e902ad1127260f32a195)\n'}, {'number': 2, 'created': '2015-12-04 19:24:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ae03a9e65695115a97694e7cffca9ee237fd75fc', 'message': 'Fixes playbook runtime issues with ldap\n\nWhen using an LDAP backend the plabooks fail when ""ensuring.*""\nwhich is a keystone client action. The reason for the failure is\nrelated to how ldap backend, and is triggered when the service\nusers are within the ldap and not SQL. To resolve the issue a boolean\nconditional was created on the various OS_.* roles to skip specific\ntasks when the service users have already been added into LDAP.\n\nChange-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit 283a89afa8d9d6840f77e902ad1127260f32a195)\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-04 19:26:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/65381cc914b5dfd3be89c847538ed418c0109f4b', 'message': 'Fixes playbook runtime issues with ldap\n\nWhen using an LDAP backend the plabooks fail when ""ensuring.*""\nwhich is a keystone client action. The reason for the failure is\nrelated to how ldap backend, and is triggered when the service\nusers are within the ldap and not SQL. To resolve the issue a boolean\nconditional was created on the various OS_.* roles to skip specific\ntasks when the service users have already been added into LDAP.\n\nChange-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit 283a89afa8d9d6840f77e902ad1127260f32a195)\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2015-12-09 20:50:12.000000000', 'files': ['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_swift/tasks/swift_service_setup.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/tasks/glance_service_setup.yml', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_ceilometer/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_keystone/defaults/main.yml', 'playbooks/roles/os_keystone/tasks/keystone_service_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b73c95d80a202cc5df61760bb706ec65a2b44783', 'message': 'Fixes playbook runtime issues with ldap\n\nWhen using an LDAP backend the playbooks fail when ""ensuring.*""\nwhich is a keystone client action. The reason for the failure is\nrelated to how ldap backend, and is triggered when the service\nusers are within the ldap and not SQL. To resolve the issue a boolean\nconditional was created on the various OS_.* roles to skip specific\ntasks when the service users have already been added into LDAP.\n\nChange-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit 2559ed4f13cd242c9f02cd023a7242db56650b0d)\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",3,253658,b73c95d80a202cc5df61760bb706ec65a2b44783,24,9,4,7353,,,0,"Fixes playbook runtime issues with ldap

When using an LDAP backend the playbooks fail when ""ensuring.*""
which is a keystone client action. The reason for the failure is
related to how ldap backend, and is triggered when the service
users are within the ldap and not SQL. To resolve the issue a boolean
conditional was created on the various OS_.* roles to skip specific
tasks when the service users have already been added into LDAP.

Change-Id: I64a8d1e926c54b821f8bfb561a8b6f755bc1ed93
Closes-Bug: #1518351
Closes-Bug: #1519174
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit 2559ed4f13cd242c9f02cd023a7242db56650b0d)
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/58/253658/3 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/os_swift/defaults/main.yml', 'playbooks/roles/os_heat/tasks/heat_service_add.yml', 'playbooks/roles/os_swift/tasks/swift_service_setup.yml', 'playbooks/roles/os_glance/defaults/main.yml', 'playbooks/roles/os_glance/tasks/glance_service_setup.yml', 'playbooks/roles/os_nova/defaults/main.yml', 'playbooks/roles/os_nova/tasks/nova_service_add.yml', 'playbooks/roles/os_neutron/tasks/neutron_service_add.yml', 'playbooks/roles/os_ceilometer/defaults/main.yml', 'playbooks/roles/os_neutron/defaults/main.yml', 'playbooks/roles/os_cinder/defaults/main.yml', 'playbooks/roles/os_cinder/tasks/cinder_service_add.yml', 'playbooks/roles/os_ceilometer/tasks/ceilometer_service_add.yml', 'playbooks/roles/os_heat/defaults/main.yml', 'playbooks/inventory/group_vars/hosts.yml', 'playbooks/roles/os_keystone/defaults/main.yml', 'playbooks/roles/os_keystone/tasks/keystone_service_setup.yml']",17,ca51a2eec4eebcc40ea82b9c0c76a09fccfbd70e,bug/1518351, when: not keystone_service_in_ldap | bool when: not keystone_service_in_ldap | bool when: not keystone_service_in_ldap | bool,,109,7
openstack%2Fironic-lib~master~I8287e3798a6b1aeab689510ced3ef62e59060df3,openstack/ironic-lib,master,I8287e3798a6b1aeab689510ced3ef62e59060df3,Updated from global requirements,MERGED,2015-12-11 15:19:47.000000000,2015-12-11 17:54:46.000000000,2015-12-11 17:54:46.000000000,"[{'_account_id': 3}, {'_account_id': 10239}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-12-11 15:19:47.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/048129a9d99778c14d6953be2bd1ab47d1b38730', 'message': 'Updated from global requirements\n\nChange-Id: I8287e3798a6b1aeab689510ced3ef62e59060df3\n'}]",0,256484,048129a9d99778c14d6953be2bd1ab47d1b38730,7,3,1,11131,,,0,"Updated from global requirements

Change-Id: I8287e3798a6b1aeab689510ced3ef62e59060df3
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/84/256484/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,048129a9d99778c14d6953be2bd1ab47d1b38730,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Fpuppet-tempest~master~I8ef56aeae46179f20569f9dc4c68c04e9123e649,openstack/puppet-tempest,master,I8ef56aeae46179f20569f9dc4c68c04e9123e649,CI test - do not merge,ABANDONED,2015-12-11 16:41:36.000000000,2015-12-11 17:52:13.000000000,,"[{'_account_id': 3}, {'_account_id': 15519}]","[{'number': 1, 'created': '2015-12-11 16:41:36.000000000', 'files': ['README.markdown'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/6af180fabebac109955cb917c1917927583a6dca', 'message': 'CI test - do not merge\n\nVerify if tempest will not break.\n\nChange-Id: I8ef56aeae46179f20569f9dc4c68c04e9123e649\nDepends-On: Ibe91ac643d620543c6f7205a8a1944a56431bf43\n'}]",0,256576,6af180fabebac109955cb917c1917927583a6dca,4,2,1,15519,,,0,"CI test - do not merge

Verify if tempest will not break.

Change-Id: I8ef56aeae46179f20569f9dc4c68c04e9123e649
Depends-On: Ibe91ac643d620543c6f7205a8a1944a56431bf43
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/76/256576/1 && git format-patch -1 --stdout FETCH_HEAD,['README.markdown'],1,6af180fabebac109955cb917c1917927583a6dca,puppet/test-ci,Do not review,,1,1
openstack%2Fopenstacksdk~master~Id036c6373092673ce0c54be1b64ea87d1de89b88,openstack/openstacksdk,master,Id036c6373092673ce0c54be1b64ea87d1de89b88,"Fix ""report a bug"" launchpad project",MERGED,2015-12-11 16:11:20.000000000,2015-12-11 17:50:01.000000000,2015-12-11 17:50:00.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 6547}, {'_account_id': 8736}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 16:11:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9403057ce9783649be4cf617c595502aed0110ac', 'message': 'Fix ""report a bug"" launchpad project\n\nFor docs set the launchpad project users report bugs\nagainst to ""python-openstacksdk"". Users can report bugs\nusing the ""bug icon"" that will\ndirectly link to the launchpad project, it currently goes to\n""openstack-manuals"" which is wrong for this content.\n\nThis variable is used by openstackdocstheme 1.2.6.\n\nAlso, update comments for the variables passed to openstackdocstheme.\n\nChange-Id: Id036c6373092673ce0c54be1b64ea87d1de89b88\nRelated-Bug: #1524476\n'}, {'number': 2, 'created': '2015-12-11 16:40:13.000000000', 'files': ['doc/source/conf.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/eeedb20a60cb0f9e9177ec958cd977794f2566d4', 'message': 'Fix ""report a bug"" launchpad project\n\nFor docs set the launchpad project users report bugs\nagainst to ""python-openstacksdk"". Users can report bugs\nusing the ""bug icon"" that will\ndirectly link to the launchpad project, it currently goes to\n""openstack-manuals"" which is wrong for this content.\n\nThis variable is used by openstackdocstheme 1.2.6.\n\nAlso, update comments for the variables passed to openstackdocstheme.\n\nChange-Id: Id036c6373092673ce0c54be1b64ea87d1de89b88\nRelated-Bug: #1524476\n'}]",2,256560,eeedb20a60cb0f9e9177ec958cd977794f2566d4,12,5,2,6547,,,0,"Fix ""report a bug"" launchpad project

For docs set the launchpad project users report bugs
against to ""python-openstacksdk"". Users can report bugs
using the ""bug icon"" that will
directly link to the launchpad project, it currently goes to
""openstack-manuals"" which is wrong for this content.

This variable is used by openstackdocstheme 1.2.6.

Also, update comments for the variables passed to openstackdocstheme.

Change-Id: Id036c6373092673ce0c54be1b64ea87d1de89b88
Related-Bug: #1524476
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/60/256560/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/conf.py'],1,9403057ce9783649be4cf617c595502aed0110ac,bug/1524476,"# A few variables have to be set for the log-a-bug feature. # giturl: The location of conf.py on Git. Must be set manually. # gitsha: The SHA checksum of the bug description. Extracted from git log. # bug_tag: Tag for categorizing the bug. Must be set manually. # bug_project: Launchpad project to file bugs against. # These variables are passed to the logabug code via html_context.pwd = os.popen(""pwd"").read().strip('\n')html_context = {""pwd"": pwd, ""gitsha"": gitsha, ""bug_tag"": bug_tag, ""giturl"": giturl, ""bug_project"": ""python-openstacksdk""}","# We ask git for the SHA checksum # The git SHA checksum is used by ""log-a-bug""# tag that reported bugs will be tagged with when using the ""log a bug"" # clickthrough on each page, such as user-guide or install-guidepwd = os.getcwd()html_context = { ""pwd"":pwd, ""gitsha"":gitsha, ""bug_tag"": bug_tag}",12,6
openstack%2Fdevstack~master~I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e,openstack/devstack,master,I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e,Support new ironic ENROLL state,ABANDONED,2015-07-27 13:02:34.000000000,2015-12-11 17:44:46.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 4656}, {'_account_id': 6773}, {'_account_id': 7118}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-07-27 13:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/24a5ba5fc6f5e1b3fa8ea2e926377e95431d1f8b', 'message': ""Support new ironic ENROLL state\n\nStarting with version 1.11 of the bare metal API nodes appear first\nin ENROLL state, not AVAILABLE. This change detects support for 1.11\nAPI version and explicitly requests it on node-create.\n\nThus we'll avoid breakage if API version >= 1.11 will ever become\nthe default in ironicclient.\n\nNice side effect of this patch is that power credentials for nodes\nwill be verified as part of node enrollment.\n\nChange-Id: I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e\n""}, {'number': 2, 'created': '2015-07-27 14:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e65bdc6755104751f3dae52e336527ed05193965', 'message': ""Support new ironic ENROLL state\n\nStarting with version 1.11 of the bare metal API nodes appear first\nin ENROLL state, not AVAILABLE. This change detects support for 1.11\nAPI version and explicitly requests it on node-create.\n\nThus we'll avoid breakage if API version >= 1.11 will ever become\nthe default in ironicclient.\n\nNice side effect of this patch is that power credentials for nodes\nwill be verified as part of node enrollment.\n\nChange-Id: I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e\n""}, {'number': 3, 'created': '2015-07-27 16:58:21.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/2b118252f4118cc863a921c134020a02be12175f', 'message': ""Support new ironic ENROLL state\n\nStarting with version 1.11 of the bare metal API nodes appear first\nin ENROLL state, not AVAILABLE. This change detects support for 1.11\nAPI version and explicitly requests it on node-create.\n\nThus we'll avoid breakage if API version >= 1.11 will ever become\nthe default in ironicclient.\n\nNice side effect of this patch is that power credentials for nodes\nwill be verified as part of node enrollment.\n\nChange-Id: I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e\n""}]",8,206055,2b118252f4118cc863a921c134020a02be12175f,14,8,3,10239,,,0,"Support new ironic ENROLL state

Starting with version 1.11 of the bare metal API nodes appear first
in ENROLL state, not AVAILABLE. This change detects support for 1.11
API version and explicitly requests it on node-create.

Thus we'll avoid breakage if API version >= 1.11 will ever become
the default in ironicclient.

Nice side effect of this patch is that power credentials for nodes
will be verified as part of node enrollment.

Change-Id: I0e33a49a6c3fdc092a62d4de1b0f12f462312f3e
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/206055/2 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,24a5ba5fc6f5e1b3fa8ea2e926377e95431d1f8b,ironic-enroll,"function wait_for_provision_state { local node_id=$1 local expected_state=$2 for i in $(seq 1 120); do local current_state=""$(ironic node-show $node_id | grep provision_state | get_field 2)"" if [[ $current_state == $expected_state ]]; then return 0 fi sleep 1 done local last_error=""$(ironic node-show $node_id | grep last_error | get_field 2)"" die $LINENO ""Timed out waiting for node $node_id provision state to become $expected_state, current state is $current_state, last error:\n$last_error"" } function enroll_nodes { echo_summary ""Detect API version 1.11 support by explicitly requesting it."" if ironic --ironic-api-version 1.11 driver-list > /dev/null; then local enroll_state_supported=1 local node_create_version_arg=""--ironic-api-version 1.11"" else local enroll_state_supported=0 local node_create_version_arg= fi local node_id=$(ironic $node_create_version_arg node-create \ $standalone_node_uuid \ if [[ ""$enroll_state_supported"" == ""1"" ]]; then ironic node-set-provision-state $node_id manage wait_for_provision_state $node_id manageable ironic node-set-provision-state $node_id provide wait_for_provision_state $node_id available fi ",function enroll_nodes { local node_id=$(ironic node-create $standalone_node_uuid\,32,1
openstack%2Fpython-openstackclient~master~If57de2871810caddeeaee96482eb34146968e173,openstack/python-openstackclient,master,If57de2871810caddeeaee96482eb34146968e173,Add source security group support to create rule,MERGED,2015-12-04 22:41:17.000000000,2015-12-11 17:40:12.000000000,2015-12-11 17:40:11.000000000,"[{'_account_id': 3}, {'_account_id': 1941}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}, {'_account_id': 14937}]","[{'number': 1, 'created': '2015-12-04 22:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/aea08acdbec01483d0ef208cb4408e41f0f6cee3', 'message': ""Add source security group support to create rule\n\nThe 'security group rule create' command was updated to support a\nsource security group. Now either a source IP address block or source\nsecurity group can be specified when creating a rule. The default\nremains the same.\n\nChange-Id: If57de2871810caddeeaee96482eb34146968e173\nCloses-Bug: #1522969\n""}, {'number': 2, 'created': '2015-12-07 18:42:22.000000000', 'files': ['doc/source/command-objects/security-group-rule.rst', 'openstackclient/tests/compute/v2/test_security_group_rule.py', 'openstackclient/compute/v2/security_group.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/566388ab1eddd339b054c2046d41e2b01476f4e2', 'message': ""Add source security group support to create rule\n\nThe 'security group rule create' command was updated to support a\nsource security group. Now either a source IP address block or source\nsecurity group can be specified when creating a rule. The default\nremains the same.\n\nChange-Id: If57de2871810caddeeaee96482eb34146968e173\nCloses-Bug: #1522969\n""}]",4,253725,566388ab1eddd339b054c2046d41e2b01476f4e2,29,6,2,8410,,,0,"Add source security group support to create rule

The 'security group rule create' command was updated to support a
source security group. Now either a source IP address block or source
security group can be specified when creating a rule. The default
remains the same.

Change-Id: If57de2871810caddeeaee96482eb34146968e173
Closes-Bug: #1522969
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/25/253725/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/command-objects/security-group-rule.rst', 'openstackclient/tests/compute/v2/test_security_group_rule.py', 'openstackclient/compute/v2/security_group.py']",3,aea08acdbec01483d0ef208cb4408e41f0f6cee3,bug/1522969," source_group = parser.add_mutually_exclusive_group() source_group.add_argument( help=""Source IP address block (may use CIDR notation; default: "" ""0.0.0.0/0)"", ) source_group.add_argument( ""--src-group"", metavar=""<group>"", help=""Source security group (ID only)"", parsed_args.src_group,"," parser.add_argument( help=""Source IP (may use CIDR notation; default: 0.0.0.0/0)"",",50,14
openstack%2Fpython-dracclient~master~Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe,openstack/python-dracclient,master,Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe,Add RAID management,MERGED,2015-12-07 15:21:04.000000000,2015-12-11 17:40:06.000000000,2015-12-11 17:40:06.000000000,"[{'_account_id': 3}, {'_account_id': 7419}, {'_account_id': 10239}, {'_account_id': 10250}]","[{'number': 1, 'created': '2015-12-07 15:21:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/65b22a9ee9fde286537eca1a83e8073d55e15a9f', 'message': 'Add RAID management\n\nChange-Id: Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe\n'}, {'number': 2, 'created': '2015-12-08 13:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/8f524f3f6e7c4d1e3debc034b5b57e475d533188', 'message': 'Add RAID management\n\nChange-Id: Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe\n'}, {'number': 3, 'created': '2015-12-09 15:20:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/b7a7411de4a038054ed2087a5dcb79b2d5cb6595', 'message': 'Add RAID management\n\nChange-Id: Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe\n'}, {'number': 4, 'created': '2015-12-09 15:23:05.000000000', 'files': ['dracclient/tests/test_client.py', 'dracclient/tests/utils.py', 'dracclient/tests/wsman_mocks/raid_service-invoke-delete_virtual_disk-ok.xml', 'dracclient/tests/wsman_mocks/physical_disk_view-enum-ok.xml', 'dracclient/tests/wsman_mocks/raid_service-invoke-create_virtual_disk-ok.xml', 'dracclient/utils.py', 'dracclient/tests/wsman_mocks/raid_service-invoke-create_virtual_disk-error.xml', 'dracclient/tests/wsman_mocks/controller_view-enum-ok.xml', 'dracclient/tests/wsman_mocks/raid_service-invoke-delete_virtual_disk-error.xml', 'dracclient/client.py', 'dracclient/resources/raid.py', 'dracclient/resources/uris.py', 'dracclient/resources/bios.py', 'dracclient/tests/wsman_mocks/virtual_disk_view-enum-ok.xml'], 'web_link': 'https://opendev.org/openstack/python-dracclient/commit/617d5d7e1b8393ce44d7c1e9243c6c028e5e0aea', 'message': 'Add RAID management\n\nChange-Id: Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe\n'}]",16,254247,617d5d7e1b8393ce44d7c1e9243c6c028e5e0aea,17,4,4,7419,,,0,"Add RAID management

Change-Id: Id342bf5de2cf06fa7a9c125a4fac15df21a1f5fe
",git fetch https://review.opendev.org/openstack/python-dracclient refs/changes/47/254247/4 && git format-patch -1 --stdout FETCH_HEAD,"['dracclient/tests/test_client.py', 'dracclient/tests/utils.py', 'dracclient/tests/wsman_mocks/raid_service-invoke-delete_virtual_disk-ok.xml', 'dracclient/tests/wsman_mocks/physical_disk_view-enum-ok.xml', 'dracclient/tests/wsman_mocks/raid_service-invoke-create_virtual_disk-ok.xml', 'dracclient/utils.py', 'dracclient/tests/wsman_mocks/raid_service-invoke-create_virtual_disk-error.xml', 'dracclient/tests/wsman_mocks/controller_view-enum-ok.xml', 'dracclient/tests/wsman_mocks/raid_service-invoke-delete_virtual_disk-error.xml', 'dracclient/client.py', 'dracclient/resources/raid.py', 'dracclient/resources/uris.py', 'dracclient/resources/bios.py', 'dracclient/tests/wsman_mocks/virtual_disk_view-enum-ok.xml']",14,65b22a9ee9fde286537eca1a83e8073d55e15a9f,fix_docstrings,"<s:Envelope xmlns:s=""http://www.w3.org/2003/05/soap-envelope"" xmlns:wsa=""http://schemas.xmlsoap.org/ws/2004/08/addressing"" xmlns:wsen=""http://schemas.xmlsoap.org/ws/2004/09/enumeration"" xmlns:wsman=""http://schemas.dmtf.org/wbem/wsman/1/wsman.xsd"" xmlns:n1=""http://schemas.dell.com/wbem/wscim/1/cim-schema/2/DCIM_VirtualDiskView"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""> <s:Header> <wsa:To>http://schemas.xmlsoap.org/ws/2004/08/addressing/role/anonymous</wsa:To> <wsa:Action>http://schemas.xmlsoap.org/ws/2004/09/enumeration/EnumerateResponse</wsa:Action> <wsa:RelatesTo>uuid:b182f1ee-103a-103a-8002-fd0aa2bdb228</wsa:RelatesTo> <wsa:MessageID>uuid:b80f21ed-103f-103f-8992-a36fc6fe83b0</wsa:MessageID> </s:Header> <s:Body> <wsen:EnumerateResponse> <wsman:Items> <n1:DCIM_VirtualDiskView> <n1:BlockSizeInBytes>512</n1:BlockSizeInBytes> <n1:BusProtocol>6</n1:BusProtocol> <n1:Cachecade>0</n1:Cachecade> <n1:DeviceDescription>Virtual Disk 0 on Integrated RAID Controller 1</n1:DeviceDescription> <n1:DiskCachePolicy>1024</n1:DiskCachePolicy> <n1:FQDD>Disk.Virtual.0:RAID.Integrated.1-1</n1:FQDD> <n1:InstanceID>Disk.Virtual.0:RAID.Integrated.1-1</n1:InstanceID> <n1:LastSystemInventoryTime>20150301200527.000000+000</n1:LastSystemInventoryTime> <n1:LastUpdateTime>20150301200527.000000+000</n1:LastUpdateTime> <n1:LockStatus>0</n1:LockStatus> <n1:MediaType>1</n1:MediaType> <n1:Name>disk 0</n1:Name> <n1:ObjectStatus>0</n1:ObjectStatus> <n1:OperationName>Background Intialization</n1:OperationName> <n1:OperationPercentComplete>8</n1:OperationPercentComplete> <n1:PendingOperations>0</n1:PendingOperations> <n1:PhysicalDiskIDs xsi:nil=""true""/> <n1:PrimaryStatus>1</n1:PrimaryStatus> <n1:RAIDStatus>2</n1:RAIDStatus> <n1:RAIDTypes>4</n1:RAIDTypes> <n1:ReadCachePolicy>16</n1:ReadCachePolicy> <n1:RemainingRedundancy>1</n1:RemainingRedundancy> <n1:RollupStatus>1</n1:RollupStatus> <n1:SizeInBytes>599550590976</n1:SizeInBytes> <n1:SpanDepth>1</n1:SpanDepth> <n1:SpanLength>2</n1:SpanLength> <n1:StartingLBAinBlocks>0</n1:StartingLBAinBlocks> <n1:StripeSize>128</n1:StripeSize> <n1:T10PIStatus>0</n1:T10PIStatus> <n1:VirtualDiskTargetID>0</n1:VirtualDiskTargetID> <n1:WriteCachePolicy>2</n1:WriteCachePolicy> </n1:DCIM_VirtualDiskView> </wsman:Items> <wsen:EnumerationContext/> <wsman:EndOfSequence/> </wsen:EnumerateResponse> </s:Body> </s:Envelope>",,1072,9
openstack%2Fironic-python-agent~master~I6a572bdd791841add913d33c5b79b59033c3f237,openstack/ironic-python-agent,master,I6a572bdd791841add913d33c5b79b59033c3f237,Run IPA in chroot instead of container in CoreOS,MERGED,2015-12-08 18:22:10.000000000,2015-12-11 17:37:53.000000000,2015-12-11 17:37:52.000000000,"[{'_account_id': 3}, {'_account_id': 6773}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11739}, {'_account_id': 12640}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-12-08 18:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/96ae72aa24308ee202d00be1229fe38ce3048bc3', 'message': 'Run IPA in chroot instead of container in CoreOS\n\nsystemd-nspawn has been adding more and more security features, the\nlatest being /sys and /proc/sys being completely read only. This breaks\nseveral things IPA needs to do from the container, including the sysrq\ntriggers used for reboot.\n\nAdditionally, any downstream hardware manager that wants to implement\nsoftware RAID requires this fix, as mdadm needs to write to /sys to\nassemble arrays. Linux-IO has a similar issue with not operating in\nar r/o /sys environment.\n\nThis changes IPA to run in a chroot instead of a container. This should\nbe the same from the perspective of IPA, but have no security rules\nlimiting what we can do inside the ramdisk.\n\nChange-Id: I6a572bdd791841add913d33c5b79b59033c3f237\nCloses-bug: 1524033\n'}, {'number': 2, 'created': '2015-12-08 18:25:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1390c257b8850a18c69e5e98ab89d6b97ca34bf7', 'message': 'Run IPA in chroot instead of container in CoreOS\n\nsystemd-nspawn has been adding more and more security features, the\nlatest being /sys and /proc/sys being completely read only. This breaks\nseveral things IPA needs to do from the container, including the sysrq\ntriggers used for reboot.\n\nAdditionally, any downstream hardware manager that wants to implement\nsoftware RAID requires this fix, as mdadm needs to write to /sys to\nassemble arrays. Linux-IO has a similar issue with not operating in\na read only /sys environment.\n\nThis changes IPA to run in a chroot instead of a container. This should\nbe the same from the perspective of IPA, but have no security rules\nlimiting what we can do inside the ramdisk.\n\nChange-Id: I6a572bdd791841add913d33c5b79b59033c3f237\nCloses-bug: 1524033'}, {'number': 3, 'created': '2015-12-08 18:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/45153f6378f5c335731273c68da1f590cca13e0b', 'message': 'Run IPA in chroot instead of container in CoreOS\n\nsystemd-nspawn has been adding more and more security features, the\nlatest being /sys and /proc/sys being completely read only. This breaks\nseveral things IPA needs to do from the container, including the sysrq\ntriggers used for reboot.\n\nAdditionally, any downstream hardware manager that wants to implement\nsoftware RAID requires this fix, as mdadm needs to write to /sys to\nassemble arrays. Linux-IO has a similar issue with not operating in\na read only /sys environment.\n\nThis changes IPA to run in a chroot instead of a container. This should\nbe the same from the perspective of IPA, but have no security rules\nlimiting what we can do inside the ramdisk.\n\nCo-Authored-By: Alex Weeks <alex.weeks@gmail.com>\nChange-Id: I6a572bdd791841add913d33c5b79b59033c3f237\nCloses-bug: 1524033'}, {'number': 4, 'created': '2015-12-09 17:17:45.000000000', 'files': ['imagebuild/coreos/oem/cloud-config.yml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/b5b0b63e32800b3745a5d0e66ce434fed09ad6b7', 'message': 'Run IPA in chroot instead of container in CoreOS\n\nsystemd-nspawn has been adding more and more security features, the\nlatest being /sys and /proc/sys being completely read only. This breaks\nseveral things IPA needs to do from the container, including the sysrq\ntriggers used for reboot.\n\nAdditionally, any downstream hardware manager that wants to implement\nsoftware RAID requires this fix, as mdadm needs to write to /sys to\nassemble arrays. Linux-IO has a similar issue with not operating in\na read only /sys environment.\n\nThis changes IPA to run in a chroot instead of a container. This should\nbe the same from the perspective of IPA, but have no security rules\nlimiting what we can do inside the ramdisk.\n\nCo-Authored-By: Alex Weeks <alex.weeks@gmail.com>\nChange-Id: I6a572bdd791841add913d33c5b79b59033c3f237\nCloses-bug: 1524033\n'}]",3,254896,b5b0b63e32800b3745a5d0e66ce434fed09ad6b7,26,7,4,10342,,,0,"Run IPA in chroot instead of container in CoreOS

systemd-nspawn has been adding more and more security features, the
latest being /sys and /proc/sys being completely read only. This breaks
several things IPA needs to do from the container, including the sysrq
triggers used for reboot.

Additionally, any downstream hardware manager that wants to implement
software RAID requires this fix, as mdadm needs to write to /sys to
assemble arrays. Linux-IO has a similar issue with not operating in
a read only /sys environment.

This changes IPA to run in a chroot instead of a container. This should
be the same from the perspective of IPA, but have no security rules
limiting what we can do inside the ramdisk.

Co-Authored-By: Alex Weeks <alex.weeks@gmail.com>
Change-Id: I6a572bdd791841add913d33c5b79b59033c3f237
Closes-bug: 1524033
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/96/254896/4 && git format-patch -1 --stdout FETCH_HEAD,['imagebuild/coreos/oem/cloud-config.yml'],1,96ae72aa24308ee202d00be1229fe38ce3048bc3,bug/1524033, - name: opt-ironic\x2dpython\x2dagent-proc.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/proc Where=/opt/ironic-python-agent/proc Type=none Options=bind - name: opt-ironic\x2dpython\x2dagent-dev.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/dev Where=/opt/ironic-python-agent/dev Type=none Options=bind - name: opt-ironic\x2dpython\x2dagent-dev-pts.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/dev/pts Where=/opt/ironic-python-agent/dev/pts Type=none Options=bind - name: opt-ironic\x2dpython\x2dagent-sys.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/sys Where=/opt/ironic-python-agent/sys Type=none Options=bind - name: opt-ironic\x2dpython\x2dagent-run.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/run Where=/opt/ironic-python-agent/run Type=none Options=bind - name: opt-ironic\x2dpython\x2dagent-mnt.mount command: start content: | [Unit] DefaultDependencies=no Conflicts=umount.target Before=umount.target [Mount] What=/usr/share/oem Where=/opt/ironic-python-agent/mnt Type=none Options=bind After=opt-ironic\x2dpython\x2dagent-proc.mount After=opt-ironic\x2dpython\x2dagent-dev.mount After=opt-ironic\x2dpython\x2dagent-dev-pts.mount After=opt-ironic\x2dpython\x2dagent-sys.mount After=opt-ironic\x2dpython\x2dagent-run.moun After=opt-ironic\x2dpython\x2dagent-mnt.mount Requires=opt-ironic\x2dpython\x2dagent-proc.mount Requires=opt-ironic\x2dpython\x2dagent-dev.mount Requires=opt-ironic\x2dpython\x2dagent-dev-pts.mount Requires=opt-ironic\x2dpython\x2dagent-sys.mount Requires=opt-ironic\x2dpython\x2dagent-run.moun Requires=opt-ironic\x2dpython\x2dagent-mnt.mount ExecStart=/usr/bin/chroot /opt/ironic-python-agent \ /usr/local/bin/ironic-python-agent, ExecStart=/usr/bin/systemd-nspawn -D /opt/ironic-python-agent \ --share-system \ --capability=all \ --machine=ironic_python_agent \ --bind=/dev:/dev \ --bind=/dev/pts:/dev/pts \ --bind=/proc:/proc \ --bind=/sys:/sys \ --bind=/usr/share/oem:/mnt \ --user=root \ --keep-unit \ /usr/local/bin/ironic-python-agent,99,12
openstack%2Fpuppet-keystone~master~If8b32695a05d1076dac851b16859a08b4a75e796,openstack/puppet-keystone,master,If8b32695a05d1076dac851b16859a08b4a75e796,comment: note how to unset version w. empty string,MERGED,2015-12-10 02:13:22.000000000,2015-12-11 17:35:57.000000000,2015-12-11 17:35:57.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 9500}]","[{'number': 1, 'created': '2015-12-10 02:13:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/59474dd50c2a404532b443bd17e1034d5dcf12ad', 'message': 'comment: note how to unset version w. empty string\n\nversion is deprecated and can be unset with an empty string, note this\nin the comments.\n\nChange-Id: If8b32695a05d1076dac851b16859a08b4a75e796\n'}, {'number': 2, 'created': '2015-12-11 15:47:07.000000000', 'files': ['manifests/endpoint.pp'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/61c71347eef8924fa0832e53d1d11bfc23469704', 'message': 'comment: note how to unset version w. empty string\n\nversion is deprecated and can be unset with an empty string, note this\nin the comments.\n\nChange-Id: If8b32695a05d1076dac851b16859a08b4a75e796\n'}]",0,255639,61c71347eef8924fa0832e53d1d11bfc23469704,17,4,2,9500,,,0,"comment: note how to unset version w. empty string

version is deprecated and can be unset with an empty string, note this
in the comments.

Change-Id: If8b32695a05d1076dac851b16859a08b4a75e796
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/39/255639/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/endpoint.pp'],1,59474dd50c2a404532b443bd17e1034d5dcf12ad,,"# from the context. If using hiera, setting version to an empty string, '', # will have the same affect.",# from the context.,2,1
openstack%2Freleases~master~I6910f98d060c9e1c57a3fd2d18565bbf0f86d786,openstack/releases,master,I6910f98d060c9e1c57a3fd2d18565bbf0f86d786,Oslo Middleware release to fix Kilo->Liberty Grenade issues,MERGED,2015-12-11 14:13:04.000000000,2015-12-11 17:29:41.000000000,2015-12-11 17:29:41.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 5638}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-12-11 14:13:04.000000000', 'files': ['deliverables/mitaka/oslo.middleware.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/d21a8566c014c6d4e4dba8df84ed46945f4571c3', 'message': 'Oslo Middleware release to fix Kilo->Liberty Grenade issues\n\nDetails are in the commit message for the following review:\nI04739bc3987786b4bc1fefc70fabaa69b3de52b4\n\nEssentially we are not allowed to break grenade job that\ngoes from kilo->liberty even for oslo.middleware work\nbeing done for Mitaka.\n\nChange-Id: I6910f98d060c9e1c57a3fd2d18565bbf0f86d786\n'}]",0,256424,d21a8566c014c6d4e4dba8df84ed46945f4571c3,8,4,1,5638,,,0,"Oslo Middleware release to fix Kilo->Liberty Grenade issues

Details are in the commit message for the following review:
I04739bc3987786b4bc1fefc70fabaa69b3de52b4

Essentially we are not allowed to break grenade job that
goes from kilo->liberty even for oslo.middleware work
being done for Mitaka.

Change-Id: I6910f98d060c9e1c57a3fd2d18565bbf0f86d786
",git fetch https://review.opendev.org/openstack/releases refs/changes/24/256424/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/mitaka/oslo.middleware.yaml'],1,d21a8566c014c6d4e4dba8df84ed46945f4571c3,, hash: 5c06fa6ea71cf9cd6526c1469dc6e12ab80a3fa1 - version: 3.2.0 projects: - repo: openstack/oslo.middleware hash: ce6ca042806dc09b33d30c56dac88e01d2ea24ec, hash: 5c06fa6ea71cf9cd6526c1469dc6e12ab80a3fa1,5,1
openstack%2Fopenstack-ansible~kilo~Ie19f1658d770cc421e23ebb59e658624cf668840,openstack/openstack-ansible,kilo,Ie19f1658d770cc421e23ebb59e658624cf668840,Keystone domain fix,MERGED,2015-10-22 13:55:50.000000000,2015-12-11 17:17:43.000000000,2015-12-11 17:17:41.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-10-22 13:55:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8441ee85049b7fd2c7ea8129ec8ee063082f7ffa', 'message': 'Pass domain to some calls in the keystone library\n\nThe API calls to list users and groups on Keystone API v3 require a\ndomain to be explicitly given.  Otherwise, the requests will not be\nauthorized.\n\nChange-Id: Ie19f1658d770cc421e23ebb59e658624cf668840\n'}, {'number': 3, 'created': '2015-12-10 18:13:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/66b9cc13339e36f7b239143a4b01bf2410f2160b', 'message': 'Pass domain to some calls in the keystone library\n\nThe API calls to list users and groups on Keystone API v3 require a\ndomain to be explicitly given.  Otherwise, the requests will not be\nauthorized.\n\nChange-Id: Ie19f1658d770cc421e23ebb59e658624cf668840\n'}, {'number': 4, 'created': '2015-12-10 18:15:06.000000000', 'files': ['playbooks/library/keystone'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/123f243b8ab90ca46fb388a50b9c6a71550cc360', 'message': 'Keystone domain fix\n\nThe keystone module is not able to function when using Keystone\nand the multi-domain backend. This issue is caused because the\ndomain argument is not passed into the client calls. to resolve\nthis issue the module has been updated to pass through the domain\nto the various client calls where needed\n\nCloses-Bug: #1518351\nCloses-Bug: #1519174\nChange-Id: Ie19f1658d770cc421e23ebb59e658624cf668840\nCo-Authored-By: Tiago Gomes <tiago.gomes@codethink.co.uk>\nCo-Authored-By: Ian Cordasco <graffatcolmingov@gmail.com>\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n(cherry picked from commit f490880abecd5d3e2acf2642024dab7a02c08975)\n'}]",0,238515,123f243b8ab90ca46fb388a50b9c6a71550cc360,17,4,3,18757,,,0,"Keystone domain fix

The keystone module is not able to function when using Keystone
and the multi-domain backend. This issue is caused because the
domain argument is not passed into the client calls. to resolve
this issue the module has been updated to pass through the domain
to the various client calls where needed

Closes-Bug: #1518351
Closes-Bug: #1519174
Change-Id: Ie19f1658d770cc421e23ebb59e658624cf668840
Co-Authored-By: Tiago Gomes <tiago.gomes@codethink.co.uk>
Co-Authored-By: Ian Cordasco <graffatcolmingov@gmail.com>
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
(cherry picked from commit f490880abecd5d3e2acf2642024dab7a02c08975)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/15/238515/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/library/keystone'],1,8441ee85049b7fd2c7ea8129ec8ee063082f7ffa,," - Name for a domain 'user_name', 'domain' def _get_user(self, name, domain=None): if domain: domain_id = domain.id else: domain_id = 'default' for entry in self.keystone.users.list(domain=domain_id): domain_name = variables_dict.pop('domain_name', 'Default') domain = self._get_domain(name=domain_name) user = self._get_user(name=user_name, domain=domain) domain_name = variables_dict.pop('domain_name', 'Default') user = self._get_user(name=user_name, domain=domain) if domain: domain_id = domain.id else: domain_id = 'default' for entry in self.keystone.groups.list(domain=domain_id): if entry.name == name: return entry"," - Name for a doamin 'user_name' def _get_user(self, name): for entry in self.keystone.users.list(): user = self._get_user(name=user_name) domain_name = variables_dict.pop('domain_name', None) or 'Default' user = self._get_user(name=user_name) for entry in self.keystone.groups.list(): if domain is None: if entry.name == name: return entry else: if entry.name == name and entry.domain_id == domain.id: return entry",22,15
openstack%2Fneutron-lbaas~master~Iab8835d745c0ffa6f6d459540ffa1deb17de5a05,openstack/neutron-lbaas,master,Iab8835d745c0ffa6f6d459540ffa1deb17de5a05,Avoid duplicating tenant check when creating resources,ABANDONED,2015-12-11 09:15:55.000000000,2015-12-11 17:17:01.000000000,,"[{'_account_id': 3}, {'_account_id': 9828}]","[{'number': 1, 'created': '2015-12-11 09:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/4544b9b24cb3bee8aba19aae97520fe7525b7173', 'message': 'Avoid duplicating tenant check when creating resources\n\nWhen the Neutron Controller processes a ""create"" request, it\nwill check that the tenant_id is valid and add it to the\nresource dict. Hence, the _get_tenant_id_for_create() can be removed,\nas proposed in :\n\nIcea06dc81344e1120bdf986a97a6b1094bbb765e\n\nChange-Id: Iab8835d745c0ffa6f6d459540ffa1deb17de5a05\nPartial-Bug: 1513825\n'}, {'number': 2, 'created': '2015-12-11 16:17:34.000000000', 'files': ['neutron_lbaas/tests/unit/db/loadbalancer/test_db_loadbalancer.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_db.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/cca3a46489207141168e31ef461fc61d769f4c58', 'message': 'Avoid duplicating tenant check when creating resources\n\nWhen the Neutron Controller processes a ""create"" request, it\nwill check that the tenant_id is valid and add it to the\nresource dict. Hence, the _get_tenant_id_for_create() can be removed,\nas proposed in :\n\nIcea06dc81344e1120bdf986a97a6b1094bbb765e\n\nChange-Id: Iab8835d745c0ffa6f6d459540ffa1deb17de5a05\nPartial-Bug: 1513825\n'}]",0,256298,cca3a46489207141168e31ef461fc61d769f4c58,6,2,2,2888,,,0,"Avoid duplicating tenant check when creating resources

When the Neutron Controller processes a ""create"" request, it
will check that the tenant_id is valid and add it to the
resource dict. Hence, the _get_tenant_id_for_create() can be removed,
as proposed in :

Icea06dc81344e1120bdf986a97a6b1094bbb765e

Change-Id: Iab8835d745c0ffa6f6d459540ffa1deb17de5a05
Partial-Bug: 1513825
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/98/256298/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/db/loadbalancer/loadbalancer_dbv2.py', 'neutron_lbaas/db/loadbalancer/loadbalancer_db.py']",2,4544b9b24cb3bee8aba19aae97520fe7525b7173,bug/1513825," tenant_id = v['tenant_id'] tenant_id=v['tenant_id'], tenant_id=v['tenant_id'], tenant_id=v['tenant_id'],"," tenant_id = self._get_tenant_id_for_create(context, v) tenant_id = self._get_tenant_id_for_create(context, v) tenant_id=tenant_id, tenant_id = self._get_tenant_id_for_create(context, v) tenant_id=tenant_id, tenant_id = self._get_tenant_id_for_create(context, v) tenant_id=tenant_id,",10,15
openstack%2Ffuel-web~master~I99f214123fa94e539279c464076c5422ccc6f8bb,openstack/fuel-web,master,I99f214123fa94e539279c464076c5422ccc6f8bb,Fixed mock is not stopped in test_role_resolver,MERGED,2015-12-11 15:24:51.000000000,2015-12-11 17:15:07.000000000,2015-12-11 16:57:54.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8766}, {'_account_id': 8776}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 13505}, {'_account_id': 19158}, {'_account_id': 19196}]","[{'number': 1, 'created': '2015-12-11 15:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/baa2238978c43a6195791e454cce8c5af8c0aa9a', 'message': 'Fixed mock is not stopped in test_role_resolver\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I99f214123fa94e539279c464076c5422ccc6f8bb\n'}, {'number': 2, 'created': '2015-12-11 15:58:48.000000000', 'files': ['nailgun/nailgun/test/unit/test_role_resolver.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a4d86a9147536bfb3e1cb53ed3166bf3c5c86077', 'message': 'Fixed mock is not stopped in test_role_resolver\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I99f214123fa94e539279c464076c5422ccc6f8bb\n'}]",0,256513,a4d86a9147536bfb3e1cb53ed3166bf3c5c86077,26,12,2,18205,,,0,"Fixed mock is not stopped in test_role_resolver

implements blueprint: task-based-deployment-astute

Change-Id: I99f214123fa94e539279c464076c5422ccc6f8bb
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/13/256513/2 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/test/unit/test_role_resolver.py'],1,baa2238978c43a6195791e454cce8c5af8c0aa9a,bp/task-based-deployment-astute, objs_mock = mock.patch('nailgun.utils.role_resolver.objects') objs_mock.start() objs_mock.Node.all_roles.side_effect = self.roles_of_nodes, objs_mock = mock.patch('nailgun.utils.role_resolver.objects').start() objs_mock.Node.all_roles.side_effect = self.roles_of_nodes,3,2
openstack%2Foslo.service~master~Ifdb86a5c429890ed3f0a05e00cb577e97c5b3a67,openstack/oslo.service,master,Ifdb86a5c429890ed3f0a05e00cb577e97c5b3a67,Trival: Remove 'MANIFEST.in',MERGED,2015-12-05 05:32:26.000000000,2015-12-11 17:12:43.000000000,2015-12-11 17:12:42.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2874}, {'_account_id': 7293}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-05 05:32:26.000000000', 'files': ['MANIFEST.in'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/cc0a18dc6215cc66fe7cf87404d8e1300ab09001', 'message': ""Trival: Remove 'MANIFEST.in'\n\nEverything in this file is automatically generated by pbr. There\nappears to be no good reason to keep it around.\nMore details please see:\nhttps://github.com/openstack-dev/pbr/blob/master/pbr/packaging.py#L384\n\nChange-Id: Ifdb86a5c429890ed3f0a05e00cb577e97c5b3a67\n""}]",0,253786,cc0a18dc6215cc66fe7cf87404d8e1300ab09001,14,5,1,9796,,,0,"Trival: Remove 'MANIFEST.in'

Everything in this file is automatically generated by pbr. There
appears to be no good reason to keep it around.
More details please see:
https://github.com/openstack-dev/pbr/blob/master/pbr/packaging.py#L384

Change-Id: Ifdb86a5c429890ed3f0a05e00cb577e97c5b3a67
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/86/253786/1 && git format-patch -1 --stdout FETCH_HEAD,['MANIFEST.in'],1,cc0a18dc6215cc66fe7cf87404d8e1300ab09001,rm_man,,include AUTHORS include ChangeLog exclude .gitignore exclude .gitreview global-exclude *.pyc ,0,6
openstack%2Fnetworking-ovn~master~I782de8d7ac7fbf5f6aa10eaf6808099237a1350c,openstack/networking-ovn,master,I782de8d7ac7fbf5f6aa10eaf6808099237a1350c,devstack plugin: avoid explicit OVS module dependency,MERGED,2015-12-10 02:48:03.000000000,2015-12-11 17:01:37.000000000,2015-12-11 17:01:35.000000000,"[{'_account_id': 3}, {'_account_id': 1561}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 11343}, {'_account_id': 11762}]","[{'number': 1, 'created': '2015-12-10 02:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/89a5989dc56d09d940a52aff5cb9c8ee9e20df74', 'message': 'devstack plugin: avoid explicit OVS module dependency\n\nThis is a follow up patch for [1], to avoid managing the OVS kernel\nmodule dependencies explicitly in devstack plugin.\n\n[1] https://review.openstack.org/#/c/255358/\n\nChange-Id: I782de8d7ac7fbf5f6aa10eaf6808099237a1350c\n'}, {'number': 2, 'created': '2015-12-10 23:25:02.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/79218c8fc32397b317b094e059fcc3e4a52a60ef', 'message': 'devstack plugin: avoid explicit OVS module dependency\n\nThis is a follow up patch for [1], to avoid managing the OVS kernel\nmodule dependencies explicitly in devstack plugin.\n\n[1] https://review.openstack.org/#/c/255358/\n\nChange-Id: I782de8d7ac7fbf5f6aa10eaf6808099237a1350c\n'}]",2,255648,79218c8fc32397b317b094e059fcc3e4a52a60ef,15,6,2,11762,,,0,"devstack plugin: avoid explicit OVS module dependency

This is a follow up patch for [1], to avoid managing the OVS kernel
module dependencies explicitly in devstack plugin.

[1] https://review.openstack.org/#/c/255358/

Change-Id: I782de8d7ac7fbf5f6aa10eaf6808099237a1350c
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/48/255648/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,89a5989dc56d09d940a52aff5cb9c8ee9e20df74,remove-module-dependency," # Be super explicit that we want our custom modules loaded ... sudo cp -f datapath/linux/*.ko /lib/modules/`uname -r`/kernel/net/openvswitch/ sudo modprobe openvswitch || (dmesg && die $LINENO ""FAILED TO LOAD openvswitch"") sudo modprobe vport-geneve || (echo ""FAILED TO LOAD vport_geneve"" && dmesg)"," sudo modprobe libcrc32c sudo modprobe nf_defrag_ipv6 sudo modprobe ip_tunnel sudo modprobe gre # Be super explicit that we want our custom modules loaded ... sudo insmod datapath/linux/openvswitch.ko || (dmesg && die $LINENO ""FAILED TO LOAD openvswitch"") sudo insmod datapath/linux/vport-geneve.ko || (echo ""FAILED TO LOAD vport_geneve"" && dmesg)",4,7
openstack%2Fastara~master~I81f31ae028d32edbe5c4f8c292438c8e427173d9,openstack/astara,master,I81f31ae028d32edbe5c4f8c292438c8e427173d9,Updated from global requirements,MERGED,2015-12-11 15:17:45.000000000,2015-12-11 17:01:06.000000000,2015-12-11 17:01:03.000000000,"[{'_account_id': 3}, {'_account_id': 2592}]","[{'number': 1, 'created': '2015-12-11 15:17:45.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/astara/commit/afab50fe255b15dbca1b4de619fc9badf26de63e', 'message': 'Updated from global requirements\n\nChange-Id: I81f31ae028d32edbe5c4f8c292438c8e427173d9\n'}]",0,256471,afab50fe255b15dbca1b4de619fc9badf26de63e,6,2,1,11131,,,0,"Updated from global requirements

Change-Id: I81f31ae028d32edbe5c4f8c292438c8e427173d9
",git fetch https://review.opendev.org/openstack/astara refs/changes/71/256471/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,afab50fe255b15dbca1b4de619fc9badf26de63e,openstack/requirements,"oslo.utils!=3.1.0,>=2.8.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,1,1
openstack%2Ffuel-main~master~I096ce8a1e76a6f65568b2180471b6cc43f06cdc8,openstack/fuel-main,master,I096ce8a1e76a6f65568b2180471b6cc43f06cdc8,Keep CentOS7 original repos,ABANDONED,2015-12-10 13:10:03.000000000,2015-12-11 16:56:44.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-12-10 13:10:03.000000000', 'files': ['iso/ks.template'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/d4684fdbaf6a75b11abc9c33a8e7cf0fc54c06ba', 'message': 'Keep CentOS7 original repos\n\nChange-Id: I096ce8a1e76a6f65568b2180471b6cc43f06cdc8\nCloses-Bug: #1524825\n'}]",0,255864,d4684fdbaf6a75b11abc9c33a8e7cf0fc54c06ba,5,5,1,7562,,,0,"Keep CentOS7 original repos

Change-Id: I096ce8a1e76a6f65568b2180471b6cc43f06cdc8
Closes-Bug: #1524825
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/64/255864/1 && git format-patch -1 --stdout FETCH_HEAD,['iso/ks.template'],1,d4684fdbaf6a75b11abc9c33a8e7cf0fc54c06ba,,,rm /etc/yum.repos.d/CentOS*.repo,0,1
openstack%2Ffuel-specs~master~I670fd7c1a635f0f203fced0e3878d3ba45b80950,openstack/fuel-specs,master,I670fd7c1a635f0f203fced0e3878d3ba45b80950,Fix to pass gate-fuel-specs-python27 gate,MERGED,2015-12-11 10:11:37.000000000,2015-12-11 16:50:19.000000000,2015-12-11 16:50:19.000000000,"[{'_account_id': 3}, {'_account_id': 7562}, {'_account_id': 7613}, {'_account_id': 8789}]","[{'number': 1, 'created': '2015-12-11 10:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/aee7cf5572d76c0ffe253d45334f8a1b4b26e092', 'message': 'Fix to pass gate-fuel-specs-python27 gate\n\nWrap lines to fit in 79 character limit to pass gate-fuel-specs-python27\n\nChange-Id: I670fd7c1a635f0f203fced0e3878d3ba45b80950\nCloses-Bug: #1524702\n'}, {'number': 2, 'created': '2015-12-11 10:51:35.000000000', 'files': ['specs/8.0/component-registry.rst', 'specs/8.0/multi-rack-static.rst', 'specs/8.0/deb-packages-naming-policy.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/ae6f1bfb09ed5d9aaf759e635b0546dea49b28b4', 'message': 'Fix to pass gate-fuel-specs-python27 gate\n\nWrap lines to fit in 79 character limit in:\n- specs/8.0/component-registry.rst\n- specs/8.0/deb-packages-naming-policy.rst\n- specs/8.0/multi-rack-static.rst\nFix titles nesting in:\n- specs/8.0/deb-packages-naming-policy.rst\n\nChange-Id: I670fd7c1a635f0f203fced0e3878d3ba45b80950\nCloses-Bug: #1524702\n'}]",0,256318,ae6f1bfb09ed5d9aaf759e635b0546dea49b28b4,11,4,2,13505,,,0,"Fix to pass gate-fuel-specs-python27 gate

Wrap lines to fit in 79 character limit in:
- specs/8.0/component-registry.rst
- specs/8.0/deb-packages-naming-policy.rst
- specs/8.0/multi-rack-static.rst
Fix titles nesting in:
- specs/8.0/deb-packages-naming-policy.rst

Change-Id: I670fd7c1a635f0f203fced0e3878d3ba45b80950
Closes-Bug: #1524702
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/18/256318/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/8.0/component-registry.rst'],1,aee7cf5572d76c0ffe253d45334f8a1b4b26e092,bug/1524702,Every type can have a compatible list or whitelist. It will be used to highlight definitely compatible components with 'green light' if all elements from compatible list are enabled... [0] https://blueprints.launchpad.net/fuel/+spec/store-plugins-attributes ,Every type can have a compatible list or whitelist. It will be used to highlight definitely compatible components with 'green light' if all elements from compatible list are enabled... [0] https://blueprints.launchpad.net/fuel/+spec/store-plugins-attributes,4,4
openstack%2Fneutron~master~I94a21ffbb82446499b1a55bd8b666d7395e4908a,openstack/neutron,master,I94a21ffbb82446499b1a55bd8b666d7395e4908a,Correct cisco_ml2_apic_contracts.router_id length,MERGED,2015-06-17 11:25:33.000000000,2015-12-11 16:49:50.000000000,2015-10-02 18:30:28.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 5170}, {'_account_id': 6524}, {'_account_id': 7249}, {'_account_id': 7448}, {'_account_id': 7715}, {'_account_id': 8124}, {'_account_id': 9008}, {'_account_id': 9681}, {'_account_id': 9682}, {'_account_id': 9787}, {'_account_id': 9845}, {'_account_id': 10121}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 10386}, {'_account_id': 10692}, {'_account_id': 13671}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 14605}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 15894}]","[{'number': 1, 'created': '2015-06-17 11:25:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a5a4e0ab1d6d0ef2cf82cc006e803f422cd0b77b', 'message': 'Correct cisco_ml2_apic_contracts.router_id length\n\nSome database engines require exact match of sizes of foreign keys\nand referenced fields. Foreign key router_id of table\ncisco_ml2_apic_contracts is varchar(64) but it references field\nid varchar(36) of table routers. This gives error while running\nmigration scripts in such databases.\n\nThis change only applies to new OpenStack installations\n\nChange-Id: I94a21ffbb82446499b1a55bd8b666d7395e4908a\nRelated-Bug: #1463806\nCloses-Bug: #1465678\n'}, {'number': 2, 'created': '2015-06-18 14:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/cc614652aaf2c22d93bc6803beaf25faa99d9c91', 'message': 'Correct cisco_ml2_apic_contracts.router_id length\n\nSome database engines require exact match of sizes of foreign keys\nand referenced fields. Foreign key router_id of table\ncisco_ml2_apic_contracts is varchar(64) but it references field\nid varchar(36) of table routers. This gives error while running\nmigration scripts in such databases.\n\nThis change only applies to new OpenStack installations\n\nChange-Id: I94a21ffbb82446499b1a55bd8b666d7395e4908a\nRelated-Bug: #1463806\nCloses-Bug: #1465678\n'}, {'number': 3, 'created': '2015-10-01 01:14:42.000000000', 'files': ['neutron/db/migration/alembic_migrations/cisco_init_ops.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ee1477ac1a8ef90413a0cb2acf90cd1b2889882b', 'message': 'Correct cisco_ml2_apic_contracts.router_id length\n\nSome database engines require exact match of sizes of foreign keys\nand referenced fields. Foreign key router_id of table\ncisco_ml2_apic_contracts is varchar(64) but it references field\nid varchar(36) of table routers. This gives error while running\nmigration scripts in such databases.\n\nThis change only applies to new OpenStack installations\n\nChange-Id: I94a21ffbb82446499b1a55bd8b666d7395e4908a\nRelated-Bug: #1463806\nCloses-Bug: #1465678\n'}]",0,192615,ee1477ac1a8ef90413a0cb2acf90cd1b2889882b,79,29,3,13671,,,0,"Correct cisco_ml2_apic_contracts.router_id length

Some database engines require exact match of sizes of foreign keys
and referenced fields. Foreign key router_id of table
cisco_ml2_apic_contracts is varchar(64) but it references field
id varchar(36) of table routers. This gives error while running
migration scripts in such databases.

This change only applies to new OpenStack installations

Change-Id: I94a21ffbb82446499b1a55bd8b666d7395e4908a
Related-Bug: #1463806
Closes-Bug: #1465678
",git fetch https://review.opendev.org/openstack/neutron refs/changes/15/192615/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/db/migration/alembic_migrations/cisco_init_ops.py'],1,a5a4e0ab1d6d0ef2cf82cc006e803f422cd0b77b,bug/1465678," sa.Column('router_id', sa.String(length=36), nullable=False),"," sa.Column('router_id', sa.String(length=64), nullable=False),",1,1
openstack%2Fmistral~master~I37c7dadfc128231bd0f0cd5e323de10a7400c6df,openstack/mistral,master,I37c7dadfc128231bd0f0cd5e323de10a7400c6df,Numerous debug messages due to iso8601 log level,MERGED,2015-12-08 20:53:14.000000000,2015-12-11 16:40:18.000000000,2015-12-11 16:40:16.000000000,"[{'_account_id': 3}, {'_account_id': 5558}, {'_account_id': 6732}, {'_account_id': 8592}, {'_account_id': 8731}, {'_account_id': 15881}, {'_account_id': 18238}]","[{'number': 1, 'created': '2015-12-08 20:53:14.000000000', 'files': ['mistral/config.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/908a980af328dabdc62249e4beefacb8e058b3c6', 'message': 'Numerous debug messages due to iso8601 log level\n\niso8601 is indirectly used by keystone client and removing\nthe log level iso8601=WARN results in numerous debug messages.\nThis patch reverts iso8601=WARN log level removal introduced\nin 91f35ae9fb8d4efc042baa3028f7c7369219d280 commit.\n\nChange-Id: I37c7dadfc128231bd0f0cd5e323de10a7400c6df\n'}]",0,254952,908a980af328dabdc62249e4beefacb8e058b3c6,15,7,1,8157,,,0,"Numerous debug messages due to iso8601 log level

iso8601 is indirectly used by keystone client and removing
the log level iso8601=WARN results in numerous debug messages.
This patch reverts iso8601=WARN log level removal introduced
in 91f35ae9fb8d4efc042baa3028f7c7369219d280 commit.

Change-Id: I37c7dadfc128231bd0f0cd5e323de10a7400c6df
",git fetch https://review.opendev.org/openstack/mistral refs/changes/52/254952/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/config.py'],1,908a980af328dabdc62249e4beefacb8e058b3c6,," 'iso8601=WARN',",,1,0
openstack%2Fshade~master~I653ed4c4fcbab6f36bf03cc68ffe862b6bfcd6eb,openstack/shade,master,I653ed4c4fcbab6f36bf03cc68ffe862b6bfcd6eb,Bug fix: Fix pass thru filtering in list_networks,MERGED,2015-12-08 17:38:10.000000000,2015-12-11 16:34:29.000000000,2015-12-11 16:34:28.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 6488}]","[{'number': 1, 'created': '2015-12-08 17:38:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/f021688662855db59ee1e4351d7f0c0705ffbb5e', 'message': 'Bug fix: Fix pass thru filtering in list_networks\n\nThe filters for list_networks() was not being passed through\nto the neutron client. Actually pass the arguments and add missing\nunit and functional tests to verify the behavior.\n\nChange-Id: I653ed4c4fcbab6f36bf03cc68ffe862b6bfcd6eb\n'}, {'number': 2, 'created': '2015-12-08 20:28:01.000000000', 'files': ['shade/tests/unit/test_shade.py', 'releasenotes/notes/fix-list-networks-a592725df64c306e.yaml', 'shade/_tasks.py', 'shade/tests/functional/test_network.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/d7e616780b3768d8674875f0e40e09dc91b62951', 'message': 'Bug fix: Fix pass thru filtering in list_networks\n\nThe filters for list_networks() was not being passed through\nto the neutron client. Actually pass the arguments and add missing\nunit and functional tests to verify the behavior.\n\nChange-Id: I653ed4c4fcbab6f36bf03cc68ffe862b6bfcd6eb\n'}]",0,254884,d7e616780b3768d8674875f0e40e09dc91b62951,10,3,2,3099,,,0,"Bug fix: Fix pass thru filtering in list_networks

The filters for list_networks() was not being passed through
to the neutron client. Actually pass the arguments and add missing
unit and functional tests to verify the behavior.

Change-Id: I653ed4c4fcbab6f36bf03cc68ffe862b6bfcd6eb
",git fetch https://review.opendev.org/openstack/shade refs/changes/84/254884/1 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_shade.py', 'releasenotes/notes/fix-list-networks-a592725df64c306e.yaml', 'shade/_tasks.py', 'shade/tests/functional/test_network.py']",4,f021688662855db59ee1e4351d7f0c0705ffbb5e,254884," self.network_name = self.getUniqueString('network') if network['name'].startswith(self.network_name): net1 = self.cloud.create_network(name=self.network_name) self.assertEqual(self.network_name, net1['name']) name=self.network_name, self.assertEqual(self.network_name, net1['name']) def test_list_networks_filtered(self): net1 = self.cloud.create_network(name=self.network_name) self.assertIsNotNone(net1) net2 = self.cloud.create_network(name=self.network_name + 'other') self.assertIsNotNone(net2) match = self.cloud.list_networks(filters=dict(name=self.network_name)) self.assertEqual(1, len(match)) self.assertEqual(net1, match[0])","import random import string self.network_prefix = 'test_network' + ''.join( random.choice(string.ascii_lowercase) for _ in range(5)) if network['name'].startswith(self.network_prefix): net1_name = self.network_prefix + '_net1' net1 = self.cloud.create_network(name=net1_name) self.assertEqual(net1_name, net1['name']) net1_name = self.network_prefix + '_net1' name=net1_name, self.assertEqual(net1_name, net1['name'])",44,13
openstack%2Fshade~master~I0fa9f9b0190cbd31d4c9b0cc6422c2f876510f77,openstack/shade,master,I0fa9f9b0190cbd31d4c9b0cc6422c2f876510f77,Improve test coverage: volume attach/detach API,MERGED,2015-12-09 21:29:53.000000000,2015-12-11 16:34:27.000000000,2015-12-11 16:34:26.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2015-12-09 21:29:53.000000000', 'files': ['shade/tests/unit/test_volume.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/47d2472df849d16c6e6c998e4f7dbee35a99ab76', 'message': 'Improve test coverage: volume attach/detach API\n\nAdd missing tests for attaching and detaching volumes to and from\nservers.\n\nChange-Id: I0fa9f9b0190cbd31d4c9b0cc6422c2f876510f77\n'}]",0,255534,47d2472df849d16c6e6c998e4f7dbee35a99ab76,6,2,1,3099,,,0,"Improve test coverage: volume attach/detach API

Add missing tests for attaching and detaching volumes to and from
servers.

Change-Id: I0fa9f9b0190cbd31d4c9b0cc6422c2f876510f77
",git fetch https://review.opendev.org/openstack/shade refs/changes/34/255534/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_volume.py'],1,47d2472df849d16c6e6c998e4f7dbee35a99ab76,coverage,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import testtools import shade from shade.tests.unit import base class TestVolume(base.TestCase): def setUp(self): super(TestVolume, self).setUp() self.cloud = shade.openstack_cloud(validate=False) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', status='available', attachments=[]) rvol = dict(id='volume001', status='attached', attachments=[ {'server_id': server['id'], 'device': 'device001'} ]) mock_nova.volumes.create_server_volume.return_value = rvol ret = self.cloud.attach_volume(server, volume, wait=False) self.assertEqual(rvol, ret) mock_nova.volumes.create_server_volume.assert_called_once_with( volume_id=volume['id'], server_id=server['id'], device=None ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume_exception(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', status='available', attachments=[]) mock_nova.volumes.create_server_volume.side_effect = Exception() with testtools.ExpectedException( shade.OpenStackCloudException, ""Error attaching volume %s to server %s"" % ( volume['id'], server['id']) ): self.cloud.attach_volume(server, volume, wait=False) @mock.patch.object(shade.OpenStackCloud, 'get_volume') @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume_wait(self, mock_nova, mock_get): server = dict(id='server001') volume = dict(id='volume001', status='available', attachments=[]) attached_volume = dict( id=volume['id'], status='attached', attachments=[{'server_id': server['id'], 'device': 'device001'}] ) mock_get.side_effect = iter([volume, attached_volume]) # defaults to wait=True ret = self.cloud.attach_volume(server, volume) mock_nova.volumes.create_server_volume.assert_called_once_with( volume_id=volume['id'], server_id=server['id'], device=None ) self.assertEqual(2, mock_get.call_count) self.assertEqual(attached_volume, ret) @mock.patch.object(shade.OpenStackCloud, 'get_volume') @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume_wait_error(self, mock_nova, mock_get): server = dict(id='server001') volume = dict(id='volume001', status='available', attachments=[]) errored_volume = dict(id=volume['id'], status='error', attachments=[]) mock_get.side_effect = iter([volume, errored_volume]) with testtools.ExpectedException( shade.OpenStackCloudException, ""Error in attaching volume %s"" % errored_volume['id'] ): self.cloud.attach_volume(server, volume) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume_not_available(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', status='error', attachments=[]) with testtools.ExpectedException( shade.OpenStackCloudException, ""Volume %s is not available. Status is '%s'"" % ( volume['id'], volume['status']) ): self.cloud.attach_volume(server, volume) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_attach_volume_already_attached(self, mock_nova): device_id = 'device001' server = dict(id='server001') volume = dict(id='volume001', attachments=[ {'server_id': 'server001', 'device': device_id} ]) with testtools.ExpectedException( shade.OpenStackCloudException, ""Volume %s already attached to server %s on device %s"" % ( volume['id'], server['id'], device_id) ): self.cloud.attach_volume(server, volume) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_detach_volume(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', attachments=[ {'server_id': 'server001', 'device': 'device001'} ]) self.cloud.detach_volume(server, volume, wait=False) mock_nova.volumes.delete_server_volume.assert_called_once_with( attachment_id=volume['id'], server_id=server['id'] ) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_detach_volume_exception(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', attachments=[ {'server_id': 'server001', 'device': 'device001'} ]) mock_nova.volumes.delete_server_volume.side_effect = Exception() with testtools.ExpectedException( shade.OpenStackCloudException, ""Error detaching volume %s from server %s"" % ( volume['id'], server['id']) ): self.cloud.detach_volume(server, volume, wait=False) @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_detach_volume_not_attached(self, mock_nova): server = dict(id='server001') volume = dict(id='volume001', attachments=[ {'server_id': 'server999', 'device': 'device001'} ]) with testtools.ExpectedException( shade.OpenStackCloudException, ""Volume %s is not attached to server %s"" % ( volume['id'], server['id']) ): self.cloud.detach_volume(server, volume, wait=False) @mock.patch.object(shade.OpenStackCloud, 'get_volume') @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_detach_volume_wait(self, mock_nova, mock_get): server = dict(id='server001') volume = dict(id='volume001', status='attached', attachments=[ {'server_id': 'server001', 'device': 'device001'} ]) avail_volume = dict(id=volume['id'], status='available', attachments=[]) mock_get.side_effect = iter([volume, avail_volume]) self.cloud.detach_volume(server, volume) mock_nova.volumes.delete_server_volume.assert_called_once_with( attachment_id=volume['id'], server_id=server['id'] ) self.assertEqual(2, mock_get.call_count) @mock.patch.object(shade.OpenStackCloud, 'get_volume') @mock.patch.object(shade.OpenStackCloud, 'nova_client') def test_detach_volume_wait_error(self, mock_nova, mock_get): server = dict(id='server001') volume = dict(id='volume001', status='attached', attachments=[ {'server_id': 'server001', 'device': 'device001'} ]) errored_volume = dict(id=volume['id'], status='error', attachments=[]) mock_get.side_effect = iter([volume, errored_volume]) with testtools.ExpectedException( shade.OpenStackCloudException, ""Error in detaching volume %s"" % errored_volume['id'] ): self.cloud.detach_volume(server, volume) ",,194,0
openstack-attic%2Fakanda~master~I69753f2dca70d700f78234be726c08f890b132df,openstack-attic/akanda,master,I69753f2dca70d700f78234be726c08f890b132df,installation documentation update,ABANDONED,2015-09-17 21:33:45.000000000,2015-12-11 16:32:17.000000000,,"[{'_account_id': 3}, {'_account_id': 1420}, {'_account_id': 2592}, {'_account_id': 6287}, {'_account_id': 6923}, {'_account_id': 8005}]","[{'number': 1, 'created': '2015-09-17 21:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/2fff5bbc6c14a6466d64590c3078541871762d78', 'message': 'installation documentation update\n\nputting the single and multi-node devstack install\ninstructions in the same place\n\nPartially Implements: blueprint liberty-doc-updates\n\nChange-Id: I69753f2dca70d700f78234be726c08f890b132df\n'}, {'number': 2, 'created': '2015-09-17 21:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/353f0d85dc0b5f4fd5e1f4bca0fb3921ab69a8fc', 'message': 'installation documentation update [WIP]\n\nputting the single and multi-node devstack install\ninstructions in the same place\n\nPartially Implements: blueprint liberty-doc-updates\n\nChange-Id: I69753f2dca70d700f78234be726c08f890b132df\n'}, {'number': 3, 'created': '2015-09-25 23:42:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/63c99cdbddc3e2cc9b683a6e0d13217a2562a578', 'message': 'installation documentation update [WIP]\n\nputting the single and multi-node devstack install\ninstructions in the same place\n\nPartially Implements: blueprint liberty-doc-updates\n\nChange-Id: I69753f2dca70d700f78234be726c08f890b132df\n'}, {'number': 4, 'created': '2015-09-25 23:42:57.000000000', 'files': ['docs/source/index.rst', 'docs/source/installing_akanda.rst', 'docs/source/developer_quickstart.rst'], 'web_link': 'https://opendev.org/openstack-attic/akanda/commit/9fa91c7c533be8b431acfce77e8f9f40cb3a1965', 'message': 'installation documentation update\n\nputting the single and multi-node devstack install\ninstructions in the same place\n\nPartially Implements: blueprint liberty-doc-updates\n\nChange-Id: I69753f2dca70d700f78234be726c08f890b132df\n'}]",0,224909,9fa91c7c533be8b431acfce77e8f9f40cb3a1965,12,6,4,6923,,,0,"installation documentation update

putting the single and multi-node devstack install
instructions in the same place

Partially Implements: blueprint liberty-doc-updates

Change-Id: I69753f2dca70d700f78234be726c08f890b132df
",git fetch https://review.opendev.org/openstack-attic/akanda refs/changes/09/224909/4 && git format-patch -1 --stdout FETCH_HEAD,"['docs/source/index.rst', 'docs/source/installing_akanda.rst', 'docs/source/developer_quickstart.rst']",3,2fff5bbc6c14a6466d64590c3078541871762d78,bp/liberty-doc-updates,,".. _developer_quickstart: Akanda Developer Quickstart ===================================== This guide provides guidance for new developers looking to get up and running with an Akanda development environment. The Akanda components may be easily deployed alongside OpenStack using DevStack. For more information about DevStack visit ``http://docs.openstack.org/developer/devstack/``. .. _developer_quickstart_rest: Deploying Akanda using DevStack ------------------------------- Preparation and prerequisites +++++++++++++++++++++++++++++ Deploying DevStack on your local workstation is not recommended. Instead, developers should use a dedicated virtual machine. Currently, Ubuntu Trusty 14.04 is the tested and supported base operating system. Additionally, you'll need at least 4GB of RAM and to have ``git`` installed:: sudo apt-get -y install git First clone the DevStack repository:: sudo mkdir -p /opt/stack/ sudo chown `whoami` /opt/stack git clone https://git.openstack.org/openstack-dev/devstack /opt/stack/devstack Configuring DevStack ++++++++++++++++++++ Next, you will need to enable the Akanda plugin in the DevStack configuration and enable the relevant services:: cat >/opt/stack/devstack/local.conf <<END [[local|localrc]] enable_plugin akanda-rug https://github.com/stackforge/akanda-rug enable_service q-svc q-agt ak-rug disable_service n-net HOST_IP=127.0.0.1 LOGFILE=/opt/stack/devstack/devstack.log DATABASE_PASSWORD=secret RABBIT_PASSWORD=secret SERVICE_TOKEN=secret SERVICE_PASSWORD=secret ADMIN_PASSWORD=secret END You may wish to SSH into the appliance VMs for debugging purposes. The RUG will enable access for the 'akanda' user for a specified public key. This may be specified by setting AKANDA_APPLIANCE_SSH_PUBLIC_KEY variable in your devstack config to point to an existing public key. The default is $HOME/.ssh/id_rsa.pub. Building a Custom Service VM ++++++++++++++++++++++++++++ By default, the Akanda plugin downloads a pre-built official Akanda image. To build your own from source, enable ``BUILD_AKANDA_APPLIANCE_IMAGE`` and specify a repository and branch to build from:: cat >>/opt/stack/devstack/local.conf <<END BUILD_AKANDA_APPLIANCE_IMAGE=True AKANDA_APPLIANCE_REPO=http://github.com/stackforge/akanda-appliance.git AKANDA_APPLIANCE_BRANCH=master END To build the appliance using locally modified ``akanda-appliance`` code, you may point devstack at the local git checkout by setting the AKANDA_APPLIANCE_DIR variable. Ensure that any changes you want included in the image build have been committed to the repository and it is checked out to the proper commit. Deploying +++++++++ Simply run DevStack and allow time for the deployment to complete:: cd /opt/stack/devstack ./stack.sh After it has completed, you should have a ``akanda-rug`` process running alongside the other services and an Akanda router appliance booted as a Nova instance. ",123,93
openstack%2Ffuel-web~master~I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f,openstack/fuel-web,master,I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f,Always show buttons in Fuel UI,MERGED,2015-12-10 15:00:54.000000000,2015-12-11 16:32:04.000000000,2015-12-11 16:15:22.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-10 15:00:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/384644a68a5d62580ec3342a2fd959dc4286d160', 'message': 'Always show buttons in Fuel UI\n\nButtons affected:\n  Reset Environment\n  Deploy Changes\n  Stop (Deployment)\n\nCloses-Bug: #1522844\n\nChange-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f\n'}, {'number': 2, 'created': '2015-12-10 15:12:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f05c0a37d51fbcfd5b2bed6d172f9314f5db3778', 'message': 'Always show buttons in Fuel UI\n\nButtons affected:\n  Reset Environment\n  Deploy Changes\n  Stop (Deployment)\n\nCloses-Bug: #1522844\n\nChange-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f\n'}, {'number': 3, 'created': '2015-12-11 08:13:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/a96afef03321bcb2709c35c0c8b197eecec501d5', 'message': 'Always show buttons in Fuel UI\n\nButtons affected:\n  Reset Environment\n  Deploy Changes\n  Stop (Deployment)\n\nCloses-Bug: #1522844\n\nChange-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f\n'}, {'number': 4, 'created': '2015-12-11 10:02:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f301c4e5cf85fc2af276c0b629b7c470a39ec5be', 'message': 'Always show buttons in Fuel UI\n\nButtons affected:\n  Reset Environment\n  Deploy Changes\n  Stop (Deployment)\n\nCloses-Bug: #1522844\n\nChange-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f\n'}, {'number': 5, 'created': '2015-12-11 14:58:25.000000000', 'files': ['nailgun/static/tests/functional/test_cluster_dashboard.js', 'nailgun/static/tests/functional/test_cluster_deployment.js', 'nailgun/static/views/cluster_page_tabs/dashboard_tab.js', 'nailgun/static/translations/core.json'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ac21cd8dfa96f28271480730f385bd66ec168761', 'message': 'Always show buttons in Fuel UI\n\nButtons affected:\n  Reset Environment\n  Deploy Changes\n  Stop (Deployment)\n\nCloses-Bug: #1522844\n\nChange-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f\n'}]",2,255922,ac21cd8dfa96f28271480730f385bd66ec168761,45,4,5,8766,,,0,"Always show buttons in Fuel UI

Buttons affected:
  Reset Environment
  Deploy Changes
  Stop (Deployment)

Closes-Bug: #1522844

Change-Id: I7dd07d8ea3f5297ce614c88f72cc295b8d9cb83f
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/22/255922/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/views/cluster_page_tabs/dashboard_tab.js', 'nailgun/static/translations/core.json', 'nailgun/static/models.js']",3,384644a68a5d62580ec3342a2fd959dc4286d160,bug/1522844, return this.match('deploy');," return this.match({name: 'deploy', status: 'running'});",22,22
openstack%2Fpuppet-murano~master~Ia34fef731f7dfe9609b65f50138b645406bd13d5,openstack/puppet-murano,master,Ia34fef731f7dfe9609b65f50138b645406bd13d5,Run db sync only from main script,MERGED,2015-12-08 15:01:14.000000000,2015-12-11 16:29:13.000000000,2015-12-11 16:29:12.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7549}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8127}, {'_account_id': 9500}, {'_account_id': 10540}, {'_account_id': 13962}, {'_account_id': 14007}, {'_account_id': 18795}]","[{'number': 1, 'created': '2015-12-08 15:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/4ba7e8430295853886e9509a219854f9d338ba61', 'message': ""Run db sync only from main script\n\nCurrently Murano runs db sync from 3 classes: api, engine and main init.\nThat's wrong.\n\nAlso because Murano services can be ran on different nodes, add include\nfor main class. And update tests.\n\nChange-Id: Ia34fef731f7dfe9609b65f50138b645406bd13d5\n""}, {'number': 2, 'created': '2015-12-09 14:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/76a48e1018eb1d948baa838066f9333ae6753bf9', 'message': ""Run db sync only from main script\n\nCurrently Murano runs db sync from 3 classes: api, engine and main init.\nThat's wrong.\n\nAlso because Murano services can be ran on different nodes, add include\nfor main class. And update tests.\n\nChange-Id: Ia34fef731f7dfe9609b65f50138b645406bd13d5\n""}, {'number': 3, 'created': '2015-12-09 15:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/1bc3d462ec1d1a846b93e12e77afbdceb1662ed6', 'message': ""Run db sync only from main script\n\nCurrently Murano runs db sync from 3 classes: api, engine and main init.\nThat's wrong.\n\nAlso because Murano services can be ran on different nodes, add include\nfor main class. And update tests.\n\nChange-Id: Ia34fef731f7dfe9609b65f50138b645406bd13d5\n""}, {'number': 4, 'created': '2015-12-09 16:05:29.000000000', 'files': ['manifests/engine.pp', 'manifests/api.pp'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/750d7806f78628257d7add6950c15ad58c601771', 'message': ""Run db sync only from main script\n\nCurrently Murano runs db sync from 3 classes: api, engine and main init.\nThat's wrong.\n\nChange-Id: Ia34fef731f7dfe9609b65f50138b645406bd13d5\n""}]",1,254809,750d7806f78628257d7add6950c15ad58c601771,24,12,4,7745,,,0,"Run db sync only from main script

Currently Murano runs db sync from 3 classes: api, engine and main init.
That's wrong.

Change-Id: Ia34fef731f7dfe9609b65f50138b645406bd13d5
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/09/254809/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/engine.pp', 'manifests/api.pp', 'spec/classes/murano_api_spec.rb', 'spec/classes/murano_engine_spec.rb']",4,4ba7e8430295853886e9509a219854f9d338ba61,fix_db_sync," let :pre_condition do ""class { ::murano: admin_password => 'password' }"" end @default_facts.merge({ }) @default_facts.merge({ })", { } { },34,14
openstack%2Fshade~master~Iacbd5060f33a9f7273d7208dd400b4868602a3e4,openstack/shade,master,Iacbd5060f33a9f7273d7208dd400b4868602a3e4,Improve test coverage: container/object list API,MERGED,2015-12-10 15:09:17.000000000,2015-12-11 16:26:54.000000000,2015-12-11 16:26:53.000000000,"[{'_account_id': 2}, {'_account_id': 3}]","[{'number': 1, 'created': '2015-12-10 15:09:17.000000000', 'files': ['shade/tests/unit/test_object.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/8d868cb27c13d73267f7097459b7b3e05ccf3eb0', 'message': 'Improve test coverage: container/object list API\n\nAdd missing tests for listing containers and objects.\n\nChange-Id: Iacbd5060f33a9f7273d7208dd400b4868602a3e4\n'}]",0,255926,8d868cb27c13d73267f7097459b7b3e05ccf3eb0,6,2,1,3099,,,0,"Improve test coverage: container/object list API

Add missing tests for listing containers and objects.

Change-Id: Iacbd5060f33a9f7273d7208dd400b4868602a3e4
",git fetch https://review.opendev.org/openstack/shade refs/changes/26/255926/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/tests/unit/test_object.py'],1,8d868cb27c13d73267f7097459b7b3e05ccf3eb0,coverage," @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_containers(self, mock_swift): containers = [dict(id='1', name='containter1')] mock_swift.get_account.return_value = ('response_headers', containers) ret = self.cloud.list_containers() mock_swift.get_account.assert_called_once_with(full_listing=True) self.assertEqual(containers, ret) @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_containers_not_full(self, mock_swift): containers = [dict(id='1', name='containter1')] mock_swift.get_account.return_value = ('response_headers', containers) ret = self.cloud.list_containers(full_listing=False) mock_swift.get_account.assert_called_once_with(full_listing=False) self.assertEqual(containers, ret) @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_containers_exception(self, mock_swift): mock_swift.get_account.side_effect = swift_exc.ClientException(""ERROR"") self.assertRaises(exc.OpenStackCloudException, self.cloud.list_containers) @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_objects(self, mock_swift): objects = [dict(id='1', name='object1')] mock_swift.get_container.return_value = ('response_headers', objects) ret = self.cloud.list_objects('container_name') mock_swift.get_container.assert_called_once_with( container='container_name', full_listing=True) self.assertEqual(objects, ret) @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_objects_not_full(self, mock_swift): objects = [dict(id='1', name='object1')] mock_swift.get_container.return_value = ('response_headers', objects) ret = self.cloud.list_objects('container_name', full_listing=False) mock_swift.get_container.assert_called_once_with( container='container_name', full_listing=False) self.assertEqual(objects, ret) @mock.patch.object(shade.OpenStackCloud, 'swift_client') def test_list_objects_exception(self, mock_swift): mock_swift.get_container.side_effect = swift_exc.ClientException( ""ERROR"") self.assertRaises(exc.OpenStackCloudException, self.cloud.list_objects, 'container_name')",,47,0
openstack%2Fshade~master~Ib35dd49627bc2209060848e719e3cec40dbb4f2a,openstack/shade,master,Ib35dd49627bc2209060848e719e3cec40dbb4f2a,Make a new swift client prior to each image upload,MERGED,2015-12-10 01:19:35.000000000,2015-12-11 16:26:51.000000000,2015-12-11 16:26:49.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 1726}, {'_account_id': 2903}, {'_account_id': 6488}, {'_account_id': 10035}, {'_account_id': 16707}]","[{'number': 1, 'created': '2015-12-10 01:19:35.000000000', 'files': ['shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/44e796a3dd48273236b586992fc870b4f81b26ed', 'message': 'Make a new swift client prior to each image upload\n\nSince swift clients do not support keystone sessions any client that\nexists for a period of time runs the risk of having an expired token and\nthe OpenStackCloud object will never recreate it to reauth. Work around\nthis by making a new client whenever we attempt image uploads to swift.\n\nThere are other potential ways to address this. We could pass the auth\ninfo into swift_client.get_capabilities() so that swift will reauth on\nits own if it needs to. We could just always make a new swiftclient for\nevery swiftclient operation. We could add keystone session support to\nswiftclient. This workaround is simple and uses existing APIs with shade\nand os-c-c so starting with it.\n\nChange-Id: Ib35dd49627bc2209060848e719e3cec40dbb4f2a\n'}]",0,255623,44e796a3dd48273236b586992fc870b4f81b26ed,11,7,1,4146,,,0,"Make a new swift client prior to each image upload

Since swift clients do not support keystone sessions any client that
exists for a period of time runs the risk of having an expired token and
the OpenStackCloud object will never recreate it to reauth. Work around
this by making a new client whenever we attempt image uploads to swift.

There are other potential ways to address this. We could pass the auth
info into swift_client.get_capabilities() so that swift will reauth on
its own if it needs to. We could just always make a new swiftclient for
every swiftclient operation. We could add keystone session support to
swiftclient. This workaround is simple and uses existing APIs with shade
and os-c-c so starting with it.

Change-Id: Ib35dd49627bc2209060848e719e3cec40dbb4f2a
",git fetch https://review.opendev.org/openstack/shade refs/changes/23/255623/1 && git format-patch -1 --stdout FETCH_HEAD,['shade/openstackcloud.py'],1,44e796a3dd48273236b586992fc870b4f81b26ed,renew-swift-client," # Lock used to reset client as swift client does not # support keystone sessions meaning that we have to make # a new client in order to get new auth prior to operations. self._swift_client_lock = threading.Lock() with self._swift_client_lock: if self._swift_client is None: self._swift_client = self._get_client( 'object-store', swiftclient.client.Connection) return self._swift_client with self._swift_client_lock: self._swift_client = None"," if self._swift_client is None: self._swift_client = self._get_client( 'object-store', swiftclient.client.Connection) return self._swift_client",11,4
openstack%2Fpuppet-neutron~master~I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b,openstack/puppet-neutron,master,I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b,Allow empty external_network_bridge value,ABANDONED,2015-11-08 16:16:46.000000000,2015-12-11 16:24:58.000000000,,"[{'_account_id': 3}, {'_account_id': 128}, {'_account_id': 7604}, {'_account_id': 7745}, {'_account_id': 8655}, {'_account_id': 9410}, {'_account_id': 9500}, {'_account_id': 10540}, {'_account_id': 11623}, {'_account_id': 16788}]","[{'number': 1, 'created': '2015-11-08 16:16:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5d4731157081228892fe374509a955d38803520d', 'message': 'Allow empty external_network_bridge value\n\nCurrently only external_network_bridge accepts only non-empty,\nuser-supplied values, or defaults to \'br-ex\' in the l3_agent.ini.\nThis change allows an empty string to be accepted, and is\nrequired to support multiple external/provider networks.  The\nNeutron documentation states:\n\nhttp://docs.openstack.org/trunk/config-reference/content/\\\nsection_neutron-l3_agent.ini.conf.html:\n""To allow L3 agent support multiple external networks, both the\nexternal_network_bridge and gateway_external_network_id must be\nleft empty.""\n\nThis option has existed in releases as far back as at least\nIcehouse.\n\nCloses-Bug: 1514204\nChange-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b\n'}, {'number': 2, 'created': '2015-11-08 16:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/f1817ff26ed394992d095e8c2459982c0006d28e', 'message': 'Allow empty external_network_bridge value\n\nCurrently l3_agent.ini external_network_bridge accepts only\nnon-empty, user-supplied values, or defaults to \'br-ex\'.\nThis change allows an empty string to be accepted, and is\nrequired to support multiple external/provider networks.  The\nNeutron config-reference documentation states:\n\n""To allow L3 agent support multiple external networks, both the\nexternal_network_bridge and gateway_external_network_id must be\nleft empty.""\n\nThis option has existed in releases as far back as at least\nIcehouse and puppet-neutron needs this support.\n\nCloses-Bug: 1514204\nChange-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b\n'}, {'number': 3, 'created': '2015-11-08 16:23:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/b00ecf1c463471f45e5ba1083171c76cf23aa75a', 'message': 'Allow empty external_network_bridge value\n\nCurrently l3_agent.ini external_network_bridge accepts only\nnon-empty, user-supplied values, or defaults to \'br-ex\'.\nThis change allows an empty string to be accepted, and is\nrequired to support multiple external/provider networks.  The\nNeutron config-reference documentation states:\n\n""To allow L3 agent support multiple external networks, both the\nexternal_network_bridge and gateway_external_network_id must be\nleft empty.""\n\nThis option has existed in releases as far back as at least\nIcehouse and puppet-neutron needs this support.\n\nCloses-Bug: 1514204\nChange-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b\n'}, {'number': 4, 'created': '2015-11-08 16:26:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/2f7add038198d0438879ea1757bc9e16abf779b5', 'message': 'Allow empty external_network_bridge value\n\nCurrently l3_agent.ini external_network_bridge accepts only\nnon-empty, user-supplied values, or defaults to \'br-ex\'.\nThis change allows an empty string to be accepted, and is\nrequired to support multiple external/provider networks.  The\nNeutron config-reference documentation states:\n\n""To allow L3 agent support multiple external networks, both the\nexternal_network_bridge and gateway_external_network_id must be\nleft empty.""\n\nThis option has existed in releases as far back as at least\nIcehouse and puppet-neutron needs this support.\n\nCloses-Bug: 1514204\nChange-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b\n'}, {'number': 5, 'created': '2015-11-08 16:49:52.000000000', 'files': ['manifests/agents/l3.pp', 'spec/classes/neutron_agents_l3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c215000dfdbc3cf9a9b90967065093562c5f0ce5', 'message': 'Allow empty external_network_bridge value\n\nCurrently l3_agent.ini external_network_bridge accepts only\nnon-empty, user-supplied values, or defaults to \'br-ex\'.\nThis change allows an empty string to be accepted, and is\nrequired to support multiple external/provider networks.  The\nNeutron config-reference documentation states:\n\n""To allow L3 agent support multiple external networks, both the\nexternal_network_bridge and gateway_external_network_id must be\nleft empty.""\n\nThis option has existed in releases as far back as at least\nIcehouse and puppet-neutron needs this support.\n\nCloses-Bug: 1514204\nChange-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b\n'}]",3,242858,c215000dfdbc3cf9a9b90967065093562c5f0ce5,16,10,5,11623,,,0,"Allow empty external_network_bridge value

Currently l3_agent.ini external_network_bridge accepts only
non-empty, user-supplied values, or defaults to 'br-ex'.
This change allows an empty string to be accepted, and is
required to support multiple external/provider networks.  The
Neutron config-reference documentation states:

""To allow L3 agent support multiple external networks, both the
external_network_bridge and gateway_external_network_id must be
left empty.""

This option has existed in releases as far back as at least
Icehouse and puppet-neutron needs this support.

Closes-Bug: 1514204
Change-Id: I9b95e7e2a3bd815054ba67be72f9ad42600d0a9b
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/58/242858/4 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/agents/l3.pp', 'spec/classes/neutron_agents_l3_spec.rb']",2,5d4731157081228892fe374509a955d38803520d,," shared_examples_for 'with external_network_bridge set to a string' do before do params.merge!( :external_network_bridge => ""br-test"", ) end it 'has external_network_bridge set when specified' do is_expected.to contain_neutron_l3_agent_config('DEFAULT/external_network_bridge').with_value('br-test') end end shared_examples_for 'with external_network_bridge set to an empty string' do before do params.merge!( :instance_user => """", ) end it 'has external_network_bridge set to an empty string when specified' do is_expected.to contain_neutron_l3_agent_config('DEFAULT/external_network_bridge').with_value('') end end ",,30,0
openstack%2Ffuel-qa~master~I0db1eb447247c3b18dd59c37ad97fd64315e8e25,openstack/fuel-qa,master,I0db1eb447247c3b18dd59c37ad97fd64315e8e25,Bump requirements for fuel-devops to the version 2.9.14,MERGED,2015-12-11 11:09:52.000000000,2015-12-11 16:21:53.000000000,2015-12-11 15:39:51.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 16414}, {'_account_id': 19119}, {'_account_id': 19120}]","[{'number': 1, 'created': '2015-12-11 11:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e0627630fd211ec368943ae3c917f36757139bae', 'message': 'Bump requirements for fuel-devops version to 2.9.14\n\nChange-Id: I0db1eb447247c3b18dd59c37ad97fd64315e8e25\n'}, {'number': 2, 'created': '2015-12-11 14:19:20.000000000', 'files': ['fuelweb_test/requirements.txt'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/71b0cb7eb58dccc171b0de84be222b64951b4c5e', 'message': 'Bump requirements for fuel-devops to the version 2.9.14\n\nChange-Id: I0db1eb447247c3b18dd59c37ad97fd64315e8e25\n'}]",0,256350,71b0cb7eb58dccc171b0de84be222b64951b4c5e,22,17,2,11969,,,0,"Bump requirements for fuel-devops to the version 2.9.14

Change-Id: I0db1eb447247c3b18dd59c37ad97fd64315e8e25
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/50/256350/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/requirements.txt'],1,e0627630fd211ec368943ae3c917f36757139bae,requirements-bump-to-2.9.14,git+git://github.com/openstack/fuel-devops.git@2.9.14,git+git://github.com/openstack/fuel-devops.git@2.9.13,1,1
openstack%2Foslo.messaging~stable%2Fliberty~Id874fcfb50b1661031589bfb6d93ddb84a1467c6,openstack/oslo.messaging,stable/liberty,Id874fcfb50b1661031589bfb6d93ddb84a1467c6,Don't trigger error_callback for known exc,MERGED,2015-12-09 21:22:19.000000000,2015-12-11 16:19:36.000000000,2015-12-11 16:19:34.000000000,"[{'_account_id': 3}, {'_account_id': 2813}]","[{'number': 1, 'created': '2015-12-09 21:22:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/67be5e58a5e800a184bc277cae3a0fcac81220ca', 'message': ""Don't trigger error_callback for known exc\n\nWhen AMQPDestinationNotFound is raised, we must not\ncall the error_callback method. The exception is logged\nonly if needed in upper layer (amqpdriver.py).\n\nRelated-bug: #1524418\n\n(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)\n\nChange-Id: Id874fcfb50b1661031589bfb6d93ddb84a1467c6\n""}, {'number': 2, 'created': '2015-12-10 06:55:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/1e23eef4d05ed6157159361c0c1fcc352e20891c', 'message': ""Don't trigger error_callback for known exc\n\nWhen AMQPDestinationNotFound is raised, we must not\ncall the error_callback method. The exception is logged\nonly if needed in upper layer (amqpdriver.py).\n\nRelated-bug: #1524418\nRelated-bug: #1521958\n\n(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)\n\nChange-Id: Id874fcfb50b1661031589bfb6d93ddb84a1467c6\n""}, {'number': 3, 'created': '2015-12-11 07:22:54.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9e095c4bd84c3e83e394071c4f49a8bba3eb1dd6', 'message': ""Don't trigger error_callback for known exc\n\nWhen AMQPDestinationNotFound is raised, we must not\ncall the error_callback method. The exception is logged\nonly if needed in upper layer (amqpdriver.py).\n\nRelated-bug: #1524418\nRelated-bug: #1521958\n\n(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)\n\nChange-Id: Id874fcfb50b1661031589bfb6d93ddb84a1467c6\n""}]",0,255532,9e095c4bd84c3e83e394071c4f49a8bba3eb1dd6,17,2,3,2813,,,0,"Don't trigger error_callback for known exc

When AMQPDestinationNotFound is raised, we must not
call the error_callback method. The exception is logged
only if needed in upper layer (amqpdriver.py).

Related-bug: #1524418
Related-bug: #1521958

(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)

Change-Id: Id874fcfb50b1661031589bfb6d93ddb84a1467c6
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/32/255532/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,67be5e58a5e800a184bc277cae3a0fcac81220ca,bug/1524418, except rpc_amqp.AMQPDestinationNotFound: # NOTE(sileht): we must reraise this without # trigger error_callback raise,,4,0
openstack%2Fsearchlight~master~I7f5a6a74968980636c340e2d059a70b508ece0fc,openstack/searchlight,master,I7f5a6a74968980636c340e2d059a70b508ece0fc,Cap elasticsearch client <2.0,MERGED,2015-12-11 05:14:37.000000000,2015-12-11 16:19:27.000000000,2015-12-11 16:19:26.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 8959}, {'_account_id': 10063}, {'_account_id': 11356}]","[{'number': 1, 'created': '2015-12-11 05:14:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/searchlight/commit/567051cefcdd3922a43f5bed8b7e84a2c85bd099', 'message': ""Cap elasticsearch client <2.0\n\nThe elasticsearch 2.0 python client is not backwards compatible\nwith 1.x, nor with server versions prior to 2.0 (and similarly, the\n1.x client cannot be used with server versions after 1.x).\n\nSee https://elasticsearch-py.readthedocs.org/en/master/ for details.\nSince devstack installs elasticsearch 1.x it seems sensible to cap\nthe client version. Deployers using version 2.0 will need to install\nthat client version in projects requiring it.\n\nNote: Autoproposal bot isn't enabled yet or this would have trickled\nfrom Steve McLellan's patch:\n\nhttps://review.openstack.org/#/c/252075/\n\nChange-Id: I7f5a6a74968980636c340e2d059a70b508ece0fc\nPartial-Bug: #1515412\nCo-Authored-By: Steve McLellan <steven.j.mclellan@gmail.com>\n""}]",0,256219,567051cefcdd3922a43f5bed8b7e84a2c85bd099,7,6,1,7665,,,0,"Cap elasticsearch client <2.0

The elasticsearch 2.0 python client is not backwards compatible
with 1.x, nor with server versions prior to 2.0 (and similarly, the
1.x client cannot be used with server versions after 1.x).

See https://elasticsearch-py.readthedocs.org/en/master/ for details.
Since devstack installs elasticsearch 1.x it seems sensible to cap
the client version. Deployers using version 2.0 will need to install
that client version in projects requiring it.

Note: Autoproposal bot isn't enabled yet or this would have trickled
from Steve McLellan's patch:

https://review.openstack.org/#/c/252075/

Change-Id: I7f5a6a74968980636c340e2d059a70b508ece0fc
Partial-Bug: #1515412
Co-Authored-By: Steve McLellan <steven.j.mclellan@gmail.com>
",git fetch https://review.opendev.org/openstack/searchlight refs/changes/19/256219/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,567051cefcdd3922a43f5bed8b7e84a2c85bd099,bug/1515412,"elasticsearch>=1.3.0,<2.0",elasticsearch>=1.3.0,1,1
openstack%2Fshade~master~I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5,openstack/shade,master,I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5,Add wait support for ironic node [de]activate,MERGED,2015-12-07 02:16:59.000000000,2015-12-11 16:18:44.000000000,2015-12-11 16:18:43.000000000,"[{'_account_id': 2}, {'_account_id': 3}, {'_account_id': 3099}, {'_account_id': 5805}, {'_account_id': 11655}, {'_account_id': 12459}]","[{'number': 1, 'created': '2015-12-07 02:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/4c6f0b0e486afc3df66f969e9efa17b5f66adc26', 'message': 'WIP: Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activateion and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}, {'number': 2, 'created': '2015-12-08 01:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/22ed6347331a64e9617fe603c7d7e4a01c13fee8', 'message': 'WIP: Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activation and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}, {'number': 3, 'created': '2015-12-08 20:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/c415860525d1a3311974cd874e1f3114e28ecaea', 'message': 'Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activation and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}, {'number': 4, 'created': '2015-12-08 21:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/809a9f9fb6c844be33855bc6ecea2c0948235eb1', 'message': 'Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activation and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}, {'number': 5, 'created': '2015-12-10 14:18:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/shade/commit/b3599b399c61ba164fff0587fa8c423615dd570b', 'message': 'Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activation and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}, {'number': 6, 'created': '2015-12-11 13:48:34.000000000', 'files': ['shade/tests/unit/test_shade_operator.py', 'shade/operatorcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/3b50573f639af48cf3b524cb12e8380b4464e274', 'message': 'Add wait support for ironic node [de]activate\n\nOriginal shade support for ironic node activation and deactivation\nwas without support for a wait option being passed into the helper\nmethods.\n\nSo the os_ironic_node module can be updated to support wait=True,\nwe need to add support in the activate_node and deactivate_node\nmethods.\n\nChange-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5\n'}]",11,253979,3b50573f639af48cf3b524cb12e8380b4464e274,28,6,6,11655,,,0,"Add wait support for ironic node [de]activate

Original shade support for ironic node activation and deactivation
was without support for a wait option being passed into the helper
methods.

So the os_ironic_node module can be updated to support wait=True,
we need to add support in the activate_node and deactivate_node
methods.

Change-Id: I69eee2d254cde2fffcf0c1ac7679a623fa7f97a5
",git fetch https://review.opendev.org/openstack/shade refs/changes/79/253979/6 && git format-patch -1 --stdout FETCH_HEAD,"['shade/tests/unit/test_shade_operator.py', 'shade/operatorcloud.py']",2,4c6f0b0e486afc3df66f969e9efa17b5f66adc26,253979," state in [""provide"", ""deleted""]): def activate_node(self, uuid, configdrive=None, wait=False, timeout=1200): self.node_set_provision_state( uuid, 'active', configdrive, wait=wait, timeout=timeout) def deactivate_node(self, uuid, wait=False, timeout=1200): self.node_set_provision_state( uuid, 'deleted', wait=wait, timeout=timeout)"," ""provide"" in state): def activate_node(self, uuid, configdrive=None): self.node_set_provision_state(uuid, 'active', configdrive) def deactivate_node(self, uuid): self.node_set_provision_state(uuid, 'deleted')",60,7
openstack%2Fpuppet-murano~master~I4ac69bb021462250c149e183990c76e3a261c29a,openstack/puppet-murano,master,I4ac69bb021462250c149e183990c76e3a261c29a,Fix service and package tags,MERGED,2015-12-09 14:30:47.000000000,2015-12-11 16:16:38.000000000,2015-12-11 16:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7549}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 8127}, {'_account_id': 9500}, {'_account_id': 10540}, {'_account_id': 13962}, {'_account_id': 14007}]","[{'number': 1, 'created': '2015-12-09 14:30:47.000000000', 'files': ['manifests/cfapi.pp', 'manifests/engine.pp', 'manifests/api.pp', 'spec/shared_examples.rb'], 'web_link': 'https://opendev.org/openstack/puppet-murano/commit/b8f767d71cfbdb6b4ae642afa98970ced626b5ac', 'message': ""Fix service and package tags\n\nSync db class contains notification for murano services after\nexecuting db sync, but all services doesn't have proper tag.\n\nChange-Id: I4ac69bb021462250c149e183990c76e3a261c29a\n""}]",0,255283,b8f767d71cfbdb6b4ae642afa98970ced626b5ac,14,10,1,7745,,,0,"Fix service and package tags

Sync db class contains notification for murano services after
executing db sync, but all services doesn't have proper tag.

Change-Id: I4ac69bb021462250c149e183990c76e3a261c29a
",git fetch https://review.opendev.org/openstack/puppet-murano refs/changes/83/255283/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/cfapi.pp', 'manifests/engine.pp', 'manifests/api.pp', 'spec/shared_examples.rb']",4,b8f767d71cfbdb6b4ae642afa98970ced626b5ac,fix_db_sync," :notify => [""Service[#{service[:name]}]""], :tag => [ 'openstack', 'murano-package'], :enable => true, :tag => 'murano-service', :notify => [""Service[#{service[:name]}]""], :tag => [ 'openstack', 'murano-package'], :enable => true, :tag => 'murano-service',"," :notify => [""Service[#{service[:name]}]""] :enable => true :notify => [""Service[#{service[:name]}]""] :enable => true",14,4
openstack%2Fcinder~master~Icd2c3d506647b7b9405d83612433fea735d13cc9,openstack/cinder,master,Icd2c3d506647b7b9405d83612433fea735d13cc9,VMware: Unit test refactoring (image to vol - 1/2),MERGED,2015-11-24 12:34:21.000000000,2015-12-11 16:13:24.000000000,2015-12-03 20:59:24.000000000,"[{'_account_id': 3}, {'_account_id': 1207}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 9171}, {'_account_id': 9535}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14305}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16660}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 16952}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18479}, {'_account_id': 19004}, {'_account_id': 19146}, {'_account_id': 19191}]","[{'number': 1, 'created': '2015-11-24 12:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/11ae8b8deaae31da6033fbf0cacf97a0a5d1bb6a', 'message': 'VMware: Unit test refactoring\n\nThere are cases where a single test tests multiple methods. This\npatch refactors the unit tests for the following methods in the\nvmdk module to fix this issue:\n   * copy_image_to_volume\n   * _create_volume_from_non_stream_optimized_image\n\nThere will be follow-up patches to fix the remaining unit tests.\n\nChange-Id: Icd2c3d506647b7b9405d83612433fea735d13cc9\n'}, {'number': 2, 'created': '2015-11-25 06:23:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8aa0a0820cdbe875b2da2d0520b5b422cc48bd7a', 'message': 'VMware: Unit test refactoring (image to vol - 1/2)\n\nThere are cases where a single test tests multiple methods. This\npatch refactors the unit tests for the following methods in the\nvmdk module to fix this issue:\n   * copy_image_to_volume\n   * _create_volume_from_non_stream_optimized_image\n\nThere will be follow-up patches to fix the remaining unit tests.\n\nChange-Id: Icd2c3d506647b7b9405d83612433fea735d13cc9\n'}, {'number': 3, 'created': '2015-12-02 12:42:24.000000000', 'files': ['cinder/tests/unit/test_vmware_vmdk.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/c09770af672ebc482fc488f5922bb1bcc0f81679', 'message': 'VMware: Unit test refactoring (image to vol - 1/2)\n\nThere are cases where a single test tests multiple methods. This\npatch refactors the unit tests for the following methods in the\nvmdk module to fix this issue:\n   * copy_image_to_volume\n   * _create_volume_from_non_stream_optimized_image\n\nThere will be follow-up patches to fix the remaining unit tests.\n\nChange-Id: Icd2c3d506647b7b9405d83612433fea735d13cc9\n'}]",21,249174,c09770af672ebc482fc488f5922bb1bcc0f81679,110,46,3,9171,,,0,"VMware: Unit test refactoring (image to vol - 1/2)

There are cases where a single test tests multiple methods. This
patch refactors the unit tests for the following methods in the
vmdk module to fix this issue:
   * copy_image_to_volume
   * _create_volume_from_non_stream_optimized_image

There will be follow-up patches to fix the remaining unit tests.

Change-Id: Icd2c3d506647b7b9405d83612433fea735d13cc9
",git fetch https://review.opendev.org/openstack/cinder refs/changes/74/249174/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/tests/unit/test_vmware_vmdk.py'],1,11ae8b8deaae31da6033fbf0cacf97a0a5d1bb6a,test_vmdk_refactor," VOL_SIZE = 2 status='available', size=VOL_SIZE): 'size': size, def test_validate_disk_format(self): self._driver._validate_disk_format('vmdk') def test_validate_disk_format_with_invalid_format(self): self._driver._validate_disk_format, 'img') def _create_image_meta(self, disk_format='vmdk', size=1*units.Gi, container_format='bare', vmware_disktype='streamOptimized', vmware_adaptertype='lsiLogic'): return {'disk_format': disk_format, 'size': size, 'container_format': container_format, 'properties': {'vmware_disktype': vmware_disktype, 'vmware_adaptertype': vmware_adaptertype, }, } @mock.patch('cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver.' '_validate_disk_format') def test_copy_image_to_volume_with_ova_container(self, validate_disk_format): image_service = mock.Mock() image_meta = self._create_image_meta(container_format='ova') context = mock.sentinel.context volume = self._create_volume_dict() image_id = mock.sentinel.image_id self.assertRaises( cinder_exceptions.ImageUnacceptable, self._driver.copy_image_to_volume, context, volume, image_service, image_id) validate_disk_format.assert_called_once_with(image_meta['disk_format']) def _test_copy_image_to_volume( self, extend_backing, vops, validate_image_disk_type, validate_image_adapter_type, validate_disk_format, fetch_stream_optimized_image, create_disk_from_non_stream_opt_image, vmware_disk_type, backing_disk_size=VOL_SIZE, call_extend_backing=False): image_service = mock.Mock() image_meta = self._create_image_meta(vmware_disktype=vmware_disk_type) image_service.show.return_value = image_meta backing = mock.sentinel.backing vops.get_backing.return_value = backing vops.get_disk_size.return_value = backing_disk_size * units.Gi context = mock.sentinel.context volume = self._create_volume_dict() image_id = mock.sentinel.image_id self._driver.copy_image_to_volume( context, volume, image_service, image_id) validate_disk_format.assert_called_once_with(image_meta['disk_format']) validate_image_disk_type.assert_called_once_with( image_meta['properties']['vmware_disktype']) validate_image_adapter_type.assert_called_once_with( image_meta['properties']['vmware_adaptertype']) if vmware_disk_type == 'streamOptimized': fetch_stream_optimized_image.assert_called_once_with( context, volume, image_service, image_id, image_meta['size'], image_meta['properties']['vmware_adaptertype']) else: create_disk_from_non_stream_opt_image.assert_called_once_with( context, volume, image_service, image_id, image_meta['size'], image_meta['properties']['vmware_adaptertype'], image_meta['properties']['vmware_disktype']) vops.get_disk_size.assert_called_once_with(backing) if call_extend_backing: extend_backing.assert_called_once_with(backing, volume['size']) else: self.assertFalse(extend_backing.called) @mock.patch('cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver.' '_validate_disk_format') @mock.patch('cinder.volume.drivers.vmware.volumeops.' 'VirtualDiskAdapterType.validate') @mock.patch('cinder.volume.drivers.vmware.vmdk.ImageDiskType.' 'validate') @mock.patch.object(VMDK_DRIVER, '_create_volume_from_non_stream_optimized_image') @mock.patch.object(VMDK_DRIVER, '_fetch_stream_optimized_image') @mock.patch.object(VMDK_DRIVER, 'volumeops') @mock.patch.object(VMDK_DRIVER, '_extend_backing') @ddt.data('sparse', 'preallocated', 'streamOptimized') def test_copy_image_to_volume( self, vmware_disk_type, extend_backing, vops, fetch_stream_opt_image, create_disk_from_non_stream_opt_image, validate_image_disk_type, validate_image_adapter_type, validate_disk_format): self._test_copy_image_to_volume( extend_backing, vops, validate_image_disk_type, validate_image_adapter_type, validate_disk_format, fetch_stream_opt_image, create_disk_from_non_stream_opt_image, vmware_disk_type) @mock.patch('cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver.' '_validate_disk_format') @mock.patch('cinder.volume.drivers.vmware.volumeops.' 'VirtualDiskAdapterType.validate') @mock.patch('cinder.volume.drivers.vmware.vmdk.ImageDiskType.' 'validate') @mock.patch.object(VMDK_DRIVER, '_create_volume_from_non_stream_optimized_image') @mock.patch.object(VMDK_DRIVER, '_fetch_stream_optimized_image') @mock.patch.object(VMDK_DRIVER, 'volumeops') @mock.patch.object(VMDK_DRIVER, '_extend_backing') @ddt.data('sparse', 'preallocated', 'streamOptimized') def test_copy_image_to_volume_with_extend_backing( self, vmware_disk_type, extend_backing, vops, fetch_stream_opt_image, create_disk_from_non_stream_opt_image, validate_image_disk_type, validate_image_adapter_type, validate_disk_format): self._test_copy_image_to_volume( extend_backing, vops, validate_image_disk_type, validate_image_adapter_type, validate_disk_format, fetch_stream_opt_image, create_disk_from_non_stream_opt_image, vmware_disk_type, backing_disk_size=1, call_extend_backing=True) def _test_create_volume_from_non_stream_optimized_image( self, get_disk_type, check_disk_conversion, generate_uuid, create_backing, get_ds_name_folder_path, vops, create_disk_from_sparse_image, create_disk_from_preallocated_image, delete_tmp_backing, select_ds_for_volume, image_disk_type, disk_conversion=False): disk_type = mock.sentinel.disk_type get_disk_type.return_value = disk_type check_disk_conversion.return_value = disk_conversion volume = self._create_volume_dict() if disk_conversion: disk_name = ""6b77b25a-9136-470e-899e-3c930e570d8e"" generate_uuid.return_value = disk_name else: disk_name = volume['name'] backing = mock.sentinel.backing create_backing.return_value = backing ds_name = mock.sentinel.ds_name folder_path = mock.sentinel.folder_path host = mock.sentinel.host dc_ref = mock.sentinel.dc_ref vmdk_path = mock.Mock() create_disk_from_sparse_image.return_value = vmdk_path create_disk_from_preallocated_image.return_value = vmdk_path if disk_conversion: rp = mock.sentinel.rp folder = mock.sentinel.folder datastore = mock.sentinel.datastore summary = mock.Mock(datastore=datastore) select_ds_for_volume.return_value = (host, rp, folder, summary) clone = mock.sentinel.clone vops.clone_backing.return_value = clone context = mock.sentinel.context image_service = mock.sentinel.image_service image_id = mock.sentinel.image_id image_size_in_bytes = units.Gi adapter_type = mock.sentinel.adapter_type self._driver._create_volume_from_non_stream_optimized_image( context, volume, image_service, image_id, image_size_in_bytes, adapter_type, image_disk_type) check_disk_conversion.assert_called_once_with(image_disk_type, mock.sentinel.disk_type) if disk_conversion: create_backing.assert_called_once_with( volume, create_params={vmdk.CREATE_PARAM_DISK_LESS: True, vmdk.CREATE_PARAM_BACKING_NAME: disk_name}) else: create_backing.assert_called_once_with( volume, create_params={vmdk.CREATE_PARAM_DISK_LESS: True}) if image_disk_type == 'sparse': create_disk_from_sparse_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, disk_name) else: create_disk_from_preallocated_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, disk_name, adapter_type) adapter_type, vmdk_path.get_descriptor_ds_file_path()) if disk_conversion: select_ds_for_volume.assert_called_once_with(volume) vops.clone_backing.assert_called_once_with( volume['name'], backing, None, volumeops.FULL_CLONE_TYPE, datastore, disk_type, host, rp) delete_tmp_backing.assert_called_once_with(backing) vops.update_backing_disk_uuid(clone, volume['id']) else: vops.update_backing_disk_uuid(backing, volume['id']) @mock.patch('cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver.' '_get_disk_type') @mock.patch.object(VMDK_DRIVER, '_check_disk_conversion') @mock.patch('oslo_utils.uuidutils.generate_uuid') @mock.patch.object(VMDK_DRIVER, '_create_backing') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_folder_path') @mock.patch.object(VMDK_DRIVER, 'volumeops') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_sparse_image') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_preallocated_image') @mock.patch.object(VMDK_DRIVER, '_select_ds_for_volume') @mock.patch.object(VMDK_DRIVER, '_delete_temp_backing') @ddt.data('sparse', 'preallocated') def test_create_volume_from_non_stream_optimized_image( self, image_disk_type, delete_temp_backing, select_ds_for_volume, create_disk_from_preallocated_image, create_disk_from_sparse_image, vops, get_ds_name_folder_path, create_backing, generate_uuid, check_disk_conversion, get_disk_type): self._test_create_volume_from_non_stream_optimized_image( get_disk_type, check_disk_conversion, generate_uuid, create_backing, get_ds_name_folder_path, vops, create_disk_from_sparse_image, create_disk_from_preallocated_image, delete_temp_backing, select_ds_for_volume, image_disk_type) @mock.patch('cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver.' '_get_disk_type') @mock.patch.object(VMDK_DRIVER, '_check_disk_conversion') @mock.patch('oslo_utils.uuidutils.generate_uuid') @mock.patch.object(VMDK_DRIVER, '_create_backing') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_folder_path') @mock.patch.object(VMDK_DRIVER, 'volumeops') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_sparse_image') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_preallocated_image') @mock.patch.object(VMDK_DRIVER, '_select_ds_for_volume') @mock.patch.object(VMDK_DRIVER, '_delete_temp_backing') @ddt.data('sparse', 'preallocated') def test_create_volume_from_non_stream_opt_image_with_disk_conversion( self, image_disk_type, delete_temp_backing, select_ds_for_volume, create_disk_from_preallocated_image, create_disk_from_sparse_image, vops, get_ds_name_folder_path, create_backing, generate_uuid, check_disk_conversion, get_disk_type): self._test_create_volume_from_non_stream_optimized_image( get_disk_type, check_disk_conversion, generate_uuid, create_backing, get_ds_name_folder_path, vops, create_disk_from_sparse_image, create_disk_from_preallocated_image, delete_temp_backing, select_ds_for_volume, image_disk_type, disk_conversion=True)"," status='available'): def test_copy_image_to_volume_non_vmdk(self): """"""Test copy_image_to_volume for a non-vmdk disk format."""""" fake_context = mock.sentinel.context fake_image_id = 'image-123456789' fake_image_meta = {'disk_format': 'novmdk'} image_service = mock.Mock() image_service.show.return_value = fake_image_meta fake_volume = {'name': 'fake_name', 'size': 1} self._driver.copy_image_to_volume, fake_context, fake_volume, image_service, fake_image_id) @mock.patch.object(VMDK_DRIVER, '_extend_backing') @mock.patch('oslo_utils.uuidutils.generate_uuid') @mock.patch.object(VMDK_DRIVER, '_select_ds_for_volume') @mock.patch.object(VMDK_DRIVER, 'volumeops') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_preallocated_image') @mock.patch.object(VMDK_DRIVER, '_create_virtual_disk_from_sparse_image') @mock.patch( 'cinder.volume.drivers.vmware.vmdk.VMwareVcVmdkDriver._get_disk_type') @mock.patch.object(VMDK_DRIVER, '_get_ds_name_folder_path') @mock.patch.object(VMDK_DRIVER, '_create_backing') def test_copy_image_to_volume_non_stream_optimized( self, create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid, extend_backing): self._test_copy_image_to_volume_non_stream_optimized( create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid, extend_backing) def _test_copy_image_to_volume_non_stream_optimized( self, create_backing, get_ds_name_folder_path, get_disk_type, create_disk_from_sparse_image, create_disk_from_preallocated_image, vops, select_ds_for_volume, generate_uuid, extend_backing): image_size_in_bytes = 2 * units.Gi adapter_type = 'lsiLogic' image_meta = {'disk_format': 'vmdk', 'size': image_size_in_bytes, 'properties': {'vmware_disktype': 'sparse', 'vmwware_adaptertype': adapter_type}} image_service = mock.Mock(glance.GlanceImageService) backing = mock.Mock() def create_backing_mock(volume, create_params): self.assertTrue(create_params[vmdk.CREATE_PARAM_DISK_LESS]) return backing create_backing.side_effect = create_backing_mock ds_name = mock.Mock() folder_path = mock.Mock() summary = mock.Mock() select_ds_for_volume.return_value = (mock.sentinel.host, mock.sentinel.rp, mock.sentinel.folder, summary) uuid = ""6b77b25a-9136-470e-899e-3c930e570d8e"" generate_uuid.return_value = uuid host = mock.Mock() dc_ref = mock.Mock() disk_type = vmdk.EAGER_ZEROED_THICK_VMDK_TYPE get_disk_type.return_value = disk_type path = mock.Mock() create_disk_from_sparse_image.return_value = path create_disk_from_preallocated_image.return_value = path clone = mock.sentinel.clone vops.clone_backing.return_value = clone volume_size = 2 vops.get_disk_size.return_value = volume_size * units.Gi context = mock.Mock() volume = {'name': 'volume_name', 'id': 'volume_id', 'size': volume_size} image_id = mock.Mock() self._driver.copy_image_to_volume( context, volume, image_service, image_id) create_params = {vmdk.CREATE_PARAM_DISK_LESS: True, vmdk.CREATE_PARAM_BACKING_NAME: uuid} create_backing.assert_called_once_with(volume, create_params=create_params) create_disk_from_sparse_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, uuid) adapter_type, path.get_descriptor_ds_file_path()) select_ds_for_volume.assert_called_once_with(volume) vops.clone_backing.assert_called_once_with( volume['name'], backing, None, volumeops.FULL_CLONE_TYPE, summary.datastore, disk_type, mock.sentinel.host, mock.sentinel.rp) vops.delete_backing.assert_called_once_with(backing) vops.update_backing_disk_uuid.assert_called_once_with(clone, volume['id']) self.assertFalse(extend_backing.called) vops.get_backing.return_value = backing vops.get_disk_size.return_value = 1 * units.Gi create_backing.reset_mock() vops.attach_disk_to_backing.reset_mock() vops.delete_backing.reset_mock() vops.update_backing_disk_uuid.reset_mock() image_meta['properties']['vmware_disktype'] = 'preallocated' self._driver.copy_image_to_volume( context, volume, image_service, image_id) del create_params[vmdk.CREATE_PARAM_BACKING_NAME] create_backing.assert_called_once_with(volume, create_params=create_params) create_disk_from_preallocated_image.assert_called_once_with( context, image_service, image_id, image_size_in_bytes, dc_ref, ds_name, folder_path, volume['name'], adapter_type) vops.attach_disk_to_backing.assert_called_once_with( backing, image_size_in_bytes / units.Ki, disk_type, adapter_type, path.get_descriptor_ds_file_path()) vops.update_backing_disk_uuid.assert_called_once_with(backing, volume['id']) extend_backing.assert_called_once_with(backing, volume['size']) extend_backing.reset_mock() create_disk_from_preallocated_image.side_effect = ( exceptions.VimException(""Error"")) self.assertRaises(exceptions.VimException, self._driver.copy_image_to_volume, context, volume, image_service, image_id) vops.delete_backing.assert_called_once_with(backing) self.assertFalse(extend_backing.called) def test_copy_image_to_volume_with_ova_container(self): image_service = mock.Mock(glance.GlanceImageService) image_size = 2 * units.Gi adapter_type = 'ide' image_meta = {'disk_format': 'vmdk', 'size': image_size, 'container_format': 'ova', 'properties': {'vmware_disktype': 'streamOptimized', 'vmware_adaptertype': adapter_type}} image_service.show.return_value = image_meta context = mock.sentinel.context vol_name = 'volume-51e47214-8e3c-475d-b44b-aea6cd3eef53' vol_id = '51e47214-8e3c-475d-b44b-aea6cd3eef53' display_name = 'foo' volume_size = 4 volume = {'name': vol_name, 'id': vol_id, 'display_name': display_name, 'size': volume_size, 'volume_type_id': None} image_id = 'image-id' self.assertRaises( cinder_exceptions.ImageUnacceptable, self._driver.copy_image_to_volume, context, volume, image_service, image_id) ",287,156
openstack%2Ffuel-library~master~Ia5f030894de80bf4092010d4c5c6c5d9cec28837,openstack/fuel-library,master,Ia5f030894de80bf4092010d4c5c6c5d9cec28837,Explicitly disable vCenter certificate verification check,MERGED,2015-12-03 20:16:19.000000000,2015-12-11 16:11:16.000000000,2015-12-11 16:10:28.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8797}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11427}, {'_account_id': 11827}, {'_account_id': 12199}, {'_account_id': 14495}, {'_account_id': 15660}, {'_account_id': 15921}, {'_account_id': 16044}]","[{'number': 1, 'created': '2015-12-03 20:16:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ee5758be5b3c1f9d1bbcecfdffbaf389aedd3a50', 'message': 'Explicitly disable vCenter certificate verification check\n\n- cinder-vmware by default tries to verify vCenter\n  certificate, if it cannot verify certificate\n  then it cannot start and operate normally.\n\nCloses-bug: #1522447\nDocImpact: Document the fact that currently it is not possible to\nverify vCenter SSL certificate by providing CA certificate bundle.\n\nChange-Id: Ia5f030894de80bf4092010d4c5c6c5d9cec28837\n'}, {'number': 2, 'created': '2015-12-08 09:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a9d8219d795724ed92e5d37287d15053c0401e05', 'message': 'Explicitly disable vCenter certificate verification check\n\n- cinder-vmware by default tries to verify vCenter\n  certificate, if it cannot verify certificate\n  then it cannot start and operate normally.\n\nCloses-bug: #1522447\nDocImpact: Document the fact that currently it is not possible to\nverify vCenter SSL certificate by providing CA certificate bundle.\n\nChange-Id: Ia5f030894de80bf4092010d4c5c6c5d9cec28837\n'}, {'number': 3, 'created': '2015-12-11 13:34:07.000000000', 'files': ['deployment/puppet/vmware/templates/cinder-volume.conf.erb'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c979dea01f77a6e2bf284bd2ff51cda73ce67332', 'message': 'Explicitly disable vCenter certificate verification check\n\n- cinder-vmware by default tries to verify vCenter\n  certificate, if it cannot verify certificate\n  then it cannot start and operate normally.\n\nCloses-bug: #1522447\nDocImpact: Document the fact that currently it is not possible to\nverify vCenter SSL certificate by providing CA certificate bundle.\n\nChange-Id: Ia5f030894de80bf4092010d4c5c6c5d9cec28837\n'}]",0,253184,c979dea01f77a6e2bf284bd2ff51cda73ce67332,52,12,3,14946,,,0,"Explicitly disable vCenter certificate verification check

- cinder-vmware by default tries to verify vCenter
  certificate, if it cannot verify certificate
  then it cannot start and operate normally.

Closes-bug: #1522447
DocImpact: Document the fact that currently it is not possible to
verify vCenter SSL certificate by providing CA certificate bundle.

Change-Id: Ia5f030894de80bf4092010d4c5c6c5d9cec28837
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/84/253184/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/puppet/vmware/templates/cinder-volume.conf.erb'],1,ee5758be5b3c1f9d1bbcecfdffbaf389aedd3a50,bug/1522447,vmware_insecure = True,,1,0
openstack%2Fopenstack-ansible~kilo~I5316432bf96124d5c4022a367a8684a4320a68f3,openstack/openstack-ansible,kilo,I5316432bf96124d5c4022a367a8684a4320a68f3,Docs for skipping user creation w/LDAP,MERGED,2015-12-09 12:45:11.000000000,2015-12-11 16:07:04.000000000,2015-12-11 16:07:02.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 12807}]","[{'number': 1, 'created': '2015-12-09 12:45:11.000000000', 'files': ['doc/source/install-guide/configure-keystone.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3d92e2981c4059c238b82e872fc91168126abe5e', 'message': 'Docs for skipping user creation w/LDAP\n\nChange-Id: I5316432bf96124d5c4022a367a8684a4320a68f3\n(cherry picked from commit 1d13b9775c2c3fb0c7b2efb671acffd00f1700aa)\n'}]",0,255241,3d92e2981c4059c238b82e872fc91168126abe5e,6,3,1,538,,,0,"Docs for skipping user creation w/LDAP

Change-Id: I5316432bf96124d5c4022a367a8684a4320a68f3
(cherry picked from commit 1d13b9775c2c3fb0c7b2efb671acffd00f1700aa)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/41/255241/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install-guide/configure-keystone.rst'],1,3d92e2981c4059c238b82e872fc91168126abe5e,,"Special considerations when using LDAP or AD backends ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Configuring LDAP or Active Directory (AD) backends for keystone can make deployment easier, but there are special considerations for these types of deployments. Creating users """""""""""""""""""""""""""" During an OpenStack-Ansible deployment, the individual roles that deploy various OpenStack services will attempt to create users in keystone. For deployments where keystone uses LDAP as an authentication backend, these users must be created **prior** to the running the OpenStack-Ansible playbooks. The tasks for adding keystone users within individual role playbooks will be skipped. Stacked authentication """""""""""""""""""""""""""""""""""""""""""" Some deployers may prefer to use ""stacked"" authentication where some users exist in a SQL backend while other users exist in an LDAP or Active Directory (AD) backend. This can be useful for deploys who want to reduce the number of service accounts that must exist in LDAP or AD. For more details on stacked authentication, see `Matt Fischer's blog post`_ or review IBM's documentation titled `Configure OpenStack Keystone support for domain-specific corporate directories`_. .. _Matt Fischer's blog post: http://www.mattfischer.com/blog/?p=576 .. _Configure OpenStack Keystone support for domain-specific corporate directories: http://www.ibm.com/developerworks/cloud/library/cl-configure-keystone-ldap-and-active-directory/index.html ",,32,0
openstack%2Fnova~master~Idb46ed2a64c989017665403c6901ccac4bd312bc,openstack/nova,master,Idb46ed2a64c989017665403c6901ccac4bd312bc,Add unit tests for signature_utils module,ABANDONED,2015-12-10 19:41:10.000000000,2015-12-11 16:06:56.000000000,,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-10 19:41:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1eda500fb203b37d485c45c3eab12d73a87bb9b4', 'message': 'Add unit tests for signature_utils module\n\nThis change adds unit tests for the signature_utils\nmodule, which is needed to support verification of\nsigned images\n\nChange-Id: Idb46ed2a64c989017665403c6901ccac4bd312bc\nDepends-On: I904a7489c8759951daa6c9ffb1cf444822132258\nImplements: blueprint nova-support-image-signing\n'}, {'number': 2, 'created': '2015-12-10 20:05:22.000000000', 'files': ['nova/tests/unit/test_signature_utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/483a566970fabc91a2cfffcb4574f3f145d9949d', 'message': 'Add unit tests for signature_utils module\n\nThis change adds unit tests for the signature_utils\nmodule, which is needed to support verification of\nsigned images\n\nChange-Id: Idb46ed2a64c989017665403c6901ccac4bd312bc\nDepends-On: I904a7489c8759951daa6c9ffb1cf444822132258\nImplements: blueprint nova-support-image-signing\n'}]",1,256072,483a566970fabc91a2cfffcb4574f3f145d9949d,12,6,2,15524,,,0,"Add unit tests for signature_utils module

This change adds unit tests for the signature_utils
module, which is needed to support verification of
signed images

Change-Id: Idb46ed2a64c989017665403c6901ccac4bd312bc
Depends-On: I904a7489c8759951daa6c9ffb1cf444822132258
Implements: blueprint nova-support-image-signing
",git fetch https://review.opendev.org/openstack/nova refs/changes/72/256072/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_signature_utils.py'],1,1eda500fb203b37d485c45c3eab12d73a87bb9b4,bp/nova-support-image-signing,"# Copyright (c) The Johns Hopkins University/Applied Physics Laboratory # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import base64 import datetime import mock import cryptography.exceptions as crypto_exceptions from cryptography.hazmat.backends import default_backend from cryptography.hazmat.primitives.asymmetric import dsa from cryptography.hazmat.primitives.asymmetric import ec from cryptography.hazmat.primitives.asymmetric import padding from cryptography.hazmat.primitives.asymmetric import rsa from nova import exception from nova import signature_utils from nova import test from oslo_utils import timeutils TEST_RSA_PRIVATE_KEY = rsa.generate_private_key(public_exponent=3, key_size=1024, backend=default_backend()) TEST_ECC_PRIVATE_KEY = ec.generate_private_key(ec.SECP521R1(), default_backend()) TEST_DSA_PRIVATE_KEY = dsa.generate_private_key(key_size=3072, backend=default_backend()) # ECC curves, for generating private keys ECC_CURVE_METHODS = { signature_utils.ECC_SECT571K1: ec.SECT571K1(), signature_utils.ECC_SECT409K1: ec.SECT409K1(), signature_utils.ECC_SECT571R1: ec.SECT571R1(), signature_utils.ECC_SECT409R1: ec.SECT409R1(), signature_utils.ECC_SECP521R1: ec.SECP521R1(), signature_utils.ECC_SECP384R1: ec.SECP384R1(), } # Required image property names (SIGNATURE, HASH_METHOD, KEY_TYPE, CERT_UUID) = ( signature_utils.SIGNATURE, signature_utils.HASH_METHOD, signature_utils.KEY_TYPE, signature_utils.CERT_UUID ) class FakeKeyManager(object): def __init__(self): self.certs = {'invalid_format_cert': FakeCastellanCertificate('A' * 256, 'BLAH'), 'valid_format_cert': FakeCastellanCertificate('A' * 256, 'X.509')} def get(self, context, cert_uuid): cert = self.certs.get(cert_uuid) if cert is None: raise Exception(""No matching certificate found."") return cert class FakeCastellanCertificate(object): def __init__(self, data, cert_format): self.data = data self.cert_format = cert_format @property def format(self): return self.cert_format def get_encoded(self): return self.data class FakeCryptoCertificate(object): def __init__(self, pub_key=TEST_RSA_PRIVATE_KEY.public_key(), not_valid_before=(timeutils.utcnow() - datetime.timedelta(hours=1)), not_valid_after=(timeutils.utcnow() + datetime.timedelta(hours=1))): self.pub_key = pub_key self.cert_not_valid_before = not_valid_before self.cert_not_valid_after = not_valid_after def public_key(self): return self.pub_key @property def not_valid_before(self): return self.cert_not_valid_before @property def not_valid_after(self): return self.cert_not_valid_after class BadPublicKey(object): def verifier(self, signature, padding, hash_method): return None class TestSignatureUtils(test.NoDBTestCase): """"""Test methods of signature_utils"""""" def test_should_verify_signature(self): image_props = {CERT_UUID: 'CERT_UUID', HASH_METHOD: 'HASH_METHOD', SIGNATURE: 'SIGNATURE', KEY_TYPE: 'SIG_KEY_TYPE'} self.assertTrue(signature_utils.should_verify_signature(image_props)) def test_should_verify_signature_fail(self): bad_image_properties = [{CERT_UUID: 'CERT_UUID', HASH_METHOD: 'HASH_METHOD', SIGNATURE: 'SIGNATURE'}, {CERT_UUID: 'CERT_UUID', HASH_METHOD: 'HASH_METHOD', KEY_TYPE: 'SIG_KEY_TYPE'}, {CERT_UUID: 'CERT_UUID', SIGNATURE: 'SIGNATURE', KEY_TYPE: 'SIG_KEY_TYPE'}, {HASH_METHOD: 'HASH_METHOD', SIGNATURE: 'SIGNATURE', KEY_TYPE: 'SIG_KEY_TYPE'}] for bad_props in bad_image_properties: result = signature_utils.should_verify_signature(bad_props) self.assertFalse(result) @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_PSS(self, mock_get_pub_key): data = b'224626ae19824466f2a7f39ab7b80f7f' mock_get_pub_key.return_value = TEST_RSA_PRIVATE_KEY.public_key() for hash_name, hash_alg in signature_utils.HASH_METHODS.items(): signer = TEST_RSA_PRIVATE_KEY.signer( padding.PSS( mgf=padding.MGF1(hash_alg), salt_length=padding.PSS.MAX_LENGTH ), hash_alg ) signer.update(data) signature = base64.b64encode(signer.finalize()) image_props = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: hash_name, KEY_TYPE: 'RSA-PSS', SIGNATURE: signature} verifier = signature_utils.get_verifier(None, image_props) verifier.update(data) verifier.verify() @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_ECC(self, mock_get_pub_key): data = b'224626ae19824466f2a7f39ab7b80f7f' # test every ECC curve for curve_name, curve_method in ECC_CURVE_METHODS.items(): # Create a private key to use private_key = ec.generate_private_key(curve_method, default_backend()) mock_get_pub_key.return_value = private_key.public_key() for hash_name, hash_alg in signature_utils.HASH_METHODS.items(): signer = private_key.signer( ec.ECDSA(hash_alg) ) signer.update(data) signature = base64.b64encode(signer.finalize()) image_props = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: hash_name, KEY_TYPE: curve_name, SIGNATURE: signature} verifier = signature_utils.get_verifier(None, image_props) verifier.update(data) verifier.verify() @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_DSA(self, mock_get_pub_key): data = b'224626ae19824466f2a7f39ab7b80f7f' mock_get_pub_key.return_value = TEST_DSA_PRIVATE_KEY.public_key() for hash_name, hash_alg in signature_utils.HASH_METHODS.items(): signer = TEST_DSA_PRIVATE_KEY.signer( hash_alg ) signer.update(data) signature = base64.b64encode(signer.finalize()) image_props = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: hash_name, KEY_TYPE: 'DSA', SIGNATURE: signature} verifier = signature_utils.get_verifier(None, image_props) verifier.update(data) verifier.verify() @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_bad_signature(self, mock_get_pub_key): data = b'224626ae19824466f2a7f39ab7b80f7f' mock_get_pub_key.return_value = TEST_RSA_PRIVATE_KEY.public_key() image_properties = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: 'SHA-256', KEY_TYPE: 'RSA-PSS', SIGNATURE: 'BLAH'} verifier = signature_utils.get_verifier(None, image_properties) verifier.update(data) self.assertRaises(crypto_exceptions.InvalidSignature, verifier.verify) @mock.patch('nova.signature_utils.should_verify_signature') def test_get_verifier_invalid_image_props(self, mock_should): mock_should.return_value = False self.assertRaisesRegex(exception.SignatureVerificationError, 'Required image properties for signature' ' verification do not exist. Cannot verify' ' signature.', signature_utils.get_verifier, None, None) @mock.patch('nova.signature_utils.get_public_key') def test_verify_signature_bad_sig_key_type(self, mock_get_pub_key): mock_get_pub_key.return_value = TEST_RSA_PRIVATE_KEY.public_key() image_properties = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: 'SHA-256', KEY_TYPE: 'BLAH', SIGNATURE: 'BLAH'} self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.get_verifier, None, image_properties) @mock.patch('nova.signature_utils.get_public_key') def test_get_verifier_none(self, mock_get_pub_key): mock_get_pub_key.return_value = BadPublicKey() image_properties = {CERT_UUID: 'fea14bc2-d75f-4ba5-bccc-b5c924ad0693', HASH_METHOD: 'SHA-256', KEY_TYPE: 'RSA-PSS', SIGNATURE: 'BLAH'} self.assertRaisesRegex(exception.SignatureVerificationError, 'Error occurred while verifying' ' the signature', signature_utils.get_verifier, None, image_properties) def test_get_signature(self): signature = b'A' * 256 data = base64.b64encode(signature) self.assertEqual(signature, signature_utils.get_signature(data)) def test_get_signature_fail(self): self.assertRaisesRegex(exception.SignatureVerificationError, 'The signature data was not properly' ' encoded using base64', signature_utils.get_signature, '///') def test_get_hash_method(self): hash_dict = signature_utils.HASH_METHODS for hash_name in hash_dict.keys(): hash_class = signature_utils.get_hash_method(hash_name).__class__ self.assertIsInstance(hash_dict[hash_name], hash_class) def test_get_hash_method_fail(self): self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature hash method: .*', signature_utils.get_hash_method, 'SHA-2') def test_get_signature_key_type(self): for sig_format in signature_utils.SIGNATURE_KEY_TYPES: result = signature_utils.get_signature_key_type(sig_format) self.assertEqual(sig_format, result) def test_get_signature_key_type_fail(self): self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid signature key type: .*', signature_utils.get_signature_key_type, 'RSB-PSS') @mock.patch('nova.signature_utils.get_certificate') def test_get_public_key_rsa(self, mock_get_cert): fake_cert = FakeCryptoCertificate() mock_get_cert.return_value = fake_cert result_pub_key = signature_utils.get_public_key(None, None, 'RSA-PSS') self.assertEqual(fake_cert.public_key(), result_pub_key) @mock.patch('nova.signature_utils.get_certificate') def test_get_public_key_ecc(self, mock_get_cert): fake_cert = FakeCryptoCertificate(TEST_ECC_PRIVATE_KEY.public_key()) mock_get_cert.return_value = fake_cert result_pub_key = signature_utils.get_public_key(None, None, 'ECC_SECP521R1') self.assertEqual(fake_cert.public_key(), result_pub_key) @mock.patch('nova.signature_utils.get_certificate') def test_get_public_key_dsa(self, mock_get_cert): fake_cert = FakeCryptoCertificate(TEST_DSA_PRIVATE_KEY.public_key()) mock_get_cert.return_value = fake_cert result_pub_key = signature_utils.get_public_key(None, None, 'DSA') self.assertEqual(fake_cert.public_key(), result_pub_key) @mock.patch('nova.signature_utils.get_certificate') def test_get_public_key_invalid_key(self, mock_get_certificate): bad_pub_key = 'A' * 256 mock_get_certificate.return_value = FakeCryptoCertificate(bad_pub_key) self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid public key type for ' 'signature key type: .*', signature_utils.get_public_key, None, None, 'RSA-PSS') @mock.patch('cryptography.x509.load_der_x509_certificate') @mock.patch('castellan.key_manager.API', return_value=FakeKeyManager()) def test_get_certificate(self, mock_key_manager_API, mock_load_cert): cert_uuid = 'valid_format_cert' x509_cert = FakeCryptoCertificate() mock_load_cert.return_value = x509_cert self.assertEqual(x509_cert, signature_utils.get_certificate(None, cert_uuid)) @mock.patch('cryptography.x509.load_der_x509_certificate') @mock.patch('castellan.key_manager.API', return_value=FakeKeyManager()) def test_get_expired_certificate(self, mock_key_manager_API, mock_load_cert): cert_uuid = 'valid_format_cert' x509_cert = FakeCryptoCertificate( not_valid_after=timeutils.utcnow() - datetime.timedelta(hours=1)) mock_load_cert.return_value = x509_cert self.assertRaisesRegex(exception.SignatureVerificationError, 'Certificate is not valid after: .*', signature_utils.get_certificate, None, cert_uuid) @mock.patch('cryptography.x509.load_der_x509_certificate') @mock.patch('castellan.key_manager.API', return_value=FakeKeyManager()) def test_get_not_yet_valid_certificate(self, mock_key_manager_API, mock_load_cert): cert_uuid = 'valid_format_cert' x509_cert = FakeCryptoCertificate( not_valid_before=timeutils.utcnow() + datetime.timedelta(hours=1)) mock_load_cert.return_value = x509_cert self.assertRaisesRegex(exception.SignatureVerificationError, 'Certificate is not valid before: .*', signature_utils.get_certificate, None, cert_uuid) @mock.patch('castellan.key_manager.API', return_value=FakeKeyManager()) def test_get_certificate_key_manager_fail(self, mock_key_manager_API): bad_cert_uuid = 'fea14bc2-d75f-4ba5-bccc-b5c924ad0695' self.assertRaisesRegex(exception.SignatureVerificationError, 'Unable to retrieve certificate with ID: .*', signature_utils.get_certificate, None, bad_cert_uuid) @mock.patch('castellan.key_manager.API', return_value=FakeKeyManager()) def test_get_certificate_invalid_format(self, mock_API): cert_uuid = 'invalid_format_cert' self.assertRaisesRegex(exception.SignatureVerificationError, 'Invalid certificate format: .*', signature_utils.get_certificate, None, cert_uuid) ",,383,0
openstack%2Ffuel-library~master~I5e440f50da20ef26fca22a34df98864925f8211e,openstack/fuel-library,master,I5e440f50da20ef26fca22a34df98864925f8211e,Combine Heat-engine OCF scripts for Ubuntu & Centos into one common,MERGED,2015-12-09 10:02:59.000000000,2015-12-11 16:06:55.000000000,2015-12-11 16:06:08.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 12559}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13752}, {'_account_id': 14007}, {'_account_id': 14525}, {'_account_id': 14985}, {'_account_id': 18795}]","[{'number': 1, 'created': '2015-12-09 10:02:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d741793ceb5a0efc0d702882ed36ccd0ea39f2aa', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patches removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 2, 'created': '2015-12-09 14:46:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3d24e81b15c0ceb1c152d60f316fb758989d3bdb', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patches removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 3, 'created': '2015-12-10 10:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/7ea061bccf42e3922b48384ef437c7689a3a1011', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 4, 'created': '2015-12-10 12:39:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/4fba2f435b58f66c047021810850956d033a53b6', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 5, 'created': '2015-12-10 16:14:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/af5a2b4dbde1e8ab79cef9b466937cb42af34d67', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 6, 'created': '2015-12-10 17:52:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/49e01ff1f979657d006cefe19a800de1239d93b0', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 7, 'created': '2015-12-11 09:41:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9eca82f2ffb96391f9e0723d69fa198071730502', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}, {'number': 8, 'created': '2015-12-11 13:29:32.000000000', 'files': ['files/fuel-ha-utils/ocf/heat-engine', 'deployment/puppet/heat_ha/manifests/engine.pp', 'debian/rules', 'files/fuel-ha-utils/ocf/heat_engine_centos', 'specs/fuel-library8.0.spec'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/f2326bb68b1985ec8c1454c1447d35f12f1c321f', 'message': 'Combine Heat-engine OCF scripts for Ubuntu & Centos into one common\n\nCurrently we have two ocf scripts for Heat-engine: for ubuntu and\ncentos. This patch removes this separation and combines into\none common OCF script.\n\nChange-Id: I5e440f50da20ef26fca22a34df98864925f8211e\nCloses-bug: #1378032\n'}]",11,255176,f2326bb68b1985ec8c1454c1447d35f12f1c321f,124,19,8,7745,,,0,"Combine Heat-engine OCF scripts for Ubuntu & Centos into one common

Currently we have two ocf scripts for Heat-engine: for ubuntu and
centos. This patch removes this separation and combines into
one common OCF script.

Change-Id: I5e440f50da20ef26fca22a34df98864925f8211e
Closes-bug: #1378032
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/76/255176/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/heat_ha/manifests/engine.pp', 'debian/rules', 'files/fuel-ha-utils/ocf/heat_engine', 'files/fuel-ha-utils/ocf/heat_engine_centos', 'specs/fuel-library8.0.spec']",5,d741793ceb5a0efc0d702882ed36ccd0ea39f2aa,bug/1378032,install -m 0755 %{files_source}/fuel-ha-utils/ocf/heat_engine %{buildroot}/usr/lib/ocf/resource.d/fuel/heat-engine,install -m 0755 %{files_source}/fuel-ha-utils/ocf/heat_engine_centos %{buildroot}/usr/lib/ocf/resource.d/fuel/heat-engine,8,332
openstack%2Fpython-fuelclient~master~I389915775c97596c2bc36ed82799e392494d55ff,openstack/python-fuelclient,master,I389915775c97596c2bc36ed82799e392494d55ff,Fix functional tests,MERGED,2015-11-26 10:08:24.000000000,2015-12-11 16:05:30.000000000,2015-12-11 16:04:46.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8749}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 9377}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 15454}, {'_account_id': 18520}]","[{'number': 1, 'created': '2015-11-26 10:08:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/c3156b8cb4b2a5b6cfb743a10afd37b8e2eca933', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}, {'number': 2, 'created': '2015-12-04 09:35:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/5f1539d02e946c12c87b9e71fd73c5f156d21d1f', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}, {'number': 3, 'created': '2015-12-10 18:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/ac8b2a4265b5bb8a006131c8167ebb252fb5e640', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}, {'number': 4, 'created': '2015-12-11 08:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/26a5e967683754360d42b26801c2f7b0ebc9c051', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}, {'number': 5, 'created': '2015-12-11 13:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/f5d5408fcac23c7f7e830dd35c89961493a11b87', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}, {'number': 6, 'created': '2015-12-11 13:23:11.000000000', 'files': ['fuelclient/tests/functional/v1/test_client.py', 'fuelclient/tests/functional/base.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/07e5fb8cbed222252caa74b32953fa162053ac9d', 'message': 'Fix functional tests\n\nthe patch fixes tox.ini to run functional tests properly.\nSince a few tests were broken, the patch fixes them as well.\n\nChange-Id: I389915775c97596c2bc36ed82799e392494d55ff\nCloses-bug: #1517948\n'}]",11,250272,07e5fb8cbed222252caa74b32953fa162053ac9d,47,13,6,6623,,,0,"Fix functional tests

the patch fixes tox.ini to run functional tests properly.
Since a few tests were broken, the patch fixes them as well.

Change-Id: I389915775c97596c2bc36ed82799e392494d55ff
Closes-bug: #1517948
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/72/250272/3 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/tests/functional/v1/test_client.py', 'tox.ini']",2,c3156b8cb4b2a5b6cfb743a10afd37b8e2eca933,bug/1517948," bash -c ""OS_TEST_PATH={posargs:./fuelclient/tests/unit} python setup.py test --slowest"" bash -c ""OS_TEST_PATH={posargs:./fuelclient/tests/functional} python setup.py test --slowest"" bash -c ""OS_TEST_PATH={posargs:./fuelclient/tests/unit} python setup.py testr --coverage"""," bash -c ""TESTS_DIR={posargs:./fuelclient/tests/unit} python setup.py test --slowest"" bash -c ""TESTS_DIR={posargs:./fuelclient/tests/functional} python setup.py test --slowest"" bash -c ""TESTS_DIR={posargs:./fuelclient/tests/unit} python setup.py testr --coverage""",5,5
openstack%2Ftraining-labs~master~Ia48f97cdaac85edc367e1f9157d2154745220f01,openstack/training-labs,master,Ia48f97cdaac85edc367e1f9157d2154745220f01,Update README with new network addresses.,MERGED,2015-12-10 16:53:40.000000000,2015-12-11 16:03:22.000000000,2015-12-11 16:03:21.000000000,"[{'_account_id': 3}, {'_account_id': 7007}, {'_account_id': 11109}]","[{'number': 1, 'created': '2015-12-10 16:53:40.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/fad1106da88661204e896d1cbe6e3d334b9cf21c', 'message': 'Update README with new network addresses.\n\nChange-Id: Ia48f97cdaac85edc367e1f9157d2154745220f01\n'}]",0,255985,fad1106da88661204e896d1cbe6e3d334b9cf21c,6,3,1,7007,,,0,"Update README with new network addresses.

Change-Id: Ia48f97cdaac85edc367e1f9157d2154745220f01
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/85/255985/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,fad1106da88661204e896d1cbe6e3d334b9cf21c,, $ ssh osbash@10.0.0.11 $ ssh osbash@10.0.0.21 $ ssh osbash@10.0.0.31, $ ssh osbash@10.10.10.51 $ ssh osbash@10.10.10.52 $ ssh osbash@10.10.10.53,3,3
openstack%2Fnetworking-ovn~master~I3d71742c90f1355c55bc66e5a3cfb3cff12a09e2,openstack/networking-ovn,master,I3d71742c90f1355c55bc66e5a3cfb3cff12a09e2,Add in constants for ACL actions,MERGED,2015-12-11 07:16:19.000000000,2015-12-11 16:03:05.000000000,2015-12-11 16:03:04.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-12-11 07:16:19.000000000', 'files': ['networking_ovn/common/constants.py', 'networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/86659bc8042283435428ebaa053117dd64aad79c', 'message': 'Add in constants for ACL actions\n\nProvide constants for the ACL actions. The supported actions are:\ndrop, allow and allow-related\n\nChange-Id: I3d71742c90f1355c55bc66e5a3cfb3cff12a09e2\n'}]",0,256253,86659bc8042283435428ebaa053117dd64aad79c,7,3,1,1653,,,0,"Add in constants for ACL actions

Provide constants for the ACL actions. The supported actions are:
drop, allow and allow-related

Change-Id: I3d71742c90f1355c55bc66e5a3cfb3cff12a09e2
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/53/256253/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/constants.py', 'networking_ovn/plugin.py']",2,86659bc8042283435428ebaa053117dd64aad79c,miaw-action-constants," action=ovn_const.ACL_ACTION_ALLOW_RELATED, action=ovn_const.ACL_ACTION_ALLOW, action=ovn_const.ACL_ACTION_DROP,"," action='allow-related', action='allow', action='drop',",7,3
openstack%2Ffuel-agent~master~Id70853ab7667b525eb78d755678c70ac76f63ef2,openstack/fuel-agent,master,Id70853ab7667b525eb78d755678c70ac76f63ef2,test,ABANDONED,2015-12-11 15:17:49.000000000,2015-12-11 16:02:12.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-12-11 15:17:49.000000000', 'files': ['debian/fuel-agent.install'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/9d5b571b6e56ae16ecc414f017bf5d5a24caa2ee', 'message': 'test\n\nChange-Id: Id70853ab7667b525eb78d755678c70ac76f63ef2\n'}]",0,256472,9d5b571b6e56ae16ecc414f017bf5d5a24caa2ee,3,1,1,10288,,,0,"test

Change-Id: Id70853ab7667b525eb78d755678c70ac76f63ef2
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/72/256472/1 && git format-patch -1 --stdout FETCH_HEAD,['debian/fuel-agent.install'],1,9d5b571b6e56ae16ecc414f017bf5d5a24caa2ee,,etc/fuel-agent/fuel-agent.conf.sample etc/fuel-agent/fuel-agent.conf,,1,0
openstack%2Fnetworking-ovn~master~I716787e737fb9b95c7562d2409cac7b26a76cd90,openstack/networking-ovn,master,I716787e737fb9b95c7562d2409cac7b26a76cd90,Move ACL_* definitions to the constants file,MERGED,2015-12-10 08:20:40.000000000,2015-12-11 16:01:36.000000000,2015-12-11 16:01:35.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 1561}, {'_account_id': 1653}, {'_account_id': 2874}, {'_account_id': 4395}, {'_account_id': 11343}]","[{'number': 1, 'created': '2015-12-10 08:20:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c9c2e7436e8579f5a9597b951a3af4c0d2c8fe73', 'message': 'Move ACL_* definitions to the constants file\n\nHave all of the constants in the same file.\n\nTrivialFix\n\nChange-Id: I716787e737fb9b95c7562d2409cac7b26a76cd90\n'}, {'number': 2, 'created': '2015-12-10 16:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f4dd8a702e524d4a736230d6558f7a50cfc637cd', 'message': 'Move ACL_* definitions to the constants file\n\nHave all of the constants in the same file.\n\nTrivialFix\n\nChange-Id: I716787e737fb9b95c7562d2409cac7b26a76cd90\n'}, {'number': 3, 'created': '2015-12-11 06:13:05.000000000', 'files': ['networking_ovn/common/constants.py', 'networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/2f64afae6f5644e9a4f213358b2872e6482be528', 'message': 'Move ACL_* definitions to the constants file\n\nHave all of the constants in the same file.\n\nTrivialFix\n\nChange-Id: I716787e737fb9b95c7562d2409cac7b26a76cd90\n'}]",2,255716,2f64afae6f5644e9a4f213358b2872e6482be528,21,7,3,1653,,,0,"Move ACL_* definitions to the constants file

Have all of the constants in the same file.

TrivialFix

Change-Id: I716787e737fb9b95c7562d2409cac7b26a76cd90
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/16/255716/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/common/constants.py', 'networking_ovn/plugin.py']",2,c9c2e7436e8579f5a9597b951a3af4c0d2c8fe73,does," priority=ovn_const.ACL_PRIORITY_ALLOW, priority=ovn_const.ACL_PRIORITY_ALLOW, priority=ovn_const.ACL_PRIORITY_DROP,","# OVN ACLs have priorities. The highest priority ACL that matches is the one # that takes effect. Our choice of priority numbers is arbitrary, but it # leaves room above and below the ACLs we create. We only need two priorities. # The first is for all the things we allow. The second is for dropping traffic # by default. ACL_PRIORITY_ALLOW = 1002 ACL_PRIORITY_DROP = 1001 priority=ACL_PRIORITY_ALLOW, priority=ACL_PRIORITY_ALLOW, priority=ACL_PRIORITY_DROP,",11,13
openstack%2Fmurano-apps~stable%2Fkilo~I287cdbed1c3b8f8bad0a80219e108f445ad409b3,openstack/murano-apps,stable/kilo,I287cdbed1c3b8f8bad0a80219e108f445ad409b3,[Docker] Pod (RC) scaling was fixed,MERGED,2015-12-10 10:17:24.000000000,2015-12-11 16:00:07.000000000,2015-12-11 16:00:05.000000000,"[{'_account_id': 3}, {'_account_id': 7549}, {'_account_id': 8127}, {'_account_id': 8731}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-10 10:17:24.000000000', 'files': ['Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Resources/ScaleRc.template'], 'web_link': 'https://opendev.org/openstack/murano-apps/commit/4f9297e93ef02edc3c91bfcb71cc72865e21e71d', 'message': '[Docker] Pod (RC) scaling was fixed\n\nChange-Id: I287cdbed1c3b8f8bad0a80219e108f445ad409b3\nCloses-Bug: #1504644\n(cherry picked from commit 5578c47b52f586214a6c88a28aae18fc27461801)\n'}]",0,255773,4f9297e93ef02edc3c91bfcb71cc72865e21e71d,10,7,1,7226,,,0,"[Docker] Pod (RC) scaling was fixed

Change-Id: I287cdbed1c3b8f8bad0a80219e108f445ad409b3
Closes-Bug: #1504644
(cherry picked from commit 5578c47b52f586214a6c88a28aae18fc27461801)
",git fetch https://review.opendev.org/openstack/murano-apps refs/changes/73/255773/1 && git format-patch -1 --stdout FETCH_HEAD,"['Docker/Kubernetes/KubernetesCluster/package/Classes/KubernetesCluster.yaml', 'Docker/Kubernetes/KubernetesCluster/package/Resources/ScaleRc.template']",2,4f9297e93ef02edc3c91bfcb71cc72865e21e71d,," return scaleRc('{0} {1}'.format(args.rcName, args.newSize)).stdout"," return scaleRc('{0} {1}'.format(args.rcName, args.newSize).stdout",2,1
openstack%2Fnova~master~Id1f52745ed8852840017667ed462d0a78d9feacc,openstack/nova,master,Id1f52745ed8852840017667ed462d0a78d9feacc,WIP: determine log serial output failure,ABANDONED,2015-10-19 18:42:57.000000000,2015-12-11 15:55:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 8871}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10635}, {'_account_id': 15751}, {'_account_id': 16376}]","[{'number': 1, 'created': '2015-10-19 18:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d05eac8b829e4f5a6c5e1472023a036ec8b2c8b5', 'message': 'WIP: determine log serial output failure\n\nChange-Id: Id1f52745ed8852840017667ed462d0a78d9feacc\n'}, {'number': 2, 'created': '2015-10-19 21:52:02.000000000', 'files': ['nova/virt/hyperv/vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6df7be0090fc7c1fe07a58c611ac2f23900b916b', 'message': 'WIP: determine log serial output failure\n\nChange-Id: Id1f52745ed8852840017667ed462d0a78d9feacc\n'}]",0,237133,6df7be0090fc7c1fe07a58c611ac2f23900b916b,33,10,2,8213,,,0,"WIP: determine log serial output failure

Change-Id: Id1f52745ed8852840017667ed462d0a78d9feacc
",git fetch https://review.opendev.org/openstack/nova refs/changes/33/237133/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/hyperv/vmops.py'],1,d05eac8b829e4f5a6c5e1472023a036ec8b2c8b5,, # log_serial_output(), log_serial_output(),1,1
openstack%2Fmurano-deployment~master~Icf546cfd941be7ab38071dd5ffbb443ba617582b,openstack/murano-deployment,master,Icf546cfd941be7ab38071dd5ffbb443ba617582b,WIP,ABANDONED,2015-12-01 14:22:55.000000000,2015-12-11 15:55:47.000000000,,"[{'_account_id': 3}, {'_account_id': 7821}, {'_account_id': 13962}]","[{'number': 1, 'created': '2015-12-01 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/597b7eab0d005e98c42be399805202dafbb4bf12', 'message': 'WIP\n\nChange-Id: Icf546cfd941be7ab38071dd5ffbb443ba617582b\n'}, {'number': 2, 'created': '2015-12-01 14:23:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/ff589348411dd9c3ce46e499f1fe38258df5d226', 'message': 'WIP\n\nChange-Id: Icf546cfd941be7ab38071dd5ffbb443ba617582b\n'}, {'number': 3, 'created': '2015-12-11 15:55:31.000000000', 'files': ['test.txt'], 'web_link': 'https://opendev.org/openstack/murano-deployment/commit/bc43cab7f675a42ee8829876534834473405044b', 'message': 'WIP\n\nChange-Id: Icf546cfd941be7ab38071dd5ffbb443ba617582b\n'}]",0,251887,bc43cab7f675a42ee8829876534834473405044b,10,3,3,13962,,,0,"WIP

Change-Id: Icf546cfd941be7ab38071dd5ffbb443ba617582b
",git fetch https://review.opendev.org/openstack/murano-deployment refs/changes/87/251887/3 && git format-patch -1 --stdout FETCH_HEAD,['test.txt'],1,597b7eab0d005e98c42be399805202dafbb4bf12,,test ,,1,0
openstack%2Fcinder~master~Ia8908941d5619d8c79fa7373c63ff37725fcc4f5,openstack/cinder,master,Ia8908941d5619d8c79fa7373c63ff37725fcc4f5,Use wild card for passing env variable,MERGED,2015-12-10 15:44:00.000000000,2015-12-11 15:53:01.000000000,2015-12-11 02:06:43.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 13394}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14865}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16422}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 17275}, {'_account_id': 17405}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18479}, {'_account_id': 18752}, {'_account_id': 19146}, {'_account_id': 19191}]","[{'number': 1, 'created': '2015-12-10 15:44:00.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder/commit/2c38caefb5ef10714bb3cae594ce7f1aad3adbc3', 'message': 'Use wild card for passing env variable\n\nChange-Id: Ia8908941d5619d8c79fa7373c63ff37725fcc4f5\n'}]",0,255943,2c38caefb5ef10714bb3cae594ce7f1aad3adbc3,40,34,1,17120,,,0,"Use wild card for passing env variable

Change-Id: Ia8908941d5619d8c79fa7373c63ff37725fcc4f5
",git fetch https://review.opendev.org/openstack/cinder refs/changes/43/255943/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2c38caefb5ef10714bb3cae594ce7f1aad3adbc3,,passenv = *_proxy *_PROXY,passenv = http_proxy HTTP_PROXY https_proxy HTTPS_PROXY no_proxy NO_PROXY,1,1
openstack%2Fmonasca-agent~master~I9ac209e0d891b78d445d298485c8ce4484781493,openstack/monasca-agent,master,I9ac209e0d891b78d445d298485c8ce4484781493,Change last of the URLs from stackforge to openstack,MERGED,2015-12-10 23:27:39.000000000,2015-12-11 15:52:36.000000000,2015-12-11 15:52:34.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 8126}, {'_account_id': 11809}, {'_account_id': 12443}, {'_account_id': 15027}, {'_account_id': 16237}, {'_account_id': 18179}]","[{'number': 1, 'created': '2015-12-10 23:27:39.000000000', 'files': ['mkdocs.yml', 'docs/Customizations.md', 'conf.d/http_check.yaml.example', 'conf.d/http_metrics.yaml.example', 'docs/MonascaMetrics.md', 'docs/Plugins.md', 'docs/Agent.md', 'setup.cfg', 'README.md', 'docs/index.md'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/0a62b8ef33710716dfc69914deb1eb36466f139e', 'message': 'Change last of the URLs from stackforge to openstack\n\nChange stackforge to openstack. Fix a couple of typos in the\nrest of the URLs as well\n\nChange-Id: I9ac209e0d891b78d445d298485c8ce4484781493\n'}]",2,256135,0a62b8ef33710716dfc69914deb1eb36466f139e,11,8,1,11809,,,0,"Change last of the URLs from stackforge to openstack

Change stackforge to openstack. Fix a couple of typos in the
rest of the URLs as well

Change-Id: I9ac209e0d891b78d445d298485c8ce4484781493
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/35/256135/1 && git format-patch -1 --stdout FETCH_HEAD,"['mkdocs.yml', 'docs/Customizations.md', 'conf.d/http_check.yaml.example', 'conf.d/http_metrics.yaml.example', 'docs/MonascaMetrics.md', 'docs/Plugins.md', 'docs/Agent.md', 'setup.cfg', 'README.md', 'docs/index.md']",10,0a62b8ef33710716dfc69914deb1eb36466f139e,,Please refer to the [project readme](https://github.com/openstack/monasca-agent) for Agent documentation. repo_url: https://github.com/openstack/monasca-agent,Please refer to the [project readme](https://github.com/stackforge/monasca-agent) for Agent documentation. repo_url: https://github.com/stackforge/monasca-agent,18,18
openstack%2Ffuel-web~master~Iccd97278d9d870ec727a75e57c4db78ee75eeb38,openstack/fuel-web,master,Iccd97278d9d870ec727a75e57c4db78ee75eeb38,Raise an error if trying to delete already deleted config,MERGED,2015-12-07 15:33:11.000000000,2015-12-11 15:52:11.000000000,2015-12-11 15:35:16.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8829}, {'_account_id': 8971}, {'_account_id': 9377}, {'_account_id': 10391}, {'_account_id': 10443}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 11898}]","[{'number': 1, 'created': '2015-12-07 15:33:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/76ef36ce190cd56352f64d7c14d0b4dafe34b45c', 'message': 'Raise an error if trying to delete already deleted config\n\nAdd check to restrict attepmpt to delete openstack configuration\nthat has been already deleted.\n\nCloses-Bug: #1523431\nChange-Id: Iccd97278d9d870ec727a75e57c4db78ee75eeb38\n'}, {'number': 2, 'created': '2015-12-08 09:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/f40033fef90a432911161dbc6856019fa7ef4486', 'message': 'Raise an error if trying to delete already deleted config\n\nAdd check to restrict attepmpt to delete openstack configuration\nthat has been already deleted.\n\nCloses-Bug: #1523431\nChange-Id: Iccd97278d9d870ec727a75e57c4db78ee75eeb38\n'}, {'number': 3, 'created': '2015-12-08 10:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/721a9e0cf005fa263ab8d24f7fb4dcb152bee422', 'message': 'Raise an error if trying to delete already deleted config\n\nAdd check to restrict attepmpt to delete openstack configuration\nthat has been already deleted.\n\nCloses-Bug: #1523431\nChange-Id: Iccd97278d9d870ec727a75e57c4db78ee75eeb38\n'}, {'number': 4, 'created': '2015-12-10 15:44:48.000000000', 'files': ['nailgun/nailgun/objects/openstack_config.py', 'nailgun/nailgun/api/v1/handlers/openstack_config.py', 'nailgun/nailgun/test/unit/test_openstack_config_handler.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/31c476e35c45213174424e01482a52bbea5710f3', 'message': 'Raise an error if trying to delete already deleted config\n\nAdd check to restrict attepmpt to delete openstack configuration\nthat has been already deleted.\n\nCloses-Bug: #1523431\nChange-Id: Iccd97278d9d870ec727a75e57c4db78ee75eeb38\n'}]",7,254255,31c476e35c45213174424e01482a52bbea5710f3,43,10,4,11898,,,0,"Raise an error if trying to delete already deleted config

Add check to restrict attepmpt to delete openstack configuration
that has been already deleted.

Closes-Bug: #1523431
Change-Id: Iccd97278d9d870ec727a75e57c4db78ee75eeb38
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/55/254255/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/api/v1/handlers/openstack_config.py', 'nailgun/nailgun/objects/openstack_config.py', 'nailgun/nailgun/test/unit/test_openstack_config_handler.py']",3,76ef36ce190cd56352f64d7c14d0b4dafe34b45c,bug/1523431," obj_id = self.configs[0].id {'obj_id': obj_id}), {'obj_id': obj_id}), # Try delete already deleted object resp = self.app.delete( reverse('OpenstackConfigHandler', {'obj_id': obj_id}), headers=self.default_headers, expect_errors=True) self.assertEqual(resp.status_code, 400) self.assertEqual( resp.json_body['message'], ""Configuration '{0}' has been already deleted."".format(obj_id)) "," {'obj_id': self.configs[0].id}), {'obj_id': self.configs[0].id}),",46,3
openstack%2Fhorizon~master~I5e42a3b25aae89e62e20e8061b39c7be700aba33,openstack/horizon,master,I5e42a3b25aae89e62e20e8061b39c7be700aba33,Delete the unused LOG configure code,MERGED,2015-09-12 06:31:22.000000000,2015-12-11 15:46:26.000000000,2015-12-11 15:46:24.000000000,"[{'_account_id': 3}, {'_account_id': 841}, {'_account_id': 6610}, {'_account_id': 6763}, {'_account_id': 6914}, {'_account_id': 9981}, {'_account_id': 10442}, {'_account_id': 12281}, {'_account_id': 12826}, {'_account_id': 16707}, {'_account_id': 17130}, {'_account_id': 17172}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-09-12 06:31:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/58226b0caa57ec4a20ea34419109942cdd36fd86', 'message': 'Delete the unused LOG configure code\n\nDelete the unused LOG configure code and import code\n\nChange-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33\n'}, {'number': 2, 'created': '2015-09-12 07:21:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/39b993485c0b4d1fd456ee89a69bdda9d195df24', 'message': 'Delete the unused LOG configure code\n\nDelete the unused LOG configure code and import code\n\nChange-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33\n'}, {'number': 3, 'created': '2015-12-09 03:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/efedb812de536a72eb80cf44708341984fdb7c1a', 'message': 'Delete the unused LOG configure code\n\nDelete the unused LOG configure code and import code\n\nChange-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33\n'}, {'number': 4, 'created': '2015-12-09 03:50:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/773b7f58162afbda1083b74278903ddbc20f52c7', 'message': 'Delete the unused LOG configure code\n\nDelete the unused LOG configure code and import code\n\nChange-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33\n'}, {'number': 5, 'created': '2015-12-09 07:05:03.000000000', 'files': ['openstack_dashboard/dashboards/project/routers/extensions/extraroutes/views.py', 'openstack_dashboard/dashboards/admin/metadata_defs/forms.py', 'openstack_dashboard/dashboards/admin/networks/agents/forms.py', 'openstack_dashboard/dashboards/project/routers/extensions/routerrules/tables.py', 'openstack_dashboard/api/ceilometer.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/dashboards/admin/metering/views.py', 'openstack_dashboard/api/heat.py', 'openstack_dashboard/dashboards/project/routers/extensions/routerrules/views.py', 'openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/api/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4636bf18d7198380485f90bd871484ad48ebe618', 'message': 'Delete the unused LOG configure code\n\nDelete the unused LOG configure code and import code\n\nChange-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33\n'}]",0,222847,4636bf18d7198380485f90bd871484ad48ebe618,32,13,5,14107,,,0,"Delete the unused LOG configure code

Delete the unused LOG configure code and import code

Change-Id: I5e42a3b25aae89e62e20e8061b39c7be700aba33
",git fetch https://review.opendev.org/openstack/horizon refs/changes/47/222847/4 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/workflows/create.py', 'openstack_dashboard/dashboards/project/routers/extensions/routerrules/tables.py', 'openstack_dashboard/dashboards/admin/metering/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/job_executions/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_sources/workflows/edit.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_image_registry/tables.py', 'openstack_dashboard/dashboards/project/routers/extensions/routerrules/views.py', 'openstack_dashboard/dashboards/project/stacks/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/clusters/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/jobs/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/nodegroup_templates/workflows/edit.py', 'openstack_dashboard/dashboards/admin/networks/agents/forms.py', 'openstack_dashboard/contrib/sahara/content/data_processing/clusters/workflows/create.py', 'openstack_dashboard/contrib/sahara/content/data_processing/nodegroup_templates/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_sources/workflows/create.py', 'openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/workflows/edit.py', 'openstack_dashboard/contrib/sahara/content/data_processing/clusters/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/job_binaries/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/nodegroup_templates/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/workflows/copy.py', 'openstack_dashboard/dashboards/project/routers/extensions/extraroutes/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_image_registry/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_sources/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/jobs/workflows/launch.py', 'openstack_dashboard/api/ceilometer.py', 'openstack_dashboard/api/swift.py', 'openstack_dashboard/api/heat.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_sources/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/job_executions/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/nodegroup_templates/workflows/create.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_plugins/views.py', 'openstack_dashboard/contrib/sahara/content/data_processing/utils/anti_affinity.py', 'openstack_dashboard/contrib/sahara/content/data_processing/cluster_templates/forms.py', 'openstack_dashboard/contrib/sahara/content/data_processing/clusters/workflows/scale.py', 'openstack_dashboard/contrib/sahara/content/data_processing/nodegroup_templates/workflows/copy.py', 'openstack_dashboard/contrib/sahara/content/data_processing/job_binaries/tables.py', 'openstack_dashboard/contrib/sahara/content/data_processing/job_binaries/forms.py', 'openstack_dashboard/contrib/sahara/content/data_processing/jobs/views.py', 'openstack_dashboard/dashboards/admin/metadata_defs/forms.py', 'openstack_dashboard/contrib/sahara/content/data_processing/wizard/views.py', 'openstack_dashboard/contrib/trove/api/trove.py', 'openstack_dashboard/contrib/sahara/content/data_processing/data_plugins/tables.py', 'openstack_dashboard/contrib/sahara/api/sahara.py', 'openstack_dashboard/api/base.py', 'openstack_dashboard/contrib/sahara/content/data_processing/jobs/workflows/create.py']",47,58226b0caa57ec4a20ea34419109942cdd36fd86,delete_unused_LOG,,import loggingLOG = logging.getLogger(__name__) ,0,184
openstack%2Fpython-fuelclient~master~I5d9f5966da49cff1f034b17c1bbf8eafed758b31,openstack/python-fuelclient,master,I5d9f5966da49cff1f034b17c1bbf8eafed758b31,Add validataion for uploaded files,MERGED,2015-12-08 17:10:47.000000000,2015-12-11 15:44:28.000000000,2015-12-11 15:43:46.000000000,"[{'_account_id': 3}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8971}, {'_account_id': 9377}, {'_account_id': 11577}, {'_account_id': 11898}, {'_account_id': 14543}, {'_account_id': 15454}]","[{'number': 1, 'created': '2015-12-08 17:10:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/b2947fa698dce290b51d22fe46976cc22cba9e4f', 'message': 'Add validataion for uploaded files\n\nIf user upload yaml of json file, client should validate that file\nhas correct format.\n\nChange-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31\nCloses-bug: #1523130\n'}, {'number': 2, 'created': '2015-12-09 10:47:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/515532d26fe470325f345c282c97ae609658895c', 'message': 'Add validataion for uploaded files\n\nIf user upload yaml of json file, client should validate that file\nhas correct format.\n\nChange-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31\nCloses-bug: #1523130\n'}, {'number': 3, 'created': '2015-12-09 12:22:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/548f84b9a9ec7e6041fe73b2ce1c44fcade28ce0', 'message': 'Add validataion for uploaded files\n\nIf user upload yaml of json file, client should validate that file\nhas correct format.\n\nChange-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31\nCloses-bug: #1523130\n'}, {'number': 4, 'created': '2015-12-09 13:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/6bb528797eb1f313c18212a74d45469fd874b5ca', 'message': 'Add validataion for uploaded files\n\nIf user upload yaml of json file, client should validate that file\nhas correct format.\n\nChange-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31\nCloses-bug: #1523130\n'}, {'number': 5, 'created': '2015-12-09 16:31:41.000000000', 'files': ['fuelclient/cli/serializers.py', 'fuelclient/tests/unit/common/test_serializers.py', 'fuelclient/utils.py'], 'web_link': 'https://opendev.org/openstack/python-fuelclient/commit/563191bd7bcf86a0ff553d3f0cacf22885517653', 'message': 'Add validataion for uploaded files\n\nIf user upload yaml of json file, client should validate that file\nhas correct format.\n\nChange-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31\nCloses-bug: #1523130\n'}]",10,254875,563191bd7bcf86a0ff553d3f0cacf22885517653,36,9,5,9377,,,0,"Add validataion for uploaded files

If user upload yaml of json file, client should validate that file
has correct format.

Change-Id: I5d9f5966da49cff1f034b17c1bbf8eafed758b31
Closes-bug: #1523130
",git fetch https://review.opendev.org/openstack/python-fuelclient refs/changes/75/254875/4 && git format-patch -1 --stdout FETCH_HEAD,"['fuelclient/cli/serializers.py', 'fuelclient/tests/unit/common/test_serializers.py']",2,b2947fa698dce290b51d22fe46976cc22cba9e4f,bug/1523130," def test_deserialize_fail(self): broken_data = '{foo: bar: buzz:}' for format in ('json', 'yaml'): self.assertRaises(error.BadDataException, Serializer(format).deserialize, broken_data) ",,25,2
openstack%2Fcinder~master~I503102f1f6765cd1f3ec21a3db3960ce0fe1a8f7,openstack/cinder,master,I503102f1f6765cd1f3ec21a3db3960ce0fe1a8f7,VMAX unit tests improvement and cleanup,ABANDONED,2015-09-11 14:38:20.000000000,2015-12-11 15:41:10.000000000,,"[{'_account_id': 3}, {'_account_id': 2759}, {'_account_id': 6491}, {'_account_id': 9008}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 13628}, {'_account_id': 14206}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16595}, {'_account_id': 16862}, {'_account_id': 17492}, {'_account_id': 17852}]","[{'number': 1, 'created': '2015-09-11 14:38:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d9c10e7d64f4143bab919f5cb80eb7d475d15b1a', 'message': 'VMAX unit tests improvement and cleanup\n\n- Removal of unused methods and parameters.\n- Increase test coverage.\n- Refactoring of unit tests to remove the need to create xml before\n  every test.\n\nChange-Id: I503102f1f6765cd1f3ec21a3db3960ce0fe1a8f7\n'}, {'number': 2, 'created': '2015-09-14 02:55:52.000000000', 'files': ['cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_provision_v3.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/tests/unit/test_emc_vmax.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/5f3663d966922787c75810a3f1b1b4790558af44', 'message': 'VMAX unit tests improvement and cleanup\n\n- Removal of unused methods and parameters.\n- Increase test coverage.\n- Refactoring of unit tests to remove the need to create xml before\n  every test.\n\nChange-Id: I503102f1f6765cd1f3ec21a3db3960ce0fe1a8f7\n'}]",0,222635,5f3663d966922787c75810a3f1b1b4790558af44,57,26,2,6491,,,0,"VMAX unit tests improvement and cleanup

- Removal of unused methods and parameters.
- Increase test coverage.
- Refactoring of unit tests to remove the need to create xml before
  every test.

Change-Id: I503102f1f6765cd1f3ec21a3db3960ce0fe1a8f7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/35/222635/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/emc/emc_vmax_provision.py', 'cinder/volume/drivers/emc/emc_vmax_common.py', 'cinder/volume/drivers/emc/emc_vmax_utils.py', 'cinder/volume/drivers/emc/emc_vmax_masking.py', 'cinder/volume/drivers/emc/emc_vmax_provision_v3.py', 'cinder/volume/drivers/emc/emc_vmax_fast.py', 'cinder/tests/unit/test_emc_vmax.py']",7,d9c10e7d64f4143bab919f5cb80eb7d475d15b1a,vmax,"from cinder.volume.drivers.emc import emc_vmax_https def add_array_info(self, doc, emc, fastpolicy): array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) ecomserverip = doc.createElement(""EcomServerIp"") ecomserveriptext = doc.createTextNode(""1.1.1.1"") emc.appendChild(ecomserverip) ecomserverip.appendChild(ecomserveriptext) ecomserverport = doc.createElement(""EcomServerPort"") ecomserverporttext = doc.createTextNode(""10"") emc.appendChild(ecomserverport) ecomserverport.appendChild(ecomserverporttext) ecomusername = doc.createElement(""EcomUserName"") ecomusernametext = doc.createTextNode(""user"") emc.appendChild(ecomusername) ecomusername.appendChild(ecomusernametext) ecompassword = doc.createElement(""EcomPassword"") ecompasswordtext = doc.createTextNode(""pass"") emc.appendChild(ecompassword) ecompassword.appendChild(ecompasswordtext) portgroup = doc.createElement(""PortGroup"") portgrouptext = doc.createTextNode(self.port_group) portgroup.appendChild(portgrouptext) portgroups = doc.createElement(""PortGroups"") portgroups.appendChild(portgroup) emc.appendChild(portgroups) pool = doc.createElement(""Pool"") pooltext = doc.createTextNode(""gold"") emc.appendChild(pool) pool.appendChild(pooltext) array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) timeout = doc.createElement(""Timeout"") timeouttext = doc.createTextNode(""0"") emc.appendChild(timeout) timeout.appendChild(timeouttext) if fastpolicy: fp = doc.createElement(""FastPolicy"") fptext = doc.createTextNode(fastpolicy) emc.appendChild(fp) fp.appendChild(fptext) return doc WaitForCopyState=None, PolicyRule=None): result = self._assocnames_hostedservice(objectpath) result = self._assocnames_assoctierpolicy(objectpath) elif ResultClass == 'CIM_StoragePool': result = self._assocnames_storagepool(objectpath) elif ResultClass == 'EMC_VirtualProvisioningPool': result = self._assocnames_storagepool(objectpath) elif ResultClass == 'CIM_DeviceMaskingGroup': result = self._assocnames_storagegroup(objectpath) def _assocnames_hostedservice(self, objectpath): emptyList = [] if objectpath == 'bogus_configService': return emptyList elif objectpath: return self._enum_hostedservice() else: return emptyList def _assocnames_assoctierpolicy(self, objectpath): if objectpath == 'FirstStorageTierInstanceNames': firstTierPolicyName = {} result = firstTierPolicyName return result else: return self._enum_assoctierpolicy() def _assocnames_storagepool(self, objectpath): if objectpath == 'bogus_poolInstanceName': return [] else: return self._enum_storagepool() def _assocnames_storagegroup(self, objectpath): if objectpath == 'bogus_volumeInstanceName': result = [] return result elif objectpath == 'bogus2_volumeInstanceName': result = [{'InstanceID': 'test'}] return result elif objectpath == 'bogus3_volumeInstanceName': result = [{'InstanceID': 'OS_default_'}] return result else: return self._enum_storagegroup() def _assocnames_tierpolicy(self, objectpath): if objectpath == 'bogus_storageGroupInstanceName': return 'tierPolicyInstanceNames' if 'JobState' in jobpath and jobpath['JobState'] == 2: jobinstance['JobState'] = 2 if 'PercentSynced' in objectpath and objectpath['PercentSynced'] < 100: svInstance['PercentSynced'] = 50class HTTPResponse(object): def __init__(self): self.status = 200 def read(self): return None class Context(object): SSLv23_METHOD = 3 VERIFY_PEER = True VERIFY_FAIL_IF_NO_PEER_CERT = True VERIFY_NONE = True def __init__(self, m_method): self.m_method = m_method def set_verify(self, mode, callback): pass def use_certificate_file(self, cert_file): if cert_file == ""fake.crt"": raise AuthError(""test"") else: pass def use_privatekey_file(self, priv_key): if priv_key == ""fake.pk"": raise AuthError(""test"") elif priv_key is None: raise AuthError(""test"") else: pass def load_verify_locations(self, ca_certs): if ca_certs == ""fake.crt"": raise AuthError(""test"") else: pass def set_default_verify_paths(self): pass class AuthError(Exception): pass self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_no_fast(self, tempdir): doc = self.data.add_array_info(doc, emc, None) config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') def create_fake_config_file_1364232(self, tempdir): config_file_1364232 = tempdir + '/' + filename def fake_gather_info(self): return def default_extraspec(self): return {'storagetype:pool': u'gold', 'volume_backend_name': 'ISCSINoFAST', 'storagetype:fastpolicy': None, 'storagetype:compositetype': u'concatenated', 'storagetype:membercount': 1, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_no_fast(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = ( self.driver.common._initial_setup(self.data.test_volume_v2)) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual(None, extraSpecs['storagetype:fastpolicy']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) def test_get_volume_stats_1364232(self): tempdir = tempfile.mkdtemp() file_name = self.create_fake_config_file_1364232(tempdir) arrayInfo = self.driver.utils.parse_file_to_get_array_map(file_name) self.assertEqual( '000198700439', arrayInfo[0]['SerialNumber']) self.assertEqual( 'FC_SLVR1', arrayInfo[0]['PoolName']) self.assertEqual( 'SILVER1', arrayInfo[0]['FastPolicy']) self.assertTrue( 'OS-PORTGROUP' in arrayInfo[0]['PortGroup']) self._cleanup(tempdir, file_name) mock_capacity): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system): extraspecs = {'storagetype:pool': u'gold', 'volume_backend_name': 'ISCSINoFAST', 'storagetype:fastpolicy': None, 'storagetype:compositetype': u'striped', 'storagetype:membercount': 4, 'storagetype:stripecount': 4, 'array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} self.driver.common._initial_setup = mock.Mock( return_value=extraspecs) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_delete_volume_no_fast_notfound(self): keys['SystemCreationClassName'] = \ notfound_delete_vol['SystemCreationClassName'] self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) emc_vmax_utils.EMCVMAXUtils, 'wait_for_job_complete', return_value=(-1, 'error')) @mock.patch.object( self, mock_storage_system, mock_wait): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_already_mapped_fast_success( self, mock_wrap_group, mock_wrap_device, mock_is_same_host): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_wrap_group, mock_storage_group, mock_add_volume): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_wrap_group, mock_storage_group, mock_initiator_group, mock_ig_from_mv): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_group, mock_ig, mock_igc): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_volume_size): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_is_extendable): extraspecs = {'pool': u'gold', 'volume_backend_name': 'ISCSINoFAST', 'fastpolicy': None, 'internal_only:compositetype': u'striped', 'internal_only:membercount': 4, 'storagetype:stripecount': 4, 'array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} self.driver.common._initial_setup = mock.Mock( return_value=extraspecs) self, mock_volume, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_sync_sv, mock_meta, mock_size): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common.utils.wait_for_sync = mock.Mock(return_value=0) @mock.patch.object( emc_vmax_common.EMCVMAXCommon, '_validate_pool', return_value=('Bogus_Pool')) def test_create_volume_from_snapshot_no_fast_failed(self, mock_pool): self, mock_volume, mock_sync_sv, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) @mock.patch.object( emc_vmax_common.EMCVMAXCommon, '_validate_pool', return_value=('Bogus_Pool')) def test_create_clone_no_fast_failed(self, mock_pool): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_cloned_volume, self.data.test_volume, EMCVMAXCommonData.test_source_volume) self, mock_sync, mock_create_replica, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_migrate_volume_no_fast_success(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage, _mock_cg, _mock_members, _mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_volume, self.driver.common.utils.wait_for_sync = mock.Mock(return_value=0) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage, _mock_cg, _mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_fast(self, tempdir): doc = self.data.add_array_info(doc, emc, 'GOLD1') config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def default_extraspec(self): return {'storagetype:pool': u'gold', 'volume_backend_name': 'ISCSIFAST', 'storagetype:fastpolicy': 'GOLD1', 'storagetype:compositetype': u'concatenated', 'storagetype:membercount': 1, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_fast(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = ( self.driver.common._initial_setup(self.data.test_volume_v2)) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual('GOLD1', extraSpecs['storagetype:fastpolicy']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) self, mock_storage_system, mock_pool_policy): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system, mock_pool_policy): extraspecs = {'storagetype:pool': u'gold', 'volume_backend_name': 'ISCSIFAST', 'storagetype:fastpolicy': 'GOLD1', 'storagetype:compositetype': u'striped', 'storagetype:membercount': 4, 'storagetype:stripecount': 4, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} self.driver.common._initial_setup = mock.Mock( return_value=extraspecs) self, mock_storage_system, mock_pool_policy): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_group): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_wrapper): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) emc_vmax_utils.EMCVMAXUtils, 'wait_for_job_complete', return_value=(-1, 'error')) @mock.patch.object( self, _mock_storage_group, mock_storage_system, mock_policy_pool, mock_wait): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_wrap_group, mock_wrap_device, mock_is_same_host): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_group, mock_ig, mock_igc): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_volume_size): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_is_extendable): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_volume, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_sync_sv, mock_meta, mock_size): self.driver.common.utils.wait_for_sync = mock.Mock(return_value=0) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_rep_service, mock_sync_sv): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_vol, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_migrate_volume_fast_success(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_wrap): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage, _mock_cg, _mock_members, _mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_no_fast(self, tempdir): doc = self.data.add_array_info(doc, emc, None) config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def default_extraspec(self): return {'storagetype:pool': u'gold', 'volume_backend_name': 'FCNoFAST', 'storagetype:fastpolicy': None, 'storagetype:compositetype': u'concatenated', 'storagetype:membercount': 1, 'array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_no_fast(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = ( self.driver.common._initial_setup(self.data.test_volume_v2)) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual(None, extraSpecs['storagetype:fastpolicy']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system): extraspecs = {'storagetype:pool': u'gold', 'volume_backend_name': 'FCNoFAST', 'storagetype:fastpolicy': None, 'storagetype:compositetype': u'striped', 'storagetype:membercount': 4, 'storagetype:stripecount': 4, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} self.driver.common._initial_setup = mock.Mock( return_value=extraspecs) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_delete_volume_no_fast_notfound(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) emc_vmax_utils.EMCVMAXUtils, 'wait_for_job_complete', return_value=(-1, 'error')) @mock.patch.object( self, mock_storage_system, mock_wait): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_maskingview, mock_is_same_host): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_map_no_fast_failed(self, mock_wrap_device): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_mv, mock_ig, mock_igc): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_extend_volume_no_fast_success(self, _mock_volume_size): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_is_extendable): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_migrate_volume_no_fast_success(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_retype_volume_no_fast_success(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage, _mock_cg, _mock_members, _mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) common._initial_setup = mock.Mock( return_value=self.default_extraspec()) common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_fast(self, tempdir): doc = self.data.add_array_info(doc, emc, 'GOLD1') config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def default_extraspec(self): return {'storagetype:pool': u'gold', 'volume_backend_name': 'FCFAST', 'storagetype:fastpolicy': 'GOLD1', 'storagetype:compositetype': u'concatenated', 'storagetype:membercount': 1, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_fast(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = ( self.driver.common._initial_setup(self.data.test_volume_v2)) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual('GOLD1', extraSpecs['storagetype:fastpolicy']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) self, mock_storage_system, mock_pool_policy): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_storage_system, mock_pool_policy): extraspecs = {'storagetype:pool': u'gold', 'volume_backend_name': 'FCFAST', 'storagetype:fastpolicy': 'GOLD1', 'storagetype:compositetype': u'striped', 'storagetype:membercount': 4, 'storagetype:stripecount': 4, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} self.driver.common._initial_setup = mock.Mock( return_value=extraspecs) self, mock_storage_system, mock_pool_policy): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_delete_volume_fast_success(self, mock_storage_group): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_delete_volume_fast_notfound(self): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) emc_vmax_utils.EMCVMAXUtils, 'wait_for_job_complete', return_value=(-1, 'error')) @mock.patch.object( self, mock_wrapper, mock_storage_system, mock_pool_policy, mock_wait): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_map_fast_success(self, mock_maskingview, mock_is_same_host): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_map_fast_failed(self, mock_wrap_device): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_detach_fast_success(self, mock_maskingview, common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_extend_volume_fast_success(self, _mock_volume_size): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_volume, common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_sync_sv, mock_meta, mock_size): self.driver.common.utils.wait_for_sync = mock.Mock(return_value=0) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_rep_service, mock_sync_sv): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_vol, mock_policy, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_migrate_volume_fast_success(self): def test_retype_volume_fast_success(self, mock_wrap): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_create_snapshot_for_CG_fast_success( self, _mock_storage, _mock_cg, _mock_members, _mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_delete_snapshot_for_CG_fast_success( self, _mock_storage): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_create_clone_without_license_failed(self): self.driver.common.utils.find_replication_service_capabilities = ( self.driver.common.utils.is_clone_licensed = ( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_v3(self, tempdir): config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_v3(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = ( self.driver.common._initial_setup(self.data.test_volume_v3)) self.assertEqual('SRP_1', extraSpecs['storagetype:pool']) self.assertEqual('DSS', extraSpecs['storagetype:workload']) self.assertEqual('Bronze', extraSpecs['storagetype:slo']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertTrue(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.data.test_ctxt, self.data.test_CG) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_migrate_volume_v3_success(self): 'get_fast_settings_from_storage_group', self, mock_fast_settings, 'get_fast_settings_from_storage_group', self, mock_fast_settings): self, _mock_storage, _mock_cg, _mock_members, mock_rg): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, mock_maskingview, mock_is_same_host): def test_map_v3_failed(self, mock_wrap_device): def test_detach_v3_success(self, mock_maskingview, self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.data.test_volume, EMCVMAXCommonData.test_source_volume) extraSpecs = self.default_extraspec() pool = extraSpecs['storagetype:pool'] slo = extraSpecs['storagetype:slo'] workload = extraSpecs['storagetype:workload'] storageGroupName = common.utils.get_v3_storage_group_name(pool, slo, workload) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_multi_pool(self, tempdir): config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_pool(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = self.driver.common._initial_setup(self.vol_v2) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual(None, extraSpecs['storagetype:fastpolicy']) self.assertEqual('concatenated', extraSpecs['storagetype:compositetype']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_pool(tempdir) config_file_path) self._cleanup(tempdir, config_file_path) self, mock_storage_system): self, mock_storage_system): self, mock_storage_system): def test_retype_volume_multi_pool_success(self): self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_multi_slo_v3(self, tempdir): config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_slo_v3(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = self.driver.common._initial_setup(self.vol_v3) self.assertEqual('SRP_1', extraSpecs['storagetype:pool']) self.assertEqual('DSS', extraSpecs['storagetype:workload']) self.assertEqual('Bronze', extraSpecs['storagetype:slo']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertTrue(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_slo_v3(tempdir) config_file_path) self, mock_storage_system): self, mock_storage_system): self, mock_storage_system): 'get_fast_settings_from_storage_group', self, mock_fast_settings, self, _mock_storage_system): self, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) self, _mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) def setUp(self): self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) def create_fake_config_file_multi_ecom(self, tempdir): config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') return config_file_path def fake_gather_info(self): return def default_extraspec(self): return {'storagetype:pool': u'gold', 'volume_backend_name': 'MULTI_POOL_BE', 'storagetype:fastpolicy': None, 'storagetype:compositetype': u'concatenated', 'storagetype:membercount': 1, 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG'} def test_initial_setup(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_ecom(tempdir) self.driver.common._register_config_file_from_config_group = ( mock.Mock(return_value=config_file_path)) extraSpecs = self.driver.common._initial_setup(self.vol_v2) self.assertEqual('gold', extraSpecs['storagetype:pool']) self.assertEqual(None, extraSpecs['storagetype:fastpolicy']) self.assertEqual('1234567891011', extraSpecs['storagetype:array']) self.assertEqual('OS-portgroup-PG', extraSpecs['portgroupname']) self.assertFalse(extraSpecs['isV3']) self._cleanup(tempdir, config_file_path) def test_array_info_multi_ecom_no_fast(self): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_ecom(tempdir) config_file_path) self._cleanup(tempdir, config_file_path) tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_ecom(tempdir) config_file_path) self._cleanup(tempdir, config_file_path) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def test_create_cg_multiple_array_failure( self, _mock_volume_type, _mock_storage_system): tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_multi_ecom(tempdir) arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) self.driver.utils.extract_record, arrayInfo, None) self, mock_storage_system): self.driver.common._initial_setup = mock.Mock( return_value=self.default_extraspec()) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) class EMCVMAXUtilsTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXUtilsTest, self).setUp() configuration = mock.Mock() configuration.safe_get.return_value = 'UtilsTests' configuration.config_group = 'UtilsTests' self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_get_ecom_connection', self.fake_ecom_connection) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) instancename = FakeCIMInstanceName() self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'get_instance_name', instancename.fake_getinstancename) self.stubs.Set(time, 'sleep', self.fake_sleep) self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', self.fake_is_v3) driver = emc_vmax_iscsi.EMCVMAXISCSIDriver(configuration=configuration) driver.db = FakeDB() self.driver = driver self.driver.utils = emc_vmax_utils.EMCVMAXUtils(object) # self.driver.versioninfo = ( # emc_vmax_utils.EMCVMAXVersionInfo(self.driver.utils)) def create_fake_config_file_no_fast(self, tempdir): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.data.add_array_info(doc, emc, None) filename = 'cinder_emc_config_ISCSINoFAST.xml' config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def create_fake_config_file_no_fast_with_interval_retries(self, tempdir): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.data.add_array_info(doc, emc, None) doc = self.add_interval_and_retries(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST.xml' config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def create_fake_config_file_no_fast_with_interval(self, tempdir): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.data.add_array_info(doc, emc, None) doc = self.add_interval_only(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST.xml' config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def create_fake_config_file_no_fast_with_retries(self, tempdir): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.data.add_array_info(doc, emc, None) doc = self.add_retries_only(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST.xml' config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def create_fake_config_file_no_fast_with_add_ons(self, tempdir): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.data.add_array_info(doc, emc, None) filename = 'cinder_emc_config_ISCSINoFAST.xml' config_file_path = tempdir + '/' + filename f = open(config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def add_interval_and_retries(self, doc, emc): interval = doc.createElement(""Interval"") intervaltext = doc.createTextNode(""5"") emc.appendChild(interval) interval.appendChild(intervaltext) retries = doc.createElement(""Retries"") retriestext = doc.createTextNode(""40"") emc.appendChild(retries) retries.appendChild(retriestext) return doc def add_interval_only(self, doc, emc): interval = doc.createElement(""Interval"") intervaltext = doc.createTextNode(""20"") emc.appendChild(interval) interval.appendChild(intervaltext) return doc def add_retries_only(self, doc, emc): retries = doc.createElement(""Retries"") retriestext = doc.createTextNode(""70"") emc.appendChild(retries) retries.appendChild(retriestext) return doc def fake_ecom_connection(self): conn = FakeEcomConnection() return conn def fake_is_v3(self, conn, serialNumber): return False def fake_sleep(self, seconds): return def fake_gather_info(self): return def test_get_volume_element_name(self): volumeId = 'ea95aa39-080b-4f11-9856-a03acf9112ad' utils = self.driver.common.utils volumeElementName = utils.get_volume_element_name(volumeId) expectVolumeElementName = ( emc_vmax_utils.VOLUME_ELEMENT_NAME_PREFIX + volumeId) self.assertEqual(volumeElementName, expectVolumeElementName) def test_get_associated_replication_from_source_volume(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils repInstanceName = ( utils.get_associated_replication_from_source_volume( conn, self.data.storage_system, self.data.test_volume['device_id'])) expectInstanceName = ( conn.EnumerateInstanceNames('SE_StorageSynchronized_SV_SV')[0]) self.assertEqual(repInstanceName, expectInstanceName) def test_get_array_and_device_id_success(self): deviceId = '0123' arrayId = u'array1234' external_ref = {u'source-name': deviceId} volume = {'volume_metadata': [{'key': 'array', 'value': arrayId}] } utils = self.driver.common.utils (arrId, devId) = utils.get_array_and_device_id(volume, external_ref) self.assertEqual(arrId, arrayId) self.assertEqual(devId, deviceId) def test_get_array_and_device_id_failed(self): deviceId = '0123' arrayId = u'array1234' external_ref = {u'no-source-name': deviceId} volume = {'volume_metadata': [{'key': 'array', 'value': arrayId}] } utils = self.driver.common.utils self.assertRaises(exception.VolumeBackendAPIException, utils.get_array_and_device_id, volume, external_ref) def test_rename_volume(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils newName = 'new_name' volume = {} volume['CreationClassName'] = 'Symm_StorageVolume' volume['DeviceID'] = '1' volume['ElementName'] = 'original_name' pywbem = mock.Mock() pywbem.cim_obj = mock.Mock() pywbem.cim_obj.CIMInstance = mock.Mock() emc_vmax_utils.pywbem = pywbem volumeInstance = conn.GetInstance(volume) originalName = volumeInstance['ElementName'] volumeInstance = utils.rename_volume(conn, volumeInstance, newName) self.assertEqual(newName, volumeInstance['ElementName']) volumeInstance = utils.rename_volume( conn, volumeInstance, originalName) self.assertEqual(originalName, volumeInstance['ElementName']) def test_populate_cgsnapshot_status(self): utils = self.driver.common.utils # Test 1. default available snapshots = utils.populate_cgsnapshot_status( None, self.driver.db, self.data.test_CG_snapshot['id']) self.assertEqual('available', snapshots[0]['status']) # Test 2. override status status = 'error' snapshots = utils.populate_cgsnapshot_status( None, self.driver.db, self.data.test_CG_snapshot['id'], status) self.assertEqual('error', snapshots[0]['status']) def test_get_volume_model_updates(self): utils = self.driver.common.utils status = 'status-string' volumes = utils.get_volume_model_updates( None, self.driver.db, self.data.test_CG['id'], status) self.assertEqual(status, volumes[0]['status']) def test_get_smi_version(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils version = utils.get_smi_version(conn) expected = int(str(self.data.majorVersion) + str(self.data.minorVersion) + str(self.data.revNumber)) self.assertEqual(expected, version) def test_intervals_and_retries_default(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' tempdir = tempfile.mkdtemp() config_file_path = self.create_fake_config_file_no_fast(tempdir) arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(60, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(10, self.driver.utils._get_interval_in_secs(extraSpecs)) self._cleanup(tempdir, config_file_path) def test_interval_only(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} tempdir = tempfile.mkdtemp() config_file_path = ( self.create_fake_config_file_no_fast_with_interval(tempdir)) pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(60, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(20, self.driver.utils._get_interval_in_secs(extraSpecs)) self._cleanup(tempdir, config_file_path) def test_retries_only(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} tempdir = tempfile.mkdtemp() config_file_path = ( self.create_fake_config_file_no_fast_with_retries(tempdir)) pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(70, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(10, self.driver.utils._get_interval_in_secs(extraSpecs)) self._cleanup(tempdir, config_file_path) def test_wait_for_sync_extra_specs(self): mysync = 'fakesync' conn = self.fake_ecom_connection() tempdir = tempfile.mkdtemp() config_file_path = ( self.create_fake_config_file_no_fast_with_interval_retries( tempdir)) extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.driver.utils._is_sync_complete = mock.Mock( return_value=True) rc = self.driver.utils.wait_for_sync(conn, mysync, extraSpecs) self.assertIsNone(rc) self.driver.utils._is_sync_complete.assert_called_once_with( conn, mysync) self.assertEqual( True, self.driver.utils._is_sync_complete.return_value) self.assertEqual(40, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(5, self.driver.utils._get_interval_in_secs(extraSpecs)) self.driver.utils._is_sync_complete.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig self._cleanup(tempdir, config_file_path) def test_intervals_and_retries_override( self): tempdir = tempfile.mkdtemp() config_file_path = ( self.create_fake_config_file_no_fast_with_interval_retries( tempdir)) extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(40, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(5, self.driver.utils._get_interval_in_secs(extraSpecs)) self._cleanup(tempdir, config_file_path) # Bug 1393555 - storage group has been deleted by another process. def test_find_storage_masking_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundStorageMaskingGroupInstanceName = ( self.driver.common.utils.find_storage_masking_group( conn, controllerConfigService, self.data.storagegroupname)) # The storage group has been found. self.assertEqual( self.data.storagegroupname, conn.GetInstance( foundStorageMaskingGroupInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageMaskingGroupInstanceName2 = ( self.driver.common.utils.find_storage_masking_group( conn, controllerConfigService, self.data.storagegroupname)) # The storage group has not been found as it has been removed # externally. self.assertIsNone(foundStorageMaskingGroupInstanceName2) # Bug 1393555 - pool has been deleted by another process. def test_get_pool_by_name(self): conn = self.fake_ecom_connection() foundPoolInstanceName = self.driver.common.utils.get_pool_by_name( conn, self.data.poolname, self.data.storage_system) # The pool has been found. self.assertEqual( self.data.poolname, conn.GetInstance(foundPoolInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundPoolInstanceName2 = self.driver.common.utils.get_pool_by_name( conn, self.data.poolname, self.data.storage_system) # The pool has not been found as it has been removed externally. self.assertIsNone(foundPoolInstanceName2) def test_get_hardware_type(self): iqn_initiator = 'iqn.1992-04.com.emc: 50000973f006dd80' hardwaretypeid = ( self.driver.utils._get_hardware_type(iqn_initiator)) self.assertEqual(5, hardwaretypeid) wwpn_initiator = '123456789012345' hardwaretypeid = ( self.driver.utils._get_hardware_type(wwpn_initiator)) self.assertEqual(2, hardwaretypeid) bogus_initiator = 'bogus' hardwaretypeid = ( self.driver.utils._get_hardware_type(bogus_initiator)) self.assertEqual(0, hardwaretypeid) def test_wait_for_job_complete(self): myjob = SE_ConcreteJob() myjob.classname = 'SE_ConcreteJob' myjob['InstanceID'] = '9999' myjob['status'] = 'success' myjob['type'] = 'type' myjob['CreationClassName'] = 'SE_ConcreteJob' myjob['Job'] = myjob conn = self.fake_ecom_connection() self.driver.utils._is_job_finished = mock.Mock( return_value=True) rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) self.driver.utils._is_job_finished.assert_called_once_with( conn, myjob) self.assertEqual( True, self.driver.utils._is_job_finished.return_value) self.driver.utils._is_job_finished.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig def test_wait_for_sync(self): mysync = 'fakesync' conn = self.fake_ecom_connection() self.driver.utils._is_sync_complete = mock.Mock( return_value=True) rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) self.driver.utils._is_sync_complete.assert_called_once_with( conn, mysync) self.assertEqual( True, self.driver.utils._is_sync_complete.return_value) self.driver.utils._is_sync_complete.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig def test_get_pool_instance_and_system_name(self): conn = self.fake_ecom_connection() # V2 - old '+' separator storagesystem = {} storagesystem['SystemName'] = self.data.storage_system storagesystem['Name'] = self.data.storage_system pools = conn.EnumerateInstanceNames(""EMC_VirtualProvisioningPool"") poolname = 'gold' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertEqual(self.data.storage_system, systemname) self.assertEqual(self.data.storagepoolid, poolinstancename['InstanceID']) # V3 - note: V2 can also have the '-+-' separator storagesystem = {} storagesystem['SystemName'] = self.data.storage_system_v3 storagesystem['Name'] = self.data.storage_system_v3 pools = conn.EnumerateInstanceNames('Symm_SRPStoragePool') poolname = 'SRP_1' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertEqual(self.data.storage_system_v3, systemname) self.assertEqual('SYMMETRIX-+-000197200056-+-SRP_1', poolinstancename['InstanceID']) # Invalid poolname poolname = 'bogus' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertIsNone(poolinstancename) self.assertEqual(self.data.storage_system_v3, systemname) def test_find_storage_configuration_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_storage_configuration_service, conn, storageSystemName) def test_find_controller_configuration_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_controller_configuration_service, conn, storageSystemName) def test_find_element_composition_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_element_composition_service, conn, storageSystemName) def test_find_storage_relocation_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_storage_relocation_service, conn, storageSystemName) def test_find_storage_hardwaredid_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_storage_hardwareid_service, conn, storageSystemName) def test_find_replication_service(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_replication_service, conn, storageSystemName) def test_find_replication_service_capabilities(self): storageSystemName = ""bogus"" common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.find_replication_service_capabilities, conn, storageSystemName) def test_get_tier_policy_service(self): storageSystemInstanceName = None common = self.driver.common conn = self.fake_ecom_connection() self.assertRaises( exception.VolumeBackendAPIException, common.utils.get_tier_policy_service, conn, storageSystemInstanceName) def test_is_job_finished(self): conn = self.fake_ecom_connection() myjob = SE_ConcreteJob() myjob.classname = 'SE_ConcreteJob' myjob['JobState'] = 2L myjob['status'] = 'Running' job = SE_ConcreteJob() job['Job'] = myjob isfinished = self.driver.common.utils._is_job_finished(conn, job) self.assertFalse(isfinished) def test_is_sync_complete(self): conn = self.fake_ecom_connection() syncname = SE_ConcreteJob() syncname.classname = 'SE_StorageSynchronized_SV_SV' syncname['PercentSynced'] = 50 issynched = self.driver.common.utils._is_sync_complete(conn, syncname) self.assertFalse(issynched) def test_get_random_portgroup_exception(self): tempdir = tempfile.mkdtemp() filename = 'cinder_emc_config_no_portgroup.xml' config_file = tempdir + '/' + filename text_file = open(config_file, ""w"") # Missing portgroups text_file.write(""<?xml version='1.0' encoding='UTF-8'?>\n<EMC>\n"" ""<EcomServerIp>10.10.10.10</EcomServerIp>\n"" ""<EcomServerPort>5988</EcomServerPort>\n"" ""<EcomUserName>user\t</EcomUserName>\n"" ""<EcomPassword>password</EcomPassword>\n"" ""<Array>000198700439</Array>\n"" ""<Pool>FC_SLVR1</Pool>\n"" ""<FastPolicy>SILVER1</FastPolicy>\n"" ""</EMC>"") text_file.close() myFile = open(config_file, 'r') data = myFile.read() myFile.close() dom = minidom.parseString(data) self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.utils._get_random_portgroup, dom) self._cleanup(tempdir, config_file) def test_get_connection_info_exception(self): tempdir = tempfile.mkdtemp() filename = 'cinder_emc_config_no_username_password.xml' config_file = tempdir + '/' + filename text_file = open(config_file, ""w"") # Missing username and password for ECOM text_file.write(""<?xml version='1.0' encoding='UTF-8'?>\n<EMC>\n"" ""<EcomServerIp>10.10.10.10</EcomServerIp>\n"" ""<EcomServerPort>5988</EcomServerPort>\n"" ""<PortGroups>\n"" ""<PortGroup>OS-PORTGROUP1-PG</PortGroup>\n"" ""</PortGroups>\n"" ""<Array>000198700439</Array>\n"" ""<Pool>FC_SLVR1</Pool>\n"" ""<FastPolicy>SILVER1</FastPolicy>\n"" ""</EMC>"") text_file.close() myFile = open(config_file, 'r') data = myFile.read() myFile.close() dom = minidom.parseString(data) self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.utils._get_connection_info, dom) self._cleanup(tempdir, config_file) def test_get_connection_info_EcomUseSSL_EcomNoVerification_is_true(self): tempdir = tempfile.mkdtemp() filenm = 'cinder_emc_config_EcomUseSSL_and_EcomNoVerification_true.xml' config_file = tempdir + '/' + filenm text_file = open(config_file, ""w"") text_file.write(""<?xml version='1.0' encoding='UTF-8'?>\n<EMC>\n"" ""<EcomServerIp>10.10.10.10</EcomServerIp>\n"" ""<EcomServerPort>5988</EcomServerPort>\n"" ""<EcomUserName>user\t</EcomUserName>\n"" ""<EcomPassword>password</EcomPassword>\n"" ""<EcomUseSSL>True</EcomUseSSL>\n"" ""<EcomNoVerification>True</EcomNoVerification>\n"" ""<PortGroups>\n"" ""<PortGroup>OS-PORTGROUP1-PG</PortGroup>\n"" ""</PortGroups>\n"" ""<Array>000198700439</Array>\n"" ""<Pool>FC_SLVR1</Pool>\n"" ""<FastPolicy>SILVER1</FastPolicy>\n"" ""</EMC>"") text_file.close() myFile = open(config_file, 'r') data = myFile.read() myFile.close() dom = minidom.parseString(data) self.assertEqual = (self.driver.common.utils._process_tag( dom, 'EcomUseSSL'), 'True') self._cleanup(tempdir, config_file) def test_multi_pool_support_log_error(self): mp_filename = 'cinder_emc_config_multi_pool_support_noArrayTag.xml' tempdir = tempfile.mkdtemp() multipool_config_file = tempdir + '/' + mp_filename text_file = open(multipool_config_file, ""w"") text_file.write(""<?xml version='1.0' encoding='UTF-8'?>\n<EMC>\n"" ""<EcomServerIp>10.10.10.10</EcomServerIp>\n"" ""<EcomServerPort>5988</EcomServerPort>\n"" ""<EcomUserName>user\t</EcomUserName>\n"" ""<EcomPassword>password</EcomPassword>\n"" ""<PortGroups>\n"" ""<PortGroup>OS-PORTGROUP1-PG</PortGroup>\n"" ""</PortGroups>\n"" ""<Pool>FC_SLVR1</Pool>\n"" ""<FastPolicy>SILVER1</FastPolicy>\n"" ""</EMC>"") text_file.close() multipool_file = open(multipool_config_file, 'r') multipool_file.close() no_array_tag_result = (self.driver.common.utils._multi_pool_support( multipool_config_file)) self.assertEqual(no_array_tag_result, []) self._cleanup(tempdir, multipool_config_file) def test_get_meta_members_capacity_in_byte(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils memberVolumeInstanceNames = [] volumeHead = EMC_StorageVolume() volumeHead.classname = 'Symm_StorageVolume' blockSize = self.data.block_size volumeHead['ConsumableBlocks'] = ( self.data.metaHead_volume['ConsumableBlocks']) volumeHead['BlockSize'] = blockSize volumeHead['DeviceID'] = self.data.metaHead_volume['DeviceID'] memberVolumeInstanceNames.append(volumeHead) metaMember1 = EMC_StorageVolume() metaMember1.classname = 'Symm_StorageVolume' metaMember1['ConsumableBlocks'] = ( self.data.meta_volume1['ConsumableBlocks']) metaMember1['BlockSize'] = blockSize metaMember1['DeviceID'] = self.data.meta_volume1['DeviceID'] memberVolumeInstanceNames.append(metaMember1) metaMember2 = EMC_StorageVolume() metaMember2.classname = 'Symm_StorageVolume' metaMember2['ConsumableBlocks'] = ( self.data.meta_volume2['ConsumableBlocks']) metaMember2['BlockSize'] = blockSize metaMember2['DeviceID'] = self.data.meta_volume2['DeviceID'] memberVolumeInstanceNames.append(metaMember2) capacities = utils.get_meta_members_capacity_in_byte( conn, memberVolumeInstanceNames) headSize = ( volumeHead['ConsumableBlocks'] - metaMember1['ConsumableBlocks'] - metaMember2['ConsumableBlocks']) expected = [headSize * blockSize, metaMember1['ConsumableBlocks'] * blockSize, metaMember2['ConsumableBlocks'] * blockSize] self.assertEqual(capacities, expected) def test_wait_for_job_complete_2(self): myjob = SE_ConcreteJob() myjob.classname = 'SE_ConcreteJob' myjob['InstanceID'] = '9999' myjob['status'] = 'success' myjob['type'] = 'type' myjob['CreationClassName'] = 'SE_ConcreteJob' myjob['Job'] = myjob conn = self.fake_ecom_connection() extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSINoFAST', 'retries': u'40', 'interval': u'20', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': None, 'isV3': False, 'pool': u'gold'} rc, errordesc = ( self.driver.common.utils.wait_for_job_complete(conn, myjob, extraSpecs)) self.assertEqual(0, rc) self.assertEqual('', errordesc) def test_get_num(self): numStr = 9 datatype = 16 result = self.driver.common.utils.get_num(numStr, datatype) self.assertEqual(9, result) def test_find_storage_system_log_error(self): configService = 'bogus_configService' conn = self.fake_ecom_connection() result = self.driver.common.utils.find_storage_system(conn, configService) self.assertEqual(None, result) def test_get_storage_groups_from_volume_else_branch(self): conn = self.fake_ecom_connection() volumeInstanceName = 'bogus_volumeInstanceName' result = self.driver.common.utils.get_storage_groups_from_volume( conn, volumeInstanceName) self.assertEqual([], result) def test_wrap_get_storage_group_from_volume(self): conn = self.fake_ecom_connection() volumeInstanceName = 'bogus_volumeInstanceName' sgName = 'bogus_sgName' result = self.driver.common.utils.wrap_get_storage_group_from_volume( conn, volumeInstanceName, sgName) self.assertEqual(None, result) def test_find_storage_system_name_from_service(self): configService = { 'CreationClassName': 'Symm_StorageConfigurationService', 'SystemName': 'SYMMETRIX+000195900551'} common = self.driver.common result = common.utils.find_storage_system_name_from_service( configService) self.assertEqual('SYMMETRIX+000195900551', result) def test_find_volume_instance_foundVolumeInstance_None(self): conn = self.fake_ecom_connection() volumeDict = { 'classname': 'Symm_StorageVolume', 'keybindings': { 'CreationClassName': 'Symm_StorageVolume', 'SystemName': 'SYMMETRIX+000195900551', 'DeviceID': '5', 'SystemCreationClassName': 'Symm_StorageSystem'}} volumeName = 'bogus_volumeName' result = self.driver.common.utils.find_volume_instance( conn, volumeDict, volumeName) self.assertEqual(None, result) def test_get_composite_type(self): compositeTypeStr = 'concatenated' result = self.driver.common.utils.get_composite_type(compositeTypeStr) self.assertEqual(2, result) def test_get_short_protocol_type(self): protocol = 'protocolnone' result = self.driver.common.utils.get_short_protocol_type(protocol) self.assertEqual('protocolnone', result) def test_isArrayV3(self): conn = self.fake_ecom_connection() arrayName = 'SYMMETRIX+000195900551' result = self.driver.common.utils.isArrayV3(conn, arrayName) self.assertEqual(False, result) def test_get_composite_elements(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeInstance = conn.GetInstance(volumeInstanceName) memberVolumeInstanceNames = utils.get_composite_elements( conn, volumeInstance) expected = [self.data.metaHead_volume, self.data.meta_volume1, self.data.meta_volume2] self.assertEqual(expected, memberVolumeInstanceNames) def test_get_pool_name(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils poolInstanceName = {} poolInstanceName['InstanceID'] = ""SATA_GOLD1"" poolInstanceName['CreationClassName'] = 'Symm_VirtualProvisioningPool' poolName = utils.get_pool_name(conn, poolInstanceName) self.assertEqual(poolName, self.data.poolname) def test_find_volume_by_device_id_on_array(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils volumeInstanceName = utils.find_volume_by_device_id_on_array( conn, self.data.storage_system, self.data.test_volume['device_id']) expectVolume = {} expectVolume['CreationClassName'] = 'Symm_StorageVolume' expectVolume['DeviceID'] = self.data.test_volume['device_id'] expect = conn.GetInstance(expectVolume) self.assertEqual(expect, volumeInstanceName) def _cleanup(self, tempdir, config_file_path): bExists = os.path.exists(config_file_path) if bExists: os.remove(config_file_path) shutil.rmtree(tempdir) class EMCVMAXFastTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXFastTest, self).setUp() configuration = mock.Mock() configuration.safe_get.return_value = 'FASTTests' configuration.config_group = 'FASTTests' self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_get_ecom_connection', self.fake_ecom_connection) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) instancename = FakeCIMInstanceName() self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'get_instance_name', instancename.fake_getinstancename) self.stubs.Set(time, 'sleep', self.fake_sleep) self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', self.fake_is_v3) driver = emc_vmax_iscsi.EMCVMAXISCSIDriver(configuration=configuration) driver.db = FakeDB() self.driver = driver self.driver.utils = emc_vmax_utils.EMCVMAXUtils(object) def fake_ecom_connection(self): conn = FakeEcomConnection() return conn def fake_gather_info(self): return def fake_is_v3(self, conn, serialNumber): return False def fake_sleep(self, seconds): return def test_create_default_storage_group(self): common = self.driver.common conn = self.fake_ecom_connection() controllerConfigService = { 'CreationClassName': 'Symm_ControllerConfigurationService', 'SystemName': 'SYMMETRIX+000195900551'} fastPolicyName = 'GOLD1' storageGroupName = 'OS_default_GOLD1_SG' extraspecs = {'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] result = common.fast._create_default_storage_group( conn, controllerConfigService, fastPolicyName, storageGroupName, vol, extraspecs) self.assertEqual(None, result) def test_is_volume_in_default_SG(self): volumeInstanceName = 'bogus_volumeInstanceName' common = self.driver.common conn = self.fake_ecom_connection() result = common.fast.is_volume_in_default_SG(conn, volumeInstanceName) self.assertEqual(False, result) def test_is_volume_in_default_SG_else_false(self): volumeInstanceName = 'bogus2_volumeInstanceName' common = self.driver.common conn = self.fake_ecom_connection() result = common.fast.is_volume_in_default_SG(conn, volumeInstanceName) self.assertEqual(False, result) def test_is_volume_in_default_SG_else_true(self): volumeInstanceName = 'bogus3_volumeInstanceName' common = self.driver.common conn = self.fake_ecom_connection() result = common.fast.is_volume_in_default_SG(conn, volumeInstanceName) self.assertEqual(True, result) def test_get_existing_tier_policies(self): common = self.driver.common conn = self.fake_ecom_connection() tierPolicyServiceInstanceName = 'this_test_name' result = common.fast._get_existing_tier_policies( conn, tierPolicyServiceInstanceName) self.assertEqual( [{'CreationClassName': 'Symm_TierPolicyRule', 'PolicyRuleName': 'gold', 'SystemName': 'SYMMETRIX+000195900551'}], result) def test_get_associated_tier_policy_from_storage_group(self): common = self.driver.common conn = self.fake_ecom_connection() storageGroupInstanceName = 'bogus_storageGroupInstanceName' result = common.fast._get_associated_tier_policy_from_storage_group( conn, storageGroupInstanceName) self.assertEqual(None, result) def test_get_pool_associated_to_policy(self): common = self.driver.common conn = self.fake_ecom_connection() fastPolicyName = None storageConfigService = 'bogus_storageConfigService' poolInstanceName = None result = common.fast.get_pool_associated_to_policy( conn, fastPolicyName, storageConfigService, poolInstanceName) self.assertEqual(None, result) def test_add_storage_group_to_tier_policy_rule(self): common = self.driver.common conn = self.fake_ecom_connection() tierPolicyServiceInstanceName = { 'CreationClassName': 'CIM_HostedService', 'SystemName': 'SYMMETRIX+000195900551', 'Name': 'SYMMETRIX+000195900551'} storageGroupInstanceName = { 'CreationClassName': 'CIM_DeviceMaskingGroup', 'ElementName': 'OS_default_GOLD1_SG', 'SystemName': 'SYMMETRIX+000195900551'} tierPolicyRuleInstanceName = 'gold' storageGroupName = 'OS_default_GOLD1_SG' fastPolicyName = 'BRONZE1' extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} result = common.fast._add_storage_group_to_tier_policy_rule( conn, tierPolicyServiceInstanceName, storageGroupInstanceName, tierPolicyRuleInstanceName, storageGroupName, fastPolicyName, extraSpecs) self.assertEqual(0L, result) def test_add_storage_group_to_tier_policy_rule_rcnotzero(self): utils = self.driver.common.fast.utils common = self.driver.common conn = self.fake_ecom_connection() tierPolicyServiceInstanceName = { 'CreationClassName': 'CIM_HostedService', 'SystemName': 'SYMMETRIX+000195900551', 'Name': 'SYMMETRIX+000195900551'} storageGroupInstanceName = { 'CreationClassName': 'CIM_DeviceMaskingGroup', 'ElementName': 'OS_default_GOLD1_SG', 'SystemName': 'SYMMETRIX+000195900551'} tierPolicyRuleInstanceName = 'gold' storageGroupName = 'OS_default_GOLD1_SG' fastPolicyName = 'BRONZE1' extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.fast._add_storage_group_to_tier_policy_rule, conn, tierPolicyServiceInstanceName, storageGroupInstanceName, tierPolicyRuleInstanceName, storageGroupName, fastPolicyName, extraSpecs) def test_add_storage_group_and_verify_tier_policy_assoc(self): common = self.driver.common conn = self.fake_ecom_connection() controllerConfigService = { 'CreationClassName': 'Symm_ControllerConfigurationService', 'SystemName': 'SYMMETRIX+000195900551'} storageGroupInstanceName = { 'CreationClassName': 'CIM_DeviceMaskingGroup', 'ElementName': 'OS_default_GOLD1_SG', 'SystemName': 'SYMMETRIX+000195900551'} storageGroupName = 'OS_default_GOLD1_SG' fastPolicyName = 'BRONZE1' extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} result = common.fast.add_storage_group_and_verify_tier_policy_assoc( conn, controllerConfigService, storageGroupInstanceName, storageGroupName, fastPolicyName, extraSpecs) self.assertEqual(None, result) def test_delete_storage_group_from_tier_policy_rule(self): common = self.driver.common conn = self.fake_ecom_connection() tierPolicyServiceInstanceName = { 'CreationClassName': 'CIM_HostedService', 'SystemName': 'SYMMETRIX+000195900551', 'Name': 'SYMMETRIX+000195900551'} storageGroupInstanceName = { 'CreationClassName': 'CIM_DeviceMaskingGroup', 'ElementName': 'OS_default_GOLD1_SG', 'SystemName': 'SYMMETRIX+000195900551'} tierPolicyRuleInstanceName = 'gold' extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} result = common.fast.delete_storage_group_from_tier_policy_rule( conn, tierPolicyServiceInstanceName, storageGroupInstanceName, tierPolicyRuleInstanceName, extraSpecs) self.assertEqual(None, result) def test_delete_storage_group_from_tier_policy_rule_rcnonzero(self): common = self.driver.common utils = self.driver.common.fast.utils conn = self.fake_ecom_connection() tierPolicyServiceInstanceName = { 'CreationClassName': 'CIM_HostedService', 'SystemName': 'SYMMETRIX+000195900551', 'Name': 'SYMMETRIX+000195900551'} storageGroupInstanceName = { 'CreationClassName': 'CIM_DeviceMaskingGroup', 'ElementName': 'OS_default_GOLD1_SG', 'SystemName': 'SYMMETRIX+000195900551'} tierPolicyRuleInstanceName = 'gold' extraSpecs = { 'array': u'1234567891011', 'volume_backend_name': 'ISCSIFAST', 'internal_only:compositetype': 'concatenated', 'portgroupname': u'OS-portgroup-PG', 'internal_only:membercount': '1', 'fastpolicy': u'GOLD1', 'isV3': False, 'pool': u'gold'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) result = common.fast.delete_storage_group_from_tier_policy_rule( conn, tierPolicyServiceInstanceName, storageGroupInstanceName, tierPolicyRuleInstanceName, extraSpecs) self.assertEqual(None, result) # Bug 1393555 - storage group has been deleted by another process. def test_get_policy_default_storage_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundStorageMaskingGroupInstanceName = ( self.driver.common.fast.get_policy_default_storage_group( conn, controllerConfigService, 'OS_default')) # The storage group has been found. self.assertEqual( 'OS_default_GOLD1_SG', conn.GetInstance( foundStorageMaskingGroupInstanceName)['ElementName']) self.driver.common.fast.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageMaskingGroupInstanceName2 = ( self.driver.common.fast.get_policy_default_storage_group( conn, controllerConfigService, 'OS_default')) # The storage group has not been found as it has been removed # externally. self.assertIsNone(foundStorageMaskingGroupInstanceName2) # Bug 1393555 - policy has been deleted by another process. def test_get_capacities_associated_to_policy(self): conn = self.fake_ecom_connection() total_capacity_gb, free_capacity_gb = ( self.driver.common.fast.get_capacities_associated_to_policy( conn, self.data.storage_system, self.data.policyrule)) # The capacities associated to the policy have been found. self.assertEqual(self.data.totalmanagedspace_gbs, total_capacity_gb) self.assertEqual(self.data.subscribedcapacity_gbs, free_capacity_gb) self.driver.common.fast.utils.get_existing_instance = mock.Mock( return_value=None) total_capacity_gb_2, free_capacity_gb_2 = ( self.driver.common.fast.get_capacities_associated_to_policy( conn, self.data.storage_system, self.data.policyrule)) # The capacities have not been found as the policy has been # removed externally. self.assertEqual(0, total_capacity_gb_2) self.assertEqual(0, free_capacity_gb_2) class EMCVMAXProvisionTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXProvisionTest, self).setUp() configuration = mock.Mock() configuration.safe_get.return_value = 'ProvisionTests' configuration.config_group = 'ProvisionTests' self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_get_ecom_connection', self.fake_ecom_connection) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) instancename = FakeCIMInstanceName() self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'get_instance_name', instancename.fake_getinstancename) self.stubs.Set(time, 'sleep', self.fake_sleep) self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', self.fake_is_v3) driver = emc_vmax_iscsi.EMCVMAXISCSIDriver(configuration=configuration) driver.db = FakeDB() self.driver = driver self.driver.utils = emc_vmax_utils.EMCVMAXUtils(object) def fake_ecom_connection(self): conn = FakeEcomConnection() return conn def fake_is_v3(self, conn, serialNumber): return False def fake_sleep(self, seconds): return def fake_gather_info(self): return def test_unbind_volume_from_storage_pool(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() storageConfigService = None volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.unbind_volume_from_storage_pool, conn, storageConfigService, volumeInstanceName, volumeName, extraSpecs) def test_unbind_volume_from_storage_pool_LOG_debug(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() storageConfigService = None volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(0, 'failure')) result = common.provision.unbind_volume_from_storage_pool( conn, storageConfigService, volumeInstanceName, volumeName, extraSpecs) self.assertEqual( (0, {'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}}), result) def test_modify_composite_volume(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() elementCompositionService = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} theVolumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) inVolumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.modify_composite_volume, conn, elementCompositionService, theVolumeInstanceName, inVolumeInstanceName, extraSpecs) def test_modify_composite_volume_LOG_debug(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() elementCompositionService = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} theVolumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) inVolumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(0, 'failure')) result = common.provision.modify_composite_volume( conn, elementCompositionService, theVolumeInstanceName, inVolumeInstanceName, extraSpecs) self.assertEqual( (0, {'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}}), result) def test_create_volume_from_pool(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() storageConfigService = ( common.utils.find_storage_configuration_service( conn, self.data.storage_system)) volumeName = ""1403160-Vol"" poolInstanceName = {} volumeSize = 10 extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_volume_from_pool, conn, storageConfigService, volumeName, poolInstanceName, volumeSize, extraSpecs) def test_delete_volume_from_pool_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() storageConfigservice = {} volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.delete_volume_from_pool, conn, storageConfigservice, volumeInstanceName, volumeName, extraSpecs) def test_create_and_get_storage_group_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_and_get_storage_group, conn, controllerConfigService, storageGroupName, volumeInstanceName, extraSpecs) def test_remove_device_from_storage_group_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageGroupInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.remove_device_from_storage_group, conn, controllerConfigService, storageGroupInstanceName, volumeInstanceName, volumeName, extraSpecs) def test_add_members_to_masking_group_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageGroupInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.add_members_to_masking_group, conn, controllerConfigService, storageGroupInstanceName, volumeInstanceName, volumeName, extraSpecs) def test_create_composite_volume_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() elementCompositionService = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} volumeSize = 10 volumeName = ""1403160-Vol"" poolInstanceName = {} compositeType = None numMembers = 1 extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_composite_volume, conn, elementCompositionService, volumeSize, volumeName, poolInstanceName, compositeType, numMembers, extraSpecs) def test_create_new_composite_volume_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() elementCompositionService = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} compositeHeadInstanceName = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} compositeMemberInstanceName = { 'CreationClassName': 'Symm_ElementCompositionService', 'SystemName': 'SYMMETRIX+000195900551'} compositeType = 2 extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_new_composite_volume, conn, elementCompositionService, compositeHeadInstanceName, compositeMemberInstanceName, compositeType, extraSpecs) def test_migrate_volume_exception(self): common = self.driver.common conn = self.fake_ecom_connection() utils = self.driver.common.provision.utils controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageRelocationServiceInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) targetPoolInstanceName = {} extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision._migrate_volume, conn, storageRelocationServiceInstanceName, volumeInstanceName, targetPoolInstanceName, extraSpecs) def test_migrate_volume(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageRelocationServiceInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) targetPoolInstanceName = {} extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(0, 'failure')) result = common.provision._migrate_volume( conn, storageRelocationServiceInstanceName, volumeInstanceName, targetPoolInstanceName, extraSpecs) self.assertEqual(0, result) def test_terminate_migrate_session_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision._terminate_migrate_session, conn, volumeInstanceName, extraSpecs) def test_create_consistency_group(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() replicationService = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} consistencyGroupName = '1234bcde' extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_consistency_group, conn, replicationService, consistencyGroupName, extraSpecs) def test_delete_consistency_group_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() replicationService = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} cgInstanceName = {'CreationClassName': 'CIM_ReplicationGroup'} consistencyGroupName = '1234bcde' extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.delete_consistency_group, conn, replicationService, cgInstanceName, consistencyGroupName, extraSpecs) def test_delete_clone_relationship_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() repServiceInstanceName = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} syncInstanceName = (None, None) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} force = False job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.delete_clone_relationship, conn, repServiceInstanceName, syncInstanceName, extraSpecs, force) def test_get_target_endpoints_exception(self): common = self.driver.common conn = self.fake_ecom_connection() storageHardwareService = {'SystemName': 'SYMMETRIX+000195900551'} hardwareId = 123456789012345 job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) self.assertRaises( exception.VolumeBackendAPIException, common.provision.get_target_endpoints, conn, storageHardwareService, hardwareId) def test_get_target_endpoints(self): common = self.driver.common conn = self.fake_ecom_connection() storageHardwareService = {'SystemName': 'SYMMETRIX+000195900551'} hardwareId = 123456789012345 job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(0, job)) result = common.provision.get_target_endpoints( conn, storageHardwareService, hardwareId) self.assertEqual( (0, {'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}}), result) def test_add_volume_to_cg_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() replicationService = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} cgInstanceName = {'CreationClassName': 'CIM_ReplicationGroup'} volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) cgName = '1234bcde' volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.add_volume_to_cg, conn, replicationService, cgInstanceName, volumeInstanceName, cgName, volumeName, extraSpecs) def test_create_group_replica_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() replicationService = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} srcGroupInstanceName = (None, { 'status': 'available', 'volume_type_id': 'abc', 'name': 'myCG1', 'id': '12345abcde'}) tgtGroupInstanceName = (None, { 'status': 'available', 'volume_type_id': 'abc', 'name': 'myCG1', 'id': '12345abcde'}) relationName = '12de' extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_group_replica, conn, replicationService, srcGroupInstanceName, tgtGroupInstanceName, relationName, extraSpecs) def test_migrate_volume_to_storage_pool(self): common = self.driver.common conn = self.fake_ecom_connection() controllerConfigService = { 'CreationClassName': 'Symm_ControllerConfigurationService', 'SystemName': 'SYMMETRIX+000195900551'} storageGroupName = self.data.storagegroupname storageRelocationServiceInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) targetPoolInstanceName = {} extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} result = common.provision.migrate_volume_to_storage_pool( conn, storageRelocationServiceInstanceName, volumeInstanceName, targetPoolInstanceName, extraSpecs) self.assertEqual(0L, result) def test_remove_volume_from_cg_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() replicationService = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} cgInstanceName = {'CreationClassName': 'CIM_ReplicationGroup'} volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) cgName = '1234bcde' volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.remove_volume_from_cg, conn, replicationService, cgInstanceName, volumeInstanceName, cgName, volumeName, extraSpecs) def test_create_element_replica_exception(self): common = self.driver.common utils = self.driver.common.provision.utils conn = self.fake_ecom_connection() repServiceInstanceName = { 'CreationClassName': 'EMC_ReplicationService', 'SystemName': 'SYMMETRIX+000195900551'} cloneName = 'vol1' sourceName = 'vol2' sourceInstance = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) targetInstance = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} copyOnWrite = True job = { 'Job': {'InstanceID': '9999', 'status': 'success', 'type': None}} conn.InvokeMethod = mock.Mock(return_value=(4096, job)) utils.wait_for_job_complete = mock.Mock(return_value=(2, 'failure')) self.assertRaises( exception.VolumeBackendAPIException, common.provision.create_element_replica, conn, repServiceInstanceName, cloneName, sourceName, sourceInstance, targetInstance, extraSpecs, copyOnWrite) class EMCVMAXCommonTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXCommonTest, self).setUp() configuration = mock.Mock() configuration.safe_get.return_value = 'CommonTests' configuration.config_group = 'CommonTests' self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_get_ecom_connection', self.fake_ecom_connection) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) instancename = FakeCIMInstanceName() self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'get_instance_name', instancename.fake_getinstancename) self.stubs.Set(time, 'sleep', self.fake_sleep) self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', self.fake_is_v3) driver = emc_vmax_iscsi.EMCVMAXISCSIDriver(configuration=configuration) driver.db = FakeDB() self.driver = driver self.driver.utils = emc_vmax_utils.EMCVMAXUtils(object) def fake_ecom_connection(self): conn = FakeEcomConnection() return conn def fake_is_v3(self, conn, serialNumber): return False def fake_sleep(self, seconds): return def fake_gather_info(self): return def test_populate_masking_dict(self): extraSpecs = {'storagetype:pool': u'gold_pool', 'volume_backend_name': 'GOLD_POOL_BE', 'storagetype:array': u'1234567891011', 'isV3': False, 'portgroupname': u'OS-portgroup-PG', 'storagetype:fastpolicy': u'GOLD'} vol = {'SystemName': self.data.storage_system} self.driver.common._find_lun = mock.Mock( return_value=vol) self.driver.common.utils.find_controller_configuration_service = ( mock.Mock(return_value=None)) # If fast is enabled it will uniquely determine the SG and MV # on the host along with the protocol(iSCSI) e.g. I maskingViewDict = self.driver.common._populate_masking_dict( self.data.test_volume, self.data.connector, extraSpecs) self.assertEqual( 'OS-fakehost-gold_pool-I-SG', maskingViewDict['sgGroupName']) self.assertEqual( 'OS-fakehost-gold_pool-I-MV', maskingViewDict['maskingViewName']) # If fast isn't enabled the pool will uniquely determine the SG and MV # on the host along with the protocol(iSCSI) e.g. I extraSpecs['storagetype:fastpolicy'] = None maskingViewDict = self.driver.common._populate_masking_dict( self.data.test_volume, self.data.connector, extraSpecs) self.assertEqual( 'OS-fakehost-gold_pool-I-SG', maskingViewDict['sgGroupName']) self.assertEqual( 'OS-fakehost-gold_pool-I-MV', maskingViewDict['maskingViewName']) # If the length of the FAST policy name is greater than 14 chars and # the length of the short host is more than 38 characters connector = {'host': 'SHORT_HOST_MORE_THEN THIRTY_EIGHT_CHARACTERS'} maskingViewDict = self.driver.common._populate_masking_dict( self.data.test_volume, connector, extraSpecs) self.assertTrue(len(maskingViewDict['sgGroupName']) <= 64) def test_find_device_number(self): data = ( self.driver.common.find_device_number(self.data.test_volume_v2)) self.assertEqual('OS-myhost-MV', data['maskingview']) def test_migrate_cleanup(self): conn = self.fake_ecom_connection() extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] # The volume is already belong to default storage group return_to_default = self.driver.common._migrate_cleanup( conn, vol, self.data.storage_system, 'GOLD1', vol['name'], extraSpecs) self.assertFalse(return_to_default) # The volume does not belong to default storage group self.driver.common.conn = conn return_to_default = self.driver.common._migrate_cleanup( conn, vol, self.data.storage_system, 'BRONZE1', vol['name'], extraSpecs) self.assertTrue(return_to_default) # Bug 1393555 - controller has been deleted by another process. def test_find_lunmasking_scsi_protocol_controller(self): self.driver.common.conn = self.fake_ecom_connection() foundControllerInstanceName = ( self.driver.common._find_lunmasking_scsi_protocol_controller( self.data.storage_system, self.data.connector)) # The controller has been found. self.assertEqual( 'OS-fakehost-gold-MV', self.driver.common.conn.GetInstance( foundControllerInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundControllerInstanceName2 = ( self.driver.common._find_lunmasking_scsi_protocol_controller( self.data.storage_system, self.data.connector)) # The controller has not been found as it has been removed # externally. self.assertIsNone(foundControllerInstanceName2) def test_unbind_and_get_volume_from_storage_pool(self): conn = self.fake_ecom_connection() common = self.driver.common common.utils.is_volume_bound_to_pool = mock.Mock( return_value='False') storageConfigService = ( common.utils.find_storage_configuration_service( conn, self.data.storage_system)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""unbind-vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False} volumeInstance = ( common._unbind_and_get_volume_from_storage_pool( conn, storageConfigService, volumeInstanceName, volumeName, extraSpecs)) self.assertEqual(self.data.storage_system, volumeInstance['SystemName']) self.assertEqual('1', volumeInstance['ElementName']) class EMCVMAXMaskingTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXMaskingTest, self).setUp() configuration = mock.Mock() configuration.safe_get.return_value = 'MaskingTests' configuration.config_group = 'MaskingTests' self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_get_ecom_connection', self.fake_ecom_connection) self.stubs.Set(emc_vmax_common.EMCVMAXCommon, '_gather_info', self.fake_gather_info) instancename = FakeCIMInstanceName() self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'get_instance_name', instancename.fake_getinstancename) self.stubs.Set(time, 'sleep', self.fake_sleep) self.stubs.Set(emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', self.fake_is_v3) driver = emc_vmax_iscsi.EMCVMAXISCSIDriver(configuration=configuration) driver.db = FakeDB() self.driver = driver self.driver.utils = emc_vmax_utils.EMCVMAXUtils(object) def fake_ecom_connection(self): conn = FakeEcomConnection() return conn def fake_is_v3(self, conn, serialNumber): return False def fake_sleep(self, seconds): return def fake_gather_info(self): return def test_create_hardware_ids(self): conn = self.fake_ecom_connection() connector = { 'ip': '10.0.0.2', 'initiator': self.data.iscsi_initiator, 'host': 'fakehost'} initiatorNames = ( self.driver.common.masking._find_initiator_names(conn, connector)) storageHardwareIDInstanceNames = ( self.driver.common.masking._create_hardware_ids( conn, initiatorNames, self.data.storage_system)) self.assertEqual(storageHardwareIDInstanceNames[0], self.data.iscsi_initiator) # Bug 1403160 - make sure the masking view is cleanly deleted def test_last_volume_delete_masking_view(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) maskingViewInstanceName = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) maskingViewName = conn.GetInstance( maskingViewInstanceName)['ElementName'] # Deleting Masking View failed self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.masking._last_volume_delete_masking_view, conn, controllerConfigService, maskingViewInstanceName, maskingViewName, extraSpecs) # Deleting Masking view successful self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking._last_volume_delete_masking_view( conn, controllerConfigService, maskingViewInstanceName, maskingViewName, extraSpecs) # Bug 1403160 - make sure the storage group is cleanly deleted def test_remove_last_vol_and_delete_sg(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageGroupInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False} # Deleting Storage Group failed self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.masking._remove_last_vol_and_delete_sg, conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstanceName, volumeName, extraSpecs) # Deleting Storage group successful self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking._remove_last_vol_and_delete_sg( conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstanceName, volumeName, extraSpecs) # Bug 1416035 - on a create masking view or a delete masking view a # single thread has exclusive access to the masking view. def test_remove_and_reset_members(self): extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False} conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeInstance = conn.GetInstance(volumeInstanceName) volumeName = ""1416035-Vol"" self.driver.common.masking.get_devices_from_storage_group = mock.Mock( return_value=['one_value']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking.remove_and_reset_members( conn, controllerConfigService, volumeInstance, volumeName, extraSpecs) def test_check_if_rollback_action_for_masking_required(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'fastpolicy': 'GOLD1'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] rollbackDict = {} rollbackDict['isV3'] = False rollbackDict['defaultStorageGroupInstanceName'] = ( self.data.default_storage_group) rollbackDict['sgName'] = self.data.storagegroupname rollbackDict['volumeName'] = 'vol1' rollbackDict['fastPolicyName'] = 'GOLD1' rollbackDict['volumeInstance'] = vol rollbackDict['controllerConfigService'] = controllerConfigService rollbackDict['extraSpecs'] = extraSpecs # Path 1 - The volume is in another storage group that isn't the # default storage group expectedmessage = (_(""V2 rollback - Volume in another storage "" ""group besides default storage group."")) message = ( self.driver.common.masking. check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) # Path 2 - The volume is not in any storage group rollbackDict['sgName'] = 'sq_not_exist' expectedmessage = (_(""V2 rollback - Volume is not in any storage "" ""group."")) message = ( self.driver.common.masking. check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) # Bug 1393555 - masking view has been deleted by another process. def test_find_maskingview(self): conn = self.fake_ecom_connection() foundMaskingViewInstanceName = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The masking view has been found. self.assertEqual( self.data.lunmaskctrl_name, conn.GetInstance(foundMaskingViewInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundMaskingViewInstanceName2 = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The masking view has not been found. self.assertIsNone(foundMaskingViewInstanceName2) # Bug 1393555 - port group has been deleted by another process. def test_find_portgroup(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundPortGroupInstanceName = ( self.driver.common.masking._find_port_group( conn, controllerConfigService, self.data.port_group)) # The port group has been found. self.assertEqual( self.data.port_group, conn.GetInstance(foundPortGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundPortGroupInstanceName2 = ( self.driver.common.masking._find_port_group( conn, controllerConfigService, self.data.port_group)) # The port group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundPortGroupInstanceName2) # Bug 1393555 - storage group has been deleted by another process. def test_get_storage_group_from_masking_view(self): conn = self.fake_ecom_connection() foundStorageGroupInstanceName = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The storage group has been found. self.assertEqual( self.data.storagegroupname, conn.GetInstance(foundStorageGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageGroupInstanceName2 = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The storage group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundStorageGroupInstanceName2) # Bug 1393555 - initiator group has been deleted by another process. def test_get_initiator_group_from_masking_view(self): conn = self.fake_ecom_connection() foundInitiatorGroupInstanceName = ( self.driver.common.masking._get_initiator_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The initiator group has been found. self.assertEqual( self.data.initiatorgroup_name, conn.GetInstance(foundInitiatorGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundInitiatorGroupInstanceName2 = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The initiator group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundInitiatorGroupInstanceName2) # Bug 1393555 - port group has been deleted by another process. def test_get_port_group_from_masking_view(self): conn = self.fake_ecom_connection() foundPortGroupInstanceName = ( self.driver.common.masking._get_port_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The port group has been found. self.assertEqual( self.data.port_group, conn.GetInstance(foundPortGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundPortGroupInstanceName2 = ( self.driver.common.masking._get_port_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The port group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundPortGroupInstanceName2) # Bug 1393555 - initiator group has been deleted by another process. def test_find_initiator_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundInitiatorGroupInstanceName = ( self.driver.common.masking._find_initiator_masking_group( conn, controllerConfigService, self.data.initiatorNames)) # The initiator group has been found. self.assertEqual( self.data.initiatorgroup_name, conn.GetInstance(foundInitiatorGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundInitiatorGroupInstanceName2 = ( self.driver.common.masking._find_initiator_masking_group( conn, controllerConfigService, self.data.initiatorNames)) # The initiator group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundInitiatorGroupInstanceName2) # Bug 1393555 - hardware id has been deleted by another process. def test_get_storage_hardware_id_instance_names(self): conn = self.fake_ecom_connection() foundHardwareIdInstanceNames = ( self.driver.common.masking._get_storage_hardware_id_instance_names( conn, self.data.initiatorNames, self.data.storage_system)) # The hardware id list has been found. self.assertEqual( '123456789012345', conn.GetInstance( foundHardwareIdInstanceNames[0])['StorageID']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundHardwareIdInstanceNames2 = ( self.driver.common.masking._get_storage_hardware_id_instance_names( conn, self.data.initiatorNames, self.data.storage_system)) # The hardware id list has not been found as it has been removed # externally. self.assertTrue(len(foundHardwareIdInstanceNames2) == 0) class EMCVMAXHTTPSTest(test.TestCase): def setUp(self): self.data = EMCVMAXCommonData() super(EMCVMAXHTTPSTest, self).setUp() driver = emc_vmax_https self.driver = driver self.user = 'user' self.password = 'pass' self.ip = '1.1.1.1' self.port = '5989' ip_port = (""%(ip)s:%(port)s"" % {'ip': self.ip, 'port': self.port}) self.url = (""https://%(ip_port)s"" % {'ip_port': ip_port}) self.key_file = ""test.pk"" self.fake_key_file = ""fake.pk"" self.cert_file = ""test.crt"" self.fake_cert_file = ""fake.crt"" self.ca_cert = ""cacert.crt"" self.fake_cacert = ""fake.crt"" self.x509 = {""key_file"": self.key_file, ""cert_file"": self.cert_file} self.driver.pywbem = mock.Mock() self.driver.pywbem.cim_http.AuthError = AuthError self.driver.pywbem.cim_http.parse_url = self.parse_url resobject = HTTPResponse() self.driver.HTTPSConnection.getresponse = ( mock.Mock(return_value=resobject)) self.driver.HTTPSConnection.verify_callback = ( mock.Mock(return_value='True')) self.driver.HTTPSConnection.endheaders = mock.Mock() self.driver.HTTPSConnection.send = mock.Mock() self.driver.HTTPSConnection.shutdown = mock.Mock() def parse_url(self, url): return self.ip, self.port, bool(""True"") def getResponseObject(self): resobject = HTTPResponse() return resobject def test_wbem_request(self): test_driver = self.driver test_driver.OpenSSL = mock.Mock() test_driver.HTTPSConnection.set_context = mock.Mock() body = self.driver.wbem_request( self.url, '', (self.user, self.password), x509=self.x509) self.assertIsNone(body) def test_wbem_request_with_Headers(self): test_driver = self.driver test_driver.OpenSSL = mock.Mock() test_driver.HTTPSConnection.set_context = mock.Mock() body = self.driver.wbem_request(self.url, '', (self.user, self.password), [], x509=self.x509) self.assertIsNone(body) def test_wbem_request_no_verification_and_cacerts(self): test_driver = self.driver test_driver.OpenSSL = mock.Mock() test_driver.HTTPSConnection.set_context = mock.Mock() body = self.driver.wbem_request(self.url, '', (self.user, self.password), [], no_verification=bool(""True""), ca_certs='testcacert.crt') self.assertIsNone(body) def test_wbem_request_no_verification(self): test_driver = self.driver test_driver.OpenSSL = mock.Mock() test_driver.HTTPSConnection.set_context = mock.Mock() body = self.driver.wbem_request(self.url, '', (self.user, self.password), [], ca_certs=None) self.assertIsNone(body) def test_set_context(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) testcase_driver.HTTPSConnection.verify_callback = ( mock.Mock(return_value='True')) testcase_driver.HTTPSConnection.host_matches_cert = ( mock.Mock(return_value='True')) httpconnection =\ testcase_driver.HTTPSConnection(self.ip, port=self.port, key_file=self.key_file, cert_file=self.cert_file, ca_certs=self.ca_cert, no_verification=True) self.assertIsNotNone(httpconnection) def test_set_context_noverification(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) testcase_driver.HTTPSConnection.verify_callback = ( mock.Mock(return_value='True')) testcase_driver.HTTPSConnection.host_matches_cert = ( mock.Mock(return_value='True')) httpconnection =\ testcase_driver.HTTPSConnection(self.ip, port=self.port, key_file=self.key_file, cert_file=self.cert_file, ca_certs='testcacert.crt') self.assertIsNotNone(httpconnection) def test_set_context_nokey(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) testcase_driver.HTTPSConnection.verify_callback = ( mock.Mock(return_value='True')) testcase_driver.HTTPSConnection.host_matches_cert = ( mock.Mock(return_value='True')) httpconnection =\ testcase_driver.HTTPSConnection(self.ip, port=self.port, cert_file=self.cert_file, ca_certs='testcacert.crt') self.assertIsNotNone(httpconnection) def test_set_context_fakekey(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) self.assertRaises(AuthError, testcase_driver.HTTPSConnection, self.ip, port=self.port, cert_file=self.cert_file, key_file=self.fake_key_file, ca_certs=self.ca_cert) self.assertRaises(AuthError, testcase_driver.HTTPSConnection, self.ip, port=self.port, cert_file=self.fake_cert_file, ca_certs=self.ca_cert) self.assertRaises(AuthError, testcase_driver.HTTPSConnection, self.ip, port=self.port, cert_file=self.cert_file, key_file=self.key_file, ca_certs=self.fake_cacert) def test_set_context_fakecert(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) self.assertRaises(AuthError, testcase_driver.HTTPSConnection, self.ip, port=self.port, cert_file=self.fake_cert_file, ca_certs='testcacert.crt') def test_set_context_nocacert(self): testcase_driver = self.driver testcase_driver.OpenSSL = mock.Mock() testcase_driver.OpenSSL.SSL = mock.Mock() testcase_driver.OpenSSL.SSL.SSLv23_METHOD = mock.Mock( return_value=Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.VERIFY_PEER = Context.VERIFY_PEER testcase_driver.OpenSSL.SSL.VERIFY_FAIL_IF_NO_PEER_CERT =\ Context.VERIFY_FAIL_IF_NO_PEER_CERT resContext = Context(Context.SSLv23_METHOD) testcase_driver.OpenSSL.SSL.Context =\ (mock.Mock(return_value=resContext)) testcase_driver.HTTPSConnection.verify_callback = ( mock.Mock(return_value='True')) testcase_driver.HTTPSConnection.host_matches_cert = ( mock.Mock(return_value='True')) httpconnection =\ testcase_driver.HTTPSConnection(self.ip, port=self.port, cert_file=self.cert_file, ca_certs=None) self.assertIsNotNone(httpconnection) def test_get_default_ca_certs(self): self.driver.os.path.exists = mock.Mock(return_value=True) self.assertIsNotNone(self.driver.get_default_ca_certs()) def test_get_default_ca_certs_No_Cert(self): delattr(self.driver.get_default_ca_certs, ""_path"") self.driver.os.path.exists = mock.Mock(return_value=False) self.assertIsNone(self.driver.get_default_ca_certs())"," WaitForCopyState=None): result = self._assocnames_hostedservice() result = self._assocnames_assoctierpolicy() elif ResultClass == 'CIM_StoragePool': result = self._assocnames_storagepool() elif ResultClass == 'EMC_VirtualProvisioningPool': result = self._assocnames_storagepool() elif ResultClass == 'CIM_DeviceMaskingGroup': result = self._assocnames_storagegroup() def _assocnames_hostedservice(self): return self._enum_hostedservice() def _assocnames_assoctierpolicy(self): return self._enum_assoctierpolicy() def _assocnames_storagepool(self): return self._enum_storagepool() def _assocnames_storagegroup(self): return self._enum_storagegroup() self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_no_fast() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_no_fast(self): doc = self.add_array_info(doc, emc) self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') doc.writexml(f) f.close() def create_fake_config_file_no_fast_with_interval_retries(self): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.add_array_info(doc, emc) doc = self.add_interval_and_retries(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST_int_ret.xml' config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') def create_fake_config_file_no_fast_with_interval(self): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.add_array_info(doc, emc) doc = self.add_interval_only(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST_int.xml' config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def create_fake_config_file_no_fast_with_retries(self): doc = minidom.Document() emc = doc.createElement(""EMC"") doc.appendChild(emc) doc = self.add_array_info(doc, emc) doc = self.add_retries_only(doc, emc) filename = 'cinder_emc_config_ISCSINoFAST_ret.xml' config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') doc.writexml(f) f.close() return config_file_path def add_array_info(self, doc, emc): array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) ecomserverip = doc.createElement(""EcomServerIp"") ecomserveriptext = doc.createTextNode(""1.1.1.1"") emc.appendChild(ecomserverip) ecomserverip.appendChild(ecomserveriptext) ecomserverport = doc.createElement(""EcomServerPort"") ecomserverporttext = doc.createTextNode(""10"") emc.appendChild(ecomserverport) ecomserverport.appendChild(ecomserverporttext) ecomusername = doc.createElement(""EcomUserName"") ecomusernametext = doc.createTextNode(""user"") emc.appendChild(ecomusername) ecomusername.appendChild(ecomusernametext) ecompassword = doc.createElement(""EcomPassword"") ecompasswordtext = doc.createTextNode(""pass"") emc.appendChild(ecompassword) ecompassword.appendChild(ecompasswordtext) portgroup = doc.createElement(""PortGroup"") portgrouptext = doc.createTextNode(self.data.port_group) portgroup.appendChild(portgrouptext) portgroups = doc.createElement(""PortGroups"") portgroups.appendChild(portgroup) emc.appendChild(portgroups) pool = doc.createElement(""Pool"") pooltext = doc.createTextNode(""gold"") emc.appendChild(pool) pool.appendChild(pooltext) array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) timeout = doc.createElement(""Timeout"") timeouttext = doc.createTextNode(""0"") emc.appendChild(timeout) timeout.appendChild(timeouttext) return doc def add_interval_and_retries(self, doc, emc): interval = doc.createElement(""Interval"") intervaltext = doc.createTextNode(""5"") emc.appendChild(interval) interval.appendChild(intervaltext) retries = doc.createElement(""Retries"") retriestext = doc.createTextNode(""40"") emc.appendChild(retries) retries.appendChild(retriestext) return doc def add_interval_only(self, doc, emc): interval = doc.createElement(""Interval"") intervaltext = doc.createTextNode(""20"") emc.appendChild(interval) interval.appendChild(intervaltext) return doc def add_retries_only(self, doc, emc): retries = doc.createElement(""Retries"") retriestext = doc.createTextNode(""70"") emc.appendChild(retries) retries.appendChild(retriestext) return doc def create_fake_config_file_1364232(self): config_file_1364232 = self.tempdir + '/' + filename def test_create_hardware_ids(self): conn = self.fake_ecom_connection() connector = { 'ip': '10.0.0.2', 'initiator': self.data.iscsi_initiator, 'host': 'fakehost'} initiatorNames = ( self.driver.common.masking._find_initiator_names(conn, connector)) storageHardwareIDInstanceNames = ( self.driver.common.masking._create_hardware_ids( conn, initiatorNames, self.data.storage_system)) self.assertEqual(self.data.iscsi_initiator, storageHardwareIDInstanceNames[0]) def test_get_pool_instance_and_system_name(self): conn = self.fake_ecom_connection() # V2 - old '+' separator storagesystem = {} storagesystem['SystemName'] = self.data.storage_system storagesystem['Name'] = self.data.storage_system pools = conn.EnumerateInstanceNames(""EMC_VirtualProvisioningPool"") poolname = 'gold' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertEqual(self.data.storage_system, systemname) self.assertEqual(self.data.storagepoolid, poolinstancename['InstanceID']) # V3 - note: V2 can also have the '-+-' separator storagesystem = {} storagesystem['SystemName'] = self.data.storage_system_v3 storagesystem['Name'] = self.data.storage_system_v3 pools = conn.EnumerateInstanceNames('Symm_SRPStoragePool') poolname = 'SRP_1' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertEqual(self.data.storage_system_v3, systemname) self.assertEqual('SYMMETRIX-+-000197200056-+-SRP_1', poolinstancename['InstanceID']) # Invalid poolname poolname = 'bogus' poolinstancename, systemname = ( self.driver.common.utils._get_pool_instance_and_system_name( conn, pools, storagesystem, poolname)) self.assertIsNone(poolinstancename) self.assertEqual(self.data.storage_system_v3, systemname) def test_get_hardware_type(self): iqn_initiator = 'iqn.1992-04.com.emc: 50000973f006dd80' hardwaretypeid = ( self.driver.utils._get_hardware_type(iqn_initiator)) self.assertEqual(5, hardwaretypeid) wwpn_initiator = '123456789012345' hardwaretypeid = ( self.driver.utils._get_hardware_type(wwpn_initiator)) self.assertEqual(2, hardwaretypeid) bogus_initiator = 'bogus' hardwaretypeid = ( self.driver.utils._get_hardware_type(bogus_initiator)) self.assertEqual(0, hardwaretypeid) def test_check_if_rollback_action_for_masking_required(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'storagetype:fastpolicy': 'GOLD1'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] rollbackDict = {} rollbackDict['isV3'] = False rollbackDict['defaultStorageGroupInstanceName'] = ( self.data.default_storage_group) rollbackDict['sgName'] = self.data.storagegroupname rollbackDict['volumeName'] = 'vol1' rollbackDict['fastPolicyName'] = 'GOLD1' rollbackDict['volumeInstance'] = vol rollbackDict['controllerConfigService'] = controllerConfigService rollbackDict['extraSpecs'] = extraSpecs # Path 1 - The volume is in another storage group that isn't the # default storage group expectedmessage = (_(""V2 rollback - Volume in another storage "" ""group besides default storage group."")) message = ( self.driver.common.masking. _check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) # Path 2 - The volume is not in any storage group rollbackDict['sgName'] = 'sq_not_exist' expectedmessage = (_(""V2 rollback, volume is not in any storage "" ""group."")) message = ( self.driver.common.masking. _check_if_rollback_action_for_masking_required( conn, rollbackDict)) self.assertEqual(expectedmessage, message) def test_migrate_cleanup(self): conn = self.fake_ecom_connection() extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False, 'storagetype:fastpolicy': 'GOLD1'} vol = EMC_StorageVolume() vol['name'] = self.data.test_volume['name'] vol['CreationClassName'] = 'Symm_StorageVolume' vol['ElementName'] = self.data.test_volume['id'] vol['DeviceID'] = self.data.test_volume['device_id'] vol['Id'] = self.data.test_volume['id'] vol['SystemName'] = self.data.storage_system vol['NumberOfBlocks'] = self.data.test_volume['NumberOfBlocks'] vol['BlockSize'] = self.data.test_volume['BlockSize'] # Added vol to vol.path vol['SystemCreationClassName'] = 'Symm_StorageSystem' vol.path = vol vol.path.classname = vol['CreationClassName'] # The volume is already belong to default storage group return_to_default = self.driver.common._migrate_cleanup( conn, vol, self.data.storage_system, 'GOLD1', vol['name'], extraSpecs) self.assertFalse(return_to_default) # The volume does not belong to default storage group return_to_default = self.driver.common._migrate_cleanup( conn, vol, self.data.storage_system, 'BRONZE1', vol['name'], extraSpecs) self.assertTrue(return_to_default) def test_wait_for_job_complete(self): myjob = SE_ConcreteJob() myjob.classname = 'SE_ConcreteJob' myjob['InstanceID'] = '9999' myjob['status'] = 'success' myjob['type'] = 'type' myjob['CreationClassName'] = 'SE_ConcreteJob' myjob['Job'] = myjob conn = self.fake_ecom_connection() self.driver.utils._is_job_finished = mock.Mock( return_value=True) rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) self.driver.utils._is_job_finished.assert_called_once_with( conn, myjob) self.assertEqual( True, self.driver.utils._is_job_finished.return_value) self.driver.utils._is_job_finished.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils._wait_for_job_complete(conn, myjob) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig def test_wait_for_sync(self): mysync = 'fakesync' conn = self.fake_ecom_connection() self.driver.utils._is_sync_complete = mock.Mock( return_value=True) rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) self.driver.utils._is_sync_complete.assert_called_once_with( conn, mysync) self.assertEqual( True, self.driver.utils._is_sync_complete.return_value) self.driver.utils._is_sync_complete.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig def test_wait_for_sync_extra_specs(self): mysync = 'fakesync' conn = self.fake_ecom_connection() file_name = ( self.create_fake_config_file_no_fast_with_interval_retries()) extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( self.config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.driver.utils._is_sync_complete = mock.Mock( return_value=True) rc = self.driver.utils.wait_for_sync(conn, mysync, extraSpecs) self.assertIsNone(rc) self.driver.utils._is_sync_complete.assert_called_once_with( conn, mysync) self.assertEqual( True, self.driver.utils._is_sync_complete.return_value) self.assertEqual(40, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(5, self.driver.utils._get_interval_in_secs(extraSpecs)) self.driver.utils._is_sync_complete.reset_mock() # Save the original state and restore it after this test loopingcall_orig = loopingcall.FixedIntervalLoopingCall loopingcall.FixedIntervalLoopingCall = mock.Mock() rc = self.driver.utils.wait_for_sync(conn, mysync) self.assertIsNone(rc) loopingcall.FixedIntervalLoopingCall.assert_called_once_with( mock.ANY) loopingcall.FixedIntervalLoopingCall.reset_mock() loopingcall.FixedIntervalLoopingCall = loopingcall_orig bExists = os.path.exists(file_name) if bExists: os.remove(file_name) # Bug 1395830: _find_lun throws exception when lun is not found. def test_find_lun(self): keybindings = {'CreationClassName': u'Symm_StorageVolume', 'SystemName': u'SYMMETRIX+000195900551', 'DeviceID': u'1', 'SystemCreationClassName': u'Symm_StorageSystem'} provider_location = {'classname': 'Symm_StorageVolume', 'keybindings': keybindings} volume = EMC_StorageVolume() volume['name'] = 'vol1' volume['provider_location'] = six.text_type(provider_location) self.driver.common.conn = self.driver.common._get_ecom_connection() findlun = self.driver.common._find_lun(volume) getinstance = self.driver.common.conn._getinstance_storagevolume( keybindings) # Found lun. self.assertEqual(getinstance, findlun) keybindings2 = {'CreationClassName': u'Symm_StorageVolume', 'SystemName': u'SYMMETRIX+000195900551', 'DeviceID': u'9', 'SystemCreationClassName': u'Symm_StorageSystem'} provider_location2 = {'classname': 'Symm_StorageVolume', 'keybindings': keybindings2} volume2 = EMC_StorageVolume() volume2['name'] = 'myVol' volume2['provider_location'] = six.text_type(provider_location2) verify_orig = self.driver.common.conn.GetInstance self.driver.common.conn.GetInstance = mock.Mock( return_value=None) findlun2 = self.driver.common._find_lun(volume2) # Not found. self.assertIsNone(findlun2) self.driver.utils.get_instance_name( provider_location2['classname'], keybindings2) self.driver.common.conn.GetInstance.assert_called_once_with( keybindings2) self.driver.common.conn.GetInstance.reset_mock() self.driver.common.conn.GetInstance = verify_orig keybindings3 = {'CreationClassName': u'Symm_StorageVolume', 'SystemName': u'SYMMETRIX+000195900551', 'DeviceID': u'9999', 'SystemCreationClassName': u'Symm_StorageSystem'} provider_location3 = {'classname': 'Symm_StorageVolume', 'keybindings': keybindings3} instancename3 = self.driver.utils.get_instance_name( provider_location3['classname'], keybindings3) # Error other than not found. arg = 9999, ""test_error"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.common.utils.process_exception_args, arg, instancename3) # Bug 1403160 - make sure the masking view is cleanly deleted def test_last_volume_delete_masking_view(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) maskingViewInstanceName = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) maskingViewName = conn.GetInstance( maskingViewInstanceName)['ElementName'] # Deleting Masking View failed self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.masking._last_volume_delete_masking_view, conn, controllerConfigService, maskingViewInstanceName, maskingViewName, extraSpecs) # Deleting Masking view successful self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking._last_volume_delete_masking_view( conn, controllerConfigService, maskingViewInstanceName, maskingViewName, extraSpecs) # Bug 1403160 - make sure the storage group is cleanly deleted def test_remove_last_vol_and_delete_sg(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) storageGroupName = self.data.storagegroupname storageGroupInstanceName = ( self.driver.utils.find_storage_masking_group( conn, controllerConfigService, storageGroupName)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeName = ""1403160-Vol"" extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False} # Deleting Storage Group failed self.assertRaises( exception.VolumeBackendAPIException, self.driver.common.masking._remove_last_vol_and_delete_sg, conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstanceName, volumeName, extraSpecs) # Deleting Storage group successful self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking._remove_last_vol_and_delete_sg( conn, controllerConfigService, storageGroupInstanceName, storageGroupName, volumeInstanceName, volumeName, extraSpecs) # Tests removal of last volume in a storage group V2 def test_remove_and_reset_members(self): extraSpecs = {'volume_backend_name': 'GOLD_BE', 'isV3': False} conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeInstance = conn.GetInstance(volumeInstanceName) volumeName = ""Last-Vol"" self.driver.common.masking.get_devices_from_storage_group = mock.Mock( return_value=['one_value']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) self.driver.common.masking.remove_and_reset_members( conn, controllerConfigService, volumeInstance, volumeName, extraSpecs) # Bug 1393555 - masking view has been deleted by another process. def test_find_maskingview(self): conn = self.fake_ecom_connection() foundMaskingViewInstanceName = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The masking view has been found. self.assertEqual( self.data.lunmaskctrl_name, conn.GetInstance(foundMaskingViewInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundMaskingViewInstanceName2 = ( self.driver.common.masking._find_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The masking view has not been found. self.assertIsNone(foundMaskingViewInstanceName2) # Bug 1393555 - port group has been deleted by another process. def test_find_portgroup(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundPortGroupInstanceName = ( self.driver.common.masking._find_port_group( conn, controllerConfigService, self.data.port_group)) # The port group has been found. self.assertEqual( self.data.port_group, conn.GetInstance(foundPortGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundPortGroupInstanceName2 = ( self.driver.common.masking._find_port_group( conn, controllerConfigService, self.data.port_group)) # The port group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundPortGroupInstanceName2) # Bug 1393555 - storage group has been deleted by another process. def test_get_storage_group_from_masking_view(self): conn = self.fake_ecom_connection() foundStorageGroupInstanceName = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The storage group has been found. self.assertEqual( self.data.storagegroupname, conn.GetInstance(foundStorageGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageGroupInstanceName2 = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The storage group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundStorageGroupInstanceName2) # Bug 1393555 - initiator group has been deleted by another process. def test_get_initiator_group_from_masking_view(self): conn = self.fake_ecom_connection() foundInitiatorGroupInstanceName = ( self.driver.common.masking._get_initiator_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The initiator group has been found. self.assertEqual( self.data.initiatorgroup_name, conn.GetInstance(foundInitiatorGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundInitiatorGroupInstanceName2 = ( self.driver.common.masking._get_storage_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The initiator group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundInitiatorGroupInstanceName2) # Bug 1393555 - port group has been deleted by another process. def test_get_port_group_from_masking_view(self): conn = self.fake_ecom_connection() foundPortGroupInstanceName = ( self.driver.common.masking._get_port_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The port group has been found. self.assertEqual( self.data.port_group, conn.GetInstance(foundPortGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundPortGroupInstanceName2 = ( self.driver.common.masking._get_port_group_from_masking_view( conn, self.data.lunmaskctrl_name, self.data.storage_system)) # The port group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundPortGroupInstanceName2) # Bug 1393555 - initiator group has been deleted by another process. def test_find_initiator_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundInitiatorGroupInstanceName = ( self.driver.common.masking._find_initiator_masking_group( conn, controllerConfigService, self.data.initiatorNames)) # The initiator group has been found. self.assertEqual( self.data.initiatorgroup_name, conn.GetInstance(foundInitiatorGroupInstanceName)['ElementName']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundInitiatorGroupInstanceName2 = ( self.driver.common.masking._find_initiator_masking_group( conn, controllerConfigService, self.data.initiatorNames)) # The initiator group has not been found as it has been deleted # externally or by another thread. self.assertIsNone(foundInitiatorGroupInstanceName2) # Bug 1393555 - hardware id has been deleted by another process. def test_get_storage_hardware_id_instance_names(self): conn = self.fake_ecom_connection() foundHardwareIdInstanceNames = ( self.driver.common.masking._get_storage_hardware_id_instance_names( conn, self.data.initiatorNames, self.data.storage_system)) # The hardware id list has been found. self.assertEqual( '123456789012345', conn.GetInstance( foundHardwareIdInstanceNames[0])['StorageID']) self.driver.common.masking.utils.get_existing_instance = mock.Mock( return_value=None) foundHardwareIdInstanceNames2 = ( self.driver.common.masking._get_storage_hardware_id_instance_names( conn, self.data.initiatorNames, self.data.storage_system)) # The hardware id list has not been found as it has been removed # externally. self.assertTrue(len(foundHardwareIdInstanceNames2) == 0) # Bug 1393555 - controller has been deleted by another process. def test_find_lunmasking_scsi_protocol_controller(self): self.driver.common.conn = self.fake_ecom_connection() foundControllerInstanceName = ( self.driver.common._find_lunmasking_scsi_protocol_controller( self.data.storage_system, self.data.connector)) # The controller has been found. self.assertEqual( 'OS-fakehost-gold-MV', self.driver.common.conn.GetInstance( foundControllerInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundControllerInstanceName2 = ( self.driver.common._find_lunmasking_scsi_protocol_controller( self.data.storage_system, self.data.connector)) # The controller has not been found as it has been removed # externally. self.assertIsNone(foundControllerInstanceName2) # Bug 1393555 - storage group has been deleted by another process. def test_get_policy_default_storage_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundStorageMaskingGroupInstanceName = ( self.driver.common.fast.get_policy_default_storage_group( conn, controllerConfigService, 'OS_default')) # The storage group has been found. self.assertEqual( 'OS_default_GOLD1_SG', conn.GetInstance( foundStorageMaskingGroupInstanceName)['ElementName']) self.driver.common.fast.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageMaskingGroupInstanceName2 = ( self.driver.common.fast.get_policy_default_storage_group( conn, controllerConfigService, 'OS_default')) # The storage group has not been found as it has been removed # externally. self.assertIsNone(foundStorageMaskingGroupInstanceName2) # Bug 1393555 - policy has been deleted by another process. def test_get_capacities_associated_to_policy(self): conn = self.fake_ecom_connection() total_capacity_gb, free_capacity_gb = ( self.driver.common.fast.get_capacities_associated_to_policy( conn, self.data.storage_system, self.data.policyrule)) # The capacities associated to the policy have been found. self.assertEqual(self.data.totalmanagedspace_gbs, total_capacity_gb) self.assertEqual(self.data.subscribedcapacity_gbs, free_capacity_gb) self.driver.common.fast.utils.get_existing_instance = mock.Mock( return_value=None) total_capacity_gb_2, free_capacity_gb_2 = ( self.driver.common.fast.get_capacities_associated_to_policy( conn, self.data.storage_system, self.data.policyrule)) # The capacities have not been found as the policy has been # removed externally. self.assertEqual(0, total_capacity_gb_2) self.assertEqual(0, free_capacity_gb_2) # Bug 1393555 - storage group has been deleted by another process. def test_find_storage_masking_group(self): conn = self.fake_ecom_connection() controllerConfigService = ( self.driver.utils.find_controller_configuration_service( conn, self.data.storage_system)) foundStorageMaskingGroupInstanceName = ( self.driver.common.utils.find_storage_masking_group( conn, controllerConfigService, self.data.storagegroupname)) # The storage group has been found. self.assertEqual( self.data.storagegroupname, conn.GetInstance( foundStorageMaskingGroupInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundStorageMaskingGroupInstanceName2 = ( self.driver.common.utils.find_storage_masking_group( conn, controllerConfigService, self.data.storagegroupname)) # The storage group has not been found as it has been removed # externally. self.assertIsNone(foundStorageMaskingGroupInstanceName2) # Bug 1393555 - pool has been deleted by another process. def test_get_pool_by_name(self): conn = self.fake_ecom_connection() foundPoolInstanceName = self.driver.common.utils.get_pool_by_name( conn, self.data.poolname, self.data.storage_system) # The pool has been found. self.assertEqual( self.data.poolname, conn.GetInstance(foundPoolInstanceName)['ElementName']) self.driver.common.utils.get_existing_instance = mock.Mock( return_value=None) foundPoolInstanceName2 = self.driver.common.utils.get_pool_by_name( conn, self.data.poolname, self.data.storage_system) # The pool has not been found as it has been removed externally. self.assertIsNone(foundPoolInstanceName2) def test_get_volume_stats_1364232(self): file_name = self.create_fake_config_file_1364232() arrayInfo = self.driver.utils.parse_file_to_get_array_map(file_name) self.assertEqual( '000198700439', arrayInfo[0]['SerialNumber']) self.assertEqual( 'FC_SLVR1', arrayInfo[0]['PoolName']) self.assertEqual( 'SILVER1', arrayInfo[0]['FastPolicy']) self.assertTrue( 'OS-PORTGROUP' in arrayInfo[0]['PortGroup']) bExists = os.path.exists(file_name) if bExists: os.remove(file_name) def test_intervals_and_retries_override( self): file_name = ( self.create_fake_config_file_no_fast_with_interval_retries()) extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( self.config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(40, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(5, self.driver.utils._get_interval_in_secs(extraSpecs)) bExists = os.path.exists(file_name) if bExists: os.remove(file_name) def test_intervals_and_retries_default(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( self.config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(60, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(10, self.driver.utils._get_interval_in_secs(extraSpecs)) def test_interval_only(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} file_name = self.create_fake_config_file_no_fast_with_interval() pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( self.config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(60, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(20, self.driver.utils._get_interval_in_secs(extraSpecs)) bExists = os.path.exists(file_name) if bExists: os.remove(file_name) def test_retries_only(self): extraSpecs = {'volume_backend_name': 'ISCSINoFAST'} file_name = self.create_fake_config_file_no_fast_with_retries() pool = 'gold+1234567891011' arrayInfo = self.driver.utils.parse_file_to_get_array_map( self.config_file_path) poolRec = self.driver.utils.extract_record(arrayInfo, pool) extraSpecs = self.driver.common._set_v2_extra_specs(extraSpecs, poolRec) self.assertEqual(70, self.driver.utils._get_max_job_retries(extraSpecs)) self.assertEqual(10, self.driver.utils._get_interval_in_secs(extraSpecs)) bExists = os.path.exists(file_name) if bExists: os.remove(file_name) @mock.patch.object( emc_vmax_utils.EMCVMAXUtils, 'isArrayV3', return_value=False) mock_capacity, mock_is_v3): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: stripedmetacount': '4', 'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) def test_delete_volume_no_fast_notfound(self, _mock_volume_type): keys['SystemCreationClassName'] = ( notfound_delete_vol['SystemCreationClassName']) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_storage_system): self.driver.create_volume(self.data.failed_delete_vol) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) def test_already_mapped_no_fast_success( self, _mock_volume_type, mock_wrap_group, mock_wrap_device, mock_is_same_host): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_wrap_group, mock_storage_group, mock_add_volume): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) _mock_volume_type, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_wrap_group, mock_storage_group, mock_initiator_group, mock_ig_from_mv): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, mock_volume_type, mock_storage_group, mock_ig, mock_igc): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_volume_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: stripedmetacount': '4', 'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_is_extendable): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, mock_volume_type, mock_volume, def test_create_snapshot_no_fast_failed(self): self.data.test_volume['volume_name'] = ""vmax-1234567"" self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_snapshot, self.data.test_volume) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, mock_volume_type, mock_sync_sv, mock_meta, mock_size): def test_create_volume_from_snapshot_no_fast_failed(self): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, mock_volume_type, mock_volume, mock_sync_sv, volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) @mock.patch.object( self, mock_sync, mock_create_replica, mock_volume_type, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) def test_migrate_volume_no_fast_success(self, _mock_volume_type): @mock.patch.object( emc_vmax_utils.EMCVMAXUtils, 'parse_pool_instance_id', return_value=('silver', 'SYMMETRIX+000195900551')) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, mock_values): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage, _mock_cg, _mock_members, _mock_rg): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, mock_volume_type, mock_volume, def test_find_volume_by_device_id_on_array(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils volumeInstanceName = utils.find_volume_by_device_id_on_array( conn, self.data.storage_system, self.data.test_volume['device_id']) expectVolume = {} expectVolume['CreationClassName'] = 'Symm_StorageVolume' expectVolume['DeviceID'] = self.data.test_volume['device_id'] expect = conn.GetInstance(expectVolume) self.assertEqual(expect, volumeInstanceName) def test_get_volume_element_name(self): volumeId = 'ea95aa39-080b-4f11-9856-a03acf9112ad' utils = self.driver.common.utils volumeElementName = utils.get_volume_element_name(volumeId) expectVolumeElementName = ( emc_vmax_utils.VOLUME_ELEMENT_NAME_PREFIX + volumeId) self.assertEqual(expectVolumeElementName, volumeElementName) def test_get_associated_replication_from_source_volume(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils repInstanceName = ( utils.get_associated_replication_from_source_volume( conn, self.data.storage_system, self.data.test_volume['device_id'])) expectInstanceName = ( conn.EnumerateInstanceNames('SE_StorageSynchronized_SV_SV')[0]) self.assertEqual(expectInstanceName, repInstanceName) def test_get_array_and_device_id_success(self): deviceId = '0123' arrayId = u'array1234' external_ref = {u'source-name': deviceId} volume = {'volume_metadata': [{'key': 'array', 'value': arrayId}] } utils = self.driver.common.utils (arrId, devId) = utils.get_array_and_device_id(volume, external_ref) self.assertEqual(arrayId, arrId) self.assertEqual(deviceId, devId) def test_get_array_and_device_id_failed(self): deviceId = '0123' arrayId = u'array1234' external_ref = {u'no-source-name': deviceId} volume = {'volume_metadata': [{'key': 'array', 'value': arrayId}] } utils = self.driver.common.utils self.assertRaises(exception.VolumeBackendAPIException, utils.get_array_and_device_id, volume, external_ref) def test_rename_volume(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils newName = 'new_name' volume = {} volume['CreationClassName'] = 'Symm_StorageVolume' volume['DeviceID'] = '1' volume['ElementName'] = 'original_name' pywbem = mock.Mock() pywbem.cim_obj = mock.Mock() pywbem.cim_obj.CIMInstance = mock.Mock() emc_vmax_utils.pywbem = pywbem volumeInstance = conn.GetInstance(volume) originalName = volumeInstance['ElementName'] volumeInstance = utils.rename_volume(conn, volumeInstance, newName) self.assertEqual(newName, volumeInstance['ElementName']) volumeInstance = utils.rename_volume( conn, volumeInstance, originalName) self.assertEqual(originalName, volumeInstance['ElementName']) def test_get_smi_version(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils version = utils.get_smi_version(conn) expected = int(str(self.data.majorVersion) + str(self.data.minorVersion) + str(self.data.revNumber)) self.assertEqual(version, expected) def test_get_pool_name(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils poolInstanceName = {} poolInstanceName['InstanceID'] = ""SATA_GOLD1"" poolInstanceName['CreationClassName'] = 'Symm_VirtualProvisioningPool' poolName = utils.get_pool_name(conn, poolInstanceName) self.assertEqual(poolName, self.data.poolname) def test_get_meta_members_capacity_in_byte(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils memberVolumeInstanceNames = [] volumeHead = EMC_StorageVolume() volumeHead.classname = 'Symm_StorageVolume' blockSize = self.data.block_size volumeHead['ConsumableBlocks'] = ( self.data.metaHead_volume['ConsumableBlocks']) volumeHead['BlockSize'] = blockSize volumeHead['DeviceID'] = self.data.metaHead_volume['DeviceID'] memberVolumeInstanceNames.append(volumeHead) metaMember1 = EMC_StorageVolume() metaMember1.classname = 'Symm_StorageVolume' metaMember1['ConsumableBlocks'] = ( self.data.meta_volume1['ConsumableBlocks']) metaMember1['BlockSize'] = blockSize metaMember1['DeviceID'] = self.data.meta_volume1['DeviceID'] memberVolumeInstanceNames.append(metaMember1) metaMember2 = EMC_StorageVolume() metaMember2.classname = 'Symm_StorageVolume' metaMember2['ConsumableBlocks'] = ( self.data.meta_volume2['ConsumableBlocks']) metaMember2['BlockSize'] = blockSize metaMember2['DeviceID'] = self.data.meta_volume2['DeviceID'] memberVolumeInstanceNames.append(metaMember2) capacities = utils.get_meta_members_capacity_in_byte( conn, memberVolumeInstanceNames) headSize = ( volumeHead['ConsumableBlocks'] - metaMember1['ConsumableBlocks'] - metaMember2['ConsumableBlocks']) expected = [headSize * blockSize, metaMember1['ConsumableBlocks'] * blockSize, metaMember2['ConsumableBlocks'] * blockSize] self.assertEqual(capacities, expected) def test_get_composite_elements(self): conn = self.fake_ecom_connection() utils = self.driver.common.utils volumeInstanceName = ( conn.EnumerateInstanceNames(""EMC_StorageVolume"")[0]) volumeInstance = conn.GetInstance(volumeInstanceName) memberVolumeInstanceNames = utils.get_composite_elements( conn, volumeInstance) expected = [self.data.metaHead_volume, self.data.meta_volume1, self.data.meta_volume2] self.assertEqual(memberVolumeInstanceNames, expected) def test_get_volume_model_updates(self): utils = self.driver.common.utils status = 'status-string' volumes = utils.get_volume_model_updates( None, self.driver.db, self.data.test_CG['id'], status) self.assertEqual(status, volumes[0]['status']) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSINoFAST'}) self, _mock_volume_type, _mock_storage, _mock_cg, _mock_rg): def _cleanup(self): if self.config_file_path: bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_fast() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_fast(self): array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) fastPolicy = doc.createElement(""FastPolicy"") fastPolicyText = doc.createTextNode(""GOLD1"") emc.appendChild(fastPolicy) fastPolicy.appendChild(fastPolicyText) ecomserverip = doc.createElement(""EcomServerIp"") ecomserveriptext = doc.createTextNode(""1.1.1.1"") emc.appendChild(ecomserverip) ecomserverip.appendChild(ecomserveriptext) ecomserverport = doc.createElement(""EcomServerPort"") ecomserverporttext = doc.createTextNode(""10"") emc.appendChild(ecomserverport) ecomserverport.appendChild(ecomserverporttext) ecomusername = doc.createElement(""EcomUserName"") ecomusernametext = doc.createTextNode(""user"") emc.appendChild(ecomusername) ecomusername.appendChild(ecomusernametext) ecompassword = doc.createElement(""EcomPassword"") ecompasswordtext = doc.createTextNode(""pass"") emc.appendChild(ecompassword) ecompassword.appendChild(ecompasswordtext) timeout = doc.createElement(""Timeout"") timeouttext = doc.createTextNode(""0"") emc.appendChild(timeout) timeout.appendChild(timeouttext) portgroup = doc.createElement(""PortGroup"") portgrouptext = doc.createTextNode(self.data.port_group) portgroup.appendChild(portgrouptext) pool = doc.createElement(""Pool"") pooltext = doc.createTextNode(""gold"") emc.appendChild(pool) pool.appendChild(pooltext) portgroups = doc.createElement(""PortGroups"") portgroups.appendChild(portgroup) emc.appendChild(portgroups) self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: stripedmetacount': '4', 'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_storage_group): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_wrapper): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage_group, mock_storage_system, mock_policy_pool): self.driver.create_volume(self.data.failed_delete_vol) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_wrap_group, mock_wrap_device, mock_is_same_host): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, mock_volume_type, mock_storage_group, mock_ig, mock_igc): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_volume_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_is_extendable): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, mock_volume_type, mock_volume, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, mock_volume_type, mock_sync_sv, mock_meta, mock_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST', 'FASTPOLICY': 'FC_GOLD1'}) self, mock_volume_type, mock_rep_service, mock_sync_sv): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, mock_volume_type, mock_vol, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) def test_migrate_volume_fast_success(self, _mock_volume_type): @mock.patch.object( emc_vmax_utils.EMCVMAXUtils, 'parse_pool_instance_id', return_value=('silver', 'SYMMETRIX+000195900551')) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, mock_values, mock_wrap): '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) def test_create_CG_fast_success( self, _mock_volume_type, _mock_storage_system): self.driver.create_consistencygroup( self.data.test_ctxt, self.data.test_CG) @mock.patch.object( emc_vmax_common.EMCVMAXCommon, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage, _mock_cg, _mock_members, _mock_rg): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'ISCSIFAST'}) self, _mock_volume_type, _mock_storage_system): def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_no_fast() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_no_fast(self): array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) ecomserverip = doc.createElement(""EcomServerIp"") ecomserveriptext = doc.createTextNode(""1.1.1.1"") emc.appendChild(ecomserverip) ecomserverip.appendChild(ecomserveriptext) ecomserverport = doc.createElement(""EcomServerPort"") ecomserverporttext = doc.createTextNode(""10"") emc.appendChild(ecomserverport) ecomserverport.appendChild(ecomserverporttext) ecomusername = doc.createElement(""EcomUserName"") ecomusernametext = doc.createTextNode(""user"") emc.appendChild(ecomusername) ecomusername.appendChild(ecomusernametext) ecompassword = doc.createElement(""EcomPassword"") ecompasswordtext = doc.createTextNode(""pass"") emc.appendChild(ecompassword) ecompassword.appendChild(ecompasswordtext) portgroup = doc.createElement(""PortGroup"") portgrouptext = doc.createTextNode(self.data.port_group) portgroup.appendChild(portgrouptext) portgroups = doc.createElement(""PortGroups"") portgroups.appendChild(portgroup) emc.appendChild(portgroups) pool = doc.createElement(""Pool"") pooltext = doc.createTextNode(""gold"") emc.appendChild(pool) pool.appendChild(pooltext) timeout = doc.createElement(""Timeout"") timeouttext = doc.createTextNode(""0"") emc.appendChild(timeout) timeout.appendChild(timeouttext) self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: stripedmetacount': '4', 'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) def test_delete_volume_no_fast_notfound(self, _mock_volume_type): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST', 'FASTPOLICY': 'FC_GOLD1'}) self, _mock_volume_type, mock_maskingview, mock_is_same_host): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST', 'FASTPOLICY': 'FC_GOLD1'}) def test_map_no_fast_failed(self, _mock_volume_type, mock_wrap_device): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, mock_volume_type, mock_mv, mock_ig, mock_igc): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) def test_extend_volume_no_fast_success(self, _mock_volume_type, _mock_volume_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_is_extendable): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) def test_migrate_volume_no_fast_success(self, _mock_volume_type): @mock.patch.object( emc_vmax_utils.EMCVMAXUtils, 'parse_pool_instance_id', return_value=('silver', 'SYMMETRIX+000195900551')) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) def test_retype_volume_no_fast_success( self, _mock_volume_type, mock_values): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_storage, _mock_cg, _mock_members, _mock_rg): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCNoFAST'}) self, _mock_volume_type, _mock_storage): common._initial_setup = mock.Mock( return_value={'volume_backend_name': 'FCNoFAST', 'storagetype:fastpolicy': None}) common._initial_setup = mock.Mock( return_value={'volume_backend_name': 'FCNoFAST', 'storagetype:fastpolicy': None}) common = self.driver.common common._initial_setup = mock.Mock( return_value={'volume_backend_name': 'FCNoFAST', 'fastpolicy': None}) def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_fast() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_fast(self): fastPolicy = doc.createElement(""FastPolicy"") fastPolicyText = doc.createTextNode(""GOLD1"") emc.appendChild(fastPolicy) fastPolicy.appendChild(fastPolicyText) ecomserverip = doc.createElement(""EcomServerIp"") ecomserveriptext = doc.createTextNode(""1.1.1.1"") emc.appendChild(ecomserverip) ecomserverip.appendChild(ecomserveriptext) ecomserverport = doc.createElement(""EcomServerPort"") ecomserverporttext = doc.createTextNode(""10"") emc.appendChild(ecomserverport) ecomserverport.appendChild(ecomserverporttext) ecomusername = doc.createElement(""EcomUserName"") ecomusernametext = doc.createTextNode(""user"") emc.appendChild(ecomusername) ecomusername.appendChild(ecomusernametext) ecompassword = doc.createElement(""EcomPassword"") ecompasswordtext = doc.createTextNode(""pass"") emc.appendChild(ecompassword) ecompassword.appendChild(ecompasswordtext) portgroup = doc.createElement(""PortGroup"") portgrouptext = doc.createTextNode(self.data.port_group) portgroup.appendChild(portgrouptext) pool = doc.createElement(""Pool"") pooltext = doc.createTextNode(""gold"") emc.appendChild(pool) pool.appendChild(pooltext) array = doc.createElement(""Array"") arraytext = doc.createTextNode(""1234567891011"") emc.appendChild(array) array.appendChild(arraytext) portgroups = doc.createElement(""PortGroups"") portgroups.appendChild(portgroup) emc.appendChild(portgroups) timeout = doc.createElement(""Timeout"") timeouttext = doc.createTextNode(""0"") emc.appendChild(timeout) timeout.appendChild(timeouttext) self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'storagetype: stripedmetacount': '4', 'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, mock_storage_system, mock_pool_policy): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_delete_volume_fast_success(self, _mock_volume_type, mock_storage_group): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_delete_volume_fast_notfound(self, _mock_volume_type): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, mock_wrapper, mock_storage_system, mock_pool_policy): self.driver.create_volume(self.data.failed_delete_vol) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) def test_map_fast_success(self, _mock_volume_type, mock_maskingview, mock_is_same_host): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) def test_map_fast_failed(self, _mock_volume_type, mock_wrap_device): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) def test_detach_fast_success(self, mock_volume_type, mock_maskingview, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_extend_volume_fast_success(self, _mock_volume_type, _mock_volume_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) _mock_volume_type, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, mock_volume_type, mock_volume, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, mock_volume_type, mock_sync_sv, mock_meta, mock_size): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST', 'FASTPOLICY': 'FC_GOLD1'}) self, mock_volume_type, mock_rep_service, mock_sync_sv): extraSpecs = {'storagetype:fastpolicy': 'FC_GOLD1', 'volume_backend_name': 'FCFAST', 'isV3': False} self.driver.common._initial_setup = ( mock.Mock(return_value=extraSpecs)) self.driver.common.extraSpecs = extraSpecs @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, mock_volume_type, mock_vol, mock_policy, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_migrate_volume_fast_success(self, _mock_volume_type): @mock.patch.object( emc_vmax_utils.EMCVMAXUtils, 'parse_pool_instance_id', return_value=('silver', 'SYMMETRIX+000195900551')) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_retype_volume_fast_success( self, _mock_volume_type, mock_values, mock_wrap): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_create_snapshot_for_CG_no_fast_success( self, _mock_volume_type, _mock_storage, _mock_cg, _mock_members, _mock_rg): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'FCFAST'}) def test_delete_snapshot_for_CG_no_fast_success( self, _mock_volume_type, _mock_storage): def test_create_clone_without_license(self): self.driver.utils.find_replication_service_capabilities = ( self.driver.utils.is_clone_licensed = ( return_value={'volume_backend_name': 'FCFAST', 'storagetype:fastpolicy': 'GOLD'}) def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.create_fake_config_file_v3() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_v3(self): self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage_system): self.data.test_ctxt, self.data.test_volume_CG_v3) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) def test_migrate_volume_v3_success(self, _mock_volume_type): '_get_fast_settings_from_storage_group', @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, mock_fast_settings, '_get_fast_settings_from_storage_group', @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, mock_fast_settings): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage, _mock_cg, _mock_members, mock_rg): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) self, _mock_volume_type, mock_maskingview, mock_is_same_host): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) def test_map_v3_failed(self, _mock_volume_type, mock_wrap_device): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'V3_BE'}) def test_detach_v3_success(self, mock_volume_type, mock_maskingview, storageConfigService = [] self.data.test_volume_v3, EMCVMAXCommonData.test_source_volume_v3) extraSpecs = common._initial_setup(self.data.test_volume_v3) storageGroupName = common.utils.get_v3_storage_group_name('SRP_1', 'Bronze', 'DSS') def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_multi_pool() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_multi_pool(self): self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') self.config_file_path) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) def test_retype_volume_multi_pool_success( self, _mock_volume_type): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_POOL_BE'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_multi_slo_v3() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_multi_slo_v3(self): self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') self.config_file_path) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, mock_storage_system): '_get_fast_settings_from_storage_group', @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, mock_fast_settings, @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, _mock_storage_system): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_SLO_BE'}) self, _mock_volume_type, _mock_storage_system): def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir) def setUp(self): self.tempdir = tempfile.mkdtemp() self.config_file_path = None self.create_fake_config_file_multi_ecom() self.addCleanup(self._cleanup) configuration.cinder_emc_config_file = self.config_file_path def create_fake_config_file_multi_ecom(self): self.config_file_path = self.tempdir + '/' + filename f = open(self.config_file_path, 'w') def test_array_info_multi_ecom_no_fast(self): self.config_file_path) self.config_file_path) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_ECOM_BE'}) self, _mock_volume_type, mock_storage_system): def test_create_CG_multi_array_failure( self, _mock_volume_type, _mock_storage_system): self.assertRaises(exception.VolumeBackendAPIException, self.driver.create_consistencygroup, self.data.test_ctxt, self.data.test_CG) @mock.patch.object( emc_vmax_common.EMCVMAXCommon, '_get_members_of_replication_group', return_value=None) @mock.patch.object( FakeDB, 'volume_get_all_by_group', return_value=None) @mock.patch.object( emc_vmax_common.EMCVMAXCommon, '_get_pool_and_storage_system', return_value=(None, EMCVMAXCommonData.storage_system)) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_ECOM_BE'}) # There is more than one unique arrays in the conf file def test_delete_CG_no_volumes_multi_array_failure( self, _mock_volume_type, _mock_storage_system, _mock_db_volumes, _mock_members): self.driver.delete_consistencygroup, self.data.test_ctxt, self.data.test_CG) @mock.patch.object( volume_types, 'get_volume_type_extra_specs', return_value={'volume_backend_name': 'MULTI_ECOM_BE'}) self, _mock_volume_type, mock_storage_system): def _cleanup(self): bExists = os.path.exists(self.config_file_path) if bExists: os.remove(self.config_file_path) shutil.rmtree(self.tempdir)",3424,2308
openstack%2Ffuel-qa~master~If14504c569bb6f14a96eda681a10e76dca7e4338,openstack/fuel-qa,master,If14504c569bb6f14a96eda681a10e76dca7e4338,Edit download link,MERGED,2015-12-10 18:02:25.000000000,2015-12-11 15:39:48.000000000,2015-12-11 15:39:47.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 14708}, {'_account_id': 15984}, {'_account_id': 16106}]","[{'number': 1, 'created': '2015-12-10 18:02:25.000000000', 'files': ['fuelweb_test/settings.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/a59e004870f8f61f2ef1b6f9e90616b62c3f2857', 'message': 'Edit download link\n\nAdd operational link for\nha_neutron_virtual_router test\n\nChange-Id: If14504c569bb6f14a96eda681a10e76dca7e4338\nCloses-Bug: #1524865\n'}]",0,256022,a59e004870f8f61f2ef1b6f9e90616b62c3f2857,12,11,1,9439,,,0,"Edit download link

Add operational link for
ha_neutron_virtual_router test

Change-Id: If14504c569bb6f14a96eda681a10e76dca7e4338
Closes-Bug: #1524865
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/22/256022/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/settings.py'],1,a59e004870f8f61f2ef1b6f9e90616b62c3f2857,download_vrouter_link," 'DOWNLOAD_LINK', 'http://ubuntu1.hti.pl/14.04.3/' 'ubuntu-14.04.3-server-amd64.iso')"," 'DOWNLOAD_LINK', 'http://cdimage.ubuntu.com/ubuntu/releases/14.04.2/' 'release/ubuntu-14.04.2-desktop-amd64+mac.iso')",2,2
openstack%2Foslo.concurrency~master~Ia848eeb1419932d880b82149859e161f90c8ce49,openstack/oslo.concurrency,master,Ia848eeb1419932d880b82149859e161f90c8ce49,Allow deletion of all lock files matching a glob,ABANDONED,2015-11-04 15:51:11.000000000,2015-12-11 15:37:02.000000000,,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 1297}, {'_account_id': 2472}, {'_account_id': 8912}, {'_account_id': 9796}, {'_account_id': 11600}]","[{'number': 1, 'created': '2015-11-04 15:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/878d4142b85b56d347f11563e6811b51ddc1ad6e', 'message': 'Allow deletion of all lock files matching a glob\n\nExtending the remove_external_lock_file functionality to allow\ndeletion of all lock files which match a glob.  This will be\nleveraged when cleaning up all lock files belonging to a resource\nwhich has since been deleted.\n\nChange-Id: Ia848eeb1419932d880b82149859e161f90c8ce49\n'}, {'number': 2, 'created': '2015-11-04 16:38:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/6e87d98a4f53286c2d6587860cf78ed1387f18b8', 'message': 'Allow deletion of all lock files matching a glob\n\nExtending the remove_external_lock_file functionality to allow\ndeletion of all lock files which match a glob.  This will be\nleveraged when cleaning up all lock files belonging to a resource\nwhich has since been deleted.\n\nChange-Id: Ia848eeb1419932d880b82149859e161f90c8ce49\n'}, {'number': 3, 'created': '2015-11-04 18:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/6e29e518079d46a5473632117426f1e44a88d67d', 'message': 'Allow deletion of all lock files matching a glob\n\nExtending the remove_external_lock_file functionality to allow\ndeletion of all lock files which match a glob.  This will be\nleveraged when cleaning up all lock files belonging to a resource\nwhich has since been deleted.\n\nChange-Id: Ia848eeb1419932d880b82149859e161f90c8ce49\n'}, {'number': 4, 'created': '2015-11-10 19:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/ef5852b08f427d3696951c8c00fee9decc14145e', 'message': 'Allow deletion of all lock files matching a glob\n\nExtending the remove_external_lock_file functionality to allow\ndeletion of all lock files which match a glob.  This will be\nleveraged when cleaning up all lock files belonging to a resource\nwhich has since been deleted.\n\nChange-Id: Ia848eeb1419932d880b82149859e161f90c8ce49\n'}, {'number': 5, 'created': '2015-11-30 15:02:32.000000000', 'files': ['oslo_concurrency/lockutils.py', 'oslo_concurrency/tests/unit/test_lockutils.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/2fdcccbb4ab3e4766aa93ce558baefe152cab309', 'message': 'Allow deletion of all lock files matching a glob\n\nExtending the remove_external_lock_file functionality to allow\ndeletion of all lock files which match a glob.  This will be\nleveraged when cleaning up all lock files belonging to a resource\nwhich has since been deleted.\n\nChange-Id: Ia848eeb1419932d880b82149859e161f90c8ce49\n'}]",17,241663,2fdcccbb4ab3e4766aa93ce558baefe152cab309,31,7,5,8912,,,0,"Allow deletion of all lock files matching a glob

Extending the remove_external_lock_file functionality to allow
deletion of all lock files which match a glob.  This will be
leveraged when cleaning up all lock files belonging to a resource
which has since been deleted.

Change-Id: Ia848eeb1419932d880b82149859e161f90c8ce49
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/63/241663/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_concurrency/lockutils.py', 'oslo_concurrency/tests/unit/test_lockutils.py']",2,878d4142b85b56d347f11563e6811b51ddc1ad6e,delete_lock_files_using_glob," def test_remove_external_file_lock_files_matching_glob(self): lock_dir = tempfile.mkdtemp() lock_names = [""project-12345"", ""project-12345-action"", ""project-12345_diff_action"", ""project-54321""] lock_files = [open(""%s/%s"" % (lock_dir, name), 'a') for name in lock_names] # Delete all locks like project-12345* lockutils.remove_external_lock_files_matching_glob('12345*', ""project-"", lock_dir) # All but last lock file should be removed for file in lock_names[:-1]: self.assertFalse(os.path.exists(os.path.join(lock_dir, file))) self.assertTrue(os.path.exists(os.path.join(lock_dir, lock_names[-1]))) shutil.rmtree(lock_dir, ignore_errors=True) ",,46,5
openstack%2Frally~master~I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a,openstack/rally,master,I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a,Fix timeout for scenario runners,MERGED,2015-10-16 13:11:59.000000000,2015-12-11 15:30:52.000000000,2015-12-11 15:30:46.000000000,"[{'_account_id': 3}, {'_account_id': 6172}, {'_account_id': 6835}, {'_account_id': 7369}, {'_account_id': 8491}, {'_account_id': 9545}, {'_account_id': 9601}, {'_account_id': 10475}, {'_account_id': 11748}, {'_account_id': 12395}, {'_account_id': 14817}]","[{'number': 1, 'created': '2015-10-16 13:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d2b59d0506e75b7b877ffbbfa04ada8ce521011e', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 2, 'created': '2015-10-22 13:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/49755def9b3f3ce5746763fb83acc662ff489bf7', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 3, 'created': '2015-10-22 13:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f4946b3ee63b1a41bb83ddba948a392676812372', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 4, 'created': '2015-10-23 15:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/275051477909e5d7f90776bd9671c1d77529e629', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 5, 'created': '2015-10-27 11:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4afbbe554d5a2c280e33046b66ed57d4f94e4873', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 6, 'created': '2015-10-27 13:06:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/23ef14853bcf7581ae595808f58c6f8c4a7b539c', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 7, 'created': '2015-10-27 16:40:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/234f8d190779f561868e1503a160f05657f048a8', 'message': ""[WIP] Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 8, 'created': '2015-10-28 14:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/4eeb2464e3a648d540d5cba7ad21e28152025d98', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 9, 'created': '2015-10-30 11:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aa05c788cd8652914e419287669c06e4bd7cd980', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 10, 'created': '2015-11-03 13:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3fec4417f3ddcb2e0cf9a6581c603d37097f2fb6', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 11, 'created': '2015-11-04 13:51:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3357caea11d47e129d8217854f9a1071de1d8320', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 12, 'created': '2015-11-05 10:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/3c5f04850e0fc19b255904cac6b82f35c0239d8d', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 13, 'created': '2015-11-05 12:01:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/9de412644f253946e52d5d483abfa8561587d433', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 14, 'created': '2015-11-10 14:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/8354ac84c467004454b0878c4aa56eb46ef9f569', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 15, 'created': '2015-11-10 14:10:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/66d7e9830655f4f7813667cee50a1233e46fd5c7', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 16, 'created': '2015-11-11 17:26:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/e82bc9c89d3c1249b95d77b5f02513fcceb0ad1c', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 17, 'created': '2015-11-11 18:43:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/843c1646848befead8d838d48a53f7a91a010f14', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 18, 'created': '2015-11-12 15:19:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aae6a87d5ecf05e0b86441b4a826fcca12b83387', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 19, 'created': '2015-11-12 20:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/25bdcd94648451a13b7ccec0fabd98b0aade446d', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 20, 'created': '2015-11-19 11:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/be7105e91406a284c74c975b79e9969dbac1af51', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 21, 'created': '2015-11-20 12:14:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/89bd36b25687b628cac07547c49ea86c321e0e31', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 22, 'created': '2015-11-24 08:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b7f32ea008566a8b56c471085fd8a25dbc27dc8e', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nAdd dummy scenarios on rps and constant runner to check that thread in\nwhich they are executed would terminated by runner timeout.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 23, 'created': '2015-11-24 11:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b2c0417719e38c902b97598a5ad697fa8e1d705c', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 24, 'created': '2015-11-25 13:53:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/c95eaee65af2ebd6dd3b5a20fc84959d35c7093d', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 25, 'created': '2015-11-25 16:46:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/b29bf005e48bba08c7ca44adc631b3e38eb493a5', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 26, 'created': '2015-11-25 18:46:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5dc905e946b33020b714b95ba2d0afd8ee5623ba', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 27, 'created': '2015-11-25 21:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/62ec1003559a4115d0df8a0c1c90db9bf0affd97', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 28, 'created': '2015-11-26 10:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/928bc1aa9e0bc09a9446cd144e341c28f160f765', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 29, 'created': '2015-11-26 12:28:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/cf2a5b81e69724b35a1265fca569428ebf93ae55', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 30, 'created': '2015-11-26 13:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0ebb3d734f451cea274847919fb86febcdd4c1ef', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTo fix this I have add function that is able to terminate threads\nof the same process by id. Also added function that is run in separate\nthread and check time execution of the threads. If they run longer then\ntimeout they would be terminated with raised exeption in those thread.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 31, 'created': '2015-11-26 15:26:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/a7d67f1f056d58e66dafda7b036bbe31a1b9ba78', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTasks are running in threads, so we need a way to kill threads.\nNew function `terminate_thread` added for this purpose.\n\nAlso added function that is run in separate thread and check\nexecution time of the threads. If they run longer then timeout\nthey would be terminated by terminate_thread.\n\nThread can not be killed during system call, so this mechanism\nisn't 100% effective. Due to this interruptable_sleep method\nwas added in order to be used by Dummy scenarios.\n\nAdded timeout argument to constant and rps runners. Also added\ntwo Dummy scenarios to test this.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 32, 'created': '2015-11-26 18:08:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/5ef6dc8275c932aea61851f6ce2e9f0fc2cb649e', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTasks are running in threads, so we need a way to kill threads.\nNew function `terminate_thread` added for this purpose.\n\nAlso added function that is run in separate thread and check\nexecution time of the threads. If they run longer then timeout\nthey would be terminated by terminate_thread.\n\nThread can not be killed during system call, so this mechanism\nisn't 100% effective. Due to this interruptable_sleep method\nwas added in order to be used by Dummy scenarios.\n\nAdded timeout argument to constant and rps runners. Also added\ntwo Dummy scenarios to test this.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 33, 'created': '2015-11-26 21:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/f49db0731538e97033bb0cf606a78cb7edcc1b58', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTasks are running in threads, so we need a way to kill threads.\nNew function `terminate_thread` added for this purpose.\n\nAlso added function that is run in separate thread and check\nexecution time of the threads. If they run longer then timeout\nthey would be terminated by terminate_thread.\n\nThread can not be killed during system call, so this mechanism\nisn't 100% effective. Due to this interruptable_sleep method\nwas added in order to be used by Dummy scenarios.\n\nAdded timeout argument to constant and rps runners. Also added\ntwo Dummy scenarios to test this.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 34, 'created': '2015-11-30 12:54:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/ea42f60edd6fdf3d9391fd63d163e1ec241502c5', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTasks are running in threads, so we need a way to kill threads.\nNew function `terminate_thread` added for this purpose.\n\nAlso added function that is run in separate thread and check\nexecution time of the threads. If they run longer then timeout\nthey would be terminated by terminate_thread.\n\nThread can not be killed during system call, so this mechanism\nisn't 100% effective. Due to this interruptable_sleep method\nwas added in order to be used by Dummy scenarios.\n\nAdded timeout argument to constant and rps runners. Also added\ntwo Dummy scenarios to test this.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}, {'number': 35, 'created': '2015-11-30 16:27:25.000000000', 'files': ['rally/exceptions.py', 'tests/unit/common/test_utils.py', 'tests/unit/plugins/common/scenarios/dummy/test_dummy.py', 'rally/plugins/common/scenarios/dummy/dummy.py', 'rally/plugins/common/runners/rps.py', 'tests/unit/plugins/common/runners/test_rps.py', 'rally/plugins/common/runners/constant.py', 'tests/unit/plugins/common/runners/test_constant.py', 'rally/common/utils.py', 'rally-jobs/rally.yaml', 'rally/task/runner.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/02c4d40ad992523650e9ad1e184d6984b2c87c38', 'message': ""Fix timeout for scenario runners\n\nTimeout for scenario runners doesn't work correctly.\nTo reproduce it just put in Dummy scenario args sleep bigger\nthen timeout and it won't fail, that will verify this bug.\n\nTasks are running in threads, so we need a way to kill threads.\nNew function `terminate_thread` added for this purpose.\n\nAlso added function that is run in separate thread and check\nexecution time of the threads. If they run longer then timeout\nthey would be terminated by terminate_thread.\n\nThread can not be killed during system call, so this mechanism\nisn't 100% effective. Due to this interruptable_sleep method\nwas added in order to be used by Dummy scenarios.\n\nAdded timeout argument to constant and rps runners. Also added\ntwo Dummy scenarios to test this.\n\nNew exception ThreadTimeoutException was added.\n\nCloses-Bug: #1385365\n\nCo-Authored-By: Roman Vasilets <rvasilets@mirantis.com>\nCo-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>\n\nChange-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a\n""}]",70,235910,02c4d40ad992523650e9ad1e184d6984b2c87c38,171,11,35,12395,,,0,"Fix timeout for scenario runners

Timeout for scenario runners doesn't work correctly.
To reproduce it just put in Dummy scenario args sleep bigger
then timeout and it won't fail, that will verify this bug.

Tasks are running in threads, so we need a way to kill threads.
New function `terminate_thread` added for this purpose.

Also added function that is run in separate thread and check
execution time of the threads. If they run longer then timeout
they would be terminated by terminate_thread.

Thread can not be killed during system call, so this mechanism
isn't 100% effective. Due to this interruptable_sleep method
was added in order to be used by Dummy scenarios.

Added timeout argument to constant and rps runners. Also added
two Dummy scenarios to test this.

New exception ThreadTimeoutException was added.

Closes-Bug: #1385365

Co-Authored-By: Roman Vasilets <rvasilets@mirantis.com>
Co-Authored-By: Sergey Scripnick <sskripnick@mirantis.com>

Change-Id: I2096ba6adaf81a18c80b2ae6a759ccc9e247c45a
",git fetch https://review.opendev.org/openstack/rally refs/changes/10/235910/13 && git format-patch -1 --stdout FETCH_HEAD,"['rally/plugins/common/runners/rps.py', 'rally/common/utils.py']",2,d2b59d0506e75b7b877ffbbfa04ada8ce521011e,bug/1385365,"import ctypes def terminate_thread(thread, exc_type=SystemExit): """"""Terminates a python thread from another thread. :param thread: a threading.Thread instance :param exc_type: an Exception object to be raised """""" if not thread.isAlive(): return exc = ctypes.py_object(exc_type) res = ctypes.pythonapi.PyThreadState_SetAsyncExc( ctypes.c_long(thread.ident), ctypes.py_object(exc)) if res == 0: raise ValueError(""nonexistent thread id"") elif res > 1: # NOTE(rvasilets) if it returns a number greater than one, you're # in trouble, and you should call it again with exc=NULL to revert # the effect ctypes.pythonapi.PyThreadState_SetAsyncExc(thread.ident, None) raise SystemError(""PyThreadState_SetAsyncExc failed"")",,30,1
openstack%2Fsecurity-specs~master~I38b38e9d4375ee6d8c0378e7f457119fce0bf8c6,openstack/security-specs,master,I38b38e9d4375ee6d8c0378e7f457119fce0bf8c6,Add python versions for classifier in setup.cfg,MERGED,2015-12-11 09:22:10.000000000,2015-12-11 15:18:30.000000000,2015-12-11 15:18:24.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10670}]","[{'number': 1, 'created': '2015-12-11 09:22:10.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/security-specs/commit/53fd8275f80a3ddb82e0ee04a2cf7bee04240948', 'message': 'Add python versions for classifier in setup.cfg\n\nChange-Id: I38b38e9d4375ee6d8c0378e7f457119fce0bf8c6\n'}]",0,256299,53fd8275f80a3ddb82e0ee04a2cf7bee04240948,7,3,1,16237,,,0,"Add python versions for classifier in setup.cfg

Change-Id: I38b38e9d4375ee6d8c0378e7f457119fce0bf8c6
",git fetch https://review.opendev.org/openstack/security-specs refs/changes/99/256299/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,53fd8275f80a3ddb82e0ee04a2cf7bee04240948,add-py, Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 3 Programming Language :: Python :: 3.3 Programming Language :: Python :: 3.4,,6,0
openstack%2Fdevstack~master~I32b3c0b774323ed71b54a5a06133872271cee9cb,openstack/devstack,master,I32b3c0b774323ed71b54a5a06133872271cee9cb,adjust config file deprecation for n-cpu ' This addresses all the regular deprecations we see for n-cpu here:,ABANDONED,2015-11-19 13:39:04.000000000,2015-12-11 15:17:40.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-11-19 13:39:04.000000000', 'files': ['lib/nova', 'lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/76524ba883324a097e5b30d6f25bcaac8f8eef90', 'message': ""adjust config file deprecation for n-cpu\n'\nThis addresses all the regular deprecations we see for n-cpu here:\n\nhttp://logs.openstack.org/90/245990/2/gate/gate-tempest-dsvm-neutron-full/6b397c6//logs/screen-n-cpu.txt.gz?level=WARNING#_2015-11-19_12_23_12_715\n\nChange-Id: I32b3c0b774323ed71b54a5a06133872271cee9cb\n""}]",0,247506,76524ba883324a097e5b30d6f25bcaac8f8eef90,5,3,1,2750,,,0,"adjust config file deprecation for n-cpu
'
This addresses all the regular deprecations we see for n-cpu here:

http://logs.openstack.org/90/245990/2/gate/gate-tempest-dsvm-neutron-full/6b397c6//logs/screen-n-cpu.txt.gz?level=WARNING#_2015-11-19_12_23_12_715

Change-Id: I32b3c0b774323ed71b54a5a06133872271cee9cb
",git fetch https://review.opendev.org/openstack/devstack refs/changes/06/247506/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/nova', 'lib/neutron-legacy']",2,76524ba883324a097e5b30d6f25bcaac8f8eef90,fix_deprecations,," iniset $NOVA_CONF neutron auth_strategy ""$Q_AUTH_STRATEGY""",4,5
openstack%2Fdevstack~master~I5adf97c4d6dea8197496d03285b34349aa352810,openstack/devstack,master,I5adf97c4d6dea8197496d03285b34349aa352810,fix deprecation with neutron,ABANDONED,2015-11-19 13:39:04.000000000,2015-12-11 15:17:21.000000000,,"[{'_account_id': 3}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 17207}]","[{'number': 1, 'created': '2015-11-19 13:39:04.000000000', 'files': ['lib/neutron-legacy'], 'web_link': 'https://opendev.org/openstack/devstack/commit/d33808f08618da1549f6cccc361b88f910b6afc1', 'message': 'fix deprecation with neutron\n\nOption ""username"" from group ""nova"" is deprecated. Use option\n""user-name"" from group ""nova\n\nVisible here -\nhttp://logs.openstack.org/90/245990/2/gate/gate-tempest-dsvm-neutron-full/6b397c6//logs/screen-q-svc.txt.gz?level=TRACE#_2015-11-19_12_22_44_315\n\nChange-Id: I5adf97c4d6dea8197496d03285b34349aa352810\n'}]",0,247505,d33808f08618da1549f6cccc361b88f910b6afc1,6,4,1,2750,,,0,"fix deprecation with neutron

Option ""username"" from group ""nova"" is deprecated. Use option
""user-name"" from group ""nova

Visible here -
http://logs.openstack.org/90/245990/2/gate/gate-tempest-dsvm-neutron-full/6b397c6//logs/screen-q-svc.txt.gz?level=TRACE#_2015-11-19_12_22_44_315

Change-Id: I5adf97c4d6dea8197496d03285b34349aa352810
",git fetch https://review.opendev.org/openstack/devstack refs/changes/05/247505/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/neutron-legacy'],1,d33808f08618da1549f6cccc361b88f910b6afc1,fix_deprecations," iniset $NOVA_CONF neutron ""user-name"" ""$Q_ADMIN_USERNAME"""," iniset $NOVA_CONF neutron username ""$Q_ADMIN_USERNAME""",1,1
openstack%2Fpython-muranoclient~master~Ic3da93bde00d96909cae106c358bf4a7d64d19a8,openstack/python-muranoclient,master,Ic3da93bde00d96909cae106c358bf4a7d64d19a8,Fixed an incorrect call to the artifacts client,MERGED,2015-11-27 10:00:48.000000000,2015-12-11 15:14:28.000000000,2015-12-01 21:02:51.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-27 10:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/27b7db06f8b29a52a970e2d5f263632f79d7198e', 'message': 'Fixed an incorrect call to the artifacts client\n\nThe artifacts client was called incorrectly in the ""toggle public""\ncall routine, leading to an exception when changing the visibility of\npackage if using Glare.\nThis has been fixed.\n\nChange-Id: Ic3da93bde00d96909cae106c358bf4a7d64d19a8\nCloses-Bug: #1501374\n'}, {'number': 2, 'created': '2015-12-01 14:43:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/48cb1d09f4df89e9cfad61275c7abe34bbafec8e', 'message': 'Fixed an incorrect call to the artifacts client\n\nThe artifacts client was called incorrectly in the ""toggle public""\ncall routine, leading to an exception when changing the visibility of\npackage if using Glare.\nThis has been fixed.\n\nChange-Id: Ic3da93bde00d96909cae106c358bf4a7d64d19a8\nCloses-Bug: #1501374\n'}, {'number': 3, 'created': '2015-12-01 16:59:03.000000000', 'files': ['muranoclient/v1/artifact_packages.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/9ee3790662c8356d6319d6212bc5b26cecaebb92', 'message': 'Fixed an incorrect call to the artifacts client\n\nThe artifacts client was called incorrectly in the ""toggle public""\ncall routine, leading to an exception when changing the visibility of\npackage if using Glare.\nThis has been fixed.\n\nChange-Id: Ic3da93bde00d96909cae106c358bf4a7d64d19a8\nCloses-Bug: #1501374\n'}]",0,250720,9ee3790662c8356d6319d6212bc5b26cecaebb92,18,9,3,8127,,,0,"Fixed an incorrect call to the artifacts client

The artifacts client was called incorrectly in the ""toggle public""
call routine, leading to an exception when changing the visibility of
package if using Glare.
This has been fixed.

Change-Id: Ic3da93bde00d96909cae106c358bf4a7d64d19a8
Closes-Bug: #1501374
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/20/250720/3 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/artifact_packages.py'],1,27b7db06f8b29a52a970e2d5f263632f79d7198e,bug/1501374, package = self.client.artifacts.get(app_id), package = self.client.get(app_id),1,1
openstack%2Fpython-muranoclient~master~I2759ade3cfcbade27b459ba9b21b29e240f7696e,openstack/python-muranoclient,master,I2759ade3cfcbade27b459ba9b21b29e240f7696e,'to_dict' method added to PackageWrapper class,MERGED,2015-11-30 09:55:22.000000000,2015-12-11 15:13:47.000000000,2015-12-01 18:42:21.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-30 09:55:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/60cb0b7e3e0a4a813d571ce88ee808972511bad6', 'message': ""'to_dict' method added to PackageWrapper class\n\nPackageWrapper objects, returned by the glare wrapper of the murano\nclient did not contain the 'to_dict' method which is needed for\ncarousel.\n\nAppropriate method has been added. It does not need to return the full\ndict representation of the object: just id, name and owner_id have to\nbe returned, as these are the only fields used by the carousel.\n\nChange-Id: I2759ade3cfcbade27b459ba9b21b29e240f7696e\nCloses-Bug: #1501405\n""}, {'number': 2, 'created': '2015-12-01 16:58:53.000000000', 'files': ['muranoclient/v1/artifact_packages.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/e5026fff1f958603fb9bf666590f1f2c2961c426', 'message': ""'to_dict' method added to PackageWrapper class\n\nPackageWrapper objects, returned by the glare wrapper of the murano\nclient did not contain the 'to_dict' method which is needed for\ncarousel.\n\nAppropriate method has been added. It does not need to return the full\ndict representation of the object: just id, name and owner_id have to\nbe returned, as these are the only fields used by the carousel.\n\nChange-Id: I2759ade3cfcbade27b459ba9b21b29e240f7696e\nCloses-Bug: #1501405\n""}]",0,251269,e5026fff1f958603fb9bf666590f1f2c2961c426,21,9,2,8127,,,0,"'to_dict' method added to PackageWrapper class

PackageWrapper objects, returned by the glare wrapper of the murano
client did not contain the 'to_dict' method which is needed for
carousel.

Appropriate method has been added. It does not need to return the full
dict representation of the object: just id, name and owner_id have to
be returned, as these are the only fields used by the carousel.

Change-Id: I2759ade3cfcbade27b459ba9b21b29e240f7696e
Closes-Bug: #1501405
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/69/251269/2 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/artifact_packages.py'],1,60cb0b7e3e0a4a813d571ce88ee808972511bad6,bug/1501405," def to_dict(self): return {'id': self.id, 'name': self.name, 'owner_id': self.owner_id} ",,3,0
openstack%2Foslo.service~master~I129d874d350c3efad780b160b4496e6527d371ed,openstack/oslo.service,master,I129d874d350c3efad780b160b4496e6527d371ed,Fix a race condition in signal handlers,MERGED,2015-12-11 07:42:35.000000000,2015-12-11 15:13:21.000000000,2015-12-11 15:13:20.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 7293}, {'_account_id': 9107}, {'_account_id': 9796}, {'_account_id': 14358}]","[{'number': 1, 'created': '2015-12-11 07:42:35.000000000', 'files': ['oslo_service/service.py'], 'web_link': 'https://opendev.org/openstack/oslo.service/commit/9ed30ac0b145d6712d817a19cf42c5fddf2c4f0b', 'message': 'Fix a race condition in signal handlers\n\nThe handlers of SIGTERM and SIGINT signals have a race condition. If\nthe same signal is received twice quickly, the signal handler can be\ncalled twice in a reentrant call. It is dangerous because currently\na lock is used indirectly to retrieve the instance of the\nSignalHandler singleton.\n\nThe change avoids the usage of the lock to support reentrant calls.\n\nSee the bug report for a full analysis and the use case where the bug\nwas seen.\n\nChange-Id: I129d874d350c3efad780b160b4496e6527d371ed\nCloses-Bug: #1524907\n'}]",0,256267,9ed30ac0b145d6712d817a19cf42c5fddf2c4f0b,14,9,1,9107,,,0,"Fix a race condition in signal handlers

The handlers of SIGTERM and SIGINT signals have a race condition. If
the same signal is received twice quickly, the signal handler can be
called twice in a reentrant call. It is dangerous because currently
a lock is used indirectly to retrieve the instance of the
SignalHandler singleton.

The change avoids the usage of the lock to support reentrant calls.

See the bug report for a full analysis and the use case where the bug
was seen.

Change-Id: I129d874d350c3efad780b160b4496e6527d371ed
Closes-Bug: #1524907
",git fetch https://review.opendev.org/openstack/oslo.service refs/changes/67/256267/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_service/service.py'],1,9ed30ac0b145d6712d817a19cf42c5fddf2c4f0b,bug/1524907, self.signal_handler.clear() self.signal_handler.clear(), SignalHandler().clear() SignalHandler().clear(),2,2
openstack%2Fpython-muranoclient~master~I98846bfad5fc03558dfc2e46fb4dcbfdb40489e8,openstack/python-muranoclient,master,I98846bfad5fc03558dfc2e46fb4dcbfdb40489e8,Glare client now properly filters by class name,MERGED,2015-11-30 11:03:04.000000000,2015-12-11 15:13:11.000000000,2015-12-01 18:44:50.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-30 11:03:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/784383175ead57e70d29b3bf0679317f58bbf6a5', 'message': 'Glare client now properly filters by class name\n\nAdaptor class which wraps the legacy filtering requests into the\nGlare-compatible ones has got a conversion for class_name ->\nclass_definitions attribute.\nThis fixes a bug when the engine could not properly fetch the package\nby class name when deploying an app.\n\nChange-Id: I98846bfad5fc03558dfc2e46fb4dcbfdb40489e8\nCloses-bug: #1503224\n'}, {'number': 2, 'created': '2015-12-01 16:58:49.000000000', 'files': ['muranoclient/v1/artifact_packages.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/4f2336fa382ed18cbdca89bf76eadb213551ada0', 'message': 'Glare client now properly filters by class name\n\nAdaptor class which wraps the legacy filtering requests into the\nGlare-compatible ones has got a conversion for class_name ->\nclass_definitions attribute.\nThis fixes a bug when the engine could not properly fetch the package\nby class name when deploying an app.\n\nChange-Id: I98846bfad5fc03558dfc2e46fb4dcbfdb40489e8\nCloses-bug: #1503224\n'}]",0,251299,4f2336fa382ed18cbdca89bf76eadb213551ada0,20,9,2,8127,,,0,"Glare client now properly filters by class name

Adaptor class which wraps the legacy filtering requests into the
Glare-compatible ones has got a conversion for class_name ->
class_definitions attribute.
This fixes a bug when the engine could not properly fetch the package
by class name when deploying an app.

Change-Id: I98846bfad5fc03558dfc2e46fb4dcbfdb40489e8
Closes-bug: #1503224
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/99/251299/1 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/artifact_packages.py'],1,784383175ead57e70d29b3bf0679317f58bbf6a5,bug/1503224," class_name = kwargs.pop('class_name', None) if class_name: kwargs['class_definitions'] = class_name",,3,0
openstack%2Fmurano~master~I252bb5545891903355cf7f8480a2cd76febcfebe,openstack/murano,master,I252bb5545891903355cf7f8480a2cd76febcfebe,Improve public network detection algorithm,MERGED,2015-12-08 18:59:00.000000000,2015-12-11 15:12:37.000000000,2015-12-11 15:12:36.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 8127}, {'_account_id': 13149}, {'_account_id': 13962}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-12-08 18:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/c9c79445b39c45d2e9b046d3ee5534accdbfb788', 'message': 'Improve public network detection algorithm\n\nIt is possible that there are several public networks exist.\nExistingNeutronNetwork used to pick first one of them.\nNow when internal network name or ID supplied it tries\nto find such public network that the internal network has\na common router with.\n\nChange-Id: I252bb5545891903355cf7f8480a2cd76febcfebe\nCloses-Bug: #1519236\n'}, {'number': 2, 'created': '2015-12-09 09:07:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/b4f90f90895f17b71e51501705f9061e1f84efab', 'message': 'Improve public network detection algorithm\n\nIt is possible that there are several public networks exist.\nExistingNeutronNetwork used to pick first one of them.\nNow when internal network name or ID supplied it tries\nto find such public network that the internal network has\na common router with.\n\nChange-Id: I252bb5545891903355cf7f8480a2cd76febcfebe\nCloses-Bug: #1519236\n'}, {'number': 3, 'created': '2015-12-09 12:57:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/murano/commit/f00966f1674fd2d4345bb8e6e4da34f6758d7fdb', 'message': 'Improve public network detection algorithm\n\nIt is possible that there are several public networks exist.\nExistingNeutronNetwork used to pick first one of them.\nNow when internal network name or ID supplied it tries\nto find such public network that the internal network has\na common router with.\n\nChange-Id: I252bb5545891903355cf7f8480a2cd76febcfebe\nCloses-Bug: #1524322\n'}, {'number': 4, 'created': '2015-12-09 13:14:49.000000000', 'files': ['meta/io.murano/Classes/resources/ExistingNeutronNetwork.yaml', 'murano/engine/system/net_explorer.py'], 'web_link': 'https://opendev.org/openstack/murano/commit/04bccb55b9923bc6742ed9677428740ed19ba6be', 'message': 'Improve public network detection algorithm\n\nIt is possible that there are several public networks exist.\nExistingNeutronNetwork used to pick first one of them.\nNow when internal network name or ID supplied it tries\nto find such public network that the internal network has\na common router with.\n\nChange-Id: I252bb5545891903355cf7f8480a2cd76febcfebe\nCloses-Bug: #1524322\n'}]",0,254910,04bccb55b9923bc6742ed9677428740ed19ba6be,40,10,4,7226,,,0,"Improve public network detection algorithm

It is possible that there are several public networks exist.
ExistingNeutronNetwork used to pick first one of them.
Now when internal network name or ID supplied it tries
to find such public network that the internal network has
a common router with.

Change-Id: I252bb5545891903355cf7f8480a2cd76febcfebe
Closes-Bug: #1524322
",git fetch https://review.opendev.org/openstack/murano refs/changes/10/254910/4 && git format-patch -1 --stdout FETCH_HEAD,"['meta/io.murano/Classes/resources/ExistingNeutronNetwork.yaml', 'murano/engine/system/net_explorer.py']",2,c9c79445b39c45d2e9b046d3ee5534accdbfb788,bug/1524322, def list_ports(self): client = self._clients.get_neutron_client() return client.list_ports()['ports'],,29,3
openstack%2Fpython-muranoclient~master~I24183f14e70fc6d5a53850d2ac00d5d52fdc5559,openstack/python-muranoclient,master,I24183f14e70fc6d5a53850d2ac00d5d52fdc5559,Fixed a download method wrapper in glare adaptor,MERGED,2015-11-30 11:07:21.000000000,2015-12-11 15:12:25.000000000,2015-12-01 18:44:39.000000000,"[{'_account_id': 3}, {'_account_id': 7225}, {'_account_id': 7226}, {'_account_id': 7535}, {'_account_id': 7549}, {'_account_id': 7821}, {'_account_id': 10063}, {'_account_id': 13149}, {'_account_id': 14265}, {'_account_id': 15168}]","[{'number': 1, 'created': '2015-11-30 11:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/646958aa43f5367dbb2b72dc223be7a83c1f1199', 'message': 'Fixed a download method wrapper in glare adaptor\n\nA method which downloads the package in PackageManagerAdapter class\nnow returns the full contents of the file instead of the iterator over\nthis contents.\n\nAlthough less memory-efficient this is needed to ensure the\ncompatibility with the legacy murano-api-based package downloader.\n\nChange-Id: I24183f14e70fc6d5a53850d2ac00d5d52fdc5559\nCloses-bug: #1521139\n'}, {'number': 2, 'created': '2015-12-01 16:58:58.000000000', 'files': ['muranoclient/v1/artifact_packages.py'], 'web_link': 'https://opendev.org/openstack/python-muranoclient/commit/dce5e20f9c20ca5c23c72a672d2edd0480fff907', 'message': 'Fixed a download method wrapper in glare adaptor\n\nA method which downloads the package in PackageManagerAdapter class\nnow returns the full contents of the file instead of the iterator over\nthis contents.\n\nAlthough less memory-efficient this is needed to ensure the\ncompatibility with the legacy murano-api-based package downloader.\n\nChange-Id: I24183f14e70fc6d5a53850d2ac00d5d52fdc5559\nCloses-bug: #1521139\n'}]",0,251303,dce5e20f9c20ca5c23c72a672d2edd0480fff907,21,10,2,8127,,,0,"Fixed a download method wrapper in glare adaptor

A method which downloads the package in PackageManagerAdapter class
now returns the full contents of the file instead of the iterator over
this contents.

Although less memory-efficient this is needed to ensure the
compatibility with the legacy murano-api-based package downloader.

Change-Id: I24183f14e70fc6d5a53850d2ac00d5d52fdc5559
Closes-bug: #1521139
",git fetch https://review.opendev.org/openstack/python-muranoclient refs/changes/03/251303/2 && git format-patch -1 --stdout FETCH_HEAD,['muranoclient/v1/artifact_packages.py'],1,646958aa43f5367dbb2b72dc223be7a83c1f1199,bug/1521139," return """".join(self.glare.download(app_id))", return self.glare.download(app_id),1,1
openstack%2Fhorizon~master~I6701394d7616fc85825e26a4f2c6752c076eaf19,openstack/horizon,master,I6701394d7616fc85825e26a4f2c6752c076eaf19,Move Page Layout Styles out of horizon.scss,MERGED,2015-11-17 15:26:55.000000000,2015-12-11 15:11:35.000000000,2015-12-11 15:11:33.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8040}, {'_account_id': 9981}, {'_account_id': 10063}, {'_account_id': 11098}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 16707}]","[{'number': 1, 'created': '2015-11-17 15:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/6e78747c145e4f85ae4a2757a50b28ea326d051f', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 2, 'created': '2015-11-18 04:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/e0f8d5c8867a18ea33a2444b60c9873861ba29bb', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 3, 'created': '2015-11-18 23:49:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/9624a347c67d6e19ba267a136f2448a17ede6a35', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 4, 'created': '2015-11-20 00:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/23974c166938f9767f84817bad30901371203ed5', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 5, 'created': '2015-11-21 03:47:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2e16ab38f1bce34921c57738fd57fe9220b38c2a', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 6, 'created': '2015-11-21 16:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b31f1c2538e1af551ae2ab2bba485ea67ae427ff', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}, {'number': 7, 'created': '2015-12-03 16:37:31.000000000', 'files': ['openstack_dashboard/static/dashboard/scss/_layout.scss', 'openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/f96557ec2fda9801db088ddab2a0179f63ca9b8b', 'message': 'Move Page Layout Styles out of horizon.scss\n\nhorizon.scss needs contain less styles and be used more for general\nimporting.  Moving page layout styles into another file.\n\nPartially-Implements: blueprint horizon-theme-css-reorg\n\nChange-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19\n'}]",0,246445,f96557ec2fda9801db088ddab2a0179f63ca9b8b,27,12,7,11778,,,0,"Move Page Layout Styles out of horizon.scss

horizon.scss needs contain less styles and be used more for general
importing.  Moving page layout styles into another file.

Partially-Implements: blueprint horizon-theme-css-reorg

Change-Id: I6701394d7616fc85825e26a4f2c6752c076eaf19
",git fetch https://review.opendev.org/openstack/horizon refs/changes/45/246445/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/static/dashboard/scss/_layout.scss', 'openstack_dashboard/static/dashboard/scss/horizon.scss']",2,6e78747c145e4f85ae4a2757a50b28ea326d051f,bug/1517084,"// Main Page Layout @import ""layout""; ","// Basic Page Layout // Make the sidebar span the entire page, instead of just the Viewport // Display Table is not ideal, but it will allow dynamic resizing of // the sidebar while growing its container to fill the entire window html, body, #container { height: 100%; } // Theme Note: // The following 1px is the default 1px for nav border in Bootstrap. If // this value is customized, then this value must change to compensate $navbar-border-size: 1px !default; $navbar-true-height: $navbar-height + $navbar-border-size !default; #main_content { height: 100%; /* fallback if needed --> its scrolls, but it works */ height: calc(100% - #{$navbar-true-height}); display: table; } #content_body, #sidebar { display: table-cell; vertical-align: top; } #content_body { width: 100%; padding-left: $content-body-padding; padding-right: $content-body-padding; } // Basic Page Layout End ",33,34
openstack%2Fnova~master~Ia7629de15055c40523882fa2fbc808e3cfe6fa6d,openstack/nova,master,Ia7629de15055c40523882fa2fbc808e3cfe6fa6d,Test patch libvirt race condition (do not merge),ABANDONED,2015-06-15 10:22:37.000000000,2015-12-11 15:10:02.000000000,,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 8300}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10485}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-06-15 10:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/caf28f04b1169336c85d4d2b09c1dde1f2bc7b61', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 2, 'created': '2015-06-15 13:21:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/743cb15f859689289257659a30ed7a146008b8fe', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 3, 'created': '2015-06-16 09:59:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b42749a323d6a70302bf0350969acecd885efcee', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 4, 'created': '2015-06-16 13:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/415b7de5f91cb240fbe059768088fb02ba5aee9c', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 5, 'created': '2015-06-17 06:50:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e98446f2e85e66dec385652c48c1f56db91cbe3c', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 6, 'created': '2015-06-17 15:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8355603221e2019288ddc4f25e61daefc919dcd8', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 7, 'created': '2015-06-17 18:08:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/30dd0d16380b288e19416cbe50090dcec0780ad9', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 8, 'created': '2015-06-18 10:55:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7f794df90d579f12410a9c85f7706d9b1810e15b', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 9, 'created': '2015-06-19 05:51:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/022f8a6d57db08448f65635ca382754c453941f3', 'message': 'Test patch race condition in delete (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 10, 'created': '2015-06-23 08:32:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5a1e93244fdd3f70115f5c9bdd3d9c1f71e861da', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 11, 'created': '2015-06-24 12:11:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8256fecd0b05f509b4dc0a245bd623f37af6c52e', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 12, 'created': '2015-06-25 07:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3cf690f521fb1e42afe3b4256515e5722644a501', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 13, 'created': '2015-06-25 09:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c8b6ca465cc9515dcd0b01984e4ab903813362f5', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 14, 'created': '2015-06-25 10:19:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d430fad0332ce19cb88baf648be87fcb13e96294', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 15, 'created': '2015-06-25 10:41:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5279433d356d5b02934bb130711488f4fbe3d588', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 16, 'created': '2015-06-25 13:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c73c91f57e83f72ac045cec655cc31cab8325a94', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 17, 'created': '2015-06-26 06:34:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/37a9d28ceb057819369d110f9193e7d59b5325f4', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 18, 'created': '2015-06-29 13:31:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5482b705a4ad7607b95265737a72d16ba7981b40', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 19, 'created': '2015-08-11 09:32:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d8c0b2ffbe2ddb8e58b16de4d20c1c854df6a3a', 'message': 'Test patch libvirt race condition (do not merge)\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 20, 'created': '2015-08-27 08:30:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d0820e005f895e6a9a01cfb7b9bbacc5abd1eaa1', 'message': 'Test patch libvirt race condition (do not merge)\n\nImageCacheManager deletes base image while image backend is copying\nimage to the instance path leading instance to go in the error state.\n\nDepends-On: I7732757653d39abbc6166307efa34920af1cf073\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 21, 'created': '2015-09-29 13:03:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e97089b0ff6f603183cd381ec95e83586a99279', 'message': 'Test patch libvirt race condition (do not merge)\n\nImageCacheManager deletes base image while image backend is copying\nimage to the instance path leading instance to go in the error state.\nDepends-On: I7732757653d39abbc6166307efa34920af1cf073\n\nDepends-On: I7732757653d39abbc6166307efa34920af1cf073\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 22, 'created': '2015-09-29 14:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18cde820433a2c408b906358355edc18a53b913d', 'message': 'Test patch libvirt race condition (do not merge)\n\nImageCacheManager deletes base image while image backend is copying\nimage to the instance path leading instance to go in the error state.\nDepends-On: I7732757653d39abbc6166307efa34920af1cf073\n\nDepends-On: I7732757653d39abbc6166307efa34920af1cf073\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 23, 'created': '2015-12-11 11:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/99227545af9b9f95336ba3ee9d1fb526c4027ad5', 'message': 'Test patch libvirt race condition (do not merge)\n\nImageCacheManager deletes base image while image backend is copying\nimage to the instance path leading instance to go in the error state.\n\nDepends-On: I337ce28e2fc516c91bec61ca3639ebff0029ad49\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}, {'number': 24, 'created': '2015-12-11 12:20:20.000000000', 'files': ['nova/virt/libvirt/imagecache.py', 'nova/tests/unit/virt/test_images.py', 'nova/tests/unit/virt/libvirt/test_imagecache.py', 'nova/tests/unit/virt/libvirt/fake_libvirt_utils.py', 'etc/nova/rootwrap.d/compute.filters', 'nova/virt/libvirt/utils.py', 'nova/virt/libvirt/imagebackend.py', 'nova/virt/images.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/970b3bb2d5d6681b3ac83ac43f9967c907960f10', 'message': 'Test patch libvirt race condition (do not merge)\n\nImageCacheManager deletes base image while image backend is copying\nimage to the instance path leading instance to go in the error state.\n\nChange-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d\n'}]",0,191732,970b3bb2d5d6681b3ac83ac43f9967c907960f10,213,16,24,10485,,,0,"Test patch libvirt race condition (do not merge)

ImageCacheManager deletes base image while image backend is copying
image to the instance path leading instance to go in the error state.

Change-Id: Ia7629de15055c40523882fa2fbc808e3cfe6fa6d
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/191732/24 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_api.py', 'nova/tests/unit/api/openstack/compute/plugins/v3/test_servers.py', 'nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/api/openstack/compute/test_servers.py', 'nova/compute/api.py']",5,caf28f04b1169336c85d4d2b09c1dde1f2bc7b61,test/1256838," if (not instance.host or instance.vm_state == vm_states.SHELVED_OFFLOADED): is_local_delete = True else: try: except exception.ComputeHostNotFound: is_local_delete = True # isn't up or is unknown i.e. instance.host is None, delete # instance from db and clean bdms info and network info else: if original_task_state in (task_states.DELETING, task_states.SOFT_DELETING): LOG.info(_LI('Instance is already in deleting state, ' 'ignoring this request'), instance=instance) quotas.rollback() return self._record_action_start(context, instance, instance_actions.DELETE) # NOTE(snikitin): If instance's vm_state is 'soft-delete', # we should not count reservations here, because instance # in soft-delete vm_state have already had quotas # decremented. More details: # https://bugs.launchpad.net/nova/+bug/1333145 if instance.vm_state == vm_states.SOFT_DELETED: quotas.rollback() cb(context, instance, bdms, reservations=quotas.reservations) except (exception.InstanceNotFound, exception.ObjectActionError):"," shelved_offloaded = (instance.vm_state == vm_states.SHELVED_OFFLOADED) if not instance.host and not shelved_offloaded: try: compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.start"" % delete_type) instance.destroy() compute_utils.notify_about_instance_usage( self.notifier, context, instance, ""%s.end"" % delete_type, system_metadata=instance.system_metadata) quotas.commit() return except exception.ObjectActionError: instance.refresh() is_local_delete = True try: if not shelved_offloaded: if not is_local_delete: if original_task_state in (task_states.DELETING, task_states.SOFT_DELETING): LOG.info(_LI('Instance is already in deleting state, ' 'ignoring this request'), instance=instance) quotas.rollback() return self._record_action_start(context, instance, instance_actions.DELETE) # NOTE(snikitin): If instance's vm_state is 'soft-delete', # we should not count reservations here, because instance # in soft-delete vm_state have already had quotas # decremented. More details: # https://bugs.launchpad.net/nova/+bug/1333145 if instance.vm_state == vm_states.SOFT_DELETED: quotas.rollback() cb(context, instance, bdms, reservations=quotas.reservations) except exception.ComputeHostNotFound: pass # isn't up, delete instance from db and clean bdms info and # network info except exception.InstanceNotFound:",202,113
openstack%2Fhorizon~master~I3509596d6adb7dc5e4f8684c73f60a52bf532bcf,openstack/horizon,master,I3509596d6adb7dc5e4f8684c73f60a52bf532bcf,usage.html doesn't need such specific styles.,MERGED,2015-11-17 22:05:18.000000000,2015-12-11 15:05:27.000000000,2015-12-11 15:05:25.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6763}, {'_account_id': 7665}, {'_account_id': 8040}, {'_account_id': 9981}, {'_account_id': 10063}, {'_account_id': 11098}, {'_account_id': 11778}, {'_account_id': 12071}, {'_account_id': 12826}, {'_account_id': 13785}, {'_account_id': 14124}, {'_account_id': 17172}, {'_account_id': 17645}]","[{'number': 1, 'created': '2015-11-17 22:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/930b921fc524614cc6fc1c69ea6affd6dfbc1170', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 2, 'created': '2015-11-18 04:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/2ea838b6182ee3ab22a591ade7a697b6a2e97e59', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 3, 'created': '2015-11-18 23:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/76c2dc48a5c809e20a4f32bf99005364bcda90bf', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 4, 'created': '2015-11-20 00:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a1287b3412ea4ef800000a0fc61ae21e3b505061', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 5, 'created': '2015-11-21 03:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/62e8ead19b21fbf6ce85c79618709f1bb741759f', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 6, 'created': '2015-11-21 16:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0bd68fccf0fc440866376b4e85251416008c347a', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}, {'number': 7, 'created': '2015-12-03 16:17:48.000000000', 'files': ['openstack_dashboard/dashboards/admin/overview/templates/overview/usage.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss'], 'web_link': 'https://opendev.org/openstack/horizon/commit/4ce1cfddba81d4f508668e95511dc77634f3f52e', 'message': ""usage.html doesn't need such specific styles.\n\nusage.html has a lot of style to it, lets just keep it simple and\ninherit from Bootstrap.  Also, list-inline is already a style that\nwe can take advantage of.\n\nChange-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf\nPartially-Implements: blueprint horizon-theme-css-reorg\nPartially-Implements: blueprint bootstrap-html-standards\n""}]",3,246622,4ce1cfddba81d4f508668e95511dc77634f3f52e,33,15,7,11778,,,0,"usage.html doesn't need such specific styles.

usage.html has a lot of style to it, lets just keep it simple and
inherit from Bootstrap.  Also, list-inline is already a style that
we can take advantage of.

Change-Id: I3509596d6adb7dc5e4f8684c73f60a52bf532bcf
Partially-Implements: blueprint horizon-theme-css-reorg
Partially-Implements: blueprint bootstrap-html-standards
",git fetch https://review.opendev.org/openstack/horizon refs/changes/22/246622/6 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/dashboards/admin/overview/templates/overview/usage.html', 'openstack_dashboard/static/dashboard/scss/horizon.scss']",2,930b921fc524614cc6fc1c69ea6affd6dfbc1170,bug/1517084,,"#monitoring { background: $body-bg; font-size: 14px; height: 20px; margin: -18px 0 25px; padding: 10px; border: 1px solid $border-color; } #monitoring h3 { font-size: 14px; font-weight: normal; float: left; line-height: 18px; } #external_links, #external_links li { float: left; } #external_links li { margin: 0 0 0 15px; } ",2,24
openstack%2Ftempest~master~Ia11ecf7bd147e35b7c8ad3db0eaad17f893e78ba,openstack/tempest,master,Ia11ecf7bd147e35b7c8ad3db0eaad17f893e78ba,Put py34 first in the env order of tox,MERGED,2015-12-02 03:42:38.000000000,2015-12-11 15:01:58.000000000,2015-12-11 15:01:56.000000000,"[{'_account_id': 3}, {'_account_id': 1921}, {'_account_id': 2813}, {'_account_id': 7350}, {'_account_id': 7428}, {'_account_id': 8871}, {'_account_id': 9323}, {'_account_id': 10385}, {'_account_id': 12017}, {'_account_id': 16237}, {'_account_id': 16707}]","[{'number': 1, 'created': '2015-12-02 03:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a357a0ef733db5b42ebb792242037370575787c', 'message': 'Put py34 first in the env order of tox\n\nTo solve the problem of ""db type could not be determined"" on py34\nwe have to run first the py34 env to, then, run py27. This patch\nputs py34 first on the tox.ini list of envs to avoid this problem\nto happen.\nCloses-bug: #1489059\nChange-Id: Ia11ecf7bd147e35b7c8ad3db0eaad17f893e78ba\n'}, {'number': 2, 'created': '2015-12-02 03:48:53.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/768c80765717ce3c4ce224a35389b337c43591ef', 'message': 'Put py34 first in the env order of tox\n\nTo solve the problem of ""db type could not be determined"" on py34\nwe have to run first the py34 env to, then, run py27. This patch\nputs py34 first in the tox.ini list of envs to avoid this problem\nto happen.\nCloses-bug: #1489059\nChange-Id: Ia11ecf7bd147e35b7c8ad3db0eaad17f893e78ba\n'}]",0,252164,768c80765717ce3c4ce224a35389b337c43591ef,22,11,2,9323,,,0,"Put py34 first in the env order of tox

To solve the problem of ""db type could not be determined"" on py34
we have to run first the py34 env to, then, run py27. This patch
puts py34 first in the tox.ini list of envs to avoid this problem
to happen.
Closes-bug: #1489059
Change-Id: Ia11ecf7bd147e35b7c8ad3db0eaad17f893e78ba
",git fetch https://review.opendev.org/openstack/tempest refs/changes/64/252164/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6a357a0ef733db5b42ebb792242037370575787c,bug/1465086,"envlist = pep8,py34,py27","envlist = pep8,py27,py34",1,1
openstack%2Frequirements~master~I79117ca39e33aad084e6470c51ee770a6ba3bb82,openstack/requirements,master,I79117ca39e33aad084e6470c51ee770a6ba3bb82,Block oslo.utils 3.1.0,MERGED,2015-12-10 22:09:16.000000000,2015-12-11 15:01:53.000000000,2015-12-11 15:01:52.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6854}]","[{'number': 1, 'created': '2015-12-10 22:09:16.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/eebb07fc70132ac8c238531f76ec55b8e3f03138', 'message': 'Block oslo.utils 3.1.0\n\n2abbe1c3b19490f570c29502cd56ec92daf4ca45 in oslo.utils 3.1.0\nmoves the netifaces runtime requirement into extras which breaks\neveryone using oslo_utils.netutils. This should have been in a\nmajor version bump and was reverted in 479587c6d9f2fd519f1ea4c7f\nand released as 3.2.0.\n\nWe should blacklist 3.1.0 for posterity.\n\nChange-Id: I79117ca39e33aad084e6470c51ee770a6ba3bb82\nRelated-Bug: #1524991\n'}]",0,256116,eebb07fc70132ac8c238531f76ec55b8e3f03138,8,3,1,6873,,,0,"Block oslo.utils 3.1.0

2abbe1c3b19490f570c29502cd56ec92daf4ca45 in oslo.utils 3.1.0
moves the netifaces runtime requirement into extras which breaks
everyone using oslo_utils.netutils. This should have been in a
major version bump and was reverted in 479587c6d9f2fd519f1ea4c7f
and released as 3.2.0.

We should blacklist 3.1.0 for posterity.

Change-Id: I79117ca39e33aad084e6470c51ee770a6ba3bb82
Related-Bug: #1524991
",git fetch https://review.opendev.org/openstack/requirements refs/changes/16/256116/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,eebb07fc70132ac8c238531f76ec55b8e3f03138,bug/1524991,"# NOTE(mriedem): oslo.utils 3.1.0 removed it's runtime # dependency on netifaces which breaks nearly everyone. oslo.utils>=2.8.0,!=3.1.0 # Apache-2.0",oslo.utils>=2.8.0 # Apache-2.0,3,1
openstack%2Ffuel-web~master~I719180010a7d92099ec5a0e0165b5a8f8323d350,openstack/fuel-web,master,I719180010a7d92099ec5a0e0165b5a8f8323d350,Load setting defaults once tab is opened,ABANDONED,2015-12-11 12:22:21.000000000,2015-12-11 14:59:50.000000000,,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-11 12:22:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/14ee4e252f390256057e9af38b411323a95fe5e3', 'message': 'Load setting defaults once tab is opened\n\nChange-Id: I719180010a7d92099ec5a0e0165b5a8f8323d350\n'}, {'number': 2, 'created': '2015-12-11 13:11:57.000000000', 'files': ['nailgun/static/views/cluster_page.js', 'nailgun/static/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/98382783b44a591efe631830420cffc3e21a01b4', 'message': 'Load setting defaults once tab is opened\n\nChange-Id: I719180010a7d92099ec5a0e0165b5a8f8323d350\n'}]",1,256385,98382783b44a591efe631830420cffc3e21a01b4,16,3,2,8766,,,0,"Load setting defaults once tab is opened

Change-Id: I719180010a7d92099ec5a0e0165b5a8f8323d350
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/85/256385/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/views/cluster_page.js', 'nailgun/static/views/cluster_page_tabs/settings_tab.js', 'nailgun/static/models.js']",3,14ee4e252f390256057e9af38b411323a95fe5e3,lock-defaults-btn," expandRestrictions: function(restrictions, path = 'restrictions') { checkRestrictions: function(models, action, path = 'restrictions') { validate: function(attrs, options = {}) { models = options.models || {}, checkRestrictions = _.partial(this.checkRestrictions, models, null); _.each(attrs, (group, groupName) => { _.each(group, (setting, settingName) => {"," expandRestrictions: function(restrictions, path) { path = path || 'restrictions'; checkRestrictions: function(models, action, path) { path = path || 'restrictions'; validate: function(attrs, options) { models = options ? options.models : {}, checkRestrictions = _.bind(function(path) { return this.checkRestrictions(models, null, path); }, this); _.each(attrs, function(group, groupName) { _.each(group, function(setting, settingName) {",31,47
openstack%2Fcompute-hyperv~stable%2Fliberty~I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2,openstack/compute-hyperv,stable/liberty,I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2,Improve startup performance of nova-compute Hyper-V driver,MERGED,2015-12-10 01:38:41.000000000,2015-12-11 14:51:47.000000000,2015-12-11 13:15:42.000000000,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 17019}]","[{'number': 1, 'created': '2015-12-10 01:38:41.000000000', 'files': ['hyperv/nova/hostutils.py', 'hyperv/tests/unit/test_hostutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/767a9eece9ac913b3018e0af61d16b6e8b8753cf', 'message': 'Improve startup performance of nova-compute Hyper-V driver\n\nDuring the nova-compute driver startup, a lot of calls are made to\nget_windows_version slowing down startup.\nThis patch speeds up the startup by caching the windows version to\nbe used for later calls of get_windows_version.\n\nChange-Id: I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2\n(cherry picked from commit 24d7079ad54793fad3692acfede95ff6e35591ae)\n'}]",0,255627,767a9eece9ac913b3018e0af61d16b6e8b8753cf,17,5,1,3185,,,0,"Improve startup performance of nova-compute Hyper-V driver

During the nova-compute driver startup, a lot of calls are made to
get_windows_version slowing down startup.
This patch speeds up the startup by caching the windows version to
be used for later calls of get_windows_version.

Change-Id: I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2
(cherry picked from commit 24d7079ad54793fad3692acfede95ff6e35591ae)
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/27/255627/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/hostutils.py', 'hyperv/tests/unit/test_hostutils.py']",2,767a9eece9ac913b3018e0af61d16b6e8b8753cf,," hostutils.HostUtils._windows_version = None def test_get_windows_version(self): os = mock.MagicMock() os.Version = self._FAKE_VERSION_GOOD self._hostutils._conn_cimv2.Win32_OperatingSystem.return_value = [os] hostutils.HostUtils._windows_version = None self.assertEqual(self._FAKE_VERSION_GOOD, self._hostutils.get_windows_version()) ",,15,2
openstack%2Fpuppet-neutron~master~Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410,openstack/puppet-neutron,master,Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410,Fix backward compatibility for some parameters,MERGED,2015-12-11 11:34:46.000000000,2015-12-11 14:48:27.000000000,2015-12-11 13:49:10.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7745}, {'_account_id': 15519}]","[{'number': 1, 'created': '2015-12-11 11:34:46.000000000', 'files': ['manifests/server/notifications.pp', 'manifests/init.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/a5083ca71f1d9faebe6cf2223daf5e3f50301a43', 'message': 'Fix backward compatibility for some parameters\n\nSince puppet-neutron was partially switched to $::os_service_default fact,\nsome backward incompatible changes were introduced. This patch makes them\ncompatible\n\nChange-Id: Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410\n'}]",0,256370,a5083ca71f1d9faebe6cf2223daf5e3f50301a43,16,4,1,7604,,,0,"Fix backward compatibility for some parameters

Since puppet-neutron was partially switched to $::os_service_default fact,
some backward incompatible changes were introduced. This patch makes them
compatible

Change-Id: Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/70/256370/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/server/notifications.pp', 'manifests/init.pp']",2,a5083ca71f1d9faebe6cf2223daf5e3f50301a43,tempest-fix, if !$rabbit_use_ssl { if ! is_service_default($kombu_ssl_ca_certs) and ($kombu_ssl_ca_certs) { fail('The kombu_ssl_ca_certs parameter requires rabbit_use_ssl to be set to true') } if ! is_service_default($kombu_ssl_certfile) and ($kombu_ssl_certfile) { fail('The kombu_ssl_certfile parameter requires rabbit_use_ssl to be set to true') } if ! is_service_default($kombu_ssl_keyfile) and ($kombu_ssl_keyfile) { fail('The kombu_ssl_keyfile parameter requires rabbit_use_ssl to be set to true') } if ! is_service_default ($service_plugins) and ($service_plugins) {, if ! is_service_default($kombu_ssl_ca_certs) and !$rabbit_use_ssl { fail('The kombu_ssl_ca_certs parameter requires rabbit_use_ssl to be set to true') } if ! is_service_default($kombu_ssl_certfile) and !$rabbit_use_ssl { fail('The kombu_ssl_certfile parameter requires rabbit_use_ssl to be set to true') } if ! is_service_default($kombu_ssl_keyfile) and !$rabbit_use_ssl { fail('The kombu_ssl_keyfile parameter requires rabbit_use_ssl to be set to true') if ! is_service_default ($service_plugins) {,19,13
openstack%2Fkolla~master~Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929,openstack/kolla,master,Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929,add python-kazoo and python-six when using centos source install type,MERGED,2015-12-11 03:24:38.000000000,2015-12-11 14:46:51.000000000,2015-12-11 14:46:50.000000000,"[{'_account_id': 3}, {'_account_id': 4715}, {'_account_id': 7488}, {'_account_id': 10787}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-12-11 03:24:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/e4369435b881fc1450baadb65576bb8a9ddeca7d', 'message': 'add python-kazzo when using centos source install type\n\nCloses-Bug: #1525055\nChange-Id: Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929\n'}, {'number': 2, 'created': '2015-12-11 04:53:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/69f2381830b0b2cbeed76c6995877f5805a9444d', 'message': 'add python-kazoo when using centos source install type\n\nCloses-Bug: #1525055\nChange-Id: Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929\n'}, {'number': 3, 'created': '2015-12-11 05:25:04.000000000', 'files': ['docker/base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/0932a0f7b2cfd15610edbc1710f14b0530275ffa', 'message': 'add python-kazoo and python-six when using centos source install type\n\nCloses-Bug: #1525055\nChange-Id: Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929\n'}]",2,256193,0932a0f7b2cfd15610edbc1710f14b0530275ffa,12,5,3,7488,,,0,"add python-kazoo and python-six when using centos source install type

Closes-Bug: #1525055
Change-Id: Id800da1a0cce4db20c32e8daf09c5f0f2c9f8929
",git fetch https://review.opendev.org/openstack/kolla refs/changes/93/256193/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/Dockerfile.j2'],1,e4369435b881fc1450baadb65576bb8a9ddeca7d,source_base_add_kazoo, python-kazoo \,,1,0
openstack%2Fcompute-hyperv~stable%2Fkilo~I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2,openstack/compute-hyperv,stable/kilo,I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2,Improve startup performance of nova-compute Hyper-V driver,MERGED,2015-12-10 01:41:02.000000000,2015-12-11 14:44:54.000000000,2015-12-11 13:13:48.000000000,"[{'_account_id': 3}, {'_account_id': 3185}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 17019}, {'_account_id': 18598}]","[{'number': 1, 'created': '2015-12-10 01:41:02.000000000', 'files': ['hyperv/nova/hostutils.py', 'hyperv/tests/unit/test_hostutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/1764c1e42ed2466c5fedfdbec498c78ded455074', 'message': 'Improve startup performance of nova-compute Hyper-V driver\n\nDuring the nova-compute driver startup, a lot of calls are made to\nget_windows_version slowing down startup.\nThis patch speeds up the startup by caching the windows version to\nbe used for later calls of get_windows_version.\n\nChange-Id: I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2\n(cherry picked from commit 24d7079ad54793fad3692acfede95ff6e35591ae)\n'}]",0,255630,1764c1e42ed2466c5fedfdbec498c78ded455074,18,6,1,3185,,,0,"Improve startup performance of nova-compute Hyper-V driver

During the nova-compute driver startup, a lot of calls are made to
get_windows_version slowing down startup.
This patch speeds up the startup by caching the windows version to
be used for later calls of get_windows_version.

Change-Id: I5b2eadc0bce79cd261a5dcaac7712c23c49dfcc2
(cherry picked from commit 24d7079ad54793fad3692acfede95ff6e35591ae)
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/30/255630/1 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/hostutils.py', 'hyperv/tests/unit/test_hostutils.py']",2,1764c1e42ed2466c5fedfdbec498c78ded455074,," hostutils.HostUtils._windows_version = None def test_get_windows_version(self): os = mock.MagicMock() os.Version = self._FAKE_VERSION_GOOD self._hostutils._conn_cimv2.Win32_OperatingSystem.return_value = [os] hostutils.HostUtils._windows_version = None self.assertEqual(self._FAKE_VERSION_GOOD, self._hostutils.get_windows_version()) ",,15,2
openstack%2Fkolla~master~I2055bbc608c35604bbb727e83d9b74295e643a7d,openstack/kolla,master,I2055bbc608c35604bbb727e83d9b74295e643a7d,install python-cephlibs in venv for glance-base,MERGED,2015-12-10 09:55:26.000000000,2015-12-11 14:44:21.000000000,2015-12-11 14:44:18.000000000,"[{'_account_id': 3}, {'_account_id': 10787}, {'_account_id': 13747}, {'_account_id': 14027}]","[{'number': 1, 'created': '2015-12-10 09:55:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fe222e280ccc1e38bc1a90ad2a14b04bafdc0c5a', 'message': 'add rbd,rados symlink from system package to venv\n\nadd rbd,rados symlink from system package to venv\n\nChange-Id: I2055bbc608c35604bbb727e83d9b74295e643a7d\nCloses-Bug: #1524684\n'}, {'number': 2, 'created': '2015-12-11 06:23:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/628c6979a1818f2a435294e16ad20d31d2d5f52a', 'message': 'install python-cephlibs in venv for glance-base\n\ninstall python-cephlibs in venv for glance-base\n\nChange-Id: I2055bbc608c35604bbb727e83d9b74295e643a7d\nCloses-Bug: #1524684\n'}, {'number': 3, 'created': '2015-12-11 06:32:42.000000000', 'files': ['docker/glance/glance-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/a9bd9a1a6529ebbd837147b55e00866d5d223185', 'message': 'install python-cephlibs in venv for glance-base\n\ninstall python-cephlibs in venv for glance-base\n\nChange-Id: I2055bbc608c35604bbb727e83d9b74295e643a7d\nCloses-Bug: #1524684\n'}]",1,255765,a9bd9a1a6529ebbd837147b55e00866d5d223185,13,4,3,13747,,,0,"install python-cephlibs in venv for glance-base

install python-cephlibs in venv for glance-base

Change-Id: I2055bbc608c35604bbb727e83d9b74295e643a7d
Closes-Bug: #1524684
",git fetch https://review.opendev.org/openstack/kolla refs/changes/65/255765/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/glance/glance-base/Dockerfile.j2'],1,fe222e280ccc1e38bc1a90ad2a14b04bafdc0c5a,bug/1524684, && chown -R glance: /etc/glance /var/log/glance /var/lib/glance /home/glance \ && ln -s /usr/lib/python2.7/dist-packages/rbd.py /var/lib/kolla/venv/lib/python2.7/site-packages \ && ln -s /usr/lib/python2.7/dist-packages/rados.py /var/lib/kolla/venv/lib/python2.7/site-packages , && chown -R glance: /etc/glance /var/log/glance /var/lib/glance /home/glance,4,1
openstack%2Ffuel-web~master~Id5b4e978eb41902a601a85e52bb2bbbd0e6cedc0,openstack/fuel-web,master,Id5b4e978eb41902a601a85e52bb2bbbd0e6cedc0,Fix network settings description styles,MERGED,2015-12-11 12:45:59.000000000,2015-12-11 14:44:19.000000000,2015-12-11 14:27:37.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-11 12:45:59.000000000', 'files': ['nailgun/static/styles/main.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/fbb4f32610214675c47895628d7ddd364380046f', 'message': 'Fix network settings description styles\n\nCloses-Bug: #1525194\n\nChange-Id: Id5b4e978eb41902a601a85e52bb2bbbd0e6cedc0\n'}]",0,256392,fbb4f32610214675c47895628d7ddd364380046f,18,4,1,8766,,,0,"Fix network settings description styles

Closes-Bug: #1525194

Change-Id: Id5b4e978eb41902a601a85e52bb2bbbd0e6cedc0
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/92/256392/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/styles/main.less'],1,fbb4f32610214675c47895628d7ddd364380046f,bug/1525194, &:not(.network) .has-error .help-block { display: block; } &.network .help-block { max-width: 400px; .forms-box:not(.network) .vlan-tagging {, .help-block { display: block; .vlan-tagging {,6,3
openstack%2Fkolla~master~Ic5d4fd1ddf71f01c547130518e311fded911c445,openstack/kolla,master,Ic5d4fd1ddf71f01c547130518e311fded911c445,Catch exception when directory creation fails,MERGED,2015-12-11 08:55:34.000000000,2015-12-11 14:35:24.000000000,2015-12-11 14:35:23.000000000,"[{'_account_id': 3}, {'_account_id': 7488}, {'_account_id': 9927}, {'_account_id': 10787}, {'_account_id': 13039}, {'_account_id': 14027}, {'_account_id': 19542}]","[{'number': 1, 'created': '2015-12-11 08:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3ddf8765ccdc32a4927c602688abe05ab8602b1a', 'message': ""Catch exception when directory creation fails\n\nThe build script now creates now creates a plugins directory for source\nbuilds to store plugins required for the container, and creates a tar\nof all plugins that is extracted at runtime.\n\nHowever, the creation of the 'plugins' directory is not handled\ncorrectly and generate an exception in the running thread if the\ndirectory exists. This is the case for example if the build script\nretries a failing image.\n\nChange-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445\n""}, {'number': 2, 'created': '2015-12-11 08:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/28acb60a399d990f8741614436b9e3431967cc02', 'message': ""Catch exception when directory creation fails\n\nThe build script now creates now creates a plugins directory for source\nbuilds to store plugins required for the container, and creates a tar\nof all plugins that is extracted at runtime.\n\nHowever, the creation of the 'plugins' directory is not handled\ncorrectly and generate an exception in the running thread if the\ndirectory exists. This is the case for example if the build script\nretries a failing image.\n\nChange-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445\nPartial-Bug: 1524897\n""}, {'number': 3, 'created': '2015-12-11 10:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/aaed35a3c701bad9079b10bbc89fe50d36ad80f8', 'message': ""Catch exception when directory creation fails\n\nThe build script now creates now creates a plugins directory for source\nbuilds to store plugins required for the container, and creates a tar\nof all plugins that is extracted at runtime.\n\nHowever, the creation of the 'plugins' directory is not handled\ncorrectly and generate an exception in the running thread if the\ndirectory exists. This is the case for example if the build script\nretries a failing image.\n\nChange-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445\nPartial-Bug: 1524897\n""}, {'number': 4, 'created': '2015-12-11 10:31:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/3ae6df2c9fadba43e5cea5b2295718ab97d1055f', 'message': ""Catch exception when directory creation fails\n\nThe build script now creates now creates a plugins directory for source\nbuilds to store plugins required for the container, and creates a tar\nof all plugins that is extracted at runtime.\n\nHowever, the creation of the 'plugins' directory is not handled\ncorrectly and generate an exception in the running thread if the\ndirectory exists. This is the case for example if the build script\nretries a failing image.\n\nChange-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445\nPartial-Bug: 1524897\n""}, {'number': 5, 'created': '2015-12-11 11:08:58.000000000', 'files': ['kolla/cmd/build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/06794fdc6b6bba7030866c2828376d07f3596343', 'message': ""Catch exception when directory creation fails\n\nThe build script now creates now creates a plugins directory for source\nbuilds to store plugins required for the container, and creates a tar\nof all plugins that is extracted at runtime.\n\nHowever, the creation of the 'plugins' directory is not handled\ncorrectly and generate an exception in the running thread if the\ndirectory exists. This is the case for example if the build script\nretries a failing image.\n\nThis commit fixes the timeout issues we've experienced with the gate.\n\nChange-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445\nCloses-Bug: 1524897\n""}]",4,256289,06794fdc6b6bba7030866c2828376d07f3596343,23,7,5,13039,,,0,"Catch exception when directory creation fails

The build script now creates now creates a plugins directory for source
builds to store plugins required for the container, and creates a tar
of all plugins that is extracted at runtime.

However, the creation of the 'plugins' directory is not handled
correctly and generate an exception in the running thread if the
directory exists. This is the case for example if the build script
retries a failing image.

This commit fixes the timeout issues we've experienced with the gate.

Change-Id: Ic5d4fd1ddf71f01c547130518e311fded911c445
Closes-Bug: 1524897
",git fetch https://review.opendev.org/openstack/kolla refs/changes/89/256289/4 && git format-patch -1 --stdout FETCH_HEAD,['kolla/cmd/build.py'],1,3ddf8765ccdc32a4927c602688abe05ab8602b1a,bug/1524897," try: os.mkdir(os.path.join(image['path'], 'plugins')) except OSError: LOG.debug('Directory {} already exists'.format( os.path.join(image['path'], 'plugins')))"," os.mkdir(os.path.join(image['path'], 'plugins'))",5,1
openstack%2Fopenstack-manuals~master~I5b29efcddef9282788323526fe6f79eaf8d1c90b,openstack/openstack-manuals,master,I5b29efcddef9282788323526fe6f79eaf8d1c90b,Add 'tip' in conventions.rst,MERGED,2015-12-11 03:51:10.000000000,2015-12-11 14:33:34.000000000,2015-12-11 14:33:32.000000000,"[{'_account_id': 3}, {'_account_id': 6772}, {'_account_id': 10497}, {'_account_id': 14396}, {'_account_id': 14947}]","[{'number': 1, 'created': '2015-12-11 03:51:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bb94967c19631ac2343461c247b20fa1a05284b3', 'message': ""Add 'tip' in conventions.rst\n\nChange-Id: I5b29efcddef9282788323526fe6f79eaf8d1c90b\n""}, {'number': 2, 'created': '2015-12-11 14:04:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/fa05ae6d56bf28bb8e74b959525c7d9ecd41d26d', 'message': ""Add 'tip' in conventions.rst\n\nChange-Id: I5b29efcddef9282788323526fe6f79eaf8d1c90b\n""}, {'number': 3, 'created': '2015-12-11 14:06:15.000000000', 'files': ['doc/common-rst/conventions.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/96de9e6ac1a0e8430911a93bbae5b95f996fab02', 'message': ""Add 'tip' in conventions.rst\n\nChange-Id: I5b29efcddef9282788323526fe6f79eaf8d1c90b\n""}]",2,256199,96de9e6ac1a0e8430911a93bbae5b95f996fab02,13,5,3,16237,,,0,"Add 'tip' in conventions.rst

Change-Id: I5b29efcddef9282788323526fe6f79eaf8d1c90b
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/99/256199/3 && git format-patch -1 --stdout FETCH_HEAD,['doc/common-rst/conventions.rst'],1,bb94967c19631ac2343461c247b20fa1a05284b3,add-tip,.. tip:: A piece of information for you to get things closer. ,,2,0
openstack%2Fcinder~master~Ifae57b9e95e01b1789a37ac7c03e9aad65cd50f7,openstack/cinder,master,Ifae57b9e95e01b1789a37ac7c03e9aad65cd50f7,VNX: Fix issue in deleting cg/cgsnapshot,MERGED,2015-12-10 03:27:56.000000000,2015-12-11 14:31:56.000000000,2015-12-11 03:03:16.000000000,"[{'_account_id': 3}, {'_account_id': 6491}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 12017}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12778}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14242}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14624}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16160}, {'_account_id': 16269}, {'_account_id': 16422}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-12-10 03:27:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/ea3bade1d94ad1c51dbd971288ebb04aeac06b06', 'message': ""VNX: Fix issue in deleting cg/cgsnapshot\n\nIf user deletes a cg/cgsnapshot quickly after its creation,\ndriver would report 'not found' warning, and return success\nfor the deletion, but actually, the object underlying the VNX\nis not deleted.\n\nThis fix tries to wait the cg and cg snapshot to be available\nto make sure it's eligible for deletion.\n\nberty-backport-potential\nCloses-Bug: 1499615\nChange-Id: Ifae57b9e95e01b1789a37ac7c03e9aad65cd50f7\n""}, {'number': 2, 'created': '2015-12-10 03:31:09.000000000', 'files': ['cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/f7b5655d188bfde96333760bbe634f45d4a16395', 'message': ""VNX: Fix issue in deleting cg/cgsnapshot\n\nIf user deletes a cg/cgsnapshot quickly after its creation,\ndriver would report 'not found' warning, and return success\nfor the deletion, but actually, the object underlying the VNX\nis not deleted.\n\nThis fix tries to wait the cg and cg snapshot to be available\nto make sure it's eligible for deletion.\n\nliberty-backport-potential\nCloses-Bug: 1499615\nChange-Id: Ifae57b9e95e01b1789a37ac7c03e9aad65cd50f7\n""}]",0,255655,f7b5655d188bfde96333760bbe634f45d4a16395,69,37,2,10628,,,0,"VNX: Fix issue in deleting cg/cgsnapshot

If user deletes a cg/cgsnapshot quickly after its creation,
driver would report 'not found' warning, and return success
for the deletion, but actually, the object underlying the VNX
is not deleted.

This fix tries to wait the cg and cg snapshot to be available
to make sure it's eligible for deletion.

liberty-backport-potential
Closes-Bug: 1499615
Change-Id: Ifae57b9e95e01b1789a37ac7c03e9aad65cd50f7
",git fetch https://review.opendev.org/openstack/cinder refs/changes/55/255655/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/test_emc_vnxdirect.py', 'cinder/volume/drivers/emc/emc_vnx_cli.py']",2,ea3bade1d94ad1c51dbd971288ebb04aeac06b06,bug/1499615," interval=INTERVAL_5_SEC, ignorable_exception_arbiter=lambda ex: ignorable_exception_arbiter=lambda ex: True, *args, **kwargs): test_value = testmethod(*args, **kwargs) self._wait_for_a_condition(self.get_consistency_group_by_name, cg_name=cg_name, interval=INTERVAL_5_SEC, ignorable_exception_arbiter=lambda ex: isinstance(ex, exception.EMCVnxCLICmdError)) else: self._raise_cli_error(cmd, rc, out) self._wait_for_a_condition(self.check_snapshot, snap_name=snap_name, interval=INTERVAL_30_SEC, ignorable_exception_arbiter=lambda ex: isinstance(ex, exception.EMCVnxCLICmdError)) def check_snapshot(self, snap_name, poll=True): """"""check if a snapshot/cgsnapshot is existed."""""" cmd_get = ('snap', '-list', '-id', snap_name) out, rc = self.command_execute(*cmd_get) if rc == 0: return True else: self._raise_cli_error(cmd_get, rc, out)"," None, INTERVAL_5_SEC, lambda ex: ignorable_exception_arbiter=lambda ex: True): test_value = testmethod()",97,11
openstack%2Fnova-powervm~master~I328738cc8833c9dbf854be5e1c7e67e9758d2c25,openstack/nova-powervm,master,I328738cc8833c9dbf854be5e1c7e67e9758d2c25,Check the destination host is capable for IBMi VM LPM.,ABANDONED,2015-12-09 03:14:50.000000000,2015-12-11 14:30:30.000000000,,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 18087}, {'_account_id': 18160}]","[{'number': 1, 'created': '2015-12-09 03:14:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/8b6b22757e813022be6e1406b7d275ee419d1865', 'message': 'Check the destination host is capable for IBMi VM LPM.\n\nTo serve as a destination host of IBM i VM LPM, the host has to enable\nIBMi mobility capable and has to be Power 7 or higher version. The\nchange set is to check those capabilities before launch a real LPM.\n\nChange-Id: I328738cc8833c9dbf854be5e1c7e67e9758d2c25\n'}, {'number': 2, 'created': '2015-12-09 08:59:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/252f51e50a9ba878c8e37e2ff4d711d747d97d7c', 'message': 'Check the destination host is capable for IBMi VM LPM.\n\nTo serve as a destination host of IBM i VM LPM, the host has to enable\nIBMi mobility capable and has to be Power 7 or higher version. The\nchange set is to check those capabilities before migrate the VM.\n\nChange-Id: I328738cc8833c9dbf854be5e1c7e67e9758d2c25\n'}, {'number': 3, 'created': '2015-12-10 05:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/ed120c016f60d8e3cc86377096b4e0037f463689', 'message': 'Check the destination host is capable for IBMi VM LPM.\n\nTo serve as a destination host of IBM i VM LPM, the host has to enable\nIBMi mobility capable and has to be Power 7 or higher version. The\nchange set is to check those capabilities before migrate the VM.\n\nChange-Id: I328738cc8833c9dbf854be5e1c7e67e9758d2c25\n'}, {'number': 4, 'created': '2015-12-10 06:25:00.000000000', 'files': ['nova_powervm/tests/virt/powervm/test_live_migration.py', 'nova_powervm/virt/powervm/live_migration.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/08a2c5b3303d6ac04719ee9ac01dc84116db9244', 'message': 'Check the destination host is capable for IBMi VM LPM.\n\nTo serve as a destination host of IBM i VM LPM, the host has to enable\nIBMi mobility capable and has to be Power 7 or higher version. The\nchange set is to check those capabilities before migrate the VM.\n\nChange-Id: I328738cc8833c9dbf854be5e1c7e67e9758d2c25\n'}]",11,255054,08a2c5b3303d6ac04719ee9ac01dc84116db9244,13,5,4,18087,,,0,"Check the destination host is capable for IBMi VM LPM.

To serve as a destination host of IBM i VM LPM, the host has to enable
IBMi mobility capable and has to be Power 7 or higher version. The
change set is to check those capabilities before migrate the VM.

Change-Id: I328738cc8833c9dbf854be5e1c7e67e9758d2c25
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/54/255054/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova_powervm/tests/virt/powervm/test_live_migration.py', 'nova_powervm/virt/powervm/live_migration.py']",2,8b6b22757e813022be6e1406b7d275ee419d1865,ibmi_lpm,"from nova_powervm.virt.powervm import image as img # Check whether the target host is capable for IBMi mobility vm_env = self.instance.system_metadata.get('image_os_distro', '') if vm_env.lower() == img.OSDistro.OS400: self._check_host_capable_ibmi_lpm(self.drvr.host_wrapper) def _check_host_capable_ibmi_lpm(self, host_w): """"""See if the target host is ready for LPM IBMi VM. :param host_w: ManagedSystem wrapper """""" can_lpm = host_w.get_capabilities().get('ibmi_lpar_mobility_capable') highest_mode = host_w.highest_compat_mode() if not can_lpm: msg = _(""The target host does not have the IBM i LPAR Mobility "" ""Capability."") raise exception.MigrationPreCheckError(reason=msg) if highest_mode < 7: msg = _(""IBM i LPAR Live Migration is only supported on "" ""POWER7 and higher systems."") raise exception.MigrationPreCheckError(reason=msg) ",,95,0
openstack%2Ftripleo-heat-templates~master~Id63c1bcfc34058eb7285698ba9bf86d1cf2025a6,openstack/tripleo-heat-templates,master,Id63c1bcfc34058eb7285698ba9bf86d1cf2025a6,Update typos,MERGED,2015-11-24 13:51:00.000000000,2015-12-11 14:26:25.000000000,2015-12-11 14:26:25.000000000,"[{'_account_id': 3}, {'_account_id': 8399}, {'_account_id': 10873}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-11-24 13:51:00.000000000', 'files': ['network/ports/noop.yaml', 'firstboot/userdata_heat_admin.yaml', 'network/ports/external.yaml', 'network/internal_api.yaml', 'network/ports/storage.yaml', 'network/ports/ctlplane_vip.yaml', 'network/ports/internal_api.yaml', 'network/storage.yaml', 'network/storage_mgmt.yaml', 'network/tenant.yaml', 'network/ports/storage_mgmt.yaml', 'network/ports/vip.yaml', 'network/ports/tenant.yaml', 'network/external.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b49a96da29d951ed3f9abd876e97b673b6270d73', 'message': 'Update typos\n\nChange-Id: Id63c1bcfc34058eb7285698ba9bf86d1cf2025a6\n'}]",0,249220,b49a96da29d951ed3f9abd876e97b673b6270d73,9,4,1,11105,,,0,"Update typos

Change-Id: Id63c1bcfc34058eb7285698ba9bf86d1cf2025a6
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/20/249220/1 && git format-patch -1 --stdout FETCH_HEAD,"['network/ports/noop.yaml', 'firstboot/userdata_heat_admin.yaml', 'network/ports/external.yaml', 'network/internal_api.yaml', 'network/ports/storage.yaml', 'network/ports/ctlplane_vip.yaml', 'network/ports/internal_api.yaml', 'network/storage.yaml', 'network/storage_mgmt.yaml', 'network/tenant.yaml', 'network/ports/storage_mgmt.yaml', 'network/ports/vip.yaml', 'network/ports/tenant.yaml', 'network/external.yaml']",14,b49a96da29d951ed3f9abd876e97b673b6270d73,typos, description: This admin state of the network., description: This admin state of of the network.,14,14
openstack%2Ffuel-library~master~If061c0f1b2706ec4fd88966b8620e5586d98b0b8,openstack/fuel-library,master,If061c0f1b2706ec4fd88966b8620e5586d98b0b8,Run db sync only on primary controller,MERGED,2015-12-08 15:04:53.000000000,2015-12-11 14:25:03.000000000,2015-12-11 14:24:19.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-08 15:04:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ec68cc77a4a6d439f067af98501f2f4acdfb2eb9', 'message': ""Run db sync only on primary controller\n\nWe should run db sync only on primary controllers. Currently\nupstream modules have posibility to specify should we run\ndb sync or don't.\n\nChange-Id: If061c0f1b2706ec4fd88966b8620e5586d98b0b8\nCloses-bug: #1330875\n""}, {'number': 2, 'created': '2015-12-09 10:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/75bb9b6abe1b3712c0b7970d7e57a2e41b7b5d1d', 'message': ""Run db sync only on primary controller\n\nWe should run db sync only on primary controllers. Currently\nupstream modules have posibility to specify should we run\ndb sync or don't.\n\nChange-Id: If061c0f1b2706ec4fd88966b8620e5586d98b0b8\nCloses-bug: #1330875\n""}, {'number': 3, 'created': '2015-12-10 16:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/89b6055c441eb2ef5e54307b718f076ed1023e71', 'message': ""Run db sync only on primary controller\n\nWe should run db sync only on primary controllers. Currently\nupstream modules have posibility to specify should we run\ndb sync or don't.\n\nChange-Id: If061c0f1b2706ec4fd88966b8620e5586d98b0b8\nCloses-bug: #1330875\n""}, {'number': 4, 'created': '2015-12-11 09:52:40.000000000', 'files': ['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'deployment/puppet/osnailyfacter/modular/heat/heat.pp', 'deployment/puppet/openstack/manifests/nova/controller.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb', 'tests/noop/spec/hosts/sahara/sahara_spec.rb', 'tests/noop/spec/hosts/glance/glance_spec.rb', 'deployment/puppet/openstack/manifests/heat.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/osnailyfacter/modular/ironic/ironic.pp', 'deployment/puppet/osnailyfacter/modular/murano/murano.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb', 'tests/noop/spec/hosts/ironic/ironic_spec.rb', 'deployment/puppet/openstack/manifests/keystone.pp', 'deployment/puppet/osnailyfacter/modular/ceilometer/controller.pp', 'tests/noop/spec/hosts/ceilometer/controller_spec.rb', 'tests/noop/spec/hosts/murano/murano_spec.rb', 'deployment/puppet/osnailyfacter/modular/sahara/sahara.pp', 'deployment/puppet/osnailyfacter/modular/glance/glance.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'deployment/Puppetfile'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a607d9ad7ac176ee2874c2204d94080804287166', 'message': ""Run db sync only on primary controller\n\nWe should run db sync only on primary controllers. Currently\nupstream modules have posibility to specify should we run\ndb sync or don't.\n\nChange-Id: If061c0f1b2706ec4fd88966b8620e5586d98b0b8\nCloses-bug: #1330875\n""}]",0,254811,a607d9ad7ac176ee2874c2204d94080804287166,50,10,4,7745,,,0,"Run db sync only on primary controller

We should run db sync only on primary controllers. Currently
upstream modules have posibility to specify should we run
db sync or don't.

Change-Id: If061c0f1b2706ec4fd88966b8620e5586d98b0b8
Closes-bug: #1330875
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/11/254811/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/manifests/glance.pp', 'deployment/puppet/osnailyfacter/modular/openstack-cinder/openstack-cinder.pp', 'deployment/puppet/openstack/manifests/cinder.pp', 'deployment/puppet/osnailyfacter/modular/heat/heat.pp', 'deployment/puppet/openstack/manifests/nova/controller.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb', 'tests/noop/spec/hosts/sahara/sahara_spec.rb', 'tests/noop/spec/hosts/glance/glance_spec.rb', 'deployment/puppet/openstack/manifests/heat.pp', 'deployment/puppet/openstack/manifests/ceilometer.pp', 'deployment/puppet/osnailyfacter/modular/ironic/ironic.pp', 'deployment/puppet/osnailyfacter/modular/murano/murano.pp', 'tests/noop/spec/hosts/openstack-cinder/openstack-cinder_spec.rb', 'tests/noop/spec/hosts/ironic/ironic_spec.rb', 'deployment/puppet/openstack/manifests/keystone.pp', 'deployment/puppet/osnailyfacter/modular/ceilometer/controller.pp', 'tests/noop/spec/hosts/ceilometer/controller_spec.rb', 'tests/noop/spec/hosts/murano/murano_spec.rb', 'deployment/puppet/osnailyfacter/modular/sahara/sahara.pp', 'deployment/puppet/osnailyfacter/modular/glance/glance.pp', 'tests/noop/spec/hosts/heat/heat_spec.rb', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp']",22,ec68cc77a4a6d439f067af98501f2f4acdfb2eb9,bug/1330875,"$primary_controller = hiera('primary_controller') primary_controller => $primary_controller,",,62,11
openstack%2Ffuel-web~master~I25f968d3f095a222f9afa4274137261c6882575a,openstack/fuel-web,master,I25f968d3f095a222f9afa4274137261c6882575a,Handle network verification task polling in cluster page,MERGED,2015-12-11 09:54:33.000000000,2015-12-11 14:21:22.000000000,2015-12-11 14:04:28.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-11 09:54:33.000000000', 'files': ['nailgun/static/views/cluster_page_tabs/network_tab.js', 'nailgun/static/views/cluster_page.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b6c0f0b2126db1ed90c87cb565fbe507839acbbc', 'message': 'Handle network verification task polling in cluster page\n\nCloses-Bug: #1521251\n\nChange-Id: I25f968d3f095a222f9afa4274137261c6882575a\n'}]",0,256310,b6c0f0b2126db1ed90c87cb565fbe507839acbbc,14,3,1,8766,,,0,"Handle network verification task polling in cluster page

Closes-Bug: #1521251

Change-Id: I25f968d3f095a222f9afa4274137261c6882575a
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/10/256310/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/views/cluster_page_tabs/network_tab.js', 'nailgun/static/views/cluster_page.js']",2,b6c0f0b2126db1ed90c87cb565fbe507839acbbc,bug/1521251," componentMixins.dispatcherMixin('networkVerificationTaskStarted', function() { this.startPolling(); }),",,5,8
openstack%2Frequirements~stable%2Fliberty~I5731b0278e266699fe716733b6dd4f7238a35586,openstack/requirements,stable/liberty,I5731b0278e266699fe716733b6dd4f7238a35586,cap oslo.middleware to < 3 for liberty,ABANDONED,2015-12-09 12:57:07.000000000,2015-12-11 14:19:12.000000000,,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2750}, {'_account_id': 4190}, {'_account_id': 4393}, {'_account_id': 5638}, {'_account_id': 6537}, {'_account_id': 6873}]","[{'number': 1, 'created': '2015-12-09 12:57:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/8aceed2195b168ffe14a7e5f1347f6bec9a1e8a2', 'message': ""cap oslo.middleware to < 3 for liberty\n\nWhile we are aggressively trying to keep caps out of our requirements,\nthere is an exception to every rule, and oslo.middleware is that\nexception.\n\noslo.middleware namespace use in paste.ini wasn't deprecated until\nliberty. Once deprecated in liberty the liberty versions of software\nprojects started shipping new paste.ini files using the new model, and\nthe deprecation warnings in a default configuration go away.\n\noslo.middleware vs. 3 drops the oslo.middleware namespace. However,\nthis means that clouds upgrading from kilo -> liberty, using\noslo.middleware >= 3 will explode in a giant ball of fire. The\nrequirements update job is currently blocked for just that reason -\nhttp://logs.openstack.org/11/246211/19/check/gate-grenade-dsvm/06a815e/.\n\nSupporting cloud upgrade from 1 version to the next is a critical\nvalue in OpenStack. It trumps just about everything else. As such we\nneed to cap oslo.middleware to < 3 for liberty to ensure that will\nwork for all our users.\n\nChange-Id: I5731b0278e266699fe716733b6dd4f7238a35586\n""}, {'number': 2, 'created': '2015-12-09 16:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/815097b744d2a2da27dda4987cf396f60c390052', 'message': ""cap oslo.middleware to < 3 for liberty\n\nWhile we are aggressively trying to keep caps out of our requirements,\nthere is an exception to every rule, and oslo.middleware is that\nexception.\n\noslo.middleware namespace use in paste.ini wasn't deprecated until\nliberty. Once deprecated in liberty the liberty versions of software\nprojects started shipping new paste.ini files using the new model, and\nthe deprecation warnings in a default configuration go away.\n\noslo.middleware version 3 drops the oslo.middleware namespace. However,\nthis means that clouds upgrading from kilo -> liberty, using\noslo.middleware >= 3 will explode in a giant ball of fire. The\nrequirements update job is currently blocked for just that reason -\nhttp://logs.openstack.org/11/246211/19/check/gate-grenade-dsvm/06a815e/.\n\nSupporting cloud upgrade from one version to the next is a critical\nvalue in OpenStack. It trumps just about everything else. As such we\nneed to cap oslo.middleware to < 3 for liberty to ensure that will\nwork for all our users.\n\nRelated-Bug: #1524404\n\nChange-Id: I5731b0278e266699fe716733b6dd4f7238a35586\n""}, {'number': 3, 'created': '2015-12-09 18:25:26.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1939b4b569561c651cb1c49aea6b9be256d8e150', 'message': ""cap oslo.middleware to < 3 for liberty\n\nWhile we are aggressively trying to keep caps out of our requirements,\nthere is an exception to every rule, and oslo.middleware is that\nexception.\n\noslo.middleware namespace use in paste.ini wasn't deprecated until\nliberty. Once deprecated in liberty the liberty versions of software\nprojects started shipping new paste.ini files using the new model, and\nthe deprecation warnings in a default configuration go away.\n\noslo.middleware version 3 drops the oslo.middleware namespace. However,\nthis means that clouds upgrading from kilo -> liberty, using\noslo.middleware >= 3 will explode in a giant ball of fire. The\nrequirements update job is currently blocked for just that reason -\nhttp://logs.openstack.org/11/246211/19/check/gate-grenade-dsvm/06a815e/.\n\nSupporting cloud upgrade from one version to the next is a critical\nvalue in OpenStack. It trumps just about everything else. As such we\nneed to cap oslo.middleware to < 3 for liberty to ensure that will\nwork for all our users.\n\nRelated-Bug: #1524404\n\nChange-Id: I5731b0278e266699fe716733b6dd4f7238a35586\n""}]",2,255245,1939b4b569561c651cb1c49aea6b9be256d8e150,27,8,3,2750,,,0,"cap oslo.middleware to < 3 for liberty

While we are aggressively trying to keep caps out of our requirements,
there is an exception to every rule, and oslo.middleware is that
exception.

oslo.middleware namespace use in paste.ini wasn't deprecated until
liberty. Once deprecated in liberty the liberty versions of software
projects started shipping new paste.ini files using the new model, and
the deprecation warnings in a default configuration go away.

oslo.middleware version 3 drops the oslo.middleware namespace. However,
this means that clouds upgrading from kilo -> liberty, using
oslo.middleware >= 3 will explode in a giant ball of fire. The
requirements update job is currently blocked for just that reason -
http://logs.openstack.org/11/246211/19/check/gate-grenade-dsvm/06a815e/.

Supporting cloud upgrade from one version to the next is a critical
value in OpenStack. It trumps just about everything else. As such we
need to cap oslo.middleware to < 3 for liberty to ensure that will
work for all our users.

Related-Bug: #1524404

Change-Id: I5731b0278e266699fe716733b6dd4f7238a35586
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/255245/2 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,8aceed2195b168ffe14a7e5f1347f6bec9a1e8a2,bug/1524404,"oslo.middleware>=2.8.0,<3 # Apache-2.0",oslo.middleware>=2.8.0 # Apache-2.0,1,1
openstack%2Ffuel-devops~master~Id5528b282cf9586dcc86678739c1ff10e88fc6de,openstack/fuel-devops,master,Id5528b282cf9586dcc86678739c1ff10e88fc6de,Bump fuel-devops version to 2.9.14,MERGED,2015-12-11 11:07:58.000000000,2015-12-11 14:17:16.000000000,2015-12-11 14:14:38.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9977}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11969}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 16414}, {'_account_id': 19119}, {'_account_id': 19120}]","[{'number': 1, 'created': '2015-12-11 11:07:58.000000000', 'files': ['docs/source/conf.py', 'setup.py', 'devops/__init__.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/f57265ae43ec08bd4aeae630a9025dff1d205d77', 'message': 'Bump fuel-devops version to 2.9.14\n\nChange-Id: Id5528b282cf9586dcc86678739c1ff10e88fc6de\n'}]",0,256349,f57265ae43ec08bd4aeae630a9025dff1d205d77,14,18,1,11969,,,0,"Bump fuel-devops version to 2.9.14

Change-Id: Id5528b282cf9586dcc86678739c1ff10e88fc6de
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/49/256349/1 && git format-patch -1 --stdout FETCH_HEAD,"['docs/source/conf.py', 'setup.py', 'devops/__init__.py']",3,f57265ae43ec08bd4aeae630a9025dff1d205d77,bump-to-2.9.14,__version__ = '2.9.14',__version__ = '2.9.13',4,4
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ia6261223e7701734f47ce48471c86f690ba3dcd5,openstack/tripleo-heat-templates,stable/liberty,Ia6261223e7701734f47ce48471c86f690ba3dcd5,Add the GlanceRegistry and Horizon endpoints to EndpointMap,MERGED,2015-12-03 16:39:18.000000000,2015-12-11 14:12:59.000000000,2015-12-11 14:12:58.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 14369}]","[{'number': 1, 'created': '2015-12-03 16:39:18.000000000', 'files': ['network/endpoints/endpoint_map.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfb8a49764cc9fac72fd2705a4d45901f1898d1f', 'message': 'Add the GlanceRegistry and Horizon endpoints to EndpointMap\n\nWe need to pass details of the Glance Registry and public Horizon\nendpoints to the load balancers so add them to the EndpointMap\n\nChange-Id: Ia6261223e7701734f47ce48471c86f690ba3dcd5\n'}]",0,253061,dfb8a49764cc9fac72fd2705a4d45901f1898d1f,9,6,1,10873,,,0,"Add the GlanceRegistry and Horizon endpoints to EndpointMap

We need to pass details of the Glance Registry and public Horizon
endpoints to the load balancers so add them to the EndpointMap

Change-Id: Ia6261223e7701734f47ce48471c86f690ba3dcd5
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/61/253061/1 && git format-patch -1 --stdout FETCH_HEAD,['network/endpoints/endpoint_map.yaml'],1,dfb8a49764cc9fac72fd2705a4d45901f1898d1f,tls_backport," GlanceRegistryAdmin: {protocol: 'http', port: '9191', host: 'IP_ADDRESS'} GlanceRegistryInternal: {protocol: 'http', port: '9191', host: 'IP_ADDRESS'} GlanceRegistryPublic: {protocol: 'http', port: '9191', host: 'IP_ADDRESS'} HorizonPublic: {protocol: 'http', port: '80', host: 'IP_ADDRESS'} GlanceRegistryInternal: type: OS::TripleO::Endpoint properties: EndpointName: GlanceInternal EndpointMap: { get_param: EndpointMap } IP: {get_param: GlanceRegistryVirtualIP} GlanceRegistryPublic: type: OS::TripleO::Endpoint properties: EndpointName: GlancePublic EndpointMap: { get_param: EndpointMap } IP: {get_param: PublicVirtualIP} GlanceRegistryAdmin: type: OS::TripleO::Endpoint properties: EndpointName: GlanceAdmin EndpointMap: { get_param: EndpointMap } IP: {get_param: GlanceRegistryVirtualIP} HorizonPublic: type: OS::TripleO::Endpoint properties: EndpointName: HeatPublic EndpointMap: { get_param: EndpointMap } IP: {get_param: PublicVirtualIP} CloudName: {get_param: CloudName} UriSuffix: '/dashboard' GlanceRegistryInternal: {get_attr: [ GlanceRegistryInternal, endpoint] } GlanceRegistryPublic: {get_attr: [ GlanceRegistryPublic, endpoint] } GlanceRegistryAdmin: {get_attr: [ GlanceRegistryAdmin, endpoint] } HorizonPublic: {get_attr: [ HorizonPublic, endpoint] }",,35,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I5c31befde51e398318c7b8c744310212288ad892,openstack/tripleo-heat-templates,stable/liberty,I5c31befde51e398318c7b8c744310212288ad892,Expose the IP of the Endpoints,MERGED,2015-12-03 16:39:18.000000000,2015-12-11 14:12:46.000000000,2015-12-11 14:12:45.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8042}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 14369}]","[{'number': 1, 'created': '2015-12-03 16:39:18.000000000', 'files': ['network/endpoints/endpoint.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6216197b600a72a4978e85b99743146267ffb5bd', 'message': 'Expose the IP of the Endpoints\n\nWe expose all of the other parameters, so expose the IP too for\nconsistency\n\nChange-Id: I5c31befde51e398318c7b8c744310212288ad892\n'}]",0,253060,6216197b600a72a4978e85b99743146267ffb5bd,9,7,1,10873,,,0,"Expose the IP of the Endpoints

We expose all of the other parameters, so expose the IP too for
consistency

Change-Id: I5c31befde51e398318c7b8c744310212288ad892
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/60/253060/1 && git format-patch -1 --stdout FETCH_HEAD,['network/endpoints/endpoint.yaml'],1,6216197b600a72a4978e85b99743146267ffb5bd,tls_backport, ip: {get_param: IP},,1,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ic6d708b083244442195eee890de91bbc7e133ec2,openstack/tripleo-heat-templates,stable/liberty,Ic6d708b083244442195eee890de91bbc7e133ec2,Make CloudName available for Endpoints,MERGED,2015-12-03 16:39:18.000000000,2015-12-11 14:12:30.000000000,2015-12-11 14:12:30.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 8399}, {'_account_id': 8449}, {'_account_id': 14369}]","[{'number': 1, 'created': '2015-12-03 16:39:18.000000000', 'files': ['network/endpoints/endpoint_map.yaml', 'overcloud-without-mergepy.yaml', 'network/endpoints/endpoint.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/da525a1d7b3e85b9ac8a3fc5cca43cc4637b7550', 'message': 'Make CloudName available for Endpoints\n\nCloudName is the DNS name for the public VIP this means we will likely\nwant it available for use in the endpoint hostnames, rather than people\nneeding to copy and paste the same hostname\n\nChange-Id: Ic6d708b083244442195eee890de91bbc7e133ec2\n'}]",0,253059,da525a1d7b3e85b9ac8a3fc5cca43cc4637b7550,9,6,1,10873,,,0,"Make CloudName available for Endpoints

CloudName is the DNS name for the public VIP this means we will likely
want it available for use in the endpoint hostnames, rather than people
needing to copy and paste the same hostname

Change-Id: Ic6d708b083244442195eee890de91bbc7e133ec2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/59/253059/1 && git format-patch -1 --stdout FETCH_HEAD,"['network/endpoints/endpoint_map.yaml', 'overcloud-without-mergepy.yaml', 'network/endpoints/endpoint.yaml']",3,da525a1d7b3e85b9ac8a3fc5cca43cc4637b7550,tls_backport," CloudName: type: string default: '' description: The DNS name of this cloud. E.g. ci-overcloud.tripleo.org params: {IP_ADDRESS: {get_param: IP}, CLOUDNAME: {get_param: CloudName}} params: {IP_ADDRESS: {get_param: IP}, CLOUDNAME: {get_param: CloudName }} params: {IP_ADDRESS: {get_param: IP}, CLOUDNAME: {get_param: CloudName} }", params: {IP_ADDRESS: {get_param: IP} } params: {IP_ADDRESS: {get_param: IP} } params: {IP_ADDRESS: {get_param: IP} },49,3
openstack%2Ffuel-web~master~I694b8255cb15db75f292099806974a5f374b7868,openstack/fuel-web,master,I694b8255cb15db75f292099806974a5f374b7868,Improve floating ranges validation,MERGED,2015-12-09 09:56:51.000000000,2015-12-11 14:10:34.000000000,2015-12-11 13:53:52.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-09 09:56:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/20c43250512bb06ff99ef6c2952c393c1178e90d', 'message': 'Improve floating ranges validation\n\nCloses-Bug: #1518435\n\nChange-Id: I694b8255cb15db75f292099806974a5f374b7868\n'}, {'number': 2, 'created': '2015-12-10 09:38:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c97a66a6afdc8be5303d3a0550a11a2d0cee479b', 'message': 'Improve floating ranges validation\n\nCloses-Bug: #1518435\n\nChange-Id: I694b8255cb15db75f292099806974a5f374b7868\n'}, {'number': 3, 'created': '2015-12-11 08:33:37.000000000', 'files': ['nailgun/static/utils.js', 'nailgun/static/translations/core.json', 'nailgun/static/models.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2c90987b8b2b9b74087534512b7f9e962fffd264', 'message': 'Improve floating ranges validation\n\nCloses-Bug: #1518435\n\nChange-Id: I694b8255cb15db75f292099806974a5f374b7868\n'}]",16,255170,2c90987b8b2b9b74087534512b7f9e962fffd264,34,4,3,8766,,,0,"Improve floating ranges validation

Closes-Bug: #1518435

Change-Id: I694b8255cb15db75f292099806974a5f374b7868
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/70/255170/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/utils.js', 'nailgun/static/translations/core.json', 'nailgun/static/models.js']",3,20c43250512bb06ff99ef6c2952c393c1178e90d,bug/1518435," var maxUntaggedNetworksCount = networks.any({name: 'public'}) && networks.any({name: 'floating'}) ? 2 : 1; networkingParametersErrors[paramName] = i18n(ns + 'invalid_name'); var defaultNodeNetworkGroupId = _.min(_.compact(networks.pluck('group_id'))), networkWithFloatingRange = networks.find( (network) => network.get('group_id') == defaultNodeNetworkGroupId && network.get('meta').floating_range_var ), networkWithFloatingRangeName = _.capitalize(networkWithFloatingRange.get('name')); var networkWithFloatingRangeCidrError = false; try { networkWithFloatingRangeCidrError = errors.networks[defaultNodeNetworkGroupId][networkWithFloatingRange.id].cidr; } catch (error) {} if (networkWithFloatingRange && !networkWithFloatingRangeCidrError) { floatingRangesErrors = utils.validateIpRanges( networkParameters.get('floating_ranges'), networkWithFloatingRange.get('cidr'), true, networkWithFloatingRange.get('meta').notation == 'ip_ranges' && networkWithFloatingRange.get('ip_ranges'), { 'does-not-match-cidr': i18n(ns + 'floating_ip_does_not_match_cidr', { cidr: networkWithFloatingRange.get('cidr'), network: networkWithFloatingRangeName }), 'ip-ranges-intersection': i18n(ns + 'floating_and_public_ip_ranges_intersection', { network: networkWithFloatingRangeName }) } ); "," var maxUntaggedNetworksCount = networks.where({name: 'public'}).length && networks.where({name: 'floating'}).length ? 2 : 1; networkingParametersErrors[paramName] = i18n('cluster_page.network_tab.validation.invalid_name'); var networkWithFloatingRange = networks.filter(function(network) { return network.get('meta').floating_range_var; })[0]; if (networkWithFloatingRange && !_.has(((errors.networks || {})[networkWithFloatingRange.get('group_id')] || {})[networkWithFloatingRange.id], 'cidr')) { floatingRangesErrors = utils.validateIpRanges(networkParameters.get('floating_ranges'), networkWithFloatingRange.get('cidr'), true);",87,46
openstack%2Frequirements~master~I2f82694711d51ce4cf07fff78a42ad86e280682c,openstack/requirements,master,I2f82694711d51ce4cf07fff78a42ad86e280682c,Bumps os-win version to 0.0.7,MERGED,2015-12-09 02:31:16.000000000,2015-12-11 14:09:45.000000000,2015-12-11 14:09:44.000000000,"[{'_account_id': 3}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-09 02:31:16.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/bd520da5005b743aa42f3de8f3034295e836db25', 'message': 'Bumps os-win version to 0.0.7\n\nos-win 0.0.7 has been released. Some of the changes are:\n\nAdds method for checking if disk is attached.\nAdds Python 3 compatibility.\nAdds exception and unused arguments cleanup.\nAdds virtual disk IOPS limits setter.\nCaches Windows version. The  HyperVDriver will load faster.\nAdds method to set VM boot order.\n\nChange-Id: I2f82694711d51ce4cf07fff78a42ad86e280682c\n'}]",0,255045,bd520da5005b743aa42f3de8f3034295e836db25,7,2,1,8213,,,0,"Bumps os-win version to 0.0.7

os-win 0.0.7 has been released. Some of the changes are:

Adds method for checking if disk is attached.
Adds Python 3 compatibility.
Adds exception and unused arguments cleanup.
Adds virtual disk IOPS limits setter.
Caches Windows version. The  HyperVDriver will load faster.
Adds method to set VM boot order.

Change-Id: I2f82694711d51ce4cf07fff78a42ad86e280682c
",git fetch https://review.opendev.org/openstack/requirements refs/changes/45/255045/1 && git format-patch -1 --stdout FETCH_HEAD,"['global-requirements.txt', 'upper-constraints.txt']",2,bd520da5005b743aa42f3de8f3034295e836db25,,os-win===0.0.7,os-win===0.0.6,2,2
openstack%2Frequirements~master~Icdb8ba7df74f8232cb0b9529f8d9d7be5f9dbcc1,openstack/requirements,master,Icdb8ba7df74f8232cb0b9529f8d9d7be5f9dbcc1,Bump inspectorclient to 1.3.0 to support get_data,MERGED,2015-12-09 20:31:22.000000000,2015-12-11 14:09:42.000000000,2015-12-11 14:09:40.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 5638}, {'_account_id': 10239}]","[{'number': 1, 'created': '2015-12-09 20:31:22.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/61f8de56a77187b87c3ae75c637a3aa9045f0beb', 'message': 'Bump inspectorclient to 1.3.0 to support get_data\n\nThis adds support for the get_data call per:\nI28c85a0354dd1880eed36bc4cee5a8051ac9d57b\n\nChange-Id: Icdb8ba7df74f8232cb0b9529f8d9d7be5f9dbcc1\n'}]",0,255482,61f8de56a77187b87c3ae75c637a3aa9045f0beb,10,4,1,360,,,0,"Bump inspectorclient to 1.3.0 to support get_data

This adds support for the get_data call per:
I28c85a0354dd1880eed36bc4cee5a8051ac9d57b

Change-Id: Icdb8ba7df74f8232cb0b9529f8d9d7be5f9dbcc1
",git fetch https://review.opendev.org/openstack/requirements refs/changes/82/255482/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,61f8de56a77187b87c3ae75c637a3aa9045f0beb,inspector-client,python-ironic-inspector-client>=1.3.0,python-ironic-inspector-client>=1.2.0,1,1
openstack%2Fsahara~master~I2381750a5a5d667780e2354a7b99e49f0d5e3aa7,openstack/sahara,master,I2381750a5a5d667780e2354a7b99e49f0d5e3aa7,Add ability to get auth token from auth plugin,MERGED,2015-12-01 12:27:08.000000000,2015-12-11 14:03:35.000000000,2015-12-11 14:03:34.000000000,"[{'_account_id': 3}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7213}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 12039}, {'_account_id': 13919}, {'_account_id': 18777}]","[{'number': 1, 'created': '2015-12-01 12:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4f12df36ffe457165113042e19c11f42bb65c098', 'message': 'Method to get fresh token from auth plugin\n\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 2, 'created': '2015-12-03 10:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cdbe79ce5eef10d592d299d75e3eb4ce1f0f9310', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 3, 'created': '2015-12-03 11:48:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/3a7ae6b28c747817322c7e6e1743bd86bcaf69e1', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 4, 'created': '2015-12-04 12:14:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/45392c1a18438c6181d0233657ebf97d8be56380', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 5, 'created': '2015-12-04 12:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/f0c56308ed5e2ce1970d6cd79711b8e02ef6c914', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 6, 'created': '2015-12-04 12:21:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/e458ef40fe3adae92e104740325bf514992e4546', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 7, 'created': '2015-12-04 12:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/9a3c9fe94dbfc4e10b210df1c1ebc3f1330cb9be', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 8, 'created': '2015-12-07 10:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/59814650f37a9219d5e9c825d44379002ca71aed', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 9, 'created': '2015-12-10 09:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e2749671658077565106912de24651157e6f39f', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}, {'number': 10, 'created': '2015-12-10 22:42:36.000000000', 'files': ['sahara/tests/unit/service/edp/binary_retrievers/test_internal_swift.py', 'sahara/service/trusts.py', 'sahara/utils/openstack/heat.py', 'sahara/service/sessions.py', 'sahara/utils/openstack/base.py', 'sahara/utils/ssh_remote.py', 'sahara/service/edp/binary_retrievers/internal_swift.py', 'sahara/utils/openstack/swift.py', 'sahara/context.py', 'sahara/utils/openstack/keystone.py', 'sahara/utils/openstack/manila.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/dd85b5d78d2ac97be91afc074dc8e4b3b4d93091', 'message': 'Add ability to get auth token from auth plugin\n\nThis implements ability to get auth token from auth plugin\nto allow refreshing auth token in case of auth plugin with\ntrusts.\n\nPartial-bug: 1486653\nChange-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7\n'}]",5,251835,dd85b5d78d2ac97be91afc074dc8e4b3b4d93091,41,11,10,12038,,,0,"Add ability to get auth token from auth plugin

This implements ability to get auth token from auth plugin
to allow refreshing auth token in case of auth plugin with
trusts.

Partial-bug: 1486653
Change-Id: I2381750a5a5d667780e2354a7b99e49f0d5e3aa7
",git fetch https://review.opendev.org/openstack/sahara refs/changes/35/251835/5 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/utils/openstack/heat.py', 'sahara/utils/openstack/base.py', 'sahara/utils/ssh_remote.py', 'sahara/context.py', 'sahara/utils/openstack/keystone.py', 'sahara/utils/openstack/manila.py']",6,4f12df36ffe457165113042e19c11f42bb65c098,bug/1486653," 'input_auth_token': context.get_auth_token(),"," 'input_auth_token': ctx.auth_token,",17,5
openstack%2Fcompute-hyperv~stable%2Fkilo~I9b4167d3c41ee34393dd93a919c642dff2ae2c5f,openstack/compute-hyperv,stable/kilo,I9b4167d3c41ee34393dd93a919c642dff2ae2c5f,Update .gitreview for new namespace,MERGED,2015-10-17 22:05:53.000000000,2015-12-11 14:01:18.000000000,2015-12-11 13:52:10.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}, {'_account_id': 16272}]","[{'number': 1, 'created': '2015-10-17 22:05:53.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/0a43428901422606bab4b9011440b5fda86a36e3', 'message': 'Update .gitreview for new namespace\n\nChange-Id: I9b4167d3c41ee34393dd93a919c642dff2ae2c5f\n'}]",0,236308,0a43428901422606bab4b9011440b5fda86a36e3,9,4,1,5263,,,0,"Update .gitreview for new namespace

Change-Id: I9b4167d3c41ee34393dd93a919c642dff2ae2c5f
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/08/236308/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,0a43428901422606bab4b9011440b5fda86a36e3,stackforge-retirement,project=openstack/compute-hyperv.git,project=stackforge/compute-hyperv.git,1,1
openstack%2Fpython-senlinclient~master~Id0560d146539f2807dbab8cc4cb9abb62dcbfe56,openstack/python-senlinclient,master,Id0560d146539f2807dbab8cc4cb9abb62dcbfe56,Make cluster-policy-update help message clear,MERGED,2015-12-09 10:04:01.000000000,2015-12-11 14:00:44.000000000,2015-12-11 14:00:44.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 9323}, {'_account_id': 15857}]","[{'number': 1, 'created': '2015-12-09 10:04:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/539e840618c523d450a78c6d2ce4ea987ae4949c', 'message': ""Make cluster-policy-update help message clear\n\nCurrent help message of cluster-policy-update may make\nuser feel updating a policy attached to a cluster.\nIn fact, only policy's properties are about to be updated.\n\nChange-Id: Id0560d146539f2807dbab8cc4cb9abb62dcbfe56\nCloses-bug: #1524261\n""}, {'number': 2, 'created': '2015-12-11 13:55:52.000000000', 'files': ['senlinclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/48cc6337c311ec9c3cabf89ffbf6c70bb6d7bdfb', 'message': ""Make cluster-policy-update help message clear\n\nCurrent help message of cluster-policy-update may make\nuser feel updating a policy attached to a cluster.\nIn fact, only policy's properties are about to be updated.\n\nChange-Id: Id0560d146539f2807dbab8cc4cb9abb62dcbfe56\nCloses-bug: #1524261\n""}]",0,255177,48cc6337c311ec9c3cabf89ffbf6c70bb6d7bdfb,14,7,2,6348,,,0,"Make cluster-policy-update help message clear

Current help message of cluster-policy-update may make
user feel updating a policy attached to a cluster.
In fact, only policy's properties are about to be updated.

Change-Id: Id0560d146539f2807dbab8cc4cb9abb62dcbfe56
Closes-bug: #1524261
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/77/255177/1 && git format-patch -1 --stdout FETCH_HEAD,['senlinclient/v1/shell.py'],1,539e840618c523d450a78c6d2ce4ea987ae4949c,bug/1524261, '''Update a policy's properties on a cluster.''' '''Enable a policy on a cluster.''', '''Update a policy on cluster.''' '''Enable a policy on cluster.''',2,2
openstack%2Fnetworking-bgpvpn~master~I3b3cbbf0846f8caadb4e7ce105bd33eac460dfe9,openstack/networking-bgpvpn,master,I3b3cbbf0846f8caadb4e7ce105bd33eac460dfe9,Update the spec : remove RTs consolidation part,MERGED,2015-12-11 09:23:41.000000000,2015-12-11 13:58:07.000000000,2015-12-11 13:58:06.000000000,"[{'_account_id': 3}, {'_account_id': 2888}, {'_account_id': 7776}, {'_account_id': 12021}]","[{'number': 1, 'created': '2015-12-11 09:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/757de0705550fc4466544f610d5a29a64e743b9c', 'message': 'Update the spec : remove RTs consolidation part.\n\nRTs consolidation specified in the spec is currently not implemented.\nThis consolidation will have to be done at the driver level,\nnot at the plugin level.\n\nChange-Id: I3b3cbbf0846f8caadb4e7ce105bd33eac460dfe9\nCloses-bug: 1478998\n'}, {'number': 2, 'created': '2015-12-11 10:09:51.000000000', 'files': ['doc/source/specs.rst'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/8c740c06464fd9782311c20757424d3bfb42e78f', 'message': 'Update the spec : remove RTs consolidation part\n\nRTs consolidation specified in the spec is currently not implemented.\nThis consolidation will have to be done at the driver level,\nnot at the plugin level.\n\nChange-Id: I3b3cbbf0846f8caadb4e7ce105bd33eac460dfe9\nCloses-bug: 1478998\n'}]",0,256300,8c740c06464fd9782311c20757424d3bfb42e78f,12,4,2,2888,,,0,"Update the spec : remove RTs consolidation part

RTs consolidation specified in the spec is currently not implemented.
This consolidation will have to be done at the driver level,
not at the plugin level.

Change-Id: I3b3cbbf0846f8caadb4e7ce105bd33eac460dfe9
Closes-bug: 1478998
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/00/256300/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/specs.rst'],1,757de0705550fc4466544f610d5a29a64e743b9c,bug/1478998,* one to define the n-n relation ship between a BGPVPN and a set of Networks * one to define the n-n relation ship between a BGPVPN and a set of RoutersAPI.,"* one to define the 1-n relation ship between a BGPVPN and a set of Networks * one to define the 1-n relation ship between a BGPVPN and a set of RoutersAPI, with an exception for route_targets: * this list will not be present in the database * on an API request to create or modify a BGPVPN: the route_targets parameter will be merged with import_rts, without duplicates, before storing in import_rts ; and the same will be done for export_rts * on an API request to show a BGPVPN: * route_targets will be synthesized to include RTs present in both export_rts and import_rts * import_targets will contain only RTs not in common with export_rts * export_targets will contain only RTs not in common with import_rts",3,18
openstack%2Ffuel-devops~master~I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d,openstack/fuel-devops,master,I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d,Add partial support for external snapshots,MERGED,2015-10-15 19:57:46.000000000,2015-12-11 13:52:56.000000000,2015-12-11 13:50:22.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 7227}, {'_account_id': 8787}, {'_account_id': 8882}, {'_account_id': 8965}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 9977}, {'_account_id': 10068}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 11110}, {'_account_id': 11969}, {'_account_id': 12200}, {'_account_id': 12867}, {'_account_id': 16106}, {'_account_id': 17214}, {'_account_id': 19071}, {'_account_id': 19119}]","[{'number': 1, 'created': '2015-10-15 19:57:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/fa5aa79c94cfc263155afce4221e88c196e8f248', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete no used external snapshot files (WIP)\n\nThis change does not add full support for external snapshots, it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy all qcow files.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 2, 'created': '2015-10-15 22:26:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/cc324a4a9720840f94e3d1d65573fb18d07d2757', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete no used external snapshot files (WIP)\n\nThis change does not add full support for external snapshots, it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy all qcow files.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 3, 'created': '2015-10-17 20:19:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/04a1019d03ddfb5bbcdaa3d8c5551fbd8e56068b', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete no used external snapshot files\n\nThis change does not add full support for external snapshots, it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 4, 'created': '2015-10-17 23:06:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/98c0a423c9724abcce6597fb2908f53d4648e598', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete no used external snapshot files\n\nThis change does not add full support for external snapshots, it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 5, 'created': '2015-10-18 10:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/86b88ea15810bd70949807b19b2665a3a9b280e1', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 6, 'created': '2015-10-18 10:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/c037f72100857db91aecdcb8e2b17276849c4828', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 7, 'created': '2015-10-19 14:47:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/eacdc5d329708f4e1eb5d6a74e01734c7581a7d4', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 8, 'created': '2015-10-19 19:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/53bbbdf7ceb48176fd6971088ff253ecbc540e72', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 9, 'created': '2015-10-20 11:05:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a1b9a366361445f95367a383168606974e682d71', 'message': '[WIP] Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 10, 'created': '2015-10-21 08:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/ea95a70f4f200bf679dd08cc19e487185e923dfb', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 11, 'created': '2015-10-24 16:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/bbe36857eed6faa8a39c44b1d3292bbee2b08499', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nBlueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 12, 'created': '2015-10-24 16:38:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/70d010fa5898dc6183824b7420c74e6900795fc8', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nBlueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 13, 'created': '2015-11-10 15:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/4f5d6e6b91172fcfc18e875f3b5d80454b90958d', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nBlueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 14, 'created': '2015-11-10 16:42:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/138833cd89b6d0fae342d3f1dd3e5852fe1c5384', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nBlueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 15, 'created': '2015-11-10 16:44:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/aba9afd862ab652864663faf93b336465522721a', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nBlueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 16, 'created': '2015-11-12 14:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/9a5161c1b17050621d789106e460389e695a7f45', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nImplements-Blueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 17, 'created': '2015-12-10 22:35:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/a68ff9017d632a1d2cc78e8c6c6b65fa98a937f2', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nImplements-Blueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}, {'number': 18, 'created': '2015-12-11 12:57:37.000000000', 'files': ['devops/helpers/ntp.py', 'devops/driver/libvirt/libvirt_driver.py', 'devops/tests/test_manager.py', 'devops/tests/test_shell.py', 'devops/settings.py', 'devops/tests/test_libvirt_driver.py', 'devops/tests/test_libvirt_xml_builder.py', 'devops/models/node.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/models/environment.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/820fb1e9d485dbcbc5ceda725ddba267d649da13', 'message': 'Add partial support for external snapshots\n\nThis change add partial support for external snapshots from libvirt.\nAllow:\n- create disk and memory snapshot in separated file\n- restore domain state\n- delete not used external snapshot files\n\nTo use external snapshots libvirt must be in version >= 1.2.12\n\nThis change does not add full support for external snapshots and it\nnot replace internal snapshots functionality. It goal is to\ncreate separate snapshots files, which could be reused on other\nsystems, without need to copy one big qcow file with all snapshots.\n\nImplements-Blueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots\n\nChange-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d\n'}]",33,235566,820fb1e9d485dbcbc5ceda725ddba267d649da13,110,20,18,17214,,,0,"Add partial support for external snapshots

This change add partial support for external snapshots from libvirt.
Allow:
- create disk and memory snapshot in separated file
- restore domain state
- delete not used external snapshot files

To use external snapshots libvirt must be in version >= 1.2.12

This change does not add full support for external snapshots and it
not replace internal snapshots functionality. It goal is to
create separate snapshots files, which could be reused on other
systems, without need to copy one big qcow file with all snapshots.

Implements-Blueprint: https://blueprints.launchpad.net/fuel/+spec/system-test-external-snapshots

Change-Id: I415d753a0847f4c6de2b4b0bb79aa5ead37e5d8d
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/66/235566/16 && git format-patch -1 --stdout FETCH_HEAD,"['devops/driver/libvirt/libvirt_driver.py', 'devops/shell.py', 'devops/models/node.py', 'devops/driver/libvirt/libvirt_xml_builder.py', 'devops/models/environment.py']",5,fa5aa79c94cfc263155afce4221e88c196e8f248,bp/https," def snapshot(self, name=None, description=None, force=False, external=False): node.snapshot(name=name, description=description, force=force, external=external) print ""ENV revert for %s"" % node.name"," def snapshot(self, name=None, description=None, force=False): node.snapshot(name=name, description=description, force=force)",151,13
openstack%2Fpuppet-tempest~master~I63716c9ecd140d85bc252ad179e76efad35c740f,openstack/puppet-tempest,master,I63716c9ecd140d85bc252ad179e76efad35c740f,CI test - do not merge,ABANDONED,2015-12-10 19:05:42.000000000,2015-12-11 13:50:44.000000000,,"[{'_account_id': 3}, {'_account_id': 7745}]","[{'number': 1, 'created': '2015-12-10 19:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/d4dc27d0a0243543b2da25ff7422ecc9dac89a53', 'message': 'CI test - do not merge\n\npuppet-tempest is broken and probably needs\nhttps://review.openstack.org/#/c/253416/\n\nChange-Id: I63716c9ecd140d85bc252ad179e76efad35c740f\nDepends-On: I5279cfd72192534a5ffcfdaf71b257b082a8b42c\n'}, {'number': 2, 'created': '2015-12-11 11:45:32.000000000', 'files': ['README.markdown'], 'web_link': 'https://opendev.org/openstack/puppet-tempest/commit/09c267ba850f83551fc4b72756bff5b6c3dd1fe7', 'message': 'CI test - do not merge\n\npuppet-tempest is broken and probably needs\nhttps://review.openstack.org/#/c/256370/\n\nChange-Id: I63716c9ecd140d85bc252ad179e76efad35c740f\nDepends-On: Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410\n'}]",0,256060,09c267ba850f83551fc4b72756bff5b6c3dd1fe7,5,2,2,3153,,,0,"CI test - do not merge

puppet-tempest is broken and probably needs
https://review.openstack.org/#/c/256370/

Change-Id: I63716c9ecd140d85bc252ad179e76efad35c740f
Depends-On: Ic14f723fe6b7dee01bed1d8234aa8c79ecf9f410
",git fetch https://review.opendev.org/openstack/puppet-tempest refs/changes/60/256060/1 && git format-patch -1 --stdout FETCH_HEAD,['README.markdown'],1,d4dc27d0a0243543b2da25ff7422ecc9dac89a53,puppet/test-ci,Do not review,,1,1
openstack%2Fapi-site~master~Iabedf9d7f1ec217d43beac667f36267eb96dc646,openstack/api-site,master,Iabedf9d7f1ec217d43beac667f36267eb96dc646,Update content in http://developer.openstack.org/,MERGED,2015-12-11 07:17:06.000000000,2015-12-11 13:50:26.000000000,2015-12-11 13:50:25.000000000,"[{'_account_id': 3}, {'_account_id': 964}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 07:17:06.000000000', 'files': ['www/index.html'], 'web_link': 'https://opendev.org/openstack/api-site/commit/2d96bc076f5b4144e5b272a89ddd63bfcd4132af', 'message': 'Update content in http://developer.openstack.org/\n\nChange-Id: Iabedf9d7f1ec217d43beac667f36267eb96dc646\n'}]",0,256254,2d96bc076f5b4144e5b272a89ddd63bfcd4132af,8,4,1,16237,,,0,"Update content in http://developer.openstack.org/

Change-Id: Iabedf9d7f1ec217d43beac667f36267eb96dc646
",git fetch https://review.opendev.org/openstack/api-site refs/changes/54/256254/1 && git format-patch -1 --stdout FETCH_HEAD,['www/index.html'],1,2d96bc076f5b4144e5b272a89ddd63bfcd4132af,update-doc," <a href=""https://git.openstack.org/cgit/openstack/python-manilaclient/""> Shared File Systems </a> </dd> <dd> <a href=""http://developer.openstack.org/api-ref-clustering-v1.html""> Clustering API v1 (CURRENT) </a> </dd> <dd> Networking API v2.0 extensions (CURRENT) <a href=""http://docs.openstack.org/contributor-guide/"">"," Networking API v2.0 extensions (CURRENT) <a href=""http://wiki.openstack.org/Documentation/HowTo"">",12,2
openstack%2Fsenlin~master~Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976,openstack/senlin,master,Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976,Fix MutableList implementation,MERGED,2015-12-09 13:46:46.000000000,2015-12-11 13:49:48.000000000,2015-12-11 11:26:52.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 11034}, {'_account_id': 15857}]","[{'number': 1, 'created': '2015-12-09 13:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/72ad5eb9dfcfd7f9548ce87fe5fa01d49af1a058', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}, {'number': 2, 'created': '2015-12-10 01:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/10f54052cec4f96498fa52c02141ad850d75f7dc', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}, {'number': 3, 'created': '2015-12-10 01:55:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/a8ce39920f80885c6f60f08bbcfbc9d7692bc017', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}, {'number': 4, 'created': '2015-12-10 04:51:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/ade87e174894538f27662325f69be1239100abbe', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}, {'number': 5, 'created': '2015-12-10 15:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/13ea6b221ef2ec6315b0ff439f6c1f90de1b3106', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}, {'number': 6, 'created': '2015-12-11 06:20:49.000000000', 'files': ['senlin/db/sqlalchemy/types.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/b907d14ca72272bef188f9b08c68431fe36a9dcd', 'message': 'Fix MutableList implementation\n\nThis patch is an attempt to fix the MutableList implementation. It is\ndoing no harm and it is probably fixing the action dependency problem.\n\nChange-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976\n'}]",0,255267,b907d14ca72272bef188f9b08c68431fe36a9dcd,29,5,6,8246,,,0,"Fix MutableList implementation

This patch is an attempt to fix the MutableList implementation. It is
doing no harm and it is probably fixing the action dependency problem.

Change-Id: Iad42bd4eedda5a1d0de77b4bf33e4d24b15bf976
",git fetch https://review.opendev.org/openstack/senlin refs/changes/67/255267/5 && git format-patch -1 --stdout FETCH_HEAD,['senlin/db/sqlalchemy/types.py'],1,72ad5eb9dfcfd7f9548ce87fe5fa01d49af1a058,fix-list-type," if not isinstance(value, MutableList): if isinstance(value, list): return MutableList(value) def __setitem__(self, key, value): old_value = list.__getitem__(self, key) for obj, key in self._parents.items(): old_value._parents.pop(obj, None) for obj, key in self._parents.items(): value._parents[obj] = key self[:] = state def extend(self, iterable): list.extend(self, iterable) self.changed() def insert(self, index, item): list.insert(self, index, item) self.changed() def pop(self, index=-1): item = list.pop(self, index) self.changed() return item def reverse(self): list.reverse(self) self.changed() def sort(self, cmp=None, key=None, reverse=False): list.sort(self, cmp, key, reverse) self.changed() "," if not isinstance(value, cls): if isinstance(value, list): return cls(value) def __delitem__(self, key): list.__delitem__(self, key) self.changed() def __setitem__(self, key, value): len = list.__len__(self) list.__delslice__(self, 0, len) list.__add__(self, state) self.changed()",29,10
openstack%2Fopenstacksdk~master~I5857b301661409262af4054941a36f53633ff2aa,openstack/openstacksdk,master,I5857b301661409262af4054941a36f53633ff2aa,Add PolicyType resource for clustering,MERGED,2015-12-09 06:59:55.000000000,2015-12-11 13:49:41.000000000,2015-12-11 13:49:41.000000000,"[{'_account_id': 3}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-09 06:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/4fb3208542cc23251b05654239727c4baeb3fb8c', 'message': 'Add PolicyType resource for clustering\n\nThis proposes the PolicyType resource for clustering (senlin) service.\n\nChange-Id: I5857b301661409262af4054941a36f53633ff2aa\n'}, {'number': 2, 'created': '2015-12-11 13:17:36.000000000', 'files': ['openstack/cluster/v1/policy_type.py', 'openstack/tests/unit/cluster/v1/test_policy_type.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/f47cd8ef1746cb5fccb33350be29be0b36ab243e', 'message': 'Add PolicyType resource for clustering\n\nThis proposes the PolicyType resource for clustering (senlin) service.\n\nChange-Id: I5857b301661409262af4054941a36f53633ff2aa\n'}]",0,255102,f47cd8ef1746cb5fccb33350be29be0b36ab243e,10,2,2,8246,,,0,"Add PolicyType resource for clustering

This proposes the PolicyType resource for clustering (senlin) service.

Change-Id: I5857b301661409262af4054941a36f53633ff2aa
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/02/255102/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/v1/policy_type.py', 'openstack/tests/unit/cluster/v1/test_policy_type.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py']",4,4fb3208542cc23251b05654239727c4baeb3fb8c,add-policy-type,"from openstack.cluster.v1 import policy_type def test_policy_types(self): self.verify_list(self.proxy.policy_types, policy_type.PolicyType, paginated=False) def test_policy_type_get(self): self.verify_get(self.proxy.get_policy_type, policy_type.PolicyType) ",,103,0
openstack%2Fopenstacksdk~master~I48b0934f6be500d7c9d12ba2643269aaa95988e8,openstack/openstacksdk,master,I48b0934f6be500d7c9d12ba2643269aaa95988e8,Add 'ProfileType' resource for senlin,MERGED,2015-12-05 15:09:27.000000000,2015-12-11 13:49:05.000000000,2015-12-11 13:49:03.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}, {'_account_id': 15857}]","[{'number': 1, 'created': '2015-12-05 15:09:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/98a954473d69331c909c614eb68aa6535df5c4ff', 'message': ""Add 'ProfileType' resource for senlin\n\nThis proposes a 'ProfileType' resource for senlin clustering service.\n\nChange-Id: I48b0934f6be500d7c9d12ba2643269aaa95988e8\n""}, {'number': 2, 'created': '2015-12-08 01:32:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/62b6f275322693918c5a5225b69693f09847fa3a', 'message': ""Add 'ProfileType' resource for senlin\n\nThis proposes a 'ProfileType' resource for senlin clustering service.\n\nChange-Id: I48b0934f6be500d7c9d12ba2643269aaa95988e8\n""}, {'number': 3, 'created': '2015-12-11 13:10:40.000000000', 'files': ['openstack/cluster/v1/profile_type.py', 'openstack/tests/unit/cluster/v1/test_profile_type.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0f3efa3ca0ea3164c1e9a96292c58e5e9ada9625', 'message': ""Add 'ProfileType' resource for senlin\n\nThis proposes a 'ProfileType' resource for senlin clustering service.\n\nChange-Id: I48b0934f6be500d7c9d12ba2643269aaa95988e8\n""}]",6,253817,0f3efa3ca0ea3164c1e9a96292c58e5e9ada9625,16,5,3,8246,,,0,"Add 'ProfileType' resource for senlin

This proposes a 'ProfileType' resource for senlin clustering service.

Change-Id: I48b0934f6be500d7c9d12ba2643269aaa95988e8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/17/253817/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/v1/profile_type.py', 'openstack/tests/unit/cluster/v1/test_profile_type.py', 'openstack/cluster/v1/_proxy.py', 'openstack/tests/unit/cluster/v1/test_proxy.py']",4,98a954473d69331c909c614eb68aa6535df5c4ff,add-profile-type,"from openstack.cluster.v1 import profile_type def test_profile_types(self): self.verify_list(self.proxy.profile_types, profile_type.ProfileType, paginated=False) def test_profile_type_get(self): self.verify_get(self.proxy.get_profile_type, profile_type.ProfileType) ",,103,0
openstack%2Ffuel-web~master~Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0,openstack/fuel-web,master,Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0,Separate dialog for Nailgun unavailability,MERGED,2015-12-10 17:02:49.000000000,2015-12-11 13:45:42.000000000,2015-12-11 13:28:46.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-10 17:02:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/8d55076e1b61176570d7bb9328f5d4fa0aac8b02', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 2, 'created': '2015-12-10 17:36:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/906bc75b72183a1ffcfa01cec48c37f66b2dcd41', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 3, 'created': '2015-12-10 19:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/06110ac2406249f29ff554c8d6c26dd0a0ef5e84', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 4, 'created': '2015-12-10 19:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b634ddcd29da57eec25dbe6d0af71c9dee462217', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 5, 'created': '2015-12-11 10:02:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/85fd74f92e19497940b597514c11be006a7e20b5', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 6, 'created': '2015-12-11 10:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/62c21691b5a0f5f9885b0da016522172951390fb', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}, {'number': 7, 'created': '2015-12-11 10:46:55.000000000', 'files': ['nailgun/static/styles/main.less', 'nailgun/static/app.js', 'nailgun/static/translations/core.json', 'nailgun/static/views/dialogs.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/131dac097569aa3a82f989b3d4c8ef2ae4679a2d', 'message': ""Separate dialog for Nailgun unavailability\n\nIt provides more thorough explanation of what's going on\nand also reattempts to start UI.\n\nChange-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0\nCloses-Bug: #1507734\n""}]",0,255991,131dac097569aa3a82f989b3d4c8ef2ae4679a2d,56,4,7,8735,,,0,"Separate dialog for Nailgun unavailability

It provides more thorough explanation of what's going on
and also reattempts to start UI.

Change-Id: Iccf7002efa06f2d9d52422b45fb77d9c75fc3bc0
Closes-Bug: #1507734
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/91/255991/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/app.js', 'nailgun/static/translations/core.json', 'nailgun/static/views/dialogs.js']",3,8d55076e1b61176570d7bb9328f5d4fa0aac8b02,bug/1507734," closeable: React.PropTypes.bool, if (this.props.keyboard !== false && this.props.closeable !== false && e.key == 'Escape') this.close(); {this.props.closeable !== false && <button type='button' className='close' aria-label='Close' onClick={this.close}> <span aria-hidden='true'>&times;</span> </button> } dialogs.NailgunUnavailabilityDialog = React.createClass({ mixins: [dialogMixin], getDefaultProps() { return { title: i18n('dialog.error_dialog.title'), closeable: false, keyboard: false, backdrop: false }; }, renderBody() { return i18n('dialog.nailgun_unavailability.loading_error'); }, renderFooter() { return ( <button className='btn btn-success' onClick={this.close} disabled={this.state.actionInProgress} > {i18n('dialog.nailgun_unavailability.retry')} </button> ); } }); ", if (this.props.keyboard !== false && e.key == 'Escape') this.close(); <button type='button' className='close' aria-label='Close' onClick={this.close}><span aria-hidden='true'>&times;</span></button>,40,11
openstack%2Fpuppet-openstack-cookiecutter~master~Ic2eb50a1c151bce06a94040b0b76b0fe47834933,openstack/puppet-openstack-cookiecutter,master,Ic2eb50a1c151bce06a94040b0b76b0fe47834933,Puppet cookiecutter with $::os_service_default,MERGED,2015-12-11 01:59:30.000000000,2015-12-11 13:40:25.000000000,2015-12-11 13:40:25.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 7423}, {'_account_id': 7745}]","[{'number': 1, 'created': '2015-12-11 01:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/3169b514620d513b5f7d49e139ec5b61f6af2254', 'message': 'Puppet cookiecutter with $::os_service_default\n\nNew projects should be have logging and db with\nos_service_default fact.\n\nChange-Id: Ic2eb50a1c151bce06a94040b0b76b0fe47834933\n'}, {'number': 2, 'created': '2015-12-11 02:03:51.000000000', 'files': ['puppet-{{cookiecutter.project_name}}/spec/classes/{{cookiecutter.project_name}}_logging_spec.rb', 'puppet-{{cookiecutter.project_name}}/manifests/logging.pp', 'puppet-{{cookiecutter.project_name}}/spec/classes/{{cookiecutter.project_name}}_db_spec.rb', 'puppet-{{cookiecutter.project_name}}/manifests/db.pp'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-cookiecutter/commit/6f71b22e35b236260c10781ed09a43c2d011c123', 'message': 'Puppet cookiecutter with $::os_service_default\n\nNew projects should be have logging and db with\nos_service_default fact.\n\nChange-Id: Ic2eb50a1c151bce06a94040b0b76b0fe47834933\n'}]",0,256176,6f71b22e35b236260c10781ed09a43c2d011c123,10,4,2,15519,,,0,"Puppet cookiecutter with $::os_service_default

New projects should be have logging and db with
os_service_default fact.

Change-Id: Ic2eb50a1c151bce06a94040b0b76b0fe47834933
",git fetch https://review.opendev.org/openstack/puppet-openstack-cookiecutter refs/changes/76/256176/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet-{{cookiecutter.project_name}}/spec/classes/{{cookiecutter.project_name}}_logging_spec.rb', 'puppet-{{cookiecutter.project_name}}/manifests/logging.pp', 'puppet-{{cookiecutter.project_name}}/spec/classes/{{cookiecutter.project_name}}_db_spec.rb', 'puppet-{{cookiecutter.project_name}}/manifests/db.pp', 'puppet-{{cookiecutter.project_name}}/manifests/init.pp']",5,3169b514620d513b5f7d49e139ec5b61f6af2254,os_service_default, include ::{{cookiecutter.project_name}}::db include ::{{cookiecutter.project_name}}::logging,,118,233
openstack%2Fpython-senlinclient~master~I79076b0d2a02eea59a47f263ad6bb30e48c6d1b7,openstack/python-senlinclient,master,I79076b0d2a02eea59a47f263ad6bb30e48c6d1b7,Fix pep8 error about D300,MERGED,2015-12-09 02:33:42.000000000,2015-12-11 13:39:01.000000000,2015-12-11 13:39:01.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 9323}, {'_account_id': 14107}, {'_account_id': 15857}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-09 02:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/2cb2bc459f5996bd924053dcf71e8b305e314201', 'message': 'Fix pep8 error about D300\n\nThis patch fix the pep8 error D300 about symbol that\nD300  Use """"""triple double quotes"""""" (found \'\'\'-quotes)\nwhen execute run_tests.sh.\n\nChange-Id: I79076b0d2a02eea59a47f263ad6bb30e48c6d1b7\n'}, {'number': 2, 'created': '2015-12-09 13:27:55.000000000', 'files': ['senlinclient/common/utils.py', 'senlinclient/tests/unit/fakes.py', 'senlinclient/common/sdk.py', 'senlinclient/shell.py', 'senlinclient/common/exc.py', 'senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/common/i18n.py', 'senlinclient/client.py', 'senlinclient/v1/shell.py'], 'web_link': 'https://opendev.org/openstack/python-senlinclient/commit/0edbcd5cc16d61774e0bedc379179eb1465f6207', 'message': 'Fix pep8 error about D300\n\nThis patch fix the pep8 error D300 about symbol that\nD300  Use """"""triple double quotes"""""" (found \'\'\'-quotes)\nwhen execute run_tests.sh.\n\nChange-Id: I79076b0d2a02eea59a47f263ad6bb30e48c6d1b7\n'}]",1,255046,0edbcd5cc16d61774e0bedc379179eb1465f6207,16,8,2,8358,,,0,"Fix pep8 error about D300

This patch fix the pep8 error D300 about symbol that
D300  Use """"""triple double quotes"""""" (found '''-quotes)
when execute run_tests.sh.

Change-Id: I79076b0d2a02eea59a47f263ad6bb30e48c6d1b7
",git fetch https://review.opendev.org/openstack/python-senlinclient refs/changes/46/255046/2 && git format-patch -1 --stdout FETCH_HEAD,"['senlinclient/common/utils.py', 'senlinclient/tests/unit/fakes.py', 'senlinclient/common/exc.py', 'senlinclient/common/sdk.py', 'senlinclient/shell.py', 'senlinclient/tests/unit/v1/test_shell.py', 'senlinclient/common/i18n.py', 'senlinclient/client.py', 'senlinclient/v1/shell.py']",9,2cb2bc459f5996bd924053dcf71e8b305e314201,fix-D300," """"""Get the details about a profile type."""""" """"""List profiles that meet the criteria."""""" """"""Create a profile."""""" """"""Show the profile details."""""" """"""Update a profile."""""" """"""Delete profile(s)."""""" """"""List the available policy types."""""" """"""Get the details about a policy type."""""" """"""List webhooks that meet the criteria."""""" """"""Show the webhook details."""""" """"""Create a webhook."""""" """"""Delete webhook(s)."""""" """"""List policies that meet the criteria."""""" """"""Create a policy."""""" """"""Show the policy details."""""" """"""Update a policy."""""" """"""Delete policy(s)."""""" """"""List the user's clusters."""""" """"""Create the cluster."""""" """"""Delete the cluster(s)."""""" """"""Update the cluster."""""" """"""Show details of the cluster."""""" """"""List nodes from cluster."""""" """"""Add specified nodes to cluster."""""" """"""Delete specified nodes from cluster."""""" """"""Resize a cluster."""""" """"""Scale out a cluster by the specified number of nodes."""""" """"""Scale in a cluster by the specified number of nodes."""""" """"""List policies from cluster."""""" """"""Show a specific policy that is bound to the specified cluster."""""" """"""Attach policy to cluster."""""" """"""Detach policy from cluster."""""" """"""Update a policy on cluster."""""" """"""Enable a policy on cluster."""""" """"""Disable a policy on a cluster."""""" """"""Show list of nodes."""""" """"""Show detailed info about the specified node."""""" """"""Create the node."""""" """"""Show detailed info about the specified node."""""" """"""Delete the node(s)."""""" """"""Update the node."""""" """"""Make node join the specified cluster."""""" """"""Make node leave its current cluster."""""" """"""List events."""""" """"""Describe the event."""""" """"""List actions."""""" """"""Show detailed info about the specified action.""""""", '''Get the details about a profile type.''' '''List profiles that meet the criteria.''' '''Create a profile.''' '''Show the profile details.''' '''Update a profile.''' '''Delete profile(s).''' '''List the available policy types.''' '''Get the details about a policy type.''' '''List webhooks that meet the criteria.''' '''Show the webhook details.''' '''Create a webhook.''' '''Delete webhook(s).''' '''List policies that meet the criteria.''' '''Create a policy.''' '''Show the policy details.''' '''Update a policy.''' '''Delete policy(s).''' '''List the user's clusters.''' '''Create the cluster.''' '''Delete the cluster(s).''' '''Update the cluster.''' '''Show details of the cluster.''' '''List nodes from cluster.''' '''Add specified nodes to cluster.''' '''Delete specified nodes from cluster.''' '''Resize a cluster.''' '''Scale out a cluster by the specified number of nodes.''' '''Scale in a cluster by the specified number of nodes.''' '''List policies from cluster.''' '''Show a specific policy that is bound to the specified cluster.''' '''Attach policy to cluster.''' '''Detach policy from cluster.''' '''Update a policy on cluster.''' '''Enable a policy on cluster.''' '''Disable a policy on a cluster.''' '''Show list of nodes.''' '''Show detailed info about the specified node.''' '''Create the node.''' '''Show detailed info about the specified node.''' '''Delete the node(s).''' '''Update the node.''' '''Make node join the specified cluster.''' '''Make node leave its current cluster.''' '''List events.''' '''Describe the event.''' '''List actions.''' '''Show detailed info about the specified action.''',65,65
openstack%2Ffuel-library~master~I466d89158fab523981ea002e83933696284a11ac,openstack/fuel-library,master,I466d89158fab523981ea002e83933696284a11ac,Move umm from puppet to a package,MERGED,2015-10-22 11:01:15.000000000,2015-12-11 13:37:25.000000000,2015-12-11 13:24:18.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11587}, {'_account_id': 13948}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-10-22 11:01:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/3890ea19797be78a8d33be89a25e7cc16d74320c', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 2, 'created': '2015-10-28 14:12:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/ae74003fa6d8d6283e83b5eb58d898b94dabc30e', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 3, 'created': '2015-10-28 15:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8d915d125c8e035efc394b289d5902a8e35dba2b', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 4, 'created': '2015-10-29 10:54:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e45e6515ba50a1ae13f3ad8a0b141a3e02bb8eda', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 5, 'created': '2015-10-29 12:40:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cb2bc62fcd7d55835ea3d82fdf4a08e64b47e157', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 6, 'created': '2015-10-29 13:58:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/5aa0ae743aa9e2efa4c1d7214610d770a3ee130f', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 7, 'created': '2015-10-30 08:48:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/73c68bead8d64d9d2cc6d8954d46f80b6fc92875', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 8, 'created': '2015-10-30 08:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/19fa870decdfaf81ef0ddf6bd128a4949c965aaa', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 9, 'created': '2015-10-30 09:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c2bacf4bc1d8a1daeb2c68c9c58093c1d4557cf7', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 10, 'created': '2015-10-30 09:15:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1db6e9c4be44417cfb6a1a647dbc3643ff3cbdb5', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 11, 'created': '2015-10-30 09:24:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8b0ce929c60b87a39d435307fb921ee52afe22fd', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 12, 'created': '2015-10-30 15:31:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/59a6fa1b4c42958fb40e20cbddd8d795da5792a5', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 13, 'created': '2015-10-30 16:39:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2796303563c8ffbd6d615f3fa5e09b6c44b1ea7f', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 14, 'created': '2015-11-02 09:30:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/e8ed0a0b9012d6cdd87976510f874d468fac75be', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 15, 'created': '2015-11-02 11:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/129292d61c86a9f3915a0a8a24e302257aa2e8ba', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 16, 'created': '2015-11-02 12:29:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c75b5c901f0bf5dc93ecc87fbc1c9d82eaa5d52d', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 17, 'created': '2015-11-02 14:03:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9c105433b8aeecb2c268e7413a8f787c54dade7f', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 18, 'created': '2015-11-03 12:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/836354753edc1c3026f12b81222b5d9d6824f840', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 19, 'created': '2015-11-09 12:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2d44fb983eb9fd5da70ba42df4a45844efbed973', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 20, 'created': '2015-11-09 15:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8938de5daf7735d6542782ec91dfcd1bf5d14ad4', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 21, 'created': '2015-11-17 13:37:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c865a06df320953482183653060fde5f57d73d8c', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 22, 'created': '2015-11-17 15:53:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a1112207a47cda0521ec758957d3848cdf8a38a9', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 23, 'created': '2015-11-19 08:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/dad48bba64c1ef344a2a5d6e80f28540b2ad1254', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 24, 'created': '2015-11-19 14:36:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8735fde2cb267be9d61a1f91a0ffb3664a03a386', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}, {'number': 25, 'created': '2015-11-20 15:12:14.000000000', 'files': ['debian/fuel-umm.postinst', 'tests/noop/spec/hosts/umm/umm_spec.rb', 'debian/fuel-umm.prerm', 'files/fuel-umm/umm.sh', 'files/fuel-umm/umm-br.conf', 'files/fuel-umm/umm-console.conf', 'files/fuel-umm/umm-tr.conf', 'deployment/puppet/umm/manifests/init.pp', 'files/fuel-umm/umm.conf', 'debian/fuel-umm.dirs', 'files/fuel-umm/umm-install.u1404', 'specs/fuel-library8.0.spec', 'files/fuel-umm/umm-run.conf', 'debian/rules', 'files/fuel-umm/umm_svc.rh6', 'deployment/puppet/umm/files/umm-install.rh6', 'debian/control', 'files/fuel-umm/umm_svc.u1404', 'files/fuel-umm/issue.mm', 'files/fuel-umm/umm_svc', 'files/fuel-umm/umm_vars', 'deployment/puppet/umm/manifests/common.pp', 'files/fuel-umm/umm-install.rh6', 'deployment/puppet/umm/templates/umm.conf.erb', 'debian/fuel-umm.install', 'files/fuel-umm/umm'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8d138e0e0d185270311580f685977d3aa6d42ca3', 'message': 'Move umm from puppet to a package\n\nMove umm related file from puppet to a package and change deploing process\n\nChange-Id: I466d89158fab523981ea002e83933696284a11ac\nCloses-bug:#1508274\n'}]",7,238452,8d138e0e0d185270311580f685977d3aa6d42ca3,283,8,25,14316,,,0,"Move umm from puppet to a package

Move umm related file from puppet to a package and change deploing process

Change-Id: I466d89158fab523981ea002e83933696284a11ac
Closes-bug:#1508274
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/52/238452/25 && git format-patch -1 --stdout FETCH_HEAD,"['files/umm/umm-install.rh6', 'files/umm/umm-tr.conf', 'files/umm/umm-br.conf', 'files/umm/umm_svc.u1404', 'files/umm/issue.mm', 'files/umm/umm-console.conf', 'files/umm/umm-install.u1404', 'files/umm/umm-run.conf', 'files/umm/umm.conf', 'files/umm/umm', 'files/umm/umm_svc.rh6', 'files/umm/umm_vars', 'files/umm/umm.sh', 'files/umm/umm_svc']",14,3890ea19797be78a8d33be89a25e7cc16d74320c,238452, [ -x ${0}.${UMM_R} ] && ${0}.${UMM_R}, ${0}.${UMM_R},1,2
openstack%2Fhorizon~master~If6f760027eca09fd74db9a82094632b8ee9fcc3e,openstack/horizon,master,If6f760027eca09fd74db9a82094632b8ee9fcc3e,"Disable ""Disassociate floating IP"" if instance is in failed state",ABANDONED,2015-12-11 09:55:57.000000000,2015-12-11 13:33:54.000000000,,"[{'_account_id': 3}, {'_account_id': 8040}, {'_account_id': 10442}]","[{'number': 1, 'created': '2015-12-11 09:55:57.000000000', 'files': ['openstack_dashboard/dashboards/project/instances/tables.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/74d2923c96502e1f422960bcc6a2d83f1e8a2926', 'message': 'Disable ""Disassociate floating IP"" if instance is in failed state\n\nSince it makes no sense to have this action enabled for an instance\nthat even failed to launch. Only simple disassociate IP action is\ndisabled, because non-simple version is not available from instances\ntable.\n\nChange-Id: If6f760027eca09fd74db9a82094632b8ee9fcc3e\nCloses-Bug: #1456439\n'}]",0,256311,74d2923c96502e1f422960bcc6a2d83f1e8a2926,10,3,1,8040,,,0,"Disable ""Disassociate floating IP"" if instance is in failed state

Since it makes no sense to have this action enabled for an instance
that even failed to launch. Only simple disassociate IP action is
disabled, because non-simple version is not available from instances
table.

Change-Id: If6f760027eca09fd74db9a82094632b8ee9fcc3e
Closes-Bug: #1456439
",git fetch https://review.opendev.org/openstack/horizon refs/changes/11/256311/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/instances/tables.py'],1,74d2923c96502e1f422960bcc6a2d83f1e8a2926,bug/1456439," if instance.status == ""ERROR"": return False",,2,0
openstack%2Ffuel-web~stable%2F6.1~Icd41b40b453079d8cbed427df449dd0226426f2b,openstack/fuel-web,stable/6.1,Icd41b40b453079d8cbed427df449dd0226426f2b,Pin networkx version below 1.10,ABANDONED,2015-10-19 11:01:25.000000000,2015-12-11 13:30:35.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 12200}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-10-19 11:01:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/6ffac1c8e091b429d44479569c813c46ad2d4e57', 'message': 'Pin networkx version below 1.10\n\nnetworkx is not compatible with Python 2.6 starting with version 1.10\n\nChange-Id: Icd41b40b453079d8cbed427df449dd0226426f2b\nCloses-Bug: #1480793\n(cherry picked from commit c0bd5b4ccb2cd55e076634c65ab9bc2da6ae39f5)\n'}, {'number': 2, 'created': '2015-12-11 13:18:35.000000000', 'files': ['specs/nailgun.spec'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/3f536875094acb3b1fca6106bc53a36bdcaaf1cd', 'message': 'Pin networkx version below 1.10\n\nnetworkx is not compatible with Python 2.6 starting with version 1.10\n\nChange-Id: Icd41b40b453079d8cbed427df449dd0226426f2b\nCloses-Bug: #1480793\n(cherry picked from commit c0bd5b4ccb2cd55e076634c65ab9bc2da6ae39f5)\n'}]",1,236903,3f536875094acb3b1fca6106bc53a36bdcaaf1cd,12,4,2,9977,,,0,"Pin networkx version below 1.10

networkx is not compatible with Python 2.6 starting with version 1.10

Change-Id: Icd41b40b453079d8cbed427df449dd0226426f2b
Closes-Bug: #1480793
(cherry picked from commit c0bd5b4ccb2cd55e076634c65ab9bc2da6ae39f5)
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/03/236903/2 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/requirements.txt', 'specs/nailgun.spec']",2,6ffac1c8e091b429d44479569c813c46ad2d4e57,,Requires: python-networkx-core < 1.10.0,,2,1
openstack%2Ftooz~master~I6a24c121c7e09af09cccc37d433d6cdd8a4fa315,openstack/tooz,master,I6a24c121c7e09af09cccc37d433d6cdd8a4fa315,Add comment in memcache explaining the current situation with lock release,MERGED,2015-12-10 06:23:04.000000000,2015-12-11 13:29:49.000000000,2015-12-11 13:29:47.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-10 06:23:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tooz/commit/e425c1a2d2df6300c400ce54725eece0723f4cea', 'message': 'Add comment in memcache explaining the current situation with lock release\n\nChange-Id: I6a24c121c7e09af09cccc37d433d6cdd8a4fa315\n'}, {'number': 2, 'created': '2015-12-10 21:12:34.000000000', 'files': ['tooz/drivers/memcached.py'], 'web_link': 'https://opendev.org/openstack/tooz/commit/b03a306a7d2524262600b27fa5ba803270c437ab', 'message': 'Add comment in memcache explaining the current situation with lock release\n\nChange-Id: I6a24c121c7e09af09cccc37d433d6cdd8a4fa315\n'}]",0,255690,b03a306a7d2524262600b27fa5ba803270c437ab,11,3,2,1297,,,0,"Add comment in memcache explaining the current situation with lock release

Change-Id: I6a24c121c7e09af09cccc37d433d6cdd8a4fa315
",git fetch https://review.opendev.org/openstack/tooz refs/changes/90/255690/1 && git format-patch -1 --stdout FETCH_HEAD,['tooz/drivers/memcached.py'],1,e425c1a2d2df6300c400ce54725eece0723f4cea,," # NOTE(harlowja): this has the potential to delete others locks # especially if this key expired before the delete/release call is # triggered. # # For example: # # 1. App #1 with coordinator 'A' acquires lock ""b"" # 2. App #1 heartbeats every 10 seconds, expiry for lock let's # say is 11 seconds. # 3. App #2 with coordinator also named 'A' blocks trying to get # lock ""b"" (let's say it retries attempts every 0.5 seconds) # 4. App #1 is running behind a little bit, tries to heartbeat but # key has expired (log message is written); at this point app #1 # doesn't own the lock anymore but it doesn't know that. # 5. App #2 now retries and adds the key, and now it believes it # has the lock. # 6. App #1 (still believing it has the lock) calls release, and # deletes app #2 lock, app #2 now doesn't own the lock anymore # but it doesn't know that and now app #(X + 1) can get it. # 7. App #2 calls release (repeat #6 as many times as desired) # # Sadly I don't think memcache has the primitives to actually make # this work, redis does because it has lua which can check a session # id and then do the delete and bail out if the session id is not # as expected but memcache doesn't seem to have any equivalent # capability.",,26,0
openstack%2Fcompute-hyperv~master~Idec103c42fcbe3b83237d7dafbe663fffab6cb95,openstack/compute-hyperv,master,Idec103c42fcbe3b83237d7dafbe663fffab6cb95,Adds logging for failed vmutils operations,ABANDONED,2015-10-02 16:46:32.000000000,2015-12-11 13:27:47.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 8213}]","[{'number': 1, 'created': '2015-10-02 16:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/06ff09bf653eb5458b343f793772609c5c888904', 'message': ""Adds logging for failed vmutils operations\n\nAdds logging for vmutils' add_virt_resource,\nmodify_virt_resource and remove_virt_resource, in order\nto observe the WMI objects the failures occur on.\n\nChange-Id: Idec103c42fcbe3b83237d7dafbe663fffab6cb95\n""}, {'number': 2, 'created': '2015-10-06 19:57:58.000000000', 'files': ['hyperv/nova/vmutilsv2.py', 'hyperv/nova/vmutils.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/3bce596be1d95fb58956c207ad23c313200a5222', 'message': ""Adds logging for failed vmutils operations\n\nAdds logging for vmutils' add_virt_resource,\nmodify_virt_resource and remove_virt_resource, in order\nto observe the WMI objects the failures occur on.\n\nChange-Id: Idec103c42fcbe3b83237d7dafbe663fffab6cb95\n""}]",0,230538,3bce596be1d95fb58956c207ad23c313200a5222,18,3,2,8213,,,0,"Adds logging for failed vmutils operations

Adds logging for vmutils' add_virt_resource,
modify_virt_resource and remove_virt_resource, in order
to observe the WMI objects the failures occur on.

Change-Id: Idec103c42fcbe3b83237d7dafbe663fffab6cb95
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/38/230538/2 && git format-patch -1 --stdout FETCH_HEAD,"['hyperv/nova/vmutilsv2.py', 'hyperv/nova/vmutils.py']",2,06ff09bf653eb5458b343f793772609c5c888904,final-branch,"import functoolsdef log_on_exception(function): @functools.wraps(function) def wrapper(self, wmi_object, parent_wmi_object_path): try: return function(self, wmi_object, parent_wmi_object_path) except HyperVException as ex: LOG.warning(_LW(""HyperVException encountered while running %s. "" ""Exception: %s.""), function.__name__, ex) LOG.debug(""WMI object: %s"", wmi_object) LOG.debug(""Parent WMI object path: %s"", parent_wmi_object_path) raise ex return wrapper @log_on_exception @log_on_exception @log_on_exception",,21,0
openstack%2Fsenlin-dashboard~master~Ibdd227e65173cf1fb0c912a4b8bcff65346337ec,openstack/senlin-dashboard,master,Ibdd227e65173cf1fb0c912a4b8bcff65346337ec,Use page_title attr in Cluster/Profile/Polices/Nodes IndexView,MERGED,2015-12-11 08:50:34.000000000,2015-12-11 13:24:39.000000000,2015-12-11 13:24:38.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}]","[{'number': 1, 'created': '2015-12-11 08:50:34.000000000', 'files': ['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/nodes/templates/nodes/index.html', 'senlin_dashboard/cluster/policies/views.py', 'senlin_dashboard/cluster/policies/templates/policies/index.html', 'senlin_dashboard/cluster/profiles/views.py', 'senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/profiles/tests.py', 'senlin_dashboard/cluster/profiles/templates/profiles/index.html', 'senlin_dashboard/cluster/policies/tests.py', 'senlin_dashboard/cluster/clusters/templates/clusters/index.html', 'senlin_dashboard/cluster/clusters/views.py', 'senlin_dashboard/cluster/nodes/tests.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/90bda51dda0c63d14d5cd20b654321c7cc91c370', 'message': 'Use page_title attr in Cluster/Profile/Polices/Nodes IndexView\n\nAnd delete needless html code, make html more clean and readable\n\nChange-Id: Ibdd227e65173cf1fb0c912a4b8bcff65346337ec\n'}]",0,256286,90bda51dda0c63d14d5cd20b654321c7cc91c370,7,3,1,6763,,,0,"Use page_title attr in Cluster/Profile/Polices/Nodes IndexView

And delete needless html code, make html more clean and readable

Change-Id: Ibdd227e65173cf1fb0c912a4b8bcff65346337ec
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/86/256286/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin_dashboard/cluster/clusters/tests.py', 'senlin_dashboard/cluster/nodes/templates/nodes/index.html', 'senlin_dashboard/cluster/policies/views.py', 'senlin_dashboard/cluster/policies/templates/policies/index.html', 'senlin_dashboard/cluster/profiles/views.py', 'senlin_dashboard/cluster/nodes/views.py', 'senlin_dashboard/cluster/profiles/tests.py', 'senlin_dashboard/cluster/profiles/templates/profiles/index.html', 'senlin_dashboard/cluster/policies/tests.py', 'senlin_dashboard/cluster/clusters/templates/clusters/index.html', 'senlin_dashboard/cluster/clusters/views.py', 'senlin_dashboard/cluster/nodes/tests.py']",12,90bda51dda0c63d14d5cd20b654321c7cc91c370,," self.assertContains(res, '<h1>Nodes</h1>')",,8,16
openstack%2Foslo.messaging~master~I301fdd51446bf0c0a6dd0d05b26da0556db8367d,openstack/oslo.messaging,master,I301fdd51446bf0c0a6dd0d05b26da0556db8367d,Cleanup parameter docstrings,MERGED,2015-12-11 08:04:28.000000000,2015-12-11 13:24:28.000000000,2015-12-11 13:24:27.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-11 08:04:28.000000000', 'files': ['oslo_messaging/server.py', 'oslo_messaging/_drivers/common.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/46daf858144202a072c4bf8580aeafec11d20e13', 'message': 'Cleanup parameter docstrings\n\nChange-Id: I301fdd51446bf0c0a6dd0d05b26da0556db8367d\n'}]",0,256275,46daf858144202a072c4bf8580aeafec11d20e13,13,4,1,5638,,,0,"Cleanup parameter docstrings

Change-Id: I301fdd51446bf0c0a6dd0d05b26da0556db8367d
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/75/256275/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/server.py', 'oslo_messaging/_drivers/common.py']",2,46daf858144202a072c4bf8580aeafec11d20e13,, :param method: The name of the rpc method being, :param rpc_method_name: The name of the rpc method being,1,25
openstack%2Fsenlin-dashboard~master~Idc1155db5caa62d417414169ebbc07efb3864070,openstack/senlin-dashboard,master,Idc1155db5caa62d417414169ebbc07efb3864070,Fix broken unit test aganist the latest horizon,MERGED,2015-12-11 03:04:46.000000000,2015-12-11 13:23:29.000000000,2015-12-11 13:23:28.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}]","[{'number': 1, 'created': '2015-12-11 03:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/28fe1e55b429161eeb0ab026c5293e31ea9150e5', 'message': ""[Test] Don't merge\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n""}, {'number': 2, 'created': '2015-12-11 03:48:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/b202417d404483048762350f101633547417941e', 'message': ""[Test] Don't merge\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n""}, {'number': 3, 'created': '2015-12-11 04:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/443e59c1bdfb935addffea2f78ccb2d840a9de28', 'message': ""[Test] Don't merge\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n""}, {'number': 4, 'created': '2015-12-11 04:28:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/d14d424bdbcfd8524564e944e650c7995614c18a', 'message': ""[Test] Don't merge\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n""}, {'number': 5, 'created': '2015-12-11 04:42:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/4d0a33d7fbbfd2e2a916f1791dabec1ba2897b9f', 'message': 'Fix broken unit test aganist the latest horizon\n\nNow we use our own test settings rather thans openstack_dashboard\nsettings, that makes more sense and the unit test works well.\n\nCloses-Bug: 1525062\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n'}, {'number': 6, 'created': '2015-12-11 05:37:33.000000000', 'files': ['senlin_dashboard/test/settings.py', 'senlin_dashboard/test/urls.py'], 'web_link': 'https://opendev.org/openstack/senlin-dashboard/commit/800f40f3c7d367a2671c1a6ef33621183d21b806', 'message': 'Fix broken unit test aganist the latest horizon\n\nNow we use our own test settings rather thans openstack_dashboard\nsettings, that makes more sense and the unit test works well.\n\nCloses-Bug: 1525062\n\nChange-Id: Idc1155db5caa62d417414169ebbc07efb3864070\n'}]",0,256187,800f40f3c7d367a2671c1a6ef33621183d21b806,20,4,6,6763,,,0,"Fix broken unit test aganist the latest horizon

Now we use our own test settings rather thans openstack_dashboard
settings, that makes more sense and the unit test works well.

Closes-Bug: 1525062

Change-Id: Idc1155db5caa62d417414169ebbc07efb3864070
",git fetch https://review.opendev.org/openstack/senlin-dashboard refs/changes/87/256187/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,28fe1e55b429161eeb0ab026c5293e31ea9150e5,bug/1525062,Senlin Dashboard Test,Senlin Dashboard,1,1
openstack%2Ffuel-library~master~I1a3af4b5a3160a6904514da60f44c1b96dc54d57,openstack/fuel-library,master,I1a3af4b5a3160a6904514da60f44c1b96dc54d57,IP-based Apache VirtualHosts configuration,MERGED,2015-12-09 21:38:26.000000000,2015-12-11 13:22:00.000000000,2015-12-11 13:21:22.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 14200}, {'_account_id': 14495}, {'_account_id': 14985}, {'_account_id': 16771}, {'_account_id': 18290}, {'_account_id': 19560}]","[{'number': 1, 'created': '2015-12-09 21:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/99aa358981bd1bd31f5bf6aaac39a656cd274c2c', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 2, 'created': '2015-12-09 21:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/bd6fde99df2ed1ecad8018fb0140a7ff8dc7d214', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 3, 'created': '2015-12-09 22:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8ae4940999490c5966e995261424ae13db5d7bbe', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 4, 'created': '2015-12-09 23:52:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a536fac0bc25803b42021adacc138dd4fb376f0a', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 5, 'created': '2015-12-10 05:20:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/71634bf03d3d4cd98b8fb9be707200554e4d1562', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 6, 'created': '2015-12-10 17:19:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/540aeba85248032546be3d9657a9eb3455653b94', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 7, 'created': '2015-12-10 20:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6e4b0afa671b4ab98e998c5849e3c8ad493654e3', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 8, 'created': '2015-12-10 20:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/29de69627bcfa31ddec8e611fceadcdb13edb7b3', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}, {'number': 9, 'created': '2015-12-10 21:45:47.000000000', 'files': ['tests/noop/spec/hosts/api-proxy/api-proxy_spec.rb', 'deployment/puppet/openstack/spec/classes/openstack_horizon_spec.rb', 'deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'tests/noop/spec/hosts/keystone/keystone_spec.rb', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/manifests/apache_api_proxy.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/openstack/manifests/horizon.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/c37048484366b7f276b385556029d855fa6866b5', 'message': 'IP-based Apache VirtualHosts configuration\n\nThis commit configures IP-based virtual hosts for all services managed by\nApache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)\nnow can be restricted to serve only on specified IP addresses/ports.\n\nThis commit also fixes security issue by restricting the API Proxy\nserved on port 8888 to listen only on Admin (PXE) network, because it\nused only for performing OSTF tests, initiated from Fuel node.\n\nChange-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57\nCloses-Bug: #1523418\n'}]",2,255538,c37048484366b7f276b385556029d855fa6866b5,114,13,9,14200,,,0,"IP-based Apache VirtualHosts configuration

This commit configures IP-based virtual hosts for all services managed by
Apache. These services (Horizon, Keystone, RADOS Gateway and API Proxy)
now can be restricted to serve only on specified IP addresses/ports.

This commit also fixes security issue by restricting the API Proxy
served on port 8888 to listen only on Admin (PXE) network, because it
used only for performing OSTF tests, initiated from Fuel node.

Change-Id: I1a3af4b5a3160a6904514da60f44c1b96dc54d57
Closes-Bug: #1523418
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/38/255538/8 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/openstack/spec/classes/openstack_horizon_spec.rb', 'deployment/puppet/osnailyfacter/modular/api-proxy/api-proxy.pp', 'deployment/puppet/osnailyfacter/modular/globals/globals.pp', 'deployment/puppet/osnailyfacter/modular/horizon/horizon.pp', 'deployment/puppet/osnailyfacter/modular/keystone/keystone.pp', 'deployment/puppet/osnailyfacter/templates/globals_yaml.erb', 'deployment/puppet/osnailyfacter/manifests/apache.pp', 'deployment/puppet/osnailyfacter/manifests/apache_api_proxy.pp', 'deployment/puppet/osnailyfacter/modular/apache/apache.pp', 'deployment/puppet/osnailyfacter/modular/ceph/radosgw.pp', 'deployment/puppet/openstack/manifests/horizon.pp']",11,99aa358981bd1bd31f5bf6aaac39a656cd274c2c,bug/1523418," add_listen => true, ip_based => true, # Do not setup outdated 'NameVirtualHost' option"," # Apache and listen ports class { 'osnailyfacter::apache': listen_ports => hiera_array('apache_ports', ['80', '8888']), } add_listen => false,",49,22
openstack%2Fpython-tripleoclient~master~I628228a406291fdc87a2990ab6e441ce01517ad0,openstack/python-tripleoclient,master,I628228a406291fdc87a2990ab6e441ce01517ad0,image build: add --builder-extra-args,MERGED,2015-10-01 09:00:33.000000000,2015-12-11 13:13:40.000000000,2015-12-11 13:13:38.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6928}, {'_account_id': 7065}, {'_account_id': 7505}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 12320}]","[{'number': 1, 'created': '2015-10-01 09:00:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b55f91f1ff02cc5f89987391b7c9573960fcb379', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 2, 'created': '2015-10-15 12:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/752d5e4dd2e292553881f7ad7ceaaa5aeda4e59e', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 3, 'created': '2015-10-15 12:56:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/cf7a32c8de4c413ee536e2666c5534895f175104', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 4, 'created': '2015-11-12 13:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6c7de33c0750d6560e9c5ac5da4371292df951f5', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 5, 'created': '2015-11-12 15:13:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b7d97ae2a3487e636f16f577f1237e840c886b41', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 6, 'created': '2015-12-04 16:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/524b8f699230f58cd8e8f2c4c7ffd0144ec465ca', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 7, 'created': '2015-12-04 16:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8618559cb08fe7243c13545d79cf7460d26793f3', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}, {'number': 8, 'created': '2015-12-07 16:26:23.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e4a4578ad25ffd59a0b905f79f5e95dbe9621e03', 'message': 'image build: add --builder-extra-args\n\nIntroduce a new --builder-extra-args parameter to allow pass arguments\nto the image builder, to be appended at the end of its invocation.\n\nAdjust the tests to account for the extra space (due to no\n--builder-extra-args specified in tests).\n\nCo-Authored-By: Jaume Devesa <devvesa@gmail.com>\nChange-Id: I628228a406291fdc87a2990ab6e441ce01517ad0\n'}]",2,229778,e4a4578ad25ffd59a0b905f79f5e95dbe9621e03,56,8,8,12320,,,0,"image build: add --builder-extra-args

Introduce a new --builder-extra-args parameter to allow pass arguments
to the image builder, to be appended at the end of its invocation.

Adjust the tests to account for the extra space (due to no
--builder-extra-args specified in tests).

Co-Authored-By: Jaume Devesa <devvesa@gmail.com>
Change-Id: I628228a406291fdc87a2990ab6e441ce01517ad0
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/78/229778/6 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,b55f91f1ff02cc5f89987391b7c9573960fcb379,extra-elements-2," ""pip-and-virtualenv-override 2>&1 | tee dib-overcloud-full.log"") ""pip-and-virtualenv-override 2>&1 | tee dib-deploy.log"") ""pip-and-virtualenv-override 2>&1 | tee dib-agent-ramdisk.log"") "" 2>&1 | tee dib-overcloud-full.log"") "" 2>&1 | tee dib-deploy.log"") "" 2>&1 | tee dib-agent-ramdisk.log"")"," ""pip-and-virtualenv-override 2>&1 | tee dib-overcloud-full.log"") ""pip-and-virtualenv-override 2>&1 | tee dib-deploy.log"") ""pip-and-virtualenv-override 2>&1 | tee dib-agent-ramdisk.log"") ""2>&1 | tee dib-overcloud-full.log"") ""2>&1 | tee dib-deploy.log"") ""2>&1 | tee dib-agent-ramdisk.log"")",24,8
openstack%2Fdevstack~master~I44e4490909a117930b1883dac859e0213827c834,openstack/devstack,master,I44e4490909a117930b1883dac859e0213827c834,Passing correct tenant/user vars to context log,ABANDONED,2015-05-20 18:02:30.000000000,2015-12-11 13:06:32.000000000,,"[{'_account_id': 3}, {'_account_id': 2472}, {'_account_id': 8871}, {'_account_id': 10343}, {'_account_id': 10697}, {'_account_id': 11042}]","[{'number': 1, 'created': '2015-05-20 18:02:30.000000000', 'files': ['lib/ironic'], 'web_link': 'https://opendev.org/openstack/devstack/commit/f70d89768bec9fee355d0c5c0d3a3c1882e67e1c', 'message': 'Passing correct tenant/user vars to context log\n\nCurrently the deployment of devstack + Ironic is breaking due to\nchanges to comply with oslo_context and the log formatting string\nthat expects, by default, user_name and project_name in the\ncontext. This patch aims to pass the current variables in the\ncontext of Ironic to generate a correct log formatting string.\n\nChange-Id: I44e4490909a117930b1883dac859e0213827c834\nCloses-bug: 1456428\n'}]",0,184568,f70d89768bec9fee355d0c5c0d3a3c1882e67e1c,10,6,1,10697,,,0,"Passing correct tenant/user vars to context log

Currently the deployment of devstack + Ironic is breaking due to
changes to comply with oslo_context and the log formatting string
that expects, by default, user_name and project_name in the
context. This patch aims to pass the current variables in the
context of Ironic to generate a correct log formatting string.

Change-Id: I44e4490909a117930b1883dac859e0213827c834
Closes-bug: 1456428
",git fetch https://review.opendev.org/openstack/devstack refs/changes/68/184568/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/ironic'],1,f70d89768bec9fee355d0c5c0d3a3c1882e67e1c,bug/1456428, setup_colorized_logging $IRONIC_CONF_FILE DEFAULT tenant user, setup_colorized_logging $IRONIC_CONF_FILE DEFAULT,1,1
openstack%2Fheat~master~I4bdaa3391863cd18a451da4eee0cb9314c0057c5,openstack/heat,master,I4bdaa3391863cd18a451da4eee0cb9314c0057c5,Make sure update successful if there is encrypt param,MERGED,2015-12-03 04:05:50.000000000,2015-12-11 13:05:32.000000000,2015-12-11 13:05:30.000000000,"[{'_account_id': 3}, {'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 6577}, {'_account_id': 7404}, {'_account_id': 8833}, {'_account_id': 10487}, {'_account_id': 12404}]","[{'number': 1, 'created': '2015-12-03 04:05:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/9ef20fb29b3738aeb8f026d38a0b1c5d2518ead2', 'message': ""Make sure update successful if there is encrypt param\n\nDon't append the param in env.encrypted_param_names again\nwhen encrypt hidden paramters, otherwise an error will raise\nwhen get template from db-object before decrypting.\n\nCloses-Bug: #1521925\nChange-Id: I4bdaa3391863cd18a451da4eee0cb9314c0057c5\n""}, {'number': 2, 'created': '2015-12-04 09:13:54.000000000', 'files': ['heat/objects/raw_template.py', 'heat/tests/test_stack.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/2fe6deee9b2dd0d94d860b1a5fad443d865d1327', 'message': ""Make sure update successful if there is encrypt param\n\nDon't append the param in env.encrypted_param_names again\nwhen encrypt hidden paramters, otherwise an error will raise\nwhen get template from db-object before decrypting.\n\nCloses-Bug: #1521925\nChange-Id: I4bdaa3391863cd18a451da4eee0cb9314c0057c5\n""}]",0,252736,2fe6deee9b2dd0d94d860b1a5fad443d865d1327,15,8,2,8289,,,0,"Make sure update successful if there is encrypt param

Don't append the param in env.encrypted_param_names again
when encrypt hidden paramters, otherwise an error will raise
when get template from db-object before decrypting.

Closes-Bug: #1521925
Change-Id: I4bdaa3391863cd18a451da4eee0cb9314c0057c5
",git fetch https://review.opendev.org/openstack/heat refs/changes/36/252736/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/objects/raw_template.py', 'heat/tests/test_stack.py']",2,9ef20fb29b3738aeb8f026d38a0b1c5d2518ead2,bug/1521925," # test update the param2 loaded_stack.state_set(self.stack.CREATE, self.stack.COMPLETE, 'for_update') env2 = environment.Environment({'param1': 'foo', 'param2': 'new_bar'}) new_stack = stack.Stack(self.ctx, 'test_update', template.Template(tmpl, env=env2)) loaded_stack.update(new_stack) self.assertEqual((loaded_stack.UPDATE, loaded_stack.COMPLETE), loaded_stack.state) db_tpl = db_api.raw_template_get(self.ctx, loaded_stack.t.id) db_params = db_tpl.environment['parameters'] self.assertEqual('foo', db_params['param1']) self.assertEqual('cryptography_decrypt_v1', db_params['param2'][0]) self.assertIsNotNone(db_params['param2'][1]) loaded_stack1 = stack.Stack.load(self.ctx, stack_id=self.stack.id) params = loaded_stack1.t.env.params self.assertEqual('foo', params.get('param1')) self.assertEqual('new_bar', params.get('param2')) ",,23,1
openstack%2Foslo.middleware~master~I04739bc3987786b4bc1fefc70fabaa69b3de52b4,openstack/oslo.middleware,master,I04739bc3987786b4bc1fefc70fabaa69b3de52b4,Re-Add oslo.middleware namespace for backward compat,MERGED,2015-12-10 16:00:17.000000000,2015-12-11 13:03:04.000000000,2015-12-11 13:03:04.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 5638}, {'_account_id': 6873}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-10 16:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/2923b33c820eee8175929e5bef9b1a284e75119a', 'message': ""Re-Add oslo.middleware namespace for backward compat\n\nShort Story:\nIf we don't do this then we have to drop,\nassert:support-upgrade from nova (Really Really Bad!)\n\nLonger Story:\nWe need to support kilo paste-ini until liberty-eol per policies\nalready in place. To do that an alternative would have been\nto cap global-requirements, but that got ruled out, please\nsee work and reasons here:\nI5731b0278e266699fe716733b6dd4f7238a35586\n\nThere's also another new spec openstack-specs that is gathering\na lot of positive votes regarding backward compat:\nI72e4e9cfa0539f6b326a0296c065fa3cb754f8ae\n\nNote that this is not a straight revert of:\nI1479f37f500a358cdf7ad416f0257288b65c9245\n\nAs i just want to drop the tests and keep the files to a\nminimum. The grenade job is enough to test the older\nscenario (which was failing) which we need to support.\n\nChange-Id: I04739bc3987786b4bc1fefc70fabaa69b3de52b4\nCloses-Bug: 1524404\n""}, {'number': 2, 'created': '2015-12-10 16:53:07.000000000', 'files': ['oslo/__init__.py', 'setup.cfg', 'oslo/middleware/__init__.py'], 'web_link': 'https://opendev.org/openstack/oslo.middleware/commit/ce6ca042806dc09b33d30c56dac88e01d2ea24ec', 'message': ""Re-Add oslo.middleware namespace for backward compat\n\nShort Story:\nIf we don't do this then we have to drop,\nassert:support-upgrade from nova (Really Really Bad!)\n\nLonger Story:\nWe need to support kilo paste-ini until liberty-eol per policies\nalready in place. To do that an alternative would have been\nto cap global-requirements, but that got ruled out, please\nsee work and reasons here:\nI5731b0278e266699fe716733b6dd4f7238a35586\n\nThere's also another new spec openstack-specs that is gathering\na lot of positive votes regarding backward compat:\nI72e4e9cfa0539f6b326a0296c065fa3cb754f8ae\n\nNote that this is not a straight revert of:\nI1479f37f500a358cdf7ad416f0257288b65c9245\n\nAs i just want to drop the tests and keep the files to a\nminimum. The grenade job is enough to test the older\nscenario (which was failing) which we need to support.\n\nChange-Id: I04739bc3987786b4bc1fefc70fabaa69b3de52b4\nCloses-Bug: 1524404\n""}]",2,255952,ce6ca042806dc09b33d30c56dac88e01d2ea24ec,17,5,2,5638,,,0,"Re-Add oslo.middleware namespace for backward compat

Short Story:
If we don't do this then we have to drop,
assert:support-upgrade from nova (Really Really Bad!)

Longer Story:
We need to support kilo paste-ini until liberty-eol per policies
already in place. To do that an alternative would have been
to cap global-requirements, but that got ruled out, please
see work and reasons here:
I5731b0278e266699fe716733b6dd4f7238a35586

There's also another new spec openstack-specs that is gathering
a lot of positive votes regarding backward compat:
I72e4e9cfa0539f6b326a0296c065fa3cb754f8ae

Note that this is not a straight revert of:
I1479f37f500a358cdf7ad416f0257288b65c9245

As i just want to drop the tests and keep the files to a
minimum. The grenade job is enough to test the older
scenario (which was failing) which we need to support.

Change-Id: I04739bc3987786b4bc1fefc70fabaa69b3de52b4
Closes-Bug: 1524404
",git fetch https://review.opendev.org/openstack/oslo.middleware refs/changes/52/255952/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo/__init__.py', 'setup.cfg', 'oslo/middleware/__init__.py']",3,2923b33c820eee8175929e5bef9b1a284e75119a,bug/1524404,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import sys import warnings def deprecated(): new_name = __name__.replace('.', '_') warnings.warn( ('The oslo namespace package is deprecated. Please use %s instead.' % new_name), DeprecationWarning, stacklevel=3, ) deprecated() from oslo_middleware import base from oslo_middleware import catch_errors from oslo_middleware import correlation_id from oslo_middleware import debug from oslo_middleware import request_id from oslo_middleware import sizelimit sys.modules['oslo.middleware.base'] = base sys.modules['oslo.middleware.catch_errors'] = catch_errors sys.modules['oslo.middleware.correlation_id'] = correlation_id sys.modules['oslo.middleware.debug'] = debug sys.modules['oslo.middleware.request_id'] = request_id sys.modules['oslo.middleware.sizelimit'] = sizelimit",,57,0
openstack%2Fheat~master~I1cb2d88ce26c307c040f3064233e410eccfd3811,openstack/heat,master,I1cb2d88ce26c307c040f3064233e410eccfd3811,Fix _show_resource in Designate::Record,MERGED,2015-12-09 12:46:31.000000000,2015-12-11 12:55:09.000000000,2015-12-11 12:55:06.000000000,"[{'_account_id': 3}, {'_account_id': 6577}, {'_account_id': 10487}, {'_account_id': 12404}, {'_account_id': 13009}, {'_account_id': 14101}]","[{'number': 1, 'created': '2015-12-09 12:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/b52b840243d21e4ab7887a41b5894f579564ae20', 'message': 'Fix _show_resource in Designate::Record\n\nget method in records requires domain_id as\nfirst argument, but in _show_resource there is\nonly self.resource_id, so this patch adds domain_id.\n\nChange-Id: I1cb2d88ce26c307c040f3064233e410eccfd3811\nCloses-bug: #1524312\n'}, {'number': 2, 'created': '2015-12-10 08:04:35.000000000', 'files': ['heat/engine/resources/openstack/designate/record.py', 'heat/engine/clients/os/designate.py', 'heat/tests/clients/test_designate_client.py', 'heat/tests/openstack/designate/test_record.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/f5e083e0721717c888ddce6237ce934938c4199c', 'message': 'Fix _show_resource in Designate::Record\n\nget method in records requires domain_id as\nfirst argument, but in _show_resource there is\nonly self.resource_id, so this patch adds domain_id.\n\nChange-Id: I1cb2d88ce26c307c040f3064233e410eccfd3811\nCloses-bug: #1524312\n'}]",2,255242,f5e083e0721717c888ddce6237ce934938c4199c,21,6,2,13009,,,0,"Fix _show_resource in Designate::Record

get method in records requires domain_id as
first argument, but in _show_resource there is
only self.resource_id, so this patch adds domain_id.

Change-Id: I1cb2d88ce26c307c040f3064233e410eccfd3811
Closes-bug: #1524312
",git fetch https://review.opendev.org/openstack/heat refs/changes/42/255242/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/openstack/designate/record.py', 'heat/tests/openstack/designate/test_record.py']",2,b52b840243d21e4ab7887a41b5894f579564ae20,fix-record-show, self.test_client_plugin.get_domain_id.assert_called_once_with( '1234567'),,6,1
openstack%2Fneutron-vpnaas~master~Ia502e27cd60012ffae6cb26e6a05c9cbd99ba2c8,openstack/neutron-vpnaas,master,Ia502e27cd60012ffae6cb26e6a05c9cbd99ba2c8,Updated from global requirements,MERGED,2015-12-09 21:58:29.000000000,2015-12-11 12:53:01.000000000,2015-12-11 12:53:00.000000000,"[{'_account_id': 3}, {'_account_id': 6659}, {'_account_id': 10692}, {'_account_id': 12403}, {'_account_id': 14605}, {'_account_id': 18573}]","[{'number': 1, 'created': '2015-12-09 21:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/f2c9639f567d8c5bef612f64b0d91e6dd2f58f69', 'message': 'Updated from global requirements\n\nChange-Id: Ia502e27cd60012ffae6cb26e6a05c9cbd99ba2c8\n'}, {'number': 2, 'created': '2015-12-11 10:48:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/dd99231bd26a9f27ccf0063398b49998c75a9e46', 'message': 'Updated from global requirements\n\nChange-Id: Ia502e27cd60012ffae6cb26e6a05c9cbd99ba2c8\n'}]",0,255558,dd99231bd26a9f27ccf0063398b49998c75a9e46,13,6,2,11131,,,0,"Updated from global requirements

Change-Id: Ia502e27cd60012ffae6cb26e6a05c9cbd99ba2c8
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/58/255558/2 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,f2c9639f567d8c5bef612f64b0d91e6dd2f58f69,openstack/requirements,"oslo.messaging!=2.8.0,!=3.1.0,>2.6.1 # Apache-2.0","oslo.messaging!=2.8.0,>2.6.1 # Apache-2.0",1,1
openstack%2Ffuel-devops~master~I936b9550256c2469e97feb5c58e7fd35a8df84f9,openstack/fuel-devops,master,I936b9550256c2469e97feb5c58e7fd35a8df84f9,Fix time synchronization for nodes with systemd,MERGED,2015-12-11 10:56:13.000000000,2015-12-11 12:37:55.000000000,2015-12-11 12:35:25.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 9439}, {'_account_id': 10136}, {'_account_id': 11081}, {'_account_id': 12867}, {'_account_id': 14057}, {'_account_id': 14708}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16106}, {'_account_id': 16414}, {'_account_id': 19119}, {'_account_id': 19120}]","[{'number': 1, 'created': '2015-12-11 10:56:13.000000000', 'files': ['devops/helpers/ntp.py'], 'web_link': 'https://opendev.org/openstack/fuel-devops/commit/9675c34fddd507d84f232e23aa86b7b526c8ce5d', 'message': 'Fix time synchronization for nodes with systemd\n\nChange-Id: I936b9550256c2469e97feb5c58e7fd35a8df84f9\nCloses-Bug:1523523\n'}]",0,256341,9675c34fddd507d84f232e23aa86b7b526c8ce5d,13,16,1,11969,,,0,"Fix time synchronization for nodes with systemd

Change-Id: I936b9550256c2469e97feb5c58e7fd35a8df84f9
Closes-Bug:1523523
",git fetch https://review.opendev.org/openstack/fuel-devops refs/changes/41/256341/1 && git format-patch -1 --stdout FETCH_HEAD,['devops/helpers/ntp.py'],1,9675c34fddd507d84f232e23aa86b7b526c8ce5d,bug/1523523," pcs_cmd = ""ps -C pacemakerd && crm_resource --resource p_ntp --locate"" systemd_cmd = ""systemctl list-unit-files| grep ntpd"" if remote.execute(pcs_cmd)['exit_code'] == 0: elif remote.execute(systemd_cmd)['exit_code'] == 0: cls = NtpSystemd() cls.is_pacemaker = False # Find upstart / sysv-init executable script cmd = ""find /etc/init.d/ -regex '/etc/init.d/ntp.?'"" cls.service = remote.execute(cmd)['stdout'][0].strip() class NtpSystemd(Ntp): """"""NtpSystemd."""""" # TODO(ddmitriev) documentation def start(self): self.is_connected = False self.remote.execute('systemctl start ntpd') def stop(self): self.is_connected = False self.remote.execute('systemctl stop ntpd') def get_peers(self): return self.remote.execute('ntpq -pn 127.0.0.1')['stdout']"," cmd = ""ps -C pacemakerd && crm_resource --resource p_ntp --locate"" if remote.execute(cmd)['exit_code'] == 0: cmd = ""find /etc/init.d/ -regex '/etc/init.d/ntp.?'"" cls.service = remote.execute(cmd)['stdout'][0].strip() ",24,5
openstack%2Ffuel-library~master~I57e845f4834d51e1a8437a37c576c6dde7a82d8c,openstack/fuel-library,master,I57e845f4834d51e1a8437a37c576c6dde7a82d8c,Added cross-dependencies to pre-deployment tasks,MERGED,2015-12-07 13:22:43.000000000,2015-12-11 12:32:54.000000000,2015-12-11 12:31:53.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 14985}, {'_account_id': 18205}]","[{'number': 1, 'created': '2015-12-07 13:22:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/cfa3ef42e727472d5e325067157db8ee8743eb3b', 'message': 'Added cross-dependencies to pre-deployment tasks\nWe have a set of tasks which have task from master node\nin ""requires"" list. Actually these dependencies are\ncross-node ones but it works in current granular-deploy\nimplementation only because all pre- and post- deployment\ntasks are executed one-by-one for whole cluster. If we try\nto use task-based deployment we need to add these\ndependencies as cross-node ones.\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: I57e845f4834d51e1a8437a37c576c6dde7a82d8c\n'}, {'number': 2, 'created': '2015-12-07 13:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/0592b8b2031f75c2825ab7e3ea8021fbce2349fd', 'message': 'Added cross-dependencies to pre-deployment tasks\n\nWe have a set of tasks which have task from master node\nin ""requires"" list. Actually these dependencies are\ncross-node ones but it works in current granular-deploy\nimplementation only because all pre- and post- deployment\ntasks are executed one-by-one for whole cluster. If we try\nto use task-based deployment we need to add these\ndependencies as cross-node ones.\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: I57e845f4834d51e1a8437a37c576c6dde7a82d8c\n'}, {'number': 3, 'created': '2015-12-10 20:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/9b3ac49c49a0e33ccb830da4bef5e28df6dd0d36', 'message': 'Added cross-dependencies to pre-deployment tasks\n\nWe have a set of tasks which have task from master node\nin ""requires"" list. Actually these dependencies are\ncross-node ones but it works in current granular-deploy\nimplementation only because all pre- and post- deployment\ntasks are executed one-by-one for whole cluster. If we try\nto use task-based deployment we need to add these\ndependencies as cross-node ones.\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: I57e845f4834d51e1a8437a37c576c6dde7a82d8c\n'}, {'number': 4, 'created': '2015-12-10 23:54:59.000000000', 'files': ['deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/d2559056fabd88e5bc245a1903e502f4a9c1d3dd', 'message': 'Added cross-dependencies to pre-deployment tasks\n\nWe have a set of tasks which have task from master node\nin ""requires"" list. Actually these dependencies are\ncross-node ones but it works in current granular-deploy\nimplementation only because all pre- and post- deployment\ntasks are executed one-by-one for whole cluster. When we try\nto use task-based deployment we need to add these\ndependencies as cross-node ones.\n\nImplements blueprint: task-based-deployment-astute\n\nChange-Id: I57e845f4834d51e1a8437a37c576c6dde7a82d8c\n'}]",0,254179,d2559056fabd88e5bc245a1903e502f4a9c1d3dd,53,12,4,16518,,,0,"Added cross-dependencies to pre-deployment tasks

We have a set of tasks which have task from master node
in ""requires"" list. Actually these dependencies are
cross-node ones but it works in current granular-deploy
implementation only because all pre- and post- deployment
tasks are executed one-by-one for whole cluster. When we try
to use task-based deployment we need to add these
dependencies as cross-node ones.

Implements blueprint: task-based-deployment-astute

Change-Id: I57e845f4834d51e1a8437a37c576c6dde7a82d8c
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/79/254179/2 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/osnailyfacter/modular/ceph/tasks.yaml', 'deployment/puppet/osnailyfacter/modular/astute/tasks.yaml']",2,cfa3ef42e727472d5e325067157db8ee8743eb3b,bp/task-based-deployment-astute, cross-depends: - name: generate_keys role: master cross-depends: - name: generate_haproxy_keys role: master,,9,0
openstack%2Fopenstack-manuals~master~Id953a6eba3729aa16b4da8f7b81a40777c0d183a,openstack/openstack-manuals,master,Id953a6eba3729aa16b4da8f7b81a40777c0d183a,Add documentation for HNAS Shared File Systems Driver,MERGED,2015-11-13 17:54:57.000000000,2015-12-11 12:32:03.000000000,2015-12-11 12:32:02.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6547}, {'_account_id': 6635}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 14863}, {'_account_id': 14865}, {'_account_id': 14908}, {'_account_id': 16237}, {'_account_id': 17832}]","[{'number': 1, 'created': '2015-11-13 17:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5d0f491f04726d3231f73231cc312eafae56c302', 'message': 'Add documentation for HNAS Manila Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 2, 'created': '2015-11-13 17:56:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/863417816887eb555f47f69c7ed871751bd330aa', 'message': 'Add documentation for HNAS Manila Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 3, 'created': '2015-11-16 15:39:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/847916279d8ab0e2c6b9a71e7fd96d6b6ba2dcde', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 4, 'created': '2015-11-17 14:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/35de924d08645db4388b3c326558dcfcd616c1f1', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 5, 'created': '2015-11-18 11:57:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/633575b8b27b529081567f9126aba12beef2982e', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 6, 'created': '2015-11-18 12:01:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6e2ce9514a1bb05f6a73f00dfd6bff5a09e1478b', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 7, 'created': '2015-11-18 15:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6c9f826b01a7edbb06ccdb794db31fdad638c606', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 8, 'created': '2015-11-19 11:49:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5449b3916488751ad2cb25fa44fe4915ebe3d9de', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 9, 'created': '2015-11-19 12:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b12219a7031ecc249f4786b64c0b9f2e3ff4c6a1', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 10, 'created': '2015-11-23 12:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d3912dc0714b2653bd110cb49e1f04f61c9f8f55', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 11, 'created': '2015-11-25 11:01:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/5db387cad54656764da867608c00ab82ad79f89a', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 12, 'created': '2015-11-27 13:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/393072ef1aa53c2b09644db5094db7fdea8c28e5', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 13, 'created': '2015-11-27 17:50:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b81900ec5c8839b4635c841fcac78ec45d4b4706', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 14, 'created': '2015-12-07 10:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/14f89ec78f84d18262f319164b5eba5cd94cc914', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 15, 'created': '2015-12-07 15:11:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d409e3410e9069792aaeefa9d72565c2360bab11', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 16, 'created': '2015-12-07 16:02:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/0f742aae58ca1aa3e6ce57d4a51d4196650a58e6', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 17, 'created': '2015-12-08 12:43:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/cca1271ea71f633400318bca206a0d767cda7a57', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 18, 'created': '2015-12-08 15:35:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/520973fedf3e56f14bb2794fb415c91c46273fba', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 19, 'created': '2015-12-09 11:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/55d5fb8c854d2bf2166b2cfa1ec7bfdd9bc785f1', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 20, 'created': '2015-12-09 12:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8bcc0a6e6f40c490a913314e845793636108aac7', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 21, 'created': '2015-12-09 15:21:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/7766d19d95f45e4dd766c2f6e4ba436f66b699c8', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 22, 'created': '2015-12-10 11:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ab2e3da49285da32bed30338d2edb47e8598afb0', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 23, 'created': '2015-12-10 12:19:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/304d64b9576c3de1dd994c4b0c316762e8fe5ce2', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}, {'number': 24, 'created': '2015-12-11 10:45:12.000000000', 'files': ['doc/config-ref-rst/source/shared-file-systems/misc.rst', 'doc/config-ref-rst/source/shared-file-systems/drivers/hitachi-hnas-driver.rst', 'doc/config-ref-rst/source/shared-file-systems/drivers.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b48d551c9471a017a5f5238f529089cd5041dd9f', 'message': 'Add documentation for HNAS Shared File Systems Driver\n\nAdd the documentation with the following information:\n- Storage Requirements\n- Supported Operations\n- Driver Configuration\n- Parameters Configuration\n- Network Configuration\n- Additional Notes\n\nChange-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a\n'}]",196,245271,b48d551c9471a017a5f5238f529089cd5041dd9f,108,12,24,14908,,,0,"Add documentation for HNAS Shared File Systems Driver

Add the documentation with the following information:
- Storage Requirements
- Supported Operations
- Driver Configuration
- Parameters Configuration
- Network Configuration
- Additional Notes

Change-Id: Id953a6eba3729aa16b4da8f7b81a40777c0d183a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/71/245271/16 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-reference/shared-file-systems/section_share-drivers.xml'],1,5d0f491f04726d3231f73231cc312eafae56c302,manila_doc_rst," <xi:include href=""drivers/hitachi-hnas-driver.xml""/>",,1,0
openstack%2Foslo.messaging~stable%2Fkilo~Id98d4054ecbc787e0d44884a9e4c48e3fae803b2,openstack/oslo.messaging,stable/kilo,Id98d4054ecbc787e0d44884a9e4c48e3fae803b2,Fix reconnection when heartbeat is missed,MERGED,2015-12-04 14:13:03.000000000,2015-12-11 12:26:15.000000000,2015-12-11 12:26:14.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-12-04 14:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/52fef407aa3f844bae598fc0fb10634f1c002477', 'message': ""Fix reconnection when heartbeat is missed\n\nWhen a heartbeat is missing we call ensure_connection()\nthat runs a dummy method to trigger the reconnection\ncode in kombu. But also the code is triggered only if the\nchannel is None.\n\nIn case of the heartbeat threads we didn't reset the channel\nbefore reconnecting, so the dummy method doesn't do anything.\n\nThis change sets the channel to None to ensure the connection\nis reestablished before the dummy method is run.\n\nAlso it replaces the dummy method by checking the kombu connection\nobject. So we are sure the connection is reestablished.\n\nCloses-bug: #1493890\n(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)\n\nChange-Id: Id98d4054ecbc787e0d44884a9e4c48e3fae803b2\n""}, {'number': 2, 'created': '2015-12-09 08:08:19.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/47c6c8ebbf92c8794ebbeaca76e3728e4a748f69', 'message': ""Fix reconnection when heartbeat is missed\n\nWhen a heartbeat is missing we call ensure_connection()\nthat runs a dummy method to trigger the reconnection\ncode in kombu. But also the code is triggered only if the\nchannel is None.\n\nIn case of the heartbeat threads we didn't reset the channel\nbefore reconnecting, so the dummy method doesn't do anything.\n\nThis change sets the channel to None to ensure the connection\nis reestablished before the dummy method is run.\n\nAlso it replaces the dummy method by checking the kombu connection\nobject. So we are sure the connection is reestablished.\n\nCloses-bug: #1493890\n(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)\n\nChange-Id: Id98d4054ecbc787e0d44884a9e4c48e3fae803b2\n""}]",0,253511,47c6c8ebbf92c8794ebbeaca76e3728e4a748f69,23,4,2,2813,,,0,"Fix reconnection when heartbeat is missed

When a heartbeat is missing we call ensure_connection()
that runs a dummy method to trigger the reconnection
code in kombu. But also the code is triggered only if the
channel is None.

In case of the heartbeat threads we didn't reset the channel
before reconnecting, so the dummy method doesn't do anything.

This change sets the channel to None to ensure the connection
is reestablished before the dummy method is run.

Also it replaces the dummy method by checking the kombu connection
object. So we are sure the connection is reestablished.

Closes-bug: #1493890
(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)

Change-Id: Id98d4054ecbc787e0d44884a9e4c48e3fae803b2
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/11/253511/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,52fef407aa3f844bae598fc0fb10634f1c002477,bug/1493890, # NOTE(sileht): we reset the channel and ensure # the kombu underlying connection works self._set_current_channel(None) self.ensure(method=lambda: self.connection.connection), self.ensure(method=lambda: True) self._set_current_channel(None),6,2
openstack%2Fopenstacksdk~master~Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d,openstack/openstacksdk,master,Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d,block_store and cluster: replace 'value' arguments,MERGED,2015-12-10 19:28:15.000000000,2015-12-11 12:24:51.000000000,2015-12-11 12:24:50.000000000,"[{'_account_id': 3}, {'_account_id': 1112}, {'_account_id': 8246}, {'_account_id': 8257}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-10 19:28:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/fb17b137c38cce2fbed8efa3868d9cdc6d7a5cb1', 'message': 'Replace generic value arguments with proper names\n\nThrough the process of building up small proxies and then copy and\npasting the appropriate methods around to complete them, we\'ve passed on\nthe idea of `value` as an argument to proxy methods that can take an ID\nor an actual resource value. That ends up not being all that helpful and\nrequires a further look to see what ""value"" actually means. It would be\nbetter if the argument names were more clear themselves, and the\ndocstrings include further details as necessary.\n\nChange-Id: Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d\n'}, {'number': 2, 'created': '2015-12-10 21:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6f7ce27d2b20115be1e7d800b82b97422ee0107c', 'message': ""block_store and cluster: replace 'value' arguments\n\nReplace 'value' arguments in proxy methods with more useful names.\n\nChange-Id: Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d\n""}, {'number': 3, 'created': '2015-12-11 04:17:48.000000000', 'files': ['openstack/cluster/v1/_proxy.py', 'openstack/block_store/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7480a69a7166021c40fa9efae2cc38551860de5e', 'message': ""block_store and cluster: replace 'value' arguments\n\nReplace 'value' arguments in proxy methods with more useful names.\n\nChange-Id: Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d\n""}]",0,256065,7480a69a7166021c40fa9efae2cc38551860de5e,19,5,3,8257,,,0,"block_store and cluster: replace 'value' arguments

Replace 'value' arguments in proxy methods with more useful names.

Change-Id: Ied0b28c40568fb962f7f4f67e10dd1d94b96aa6d
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/65/256065/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/cluster/v1/_proxy.py', 'openstack/block_store/v2/_proxy.py']",2,fb17b137c38cce2fbed8efa3868d9cdc6d7a5cb1,value_renaming,"from openstack.block_store.v2 import snapshot as _snapshot from openstack.block_store.v2 import type as _type from openstack.block_store.v2 import volume as _volume def get_snapshot(self, snapshot): :param snapshot: The value can be the ID of a snapshot or a :class:`~openstack.volume.v2.snapshot.Snapshot` instance. return self._get(_snapshot.Snapshot, snapshot) return self._create(_snapshot.Snapshot, **attrs) def delete_snapshot(self, snapshot, ignore_missing=True): :param snapshot: The value can be either the ID of a snapshot or a :class:`~openstack.volume.v2.snapshot.Snapshot` instance. self._delete(_snapshot.Snapshot, snapshot, ignore_missing=ignore_missing) def get_type(self, type): :param type: The value can be the ID of a type or a :class:`~openstack.volume.v2.type.Type` instance. return self._get(_type.Type, type) return self._create(_type.Type, **attrs) def delete_type(self, type, ignore_missing=True): :param type: The value can be either the ID of a type or a :class:`~openstack.volume.v2.type.Type` instance. self._delete(_type.Type, type, ignore_missing=ignore_missing) def get_volume(self, volume): :param volume: The value can be the ID of a volume or a :class:`~openstack.volume.v2.volume.Volume` instance. return self._get(_volume.Volume, volume) return self._create(_volume.Volume, **attrs) def delete_volume(self, volume, ignore_missing=True): :param volume: The value can be either the ID of a volume or a :class:`~openstack.volume.v2.volume.Volume` instance. self._delete(_volume.Volume, volume, ignore_missing=ignore_missing)","from openstack.block_store.v2 import snapshot from openstack.block_store.v2 import type from openstack.block_store.v2 import volume def get_snapshot(self, value): :param value: The value can be the ID of a snapshot or a :class:`~openstack.volume.v2.snapshot.Snapshot` instance. return self._get(snapshot.Snapshot, value) return self._create(snapshot.Snapshot, **attrs) def delete_snapshot(self, value, ignore_missing=True): :param value: The value can be either the ID of a snapshot or a :class:`~openstack.volume.v2.snapshot.Snapshot` instance. self._delete(snapshot.Snapshot, value, ignore_missing=ignore_missing) def get_type(self, value): :param value: The value can be the ID of a type or a :class:`~openstack.volume.v2.type.Type` instance. return self._get(type.Type, value) return self._create(type.Type, **attrs) def delete_type(self, value, ignore_missing=True): :param value: The value can be either the ID of a type or a :class:`~openstack.volume.v2.type.Type` instance. self._delete(type.Type, value, ignore_missing=ignore_missing) def get_volume(self, value): :param value: The value can be the ID of a volume or a :class:`~openstack.volume.v2.volume.Volume` instance. return self._get(volume.Volume, value) return self._create(volume.Volume, **attrs) def delete_volume(self, value, ignore_missing=True): :param value: The value can be either the ID of a volume or a :class:`~openstack.volume.v2.volume.Volume` instance. self._delete(volume.Volume, value, ignore_missing=ignore_missing)",94,90
openstack%2Ffuel-octane~stable%2F7.0~I5be715f4eab445f3cf823526a98a23e7a1749f2a,openstack/fuel-octane,stable/7.0,I5be715f4eab445f3cf823526a98a23e7a1749f2a,Pass FQDN to host_evacuate.sh command,MERGED,2015-12-11 10:55:48.000000000,2015-12-11 12:24:05.000000000,2015-12-11 12:24:04.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}]","[{'number': 1, 'created': '2015-12-11 10:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/5a918a0ad2f6c19ac59ab2f21ebc73d9b917fb7f', 'message': ""Pass FQDN to host_evacuate.sh command\n\nFQDN is required for nova to identify the host since version 6.1.\n\nPass FQDN value from node's data hash to command host_evacuate.sh\nif version of the original environment is 6.1 or higher. Pass\nthe short name (node-N) of the node otherwise.\n\nCloses-bug: 1523469\nChange-Id: I5be715f4eab445f3cf823526a98a23e7a1749f2a\n""}, {'number': 2, 'created': '2015-12-11 11:25:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/7f2bb0fc99f3008eddcb13a453e7b63631b7a41e', 'message': ""Pass FQDN to host_evacuate.sh command\n\nFQDN is required for nova to identify the host since version 6.1.\n\nPass FQDN value from node's data hash to command host_evacuate.sh\nif version of the original environment is 6.1 or higher. Pass\nthe short name (node-N) of the node otherwise.\n\nCloses-bug: 1523469\nChange-Id: I5be715f4eab445f3cf823526a98a23e7a1749f2a\nCherry-picked from: 8c615af7ac8c38fe2d11c74f8cda89f079d0bc3f""}, {'number': 3, 'created': '2015-12-11 11:28:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/29dfbde0f40d3b2cf9aa99da98218fdd254abb4f', 'message': ""Pass FQDN to host_evacuate.sh command\n\nFQDN is required for nova to identify the host since version 6.1.\n\nPass FQDN value from node's data hash to command host_evacuate.sh\nif version of the original environment is 6.1 or higher. Pass\nthe short name (node-N) of the node otherwise.\n\nCloses-bug: 1523469\nChange-Id: I5be715f4eab445f3cf823526a98a23e7a1749f2a\n(cherry picked from commit 8c615af7ac8c38fe2d11c74f8cda89f079d0bc3f)""}, {'number': 4, 'created': '2015-12-11 12:12:20.000000000', 'files': ['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/handlers/upgrade/compute.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/10bc5e84ebcb00d04ed98a1fcbf135c4ce712e07', 'message': ""Pass FQDN to host_evacuate.sh command\n\nFQDN is required for nova to identify the host since version 6.1.\n\nPass FQDN value from node's data hash to command host_evacuate.sh\nif version of the original environment is 6.1 or higher. Pass\nthe short name (node-N) of the node otherwise.\n\nCloses-bug: 1523469\nChange-Id: I5be715f4eab445f3cf823526a98a23e7a1749f2a\n(cherry picked from commit 8c615af7ac8c38fe2d11c74f8cda89f079d0bc3f)""}]",0,256340,10bc5e84ebcb00d04ed98a1fcbf135c4ce712e07,16,3,4,6677,,,0,"Pass FQDN to host_evacuate.sh command

FQDN is required for nova to identify the host since version 6.1.

Pass FQDN value from node's data hash to command host_evacuate.sh
if version of the original environment is 6.1 or higher. Pass
the short name (node-N) of the node otherwise.

Closes-bug: 1523469
Change-Id: I5be715f4eab445f3cf823526a98a23e7a1749f2a
(cherry picked from commit 8c615af7ac8c38fe2d11c74f8cda89f079d0bc3f)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/40/256340/4 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/handlers/upgrade/compute.py']",3,5a918a0ad2f6c19ac59ab2f21ebc73d9b917fb7f,bug/1523469," [remote_path, node_util.get_nova_node_handle(self.node)],"," [remote_path, 'node-{0}'.format(self.node.data['id'])],",38,6
openstack%2Fsenlin~master~I061f89d4bfbda262f8ff2eaa85a4d77a075bb221,openstack/senlin,master,I061f89d4bfbda262f8ff2eaa85a4d77a075bb221,Remove oslosphinx,ABANDONED,2015-12-11 11:22:23.000000000,2015-12-11 12:17:18.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-12-11 11:22:23.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/senlin/commit/69afcda3ffd9e794619fccc707d261041a7ccf1a', 'message': ""Remove oslosphinx\n\nMoving to openstackdocthemes means that we don't need oslosphinx any\nmore.\n\nChange-Id: I061f89d4bfbda262f8ff2eaa85a4d77a075bb221\n""}]",0,256360,69afcda3ffd9e794619fccc707d261041a7ccf1a,3,1,1,8246,,,0,"Remove oslosphinx

Moving to openstackdocthemes means that we don't need oslosphinx any
more.

Change-Id: I061f89d4bfbda262f8ff2eaa85a4d77a075bb221
",git fetch https://review.opendev.org/openstack/senlin refs/changes/60/256360/1 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,69afcda3ffd9e794619fccc707d261041a7ccf1a,remove-oslosphinx,"openstackdocstheme>=1.0.3sphinx!=1.2.0,!=1.3b1,<1.3,>=1.1.2","openstackdocstheme>=1.0.3oslosphinx!=3.4.0,>=2.5.0 # Apache-2.0 sphinx!=1.2.0,!=1.3b1,<1.3,>=1.1.2",2,3
openstack%2Fnova~master~Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064,openstack/nova,master,Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064,drop _create_glance_client function,ABANDONED,2015-12-08 15:41:22.000000000,2015-12-11 12:17:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-08 15:41:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/44156a48416ef7e8572f9e2ab3ef6ea6a400509b', 'message': 'drop _create_glance_client function\n\nThis is now no longer used. This drops the function and updates all\nthe unit tests to use _glanceclient_from_endpoint instead.\n\nThe unit tests for special casing the non keystone case is dropped, as\nsending the additional headers should be fine in the noauth case.\n\nChange-Id: Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064\n'}, {'number': 2, 'created': '2015-12-08 22:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/402063274daff1be60e7cdd586a48d215c53ad47', 'message': 'drop _create_glance_client function\n\nThis is now no longer used. This drops the function and updates all\nthe unit tests to use _glanceclient_from_endpoint instead.\n\nThe unit tests for special casing the non keystone case is dropped, as\nsending the additional headers should be fine in the noauth case.\n\nChange-Id: Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064\n'}, {'number': 3, 'created': '2015-12-08 22:58:21.000000000', 'files': ['nova/image/glance.py', 'nova/tests/unit/image/test_glance.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/192794851488216e0f4054e74dd0da42a62a7ca5', 'message': 'drop _create_glance_client function\n\nThis is now no longer used. This drops the function and updates all\nthe unit tests to use _glanceclient_from_endpoint instead.\n\nThe unit tests for special casing the non keystone case is dropped, as\nsending the additional headers should be fine in the noauth case.\n\nChange-Id: Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064\n'}]",0,254827,192794851488216e0f4054e74dd0da42a62a7ca5,21,10,3,2750,,,0,"drop _create_glance_client function

This is now no longer used. This drops the function and updates all
the unit tests to use _glanceclient_from_endpoint instead.

The unit tests for special casing the non keystone case is dropped, as
sending the additional headers should be fine in the noauth case.

Change-Id: Ia3eeb07c1e3d80d96be1f5e67251e7fae584d064
",git fetch https://review.opendev.org/openstack/nova refs/changes/27/254827/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/image/glance.py', 'nova/tests/unit/image/test_glance.py']",2,44156a48416ef7e8572f9e2ab3ef6ea6a400509b,glance_image_config," endpoint = glance.GlanceEndpoint(url=expected_endpoint) } } glance._glanceclient_from_endpoint(ctx, endpoint) } } glance._glanceclient_from_endpoint(ctx, endpoint, version=2) endpoint = glance.GlanceEndpoint(url=expected_endpoint) glance._glanceclient_from_endpoint(ctx, endpoint) endpoint = glance.GlanceEndpoint(url='https://host4:9295') glance._glanceclient_from_endpoint(ctxt, endpoint) cert_file='bar.cert', key_file='wut.key', cacert='foo.cert', identity_headers=mock.ANY)"," host = 'host4' port = 9295 use_ssl = False }, 'token': 'token' } glance._create_glance_client(ctx, host, port, use_ssl) }, 'token': 'token' } glance._create_glance_client(ctx, host, port, use_ssl, version=2) # Test that non-keystone auth strategy doesn't bother to pass # glanceclient all the Keystone-related headers. ipv6_mock.reset_mock() init_mock.reset_mock() self.flags(auth_strategy='non-keystone') expected_endpoint = 'http://host4:9295' expected_params = { } glance._create_glance_client(ctx, host, port, use_ssl) init_mock.assert_called_once_with('1', expected_endpoint, **expected_params) expected_params = { } glance._create_glance_client(ctx, host, port, use_ssl) glance._create_glance_client(ctxt, 'host4', 9295, use_ssl=True) cert_file='bar.cert', key_file='wut.key', cacert='foo.cert')",12,60
openstack%2Ffuel-main~master~I419dfaa447336d7c1cb04b8f6f8354038b90ee03,openstack/fuel-main,master,I419dfaa447336d7c1cb04b8f6f8354038b90ee03,Install daemonize into mcollective container,MERGED,2015-12-10 19:47:43.000000000,2015-12-11 12:12:27.000000000,2015-12-11 12:12:25.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7195}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10474}, {'_account_id': 11081}, {'_account_id': 12817}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-12-10 19:47:43.000000000', 'files': ['requirements-rpm.txt', 'docker/mcollective/setup.sh'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c65a6d5faf8fb7d72edb84c671acf2d173afd1b2', 'message': 'Install daemonize into mcollective container\n\nChange-Id: I419dfaa447336d7c1cb04b8f6f8354038b90ee03\nCloses-Bug: #1524116\n'}]",0,256074,c65a6d5faf8fb7d72edb84c671acf2d173afd1b2,14,10,1,7562,,,0,"Install daemonize into mcollective container

Change-Id: I419dfaa447336d7c1cb04b8f6f8354038b90ee03
Closes-Bug: #1524116
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/74/256074/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements-rpm.txt', 'docker/mcollective/setup.sh']",2,c65a6d5faf8fb7d72edb84c671acf2d173afd1b2,,"packages=""sudo mcollective shotgun fuel-agent fuel-provisioning-scripts psmisc daemonize""","packages=""sudo mcollective shotgun fuel-agent fuel-provisioning-scripts psmisc""",2,1
openstack%2Ffuel-octane~stable%2F7.0~I13a20b884aea1e3058a93f5459955b4d2a8a2089,openstack/fuel-octane,stable/7.0,I13a20b884aea1e3058a93f5459955b4d2a8a2089,Evacuate VMs from Compute node,MERGED,2015-12-11 10:55:48.000000000,2015-12-11 12:09:01.000000000,2015-12-11 12:08:59.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}]","[{'number': 1, 'created': '2015-12-11 10:55:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/922aabd08131c2ae2bd60ec8e19a4ae75e62ceef', 'message': 'Evacuate VMs from Compute node\n\nIn preparation phase of the upgrade of a node, evacuate virtual machines\nfrom that node to other hosts using live migration.\n\nThis feature only supported for nodes where live migration is available.\n\nChange-Id: I13a20b884aea1e3058a93f5459955b4d2a8a2089\nRelated-bug: 1523469\n'}, {'number': 2, 'created': '2015-12-11 11:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/ebdf98fd4c4f0a805a6a9847aaa634d57ac68149', 'message': 'Evacuate VMs from Compute node\n\nIn preparation phase of the upgrade of a node, evacuate virtual machines\nfrom that node to other hosts using live migration.\n\nThis feature only supported for nodes where live migration is available.\n\nChange-Id: I13a20b884aea1e3058a93f5459955b4d2a8a2089\nRelated-bug: 1523469\nCherry-picked from: fbcf3c2d9545c014fea0b5c54a47d30abdad9afe'}, {'number': 3, 'created': '2015-12-11 11:29:15.000000000', 'files': ['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/handlers/upgrade/__init__.py', 'octane/handlers/upgrade/compute.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/2519727b03606a309f92511b6f5203076841028d', 'message': 'Evacuate VMs from Compute node\n\nIn preparation phase of the upgrade of a node, evacuate virtual machines\nfrom that node to other hosts using live migration.\n\nThis feature only supported for nodes where live migration is available.\n\nChange-Id: I13a20b884aea1e3058a93f5459955b4d2a8a2089\nRelated-bug: 1523469\n(cherry picked from commit fbcf3c2d9545c014fea0b5c54a47d30abdad9afe)'}]",0,256339,2519727b03606a309f92511b6f5203076841028d,11,3,3,6677,,,0,"Evacuate VMs from Compute node

In preparation phase of the upgrade of a node, evacuate virtual machines
from that node to other hosts using live migration.

This feature only supported for nodes where live migration is available.

Change-Id: I13a20b884aea1e3058a93f5459955b4d2a8a2089
Related-bug: 1523469
(cherry picked from commit fbcf3c2d9545c014fea0b5c54a47d30abdad9afe)",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/39/256339/3 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/handlers/upgrade/__init__.py', 'octane/handlers/upgrade/compute.py']",4,922aabd08131c2ae2bd60ec8e19a4ae75e62ceef,bug/1523469, if node_util.is_live_migration_supported(self.node): self.evacuate_host() else: self.backup_iscsi_initiator_info() self.preserve_partition(), self.backup_iscsi_initiator_info() self.preserve_partition(),37,2
openstack%2Ffuel-web~master~I1ba71a2f1979c26e1fad1da92c107ab8003474bf,openstack/fuel-web,master,I1ba71a2f1979c26e1fad1da92c107ab8003474bf,Collect info about installed packages in containers,MERGED,2015-12-08 16:27:55.000000000,2015-12-11 12:04:00.000000000,2015-12-11 11:46:46.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6623}, {'_account_id': 8003}, {'_account_id': 8789}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 10959}, {'_account_id': 11577}, {'_account_id': 14543}, {'_account_id': 18205}, {'_account_id': 18520}, {'_account_id': 19196}]","[{'number': 1, 'created': '2015-12-08 16:27:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/d2a94e096af3c3820650efdf7157b0a85f05fe40', 'message': 'Collect info about installed packages in containers\n\nChange-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf\nCloses-bug: #1511730\n'}, {'number': 2, 'created': '2015-12-09 10:05:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/9342d74537292ef6a75568fc776049549ba27872', 'message': 'Collect info about installed packages in containers\n\nChange-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf\nCloses-bug: #1511730\n'}, {'number': 3, 'created': '2015-12-09 13:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/0db49e51beff922d9961e0ed611acaac7de2953a', 'message': 'Collect info about installed packages in containers\n\nChange-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf\nCloses-bug: #1511730\n'}, {'number': 4, 'created': '2015-12-09 16:30:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/4f554c98377764265ce760bae639446113a7079c', 'message': 'Collect info about installed packages in containers\n\nChange-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf\nCloses-bug: #1511730\n'}, {'number': 5, 'created': '2015-12-10 14:06:42.000000000', 'files': ['nailgun/nailgun/settings.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/2ccb8e09fcfbe002fdc6743a7356d0aa1365d97f', 'message': 'Collect info about installed packages in containers\n\nChange-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf\nCloses-bug: #1511730\n'}]",16,254850,2ccb8e09fcfbe002fdc6743a7356d0aa1365d97f,59,14,5,18520,,,0,"Collect info about installed packages in containers

Change-Id: I1ba71a2f1979c26e1fad1da92c107ab8003474bf
Closes-bug: #1511730
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/50/254850/4 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/nailgun/settings.yaml'],1,d2a94e096af3c3820650efdf7157b0a85f05fe40,collect-info-in-containers-2, command: dockerctl shell nginx rpm -qa to_file: centos_nginx_installed_rpms.txt - type: command command: dockerctl shell rabbitmq rpm -qa to_file: centos_rabbitmq_installed_rpms.txt - type: command command: dockerctl shell astute rpm -qa to_file: centos_astute_installed_rpms.txt - type: command command: dockerctl shell rsync rpm -qa to_file: centos_rsync_installed_rpms.txt - type: command command: dockerctl shell keystone rpm -qa to_file: centos_keystone_installed_rpms.txt - type: command command: dockerctl shell postgres rpm -qa to_file: centos_postgres_installed_rpms.txt - type: command command: dockerctl shell rsyslog keystone rpm -qa to_file: centos_rsyslog_installed_rpms.txt - type: command command: dockerctl shell nailgun keystone rpm -qa to_file: centos_nailgun_installed_rpms.txt - type: command command: dockerctl shell cobbler keystone rpm -qa to_file: centos_cobbler_installed_rpms.txt - type: command command: dockerctl shell ostf keystone rpm -qa to_file: centos_ostf_installed_rpms.txt - type: command command: dockerctl shell mcollective keystone rpm -qa to_file: centos_mcollective_installed_rpms.txt - type: command,,33,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ib104e51782c6d3f646907cdb06c74fd4cbf9028c,openstack/tripleo-heat-templates,stable/liberty,Ib104e51782c6d3f646907cdb06c74fd4cbf9028c,Apply mongod timeout via cib-push,MERGED,2015-12-09 14:54:32.000000000,2015-12-11 11:59:41.000000000,2015-12-11 11:59:40.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-09 14:54:32.000000000', 'files': ['extraconfig/tasks/yum_update.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e0cc72adba742229c4f5d9aec72bc634b4865c76', 'message': 'Apply mongod timeout via cib-push\n\nWe forgot to apply the mongod timeout in the cib dump first, to\napply it later in a single cib-push step.\n\nChange-Id: Ib104e51782c6d3f646907cdb06c74fd4cbf9028c\n(cherry picked from commit e6c33852a9cedb67e22ce66e8910849cc3b397b3)\n'}]",0,255300,e0cc72adba742229c4f5d9aec72bc634b4865c76,8,3,1,8449,,,0,"Apply mongod timeout via cib-push

We forgot to apply the mongod timeout in the cib dump first, to
apply it later in a single cib-push step.

Change-Id: Ib104e51782c6d3f646907cdb06c74fd4cbf9028c
(cherry picked from commit e6c33852a9cedb67e22ce66e8910849cc3b397b3)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/00/255300/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/yum_update.sh'],1,e0cc72adba742229c4f5d9aec72bc634b4865c76,bug/1501378, pcs -f $pacemaker_dumpfile resource update mongod op stop timeout=100s, pcs resource update mongod op stop timeout=100s,1,1
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I6875f19e1f34f0fdcf0928421f49b61d857ca7c8,openstack/tripleo-heat-templates,stable/liberty,I6875f19e1f34f0fdcf0928421f49b61d857ca7c8,Add constraints and timeouts from file in single step,MERGED,2015-12-09 14:54:32.000000000,2015-12-11 11:59:06.000000000,2015-12-11 11:59:06.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-09 14:54:32.000000000', 'files': ['extraconfig/tasks/yum_update.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/220a3d72a42e1c308fc105be8e3dcc20fbe79283', 'message': 'Add constraints and timeouts from file in single step\n\nTo avoid pcmk reconfiguring the resources on each config change,\nwe want to apply the constraints and timeouts from file.\n\nWe also *do not* want to alter the timeouts for a few ocf resources\nwhich are rabbitmq, neutron-netns-cleanup and neutron-ovs-cleanup\n\nChange-Id: I6875f19e1f34f0fdcf0928421f49b61d857ca7c8\nCo-Authored-By: Andrew Beekhof <abeekhof@redhat.com>\n(cherry picked from commit daccacc20060c7b166883ae5377dfcc5495a48a5)\n'}]",0,255299,220a3d72a42e1c308fc105be8e3dcc20fbe79283,8,3,1,8449,,,0,"Add constraints and timeouts from file in single step

To avoid pcmk reconfiguring the resources on each config change,
we want to apply the constraints and timeouts from file.

We also *do not* want to alter the timeouts for a few ocf resources
which are rabbitmq, neutron-netns-cleanup and neutron-ovs-cleanup

Change-Id: I6875f19e1f34f0fdcf0928421f49b61d857ca7c8
Co-Authored-By: Andrew Beekhof <abeekhof@redhat.com>
(cherry picked from commit daccacc20060c7b166883ae5377dfcc5495a48a5)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/255299/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/yum_update.sh'],1,220a3d72a42e1c308fc105be8e3dcc20fbe79283,bug/1501378,"cluster_start_timeout=600pacemaker_dumpfile=$(mktemp) echo ""Dumping Pacemaker config"" pcs cluster cib $pacemaker_dumpfile echo ""Checking for missing constraints"" pcs -f $pacemaker_dumpfile constraint order start openstack-nova-novncproxy-clone then openstack-nova-api-clone pcs -f $pacemaker_dumpfile constraint order start rabbitmq-clone then openstack-keystone-clone pcs -f $pacemaker_dumpfile constraint order promote galera-master then openstack-keystone-clone pcs -f $pacemaker_dumpfile constraint order start haproxy-clone then openstack-keystone-clone pcs -f $pacemaker_dumpfile constraint order start memcached-clone then openstack-keystone-clone pcs -f $pacemaker_dumpfile constraint order promote redis-master then start openstack-ceilometer-central-clone require-all=false pcs -f $pacemaker_dumpfile resource defaults resource-stickiness=INFINITY SERVICES="" haproxy memcached httpd neutron-dhcp-agent neutron-l3-agent neutron-metadata-agent neutron-openvswitch-agent neutron-server openstack-ceilometer-alarm-evaluator openstack-ceilometer-alarm-notifier openstack-ceilometer-api openstack-ceilometer-central openstack-ceilometer-collector openstack-ceilometer-notification openstack-cinder-api openstack-cinder-scheduler openstack-cinder-volume openstack-glance-api openstack-glance-registry openstack-heat-api openstack-heat-api-cfn openstack-heat-api-cloudwatch openstack-heat-engine openstack-keystone openstack-nova-api openstack-nova-conductor openstack-nova-consoleauth openstack-nova-novncproxy openstack-nova-scheduler"" for service in $SERVICES; do pcs -f $pacemaker_dumpfile resource update $service op start timeout=100s op stop timeout=100s done # mongod start timeout is higher, setting only stop timeout echo ""Applying new Pacemaker config"" pcs cluster cib-push $pacemaker_dumpfile","cluster_start_timeout=360 echo ""Checking for and adding missing constraints"" pcs constraint order start openstack-nova-novncproxy-clone then openstack-nova-api-clone pcs constraint order start rabbitmq-clone then openstack-keystone-clone pcs constraint order promote galera-master then openstack-keystone-clone pcs constraint order start haproxy-clone then openstack-keystone-clone pcs constraint order start memcached-clone then openstack-keystone-clone pcs constraint order promote redis-master then start openstack-ceilometer-central-clone require-all=false pcs resource defaults resource-stickiness=INFINITY # timeouts for non-openstack services and special cases pcs resource update haproxy op start timeout=100s pcs resource update haproxy op stop timeout=100s # mongod start timeout is also higher, setting only stop timeout # rabbit start timeout is already 100s pcs resource update rabbitmq op stop timeout=100s pcs resource update memcached op start timeout=100s pcs resource update memcached op stop timeout=100s pcs resource update httpd op start timeout=100s pcs resource update httpd op stop timeout=100s # neutron-netns-cleanup stop timeout is 300s, setting only start timeout pcs resource update neutron-netns-cleanup op start timeout=100s # neutron-ovs-cleanup stop timeout is 300s, setting only start timeout pcs resource update neutron-ovs-cleanup op start timeout=100s # timeouts for openstack services pcs resource update neutron-dhcp-agent op start timeout=100s pcs resource update neutron-dhcp-agent op stop timeout=100s pcs resource update neutron-l3-agent op start timeout=100s pcs resource update neutron-l3-agent op stop timeout=100s pcs resource update neutron-metadata-agent op start timeout=100s pcs resource update neutron-metadata-agent op stop timeout=100s pcs resource update neutron-openvswitch-agent op start timeout=100s pcs resource update neutron-openvswitch-agent op stop timeout=100s pcs resource update neutron-server op start timeout=100s pcs resource update neutron-server op stop timeout=100s pcs resource update openstack-ceilometer-alarm-evaluator op start timeout=100s pcs resource update openstack-ceilometer-alarm-evaluator op stop timeout=100s pcs resource update openstack-ceilometer-alarm-notifier op start timeout=100s pcs resource update openstack-ceilometer-alarm-notifier op stop timeout=100s pcs resource update openstack-ceilometer-api op start timeout=100s pcs resource update openstack-ceilometer-api op stop timeout=100s pcs resource update openstack-ceilometer-central op start timeout=100s pcs resource update openstack-ceilometer-central op stop timeout=100s pcs resource update openstack-ceilometer-collector op start timeout=100s pcs resource update openstack-ceilometer-collector op stop timeout=100s pcs resource update openstack-ceilometer-notification op start timeout=100s pcs resource update openstack-ceilometer-notification op stop timeout=100s pcs resource update openstack-cinder-api op start timeout=100s pcs resource update openstack-cinder-api op stop timeout=100s pcs resource update openstack-cinder-scheduler op start timeout=100s pcs resource update openstack-cinder-scheduler op stop timeout=100s pcs resource update openstack-cinder-volume op start timeout=100s pcs resource update openstack-cinder-volume op stop timeout=100s pcs resource update openstack-glance-api op start timeout=100s pcs resource update openstack-glance-api op stop timeout=100s pcs resource update openstack-glance-registry op start timeout=100s pcs resource update openstack-glance-registry op stop timeout=100s pcs resource update openstack-heat-api op start timeout=100s pcs resource update openstack-heat-api op stop timeout=100s pcs resource update openstack-heat-api-cfn op start timeout=100s pcs resource update openstack-heat-api-cfn op stop timeout=100s pcs resource update openstack-heat-api-cloudwatch op start timeout=100s pcs resource update openstack-heat-api-cloudwatch op stop timeout=100s pcs resource update openstack-heat-engine op start timeout=100s pcs resource update openstack-heat-engine op stop timeout=100s pcs resource update openstack-keystone op start timeout=100s pcs resource update openstack-keystone op stop timeout=100s pcs resource update openstack-nova-api op start timeout=100s pcs resource update openstack-nova-api op stop timeout=100s pcs resource update openstack-nova-conductor op start timeout=100s pcs resource update openstack-nova-conductor op stop timeout=100s pcs resource update openstack-nova-consoleauth op start timeout=100s pcs resource update openstack-nova-consoleauth op stop timeout=100s pcs resource update openstack-nova-novncproxy op start timeout=100s pcs resource update openstack-nova-novncproxy op stop timeout=100s pcs resource update openstack-nova-scheduler op start timeout=100s pcs resource update openstack-nova-scheduler op stop timeout=100s",49,77
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ie8fc2c5d5214deacea94ca658ac75359b318ced1,openstack/tripleo-heat-templates,stable/liberty,Ie8fc2c5d5214deacea94ca658ac75359b318ced1,Verify galera is sync'd in yum_update.sh,MERGED,2015-12-09 14:54:32.000000000,2015-12-11 11:58:39.000000000,2015-12-11 11:58:38.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7144}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-09 14:54:32.000000000', 'files': ['extraconfig/tasks/yum_update.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/468796d7728229775b03e81097c650dc88e21908', 'message': ""Verify galera is sync'd in yum_update.sh\n\nWhen the cluster is brought back online after a yum update in\nyum_update.sh, we should verify that galera is fully sync'd before\nmoving on. This ensures the sync is complete before moving on to update\nany other nodes in the cluster.\n\nChange-Id: Ie8fc2c5d5214deacea94ca658ac75359b318ced1\n(cherry picked from commit fe87f5bb6b748d54f9829fb4f7cb5431a832c406)\n""}]",0,255298,468796d7728229775b03e81097c650dc88e21908,8,4,1,8449,,,0,"Verify galera is sync'd in yum_update.sh

When the cluster is brought back online after a yum update in
yum_update.sh, we should verify that galera is fully sync'd before
moving on. This ensures the sync is complete before moving on to update
any other nodes in the cluster.

Change-Id: Ie8fc2c5d5214deacea94ca658ac75359b318ced1
(cherry picked from commit fe87f5bb6b748d54f9829fb4f7cb5431a832c406)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/255298/1 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/tasks/yum_update.sh'],1,468796d7728229775b03e81097c650dc88e21908,bug/1501378,"galera_sync_timeout=360 tstart=$(date +%s) while ! clustercheck; do sleep 5 tnow=$(date +%s) if (( tnow-tstart > galera_sync_timeout )) ; then echo ""ERROR galera sync timed out"" exit 1 fi done ",,12,0
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Ic352ddd30807dc378e5e7b6c396bc53f5d6d5622,openstack/tripleo-heat-templates,stable/liberty,Ic352ddd30807dc378e5e7b6c396bc53f5d6d5622,Add DeployIdentifier overcloud parameter,MERGED,2015-12-08 15:16:41.000000000,2015-12-11 11:57:22.000000000,2015-12-11 11:57:21.000000000,"[{'_account_id': 3}, {'_account_id': 360}, {'_account_id': 4328}, {'_account_id': 8449}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-08 15:16:41.000000000', 'files': ['overcloud-without-mergepy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9e010667c36c84b54d2f06603cff9b6926668854', 'message': ""Add DeployIdentifier overcloud parameter\n\nWe've heard from end users that it is confusing that puppet\nisn't re-executed on a heat stack-update.\n\nThis patch adds a new DeployIdentifier parameter which\nwe can set via client tooling (tripleoclient) to a unique\nvalue so that on each heat stack-update we always execute\nall of our configuration deployments.\n\nChange-Id: Ic352ddd30807dc378e5e7b6c396bc53f5d6d5622\nRelated-bug: #1505430\n""}]",0,254815,9e010667c36c84b54d2f06603cff9b6926668854,9,5,1,8449,,,0,"Add DeployIdentifier overcloud parameter

We've heard from end users that it is confusing that puppet
isn't re-executed on a heat stack-update.

This patch adds a new DeployIdentifier parameter which
we can set via client tooling (tripleoclient) to a unique
value so that on each heat stack-update we always execute
all of our configuration deployments.

Change-Id: Ic352ddd30807dc378e5e7b6c396bc53f5d6d5622
Related-bug: #1505430
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/15/254815/1 && git format-patch -1 --stdout FETCH_HEAD,['overcloud-without-mergepy.yaml'],1,9e010667c36c84b54d2f06603cff9b6926668854,bug/1505430, DeployIdentifier: default: '' type: string description: > Setting this to a unique value will re-run any deployment tasks which perform configuration on a Heat stack-update. deployment_identifier: {get_param: DeployIdentifier} deployment_identifier: {get_param: DeployIdentifier} deployment_identifier: {get_param: DeployIdentifier} deployment_identifier: {get_param: DeployIdentifier} deployment_identifier: {get_param: DeployIdentifier},,11,0
openstack%2Ffuel-library~master~I78f31000e57fb9bfeecad2ba9a7f343967e68f9c,openstack/fuel-library,master,I78f31000e57fb9bfeecad2ba9a7f343967e68f9c,l23network corrections,MERGED,2015-12-10 12:30:34.000000000,2015-12-11 11:53:21.000000000,2015-12-11 11:52:36.000000000,"[{'_account_id': 3}, {'_account_id': 6926}, {'_account_id': 7195}, {'_account_id': 7468}, {'_account_id': 8786}, {'_account_id': 8971}, {'_account_id': 9037}, {'_account_id': 9387}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13344}, {'_account_id': 13948}, {'_account_id': 14985}]","[{'number': 1, 'created': '2015-12-10 12:30:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/6cc2c0619a8cd0e5cb68e27549b609822a156f62', 'message': 'l23network corrections\n\n* Use bash as shebang for scripts as well as CenOS/RHEL network scripts use\n* Changes if conditions according to bash\n* Move files that are not templates to files folder\n\nChange-Id: I78f31000e57fb9bfeecad2ba9a7f343967e68f9c\nPartial-bug: #1522481\n'}, {'number': 2, 'created': '2015-12-10 12:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/1d3f45e13e55de4f4f3e2143c7f3edcb30bd2ffb', 'message': 'l23network corrections\n\n* Use bash as shebang for scripts as well as CenOS/RHEL network scripts use\n* Changes if conditions according to bash\n* Move files that are not templates to files folder\n\nChange-Id: I78f31000e57fb9bfeecad2ba9a7f343967e68f9c\nPartial-bug: #1522481\n'}, {'number': 3, 'created': '2015-12-10 13:44:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/8a7d492f96f6c7b9f6e2ad0157a55eae64069639', 'message': 'l23network corrections\n\n* Use bash as shebang for scripts as well as CenOS/RHEL network scripts use\n* Changes if conditions according to bash\n* Move files that are not templates to files folder\n* Add chmod for pre-up configs\n* Remove jacks for l23_stored_config ovs2lnx patch as it is not used\n\nChange-Id: I78f31000e57fb9bfeecad2ba9a7f343967e68f9c\nPartial-bug: #1522481\n'}, {'number': 4, 'created': '2015-12-10 14:43:35.000000000', 'files': ['deployment/puppet/l23network/templates/centos_ifup-local.erb', 'deployment/puppet/l23network/files/centos_ifup-local', 'deployment/puppet/l23network/manifests/l2/patch.pp', 'deployment/puppet/l23network/lib/puppet/provider/l23_stored_config_centos.rb', 'deployment/puppet/l23network/manifests/l2/centos_upndown_scripts.pp', 'deployment/puppet/l23network/files/centos_ifdown-local', 'deployment/puppet/l23network/files/interfaces', 'deployment/puppet/l23network/spec/classes/ovs2lnx__ovs_patch__spec.rb', 'deployment/puppet/l23network/files/centos_ifup-pre-local', 'deployment/puppet/l23network/templates/centos_ifdown-local.erb', 'deployment/puppet/l23network/manifests/init.pp', 'deployment/puppet/l23network/spec/defines/l2_patch__spec.rb', 'deployment/puppet/l23network/spec/fixtures/provider/l23_stored_config/lnx_centos7__lnx2lnx_patch__spec/pre-up-ifcfg-p_33470efd-1', 'deployment/puppet/l23network/spec/fixtures/provider/l23_stored_config/lnx_centos7__lnx2lnx_patch__spec/pre-up-ifcfg-p_33470efd-0'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/a17eb556d96da0a2575df7a33fc96d79756b8ec6', 'message': 'l23network corrections\n\n* Use bash as shebang for scripts as well as CenOS/RHEL network scripts use\n* Change *if* conditions according to bash\n* Move files that are not templates to files folder\n* Add chmod for pre-up config files\n* Remove jacks for l23_stored_config ovs2lnx patch as it is not used\n\nChange-Id: I78f31000e57fb9bfeecad2ba9a7f343967e68f9c\nPartial-bug: #1522481\n'}]",0,255841,a17eb556d96da0a2575df7a33fc96d79756b8ec6,51,14,4,13343,,,0,"l23network corrections

* Use bash as shebang for scripts as well as CenOS/RHEL network scripts use
* Change *if* conditions according to bash
* Move files that are not templates to files folder
* Add chmod for pre-up config files
* Remove jacks for l23_stored_config ovs2lnx patch as it is not used

Change-Id: I78f31000e57fb9bfeecad2ba9a7f343967e68f9c
Partial-bug: #1522481
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/41/255841/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/puppet/l23network/files/interfaces', 'deployment/puppet/l23network/files/centos_ifup-pre-local', 'deployment/puppet/l23network/templates/centos_ifup-local.erb', 'deployment/puppet/l23network/templates/centos_ifdown-local.erb', 'deployment/puppet/l23network/files/centos_ifup-local', 'deployment/puppet/l23network/manifests/init.pp', 'deployment/puppet/l23network/manifests/l2/centos_upndown_scripts.pp', 'deployment/puppet/l23network/files/centos_ifdown-local']",8,6cc2c0619a8cd0e5cb68e27549b609822a156f62,bug/bash_sh_thing2,"#!/bin/bash SCRIPT=""/etc/sysconfig/network-scripts/interface-down-script-$1"" [ -x $SCRIPT ] && . $SCRIPT ",,11,17
openstack%2Fpython-tripleoclient~stable%2Fliberty~Ib2ea84a8e7f0a42423199cd1db40136ab8495fdc,openstack/python-tripleoclient,stable/liberty,Ib2ea84a8e7f0a42423199cd1db40136ab8495fdc,Do not try to introspect nodes in maintenance mode and associated ones,MERGED,2015-12-03 15:38:55.000000000,2015-12-11 11:50:14.000000000,2015-12-11 11:50:14.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 10239}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-03 15:38:55.000000000', 'files': ['tripleoclient/v1/baremetal.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/304badecc7e49717ded868356bb5825c23fa42de', 'message': 'Do not try to introspect nodes in maintenance mode and associated ones\n\nSome time ago ironic-discoverd used to require maintenance mode.\nThis was changed back in Kilo, and was deprecated in Liberty.\n\nAlso cleans up introspection code a bit.\n\nChange-Id: Ib2ea84a8e7f0a42423199cd1db40136ab8495fdc\n(cherry picked from commit 6c5ce78479a75f28422f0e233c7cbdd36a1471d9)\n'}]",0,253024,304badecc7e49717ded868356bb5825c23fa42de,14,4,1,10239,,,0,"Do not try to introspect nodes in maintenance mode and associated ones

Some time ago ironic-discoverd used to require maintenance mode.
This was changed back in Kilo, and was deprecated in Liberty.

Also cleans up introspection code a bit.

Change-Id: Ib2ea84a8e7f0a42423199cd1db40136ab8495fdc
(cherry picked from commit 6c5ce78479a75f28422f0e233c7cbdd36a1471d9)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/24/253024/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/baremetal.py'],1,304badecc7e49717ded868356bb5825c23fa42de,," available_nodes = [node for node in client.node.list(maintenance=False, associated=False) for node in client.node.list(maintenance=False, associated=False): available_nodes = [node for node in client.node.list(maintenance=False, associated=False) client, available_nodes, 'provide',"," available_nodes = [node for node in client.node.list() for node in client.node.list(): clients = self.app.client_manager baremetal_client = clients.tripleoclient.baremetal() available_nodes = [node for node in client.node.list() baremetal_client, baremetal_client.node.list(), 'provide',",6,6
openstack%2Fpython-tripleoclient~stable%2Fliberty~Ia7b50f7cfde4eb4444e7ba77a7d825ac8ba58318,openstack/python-tripleoclient,stable/liberty,Ia7b50f7cfde4eb4444e7ba77a7d825ac8ba58318,Install bigswitch networking plugin by default,MERGED,2015-11-09 20:45:58.000000000,2015-12-11 11:48:14.000000000,2015-12-11 11:48:13.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-11-09 20:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/038669443cf114b4868b386fe82f66c71700c6b9', 'message': 'Install bigswitch networking plugin by default\n\nInstall the bigswitch networking packages\npython-networking-bigswitch\nopenstack-neutron-bigswitch-lldp\n\nRelated:  rhbz#1262059\n\nChange-Id: Ia7b50f7cfde4eb4444e7ba77a7d825ac8ba58318\n'}, {'number': 2, 'created': '2015-11-17 20:43:28.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2ca2c5966d2285b0edd2bb77b0ac766d56afb5e6', 'message': 'Install bigswitch networking plugin by default\n\nInstall the bigswitch networking packages\npython-networking-bigswitch\nopenstack-neutron-bigswitch-lldp\n\nRelated:  rhbz#1262059\n\nChange-Id: Ia7b50f7cfde4eb4444e7ba77a7d825ac8ba58318\n'}]",1,243309,2ca2c5966d2285b0edd2bb77b0ac766d56afb5e6,17,6,2,9979,,,0,"Install bigswitch networking plugin by default

Install the bigswitch networking packages
python-networking-bigswitch
openstack-neutron-bigswitch-lldp

Related:  rhbz#1262059

Change-Id: Ia7b50f7cfde4eb4444e7ba77a7d825ac8ba58318
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/09/243309/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,038669443cf114b4868b386fe82f66c71700c6b9,liberty," ""device-mapper-multipath,python-networking-bigswitch,"" ""openstack-neutron-bigswitch-lldp """," ""device-mapper-multipath """,4,2
openstack%2Fpython-tripleoclient~stable%2Fliberty~Ib09ef36507ffbe0589c57d1a23ee6da38ffa0e5a,openstack/python-tripleoclient,stable/liberty,Ib09ef36507ffbe0589c57d1a23ee6da38ffa0e5a,Do not throw an error on validation when tunneling is disabled,MERGED,2015-11-09 20:45:58.000000000,2015-12-11 11:46:33.000000000,2015-12-11 11:46:31.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-11-09 20:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d132d50d894ce14fb462c55295ee7d53b863b390', 'message': 'Do not throw an error on validation when tunneling is disabled\n\nWhen neutron tunneling is disabled, allow the passing of neutron network type\nwithout the need for neutron tunnel types.\n\nChange-Id: Ib09ef36507ffbe0589c57d1a23ee6da38ffa0e5a\nCloses-Bug: #1507556\n'}, {'number': 2, 'created': '2015-11-17 20:43:28.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9fa00783bfe485c3b95657d70a9ee33f1e3281e9', 'message': 'Do not throw an error on validation when tunneling is disabled\n\nWhen neutron tunneling is disabled, allow the passing of neutron network type\nwithout the need for neutron tunnel types.\n\nChange-Id: Ib09ef36507ffbe0589c57d1a23ee6da38ffa0e5a\nCloses-Bug: #1507556\n'}]",0,243308,9fa00783bfe485c3b95657d70a9ee33f1e3281e9,17,6,2,9979,,,0,"Do not throw an error on validation when tunneling is disabled

When neutron tunneling is disabled, allow the passing of neutron network type
without the need for neutron tunnel types.

Change-Id: Ib09ef36507ffbe0589c57d1a23ee6da38ffa0e5a
Closes-Bug: #1507556
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/08/243308/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py']",2,d132d50d894ce14fb462c55295ee7d53b863b390,liberty," tunnel_disabled = parsed_args.neutron_disable_tunneling elif not tunnel_disabled: if network_type and not tunnel_types: raise oscexc.CommandError(""Neutron tunnel types must be "" ""specified when Neutron network "" ""type is specified"") elif tunnel_types and not network_type: raise oscexc.CommandError(""Neutron network type must be "" ""specified when Neutron tunnel "" ""types is specified"")"," elif network_type and not tunnel_types: raise oscexc.CommandError(""Neutron tunnel types must be specified "" ""when Neutron network type is specified"") elif tunnel_types and not network_type: raise oscexc.CommandError(""Neutron network type must be specified "" ""when Neutron tunnel types is specified"")",40,6
openstack%2Fpython-tripleoclient~stable%2Fliberty~I5b575fe7728fd58c1fd448b1f4355ee4df7bffb8,openstack/python-tripleoclient,stable/liberty,I5b575fe7728fd58c1fd448b1f4355ee4df7bffb8,Install device-mapper-multipath on overcloud-full,MERGED,2015-11-09 20:45:58.000000000,2015-12-11 11:46:21.000000000,2015-12-11 11:46:20.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7065}, {'_account_id': 7144}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-11-09 20:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b608618e37789e71d2632922ef78375599232d33', 'message': 'Install device-mapper-multipath on overcloud-full\n\ndevice-mapper-multipath needs to be installed for managing of multipath\ndevices for scenarios where fail over or load balancing of block devices\nis desirable.\n\nThis change installs the package by default in the overcloud-full image\nfor connvenience. The multipathd daemon is not started or enabled nor\nany multipath configuration exposed. Those exercises would be left to be\ndone via the ExtraConfig resources in tripleo-heat-templates.\n\nChange-Id: I5b575fe7728fd58c1fd448b1f4355ee4df7bffb8\n'}, {'number': 2, 'created': '2015-11-17 20:43:28.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/01ea96fa51f2d2a050e01f862f861485805b5786', 'message': 'Install device-mapper-multipath on overcloud-full\n\ndevice-mapper-multipath needs to be installed for managing of multipath\ndevices for scenarios where fail over or load balancing of block devices\nis desirable.\n\nThis change installs the package by default in the overcloud-full image\nfor connvenience. The multipathd daemon is not started or enabled nor\nany multipath configuration exposed. Those exercises would be left to be\ndone via the ExtraConfig resources in tripleo-heat-templates.\n\nChange-Id: I5b575fe7728fd58c1fd448b1f4355ee4df7bffb8\n'}]",0,243307,01ea96fa51f2d2a050e01f862f861485805b5786,18,8,2,9979,,,0,"Install device-mapper-multipath on overcloud-full

device-mapper-multipath needs to be installed for managing of multipath
devices for scenarios where fail over or load balancing of block devices
is desirable.

This change installs the package by default in the overcloud-full image
for connvenience. The multipathd daemon is not started or enabled nor
any multipath configuration exposed. Those exercises would be left to be
done via the ExtraConfig resources in tripleo-heat-templates.

Change-Id: I5b575fe7728fd58c1fd448b1f4355ee4df7bffb8
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/07/243307/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,b608618e37789e71d2632922ef78375599232d33,liberty," ""python-networking-cisco,python-UcsSdk,"" ""device-mapper-multipath """," ""python-networking-cisco,python-UcsSdk """,3,2
openstack%2Fpython-tripleoclient~stable%2Fliberty~I205569f4be0bcee2b284048dec7ddf0b28bbd8a1,openstack/python-tripleoclient,stable/liberty,I205569f4be0bcee2b284048dec7ddf0b28bbd8a1,Consolidate module constants.,MERGED,2015-11-09 20:45:58.000000000,2015-12-11 11:44:58.000000000,2015-12-11 11:44:57.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 4571}, {'_account_id': 7065}, {'_account_id': 9712}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 12321}]","[{'number': 1, 'created': '2015-11-09 20:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/28f4a75a4848c262e6d75c62c5a01de449280a66', 'message': 'Consolidate module constants.\n\n3 separate places had hardcoded values for the t-h-t directory. Many\nvalues are/will be shared, this patch consolidates them to avoid having\nthem diverge in the future.\n\nDepends-On: I98e19cc29d69cbd6636cd4ce77a07c7a0e3dc048\nChange-Id: I205569f4be0bcee2b284048dec7ddf0b28bbd8a1\n'}, {'number': 2, 'created': '2015-11-17 20:43:28.000000000', 'files': ['tripleoclient/constants.py', 'tripleoclient/utils.py', 'tripleoclient/v1/overcloud_update.py', 'tripleoclient/v1/overcloud_node.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5dcfdce19c48e91331de2e747802c612b91d5ea8', 'message': 'Consolidate module constants.\n\n3 separate places had hardcoded values for the t-h-t directory. Many\nvalues are/will be shared, this patch consolidates them to avoid having\nthem diverge in the future.\n\nDepends-On: I98e19cc29d69cbd6636cd4ce77a07c7a0e3dc048\nChange-Id: I205569f4be0bcee2b284048dec7ddf0b28bbd8a1\n'}]",0,243306,5dcfdce19c48e91331de2e747802c612b91d5ea8,25,8,2,9979,,,0,"Consolidate module constants.

3 separate places had hardcoded values for the t-h-t directory. Many
values are/will be shared, this patch consolidates them to avoid having
them diverge in the future.

Depends-On: I98e19cc29d69cbd6636cd4ce77a07c7a0e3dc048
Change-Id: I205569f4be0bcee2b284048dec7ddf0b28bbd8a1
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/06/243306/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/constants.py', 'tripleoclient/utils.py', 'tripleoclient/v1/overcloud_update.py', 'tripleoclient/v1/overcloud_node.py', 'tripleoclient/v1/overcloud_deploy.py']",5,28f4a75a4848c262e6d75c62c5a01de449280a66,liberty,"from tripleoclient import constants parameters = constants.PARAMETERS.copy() if stack is None: parameters.update(constants.NEW_STACK_PARAMETERS) environment = os.path.join( tht_root, constants.RHEL_REGISTRATION_EXTRACONFIG_NAME, 'environment-rhel-registration.yaml') registry = os.path.join( tht_root, constants.RHEL_REGISTRATION_EXTRACONFIG_NAME, 'rhel-registration-resource-registry.yaml') resource_registry_path = os.path.join( tht_root, constants.RESOURCE_REGISTRY_NAME) overcloud_yaml = os.path.join(tht_root, constants.OVERCLOUD_YAML_NAME) for service, data in six.iteritems(constants.SERVICE_LIST): '--templates', nargs='?', const=constants.TRIPLEO_HEAT_TEMPLATES,","TRIPLEO_HEAT_TEMPLATES = ""/usr/share/openstack-tripleo-heat-templates/"" OVERCLOUD_YAML_NAME = ""overcloud-without-mergepy.yaml"" RESOURCE_REGISTRY_NAME = ""overcloud-resource-registry-puppet.yaml"" RHEL_REGISTRATION_EXTRACONFIG_NAME = ( ""extraconfig/pre_deploy/rhel-registration/"") PARAMETERS = { 'AdminPassword': None, 'AdminToken': None, 'CeilometerPassword': None, 'CeilometerMeteringSecret': None, 'CinderPassword': None, 'CinderISCSIHelper': 'lioadm', 'CloudName': 'overcloud', 'ExtraConfig': '{}', 'GlancePassword': None, 'HeatPassword': None, 'HeatStackDomainAdminPassword': None, 'NeutronControlPlaneID': None, 'NeutronDnsmasqOptions': 'dhcp-option-force=26,1400', 'NeutronPassword': None, 'NeutronPublicInterface': 'nic1', 'NeutronFlatNetworks': 'datacentre', 'HypervisorNeutronPhysicalBridge': 'br-ex', 'NeutronBridgeMappings': 'datacentre:br-ex', 'HypervisorNeutronPublicInterface': 'nic1', 'NovaPassword': None, 'SwiftHashSuffix': None, 'SwiftPassword': None, 'SnmpdReadonlyUserPassword': None, 'NtpServer': '', 'controllerImage': 'overcloud-full', 'NovaImage': 'overcloud-full', 'BlockStorageImage': 'overcloud-full', 'SwiftStorageImage': 'overcloud-full', 'CephStorageImage': 'overcloud-full', 'OvercloudControlFlavor': 'baremetal', 'OvercloudComputeFlavor': 'baremetal', 'OvercloudBlockStorageFlavor': 'baremetal', 'OvercloudSwiftStorageFlavor': 'baremetal', 'OvercloudCephStorageFlavor': 'baremetal', 'NeutronNetworkVLANRanges': 'datacentre:1:1000', } NEW_STACK_PARAMETERS = { 'NovaComputeLibvirtType': 'kvm', 'NeutronTunnelIdRanges': ['1:1000'], 'NeutronVniRanges': ['1:1000'], 'NeutronEnableTunnelling': 'True', 'NeutronNetworkType': 'gre', 'NeutronTunnelTypes': 'gre', } parameters = PARAMETERS.copy() if stack is None: parameters.update(NEW_STACK_PARAMETERS) environment = os.path.join(tht_root, RHEL_REGISTRATION_EXTRACONFIG_NAME, 'environment-rhel-registration.yaml') registry = os.path.join(tht_root, RHEL_REGISTRATION_EXTRACONFIG_NAME, 'rhel-registration-resource-registry.yaml') resource_registry_path = os.path.join(tht_root, RESOURCE_REGISTRY_NAME) overcloud_yaml = os.path.join(tht_root, OVERCLOUD_YAML_NAME) for service, data in six.iteritems(utils.SERVICE_LIST): '--templates', nargs='?', const=TRIPLEO_HEAT_TEMPLATES,",106,89
openstack%2Fnova~master~I756cc85316e269caed4eaa8a24ccd13361b60bfe,openstack/nova,master,I756cc85316e269caed4eaa8a24ccd13361b60bfe,Updated from global requirements,MERGED,2015-12-06 10:42:40.000000000,2015-12-11 11:42:24.000000000,2015-12-10 20:29:21.000000000,"[{'_account_id': 3}, {'_account_id': 679}, {'_account_id': 5170}, {'_account_id': 5441}, {'_account_id': 6873}, {'_account_id': 7111}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14511}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 16272}, {'_account_id': 16897}, {'_account_id': 16898}]","[{'number': 1, 'created': '2015-12-06 10:42:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1f857dfbe5dea91174900b7a698f7c5d9866b589', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 2, 'created': '2015-12-08 02:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5001c6f203c7fd749dd1354646a2f5375bd5b278', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 3, 'created': '2015-12-08 02:32:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e3e07081b835ea16da61bbddad0c12c18db7a6b7', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 4, 'created': '2015-12-08 06:50:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c949240a8b85749c8e40bb3e9d5e124321f71fcc', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 5, 'created': '2015-12-08 21:35:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0b5a323caf3d5084c63d4b6cbbff0182e721061d', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 6, 'created': '2015-12-09 02:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5bf3b420ef1dc2a35d3e9da62574973c30c71ec9', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 7, 'created': '2015-12-09 07:08:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af1d3784547a9936bcb1ef704a9ca7a8017d90af', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 8, 'created': '2015-12-09 18:16:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c83ffd28bd35fe17514a4a4c0de797d08d1a9e17', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 9, 'created': '2015-12-09 21:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/57458dc598f5e5f52407819e8083748708241b35', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}, {'number': 10, 'created': '2015-12-10 12:45:15.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/nova/commit/b086a780076cc12e8fbc49629ffeffaef4efb00f', 'message': 'Updated from global requirements\n\nChange-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe\n'}]",1,253901,b086a780076cc12e8fbc49629ffeffaef4efb00f,109,18,10,11131,,,0,"Updated from global requirements

Change-Id: I756cc85316e269caed4eaa8a24ccd13361b60bfe
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/253901/10 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,1f857dfbe5dea91174900b7a698f7c5d9866b589,openstack/requirements,tempest-lib>=0.11.0,tempest-lib>=0.10.0,1,1
openstack%2Ffuel-web~master~Ia9ad4438ebfd2f6c6cdc1aaebae4f52f96a333c7,openstack/fuel-web,master,Ia9ad4438ebfd2f6c6cdc1aaebae4f52f96a333c7,Tox python env changed to py27 in run_tests.sh,MERGED,2015-12-09 14:38:47.000000000,2015-12-11 11:36:06.000000000,2015-12-11 11:19:20.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 6623}, {'_account_id': 8392}, {'_account_id': 8749}, {'_account_id': 8931}, {'_account_id': 8971}, {'_account_id': 10391}, {'_account_id': 11577}, {'_account_id': 14543}, {'_account_id': 18205}, {'_account_id': 18520}, {'_account_id': 19196}]","[{'number': 1, 'created': '2015-12-09 14:38:47.000000000', 'files': ['run_tests.sh'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/30f0f8007b10e9b25229d64cccd4a80d6c8cd8e8', 'message': 'Tox python env changed to py27 in run_tests.sh\n\nAfter moving to the CentOS 7 we have no python26 env.\n\nChange-Id: Ia9ad4438ebfd2f6c6cdc1aaebae4f52f96a333c7\nCloses-Bug: #1523397\n'}]",0,255288,30f0f8007b10e9b25229d64cccd4a80d6c8cd8e8,17,13,1,10959,,,0,"Tox python env changed to py27 in run_tests.sh

After moving to the CentOS 7 we have no python26 env.

Change-Id: Ia9ad4438ebfd2f6c6cdc1aaebae4f52f96a333c7
Closes-Bug: #1523397
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/88/255288/1 && git format-patch -1 --stdout FETCH_HEAD,['run_tests.sh'],1,30f0f8007b10e9b25229d64cccd4a80d6c8cd8e8,bug/1523397,TOXENV=${TOXENV:-py27},TOXENV=${TOXENV:-py26},1,1
openstack%2Foslo.messaging~stable%2Fliberty~Iee70ea7ff3816802195b29ba231fadddbe6159da,openstack/oslo.messaging,stable/liberty,Iee70ea7ff3816802195b29ba231fadddbe6159da,Fix reconnection when heartbeat is missed,MERGED,2015-12-04 14:13:39.000000000,2015-12-11 11:31:13.000000000,2015-12-11 11:31:08.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 9796}]","[{'number': 1, 'created': '2015-12-04 14:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8882e6b26505fc95c99a9926fe8362041d4b86d2', 'message': ""Fix reconnection when heartbeat is missed\n\nWhen a heartbeat is missing we call ensure_connection()\nthat runs a dummy method to trigger the reconnection\ncode in kombu. But also the code is triggered only if the\nchannel is None.\n\nIn case of the heartbeat threads we didn't reset the channel\nbefore reconnecting, so the dummy method doesn't do anything.\n\nThis change sets the channel to None to ensure the connection\nis reestablished before the dummy method is run.\n\nAlso it replaces the dummy method by checking the kombu connection\nobject. So we are sure the connection is reestablished.\n\nCloses-bug: #1493890\n(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)\n\nChange-Id: Iee70ea7ff3816802195b29ba231fadddbe6159da\n""}, {'number': 2, 'created': '2015-12-09 12:26:58.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/006b74a64223306d1871550156f8d73bc96a2cc7', 'message': ""Fix reconnection when heartbeat is missed\n\nWhen a heartbeat is missing we call ensure_connection()\nthat runs a dummy method to trigger the reconnection\ncode in kombu. But also the code is triggered only if the\nchannel is None.\n\nIn case of the heartbeat threads we didn't reset the channel\nbefore reconnecting, so the dummy method doesn't do anything.\n\nThis change sets the channel to None to ensure the connection\nis reestablished before the dummy method is run.\n\nAlso it replaces the dummy method by checking the kombu connection\nobject. So we are sure the connection is reestablished.\n\nCloses-bug: #1493890\n(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)\n\nDepends-On: Ibce834c3e76d71a770013cf1b469aa86396751b9\nChange-Id: Iee70ea7ff3816802195b29ba231fadddbe6159da\n""}]",0,253514,006b74a64223306d1871550156f8d73bc96a2cc7,9,3,2,2813,,,0,"Fix reconnection when heartbeat is missed

When a heartbeat is missing we call ensure_connection()
that runs a dummy method to trigger the reconnection
code in kombu. But also the code is triggered only if the
channel is None.

In case of the heartbeat threads we didn't reset the channel
before reconnecting, so the dummy method doesn't do anything.

This change sets the channel to None to ensure the connection
is reestablished before the dummy method is run.

Also it replaces the dummy method by checking the kombu connection
object. So we are sure the connection is reestablished.

Closes-bug: #1493890
(cherry picked from commit I39f8cd23c5a5498e6f4c1aa3236ed27f3b5d7c9a)

Depends-On: Ibce834c3e76d71a770013cf1b469aa86396751b9
Change-Id: Iee70ea7ff3816802195b29ba231fadddbe6159da
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/14/253514/2 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,8882e6b26505fc95c99a9926fe8362041d4b86d2,bug/1493890, # NOTE(sileht): we reset the channel and ensure # the kombu underlying connection works self._set_current_channel(None) self.ensure(method=lambda: self.connection.connection), self.ensure(method=lambda: True) self._set_current_channel(None),6,2
openstack%2Ftripleo-heat-templates~stable%2Fliberty~Idef3e1ed4e8e21b645081869b8d6fad2329bdc60,openstack/tripleo-heat-templates,stable/liberty,Idef3e1ed4e8e21b645081869b8d6fad2329bdc60,Allow customization of Ceph client user,MERGED,2015-11-26 01:29:21.000000000,2015-12-11 11:26:09.000000000,2015-12-11 11:26:03.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-11-26 01:29:21.000000000', 'files': ['os-apply-config/ceph-cluster-config.yaml', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'environments/puppet-ceph-external.yaml', 'puppet/hieradata/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/ceph-cluster-config.yaml', 'puppet/extraconfig/ceph/ceph-external-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ec00801eb356eb9cd78501b9c8f9a092a5b4ea62', 'message': ""Allow customization of Ceph client user\n\nPreviously we enforced the Ceph user used by the OpenStack clients\nto be named 'openstack', this change allows for customization\nof such a name.\n\nChange-Id: Idef3e1ed4e8e21b645081869b8d6fad2329bdc60\n(cherry picked from commit 9ea7831eaeadced1b5599b6ef1feb01d0cb6dca2)\n""}]",0,250106,ec00801eb356eb9cd78501b9c8f9a092a5b4ea62,11,4,1,6796,,,0,"Allow customization of Ceph client user

Previously we enforced the Ceph user used by the OpenStack clients
to be named 'openstack', this change allows for customization
of such a name.

Change-Id: Idef3e1ed4e8e21b645081869b8d6fad2329bdc60
(cherry picked from commit 9ea7831eaeadced1b5599b6ef1feb01d0cb6dca2)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/06/250106/1 && git format-patch -1 --stdout FETCH_HEAD,"['os-apply-config/ceph-cluster-config.yaml', 'puppet/manifests/overcloud_controller.pp', 'puppet/manifests/overcloud_compute.pp', 'environments/puppet-ceph-external.yaml', 'puppet/hieradata/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/ceph-cluster-config.yaml', 'puppet/extraconfig/ceph/ceph-external-config.yaml']",8,ec00801eb356eb9cd78501b9c8f9a092a5b4ea62,ceph, CephClientUserName: default: openstack type: string client.CLIENT_USER: { CLIENT_USER: {get_param: CephClientUserName} nova::compute::rbd::libvirt_rbd_user: {get_param: CephClientUserName} glance::backend::rbd::rbd_store_pool: {get_param: CephClientUserName} nova::compute::rbd::rbd_keyring: list_join: - '.' - - 'client' - {get_param: CephClientUserName} ceph_client_user_name: {get_param: CephClientUserName}, client.openstack: {,38,10
openstack%2Ftripleo-heat-templates~stable%2Fliberty~I1749d2a6547f6ce25843709e46a1447e8d42cfff,openstack/tripleo-heat-templates,stable/liberty,I1749d2a6547f6ce25843709e46a1447e8d42cfff,Allow customization of the Ceph pool names,MERGED,2015-11-26 01:28:32.000000000,2015-12-11 11:23:03.000000000,2015-12-11 11:23:02.000000000,"[{'_account_id': 3}, {'_account_id': 4328}, {'_account_id': 6796}]","[{'number': 1, 'created': '2015-11-26 01:28:32.000000000', 'files': ['os-apply-config/ceph-cluster-config.yaml', 'puppet/manifests/overcloud_controller.pp', 'environments/puppet-ceph-external.yaml', 'puppet/hieradata/ceph.yaml', 'puppet/hieradata/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/ceph-cluster-config.yaml', 'puppet/extraconfig/ceph/ceph-external-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c8a12e9a606460157c55ba2620fa547e16dc4fd9', 'message': 'Allow customization of the Ceph pool names\n\nThis is useful in those scenarios were we want to use an external\nCeph deployment with multiple overclouds.\n\nChange-Id: I1749d2a6547f6ce25843709e46a1447e8d42cfff\n(cherry picked from commit e19ae9dfe03e2868562ef090c455aa9e8c394d9e)\n'}]",0,250104,c8a12e9a606460157c55ba2620fa547e16dc4fd9,10,3,1,6796,,,0,"Allow customization of the Ceph pool names

This is useful in those scenarios were we want to use an external
Ceph deployment with multiple overclouds.

Change-Id: I1749d2a6547f6ce25843709e46a1447e8d42cfff
(cherry picked from commit e19ae9dfe03e2868562ef090c455aa9e8c394d9e)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/04/250104/1 && git format-patch -1 --stdout FETCH_HEAD,"['os-apply-config/ceph-cluster-config.yaml', 'puppet/manifests/overcloud_controller.pp', 'environments/puppet-ceph-external.yaml', 'puppet/hieradata/ceph.yaml', 'puppet/hieradata/compute.yaml', 'puppet/manifests/overcloud_controller_pacemaker.pp', 'puppet/ceph-cluster-config.yaml', 'puppet/extraconfig/ceph/ceph-external-config.yaml']",8,c8a12e9a606460157c55ba2620fa547e16dc4fd9,ceph," NovaRbdPoolName: default: vms type: string CinderRbdPoolName: default: volumes type: string GlanceRbdPoolName: default: images type: string cap_osd: 'allow class-read object_prefix rbd_children, allow rwx pool=CINDER_POOL, allow rwx pool=NOVA_POOL, allow rwx pool=GLANCE_POOL' NOVA_POOL: {get_param: NovaRbdPoolName} CINDER_POOL: {get_param: CinderRbdPoolName} GLANCE_POOL: {get_param: GlanceRbdPoolName} nova::compute::rbd::libvirt_images_rbd_pool: {get_param: NovaRbdPoolName} cinder_rbd_pool_name: {get_param: CinderRbdPoolName} glance::backend::rbd::rbd_store_pool: {get_param: GlanceRbdPoolName} ceph_pools: - {get_param: CinderRbdPoolName} - {get_param: NovaRbdPoolName} - {get_param: GlanceRbdPoolName}"," cap_osd: 'allow class-read object_prefix rbd_children, allow rwx pool=volumes, allow rwx pool=vms, allow rwx pool=images'",59,14
openstack%2Fnova~master~I26af2ff71df86754545c1dc329ad6ad5218d25d9,openstack/nova,master,I26af2ff71df86754545c1dc329ad6ad5218d25d9,Improve Filter Scheduler doc clarity,MERGED,2015-12-07 21:35:26.000000000,2015-12-11 11:07:58.000000000,2015-12-11 11:07:54.000000000,"[{'_account_id': 3}, {'_account_id': 7}, {'_account_id': 5170}, {'_account_id': 7166}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-07 21:35:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5701e2ebb9aab82120fccfa710337dabac55d055', 'message': 'Improve Filter Scheduler doc clarity\n\nMiscellaneous structural and grammatic adjustments to improve the\nclarity and readability of the Filter Scheduler doc. There are\ncertainly additional improvements that could be made (there always\nare) but these were obvious while doing a read through.\n\nChange-Id: I26af2ff71df86754545c1dc329ad6ad5218d25d9\n'}, {'number': 2, 'created': '2015-12-09 17:39:13.000000000', 'files': ['doc/source/filter_scheduler.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/6c94c12824d3b53e4d7e96aca98eabd99e08fe97', 'message': 'Improve Filter Scheduler doc clarity\n\nMiscellaneous structural and grammatic adjustments to improve the\nclarity and readability of the Filter Scheduler doc. There are\ncertainly additional improvements that could be made (there always\nare) but these were obvious while doing a read through.\n\nChange-Id: I26af2ff71df86754545c1dc329ad6ad5218d25d9\n'}]",4,254394,6c94c12824d3b53e4d7e96aca98eabd99e08fe97,19,8,2,11564,,,0,"Improve Filter Scheduler doc clarity

Miscellaneous structural and grammatic adjustments to improve the
clarity and readability of the Filter Scheduler doc. There are
certainly additional improvements that could be made (there always
are) but these were obvious while doing a read through.

Change-Id: I26af2ff71df86754545c1dc329ad6ad5218d25d9
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/254394/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/filter_scheduler.rst'],1,5701e2ebb9aab82120fccfa710337dabac55d055,cd/filter-doc-tidy,"working with Compute Nodes only.During its work Filter Scheduler first makes dictionaries of unfiltered hosts,If the Scheduler cannot find candidates for the next instance, it means that there are no appropriate hosts where that instance can be scheduled. The Filter Scheduler has to be quite flexible to support the required variety of `filtering` and `weighting` strategies. If this flexibility is insufficient you can implement `your own filtering algorithm`. There are many standard filter classes which may be used (:mod:`nova.scheduler.filters`): * |AllHostsFilter| - does no filtering. It passes all the available hosts. on the instance's image. It passes hosts that can support the properties specified on the image used by the instance. instance type. It passes hosts that can create the specified instance type. ignores the namespace. For example ``capabilities:cpu_info:features`` is a valid scope format. For backward compatibility, the filter also treats the extra specs key as the key to be matched if no namespace is present; this action is highly discouraged because it conflicts with is found for a host (meaning the host is in two different aggregates with is found for a host (meaning the host is in two different aggregates with ``disk_allocation_ratio`` setting. The virtual disk to physical disk allocation ratio, 1.0 by default. The total allowed allocated disk size will* |NumInstancesFilter| - filters hosts by number of running instances. Hosts with too many instances will be filtered. this host. The host will be ignored by the scheduler if more than ``max_instances_per_host`` already exist on the host.* |SimpleCIDRAffinityFilter| - allows a new instance on a host within* |DifferentHostFilter| - allows the instance on a different host from a ServerGroupAntiAffinityFilter. The difference is that when you create the serverNow we can focus on these standard filter classes in some detail. We'll skip the simplest ones, such as |AllHostsFilter|, |CoreFilter| and |RamFilter|, because their functionality is relatively simple and can be understood from theratio (it is ``1.5`` by default). The |AvailabilityZoneFilter| looks at the availability zone of compute nodeon each compute host. This class's method ``host_passes`` returns ``True`` ifhypervisor type and virtual machine mode specified in the instance. For example, an instance might require a host that supports the ARM architecture on a qemu compute host. The |ImagePropertiesFilter| will only pass hosts that can satisfy this request. These instance properties are populated from properties defined on the instance's image.images to run on the isolated hosts are also called isolated. The filteras the host. Isolated hosts can run non isolated images if the flag|DifferentHostFilter| - method ``host_passes`` returns ``True`` if the host to place an instance on is different from all the hosts used by a set of instances. |SameHostFilter| does the opposite to what |DifferentHostFilter| does. ``host_passes`` returns ``True`` if the host we want to place an instance on is one of the hosts used by a set of instances.logical operations: ``not``, ``or``, ``and``. For example, the following query can be found in tests:To use filters you specify two settings: scheduler. This setting can be used multiple times.To create **your own filter** you must inherit from |BaseHostFilter| and implement one method: ``host_passes``. This method should return ``True`` if a host passes the filter. It takes ``host_state`` (describing the host) and ``filter_properties`` dictionary as theFilter Scheduler uses the so-called **weights** during its work. A weigher is aimplement the ``weight_multiplier`` and ``weight_objects`` methods. If the* |RAMWeigher| Compute weight based on available RAM on the compute node. Sort with the largest weight winning. If the multiplier is negative, the host with least RAM available will win (useful for stacking hosts, instead of spreading).Filter Scheduler makes a local list of acceptable hosts by repeated filtering andasks for a large block of instances, because weight is computed forAt the end Filter Scheduler sorts selected hosts by their weight and attempts to provision instances on the chosen hosts.in :mod:`nova.tests.scheduler`.","only working with Compute Nodes.During its work Filter Scheduler firstly makes dictionary of unfiltered hosts,If it turns up, that it can't find candidates for the next instance, it means that there are no more appropriate hosts where the instance could be scheduled. If we speak about `filtering` and `weighting`, their work is quite flexible in the Filter Scheduler. There are a lot of filtering strategies for the Scheduler to support. Also you can even implement `your own algorithm of filtering`. There are some standard filter classes to use (:mod:`nova.scheduler.filters`): * |AllHostsFilter| - frankly speaking, this filter does no operation. It passes all the available hosts. on the instance's image. It passes hosts that can support the specified image properties contained in the instance. instance type. It passes hosts that can create the specified instance type. ignores the namespace. Example like ``capabilities:cpu_info:features`` is a valid scope format. For backward compatibility, also treats the extra specs key as the key to be matched if no namespace is present; this action is highly discouraged because it conflicts with is found for a host (meaning the host is in two different aggregate with is found for a host (meaning the host is in two different aggregate with ``disk_allocation_ratio`` setting. It's virtual disk to physical disk allocation ratio and it's 1.0 by default. The total allow allocated disk size will* |NumInstancesFilter| - filters hosts by number of running instances on it. hosts with too many instances will be filtered. this host, the host will be ignored by scheduler if more than ``max_instances_per_host`` are already existing on the host.* |SimpleCIDRAffinityFilter| - allows to put a new instance on a host within* |DifferentHostFilter| - allows to put the instance on a different host from a ServerGroupAntiAffinityFilter. The difference is that when you create the serverNow we can focus on these standard filter classes in details. I will pass the simplest ones, such as |AllHostsFilter|, |CoreFilter| and |RamFilter| are, because their functionality is quite simple and can be understood just from theratio (it is ``1.5`` by default). Really, nice and simple. Next standard filter to describe is |AvailabilityZoneFilter| and it isn't difficult too. This filter just looks at the availability zone of compute nodeon each compute host. This classes method ``host_passes`` returns ``True`` ifhypervisor type, and virtual machine mode specified in the instance. E.g., an instance might require a host that supports the arm architecture on a qemu compute host. The |ImagePropertiesFilter| will only pass hosts that can satisfy this request. These instance properties are populated from properties define on the instance's image.images to run on the isolated hosts are also called isolated. This Schedulerthat the host has. Isolated hosts can run non isolated images if the flag|DifferentHostFilter| - its method ``host_passes`` returns ``True`` if host to place instance on is different from all the hosts used by set of instances. |SameHostFilter| does the opposite to what |DifferentHostFilter| does. So its ``host_passes`` returns ``True`` if the host we want to place instance on is one of the set of instances uses.logical operations: ``not``, ``or``, ``and``. For example, there is the query you can find in tests:To use filters you specify next two settings: scheduler. This setting can be used multiple times.If you want to create **your own filter** you just need to inherit from |BaseHostFilter| and implement one method: ``host_passes``. This method should return ``True`` if host passes the filter. It takes ``host_state`` (describes host) and ``filter_properties`` dictionary as theFilter Scheduler uses the so called **weights** during its work. A weigher is aimplement the ``weight_multiplier`` and ``weight_object`` methods. If the* |RAMWeigher| Hosts are then weighted and sorted with the largest weight winning. If the multiplier is negative, the host with less RAM available will win (useful for stacking hosts, instead of spreading).Filter Scheduler finds local list of acceptable hosts by repeated filtering andasks for the some large amount of instances, because weight is computed forIn the end Filter Scheduler sorts selected hosts by their weight and provisions instances on them.in :mod:``nova.tests.scheduler``.",64,65
openstack%2Fswift~master~Ia6c14377e5dd768a5306a2448f0bf244ebc3634e,openstack/swift,master,Ia6c14377e5dd768a5306a2448f0bf244ebc3634e,fix mock and assert in test_direct_client,MERGED,2015-12-07 18:19:59.000000000,2015-12-11 11:05:44.000000000,2015-12-11 11:05:42.000000000,"[{'_account_id': 3}, {'_account_id': 1179}, {'_account_id': 2622}, {'_account_id': 4608}, {'_account_id': 13052}]","[{'number': 1, 'created': '2015-12-07 18:19:59.000000000', 'files': ['test/unit/common/test_direct_client.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/62b9a0eeeaeb3a5a0daff981cf6fa1cb50e78a50', 'message': 'fix mock and assert in test_direct_client\n\nChange-Id: Ia6c14377e5dd768a5306a2448f0bf244ebc3634e\n'}]",1,254341,62b9a0eeeaeb3a5a0daff981cf6fa1cb50e78a50,10,5,1,1179,,,0,"fix mock and assert in test_direct_client

Change-Id: Ia6c14377e5dd768a5306a2448f0bf244ebc3634e
",git fetch https://review.opendev.org/openstack/swift refs/changes/41/254341/1 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/common/test_direct_client.py'],1,62b9a0eeeaeb3a5a0daff981cf6fa1cb50e78a50,," if isinstance(self.body, six.StringIO): elif amt is None: return self.body self.assertEqual(obj_body, contents.getvalue())"," if amt is None: return self.body elif isinstance(self.body, six.StringIO): self.assertEqual(obj_body, contents)",4,4
openstack%2Fmanila-ui~master~Ic121ac52d261b1f4eb972a0075cd3a09883fb100,openstack/manila-ui,master,Ic121ac52d261b1f4eb972a0075cd3a09883fb100,Remove import of unnecessary modules from Horizon,MERGED,2015-12-10 11:19:31.000000000,2015-12-11 11:05:26.000000000,2015-12-10 17:41:27.000000000,"[{'_account_id': 3}, {'_account_id': 5623}, {'_account_id': 6491}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11047}, {'_account_id': 11865}, {'_account_id': 14232}]","[{'number': 1, 'created': '2015-12-10 11:19:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/4a7de1fbac354c0ee07d8c6946206b21e50705ef', 'message': 'Remove import of unnecessary modules from Horizon\n\nManila UI tests import modules with test data for lots of projects.\nIt is unnecessary and should be removed.\nOne of such unnecessary modules was removed from Horizon and unit tests\nare broken because of it. So, remove breaking one and all other unused.\n\nChange-Id: Ic121ac52d261b1f4eb972a0075cd3a09883fb100\nCloses-Bug: #1524735\n'}, {'number': 2, 'created': '2015-12-10 11:29:44.000000000', 'files': ['manila_ui/test/test_data/utils.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/ef8bf7bcb9aee5355f998aeb62f674ad9f12e9eb', 'message': 'Remove import of unnecessary modules from Horizon\n\nManila UI tests import modules with test data for lots of projects.\nIt is unnecessary and should be removed.\nOne of such unnecessary modules was removed from Horizon and unit tests\nare broken because of it. So, remove breaking one and all other unused.\n\nChange-Id: Ic121ac52d261b1f4eb972a0075cd3a09883fb100\nCloses-Bug: #1524735\n'}]",0,255800,ef8bf7bcb9aee5355f998aeb62f674ad9f12e9eb,14,8,2,8851,,,0,"Remove import of unnecessary modules from Horizon

Manila UI tests import modules with test data for lots of projects.
It is unnecessary and should be removed.
One of such unnecessary modules was removed from Horizon and unit tests
are broken because of it. So, remove breaking one and all other unused.

Change-Id: Ic121ac52d261b1f4eb972a0075cd3a09883fb100
Closes-Bug: #1524735
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/00/255800/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_ui/test/test_data/utils.py'],1,4a7de1fbac354c0ee07d8c6946206b21e50705ef,bug/1524735,," from openstack_dashboard.test.test_data import ceilometer_data from openstack_dashboard.test.test_data import cinder_data from openstack_dashboard.test.test_data import glance_data from openstack_dashboard.test.test_data import heat_data from openstack_dashboard.test.test_data import neutron_data from openstack_dashboard.test.test_data import sahara_data from openstack_dashboard.test.test_data import swift_data from openstack_dashboard.test.test_data import trove_data glance_data.data, nova_data.data, cinder_data.data, neutron_data.data, swift_data.data, heat_data.data, ceilometer_data.data, trove_data.data, sahara_data.data,",0,17
openstack%2Ffuel-main~master~I3956be2b24309864e308069865b461f0df1708e1,openstack/fuel-main,master,I3956be2b24309864e308069865b461f0df1708e1,Update fuel packages list,MERGED,2015-12-09 09:34:47.000000000,2015-12-11 11:02:31.000000000,2015-12-11 11:02:31.000000000,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8777}, {'_account_id': 10288}, {'_account_id': 10474}, {'_account_id': 12817}]","[{'number': 1, 'created': '2015-12-09 09:34:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/40a73b849850bd9bedc3c5156f27c4381c14c55d', 'message': 'Update fuel packages list\n\n* Align packages list with CentOS 7\n* Update packages regarding fuel-craetemirror deprecation\n* Add late artifacts\n\nRelated-bug: #1460480\n\nChange-Id: I3956be2b24309864e308069865b461f0df1708e1\n'}, {'number': 2, 'created': '2015-12-10 11:26:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/c2fad4d1c81faabccc879d27302acaddafdeb4fe', 'message': 'Update fuel packages list\n\n* Align packages list with CentOS 7\n* Update packages regarding fuel-craetemirror deprecation\n* Add late artifacts\n\nRelated-bug: #1460480\n\nChange-Id: I3956be2b24309864e308069865b461f0df1708e1\n'}, {'number': 3, 'created': '2015-12-11 11:00:06.000000000', 'files': ['requirements-fuel-rpm.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b34032b520ee57ddc8b0f88637089c7fd12ae379', 'message': 'Update fuel packages list\n\n* Align packages list with CentOS 7\n* Update packages regarding fuel-craetemirror deprecation\n* Add late artifacts\n\nRelated-bug: #1460480\n\nChange-Id: I3956be2b24309864e308069865b461f0df1708e1\n'}]",2,255157,b34032b520ee57ddc8b0f88637089c7fd12ae379,19,6,3,12817,,,0,"Update fuel packages list

* Align packages list with CentOS 7
* Update packages regarding fuel-craetemirror deprecation
* Add late artifacts

Related-bug: #1460480

Change-Id: I3956be2b24309864e308069865b461f0df1708e1
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/57/255157/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-fuel-rpm.txt'],1,40a73b849850bd9bedc3c5156f27c4381c14c55d,,fuel-bootstrap-imagefuel-docker-imagespython-packetary rubygem-astute,ruby21-nailgun-mcagents ruby21-rubygem-astute,4,2
openstack%2Fnetworking-bgpvpn~master~I8769b0b135d9c9108475a4366c53266787228beb,openstack/networking-bgpvpn,master,I8769b0b135d9c9108475a4366c53266787228beb,Fix RT/RD validation,MERGED,2015-12-11 10:40:15.000000000,2015-12-11 11:01:26.000000000,2015-12-11 11:01:24.000000000,"[{'_account_id': 3}, {'_account_id': 2888}]","[{'number': 1, 'created': '2015-12-11 10:40:15.000000000', 'files': ['networking_bgpvpn/tests/unit/extensions/test_bgpvpn.py', 'networking_bgpvpn/neutron/extensions/bgpvpn.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/5b530c24da811957548cf01d28e94dbafd8db558', 'message': 'Fix RT/RD validation\n\nThis change fixes the RT/RD validation code:\n- use the same validation function for route_targets than\n  the one used for import_rts and export_rts\n- allow an empty value without allowing everything\n  (_validate_rt_list_or_none was accepting anything non-empty)\n- add unit tests testing the validation of the four RT/RD fields\n\nChange-Id: I8769b0b135d9c9108475a4366c53266787228beb\nCloses-Bug: 1524169\n'}]",0,256330,5b530c24da811957548cf01d28e94dbafd8db558,6,2,1,12021,,,0,"Fix RT/RD validation

This change fixes the RT/RD validation code:
- use the same validation function for route_targets than
  the one used for import_rts and export_rts
- allow an empty value without allowing everything
  (_validate_rt_list_or_none was accepting anything non-empty)
- add unit tests testing the validation of the four RT/RD fields

Change-Id: I8769b0b135d9c9108475a4366c53266787228beb
Closes-Bug: 1524169
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/30/256330/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_bgpvpn/tests/unit/extensions/test_bgpvpn.py', 'networking_bgpvpn/neutron/extensions/bgpvpn.py']",2,5b530c24da811957548cf01d28e94dbafd8db558,bug/1524169," if data is None or data is """": return validators = {'type:route_target_list': _validate_rt_list} 'validate': {'type:route_target_list': None}, 'validate': {'type:route_target_list': None}, 'validate': {'type:route_target_list': None},"," def _validate_rt_list_or_none(data, valid_values=None): if not data: return _validate_rt_list(data, valid_values=valid_values) validators = {'type:route_target_list': _validate_rt_list, 'type:route_target_list_or_none': _validate_rt_list_or_none} 'validate': {'type:route_target_list_or_none': None}, 'validate': {'type:route_target_list_or_none': None}, 'validate': {'type:route_target_list_or_none': None},",38,34
openstack%2Ffreezer~master~I92e99c087cb2c2f836770644621f711af597dffc,openstack/freezer,master,I92e99c087cb2c2f836770644621f711af597dffc,Switch freezer-scheduler to oslo.config and oslo.log switch freezer-scheduler to use oslo.config and switch from native python logging module to oslo.log This commit includes: - using oslo.config for parsing cli and config files options - using oslo.log instead of native python logging module - this applied only on freezer-scheduler Implements: blueprint using-oslo-libs,MERGED,2015-12-02 19:31:25.000000000,2015-12-11 10:53:18.000000000,2015-12-11 10:53:18.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14123}, {'_account_id': 14159}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 15358}, {'_account_id': 17130}]","[{'number': 1, 'created': '2015-12-02 19:31:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e30b1bedf57aa8fbdcf18c92d43ce84633ebad47', 'message': 'Switch freezer-scheduler to oslo.config and oslo.log\nswitch freezer-scheduler to use oslo.config and\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n- this applied only on freezer-scheduler\nImplements: blueprint using-oslo-libs\n\nChange-Id: I92e99c087cb2c2f836770644621f711af597dffc\n'}, {'number': 2, 'created': '2015-12-04 16:24:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/46071f6d15b60aede06d4c107652176fc4778071', 'message': 'Switch freezer-scheduler to oslo.config and oslo.log\nswitch freezer-scheduler to use oslo.config and\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n- this applied only on freezer-scheduler\nImplements: blueprint using-oslo-libs\n\nChange-Id: I92e99c087cb2c2f836770644621f711af597dffc\n'}, {'number': 3, 'created': '2015-12-10 12:41:45.000000000', 'files': ['freezer/scheduler/arguments.py', 'tests/test_apiclient_client.py', 'freezer/apiclient/client.py', 'requirements.txt', 'freezer/scheduler/freezer_scheduler.py', 'tests/test_scheduler_arguments.py', 'freezer/__init__.py', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/freezer/commit/095142c40d00746c3d45e9cceac90b85022bfbbb', 'message': 'Switch freezer-scheduler to oslo.config and oslo.log\nswitch freezer-scheduler to use oslo.config and\nswitch from native python logging module to oslo.log\nThis commit includes:\n- using oslo.config for parsing cli and config files options\n- using oslo.log instead of native python logging module\n- this applied only on freezer-scheduler\nImplements: blueprint using-oslo-libs\n\nChange-Id: I92e99c087cb2c2f836770644621f711af597dffc\n'}]",7,252568,095142c40d00746c3d45e9cceac90b85022bfbbb,23,9,3,13940,,,0,"Switch freezer-scheduler to oslo.config and oslo.log
switch freezer-scheduler to use oslo.config and
switch from native python logging module to oslo.log
This commit includes:
- using oslo.config for parsing cli and config files options
- using oslo.log instead of native python logging module
- this applied only on freezer-scheduler
Implements: blueprint using-oslo-libs

Change-Id: I92e99c087cb2c2f836770644621f711af597dffc
",git fetch https://review.opendev.org/openstack/freezer refs/changes/68/252568/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer/scheduler/arguments.py', 'tests/test_apiclient_client.py', 'freezer/apiclient/client.py', 'requirements.txt', 'freezer/scheduler/freezer_scheduler.py', 'tests/test_scheduler_arguments.py', 'HACKING.rst']",7,e30b1bedf57aa8fbdcf18c92d43ce84633ebad47,bp/using-oslo-libs,"Freezer Style Commandments =========================== - Step 1: Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/ - Step 2: Read on Freezer Specific Commandments ------------------------------ Logging ------- Use the common logging module, and ensure you ``getLogger``:: from oslo_log import log LOG = log.getLogger(__name__) LOG.debug('Foobar') ",,235,233
openstack%2Fgnocchi~master~I721519e43790ae56d038ef4732cc38a4bfc39ba6,openstack/gnocchi,master,I721519e43790ae56d038ef4732cc38a4bfc39ba6,influxdb: avoid running first query if unnecessary,MERGED,2015-12-07 14:54:32.000000000,2015-12-11 10:52:40.000000000,2015-12-11 10:52:37.000000000,"[{'_account_id': 3}, {'_account_id': 1669}, {'_account_id': 6537}, {'_account_id': 8358}]","[{'number': 1, 'created': '2015-12-07 14:54:32.000000000', 'files': ['gnocchi/storage/influxdb.py'], 'web_link': 'https://opendev.org/openstack/gnocchi/commit/86dd58c00d9fe3d5b7cb7f5bf49cf445c72b1da6', 'message': 'influxdb: avoid running first query if unnecessary\n\nChange-Id: I721519e43790ae56d038ef4732cc38a4bfc39ba6\n'}]",0,254234,86dd58c00d9fe3d5b7cb7f5bf49cf445c72b1da6,14,4,1,1669,,,0,"influxdb: avoid running first query if unnecessary

Change-Id: I721519e43790ae56d038ef4732cc38a4bfc39ba6
",git fetch https://review.opendev.org/openstack/gnocchi refs/changes/34/254234/1 && git format-patch -1 --stdout FETCH_HEAD,['gnocchi/storage/influxdb.py'],1,86dd58c00d9fe3d5b7cb7f5bf49cf445c72b1da6,jd/fix-influxdb-tests," result = self._query(metric, ""select * from \""%(metric_id)s\"""" % dict(metric_id=metric_id)) result = list(result[metric_id])"," result = self._query(metric, ""select * from \""%(metric_id)s\"""" % dict(metric_id=metric_id)) result = list(result[metric_id]) ",3,4
openstack%2Ffuel-octane~stable%2F7.0~I4fcefae2051221ad220c0cb70226083060c5aa23,openstack/fuel-octane,stable/7.0,I4fcefae2051221ad220c0cb70226083060c5aa23,Add functions to set/unset upgrade_levels for compute service,MERGED,2015-12-10 19:36:21.000000000,2015-12-11 10:50:25.000000000,2015-12-11 10:50:24.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}]","[{'number': 1, 'created': '2015-12-10 19:36:21.000000000', 'files': ['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/magic_consts.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/b580f785cd0c27f1746fa441d6360dc98580c4eb', 'message': 'Add functions to set/unset upgrade_levels for compute service\n\nThese functions set and unset upgrade_levels for the compute service\nin nova.conf file. It will be used to handle rolling upgrade of compute\nnodes as well as the cleanup of nova.conf once upgrade is finished.\n\nRelated-bug: #1506041\nCo-Authored-By: Ilya Kharin <akscram@gmail.com>\nChange-Id: I4fcefae2051221ad220c0cb70226083060c5aa23\n(cherry picked from commit a17dba4c839318b4b36f447d134f4bea28213400)\n'}]",0,256068,b580f785cd0c27f1746fa441d6360dc98580c4eb,6,3,1,6677,,,0,"Add functions to set/unset upgrade_levels for compute service

These functions set and unset upgrade_levels for the compute service
in nova.conf file. It will be used to handle rolling upgrade of compute
nodes as well as the cleanup of nova.conf once upgrade is finished.

Related-bug: #1506041
Co-Authored-By: Ilya Kharin <akscram@gmail.com>
Change-Id: I4fcefae2051221ad220c0cb70226083060c5aa23
(cherry picked from commit a17dba4c839318b4b36f447d134f4bea28213400)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/68/256068/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/tests/test_util_node.py', 'octane/util/node.py', 'octane/magic_consts.py']",3,b580f785cd0c27f1746fa441d6360dc98580c4eb,,"VERSIONS = { '7.0': 'kilo', '6.1': 'juno', '6.0': 'juno', '5.2.9': 'icehouse', '5.1.1': 'icehouse', '5.1': 'icehouse', }",,71,0
openstack%2Foslo.messaging~stable%2Fkilo~Ie9d47fc357e03dd095f2b3844282ac5b680d9a25,openstack/oslo.messaging,stable/kilo,Ie9d47fc357e03dd095f2b3844282ac5b680d9a25,Move to debug a too verbose log,ABANDONED,2015-12-11 10:43:43.000000000,2015-12-11 10:49:47.000000000,,[],"[{'number': 1, 'created': '2015-12-11 10:43:43.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/fc84a95661d9414d48d325ac6470b790a12f3fa7', 'message': 'Move to debug a too verbose log\n\nWhen a client is gone (died/restart) and somes replies cannot be sent because\nthe the exchange of this client will never comeback. We log one message per\nreply every 0.25 messages during 60 seconds. When the only useful log\nis the one where we decide to drop this replies.\n\nThis change moves the less important message to debug level.\n\nChange-Id: Ie9d47fc357e03dd095f2b3844282ac5b680d9a25\n(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)\nRelated-bug: #1524418\n'}]",0,256331,fc84a95661d9414d48d325ac6470b790a12f3fa7,2,0,1,2813,,,0,"Move to debug a too verbose log

When a client is gone (died/restart) and somes replies cannot be sent because
the the exchange of this client will never comeback. We log one message per
reply every 0.25 messages during 60 seconds. When the only useful log
is the one where we decide to drop this replies.

This change moves the less important message to debug level.

Change-Id: Ie9d47fc357e03dd095f2b3844282ac5b680d9a25
(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)
Related-bug: #1524418
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/31/256331/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/amqpdriver.py'],1,fc84a95661d9414d48d325ac6470b790a12f3fa7,bug/1524418," LOG.debug((""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})"," LOG.info(_LI(""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})",5,5
openstack%2Foslo.messaging~stable%2Fliberty~Ic8cec93b6f93363720e4c8dfa407769c29616009,openstack/oslo.messaging,stable/liberty,Ic8cec93b6f93363720e4c8dfa407769c29616009,Move to debug a too verbose log,ABANDONED,2015-12-11 10:35:40.000000000,2015-12-11 10:49:43.000000000,,[],"[{'number': 1, 'created': '2015-12-11 10:35:40.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/e76506b84cf4ba3083edbe815181527697ef532c', 'message': 'Move to debug a too verbose log\n\nWhen a client is gone (died/restart) and somes replies cannot be sent because\nthe the exchange of this client will never comeback. We log one message per\nreply every 0.25 messages during 60 seconds. When the only useful log\nis the one where we decide to drop this replies.\n\nThis change moves the less important message to debug level.\n\nChange-Id: Ic8cec93b6f93363720e4c8dfa407769c29616009\n(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)\nRelated-bug: #1524418\n'}]",0,256327,e76506b84cf4ba3083edbe815181527697ef532c,2,0,1,2813,,,0,"Move to debug a too verbose log

When a client is gone (died/restart) and somes replies cannot be sent because
the the exchange of this client will never comeback. We log one message per
reply every 0.25 messages during 60 seconds. When the only useful log
is the one where we decide to drop this replies.

This change moves the less important message to debug level.

Change-Id: Ic8cec93b6f93363720e4c8dfa407769c29616009
(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)
Related-bug: #1524418
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/27/256327/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/amqpdriver.py'],1,e76506b84cf4ba3083edbe815181527697ef532c,bug/1524418," LOG.debug((""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})"," LOG.info(_LI(""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})",5,5
openstack%2Ffreezer~master~I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8,openstack/freezer,master,I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8,Fix typo: my scheduled backup 6 => schedule_backups 6,MERGED,2015-12-01 08:49:23.000000000,2015-12-11 10:49:31.000000000,2015-12-11 10:49:30.000000000,"[{'_account_id': 3}, {'_account_id': 358}, {'_account_id': 10068}, {'_account_id': 11151}, {'_account_id': 13111}, {'_account_id': 14509}, {'_account_id': 15358}, {'_account_id': 16522}, {'_account_id': 17104}]","[{'number': 1, 'created': '2015-12-01 08:49:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/b1a38ad52f6d05fd772ac67ba9adf361ef17012d', 'message': 'Fix typo: my scheduled backup 6 => schedule_backups 6\nIt was corrected because the contents of test_job.json\nwere different from a result.\n\nChange-Id: I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8\n'}, {'number': 2, 'created': '2015-12-02 09:31:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/ec849af32dca6731701e1ba1131797c2f5a1103d', 'message': 'Fix typo: my scheduled backup 6 => schedule_backups 6\nIt was corrected because the contents of test_job.json\nwere different from a result.\n\nChange-Id: I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8\n'}, {'number': 3, 'created': '2015-12-04 05:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer/commit/e56f89e76c404d15776ef36b597978f063c49476', 'message': 'Fix typo: my scheduled backup 6 => schedule_backups 6\n\nIt was corrected because the contents of test_job.json\nwere different from a result.\n\nChange-Id: I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8\n'}, {'number': 4, 'created': '2015-12-04 17:08:02.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/freezer/commit/7939993856930755d314ad4ad328463c7b264fe7', 'message': 'Fix typo: my scheduled backup 6 => schedule_backups 6\n\nIt was corrected because the contents of test_job.json\nwere different from a result.\n\nChange-Id: I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8\n'}]",2,251710,7939993856930755d314ad4ad328463c7b264fe7,21,9,4,16522,,,0,"Fix typo: my scheduled backup 6 => schedule_backups 6

It was corrected because the contents of test_job.json
were different from a result.

Change-Id: I5f7ac5a4a5e4420458ec82b40a3e12f96a8380a8
",git fetch https://review.opendev.org/openstack/freezer refs/changes/10/251710/3 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,b1a38ad52f6d05fd772ac67ba9adf361ef17012d,typo," ""description"": ""scheduled backup 6"""," ""description"": ""my scheduled backup 6""",1,1
openstack%2Fmanila-ui~master~I8c8287899f7659273f6768f3c441aa48904dfc74,openstack/manila-ui,master,I8c8287899f7659273f6768f3c441aa48904dfc74,Fix call to Client() with 2 api_version args,MERGED,2015-12-09 21:47:51.000000000,2015-12-11 10:48:46.000000000,2015-12-10 18:06:37.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 7102}, {'_account_id': 8851}, {'_account_id': 11865}]","[{'number': 1, 'created': '2015-12-09 21:47:51.000000000', 'files': ['manila_ui/api/manila.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/2ec35ef8ff3161c104eee2c5f99efd0c407bbc21', 'message': 'Fix call to Client() with 2 api_version args\n\nThe Client() uses api_version as the positional\nparameter, so also sending the api_version as a kwarg\ncauses a python error. The log shows this ""recoverable""\nerror, but the UI becomes unusable.\n\nRecoverable error: Client() got multiple values for\nkeyword argument \'api_version\'\n\nChange-Id: I8c8287899f7659273f6768f3c441aa48904dfc74\nCloses-Bug: #1524508\n'}]",0,255541,2ec35ef8ff3161c104eee2c5f99efd0c407bbc21,11,5,1,11047,,,0,"Fix call to Client() with 2 api_version args

The Client() uses api_version as the positional
parameter, so also sending the api_version as a kwarg
causes a python error. The log shows this ""recoverable""
error, but the UI becomes unusable.

Recoverable error: Client() got multiple values for
keyword argument 'api_version'

Change-Id: I8c8287899f7659273f6768f3c441aa48904dfc74
Closes-Bug: #1524508
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/41/255541/1 && git format-patch -1 --stdout FETCH_HEAD,['manila_ui/api/manila.py'],1,2ec35ef8ff3161c104eee2c5f99efd0c407bbc21,bug/1524508,," api_version=MANILA_VERSION,",0,1
openstack%2Ffuel-octane~stable%2F7.0~Iae6223c5b4b0ba78519f76cb86aba2c9e1b90517,openstack/fuel-octane,stable/7.0,Iae6223c5b4b0ba78519f76cb86aba2c9e1b90517,Use node util functions to manage upgrade_levels,MERGED,2015-12-10 19:02:33.000000000,2015-12-11 10:48:18.000000000,2015-12-11 10:48:17.000000000,"[{'_account_id': 3}, {'_account_id': 708}, {'_account_id': 6677}]","[{'number': 1, 'created': '2015-12-10 19:02:33.000000000', 'files': ['octane/handlers/upgrade/compute.py', 'octane/handlers/upgrade/controller.py', 'octane/commands/cleanup.py'], 'web_link': 'https://opendev.org/openstack/fuel-octane/commit/92d080d55098ab0ec0dd320a77fd0e247ecd3d08', 'message': ""Use node util functions to manage upgrade_levels\n\nReplace upgrade_levels set logic with call to node util function\n'add_compute_upgrade_levels'.\nAdd 'remove_compute_upgrade_levels' operation for every node to\n'cleanup' command.\n\nCloses-bug: 1506041\nChange-Id: Iae6223c5b4b0ba78519f76cb86aba2c9e1b90517\n(cherry picked from commit 9acebae050b87629e5e4840bb8c36812877fc249)\n""}]",0,256058,92d080d55098ab0ec0dd320a77fd0e247ecd3d08,6,3,1,6677,,,0,"Use node util functions to manage upgrade_levels

Replace upgrade_levels set logic with call to node util function
'add_compute_upgrade_levels'.
Add 'remove_compute_upgrade_levels' operation for every node to
'cleanup' command.

Closes-bug: 1506041
Change-Id: Iae6223c5b4b0ba78519f76cb86aba2c9e1b90517
(cherry picked from commit 9acebae050b87629e5e4840bb8c36812877fc249)
",git fetch https://review.opendev.org/openstack/fuel-octane refs/changes/58/256058/1 && git format-patch -1 --stdout FETCH_HEAD,"['octane/handlers/upgrade/compute.py', 'octane/handlers/upgrade/controller.py', 'octane/commands/cleanup.py']",3,92d080d55098ab0ec0dd320a77fd0e247ecd3d08,,from octane.util import node as node_util nodes = env.get_all_nodes() for node in nodes: node_util.remove_compute_upgrade_levels(node) ,,14,14
openstack%2Frequirements~master~I44235a4596c944171e391a07287bc9b0c960c3f8,openstack/requirements,master,I44235a4596c944171e391a07287bc9b0c960c3f8,Updated from generate-constraints,MERGED,2015-12-11 06:34:44.000000000,2015-12-11 10:43:33.000000000,2015-12-11 10:43:33.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6854}, {'_account_id': 10873}]","[{'number': 1, 'created': '2015-12-11 06:34:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1d2d925f9b57ff26a0ebcbac9148e62159875d91', 'message': 'Updated from generate-constraints\n\nChange-Id: I44235a4596c944171e391a07287bc9b0c960c3f8\n'}]",2,256238,1d2d925f9b57ff26a0ebcbac9148e62159875d91,9,4,1,11131,,,0,"Updated from generate-constraints

Change-Id: I44235a4596c944171e391a07287bc9b0c960c3f8
",git fetch https://review.opendev.org/openstack/requirements refs/changes/38/256238/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,1d2d925f9b57ff26a0ebcbac9148e62159875d91,openstack/requirements/constraints,cryptography===1.1.2decorator===4.0.6diskimage-builder===1.5.0notifier===1.0.2openstackdocstheme===1.2.6 openstacksdk===0.7.2python-swiftclient===2.7.0,cryptography===1.1.1decorator===4.0.5diskimage-builder===1.4.0notifier===1.0.1openstackdocstheme===1.2.5 openstacksdk===0.7.1python-swiftclient===2.6.0,7,7
openstack%2Ffreezer~master~I7908520f6e2935ffacf5d914a01078939392e2e2,openstack/freezer,master,I7908520f6e2935ffacf5d914a01078939392e2e2,Delete python bytecode before every test run,MERGED,2015-12-07 07:44:49.000000000,2015-12-11 10:35:39.000000000,2015-12-11 10:35:39.000000000,"[{'_account_id': 3}, {'_account_id': 11151}, {'_account_id': 13111}, {'_account_id': 14340}, {'_account_id': 15358}]","[{'number': 1, 'created': '2015-12-07 07:44:49.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/freezer/commit/623f08928eeba3e523850018813b17dad8c51870', 'message': 'Delete python bytecode before every test run\n\nBecause python creates pyc files during tox runs, certain\nchanges in the tree, like deletes of files, or switching\nbranches, can create spurious errors.\n\nChange-Id: I7908520f6e2935ffacf5d914a01078939392e2e2\nCloses-Bug: #1368661\n'}]",0,254050,623f08928eeba3e523850018813b17dad8c51870,9,5,1,17104,,,0,"Delete python bytecode before every test run

Because python creates pyc files during tox runs, certain
changes in the tree, like deletes of files, or switching
branches, can create spurious errors.

Change-Id: I7908520f6e2935ffacf5d914a01078939392e2e2
Closes-Bug: #1368661
",git fetch https://review.opendev.org/openstack/freezer refs/changes/50/254050/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,623f08928eeba3e523850018813b17dad8c51870,bug/1368661," find find . -type f -name ""*.pyc"" -delete",,2,0
openstack%2Foslo.messaging~stable%2Fliberty~I491e0d5dad7406859e762b53859790289e7cd626,openstack/oslo.messaging,stable/liberty,I491e0d5dad7406859e762b53859790289e7cd626,Move to debug a too verbose log,ABANDONED,2015-12-11 10:32:45.000000000,2015-12-11 10:35:20.000000000,,[],"[{'number': 1, 'created': '2015-12-11 10:32:45.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a9899d9266bd2c2e3ff366dd934d75671120fc89', 'message': 'Move to debug a too verbose log\n\nWhen a client is gone (died/restart) and somes replies cannot be sent because\nthe the exchange of this client will never comeback. We log one message per\nreply every 0.25 messages during 60 seconds. When the only useful log\nis the one where we decide to drop this replies.\n\nThis change moves the less important message to debug level.\n\nChange-Id: I491e0d5dad7406859e762b53859790289e7cd626\nn(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)\nRelated-bug: #1524418\n'}]",0,256325,a9899d9266bd2c2e3ff366dd934d75671120fc89,2,0,1,2813,,,0,"Move to debug a too verbose log

When a client is gone (died/restart) and somes replies cannot be sent because
the the exchange of this client will never comeback. We log one message per
reply every 0.25 messages during 60 seconds. When the only useful log
is the one where we decide to drop this replies.

This change moves the less important message to debug level.

Change-Id: I491e0d5dad7406859e762b53859790289e7cd626
n(cherry picked from commit I508787c0db4dcec2c0027b89eb4e65c4f98022b9)
Related-bug: #1524418
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/25/256325/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/amqpdriver.py'],1,a9899d9266bd2c2e3ff366dd934d75671120fc89,bug/1524418," LOG.debug((""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})"," LOG.info(_LI(""The reply %(msg_id)s cannot be sent "" ""%(reply_q)s reply queue don't exist, "" ""retrying..."") % { 'msg_id': self.msg_id, 'reply_q': self.reply_q})",5,5
openstack%2Fdocs-specs~master~I916f27a1c061eb29a34f892fdc3a1e9d83ef5e95,openstack/docs-specs,master,I916f27a1c061eb29a34f892fdc3a1e9d83ef5e95,Add python versions for classifier in setup.cfg,MERGED,2015-12-11 09:13:56.000000000,2015-12-11 10:33:54.000000000,2015-12-11 10:33:53.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 09:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/1037c623ed4c83c7cca3420a178880da23c0b212', 'message': 'Add python versions for classifier in setup.cfg\n\nChange-Id: I916f27a1c061eb29a34f892fdc3a1e9d83ef5e95\n'}, {'number': 2, 'created': '2015-12-11 09:24:05.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/docs-specs/commit/0df80c98fd9b9e3fd6297cd74111fce0b493151b', 'message': 'Add python versions for classifier in setup.cfg\n\nChange-Id: I916f27a1c061eb29a34f892fdc3a1e9d83ef5e95\n'}]",1,256296,0df80c98fd9b9e3fd6297cd74111fce0b493151b,10,3,2,16237,,,0,"Add python versions for classifier in setup.cfg

Change-Id: I916f27a1c061eb29a34f892fdc3a1e9d83ef5e95
",git fetch https://review.opendev.org/openstack/docs-specs refs/changes/96/256296/2 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,1037c623ed4c83c7cca3420a178880da23c0b212,add-py26, Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 3 Programming Language :: Python :: 3.3 Programming Language :: Python :: 3.4,,6,0
openstack%2Fopenstack-manuals~master~If0ec32e7c66ce266693d0dcd2282e73f81e09fa0,openstack/openstack-manuals,master,If0ec32e7c66ce266693d0dcd2282e73f81e09fa0,[user-guides] Update dashboard navigation for Liberty,MERGED,2015-12-11 03:14:59.000000000,2015-12-11 10:30:02.000000000,2015-12-11 10:30:00.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 14947}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 03:14:59.000000000', 'files': ['doc/user-guide-admin/source/dashboard_manage_flavors.rst', 'doc/user-guide-admin/source/dashboard_manage_images.rst', 'doc/user-guide-admin/source/dashboard_manage_host_aggregates.rst', 'doc/user-guide-admin/source/dashboard_manage_volumes.rst', 'doc/user-guide-admin/source/dashboard_manage_instances.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/07c0bd6261fe2d46459bb66586d530551ac5f80f', 'message': '[user-guides] Update dashboard navigation for Liberty\n\nThis patch covers Admin User Guide only.\n\nChange-Id: If0ec32e7c66ce266693d0dcd2282e73f81e09fa0\nImplements: blueprint user-guides-reorganised\n'}]",0,256192,07c0bd6261fe2d46459bb66586d530551ac5f80f,8,4,1,10497,,,0,"[user-guides] Update dashboard navigation for Liberty

This patch covers Admin User Guide only.

Change-Id: If0ec32e7c66ce266693d0dcd2282e73f81e09fa0
Implements: blueprint user-guides-reorganised
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/256192/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/user-guide-admin/source/dashboard_manage_flavors.rst', 'doc/user-guide-admin/source/dashboard_manage_images.rst', 'doc/user-guide-admin/source/dashboard_manage_host_aggregates.rst', 'doc/user-guide-admin/source/dashboard_manage_volumes.rst', 'doc/user-guide-admin/source/dashboard_manage_instances.rst']",5,07c0bd6261fe2d46459bb66586d530551ac5f80f,bp/user-guides-reorganised,"#. From the drop-down list in the :guilabel:`Actions` column, an instance (actions in red color are dangerous). **Figure Dashboard — Instance Actions**Use the :guilabel:`Overview` category to track usage of instances for each project.#. Log in to the Dashboard and choose the admin project from the drop-down list at the top of the page.","#. In the :guilabel:`More` drop-down list in the :guilabel:`Actions` column, an instance (items in red are dangerous). **Figure Dashboard—Instance Actions**Use the Overview category to track usage of instances for each project.#. Log in to the Dashboard and choose the admin project from the CURRENT PROJECT drop-down list.",29,32
openstack%2Ffuel-qa~master~I59814f9c36398dc12c7ca230c3ce8a974ccfc554,openstack/fuel-qa,master,I59814f9c36398dc12c7ca230c3ce8a974ccfc554,Fix ceph version checker,MERGED,2015-12-08 06:40:02.000000000,2015-12-11 10:29:39.000000000,2015-12-09 13:47:11.000000000,"[{'_account_id': 3}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 11081}]","[{'number': 1, 'created': '2015-12-08 06:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/76af1c9ca2ae0c9bff66125a64243df26872dca3', 'message': 'Fix ceph version checker\n\nChange-Id: I59814f9c36398dc12c7ca230c3ce8a974ccfc554\n'}, {'number': 2, 'created': '2015-12-08 06:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/54b6ef925bb29a21c9df9c4cbfcf1726772b26dd', 'message': 'Fix ceph version checker\n\nChanged type of check on equality\nCloses-Bug: #1522020\nChange-Id: I59814f9c36398dc12c7ca230c3ce8a974ccfc554\n'}, {'number': 3, 'created': '2015-12-08 06:49:02.000000000', 'files': ['fuelweb_test/tests/test_ceph.py'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c6bac70c2b661e2e7b07d63c0e84a020de703a8d', 'message': 'Fix ceph version checker\n\nChanged type of check on equality\nCloses-Bug: #1522020\nChange-Id: I59814f9c36398dc12c7ca230c3ce8a974ccfc554\n'}]",0,254572,c6bac70c2b661e2e7b07d63c0e84a020de703a8d,20,5,3,8882,,,0,"Fix ceph version checker

Changed type of check on equality
Closes-Bug: #1522020
Change-Id: I59814f9c36398dc12c7ca230c3ce8a974ccfc554
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/72/254572/1 && git format-patch -1 --stdout FETCH_HEAD,['fuelweb_test/tests/test_ceph.py'],1,76af1c9ca2ae0c9bff66125a64243df26872dca3,, # Check version. True if version equal @ceph_version return not (parse_version(v['ceph_version']) ==, # Check version. True if version bigger or equal @ceph_version return not (parse_version(v['ceph_version']) <,2,2
openstack%2Fnova~master~I16147e60b60be0f51c2aeb404ea9ed9fd3066795,openstack/nova,master,I16147e60b60be0f51c2aeb404ea9ed9fd3066795,Fix capitalization of IP,MERGED,2015-09-21 16:15:20.000000000,2015-12-11 10:23:28.000000000,2015-12-10 20:30:09.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 782}, {'_account_id': 1063}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 6547}, {'_account_id': 8688}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11303}, {'_account_id': 14358}, {'_account_id': 15286}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 16237}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17106}]","[{'number': 1, 'created': '2015-09-21 16:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3e51e06975405179b4b4c376c0d2b5b21af2d26e', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change all visible strings.\nInclude some small updates in updated strings.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 2, 'created': '2015-09-21 18:14:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/682de2de96fb3edfb444561d439b6dc24fc008b5', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change all visible strings.\nInclude some small updates in updated strings.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 3, 'created': '2015-09-21 19:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c3ff20262ebf5236106ce1b87010de221808fa9e', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change visible strings\nthat are user visible or documentation strings.\nInclude some small updates in updated strings.\nThis does not change any comments.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 4, 'created': '2015-10-26 18:00:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21b978ff946e65e7b6b933dfd27bfa74e3afef71', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change visible strings\nthat are user visible or documentation strings.\nInclude some small updates in updated strings.\nThis does not change any comments.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 5, 'created': '2015-10-26 20:48:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/413e68c957627378b60640e46227e6dbb4694033', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change strings\nthat are user visible or documentation strings.\nInclude some small updates in updated strings.\nThis does not change any comments.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 6, 'created': '2015-10-30 06:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7486544f1b8c7c20b363fa6367ec3a1a1f3c6360', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change strings\nthat are user visible or documentation strings.\nInclude some small updates in updated strings.\nThis does not change any comments.\n\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}, {'number': 7, 'created': '2015-12-09 10:44:17.000000000', 'files': ['nova/api/openstack/compute/floating_ips_bulk.py', 'nova/cmd/dhcpbridge.py', 'nova/network/manager.py', 'nova/network/linux_net.py', 'nova/api/metadata/handler.py', 'nova/cmd/manage.py', 'nova/tests/unit/api/openstack/compute/test_floating_ips.py', 'nova/api/openstack/compute/legacy_v2/contrib/os_networks.py', 'nova/db/sqlalchemy/api.py', 'nova/network/floating_ips.py', 'nova/network/neutronv2/api.py', 'nova/db/sqlalchemy/models.py', 'nova/exception.py', 'nova/api/openstack/compute/legacy_v2/contrib/floating_ips_bulk.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/api/openstack/compute/legacy_v2/contrib/floating_ips.py', 'nova/api/openstack/compute/legacy_v2/contrib/fixed_ips.py', 'nova/api/openstack/compute/legacy_v2/contrib/cloudpipe_update.py', 'nova/api/openstack/compute/floating_ips.py', 'nova/db/api.py', 'nova/api/openstack/compute/fixed_ips.py', 'nova/tests/unit/network/test_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a6ac4ec5d1c16cbb89fc5d2374f8ac90e9c31fb7', 'message': 'Fix capitalization of IP\n\nIt should be ""IP"" not ""ip"". Change strings\nthat are user visible or documentation strings.\nInclude some small updates in updated strings.\nThis does not change any comments.\n\nCloses-Bug: #1524276\nChange-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795\n'}]",2,225923,a6ac4ec5d1c16cbb89fc5d2374f8ac90e9c31fb7,111,23,7,6547,,,0,"Fix capitalization of IP

It should be ""IP"" not ""ip"". Change strings
that are user visible or documentation strings.
Include some small updates in updated strings.
This does not change any comments.

Closes-Bug: #1524276
Change-Id: I16147e60b60be0f51c2aeb404ea9ed9fd3066795
",git fetch https://review.opendev.org/openstack/nova refs/changes/23/225923/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/manager.py', 'nova/cmd/manage.py', 'nova/network/floating_ips.py', 'nova/network/neutronv2/api.py', 'nova/db/sqlalchemy/models.py', 'nova/exception.py', 'nova/network/api.py', 'nova/network/base_api.py', 'nova/api/openstack/compute/legacy_v2/contrib/floating_ips.py', 'nova/api/openstack/compute/legacy_v2/contrib/fixed_ips.py', 'nova/api/openstack/compute/floating_ips.py', 'nova/db/api.py', 'nova/api/openstack/compute/fixed_ips.py', 'nova/tests/unit/network/test_manager.py']",14,3e51e06975405179b4b4c376c0d2b5b21af2d26e,fixed_ip_capitalization, a public IP of other project., a public ip of other project.,179,179
openstack%2Fopenstack-manuals~master~If5acc6cf9100fffff8871f2784587bba8ca86479,openstack/openstack-manuals,master,If5acc6cf9100fffff8871f2784587bba8ca86479,[config-ref] Convert the XtremIO cinder driver to RST,MERGED,2015-12-10 15:20:53.000000000,2015-12-11 10:19:52.000000000,2015-12-11 10:19:50.000000000,"[{'_account_id': 3}, {'_account_id': 6635}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 11482}, {'_account_id': 14947}, {'_account_id': 16237}, {'_account_id': 17832}]","[{'number': 1, 'created': '2015-12-10 15:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/a5a4db51df61ae4c7b98e3ebe129e71fdd4892bd', 'message': '[config-ref] Convert the XtremIO cinder driver to RST\n\nChange-Id: If5acc6cf9100fffff8871f2784587bba8ca86479\nImplements: blueprint config-ref-rst\n'}, {'number': 2, 'created': '2015-12-10 16:47:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6ed97628770d75d2fd524c6b337c3287d240426f', 'message': '[config-ref] Convert the XtremIO cinder driver to RST\n\nChange-Id: If5acc6cf9100fffff8871f2784587bba8ca86479\nImplements: blueprint config-ref-rst\n'}, {'number': 3, 'created': '2015-12-10 19:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/d809565b2cb86f483fb2da8b6694b579e2c542dc', 'message': '[config-ref] Convert the XtremIO cinder driver to RST\n\nChange-Id: If5acc6cf9100fffff8871f2784587bba8ca86479\nImplements: blueprint config-ref-rst\n'}, {'number': 4, 'created': '2015-12-10 19:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8a45a52663eed6b32a1b5d631f01738d8db38c8d', 'message': '[config-ref] Convert the XtremIO cinder driver to RST\n\nRemoved the service restart step, usually not documented in the\nconfig ref.\n\nChange-Id: If5acc6cf9100fffff8871f2784587bba8ca86479\nImplements: blueprint config-ref-rst\n'}, {'number': 5, 'created': '2015-12-11 00:18:50.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/emc-xtremio-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/2935ab8e8b67386fc6c92c75e1c8b442680e1c2c', 'message': '[config-ref] Convert the XtremIO cinder driver to RST\n\nRemoved the service restart step, usually not documented in the\nconfig ref.\n\nChange-Id: If5acc6cf9100fffff8871f2784587bba8ca86479\nImplements: blueprint config-ref-rst\n'}]",14,255932,2935ab8e8b67386fc6c92c75e1c8b442680e1c2c,29,9,5,7923,,,0,"[config-ref] Convert the XtremIO cinder driver to RST

Removed the service restart step, usually not documented in the
config ref.

Change-Id: If5acc6cf9100fffff8871f2784587bba8ca86479
Implements: blueprint config-ref-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/32/255932/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/block-storage/drivers/emc-xtremio-driver.rst'],1,a5a4db51df61ae4c7b98e3ebe129e71fdd4892bd,bp/config-ref-rst," The high performance XtremIO All Flash Array (AFA) offers Block Storage services to OpenStack. Using the driver, OpenStack Block Storage hosts can connect to an XtermIO Storage cluster. This section explains how to configure and connect an OpenStack block storage host to an XtremIO storage cluster. Support matrix ~~~~~~~~~~~~~~ Xtremapp version 3.0 and 4.0 are supported. Supported operations ~~~~~~~~~~~~~~~~~~~~ - Create, delete, clone, attach, and detach volumes. - Create and delete volume snapshots. - Create a volume from a snapshot. - Copy an image to a volume. - Copy a volume to an image. - Extend a volume. - Manage and unmanage a volume. - Get volume statistics. XtremIO Block Storage driver configuration ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ Edit the ``cinder.conf`` file by adding the configuration below under the ``[DEFAULT]`` section of the file in case of a single back end or under a separate section in case of multiple back ends (for example [XTREMIO]). The configuration file is usually located under the following path ``/etc/cinder/cinder.conf``. For a configuration example, refer to the configuration :ref:`emc_extremio_configuration_example`. XtremIO driver name ------------------- Configure the driver name by setting the following parameter in the ``cinder.conf`` file: - For iSCSI: .. code-block:: ini volume_driver = cinder.volume.drivers.emc.xtremio.XtremIOIscsiDriver - For Fibre Channel: .. code-block:: ini volume_driver = cinder.volume.drivers.emc.xtremio.XtremIOFibreChannelDriver XtremIO management server (XMS) IP ---------------------------------- To retrieve the management IP, use the :command:`show-xms` CLI command. Configure the management IP by adding the following parameter: .. code-block:: ini san_ip = XMS Management IP XtremIO cluster name -------------------- In XtremIO version 4.0, a single XMS can manage multiple cluster back ends. In such setups, the administrator is required to specify the cluster name (in addition to the XMS IP). Each cluster must be defined as a separate back end. To retrieve the Cluster Name, run the :command:`show-clusters` CLI command. Configure the cluster name by adding the following parameter: .. code-block:: ini xtremio_cluster_name = Cluster-Name .. note:: When a single cluster is managed in XtremIO version 4.0, the cluster name is not required. XtremIO user credentials ------------------------ OpenStack Block Storage requires an XtremIO XMS user with administrative privileges. XtremIO recommends creating a dedicated OpenStack user account that holds an administrative user role. Refer to the XtremIO User Guide for details on user account management Create an XMS account using either the XMS GUI or the :command:`add-user-account` CLI command. Configure the user credentials by adding the following parameters: .. code-block:: ini san_login = XMS username san_password = XMS username password Multiple back ends ~~~~~~~~~~~~~~~~~~ Configuring multiple storage back ends enables you to create several back-end storage solutions that serve the same OpenStack Compute resources. When a volume is created, the scheduler selects the appropriate back end to handle the request, according to the specified volume type. Setting thin provisioning and multipathing parameters ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ To support thin provisioning and multipathing in the XtremIO Array, the following parameters from the Nova and Cinder configuration files should be modified as follows: - Thin Provisioning All XtremIO volumes are thin provisioned. The default value of 20 should be maintained for the ``max_over_subscription_ratio`` parameter. The ``use_cow_images`` parameter in the ``nova.conf`` file should be set to ``False`` as follows: .. code-block:: ini use_cow_images = False - Multipathing The ``use_multipath_for_image_xfer`` parameter in the ``cinder.conf`` file should be set to ``True`` as follows: .. code-block:: ini use_multipath_for_image_xfer = True Configuring CHAP ~~~~~~~~~~~~~~~~ The XtremIO Block Storage driver supports CHAP initiator authentication. If CHAP initiator authentication is required, set the CHAP Authentication mode to initiator. To set the CHAP initiator mode using CLI, run the following CLI command: .. code-block:: console $ modify-chap chap-authentication-mode=initiator The CHAP initiator mode can also be set via the XMS GUI. Refer to XtremIO User Guide for details on CHAP configuration via GUI and CLI. The CHAP initiator authentication credentials (username and password) are generated automatically by the Block Storage driver. Therefore, there is no need to configure the initial CHAP credentials manually in XMS. .. _emc_extremio_configuration_example: Configuration example ~~~~~~~~~~~~~~~~~~~~~ You can update the ``cinder.conf`` file by editing the necessary parameters as follows: .. code-block:: ini [Default] enabled_backends = XtremIO [XtremIO] volume_driver = cinder.volume.drivers.emc.xtremio.XtremIOFibreChannelDriver san_ip = XMS_IP xtremio_cluster_name = Cluster01 san_login = XMS_USER san_password = XMS_PASSWD volume_backend_name = XtremIOAFA",,184,0
openstack%2Fopenstack-manuals~master~I923c72ecbd0053abc087a5713944529136f2e93c,openstack/openstack-manuals,master,I923c72ecbd0053abc087a5713944529136f2e93c,[config-ref] Fix the toctree at top of the page,MERGED,2015-12-11 01:17:26.000000000,2015-12-11 10:19:43.000000000,2015-12-11 10:19:40.000000000,"[{'_account_id': 3}, {'_account_id': 7923}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 01:17:26.000000000', 'files': ['doc/config-ref-rst/source/shared-file-systems.rst', 'doc/config-ref-rst/source/telemetry.rst', 'doc/config-ref-rst/source/networking.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/f07fbad4fa54b624fc89ada0513f8027413b6282', 'message': '[config-ref] Fix the toctree at top of the page\n\nChange-Id: I923c72ecbd0053abc087a5713944529136f2e93c\n'}]",0,256169,f07fbad4fa54b624fc89ada0513f8027413b6282,7,3,1,16237,,,0,"[config-ref] Fix the toctree at top of the page

Change-Id: I923c72ecbd0053abc087a5713944529136f2e93c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/69/256169/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-ref-rst/source/shared-file-systems.rst', 'doc/config-ref-rst/source/telemetry.rst', 'doc/config-ref-rst/source/networking.rst']",3,f07fbad4fa54b624fc89ada0513f8027413b6282,fix-tree," This chapter explains the OpenStack Networking configuration options. For installation prerequisites, steps, and use cases, see the OpenStack Installation Guide for your distribution (`docs.openstack.org <http://docs.openstack.org>`__) and the `Cloud Administrator Guide <http://docs.openstack.org/admin-guide-cloud/>`__. ","This chapter explains the OpenStack Networking configuration options. For installation prerequisites, steps, and use cases, see the OpenStack Installation Guide for your distribution (`docs.openstack.org <http://docs.openstack.org>`__) and the `Cloud Administrator Guide <http://docs.openstack.org/admin-guide-cloud/>`__. ",18,15
openstack%2Fopenstack-manuals~master~If3d6700908d827809e1fdc00196440f83bc9a98c,openstack/openstack-manuals,master,If3d6700908d827809e1fdc00196440f83bc9a98c,[config-ref] Convert EMC VNX driver to RST,MERGED,2015-12-10 16:45:18.000000000,2015-12-11 10:19:33.000000000,2015-12-11 10:19:31.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 7923}, {'_account_id': 10497}, {'_account_id': 10607}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 16:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ddd24377bc39b99d71e1790902c4338dd4f1326d', 'message': '[config-ref] Convert EMC VNX driver to RST\n\nImplements: blueprint config-ref-rst\nChange-Id: If3d6700908d827809e1fdc00196440f83bc9a98c\n'}, {'number': 2, 'created': '2015-12-10 19:29:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/b5bc4e2c8dfab904c8ebcfeb51b22981b71480df', 'message': '[config-ref] Convert EMC VNX driver to RST\n\nThe ""Install EMC VNX driver"" has been removed because it doesn\'t bring\nuseful information, and is something that is not done in other drivers.\n\nImplements: blueprint config-ref-rst\nChange-Id: If3d6700908d827809e1fdc00196440f83bc9a98c\n'}, {'number': 3, 'created': '2015-12-10 19:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8aa6a1bd72d3ac76d2d97e81885c5dfe4498ece9', 'message': '[config-ref] Convert EMC VNX driver to RST\n\nThe ""Install EMC VNX driver"" has been removed because it doesn\'t bring\nuseful information, and is something that is not done in other drivers.\n\nImplements: blueprint config-ref-rst\nChange-Id: If3d6700908d827809e1fdc00196440f83bc9a98c\n'}, {'number': 4, 'created': '2015-12-11 08:18:10.000000000', 'files': ['doc/config-ref-rst/source/figures/emc-enabler.png', 'doc/config-ref-rst/source/block-storage/drivers/emc-vnx-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/bf9696e4d58f5e1048c1c5ddd9cb3007924308a7', 'message': '[config-ref] Convert EMC VNX driver to RST\n\nThe ""Install EMC VNX driver"" has been removed because it doesn\'t bring\nuseful information, and is something that is not done in other drivers.\n\nImplements: blueprint config-ref-rst\nChange-Id: If3d6700908d827809e1fdc00196440f83bc9a98c\n'}]",32,255977,bf9696e4d58f5e1048c1c5ddd9cb3007924308a7,27,6,4,7923,,,0,"[config-ref] Convert EMC VNX driver to RST

The ""Install EMC VNX driver"" has been removed because it doesn't bring
useful information, and is something that is not done in other drivers.

Implements: blueprint config-ref-rst
Change-Id: If3d6700908d827809e1fdc00196440f83bc9a98c
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/77/255977/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-ref-rst/source/figures/emc-enabler.png', 'doc/config-ref-rst/source/block-storage/drivers/emc-vnx-driver.rst']",2,ddd24377bc39b99d71e1790902c4338dd4f1326d,bp/config-ref-rst," EMC VNX driver consists of EMCCLIISCSIDriver and EMCCLIFCDriver, and supports both iSCSI and FC protocol. ``EMCCLIISCSIDriver`` (VNX iSCSI driver) and ``EMCCLIFCDriver`` (VNX FC driver) are separately based on the ``ISCSIDriver`` and ``FCDriver`` defined in Block Storage. The VNX iSCSI driver and VNX FC driver perform the volume operations by executing Navisphere CLI (NaviSecCLI) which is a command line interface used for management, diagnostics, and reporting functions for VNX. System requirement ~~~~~~~~~~~~~~~~~~~ - VNX Operational Environment for Block version 5.32 or higher. - VNX Snapshot and Thin Provisioning license should be activated for VNX. - Navisphere CLI v7.32 or higher is installed along with the driver. Supported operations ~~~~~~~~~~~~~~~~~~~~ - Create, delete, attach, and detach volumes. - Create, list, and delete volume snapshots. - Create a volume from a snapshot. - Copy an image to a volume. - Clone a volume. - Extend a volume. - Migrate a volume. - Retype a volume. - Get volume statistics. - Create and delete consistency groups. - Create, list, and delete consistency group snapshots. - Modify consistency groups. - Efficient non-disruptive volume backup. Preparation ~~~~~~~~~~~ This section contains instructions to prepare the Block Storage nodes to use the EMC VNX driver. You install the Navisphere CLI, install the driver, ensure you have correct zoning configurations, and register the driver. Install Navisphere CLI ---------------------- Navisphere CLI needs to be installed on all Block Storage nodes within an OpenStack deployment. You need to download different versions for different platforms. - For Ubuntu x64, DEB is available at `EMC OpenStack Github <https://github.com/emc-openstack/naviseccli>`__. - For all other variants of Linux, Navisphere CLI is available at `Downloads for VNX2 Series <https://support.emc.com/downloads/36656_VNX2-Series>`__ or `Downloads for VNX1 Series <https://support.emc.com/downloads/12781_VNX1-Series>`__. - After installation, set the security level of Navisphere CLI to low: .. code-block:: console $ /opt/Navisphere/bin/naviseccli security -certificate -setLevel low Check array software -------------------- Make sure your have the following software installed for certain features: +--------------------------------------------+---------------------+ | Feature | Software Required | +============================================+=====================+ | All | ThinProvisioning | +--------------------------------------------+---------------------+ | All | VNXSnapshots | +--------------------------------------------+---------------------+ | FAST cache support | FASTCache | +--------------------------------------------+---------------------+ | Create volume with type ``compressed`` | Compression | +--------------------------------------------+---------------------+ | Create volume with type ``deduplicated`` | Deduplication | +--------------------------------------------+---------------------+ **Required software** You can check the status of your array software in the :guilabel:`Software` page of :guilabel:`""Storage System Properties`. Here is how it looks like: .. figure:: ../../figures/emc-enabler.png Network configuration --------------------- For FC Driver, FC zoning is properly configured between hosts and VNX. Check :ref:`register-fc-port-with-vnx` for reference. For iSCSI Driver, make sure your VNX iSCSI port is accessible by your hosts. Check :ref:`register-iscsi-port-with-vnx` for reference. You can use ``initiator_auto_registration = True`` configuration to avoid registering the ports manually. Check the detail of the configuration in :ref:`emc-vnx-conf` for reference. If you are trying to setup multipath, refer to :ref:`multipath-setup`. .. _emc-vnx-conf: Backend configuration ~~~~~~~~~~~~~~~~~~~~~ Make the following changes in ``/etc/cinder/cinder.conf`` file. Minimum configuration --------------------- Here is a sample of minimum backend configuration. See following sections for the detail of each option Replace ``EMCCLIFCDriver`` to ``EMCCLIISCSIDriver`` if your are using the iSCSI driver. .. code-block:: ini [DEFAULT] enabled_backends = vnx_array1 [vnx_array1] san_ip = 10.10.72.41 san_login = sysadmin san_password = sysadmin naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver=cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration=True Multi-backend configuration --------------------------- Here is a sample of a multi-backend configuration. See following sections for the detail of each option. Replace ``EMCCLIFCDriver`` to ``EMCCLIISCSIDriver`` if your are using the iSCSI driver. .. code-block:: ini [DEFAULT] enabled_backends=backendA, backendB [backendA] storage_vnx_pool_names = Pool_01_SAS, Pool_02_FLASH san_ip = 10.10.72.41 storage_vnx_security_file_dir = /etc/secfile/array1 naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver=cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration=True [backendB] storage_vnx_pool_names = Pool_02_SAS san_ip = 10.10.26.101 san_login = username san_password = password naviseccli_path = /opt/Navisphere/bin/naviseccli volume_driver=cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver initiator_auto_registration=True For more details on multi-backends, see `OpenStack Cloud Administration Guide <http://docs.openstack.org/admin-guide-cloud/index.html>`__ Required configurations ----------------------- **IP of the VNX Storage Processors** Specify the SP A and SP B IP to connect: .. code-block:: ini san_ip = <IP of VNX Storage Processor A> san_secondary_ip = <IP of VNX Storage Processor B> **VNX login credentials** There are two ways to specify the credentials. - Use plain text username and password. Supply for plain username and password: .. code-block:: ini san_login = <VNX account with administrator role> san_password = <password for VNX account> storage_vnx_authentication_type = global Valid values for ``storage_vnx_authentication_type`` are: ``global`` (default), ``local``, and ``ldap``. - Use Security file. This approach avoids the plain text password in your cinder configuration file. Supply a security file as below: .. code-block:: ini storage_vnx_security_file_dir = <path to security file> Check Unisphere CLI user guide or :ref:`authenticate-by-security-file` for how to create a security file. **Path to your Unisphere CLI** Specify the absolute path to your naviseccli: .. code-block:: ini naviseccli_path = /opt/Navisphere/bin/naviseccli **Driver name** - For the FC Driver, add the following option: .. code-block:: ini volume_driver = cinder.volume.drivers.emc.emc_cli_fc.EMCCLIFCDriver - For iSCSI Driver, add the following option: .. code-block:: ini volume_driver = cinder.volume.drivers.emc.emc_cli_iscsi.EMCCLIISCSIDriver Optional configurations ~~~~~~~~~~~~~~~~~~~~~~~ VNX pool names -------------- Specify the list of pools to be managed, separated by commas. They should already exist in VNX. .. code-block:: ini storage_vnx_pool_names = pool 1, pool 2 If this value is not specified, all pools of the array will be used. **Initiator auto registration** When ``initiator_auto_registration`` is set to ``True``, the driver will automatically register initiators to all working target ports of the VNX array during volume attaching (The driver will skip those initiators that have already been registered) if the option ``io_port_list`` is not specified in ``cinder.conf``. If the user wants to register the initiators with some specific ports but not register with the other ports, this functionality should be disabled. When a comma-separated list is given to ``io_port_list``, the driver will only register the initiator to the ports specified in the list and only return target port(s) which belong to the target ports in the ``io_port_list`` instead of all target ports. - Example for FC ports: .. code-block:: ini io_port_list = a-1,B-3 ``a`` or ``B`` is *Storage Processor*, number ``1`` and ``3`` are *Port ID*. - Example for iSCSI ports: .. code-block:: ini io_port_list = a-1-0,B-3-0 ``a`` or ``B`` is *Storage Processor*, the first numbers ``1`` and ``3`` are *Port ID* and the second number ``0`` is *Virtual Port ID* .. note:: - Rather than de-registered, the registered ports will be simply bypassed whatever they are in ``io_port_list`` or not. - The driver will raise an exception if ports in ``io_port_list`` are not existed in VNX during startup. Force delete volumes in storage group ------------------------------------- Some ``available`` volumes may remain in storage group on the VNX array due to some OpenStack timeout issue. But the VNX array do not allow the user to delete the volumes which are in storage group. Option ``force_delete_lun_in_storagegroup`` is introduced to allow the user to delete the ``available`` volumes in this tricky situation. When ``force_delete_lun_in_storagegroup`` is set to ``True`` in the back-end section, the driver will move the volumes out of storage groups and then delete them if the user tries to delete the volumes that remain in storage group on the VNX array. The default value of ``force_delete_lun_in_storagegroup`` is ``False``. Over subscription in thin provisioning -------------------------------------- Over subscription allows that the sum of all volumes' capacity (provisioned capacity) to be larger than the pool's total capacity. ``max_over_subscription_ratio`` in the back-end section is the ratio of provisioned capacity over total capacity. The default value of ``max_over_subscription_ratio`` is 20.0, which means the provisioned capacity can not exceed the total capacity. If the value of this ratio is set larger than 1.0, the provisioned capacity can exceed the total capacity. Storage group automatic deletion -------------------------------- For volume attaching, the driver has a storage group on VNX for each compute node hosting the vm instances which are going to consume VNX Block Storage (using compute node's hostname as storage group's name). All the volumes attached to the VM instances in a compute node will be put into the storage group. If ``destroy_empty_storage_group`` is set to ``True``, the driver will remove the empty storage group after its last volume is detached. For data safety, it does not suggest to set ``destroy_empty_storage_group=True`` unless the VNX is exclusively managed by one Block Storage node because consistent ``lock_path`` is required for operation synchronization for this behavior. Initiator auto deregistration ----------------------------- Enabling storage group automatic deletion is the precondition of this function. If ``initiator_auto_deregistration`` is set to ``True`` is set, the driver will deregister all the initiators of the host after its storage group is deleted. FC SAN auto zoning ------------------ The EMC VNX FC driver supports FC SAN auto zoning when ZoneManager is configured. Set ``zoning_mode`` to ``fabric`` in the ``[DEFAULT]`` section to enable this feature. For ZoneManager configuration, refer to Block Storage official guide. Volume number threshold ----------------------- In VNX, there is a limitation on the number of pool volumes that can be created in the system. When the limitation is reached, no more pool volumes can be created even if there is remaining capacity in the storage pool. In other words, if the scheduler dispatches a volume creation request to a back end that has free capacity but reaches the volume limitation, the creation fails. The default value of ``check_max_pool_luns_threshold`` is ``False``. When ``check_max_pool_luns_threshold=True``, the pool-based back end will check the limit and will report 0 free capacity to the scheduler if the limit is reached. So the scheduler will be able to skip this kind of pool-based back end that runs out of the pool volume number. iSCSI initiators ---------------- ``iscsi_initiators`` is a dictionary of IP addresses of the iSCSI initiator ports on OpenStack Compute and Block Storage nodes which want to connect to VNX via iSCSI. If this option is configured, the driver will leverage this information to find an accessible iSCSI target portal for the initiator when attaching volume. Otherwise, the iSCSI target portal will be chosen in a relative random way. .. note:: This option is only valid for iSCSI driver. Here is an example. VNX will connect ``host1`` with ``10.0.0.1`` and ``10.0.0.2``. And it will connect ``host2`` with ``10.0.0.3``. The key name (``host1`` in the example) should be the output of the command :command:`hostname`. .. code-block:: ini iscsi_initiators = {""host1"":[""10.0.0.1"", ""10.0.0.2""],""host2"":[""10.0.0.3""]} Default timeout --------------- Specify the timeout in minutes for operations like LUN migration, LUN creation, etc. For example, LUN migration is a typical long running operation, which depends on the LUN size and the load of the array. An upper bound in the specific deployment can be set to avoid unnecessary long wait. The default value for this option is infinite. .. code-block:: ini default_timeout = 10 Max LUNs per storage group -------------------------- ``max_luns_per_storage_group`` specify the max number of LUNs in a storage group. Default value is 255. It is also the max value supportedby VNX. Ignore pool full threshold -------------------------- if ``ignore_pool_full_threshold`` is set to ``True``, driver will force LUN creation even if the full threshold of pool is reached. Default to ``False``. Extra spec options ~~~~~~~~~~~~~~~~~~ Extra specs are used in volume types created in Block Storage as the preferred property of the volume. The Block storage scheduler will use extra specs to find the suitable back end for the volume and the Block storage driver will create the volume based on the properties specified by the extra spec. Use following command to create a volume type: .. code-block:: console $ cinder type-create ""demoVolumeType"" Use following command to update the extra spec of a volume type: .. code-block:: console $ cinder type-key ""demoVolumeType"" set provisioning:type=thin The following sections describe the VNX extra keys. Provisioning type ----------------- - Key: ``provisioning:type`` - Possible Values: - ``thick`` Volume is fully provisioned. .. code-block:: console $ cinder type-create ""ThickVolumeType"" $ cinder type-key ""ThickVolumeType"" set provisioning:type=thick thick_provisioning_support='<is> True' - ``thin`` Volume is virtually provisioned. .. code-block:: console $ cinder type-create ""ThinVolumeType"" $ cinder type-key ""ThinVolumeType"" set provisioning:type=thin thin_provisioning_support='<is> True' - ``deduplicated`` Volume is ``thin`` and deduplication is enabled. The administrator shall go to VNX to configure the system level deduplication settings. To create a deduplicated volume, the VNX Deduplication license must be activated on VNX, and specify ``deduplication_support=True`` to let Block Storage scheduler find the proper volume back end. .. code-block:: console $ cinder type-create ""DeduplicatedVolumeType"" $ cinder type-key ""DeduplicatedVolumeType"" set provisioning:type=deduplicated deduplication_support='<is> True' - ``compressed`` Volume is ``thin`` and compression is enabled. The administrator shall go to the VNX to configure the system level compression settings. To create a compressed volume, the VNX Compression license must be activated on VNX , and use ``compression_support=True`` to let Block Storage scheduler find a volume back end. VNX does not support creating snapshots on a compressed volume. .. code-block:: console $ cinder type-create ""CompressedVolumeType"" $ cinder type-key ""CompressedVolumeType"" set provisioning:type=compressed compression_support='<is> True' - Default: ``thick`` .. note:: ``provisioning:type`` replaces the old spec key ``storagetype:provisioning``. The latter one will be obsoleted in the next release. If both ``provisioning:type`` and ``storagetype:provisioning`` are set in the volume type, the value of ``provisioning:type`` will be used. Storage tiering support ----------------------- - Key: ``storagetype:tiering`` - Possible Values: - ``StartHighThenAuto`` - ``Auto`` - ``HighestAvailable`` - ``LowestAvailable`` - ``NoMovement`` - Default: ``StartHighThenAuto`` VNX supports fully automated storage tiering which requires the FAST license activated on the VNX. The OpenStack administrator can use the extra spec key ``storagetype:tiering`` to set the tiering policy of a volume and use the key ``fast_support='<is> True'`` to let Block Storage scheduler find a volume back end which manages a VNX with FAST license activated. Here are the five supported values for the extra spec key ``storagetype:tiering``: .. code-block:: console $ cinder type-create ""ThinVolumeOnLowestAvaibleTier"" $ cinder type-key ""CompressedVolumeOnLowestAvaibleTier"" set provisioning:type=thin storagetype:tiering=Auto fast_support='<is> True' .. note:: Tiering policy can not be applied to a deduplicated volume. Tiering policy of the deduplicated LUN align with the settings of the pool. FAST cache support ------------------ - Key: ``fast_cache_enabled`` - Possible Values: - ``True`` - ``False`` - Default: ``False`` VNX has FAST Cache feature which requires the FAST Cache license activated on the VNX. Volume will be created on the backend with FAST cache enabled when ``True`` is specified. Snap-copy --------- - Key: ``copytype:snap`` - Possible Values: - ``True`` - ``False`` - Default: ``False`` The VNX driver supports snap-copy, which extremely accelerates the process for creating a copied volume. By default, the driver will do full data copy when creating a volume from a snapshot or cloning a volume, which is time-consuming especially for large volumes. When the snap-copy is used, the driver will simply create a snapshot and mount it as a volume for the 2 kinds of operations which will be instant even for large volumes. To enable this functionality, the source volume should have ``copytype:snap=True`` in the extra specs of its volume type. Then the new volume cloned from the source or copied from the snapshot for the source, will be in fact a snap-copy instead of a full copy. If a full copy is needed, retype/migration can be used to convert the snap-copy volume to a full-copy volume which may be time-consuming. .. code-block:: console $ cinder type-create ""SnapCopy"" $ cinder type-key ""SnapCopy"" set copytype:snap=True User can determine whether the volume is a snap-copy volume or not by showing its metadata. If the ``lun_type`` in metadata is ``smp``, the volume is a snap-copy volume. Otherwise, it is a full-copy volume. .. code-block:: console $ cinder metadata-show <volume> **Constraints** - ``copytype:snap=True`` is not allowed in the volume type of a consistency group. - Clone and snapshot creation are not allowed on a copied volume created through the snap-copy before it is converted to a full copy. - The number of snap-copy volume created from a source volume is limited to 255 at one point in time. - The source volume which has snap-copy volume can not be deleted. Pool name --------- - Key: ``pool_name`` - Possible Values: name of the storage pool managed by cinder - Default: None If the user wants to create a volume on a certain storage pool in a back end that manages multiple pools, a volume type with a extra spec specified storage pool should be created first, then the user can use this volume type to create the volume. .. code-block:: console $ cinder type-create ""HighPerf"" $ cinder type-key ""HighPerf"" set pool_name=Pool_02_SASFLASH volume_backend_name=vnx_41 Advanced features ~~~~~~~~~~~~~~~~~ Read-only volumes ----------------- OpenStack supports read-only volumes. The following command can be used to set a volume as read-only. .. code-block:: console $ cinder readonly-mode-update <volume> True After a volume is marked as read-only, the driver will forward the information when a hypervisor is attaching the volume and the hypervisor will make sure the volume is read-only. Efficient non-disruptive volume backup -------------------------------------- The default implementation in Block Storage for non-disruptive volume backup is not efficient since a cloned volume will be created during backup. The approach of efficient backup is to create a snapshot for the volume and connect this snapshot (a mount point in VNX) to the Block Storage host for volume backup. This eliminates migration time involved in volume clone. **Constraints** - Backup creation for a snap-copy volume is not allowed if the volume status is ``in-use`` since snapshot cannot be taken from this volume. Best practice ~~~~~~~~~~~~~ .. _multipath-setup: Multipath setup --------------- Enabling multipath volume access is recommended for robust data access. The major configuration includes: #. Install ``multipath-tools``, ``sysfsutils`` and ``sg3-utils`` on nodes hosting Nova-Compute and Cinder-Volume services. Check the operating system manual for the system distribution for specific installation steps. For Red Hat based distributions, they should be ``device-mapper-multipath``, ``sysfsutils`` and ``sg3_utils``. #. Specify ``use_multipath_for_image_xfer=true`` in cinder.conf for each FC/iSCSI back end. #. Specify ``iscsi_use_multipath=True`` in ``libvirt`` section of ``nova.conf``. This option is valid for both iSCSI and FC driver. For multipath-tools, here is an EMC recommended sample of ``/etc/multipath.conf``. ``user_friendly_names`` is not specified in the configuration and thus it will take the default value ``no``. It is not recommended to set it to ``yes`` because it may fail operations such as VM live migration. .. code-block:: none blacklist { # Skip the files under /dev that are definitely not FC/iSCSI devices # Different system may need different customization devnode ""^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*"" devnode ""^hd[a-z][0-9]*"" devnode ""^cciss!c[0-9]d[0-9]*[p[0-9]*]"" # Skip LUNZ device from VNX device { vendor ""DGC"" product ""LUNZ"" } } defaults { user_friendly_names no flush_on_last_del yes } devices { # Device attributed for EMC CLARiiON and VNX series ALUA device { vendor ""DGC"" product "".*"" product_blacklist ""LUNZ"" path_grouping_policy group_by_prio path_selector ""round-robin 0"" path_checker emc_clariion features ""1 queue_if_no_path"" hardware_handler ""1 alua"" prio alua failback immediate } } .. note:: When multipath is used in OpenStack, multipath faulty devices may come out in Nova-Compute nodes due to different issues (`Bug 1336683 <https://bugs.launchpad.net/nova/+bug/1336683>`__ is a typical example). A solution to completely avoid faulty devices has not been found yet. ``faulty_device_cleanup.py`` mitigates this issue when VNX iSCSI storage is used. Cloud administrators can deploy the script in all Nova-Compute nodes and use a CRON job to run the script on each Nova-Compute node periodically so that faulty devices will not stay too long. Refer to: `VNX faulty device cleanup <https://github.com/emc-openstack/vnx-faulty-device-cleanup>`__ for detailed usage and the script. Restrictions and limitations ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ iSCSI port cache ---------------- EMC VNX iSCSI driver caches the iSCSI ports information, so that the user should restart the cinder-volume service or wait for seconds (which is configured by ``periodic_interval`` in ``cinder.conf``) before any volume attachment operation after changing the iSCSI port configurations. Otherwise the attachment may fail because the old iSCSI port configurations were used. No extending for volume with snapshots -------------------------------------- VNX does not support extending the thick volume which has a snapshot. If the user tries to extend a volume which has a snapshot, the status of the volume would change to ``error_extending``. Limitations for deploying cinder on computer node ------------------------------------------------- It is not recommended to deploy the driver on a compute node if ``cinder upload-to-image --force True`` is used against an in-use volume. Otherwise, ``cinder upload-to-image --force True`` will terminate the data access of the vm instance to the volume. Storage group with host names in VNX ------------------------------------ When the driver notices that there is no existing storage group that has the host name as the storage group name, it will create the storage group and also add the compute node's or Block Storage nodes' registered initiators into the storage group. If the driver notices that the storage group already exists, it will assume that the registered initiators have also been put into it and skip the operations above for better performance. It is recommended that the storage administrator does not create the storage group manually and instead relies on the driver for the preparation. If the storage administrator needs to create the storage group manually for some special requirements, the correct registered initiators should be put into the storage group as well (otherwise the following volume attaching operations will fail). EMC storage-assisted volume migration ------------------------------------- EMC VNX driver supports storage-assisted volume migration, when the user starts migrating with ``cinder migrate --force-host-copy False <volume_id> <host>`` or ``cinder migrate <volume_id> <host>``, cinder will try to leverage the VNX's native volume migration functionality. In following scenarios, VNX storage-assisted volume migration will not be triggered: 1. Volume migration between back ends with different storage protocol, ex, FC and iSCSI. 2. Volume is to be migrated across arrays. Appendix ~~~~~~~~ .. _authenticate-by-security-file: Authenticate by security file ----------------------------- VNX credentials are necessary when the driver connects to the VNX system. Credentials in global, local and ldap scopes are supported. There are two approaches to provide the credentials. The recommended one is using the Navisphere CLI security file to provide the credentials which can get rid of providing the plain text credentials in the configuration file. Following is the instruction on how to do this. #. Find out the Linux user id of the cinder-volume processes. Assuming the service cinder-volume is running by the account ``cinder``. #. Run ``su`` as root user. #. In ``/etc/passwd``, change ``cinder:x:113:120::/var/lib/cinder:/bin/false`` to ``cinder:x:113:120::/var/lib/cinder:/bin/bash`` (This temporary change is to make step 4 work.) #. Save the credentials on behalf of ``cinder`` user to a security file (assuming the array credentials are ``admin/admin`` in ``global`` scope). In the command below, the '-secfilepath' switch is used to specify the location to save the security file. .. code-block:: console # su -l cinder -c '/opt/Navisphere/bin/naviseccli \ -AddUserSecurity -user admin -password admin -scope 0 -secfilepath <location>' #. Change ``cinder:x:113:120::/var/lib/cinder:/bin/bash`` back to ``cinder:x:113:120::/var/lib/cinder:/bin/false`` in ``/etc/passwd`` #. Remove the credentials options ``san_login``, ``san_password`` and ``storage_vnx_authentication_type`` from cinder.conf. (normally it is ``/etc/cinder/cinder.conf``). Add option ``storage_vnx_security_file_dir`` and set its value to the directory path of your security file generated in step 4. Omit this option if ``-secfilepath`` is not used in step 4. #. Restart the cinder-volume service to validate the change. .. _register-fc-port-with-vnx: Register FC port with VNX ------------------------- This configuration is only required when ``initiator_auto_registration=False``. To access VNX storage, the compute nodes should be registered on VNX first if initiator auto registration is not enabled. To perform ""Copy Image to Volume"" and ""Copy Volume to Image"" operations, the nodes running the cinder-volume service (Block Storage nodes) must be registered with the VNX as well. The steps mentioned below are for the compute nodes. Follow the same steps for the Block Storage nodes also (The steps can be skipped if initiator auto registration is enabled). #. Assume ``20:00:00:24:FF:48:BA:C2:21:00:00:24:FF:48:BA:C2`` is the WWN of a FC initiator port name of the compute node whose hostname and IP are ``myhost1`` and ``10.10.61.1``. Register ``20:00:00:24:FF:48:BA:C2:21:00:00:24:FF:48:BA:C2`` in Unisphere: #. Login to Unisphere, go to FNM0000000000->Hosts->Initiators. #. Refresh and wait until the initiator ``20:00:00:24:FF:48:BA:C2:21:00:00:24:FF:48:BA:C2`` with SP Port ``A-1`` appears. #. Click the Register button, select CLARiiON/VNX and enter the hostname (which is the output of the :command:`hostname` command) and IP address: - Hostname: ``myhost1`` - IP: ``10.10.61.1`` - Click Register. #. Then host ``10.10.61.1`` will appear under Hosts->Host List as well. #. Register the wwn with more ports if needed. .. _register-iscsi-port-with-vnx: Register iSCSI port with VNX ---------------------------- This configuration is only required when ``initiator_auto_registration=False``. To access VNX storage, the compute nodes should be registered on VNX first if initiator auto registration is not enabled. To perform ""Copy Image to Volume"" and ""Copy Volume to Image"" operations, the nodes running the cinder-volume service (Block Storage nodes) must be registered with the VNX as well. The steps mentioned below are for the compute nodes. Follow the same steps for the Block Storage nodes also (The steps can be skipped if initiator auto registration is enabled). #. On the compute node with IP address ``10.10.61.1`` and hostname ``myhost1``, execute the following commands (assuming ``10.10.61.35`` is the iSCSI target): #. Start the iSCSI initiator service on the node: .. code-block:: console # /etc/init.d/open-iscsi start #. Discover the iSCSI target portals on VNX: .. code-block:: console # iscsiadm -m discovery -t st -p 10.10.61.35 #. Enter ``/etc/iscsi``: .. code-block:: console # cd /etc/iscsi #. Find out the iqn of the node: .. code-block:: console # more initiatorname.iscsi #. Login to VNX from the compute node using the target corresponding to the SPA port: .. code-block:: console # iscsiadm -m node -T iqn.1992-04.com.emc:cx.apm01234567890.a0 -p 10.10.61.35 -l #. Assume ``iqn.1993-08.org.debian:01:1a2b3c4d5f6g`` is the initiator name of the compute node. Register ``iqn.1993-08.org.debian:01:1a2b3c4d5f6g`` in Unisphere: #. Login to Unisphere, go to FNM0000000000->Hosts->Initiators. #. Refresh and wait until the initiator ``iqn.1993-08.org.debian:01:1a2b3c4d5f6g`` with SP Port ``A-8v0`` appears. #. Click the Register button, select CLARiiON/VNX and enter the hostname (which is the output of the :command:`hostname` command) and IP address: - Hostname: ``myhost1`` - IP: ``10.10.61.1`` - Click Register #. Then host ``10.10.61.1`` will appear under Hosts->Host List as well. #. Logout iSCSI on the node: .. code-block:: console # iscsiadm -m node -u #. Login to VNX from the compute node using the target corresponding to the SPB port: .. code-block:: console # iscsiadm -m node -T iqn.1992-04.com.emc:cx.apm01234567890.b8 -p 10.10.61.36 -l #. In Unisphere register the initiator with the SPB port. #. Logout iSCSI on the node: .. code-block:: console # iscsiadm -m node -u #. Register the iqn with more ports if needed.",,988,0
openstack%2Ffuel-qa~master~I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b,openstack/fuel-qa,master,I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b,Update vCenter tests for 8.0 release,MERGED,2015-12-10 09:00:29.000000000,2015-12-11 10:16:38.000000000,2015-12-11 10:16:37.000000000,"[{'_account_id': 3}, {'_account_id': 6719}, {'_account_id': 8882}, {'_account_id': 8971}, {'_account_id': 10136}, {'_account_id': 13306}, {'_account_id': 15660}, {'_account_id': 15943}, {'_account_id': 15984}, {'_account_id': 16044}, {'_account_id': 18191}]","[{'number': 1, 'created': '2015-12-10 09:00:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/7da2b20314031bf9061a8cfc1ed605641f051179', 'message': 'vCenter tests were rewrited in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 2, 'created': '2015-12-10 09:16:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/f249515fe2882866be8a0b93035440f9667874c6', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 3, 'created': '2015-12-10 09:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/39bac42f64ddd7c2a0aa1837f32cc495a6f78daf', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 4, 'created': '2015-12-10 10:18:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/c310d5815792d4241e52ad6cbc354803db857848', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 5, 'created': '2015-12-10 11:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/1ae67fea032bc7e103ba8c3bb9ded2dd1a006366', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 6, 'created': '2015-12-10 11:51:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/dae159a962ccbdfc416e097a71314e7a46b1928c', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 7, 'created': '2015-12-10 15:00:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/042aa703964912589616deceaf5be5549b054780', 'message': 'vCenter tests were rewrittеn in accordance with changes in 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 8, 'created': '2015-12-11 09:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/ef05b55b9aa817d61dec381053c631d23603e172', 'message': 'Update vCenter tests for 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}, {'number': 9, 'created': '2015-12-11 09:30:49.000000000', 'files': ['system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_ifaces.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_cinder_and_ceph.yaml', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceilometer_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceilometer.yaml', 'system_test/tests/vcenter/test_vcenter_dvs.py', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_main.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_smoke.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_ceilometer.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceph_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_cinder.yaml', 'doc/system_tests.rst', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_bvt.yaml', 'system_test/tests/vcenter/__init__.py', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_cindervmdk_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_multiple_clusters.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_glance.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_ceph.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl_comp-vmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cindervmware.yaml'], 'web_link': 'https://opendev.org/openstack/fuel-qa/commit/e98ef8cb59e3afb672ef47d72fe7a5b812d9e6cd', 'message': 'Update vCenter tests for 8.0 release\n\nChange-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b\nCloses-bug: #1524645\n'}]",0,255749,e98ef8cb59e3afb672ef47d72fe7a5b812d9e6cd,54,11,9,15921,,,0,"Update vCenter tests for 8.0 release

Change-Id: I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b
Closes-bug: #1524645
",git fetch https://review.opendev.org/openstack/fuel-qa refs/changes/49/255749/1 && git format-patch -1 --stdout FETCH_HEAD,"['system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_computevmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_ifaces.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_cinder_and_ceph.yaml', 'fuelweb_test/run_tests.py', 'fuelweb_test/settings.py', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceilometer_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceilometer.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_main.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_controller.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_smoke.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_ceph.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_ceilometer.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ceph_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_cinder.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_dvs_bvt.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/dvs_main.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_glance_backend_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_cindervmdk_and_computevmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_ha_multiple_clusters.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/vcenter_glance.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_multiroles_cindervmdk_and_ceph.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/2clusters_ctrl_comp-vmware.yaml', 'system_test/tests_templates/cluster_configs/settings/vmware/nova_compute/1cluster_comp-vmware.yaml', 'system_test/tests_templates/tests_configs/vcenter_dvs/vcenter_add_cindervmware.yaml']",27,7da2b20314031bf9061a8cfc1ed605641f051179,I7fff70f9149dcc8e9bbb73e2c4471594c0249e2b,"--- template: name: 3 controllers, 1 compute + cinder, 1 compute-vmware on Neutron/VLAN with DVS plugin slaves: 6 cluster_template: name: vcenter_add_cindervmware release: ubuntu network: !include cluster_configs/networks/neutron_vlan.yaml settings: components: !include cluster_configs/settings/components/wo_components.yaml storages: !include cluster_configs/settings/storages/cinder_only.yaml vmware_vcenter: settings: !include cluster_configs/settings/vmware/vcenter_main.yaml nova-compute: !include cluster_configs/settings/vmware/nova_compute/2clusters_ctrl.yaml glance: enable: false vmware_dvs: !include cluster_configs/settings/vmware/dvs_main.yaml nodes: - roles: - controller iface: !include cluster_configs/settings/vmware/vcenter_ifaces.yaml count: 3 - roles: - compute - cinder iface: !include cluster_configs/settings/vmware/vcenter_ifaces.yaml count: 1 - roles: - compute-vmware iface: !include cluster_configs/settings/vmware/vcenter_ifaces.yaml count: 1 scale_nodes: - - roles: - cinder-vmware count: 1",,723,0
openstack%2Fgovernance~master~I8978af21f49e18ccd1f9b8de848f507eb7d4f962,openstack/governance,master,I8978af21f49e18ccd1f9b8de848f507eb7d4f962,Add performance-docs under Rally project,MERGED,2015-12-03 10:57:33.000000000,2015-12-11 10:11:10.000000000,2015-12-11 10:11:09.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 970}, {'_account_id': 3012}, {'_account_id': 6159}, {'_account_id': 6172}, {'_account_id': 17130}, {'_account_id': 18137}]","[{'number': 1, 'created': '2015-12-03 10:57:33.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/5870472b856532f52adb3dc0438396d7f127dbf8', 'message': 'Add performance-docs under Rally project\n\nDepends-On: I1dc27f77d72babdfef2d63abef52cef50454c01e\nChange-Id: I8978af21f49e18ccd1f9b8de848f507eb7d4f962\n'}]",0,252878,5870472b856532f52adb3dc0438396d7f127dbf8,16,9,1,3012,,,0,"Add performance-docs under Rally project

Depends-On: I1dc27f77d72babdfef2d63abef52cef50454c01e
Change-Id: I8978af21f49e18ccd1f9b8de848f507eb7d4f962
",git fetch https://review.opendev.org/openstack/governance refs/changes/78/252878/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,5870472b856532f52adb3dc0438396d7f127dbf8,new-project, - openstack/performance-docs,,1,0
openstack%2Ffuel-web~master~I0b4f7c81bd1619002483c5eea6750765e7e8f091,openstack/fuel-web,master,I0b4f7c81bd1619002483c5eea6750765e7e8f091,Fix styles to support nice UI with Japanese language,MERGED,2015-12-11 09:03:22.000000000,2015-12-11 10:10:37.000000000,2015-12-11 09:53:47.000000000,"[{'_account_id': 3}, {'_account_id': 8735}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-11 09:03:22.000000000', 'files': ['nailgun/static/styles/main.less'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/ce4e8f889be7574522c9441203de10be1da35234', 'message': 'Fix styles to support nice UI with Japanese language\n\n* Level volumn was extended to min 60px width on Logs tab\n* Standard node panel status block extended a little to\n  support more longer status string\n\nCloses-Bug: #1506131\nCloses-Bug: #1521141\n\nChange-Id: I0b4f7c81bd1619002483c5eea6750765e7e8f091\n'}]",0,256290,ce4e8f889be7574522c9441203de10be1da35234,14,3,1,8766,,,0,"Fix styles to support nice UI with Japanese language

* Level volumn was extended to min 60px width on Logs tab
* Standard node panel status block extended a little to
  support more longer status string

Closes-Bug: #1506131
Closes-Bug: #1521141

Change-Id: I0b4f7c81bd1619002483c5eea6750765e7e8f091
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/90/256290/1 && git format-patch -1 --stdout FETCH_HEAD,['nailgun/static/styles/main.less'],1,ce4e8f889be7574522c9441203de10be1da35234,bug/1506131, min-width: 60px; width: 22%; width: @node-button-size; margin-left: 15px;, width: 50px; width: 20%; width: 5%; margin-left: 24px;,4,4
openstack%2Fgovernance~master~I2d89704a1dc85754057d3f3d3322d10fe09eeb7f,openstack/governance,master,I2d89704a1dc85754057d3f3d3322d10fe09eeb7f,Sahara dashboard extracted back from Horizon to sahara-dashboard repo,MERGED,2015-12-02 18:40:02.000000000,2015-12-11 10:10:12.000000000,2015-12-11 10:10:11.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 970}, {'_account_id': 6159}, {'_account_id': 6786}, {'_account_id': 7125}, {'_account_id': 7132}, {'_account_id': 7555}, {'_account_id': 7710}, {'_account_id': 8090}, {'_account_id': 8091}, {'_account_id': 8304}, {'_account_id': 8411}, {'_account_id': 10670}, {'_account_id': 12038}, {'_account_id': 13953}]","[{'number': 1, 'created': '2015-12-02 18:40:02.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/475aa9e017ac491ce1bf57b3a68c34962401e6f8', 'message': ""Sahara dashboard extracted back from Horizon to sahara-dashboard repo\n\nCurrently we're working on extracting back the Sahara dashboard\ncodebase from Horizon repository to the sahara-dashboard. It'll be\nfully ready in M-2 time frame.\n\nChange-Id: I2d89704a1dc85754057d3f3d3322d10fe09eeb7f\n""}]",0,252547,475aa9e017ac491ce1bf57b3a68c34962401e6f8,14,16,1,6786,,,0,"Sahara dashboard extracted back from Horizon to sahara-dashboard repo

Currently we're working on extracting back the Sahara dashboard
codebase from Horizon repository to the sahara-dashboard. It'll be
fully ready in M-2 time frame.

Change-Id: I2d89704a1dc85754057d3f3d3322d10fe09eeb7f
",git fetch https://review.opendev.org/openstack/governance refs/changes/47/252547/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,475aa9e017ac491ce1bf57b3a68c34962401e6f8,, - openstack/sahara-dashboard," sahara-dashboard: repos: - openstack/sahara-dashboard tags: - type:library # NOTE(dhellmann): The dashboard has been merged into horizon, # and is no longer released. - release:none",1,8
openstack%2Fgovernance~master~I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3,openstack/governance,master,I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3,Standardizes name of freezer service to match conventions,MERGED,2015-11-25 13:40:27.000000000,2015-12-11 10:09:58.000000000,2015-12-11 10:09:57.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 11151}]","[{'number': 1, 'created': '2015-11-25 13:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/0e8b26eff5f6d7dd99f99e9ef777bd04a3ad7bf3', 'message': 'Standardizes name of freezer service to match conventions\n\nChange-Id: I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3\nReference: http://governance.openstack.org/reference/service-project-naming.html#service-name-guidelines\n'}, {'number': 2, 'created': '2015-11-25 15:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/ede902d272d7751b95b845f63576eea51b2d3a0c', 'message': 'Standardizes name of freezer service to match conventions\n\nChange-Id: I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3\nReference: http://governance.openstack.org/reference/service-project-naming.html#service-name-guidelines\n'}, {'number': 3, 'created': '2015-12-08 20:31:45.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/a3daf2051ffc77cf8528a5ba045489e681e4ea43', 'message': 'Standardizes name of freezer service to match conventions\n\nChange-Id: I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3\nReference: http://governance.openstack.org/reference/service-project-naming.html#service-name-guidelines\n'}]",5,249788,a3daf2051ffc77cf8528a5ba045489e681e4ea43,24,8,3,964,,,0,"Standardizes name of freezer service to match conventions

Change-Id: I2ed591dd824ec789bb26e9ac727b14c5e4f06ce3
Reference: http://governance.openstack.org/reference/service-project-naming.html#service-name-guidelines
",git fetch https://review.opendev.org/openstack/governance refs/changes/88/249788/1 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,0e8b26eff5f6d7dd99f99e9ef777bd04a3ad7bf3,249788," service: Backup, Restore, and Recover", service: backup restore and disaster recovery as a service,1,1
openstack%2Fopenstack-ansible-lxc_container_create~master~If188d528944470cf99d2551c284e2c5cba4a4aac,openstack/openstack-ansible-lxc_container_create,master,If188d528944470cf99d2551c284e2c5cba4a4aac,Update run_tests to be more complete,MERGED,2015-12-09 13:41:28.000000000,2015-12-11 10:07:45.000000000,2015-12-11 10:07:44.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 13:41:28.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/37a1f4cd16487ee5aa60f0030944e312e854d227', 'message': 'Update run_tests to be more complete\n\nThis patch updates the run_tests convenience script to make it\nexecute all test environments using tox, but also ensures that\nall the correct pre-requisites are in place before doing so.\n\nChange-Id: If188d528944470cf99d2551c284e2c5cba4a4aac\n'}]",0,255260,37a1f4cd16487ee5aa60f0030944e312e854d227,11,3,1,6816,,,0,"Update run_tests to be more complete

This patch updates the run_tests convenience script to make it
execute all test environments using tox, but also ensures that
all the correct pre-requisites are in place before doing so.

Change-Id: If188d528944470cf99d2551c284e2c5cba4a4aac
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/60/255260/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,37a1f4cd16487ee5aa60f0030944e312e854d227,,"envlist = docs,pep8,bashate,ansible-syntax,ansible-lint,ansible-functional","envlist = docs,pep8,bashate,ansible-syntax,ansible-lint",21,16
openstack%2Ffuel-web~master~I5bfb135fe95ed8faee6df81e31748e0143c568e6,openstack/fuel-web,master,I5bfb135fe95ed8faee6df81e31748e0143c568e6,Introduced policies to resolve nodes by its role,MERGED,2015-12-10 13:01:05.000000000,2015-12-11 10:06:18.000000000,2015-12-11 09:49:35.000000000,"[{'_account_id': 3}, {'_account_id': 8392}, {'_account_id': 8735}, {'_account_id': 8749}, {'_account_id': 8776}, {'_account_id': 8786}, {'_account_id': 8907}, {'_account_id': 8971}, {'_account_id': 9977}, {'_account_id': 10391}, {'_account_id': 12200}, {'_account_id': 13505}, {'_account_id': 16518}, {'_account_id': 18205}, {'_account_id': 19158}]","[{'number': 1, 'created': '2015-12-10 13:01:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/b92a93e30b17c960a2c236f59961bc2d1e8e1131', 'message': 'Introduced policies to resolve nodes by its role\n\nNullResolver the fake resolver\nPatternBasedRoleResolver allows to use pattern in name of role\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I5bfb135fe95ed8faee6df81e31748e0143c568e6\n'}, {'number': 2, 'created': '2015-12-10 15:35:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/27412bb79f844a9d2b3e4ade42037d2a5f1434fe', 'message': 'Introduced policies to resolve nodes by its role\n\nNullResolver the fake resolver\nPatternBasedRoleResolver allows to use pattern in name of role\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I5bfb135fe95ed8faee6df81e31748e0143c568e6\n'}, {'number': 3, 'created': '2015-12-10 18:22:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c9b817c67085d5757cbe27689f0b55c87fc8e2c7', 'message': 'Introduced policies to resolve nodes by its role\n\nNullResolver the fake resolver\nPatternBasedRoleResolver allows to use pattern in name of role\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I5bfb135fe95ed8faee6df81e31748e0143c568e6\n'}, {'number': 4, 'created': '2015-12-10 18:25:02.000000000', 'files': ['nailgun/nailgun/utils/role_resolver.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/test/unit/test_role_resolver.py'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/eea95621e0f4afb8d21607e670024ce8a0e835ec', 'message': 'Introduced policies to resolve nodes by its role\n\nNullResolver the fake resolver\nPatternBasedRoleResolver allows to use pattern in name of role\n\nimplements blueprint: task-based-deployment-astute\n\nChange-Id: I5bfb135fe95ed8faee6df81e31748e0143c568e6\n'}]",33,255857,eea95621e0f4afb8d21607e670024ce8a0e835ec,47,15,4,18205,,,0,"Introduced policies to resolve nodes by its role

NullResolver the fake resolver
PatternBasedRoleResolver allows to use pattern in name of role

implements blueprint: task-based-deployment-astute

Change-Id: I5bfb135fe95ed8faee6df81e31748e0143c568e6
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/57/255857/4 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/nailgun/utils/role_resolver.py', 'nailgun/nailgun/consts.py', 'nailgun/nailgun/test/unit/test_role_resolver.py']",3,b92a93e30b17c960a2c236f59961bc2d1e8e1131,bp/task-based-deployment-astute,"# -*- coding: utf-8 -*- # Copyright 2014 Mirantis, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock import six from nailgun import consts from nailgun.test.base import BaseUnitTest from nailgun.utils import role_resolver class TestNameMatchPolicy(BaseUnitTest): def test_exact_match(self): match_policy = role_resolver.NameMatchPolicy.create(""controller"") self.assertIsInstance(match_policy, role_resolver.ExactMatch) self.assertTrue(match_policy.match(""controller"")) self.assertFalse(match_policy.match(""controller1"")) def test_pattern_match(self): match_policy = role_resolver.NameMatchPolicy.create(""/controller/"") self.assertIsInstance(match_policy, role_resolver.PatternMatch) self.assertTrue(match_policy.match(""controller"")) self.assertTrue(match_policy.match(""controller1"")) class TestPatternBasedRoleResolver(BaseUnitTest): @classmethod def setUpClass(cls): cls.roles_of_nodes = [ [""primary-controller""], [""cinder""], [""controller"", ""compute""], [""controller"", ""cinder""], [""compute""], ] cls.nodes = [ mock.MagicMock(uid=str(i)) for i in six.moves.range(len(cls.roles_of_nodes)) ] def setUp(self): objs_mock = mock.patch('nailgun.utils.role_resolver.objects').start() objs_mock.Node.all_roles.side_effect = self.roles_of_nodes self.addCleanup(objs_mock.stop) def test_resolve_by_pattern(self): resolver = role_resolver.PatternBasedRoleResolver(self.nodes) self.assertItemsEqual( [""0"", ""2"", ""3""], resolver.resolve([""/.*controller/""]) ) self.assertItemsEqual( [""2"", ""3""], resolver.resolve([""controller""]) ) self.assertItemsEqual( [""1"", ""2"", ""3"", ""4""], resolver.resolve([""/c.+/""]) ) def test_resolve_all(self): resolver = role_resolver.PatternBasedRoleResolver(self.nodes) self.assertItemsEqual( (x.uid for x in self.nodes), resolver.resolve(""*"") ) def test_resolve_master(self): resolver = role_resolver.PatternBasedRoleResolver(self.nodes) self.assertEqual( [consts.MASTER_ROLE], resolver.resolve(consts.MASTER_ROLE) ) def test_resolve_any(self): resolver = role_resolver.PatternBasedRoleResolver(self.nodes) all_nodes = resolver.resolve(""*"", consts.NODE_RESOLVE_POLICY.all) any_node = resolver.resolve(""*"", consts.NODE_RESOLVE_POLICY.any) self.assertEqual(1, len(any_node)) self.assertIn(any_node[0], all_nodes) class TestNullResolver(BaseUnitTest): def test_resolve(self): node_ids = ['1', '2', '3'] self.assertIs( node_ids, role_resolver.NullResolver(node_ids).resolve(""controller"") ) ",,257,0
openstack%2Fnetworking-bgpvpn~master~Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af,openstack/networking-bgpvpn,master,Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af,Remove partial implementation of auto_aggregate,MERGED,2015-12-02 16:57:27.000000000,2015-12-11 09:59:24.000000000,2015-12-11 09:59:23.000000000,"[{'_account_id': 3}, {'_account_id': 55}, {'_account_id': 2888}, {'_account_id': 12021}, {'_account_id': 16351}]","[{'number': 1, 'created': '2015-12-02 16:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/21b9948363d6196fbe8312fd9be2d190dfbb18d0', 'message': 'Document auto_aggregate attribute as future\n\nThis change updates API documentation to indicate\nthat the auto_aggregate attribute is not implemented yet.\n\nChange-Id: Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af\n'}, {'number': 2, 'created': '2015-12-03 09:31:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/b2892d23ab4114b9a209071c110c84f0820ac172', 'message': 'Remove partial implementation of auto_aggregate\n\nThis change removes all the code related to the auto_aggregate\nattribute.  The intent is to revert this change when/if drivers\nstart to support this attribute.\n\nThis change also updates the API documentation to indicate\nthat the auto_aggregate attribute is not implemented yet.\n\nCloses-Bug: 1522325\nChange-Id: Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af\n'}, {'number': 3, 'created': '2015-12-03 09:40:19.000000000', 'files': ['doc/source/future/attributes.rst', 'networking_bgpvpn/neutron/services/common/utils.py', 'networking_bgpvpn/tests/unit/extensions/test_bgpvpn.py', 'networking_bgpvpn/neutron/db/bgpvpn_db.py', 'networking_bgpvpn/tests/unit/services/test_plugin.py', 'doc/source/api.rst', 'networking_bgpvpn/neutronclient/neutron/v2_0/bgpvpn/bgpvpn.py', 'networking_bgpvpn/tests/unit/services/odl/test_odl.py', 'networking_bgpvpn/neutron/db/migration/alembic_migrations/versions/liberty/expand/17d9fd4fddee_initial.py', 'networking_bgpvpn/tests/unit/db/test_db.py', 'networking_bgpvpn/neutron/extensions/bgpvpn.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/b3ddcf22123af47964975e13c844ff02bc9c4fbc', 'message': 'Remove partial implementation of auto_aggregate\n\nThis change removes all the code related to the auto_aggregate\nattribute.  The intent is to revert this change when/if drivers\nstart to support this attribute.\n\nThis change also updates the API documentation to indicate\nthat the auto_aggregate attribute is not implemented yet.\n\nCloses-Bug: 1522325\nChange-Id: Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af\n'}]",2,252519,b3ddcf22123af47964975e13c844ff02bc9c4fbc,16,5,3,12021,,,0,"Remove partial implementation of auto_aggregate

This change removes all the code related to the auto_aggregate
attribute.  The intent is to revert this change when/if drivers
start to support this attribute.

This change also updates the API documentation to indicate
that the auto_aggregate attribute is not implemented yet.

Closes-Bug: 1522325
Change-Id: Ia4aec84f5f9022e98b0d417e265a9201cbc0d5af
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/19/252519/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/future/attributes.rst', 'doc/source/api.rst']",2,21b9948363d6196fbe8312fd9be2d190dfbb18d0,bug/1522325,," auto_aggregate,bool,RW admin only,False,{ True | False },enable prefix aggregation or not (type l3 only)",2,2
openstack%2Fopenstack-ansible-rsyslog_server~master~I5a3bcb95afcb0b9efe17c66e3c623c76418405e4,openstack/openstack-ansible-rsyslog_server,master,I5a3bcb95afcb0b9efe17c66e3c623c76418405e4,updated repo pathing for new org,MERGED,2015-12-10 17:42:07.000000000,2015-12-11 09:46:32.000000000,2015-12-11 09:46:32.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2015-12-10 17:42:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/a42a2dc2864efa431a40ce1310ec74c474bae1f0', 'message': 'updated repo pathing for new org\n\nChange-Id: I5a3bcb95afcb0b9efe17c66e3c623c76418405e4\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/764e2afdb3ad0f192a0dde9afa9fccba1775c424', 'message': 'updated repo pathing for new org\n\nChange-Id: I5a3bcb95afcb0b9efe17c66e3c623c76418405e4\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-10 22:57:26.000000000', 'files': ['tests/ansible.cfg', '.gitignore', '.gitreview'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/0cf98aeda8b9c1ed3cfafc282c662f447b24edde', 'message': 'updated repo pathing for new org\n\nChange-Id: I5a3bcb95afcb0b9efe17c66e3c623c76418405e4\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256010,0cf98aeda8b9c1ed3cfafc282c662f447b24edde,12,2,3,7353,,,0,"updated repo pathing for new org

Change-Id: I5a3bcb95afcb0b9efe17c66e3c623c76418405e4
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/10/256010/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview']",2,a42a2dc2864efa431a40ce1310ec74c474bae1f0,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-rsyslog_server.git ,,66,0
openstack%2Fopenstack-ansible-memcached_server~master~I80feddde8f79f86f0cb6089becca941cdd708b89,openstack/openstack-ansible-memcached_server,master,I80feddde8f79f86f0cb6089becca941cdd708b89,updated repo pathing for new org,MERGED,2015-12-10 17:45:02.000000000,2015-12-11 09:46:26.000000000,2015-12-11 09:46:26.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2015-12-10 17:45:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/9d477b083c2231e0c3fc0b40eaa4b7555be6b60d', 'message': 'updated repo pathing for new org\n\nChange-Id: I80feddde8f79f86f0cb6089becca941cdd708b89\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/e04e1f6a2c3ed6908fadba258002ae69221de579', 'message': 'updated repo pathing for new org\n\nChange-Id: I80feddde8f79f86f0cb6089becca941cdd708b89\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-10 22:51:52.000000000', 'files': ['tests/ansible.cfg', '.gitignore', '.gitreview', 'tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/40aa9e7df5ad8f09e2de266f1c6508cd20c57026', 'message': 'updated repo pathing for new org\n\nChange-Id: I80feddde8f79f86f0cb6089becca941cdd708b89\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256015,40aa9e7df5ad8f09e2de266f1c6508cd20c57026,11,2,3,7353,,,0,"updated repo pathing for new org

Change-Id: I80feddde8f79f86f0cb6089becca941cdd708b89
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-memcached_server refs/changes/15/256015/3 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview']",2,9d477b083c2231e0c3fc0b40eaa4b7555be6b60d,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-memcached_server.git ,,66,0
openstack%2Fopenstack-ansible-repo_server~master~I6ea4732625233c1940c07535314dddbc59f2aaf0,openstack/openstack-ansible-repo_server,master,I6ea4732625233c1940c07535314dddbc59f2aaf0,updated repo pathing for new org,MERGED,2015-12-10 17:39:28.000000000,2015-12-11 09:46:25.000000000,2015-12-11 09:46:25.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 17:39:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/47c34c7eabc553d0b1afe76cd9f9089d4a865bda', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/8290eaca8006f5ba4b389348aa44e050add67816', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-10 19:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/eef0a25b6421be81c03ed134e751f4b753165b51', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2015-12-10 22:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/595c421261dbd482d4934db0616dc0593245fabc', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2015-12-11 02:34:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/c2156fcdf1457200a15c64a5dc06b5bdf7034bf5', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2015-12-11 02:47:50.000000000', 'files': ['tests/ansible.cfg', 'tests/ansible-role-requirements.yml', '.gitreview', 'tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/9d423e6144b495d51a71335ff86740e249dcc95e', 'message': 'updated repo pathing for new org\n\nChange-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256008,9d423e6144b495d51a71335ff86740e249dcc95e,20,5,6,7353,,,0,"updated repo pathing for new org

Change-Id: I6ea4732625233c1940c07535314dddbc59f2aaf0
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/08/256008/6 && git format-patch -1 --stdout FETCH_HEAD,"['tests/ansible-role-requirements.yml', '.gitreview']",2,47c34c7eabc553d0b1afe76cd9f9089d4a865bda,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-repo_server.git ,,6,1
openstack%2Fopenstack-ansible-galera_client~master~Ib93a8fa71674ada66fa4241c07a2028934b3d7e9,openstack/openstack-ansible-galera_client,master,Ib93a8fa71674ada66fa4241c07a2028934b3d7e9,updated repo pathing for new org,MERGED,2015-12-10 17:41:16.000000000,2015-12-11 09:45:27.000000000,2015-12-11 09:45:27.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-10 17:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/5fff145fe57388bf89c368c47c072a4dc1790fc4', 'message': 'updated repo pathing for new org\n\nChange-Id: Ib93a8fa71674ada66fa4241c07a2028934b3d7e9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:24:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/7a69c4ac0d281028d3b9336e24577526c9e776c2', 'message': 'updated repo pathing for new org\n\nChange-Id: Ib93a8fa71674ada66fa4241c07a2028934b3d7e9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-11 02:50:06.000000000', 'files': ['tests/ansible.cfg', '.gitignore', '.gitreview', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/315030e064ae043f64857a2c99883de7b0cbf96d', 'message': 'updated repo pathing for new org\n\nChange-Id: Ib93a8fa71674ada66fa4241c07a2028934b3d7e9\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256009,315030e064ae043f64857a2c99883de7b0cbf96d,13,3,3,7353,,,0,"updated repo pathing for new org

Change-Id: Ib93a8fa71674ada66fa4241c07a2028934b3d7e9
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/09/256009/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview']",2,5fff145fe57388bf89c368c47c072a4dc1790fc4,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-galera_client.git ,,66,0
openstack%2Fopenstack-ansible-rabbitmq_server~master~I68d7daf1fda3d8b5cd538f684e973366a3fd61c8,openstack/openstack-ansible-rabbitmq_server,master,I68d7daf1fda3d8b5cd538f684e973366a3fd61c8,updated repo pathing for new org,MERGED,2015-12-10 17:43:26.000000000,2015-12-11 09:45:25.000000000,2015-12-11 09:45:24.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17722}]","[{'number': 1, 'created': '2015-12-10 17:43:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/46023f935bc32ac8a38b80a5b5e78ce69be2c3a6', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:26:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/4fc1b4edd8a4585b15857f6421dbb5fc91cc38eb', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-10 19:29:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/68756fbcaf717faf4a873366398a2188203d45fa', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2015-12-10 22:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/b0f5d4e07342c18765c1cc93d5c40ccfd38e3c23', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 5, 'created': '2015-12-10 23:10:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/733e177e09a394c52986adf433ac3fe1b8c8f6d8', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 6, 'created': '2015-12-11 00:06:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/1c07faf576ef1fc5641c8f402a973b3642d45198', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2015-12-11 00:18:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/6a656c733f7903d43e32de1187e8e23001eeba70', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2015-12-11 00:28:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/b76f7ee492363f4281cc86559dc5376210c553b5', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 9, 'created': '2015-12-11 00:34:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/37ac3fee416b84020cea6471f6cad1f1482faaa1', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 10, 'created': '2015-12-11 02:08:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/16faca8a6e85d81b28bc3a07d39fd3c64a79355e', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 11, 'created': '2015-12-11 02:16:07.000000000', 'files': ['tests/ansible.cfg', '.gitignore', 'tests/ansible-role-requirements.yml', '.gitreview', 'tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/0779d1ecb9b5c6b6731d9be6600b1b3371ff4dee', 'message': 'updated repo pathing for new org\n\nChange-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256012,0779d1ecb9b5c6b6731d9be6600b1b3371ff4dee,31,4,11,7353,,,0,"updated repo pathing for new org

Change-Id: I68d7daf1fda3d8b5cd538f684e973366a3fd61c8
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/12/256012/8 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview']",2,46023f935bc32ac8a38b80a5b5e78ce69be2c3a6,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-rabbitmq_server.git ,,66,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I7c269971f453a79787c3b9fc8d56f513bf2d91da,openstack/openstack-ansible-lxc_hosts,master,I7c269971f453a79787c3b9fc8d56f513bf2d91da,Update run_tests to be more complete,MERGED,2015-12-09 13:45:21.000000000,2015-12-11 09:43:29.000000000,2015-12-11 09:43:27.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 13:45:21.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/f7f29d93d06de506b37da118f43237e9e5c62e81', 'message': 'Update run_tests to be more complete\n\nThis patch updates the run_tests convenience script to make it\nexecute all test environments using tox, but also ensures that\nall the correct pre-requisites are in place before doing so.\n\nChange-Id: I7c269971f453a79787c3b9fc8d56f513bf2d91da\n'}]",0,255265,f7f29d93d06de506b37da118f43237e9e5c62e81,7,3,1,6816,,,0,"Update run_tests to be more complete

This patch updates the run_tests convenience script to make it
execute all test environments using tox, but also ensures that
all the correct pre-requisites are in place before doing so.

Change-Id: I7c269971f453a79787c3b9fc8d56f513bf2d91da
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/65/255265/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,f7f29d93d06de506b37da118f43237e9e5c62e81,,"envlist = docs,pep8,bashate,ansible-syntax,ansible-lint,ansible-functional","envlist = docs,pep8,bashate,ansible-syntax,ansible-lint",21,16
openstack%2Fopenstack-ansible-openstack_hosts~master~I6fc9e93976d7bbee3fbac693990b76a5f4bfca01,openstack/openstack-ansible-openstack_hosts,master,I6fc9e93976d7bbee3fbac693990b76a5f4bfca01,Update run_tests to be more complete,MERGED,2015-12-09 13:44:28.000000000,2015-12-11 09:42:23.000000000,2015-12-11 09:42:22.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 13:44:28.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/871abd62e5326e1f4974310ba5d5982dcfcbb578', 'message': 'Update run_tests to be more complete\n\nThis patch updates the run_tests convenience script to make it\nexecute all test environments using tox, but also ensures that\nall the correct pre-requisites are in place before doing so.\n\nChange-Id: I6fc9e93976d7bbee3fbac693990b76a5f4bfca01\n'}]",0,255264,871abd62e5326e1f4974310ba5d5982dcfcbb578,7,3,1,6816,,,0,"Update run_tests to be more complete

This patch updates the run_tests convenience script to make it
execute all test environments using tox, but also ensures that
all the correct pre-requisites are in place before doing so.

Change-Id: I6fc9e93976d7bbee3fbac693990b76a5f4bfca01
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/64/255264/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,871abd62e5326e1f4974310ba5d5982dcfcbb578,,"envlist = docs,pep8,bashate,ansible-syntax,ansible-lint,ansible-functional","envlist = docs,pep8,bashate,ansible-syntax,ansible-lint",21,16
openstack%2Fopenstack-ansible-rsyslog_client~master~Ib517dade3cbc9b3cb23010a189d36d0d89f975ee,openstack/openstack-ansible-rsyslog_client,master,Ib517dade3cbc9b3cb23010a189d36d0d89f975ee,Update run_tests to be more complete,MERGED,2015-12-09 13:46:13.000000000,2015-12-11 09:41:31.000000000,2015-12-11 09:41:30.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 13:46:13.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/5c42ba7b64111952f6c2b175adcabfa0e81b3cf1', 'message': 'Update run_tests to be more complete\n\nThis patch updates the run_tests convenience script to make it\nexecute all test environments using tox, but also ensures that\nall the correct pre-requisites are in place before doing so.\n\nChange-Id: Ib517dade3cbc9b3cb23010a189d36d0d89f975ee\n'}]",0,255266,5c42ba7b64111952f6c2b175adcabfa0e81b3cf1,7,3,1,6816,,,0,"Update run_tests to be more complete

This patch updates the run_tests convenience script to make it
execute all test environments using tox, but also ensures that
all the correct pre-requisites are in place before doing so.

Change-Id: Ib517dade3cbc9b3cb23010a189d36d0d89f975ee
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/66/255266/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,5c42ba7b64111952f6c2b175adcabfa0e81b3cf1,,"envlist = docs,pep8,bashate,ansible-syntax,ansible-lint,ansible-functional","envlist = docs,pep8,bashate,ansible-syntax,ansible-lint",22,12
openstack%2Fopenstack-ansible-pip_install~master~I7c7d8caead7da9c830566b2fe71612a71205bf46,openstack/openstack-ansible-pip_install,master,I7c7d8caead7da9c830566b2fe71612a71205bf46,Update run_tests to be more complete,MERGED,2015-12-09 13:39:55.000000000,2015-12-11 09:41:13.000000000,2015-12-11 09:41:13.000000000,"[{'_account_id': 3}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 13:39:55.000000000', 'files': ['run_tests.sh', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/f88b45370222c722f808e5cdb72bb161ec630b61', 'message': 'Update run_tests to be more complete\n\nThis patch updates the run_tests convenience script to make it\nexecute all test environments using tox, but also ensures that\nall the correct pre-requisites are in place before doing so.\n\nChange-Id: I7c7d8caead7da9c830566b2fe71612a71205bf46\n'}]",0,255259,f88b45370222c722f808e5cdb72bb161ec630b61,7,3,1,6816,,,0,"Update run_tests to be more complete

This patch updates the run_tests convenience script to make it
execute all test environments using tox, but also ensures that
all the correct pre-requisites are in place before doing so.

Change-Id: I7c7d8caead7da9c830566b2fe71612a71205bf46
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/59/255259/1 && git format-patch -1 --stdout FETCH_HEAD,"['run_tests.sh', 'tox.ini']",2,f88b45370222c722f808e5cdb72bb161ec630b61,,"envlist = docs,pep8,bashate,ansible-syntax,ansible-lint,ansible-functional","envlist = docs,pep8,bashate,ansible-syntax,ansible-lint",22,12
openstack%2Fopenstack-ansible-pip_lock_down~master~If8d7b1e0e21464fc876aadd1e851e731e38a877c,openstack/openstack-ansible-pip_lock_down,master,If8d7b1e0e21464fc876aadd1e851e731e38a877c,updated repo pathing for new org,MERGED,2015-12-10 17:44:13.000000000,2015-12-11 09:41:07.000000000,2015-12-11 09:41:07.000000000,"[{'_account_id': 3}, {'_account_id': 6816}]","[{'number': 1, 'created': '2015-12-10 17:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/5d72c0a71cc3f51d89358b5d619026bac619b1cd', 'message': 'updated repo pathing for new org\n\nChange-Id: If8d7b1e0e21464fc876aadd1e851e731e38a877c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2015-12-10 19:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/efaed426c8a4297f9677e1f4b979542bfa4640fd', 'message': 'updated repo pathing for new org\n\nChange-Id: If8d7b1e0e21464fc876aadd1e851e731e38a877c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 3, 'created': '2015-12-10 19:23:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/518a0a1fc507c8443dbc045c6632a68e65726e64', 'message': 'updated repo pathing for new org\n\nChange-Id: If8d7b1e0e21464fc876aadd1e851e731e38a877c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 4, 'created': '2015-12-10 22:56:34.000000000', 'files': ['tests/ansible.cfg', '.gitignore', 'tests/ansible-role-requirements.yml', '.gitreview'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_lock_down/commit/bf5e9d4132a52deb9e268b67b325e0ae9a6ad9d5', 'message': 'updated repo pathing for new org\n\nChange-Id: If8d7b1e0e21464fc876aadd1e851e731e38a877c\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",0,256013,bf5e9d4132a52deb9e268b67b325e0ae9a6ad9d5,13,2,4,7353,,,0,"updated repo pathing for new org

Change-Id: If8d7b1e0e21464fc876aadd1e851e731e38a877c
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_lock_down refs/changes/13/256013/3 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', '.gitreview']",2,5d72c0a71cc3f51d89358b5d619026bac619b1cd,,[gerrit] host=review.openstack.org port=29418 project=openstack/openstack-ansible-pip_lock_down.git ,,66,0
openstack%2Fnetworking-midonet~master~I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f,openstack/networking-midonet,master,I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f,Add missing 'ext-gw-mode' extension to v1,MERGED,2015-08-19 13:45:31.000000000,2015-12-11 09:38:10.000000000,2015-08-20 06:03:12.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6854}, {'_account_id': 8837}]","[{'number': 1, 'created': '2015-08-19 13:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/fa9a29893b78004a35399e3346a41b8115b3ea58', 'message': ""Add missing 'ext-gw-mode' extension to v1\n\nEven though MiodNet plugin v1 supported 'ext-gw-mode', it was never\ndeclared properly in supported extension list.\n\nFixes Bug: bug/1485156\n\nChange-Id: I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f\n""}, {'number': 2, 'created': '2015-08-19 13:47:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/593603ad416296e925681132dffe59ecef125573', 'message': ""Add missing 'ext-gw-mode' extension to v1\n\nEven though MiodNet plugin v1 supported 'ext-gw-mode', it was never\ndeclared properly in supported extension list.\n\nCloses Bug:  #1485156\n\nChange-Id: I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f\n""}, {'number': 3, 'created': '2015-08-20 03:22:22.000000000', 'files': ['midonet/neutron/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-midonet/commit/384039be4ae7b1486f7b2a304d62c228d6c7582a', 'message': ""Add missing 'ext-gw-mode' extension to v1\n\nEven though MiodNet plugin v1 supported 'ext-gw-mode', it was never\ndeclared properly in supported extension list.\n\nCloses-Bug:  #1485156\n\nChange-Id: I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f\n""}]",2,214616,384039be4ae7b1486f7b2a304d62c228d6c7582a,14,4,3,156,,,0,"Add missing 'ext-gw-mode' extension to v1

Even though MiodNet plugin v1 supported 'ext-gw-mode', it was never
declared properly in supported extension list.

Closes-Bug:  #1485156

Change-Id: I8f9d8bd3a734d2193dc82cc38f47151c82e62a6f
",git fetch https://review.opendev.org/openstack/networking-midonet refs/changes/16/214616/2 && git format-patch -1 --stdout FETCH_HEAD,['midonet/neutron/plugin.py'],1,fa9a29893b78004a35399e3346a41b8115b3ea58,(detached," supported_extension_aliases = ['ext-gw-mode', 'extra_dhcp_opt']", supported_extension_aliases = ['extra_dhcp_opt'],1,1
openstack%2Fopenstack-ansible~master~I18ef63747369c6722194b6412fea24fbb248ab1d,openstack/openstack-ansible,master,I18ef63747369c6722194b6412fea24fbb248ab1d,Added in keystone reserved port,MERGED,2015-06-29 15:19:55.000000000,2015-12-11 09:30:39.000000000,2015-12-10 19:44:00.000000000,"[{'_account_id': 3}, {'_account_id': 4}, {'_account_id': 425}, {'_account_id': 538}, {'_account_id': 6816}, {'_account_id': 7217}, {'_account_id': 7219}, {'_account_id': 7244}, {'_account_id': 7307}, {'_account_id': 7353}, {'_account_id': 12807}, {'_account_id': 12952}, {'_account_id': 14288}, {'_account_id': 15993}]","[{'number': 1, 'created': '2015-06-29 15:19:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/61adc32ca0f87f4846ffe9de3f310f8ef6a6ae8b', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\n'}, {'number': 2, 'created': '2015-07-07 11:05:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a8540f70fb192e7ebccd5a7ab4a81926da0acdce', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\n'}, {'number': 3, 'created': '2015-07-13 14:30:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/738e5eac9f28a13cb8dd32ef4c8ddf7fa38e0c98', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\n'}, {'number': 4, 'created': '2015-07-16 00:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/612dd27df27f15620864b29b4596e0a6538dc6c5', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\n'}, {'number': 5, 'created': '2015-09-09 04:17:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/53a37cc7936625d96a991ba50ecf44bcdf63b60f', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\n'}, {'number': 6, 'created': '2015-12-02 01:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e23bf133c49d368e6ae0cad03e51235b4934bb83', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 7, 'created': '2015-12-03 16:26:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/50f54918597840dee039a5fe6e0c7305c4fe4858', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nCloses-Bug: #1426371\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 8, 'created': '2015-12-10 01:48:28.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/41b23acac3b3292693514365d6fd88af0fb33f4f', 'message': 'Added in keystone reserved port\n\nThis change adds a reserved port for keystone based on the defined\nadmin port in the variable `keystone_admin_port`.\n\nPlease note this task is expected to fail as the current trusty kernel\ndoes not support this action\n(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)\n\nChange-Id: I18ef63747369c6722194b6412fea24fbb248ab1d\nPartial-Bug: #1426371\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",13,196702,41b23acac3b3292693514365d6fd88af0fb33f4f,64,14,8,7353,,,0,"Added in keystone reserved port

This change adds a reserved port for keystone based on the defined
admin port in the variable `keystone_admin_port`.

Please note this task is expected to fail as the current trusty kernel
does not support this action
(https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041)

Change-Id: I18ef63747369c6722194b6412fea24fbb248ab1d
Partial-Bug: #1426371
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/02/196702/8 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/roles/os_keystone/tasks/keystone_pre_install.yml'],1,61adc32ca0f87f4846ffe9de3f310f8ef6a6ae8b,bug/1426371," - name: Add keystone reserved port sysctl: name: ""{{ item.key }}"" value: ""{{ item.value }}"" sysctl_set: ""{{ item.set|default('yes') }}"" state: ""{{ item.state|default('present') }}"" reload: ""{{ item.reload|default('yes') }}"" with_items: - { key: ""net.ipv4.ip_local_reserved_ports"", value: ""{{ keystone_admin_port }}""} ignore_errors: true tags: - keystone-reserved-port",,13,0
openstack%2Fopenstack-ansible~master~Iec03c768a9fadf82831af4b90db1907abd399966,openstack/openstack-ansible,master,Iec03c768a9fadf82831af4b90db1907abd399966,Use fastest Linux mirrors for gate jobs,MERGED,2015-12-04 20:20:47.000000000,2015-12-11 09:30:28.000000000,2015-12-10 22:42:02.000000000,"[{'_account_id': 3}, {'_account_id': 425}, {'_account_id': 6816}, {'_account_id': 12807}, {'_account_id': 15993}]","[{'number': 1, 'created': '2015-12-04 20:20:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/e4ca795c71cf9c58acccf87e6df3c4f76b0fa127', 'message': ""Use fastest Linux mirrors for gate jobs\n\nSome new providers for OpenStack CI have popped up in the last week and\nthis patch ensures we're using the fastest possible mirrors in those\nlocations.\n\nCloses-bug: 1522957\n\nChange-Id: Iec03c768a9fadf82831af4b90db1907abd399966\n""}, {'number': 2, 'created': '2015-12-09 19:02:18.000000000', 'files': ['scripts/gate-check-commit.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/8f78f257d11dc2d788cf52099a0a5e34c32e4fce', 'message': ""Use fastest Linux mirrors for gate jobs\n\nSome new providers for OpenStack CI have popped up in the last week and\nthis patch ensures we're using the fastest possible mirrors in those\nlocations.\n\nCloses-bug: 1522957\n\nChange-Id: Iec03c768a9fadf82831af4b90db1907abd399966\n""}]",0,253686,8f78f257d11dc2d788cf52099a0a5e34c32e4fce,15,5,2,538,,,0,"Use fastest Linux mirrors for gate jobs

Some new providers for OpenStack CI have popped up in the last week and
this patch ensures we're using the fastest possible mirrors in those
locations.

Closes-bug: 1522957

Change-Id: Iec03c768a9fadf82831af4b90db1907abd399966
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/86/253686/2 && git format-patch -1 --stdout FETCH_HEAD,['scripts/gate-check-commit.sh'],1,e4ca795c71cf9c58acccf87e6df3c4f76b0fa127,bug/1522957," # Get the fastest possible Linux mirror depending on the datacenter where the # tests are running. case ${NODEPOOL_PROVIDER} in ""rax-dfw""*) export UBUNTU_REPO=""http://dfw.mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""rax-ord""*) export UBUNTU_REPO=""http://ord.mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""rax-iad""*) export UBUNTU_REPO=""http://iad.mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""hpcloud""*) export UBUNTU_REPO=""http://${NODEPOOL_AZ}.clouds.archive.ubuntu.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""ovh-gra1""*) export UBUNTU_REPO=""http://ubuntu.mirrors.ovh.net/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""ovh-bhs1""*) export UBUNTU_REPO=""http://ubuntu.bhs.mirrors.ovh.net/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""bluebox-sjc1""*) export UBUNTU_REPO=""http://ord.mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; ""internap-nyj01""*) export UBUNTU_REPO=""http://iad.mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" ;; esac"," if [[ ${NODEPOOL_PROVIDER} == ""rax""* ]]; then # Set the Ubuntu Repository to the RAX Mirror export UBUNTU_REPO=""http://mirror.rackspace.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" elif [[ ${NODEPOOL_PROVIDER} == ""hpcloud""* ]]; then # Set the Ubuntu Repository to the HP Cloud Mirror export UBUNTU_REPO=""http://${NODEPOOL_AZ}.clouds.archive.ubuntu.com/ubuntu"" export UBUNTU_SEC_REPO=""${UBUNTU_REPO}"" fi",36,13
openstack%2Foslo.messaging~stable%2Fliberty~I18144ede387e1d28f7b5de0131b6b6cc7d57bb86,openstack/oslo.messaging,stable/liberty,I18144ede387e1d28f7b5de0131b6b6cc7d57bb86,Don't hold the connection when reply fail,MERGED,2015-12-02 12:10:43.000000000,2015-12-11 09:30:18.000000000,2015-12-11 09:30:18.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 6159}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-12-02 12:10:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8e64a599b1637beeb8caa39f7a7d44f486538651', 'message': ""Don't hold the connection when reply fail\n\nThis change moves the reply retry code to upper layer\nto be able to release the connection while we wait between\ntwo retries.\n\nIn the worse scenario, a client waits for more than 30 replies\nand died/restart, the server tries to send this 30 replies to this\nthis client and can wait too 60s per replies. During this\nreplies for other clients are just stuck.\n\nThis change fixes that.\n\nRelated-bug: #1477914\nCloses-bug: #1521958\n\n(cherry picked from commit I0d3c16ea6d2c1da143de4924b3be41d1cea159bd)\n\nConflicts:\n\toslo_messaging/_drivers/amqpdriver.py\n\toslo_messaging/_drivers/impl_rabbit.py\n\nChange-Id: I18144ede387e1d28f7b5de0131b6b6cc7d57bb86\n""}, {'number': 2, 'created': '2015-12-09 12:26:04.000000000', 'files': ['oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/impl_rabbit.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8504e2508bbec963ae817cc31fec509d058c0e96', 'message': ""Don't hold the connection when reply fail\n\nThis change moves the reply retry code to upper layer\nto be able to release the connection while we wait between\ntwo retries.\n\nIn the worse scenario, a client waits for more than 30 replies\nand died/restart, the server tries to send this 30 replies to this\nthis client and can wait too 60s per replies. During this\nreplies for other clients are just stuck.\n\nThis change fixes that.\n\nRelated-bug: #1477914\nCloses-bug: #1521958\n\n(cherry picked from commit I0d3c16ea6d2c1da143de4924b3be41d1cea159bd)\n\nConflicts:\n\toslo_messaging/_drivers/amqpdriver.py\n\toslo_messaging/_drivers/impl_rabbit.py\n\nDepends-On: Ibce834c3e76d71a770013cf1b469aa86396751b9\nChange-Id: I18144ede387e1d28f7b5de0131b6b6cc7d57bb86\n""}]",0,252359,8504e2508bbec963ae817cc31fec509d058c0e96,11,5,2,2813,,,0,"Don't hold the connection when reply fail

This change moves the reply retry code to upper layer
to be able to release the connection while we wait between
two retries.

In the worse scenario, a client waits for more than 30 replies
and died/restart, the server tries to send this 30 replies to this
this client and can wait too 60s per replies. During this
replies for other clients are just stuck.

This change fixes that.

Related-bug: #1477914
Closes-bug: #1521958

(cherry picked from commit I0d3c16ea6d2c1da143de4924b3be41d1cea159bd)

Conflicts:
	oslo_messaging/_drivers/amqpdriver.py
	oslo_messaging/_drivers/impl_rabbit.py

Depends-On: Ibce834c3e76d71a770013cf1b469aa86396751b9
Change-Id: I18144ede387e1d28f7b5de0131b6b6cc7d57bb86
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/59/252359/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/impl_rabbit.py']",2,8e64a599b1637beeb8caa39f7a7d44f486538651,bug/1477914," def _publish_and_raises_on_missing_exchange(self, exchange, msg, routing_key=None, timeout=None): """"""Publisher that raises exception if exchange is missing."""""" try: self._publish(exchange, msg, routing_key=routing_key, timeout=timeout) return except self.connection.channel_errors as exc: if exc.code == 404: raise rpc_amqp.AMQPDestinationNotFound( ""exchange %s doesn't exists"" % exchange.name) raise self._ensure_publishing(self._publish_and_raises_on_missing_exchange, self.missing_destination_retry_timeout = ( conf.oslo_messaging_rabbit.kombu_reconnect_timeout) "," def _publish_and_retry_on_missing_exchange(self, exchange, msg, routing_key=None, timeout=None): """"""Publisher that retry if the exchange is missing. """""" # TODO(sileht): use @retrying # NOTE(sileht): no need to wait the application expect a response # before timeout is exshauted duration = ( timeout if timeout is not None else self.kombu_reconnect_timeout ) timer = rpc_common.DecayingTimer(duration=duration) timer.start() while True: try: self._publish(exchange, msg, routing_key=routing_key, timeout=timeout) return except self.connection.channel_errors as exc: if exc.code == 404 and timer.check_return() > 0: LOG.info(_LI(""The exchange %(exchange)s to send to "" ""%(routing_key)s doesn't exist yet, "" ""retrying..."") % { 'exchange': exchange.name, 'routing_key': routing_key}) time.sleep(0.25) continue elif exc.code == 404: msg = _(""The exchange %(exchange)s to send to "" ""%(routing_key)s still doesn't exist after "" ""%(duration)s sec abandonning..."") % { 'duration': duration, 'exchange': exchange.name, 'routing_key': routing_key} LOG.info(msg) raise rpc_amqp.AMQPDestinationNotFound(msg) raise self._ensure_publishing(self._publish_and_retry_on_missing_exchange,",61,54
openstack%2Foslo.messaging~stable%2Fkilo~I4bc323f0b9578cfd4972f882d6fbf59b9064ca53,openstack/oslo.messaging,stable/kilo,I4bc323f0b9578cfd4972f882d6fbf59b9064ca53,Don't trigger error_callback for known exc,MERGED,2015-12-09 21:21:27.000000000,2015-12-11 09:29:52.000000000,2015-12-11 09:29:51.000000000,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 7491}]","[{'number': 1, 'created': '2015-12-09 21:21:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/3771a4898b2a38219568ea8a54b451de9a5e0703', 'message': ""Don't trigger error_callback for known exc\n\nWhen AMQPDestinationNotFound is raised, we must not\ncall the error_callback method. The exception is logged\nonly if needed in upper layer (amqpdriver.py).\n\nRelated-bug: #1524418\n\n(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)\n\nChange-Id: I4bc323f0b9578cfd4972f882d6fbf59b9064ca53\n""}, {'number': 2, 'created': '2015-12-10 06:41:16.000000000', 'files': ['oslo_messaging/_drivers/impl_rabbit.py', 'oslo_messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/8093aefaae695bc4407b451f8863ed1137a0e022', 'message': ""Don't trigger error_callback for known exc\n\nWhen AMQPDestinationNotFound is raised, we must not\ncall the error_callback method. The exception is logged\nonly if needed in upper layer (amqpdriver.py).\n\nRelated-bug: #1524418\nRelated-bug: #1521958\n\n(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)\n\nChange-Id: I4bc323f0b9578cfd4972f882d6fbf59b9064ca53\n""}]",0,255530,8093aefaae695bc4407b451f8863ed1137a0e022,10,3,2,2813,,,0,"Don't trigger error_callback for known exc

When AMQPDestinationNotFound is raised, we must not
call the error_callback method. The exception is logged
only if needed in upper layer (amqpdriver.py).

Related-bug: #1524418
Related-bug: #1521958

(cherry picked from commit Ic1ddec2d13172532dbaa572d04a4c22c97ac4fe7)

Change-Id: I4bc323f0b9578cfd4972f882d6fbf59b9064ca53
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/30/255530/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/_drivers/impl_rabbit.py'],1,3771a4898b2a38219568ea8a54b451de9a5e0703,bug/1524418, except rpc_amqp.AMQPDestinationNotFound: # NOTE(sileht): we must reraise this without # trigger error_callback raise,,4,0
openstack%2Fdevstack~master~Ib8d8a98f9e47c6f1332d8886366cce33f2891cab,openstack/devstack,master,Ib8d8a98f9e47c6f1332d8886366cce33f2891cab,Optimize install_package function when executing nominal flow.,ABANDONED,2015-11-22 14:11:36.000000000,2015-12-11 09:28:12.000000000,,"[{'_account_id': 3}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11604}, {'_account_id': 14287}, {'_account_id': 17377}]","[{'number': 1, 'created': '2015-11-22 14:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/96d17a481047129bcc1e1cc7ae2b6f843ab85ac0', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nCloses-bug: #1518544\n'}, {'number': 2, 'created': '2015-11-22 14:33:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/7977c0913ee8164bf76dc5007a5d5fb36d14913c', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nCloses-bug: #1518544\n'}, {'number': 3, 'created': '2015-11-22 14:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f48f79f7d6e23431d4e298f4a1aa75e1787fb48b', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nCloses-bug: #1518544\n'}, {'number': 4, 'created': '2015-11-22 14:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/f3352ad815c6b72226b0154444b0c6ab207bd9ee', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nCloses-bug: #1518544\n'}, {'number': 5, 'created': '2015-11-22 15:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/41ae9399b0cc14425b54129704fb8cf5d7a7759f', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 6, 'created': '2015-11-22 15:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/c65cf6976a3be9c43a59073d3a7d1a3861bfb142', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 7, 'created': '2015-11-22 21:07:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3979f680b9de5bf4f7bb0b95152761534fe8ec41', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 8, 'created': '2015-11-22 22:56:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/578972b261e578d36971b591a8d59ee1ad8830e2', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 9, 'created': '2015-11-23 07:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/201017a941e5b5bb20b01ca7d184a8bfe99b76dc', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 10, 'created': '2015-11-23 14:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/40935a3bd0f7d9cce79b5dc37a02771bc5ed8053', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}, {'number': 11, 'created': '2015-12-02 11:37:59.000000000', 'files': ['functions-common'], 'web_link': 'https://opendev.org/openstack/devstack/commit/898a09053a14dc66ef7a1b4ff64ab9b961115856', 'message': 'Optimize install_package function when executing nominal flow.\n\nChange-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab\nDepends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984\nCloses-Bug: #1518544\n'}]",0,248458,898a09053a14dc66ef7a1b4ff64ab9b961115856,38,7,11,17377,,,0,"Optimize install_package function when executing nominal flow.

Change-Id: Ib8d8a98f9e47c6f1332d8886366cce33f2891cab
Depends-On: I4a536abefa7824ac6d42e7bbbf1079d9cc055984
Closes-Bug: #1518544
",git fetch https://review.opendev.org/openstack/devstack refs/changes/58/248458/5 && git format-patch -1 --stdout FETCH_HEAD,['functions-common'],1,96d17a481047129bcc1e1cc7ae2b6f843ab85ac0,bug/1518544,"# update_package_repo function update_package_repo { if [[ ""$REPOS_UPDATED"" != ""True"" || ""$RETRY_UPDATE"" = ""True"" ]]; then retry_update_package_repo fi } # Distro-agnostic package installer # Uses globals ``NO_UPDATE_REPOS``, ``REPOS_UPDATED`` # retry_update_package_repo function retry_update_package_repo { NO_UPDATE_REPOS=${NO_UPDATE_REPOS:-False} if [[ ""$NO_UPDATE_REPOS"" != ""True"" ]]; then if is_ubuntu; then local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace apt_get update local RESULT=$? REPOS_UPDATED=True $xtrace fi return ${RESULT:-0} # I fill lucky. Update pckages index only when installation fails if real_install_package ""$@""; then # Package installed at first attempt! return 0 elif retry_update_package_repo; then # Retry installing after updating pakcage index if real_install_package ""$@""; then # Package installed at second attempt return 0 fi fi # Something went wrong. echo ""Unable to install package(s):"" ""$@"" return 1","# install_package package [package ...] function update_package_repo { NO_UPDATE_REPOS=${NO_UPDATE_REPOS:-False} if [[ ""$NO_UPDATE_REPOS"" = ""True"" ]]; then return 0 if is_ubuntu; then local xtrace xtrace=$(set +o | grep xtrace) set +o xtrace if [[ ""$REPOS_UPDATED"" != ""True"" || ""$RETRY_UPDATE"" = ""True"" ]]; then # if there are transient errors pulling the updates, that's fine. # It may be secondary repositories that we don't really care about. apt_get update || /bin/true REPOS_UPDATED=True fi $xtrace fi update_package_repo real_install_package $@ || RETRY_UPDATE=True update_package_repo && real_install_package $@",38,18
openstack%2Fopenstack-manuals~master~I6971fceea91965fd078167aa14df4ff21bc684f0,openstack/openstack-manuals,master,I6971fceea91965fd078167aa14df4ff21bc684f0,Drop py26 classifier from setup.cfg,MERGED,2015-12-10 15:01:16.000000000,2015-12-11 09:26:30.000000000,2015-12-11 09:26:25.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 15:01:16.000000000', 'files': ['doc/config-ref-rst/setup.cfg', 'doc/networking-guide/setup.cfg', 'doc/arch-design/setup.cfg', 'doc/image-guide/setup.cfg', 'doc/user-guide-admin/setup.cfg', 'doc/admin-guide-cloud/setup.cfg', 'doc/contributor-guide/setup.cfg', 'doc/user-guide/setup.cfg', 'doc/install-guide/setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/e92dce4674f59e01595189b83093091ebf658566', 'message': 'Drop py26 classifier from setup.cfg\n\nAs of https://wiki.openstack.org/wiki/python3 the\nOpenStack is targeted for py27 and py34. And also\ndropping py26 for OpenStack mitaka. So In this patch\nI deleted the py26 classifier from all setup.cfg files\n\nChange-Id: I6971fceea91965fd078167aa14df4ff21bc684f0\n'}]",0,255923,e92dce4674f59e01595189b83093091ebf658566,9,3,1,16237,,,0,"Drop py26 classifier from setup.cfg

As of https://wiki.openstack.org/wiki/python3 the
OpenStack is targeted for py27 and py34. And also
dropping py26 for OpenStack mitaka. So In this patch
I deleted the py26 classifier from all setup.cfg files

Change-Id: I6971fceea91965fd078167aa14df4ff21bc684f0
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/23/255923/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/config-ref-rst/setup.cfg', 'doc/networking-guide/setup.cfg', 'doc/arch-design/setup.cfg', 'doc/image-guide/setup.cfg', 'doc/user-guide-admin/setup.cfg', 'doc/admin-guide-cloud/setup.cfg', 'doc/contributor-guide/setup.cfg', 'doc/user-guide/setup.cfg', 'doc/install-guide/setup.cfg']",9,e92dce4674f59e01595189b83093091ebf658566,drop-py26,,Programming Language :: Python :: 2.6,0,9
openstack%2Fcinder~master~Id780e343cc582168bfa2554e25513e94475d776b,openstack/cinder,master,Id780e343cc582168bfa2554e25513e94475d776b,Imported Translations from Zanata,MERGED,2015-12-09 06:26:56.000000000,2015-12-11 09:16:51.000000000,2015-12-10 15:36:40.000000000,"[{'_account_id': 3}, {'_account_id': 9008}, {'_account_id': 10621}, {'_account_id': 10622}, {'_account_id': 11904}, {'_account_id': 12032}, {'_account_id': 12033}, {'_account_id': 12249}, {'_account_id': 12369}, {'_account_id': 12491}, {'_account_id': 12540}, {'_account_id': 12822}, {'_account_id': 13394}, {'_account_id': 14206}, {'_account_id': 14242}, {'_account_id': 14259}, {'_account_id': 14384}, {'_account_id': 14587}, {'_account_id': 14797}, {'_account_id': 14969}, {'_account_id': 15249}, {'_account_id': 15296}, {'_account_id': 15374}, {'_account_id': 15386}, {'_account_id': 16160}, {'_account_id': 16422}, {'_account_id': 16595}, {'_account_id': 16834}, {'_account_id': 16862}, {'_account_id': 16897}, {'_account_id': 16941}, {'_account_id': 17852}, {'_account_id': 18402}, {'_account_id': 18752}, {'_account_id': 19146}]","[{'number': 1, 'created': '2015-12-09 06:26:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/f140394d0f397e83de0dc4dc5fc340b3b86b029b', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Id780e343cc582168bfa2554e25513e94475d776b\n'}, {'number': 2, 'created': '2015-12-10 06:21:05.000000000', 'files': ['cinder/locale/cinder.pot', 'cinder/locale/tr_TR/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cs/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/cinder-log-error.pot', 'cinder/locale/cs/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cinder-log-warning.pot', 'cinder/locale/cs/LC_MESSAGES/cinder.po'], 'web_link': 'https://opendev.org/openstack/cinder/commit/63153123cd44d62c88b2cae39cb04f6e581021af', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Id780e343cc582168bfa2554e25513e94475d776b\n'}]",0,255091,63153123cd44d62c88b2cae39cb04f6e581021af,56,35,2,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Id780e343cc582168bfa2554e25513e94475d776b
",git fetch https://review.opendev.org/openstack/cinder refs/changes/91/255091/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/locale/cinder.pot', 'cinder/locale/tr_TR/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cs/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/tr_TR/LC_MESSAGES/cinder-log-warning.po', 'cinder/locale/cinder-log-error.pot', 'cinder/locale/cs/LC_MESSAGES/cinder-log-error.po', 'cinder/locale/cinder-log-warning.pot', 'cinder/locale/cs/LC_MESSAGES/cinder.po']",8,f140394d0f397e83de0dc4dc5fc340b3b86b029b,zanata/translations,"""Project-Id-Version: cinder 8.0.0.0b2.dev27\n""""POT-Creation-Date: 2015-12-09 06:26+0000\n"" ""PO-Revision-Date: 2015-12-08 03:38+0000\n""msgid ""glance_metadata assigned"" msgstr ""popisná data glance přidělena"" msgid ""glance_metadata changed"" msgstr ""popisná data glance změněna"" msgid ""snapshots assigned"" msgstr ""snímky přiděleny"" ","""Project-Id-Version: cinder 8.0.0.dev388\n""""POT-Creation-Date: 2015-12-02 06:25+0000\n"" ""PO-Revision-Date: 2015-12-01 08:17+0000\n""",727,558
openstack%2Fapi-site~master~I04b5c4ffa8f6a8f3ee08a6b32d7e7ee9f8950ad6,openstack/api-site,master,I04b5c4ffa8f6a8f3ee08a6b32d7e7ee9f8950ad6,Add Python versions for classifier in setup.cfg,MERGED,2015-12-11 08:39:08.000000000,2015-12-11 09:16:16.000000000,2015-12-11 09:16:15.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 08:39:08.000000000', 'files': ['firstapp/setup.cfg', 'api-quick-start/setup.cfg'], 'web_link': 'https://opendev.org/openstack/api-site/commit/bf25f5b6128d50e74e25bbfa7185e8025a6ea82a', 'message': 'Add Python versions for classifier in setup.cfg\n\nChange-Id: I04b5c4ffa8f6a8f3ee08a6b32d7e7ee9f8950ad6\n'}]",0,256283,bf25f5b6128d50e74e25bbfa7185e8025a6ea82a,6,2,1,16237,,,0,"Add Python versions for classifier in setup.cfg

Change-Id: I04b5c4ffa8f6a8f3ee08a6b32d7e7ee9f8950ad6
",git fetch https://review.opendev.org/openstack/api-site refs/changes/83/256283/1 && git format-patch -1 --stdout FETCH_HEAD,"['firstapp/setup.cfg', 'api-quick-start/setup.cfg']",2,bf25f5b6128d50e74e25bbfa7185e8025a6ea82a,drop-py26, Programming Language :: Python Programming Language :: Python :: 2 Programming Language :: Python :: 2.7 Programming Language :: Python :: 3 Programming Language :: Python :: 3.3 Programming Language :: Python :: 3.4,,12,0
openstack%2Fha-guide~master~If040304ba13149a83ffd4fa6ce5f9dbe2df2749b,openstack/ha-guide,master,If040304ba13149a83ffd4fa6ce5f9dbe2df2749b,Drop py26 from setup.cfg,MERGED,2015-12-11 08:48:34.000000000,2015-12-11 09:14:54.000000000,2015-12-11 09:14:54.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 08:48:34.000000000', 'files': ['doc/ha-guide/setup.cfg'], 'web_link': 'https://opendev.org/openstack/ha-guide/commit/96a8e4099ac3453f2b05f69fd45b6ba574ea93ed', 'message': 'Drop py26 from setup.cfg\n\nAs of https://wiki.openstack.org/wiki/python3 OpenStack is\ndropping py26 for mitaka. So In this patch I deleted py26\nfrom setup.cfg\n\nChange-Id: If040304ba13149a83ffd4fa6ce5f9dbe2df2749b\n'}]",0,256285,96a8e4099ac3453f2b05f69fd45b6ba574ea93ed,6,2,1,16237,,,0,"Drop py26 from setup.cfg

As of https://wiki.openstack.org/wiki/python3 OpenStack is
dropping py26 for mitaka. So In this patch I deleted py26
from setup.cfg

Change-Id: If040304ba13149a83ffd4fa6ce5f9dbe2df2749b
",git fetch https://review.opendev.org/openstack/ha-guide refs/changes/85/256285/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/ha-guide/setup.cfg'],1,96a8e4099ac3453f2b05f69fd45b6ba574ea93ed,py26,,Programming Language :: Python :: 2.6,0,1
openstack%2Ffuel-library~stable%2F7.0~I49bb3c6b8c14533b44f5f849f66476e95cda9de7,openstack/fuel-library,stable/7.0,I49bb3c6b8c14533b44f5f849f66476e95cda9de7,Enable trust tokens in murano by default,ABANDONED,2015-09-17 13:16:47.000000000,2015-12-11 09:09:52.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}, {'_account_id': 11090}, {'_account_id': 11827}, {'_account_id': 13343}, {'_account_id': 13752}, {'_account_id': 13948}, {'_account_id': 14985}, {'_account_id': 16518}]","[{'number': 1, 'created': '2015-09-17 13:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/47184c50df341b6350b41fd092d24acaba84b39e', 'message': 'Enable usage of trusts in murano by default\n\nChange-Id: I49bb3c6b8c14533b44f5f849f66476e95cda9de7\nCloses-Bug: #1496397\n'}, {'number': 2, 'created': '2015-09-23 12:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/16b3b43b548e0ea75ba93a45c6011a0868002a46', 'message': 'Enable usage of trusts in murano by default\n\nChange-Id: I49bb3c6b8c14533b44f5f849f66476e95cda9de7\nCloses-Bug: #1496397\n'}, {'number': 3, 'created': '2015-10-05 15:53:03.000000000', 'files': ['tests/noop/spec/hosts/murano/murano_spec.rb', 'deployment/puppet/murano/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/murano/murano.pp'], 'web_link': 'https://opendev.org/openstack/fuel-library/commit/2e422c92445e256e02a9c688158ff192bbc85d10', 'message': 'Enable trust tokens in murano by default\n\nChange-Id: I49bb3c6b8c14533b44f5f849f66476e95cda9de7\nCloses-Bug: #1496397\n'}]",0,224723,2e422c92445e256e02a9c688158ff192bbc85d10,38,9,3,13752,,,0,"Enable trust tokens in murano by default

Change-Id: I49bb3c6b8c14533b44f5f849f66476e95cda9de7
Closes-Bug: #1496397
",git fetch https://review.opendev.org/openstack/fuel-library refs/changes/23/224723/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/noop/spec/hosts/murano/murano_spec.rb', 'deployment/puppet/murano/manifests/init.pp', 'deployment/puppet/osnailyfacter/modular/murano/murano.pp']",3,47184c50df341b6350b41fd092d24acaba84b39e,," use_trusts => true,",,9,0
openstack%2Fsecurity-doc~master~I1a7ac7f0d7a980f145b573bd8f2739655d12b79d,openstack/security-doc,master,I1a7ac7f0d7a980f145b573bd8f2739655d12b79d,Drop py26 from setup.cfg file,MERGED,2015-12-11 08:44:26.000000000,2015-12-11 09:06:50.000000000,2015-12-11 09:06:50.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 08:44:26.000000000', 'files': ['security-guide/setup.cfg'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/80fad6b517850a1d2150f8c9db660f06c044fc9c', 'message': 'Drop py26 from setup.cfg file\n\nAs of https://wiki.openstack.org/wiki/python3 OpenStack\nis dropping py26 for mitaka. In this patch I deleted py26\nfrom setup.cfg\n\nChange-Id: I1a7ac7f0d7a980f145b573bd8f2739655d12b79d\n'}]",0,256284,80fad6b517850a1d2150f8c9db660f06c044fc9c,6,2,1,16237,,,0,"Drop py26 from setup.cfg file

As of https://wiki.openstack.org/wiki/python3 OpenStack
is dropping py26 for mitaka. In this patch I deleted py26
from setup.cfg

Change-Id: I1a7ac7f0d7a980f145b573bd8f2739655d12b79d
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/84/256284/1 && git format-patch -1 --stdout FETCH_HEAD,['security-guide/setup.cfg'],1,80fad6b517850a1d2150f8c9db660f06c044fc9c,py26,,Programming Language :: Python :: 2.6,0,1
openstack%2Fopenstackdocstheme~master~I1ae1507cdad0e940167c9c27363ed585a426a7d8,openstack/openstackdocstheme,master,I1ae1507cdad0e940167c9c27363ed585a426a7d8,Drop py26 from setup.cfg,MERGED,2015-12-11 08:53:07.000000000,2015-12-11 09:04:17.000000000,2015-12-11 09:04:17.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 08:53:07.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/7a4866339c8878a92e773e1a11846f001a4ffb85', 'message': 'Drop py26 from setup.cfg\n\nAs of https://wiki.openstack.org/wiki/python3 OpenStack\nis dropping py26 for mitaka. In this patch I deleted py26\nfrom setup.cfg\n\nChange-Id: I1ae1507cdad0e940167c9c27363ed585a426a7d8\n'}]",0,256288,7a4866339c8878a92e773e1a11846f001a4ffb85,6,2,1,16237,,,0,"Drop py26 from setup.cfg

As of https://wiki.openstack.org/wiki/python3 OpenStack
is dropping py26 for mitaka. In this patch I deleted py26
from setup.cfg

Change-Id: I1ae1507cdad0e940167c9c27363ed585a426a7d8
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/88/256288/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,7a4866339c8878a92e773e1a11846f001a4ffb85,py26,, Programming Language :: Python :: 2.6,0,1
openstack%2Ffuel-agent~master~Ie210cff872a0cfdf7e16876666bf4dc30ec6c6af,openstack/fuel-agent,master,Ie210cff872a0cfdf7e16876666bf4dc30ec6c6af,Switch fuel-bootstrap builder to local mos mirror,ABANDONED,2015-12-10 15:31:29.000000000,2015-12-11 09:03:35.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 8003}, {'_account_id': 10288}, {'_account_id': 11081}, {'_account_id': 12817}]","[{'number': 1, 'created': '2015-12-10 15:31:29.000000000', 'files': ['contrib/fuel_bootstrap/fuel_bootstrap_cli/fuel_bootstrap/settings.yaml.sample'], 'web_link': 'https://opendev.org/openstack/fuel-agent/commit/fc9a3bf87b16c19b04da265efbbfe3b66fe0d0d2', 'message': 'Switch fuel-bootstrap builder to local mos mirror\n\n* By default, environment build process uses local mos mirror, shipped\n  with iso, otherwise bootstrap builder always uses upstream\n\nChange-Id: Ie210cff872a0cfdf7e16876666bf4dc30ec6c6af\nPartial-bug: #1524855\n'}]",2,255940,fc9a3bf87b16c19b04da265efbbfe3b66fe0d0d2,6,6,1,10288,,,0,"Switch fuel-bootstrap builder to local mos mirror

* By default, environment build process uses local mos mirror, shipped
  with iso, otherwise bootstrap builder always uses upstream

Change-Id: Ie210cff872a0cfdf7e16876666bf4dc30ec6c6af
Partial-bug: #1524855
",git fetch https://review.opendev.org/openstack/fuel-agent refs/changes/40/255940/1 && git format-patch -1 --stdout FETCH_HEAD,['contrib/fuel_bootstrap/fuel_bootstrap_cli/fuel_bootstrap/settings.yaml.sample'],1,fc9a3bf87b16c19b04da265efbbfe3b66fe0d0d2,bug/1524855," uri: ""http://127.0.0.1:8080/ubuntu/x86_64""#extra_repos: # - # name: Extra_repo # priority: null # section: main # suite: trusty # type: deb # uri: ""http://archive.ubuntu.com/ubuntu"""," uri: ""http://mirror.fuel-infra.org/mos-repos/ubuntu/8.0""extra_repos: - name: Extra_repo priority: null section: main suite: trusty type: deb uri: ""http://archive.ubuntu.com/ubuntu""",9,9
openstack%2Frequirements~master~Iae3b5c2bf75e64af73ceb58ce5586f39b342a589,openstack/requirements,master,Iae3b5c2bf75e64af73ceb58ce5586f39b342a589,Bump decorator version from 4.0.5 to 4.0.6,ABANDONED,2015-12-11 07:43:33.000000000,2015-12-11 09:01:51.000000000,,[{'_account_id': 6854}],"[{'number': 1, 'created': '2015-12-11 07:43:33.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/92104a0572198797b7c89a1ec8477b56631c7868', 'message': 'Bump decorator version from 4.0.5 to 4.0.6\n\nfor unknown reason, decorator 4.0.5 disappared in pypi[0].\n\n[0] https://pypi.python.org/simple/decorator/\n\nChange-Id: Iae3b5c2bf75e64af73ceb58ce5586f39b342a589\n'}]",0,256268,92104a0572198797b7c89a1ec8477b56631c7868,3,1,1,7488,,,0,"Bump decorator version from 4.0.5 to 4.0.6

for unknown reason, decorator 4.0.5 disappared in pypi[0].

[0] https://pypi.python.org/simple/decorator/

Change-Id: Iae3b5c2bf75e64af73ceb58ce5586f39b342a589
",git fetch https://review.opendev.org/openstack/requirements refs/changes/68/256268/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,92104a0572198797b7c89a1ec8477b56631c7868,,decorator===4.0.6,decorator===4.0.5,1,1
openstack%2Fnetworking-odl~master~I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f,openstack/networking-odl,master,I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f,Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.,ABANDONED,2015-12-08 02:38:54.000000000,2015-12-11 09:01:47.000000000,,"[{'_account_id': 3}, {'_account_id': 2874}, {'_account_id': 6854}, {'_account_id': 10386}, {'_account_id': 17377}]","[{'number': 1, 'created': '2015-12-08 02:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/e7c7764b9e434ae585da0664a336f60ab2710602', 'message': 'Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.\nThis is a temporary workaround for having CI working again.\n\nChange-Id: I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f\nPartial-Bug: 1523716\n'}, {'number': 2, 'created': '2015-12-08 05:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/2267e24a91e535ea321febb4f9630d385933b1e3', 'message': 'Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.\nThis is a temporary workaround for having CI working again.\n\nChange-Id: I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f\nPartial-Bug: 1523716\n'}, {'number': 3, 'created': '2015-12-08 16:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/e5fc8a0476b2d2aa4eab1cc86e0ff92500b409e7', 'message': 'Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.\nThis is a temporary workaround for having CI working again.\n\nChange-Id: I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f\nCloses-Bug: #1523716\n'}, {'number': 4, 'created': '2015-12-08 16:43:38.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/7ad75c55c42ae354c93b4c7b8f9c95c4c4f73fcf', 'message': 'Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.\n\nThis is a temporary workaround for having CI working again.\n\nChange-Id: I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f\nCloses-Bug: #1523716\n'}]",0,254505,7ad75c55c42ae354c93b4c7b8f9c95c4c4f73fcf,18,5,4,17377,,,0,"Requirements of oslo.utils (3.1.0) is breaking ODL unit tests.

This is a temporary workaround for having CI working again.

Change-Id: I13d5d7d375e5c3ab48ab9382ad0eb27271dee77f
Closes-Bug: #1523716
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/05/254505/2 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,e7c7764b9e434ae585da0664a336f60ab2710602,bug/1523716,netifaces>=0.10.4,,1,0
openstack%2Fproject-config~master~Ibcd7c35529d4ceb9d825f5814b001bcb043bfd11,openstack/project-config,master,Ibcd7c35529d4ceb9d825f5814b001bcb043bfd11,networking-midonet: Move ML2 job out of experimental,MERGED,2015-12-09 09:52:32.000000000,2015-12-11 08:59:46.000000000,2015-12-11 08:59:45.000000000,"[{'_account_id': 3}, {'_account_id': 156}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 6598}, {'_account_id': 6854}, {'_account_id': 7505}, {'_account_id': 8837}]","[{'number': 1, 'created': '2015-12-09 09:52:32.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/1984ed6af455a4dfb1191e009ab7b3cb0434789d', 'message': 'networking-midonet: Move ML2 job out of experimental\n\nAs ML2 experimental job seems stable as our other jobs,\nturn it to a non-voting job.\n\nChange-Id: Ibcd7c35529d4ceb9d825f5814b001bcb043bfd11\n'}]",0,255167,1984ed6af455a4dfb1191e009ab7b3cb0434789d,7,8,1,6854,,,0,"networking-midonet: Move ML2 job out of experimental

As ML2 experimental job seems stable as our other jobs,
turn it to a non-voting job.

Change-Id: Ibcd7c35529d4ceb9d825f5814b001bcb043bfd11
",git fetch https://review.opendev.org/openstack/project-config refs/changes/67/255167/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,1984ed6af455a4dfb1191e009ab7b3cb0434789d,midonet-ml2-nonvoting, - gate-tempest-dsvm-networking-midonet-ml2, experimental: - gate-tempest-dsvm-networking-midonet-ml2,1,2
openstack%2Fproject-config~master~I89b89915a67dc64f4fea168bcd3dd13535ace7bc,openstack/project-config,master,I89b89915a67dc64f4fea168bcd3dd13535ace7bc,Allow branch creation for swiftonfile project,MERGED,2015-12-10 12:08:44.000000000,2015-12-11 08:55:05.000000000,2015-12-11 08:55:03.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 9625}]","[{'number': 1, 'created': '2015-12-10 12:08:44.000000000', 'files': ['gerrit/acls/openstack/swiftonfile.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/cbb6e78e6d7af9cf9372418f29a7862b1f7b0915', 'message': 'Allow branch creation for swiftonfile project\n\nChange-Id: I89b89915a67dc64f4fea168bcd3dd13535ace7bc\nSigned-off-by: Prashanth Pai <ppai@redhat.com>\n'}]",0,255827,cbb6e78e6d7af9cf9372418f29a7862b1f7b0915,8,4,1,8542,,,0,"Allow branch creation for swiftonfile project

Change-Id: I89b89915a67dc64f4fea168bcd3dd13535ace7bc
Signed-off-by: Prashanth Pai <ppai@redhat.com>
",git fetch https://review.opendev.org/openstack/project-config refs/changes/27/255827/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/acls/openstack/swiftonfile.config'],1,cbb6e78e6d7af9cf9372418f29a7862b1f7b0915,create-branch,create = group swiftonfile-release,,1,0
openstack%2Fproject-config~master~I79ca1fd1335482cb54201db6f36aa2be2a2401a7,openstack/project-config,master,I79ca1fd1335482cb54201db6f36aa2be2a2401a7,Disable stable/kilo python3 jobs for networking_hyperv,MERGED,2015-12-10 13:51:29.000000000,2015-12-11 08:54:56.000000000,2015-12-11 08:54:55.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-10 13:51:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/29711ef49aa6b24e578163540947bbb6429b8077', 'message': 'Disable stable/kilo python3 jobs for networking_hyperv\n\nPython 3 compatiblity was introduced in Liberty. There is\nno point in running the python 3 jobs for Kilo.\n\nChange-Id: I79ca1fd1335482cb54201db6f36aa2be2a2401a7\n'}, {'number': 2, 'created': '2015-12-10 13:56:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/8081058059234f6517cd8d76c827a95ad1340831', 'message': 'Disable stable/kilo python3 jobs for networking_hyperv\n\nPython 3 compatiblity was introduced in Liberty. There is\nno point in running the python 3 jobs for Kilo.\n\nChange-Id: I79ca1fd1335482cb54201db6f36aa2be2a2401a7\n'}, {'number': 3, 'created': '2015-12-10 14:17:37.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/efefd44fe849a05d679720d354991e4b6b228374', 'message': 'Disable stable/kilo python3 jobs for networking_hyperv\n\nPython 3 compatiblity was introduced in Liberty. There is\nno point in running the python 3 jobs for Kilo.\n\nChange-Id: I79ca1fd1335482cb54201db6f36aa2be2a2401a7\n'}]",1,255882,efefd44fe849a05d679720d354991e4b6b228374,13,3,3,8213,,,0,"Disable stable/kilo python3 jobs for networking_hyperv

Python 3 compatiblity was introduced in Liberty. There is
no point in running the python 3 jobs for Kilo.

Change-Id: I79ca1fd1335482cb54201db6f36aa2be2a2401a7
",git fetch https://review.opendev.org/openstack/project-config refs/changes/82/255882/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,29711ef49aa6b24e578163540947bbb6429b8077,, - name: gate-networking-hyperv-python34 branch: branch: ^(?!stable/kilo).*$ ,,3,0
openstack%2Fproject-config~master~Idb26539f24797138333dfc7e06d717c76a6c5742,openstack/project-config,master,Idb26539f24797138333dfc7e06d717c76a6c5742,Bring back python27 checks for fuel-specs,MERGED,2015-12-10 12:09:22.000000000,2015-12-11 08:54:47.000000000,2015-12-11 08:54:46.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}, {'_account_id': 10474}]","[{'number': 1, 'created': '2015-12-10 12:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/41e70f77f396fda897e03ac23b262dc4eb55a452', 'message': 'Bring back python27 checks for fuel-specs\n\ngate-fuel-specs-python27 job was disabled by mistake in\nhttps://review.openstack.org/#/c/247471/\n\nChange-Id: Idb26539f24797138333dfc7e06d717c76a6c5742\nRelated-Bug: #1524702\n'}, {'number': 2, 'created': '2015-12-10 12:10:17.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/136a23695738d1938053194f9bc3e042f5f36c9a', 'message': 'Bring back python27 checks for fuel-specs\n\ngate-fuel-specs-python27 job was disabled by mistake in\nhttps://review.openstack.org/#/c/247471/\n\nChange-Id: Idb26539f24797138333dfc7e06d717c76a6c5742\nRelated-Bug: #1524702\n'}]",0,255828,136a23695738d1938053194f9bc3e042f5f36c9a,9,4,2,13505,,,0,"Bring back python27 checks for fuel-specs

gate-fuel-specs-python27 job was disabled by mistake in
https://review.openstack.org/#/c/247471/

Change-Id: Idb26539f24797138333dfc7e06d717c76a6c5742
Related-Bug: #1524702
",git fetch https://review.opendev.org/openstack/project-config refs/changes/28/255828/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,41e70f77f396fda897e03ac23b262dc4eb55a452,bug/1524702, check: - gate-fuel-specs-python27 gate: - gate-fuel-specs-python27 ,,4,0
openstack%2Fnetworking-bgpvpn~master~I01f192feadfce99d8eba8ba6701f0139ede985be,openstack/networking-bgpvpn,master,I01f192feadfce99d8eba8ba6701f0139ede985be,Add unit tests for neutronclient extension,MERGED,2015-12-10 20:52:43.000000000,2015-12-11 08:51:57.000000000,2015-12-11 08:51:56.000000000,"[{'_account_id': 3}, {'_account_id': 2888}]","[{'number': 1, 'created': '2015-12-10 20:52:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/2bf275aa22b37c890f92e92a8a61d530d8b89909', 'message': 'Add unit tests for neutronclient extension\n\nThis change adds a test to check that the neutronclient\nextension works as expected.\n\nIt will fail unless python-neutronclient includes the fix we\nneed for subresources support [1].\n\n[1] https://review.openstack.org/#/c/235827\n\nChange-Id: I01f192feadfce99d8eba8ba6701f0139ede985be\n'}, {'number': 2, 'created': '2015-12-10 21:23:55.000000000', 'files': ['test-requirements.txt', 'networking_bgpvpn/tests/unit/client/test_client.py', 'networking_bgpvpn/tests/unit/client/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/339658b5e91ba748f34edfd0d54f7f2b327cf2d0', 'message': 'Add unit tests for neutronclient extension\n\nThis change adds a test to check that the neutronclient\nextension works as expected.\n\nIt will fail unless python-neutronclient includes the fix we\nneed for subresources support [1].\n\n[1] https://review.openstack.org/#/c/235827\n\nChange-Id: I01f192feadfce99d8eba8ba6701f0139ede985be\n'}]",0,256092,339658b5e91ba748f34edfd0d54f7f2b327cf2d0,8,2,2,12021,,,0,"Add unit tests for neutronclient extension

This change adds a test to check that the neutronclient
extension works as expected.

It will fail unless python-neutronclient includes the fix we
need for subresources support [1].

[1] https://review.openstack.org/#/c/235827

Change-Id: I01f192feadfce99d8eba8ba6701f0139ede985be
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/92/256092/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'networking_bgpvpn/tests/unit/client/test_client.py', 'networking_bgpvpn/tests/unit/client/__init__.py']",3,2bf275aa22b37c890f92e92a8a61d530d8b89909,neutronclient_test,,,51,0
openstack%2Ffuel-web~master~Ie3a5d33b5ac7610fff25a4a4340f9207e93e1568,openstack/fuel-web,master,Ie3a5d33b5ac7610fff25a4a4340f9207e93e1568,Show more specific error if Keystone is unavailable,MERGED,2015-12-10 16:23:54.000000000,2015-12-11 08:50:54.000000000,2015-12-11 08:33:55.000000000,"[{'_account_id': 3}, {'_account_id': 8766}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-12-10 16:23:54.000000000', 'files': ['nailgun/static/translations/core.json', 'nailgun/static/views/login_page.js'], 'web_link': 'https://opendev.org/openstack/fuel-web/commit/c035138e62b2fea39b6c22c81a87e63d6d063863', 'message': 'Show more specific error if Keystone is unavailable\n\nChange-Id: Ie3a5d33b5ac7610fff25a4a4340f9207e93e1568\nCloses-Bug: #1507734\n'}]",0,255966,c035138e62b2fea39b6c22c81a87e63d6d063863,14,3,1,8735,,,0,"Show more specific error if Keystone is unavailable

Change-Id: Ie3a5d33b5ac7610fff25a4a4340f9207e93e1568
Closes-Bug: #1507734
",git fetch https://review.opendev.org/openstack/fuel-web refs/changes/66/255966/1 && git format-patch -1 --stdout FETCH_HEAD,"['nailgun/static/translations/core.json', 'nailgun/static/views/login_page.js']",2,c035138e62b2fea39b6c22c81a87e63d6d063863,bug/1507734, .fail((xhr) => { var status = xhr && xhr.status; var error = 'login_error'; if (status == 401) { error = 'credentials_error'; } else if (!status || String(status)[0] == '5') { // no status (connection refused) or 5xx error error = 'keystone_unavailable_error'; } this.setState({error: i18n('login_page.' + error)}); }) .then(() => { }) .then(() => { });," .fail(_.bind(function(xhr) { var error = i18n('login_page.' + (xhr && xhr.status == 401 ? 'credentials_error' : 'login_error')); this.setState({error: error}); }, this)) .then(_.bind(function() { }, this)) .done(_.bind(function() { }));",16,8
openstack%2Fdevstack~master~Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c,openstack/devstack,master,Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c,Configure Ironic to use SSL natively or via proxy,ABANDONED,2015-11-02 09:28:58.000000000,2015-12-11 08:43:31.000000000,,"[{'_account_id': 3}, {'_account_id': 970}, {'_account_id': 10118}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 11655}, {'_account_id': 13636}]","[{'number': 1, 'created': '2015-11-02 09:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/e3f9539d66f4bc129dc09e8b9f56c86b4bf37d00', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 2, 'created': '2015-11-02 09:31:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/508e352df255cc12b93aff786795ceff860b61ce', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 3, 'created': '2015-11-02 13:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/fbab0b4e8aa58f33c97660fe6aef04f8b92c74fa', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 4, 'created': '2015-11-03 15:38:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/606b0022ce99f8017b0c411a46de6e35edae1305', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 5, 'created': '2015-11-03 15:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/ecdd6bcf79bad549ed4f8d5397f193d8008e53f1', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 6, 'created': '2015-11-05 12:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a8a20aab7075ef1cc76fdee6186878c74ce559cd', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 7, 'created': '2015-11-09 12:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/705ce9562be19e9a454e88c1800700f048505d00', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}, {'number': 8, 'created': '2015-12-02 14:14:34.000000000', 'files': ['lib/ironic', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/3380ab009e08c5e9286534b787cd633cf0647558', 'message': 'Configure Ironic to use SSL natively or via proxy\n\nTo enable SSL natively, in local.conf add:\nUSE_SSL=True\n\nNative SSL by default will also use the devstack-generate root and\nsubordinate CA.\nYou can override this with:\n\nIRONIC_SSL_CERT=/path/to/cert\nIRONIC_SSL_KEY=/path/to/key\nIRONIC_SSL_PATH=/path/to/ca\n\nChange-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c\nDepends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159\n'}]",4,240802,3380ab009e08c5e9286534b787cd633cf0647558,29,7,8,13636,,,0,"Configure Ironic to use SSL natively or via proxy

To enable SSL natively, in local.conf add:
USE_SSL=True

Native SSL by default will also use the devstack-generate root and
subordinate CA.
You can override this with:

IRONIC_SSL_CERT=/path/to/cert
IRONIC_SSL_KEY=/path/to/key
IRONIC_SSL_PATH=/path/to/ca

Change-Id: Ia0cdb04e0d8fe67431d9acf73b9ad9b8a54da93c
Depends-On: Id4b84d83f9aa6c7f898b3b9b59158d5b1a00e159
",git fetch https://review.opendev.org/openstack/devstack refs/changes/02/240802/3 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'stack.sh']",2,e3f9539d66f4bc129dc09e8b9f56c86b4bf37d00,ironic-ssl-support,"SSL_ENABLED_SERVICES=""key,nova,cinder,glance,s-proxy,neutron,ironic""","SSL_ENABLED_SERVICES=""key,nova,cinder,glance,s-proxy,neutron""",24,3
openstack%2Fwatcher~master~Ifb8e1cdacd1879874be7496a8bc4bc8349085456,openstack/watcher,master,Ifb8e1cdacd1879874be7496a8bc4bc8349085456,Remove references to removed watcher/openstack directory,MERGED,2015-12-08 12:56:45.000000000,2015-12-11 08:42:47.000000000,2015-12-11 08:42:46.000000000,"[{'_account_id': 3}, {'_account_id': 12394}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2015-12-08 12:56:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/0222255f19cda13b76b818a627dc60b639266ec2', 'message': 'Cleanup tox.ini\n\nSince we removed openstack/common this is not useful.\n\nChange-Id: Ifb8e1cdacd1879874be7496a8bc4bc8349085456\n'}, {'number': 2, 'created': '2015-12-10 16:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/9a3cf05dfb65fd1939795080f63afd776454276c', 'message': 'Cleanup tox.ini\n\nSince we removed openstack/common this is not useful.\n\nChange-Id: Ifb8e1cdacd1879874be7496a8bc4bc8349085456\n'}, {'number': 3, 'created': '2015-12-10 16:13:43.000000000', 'files': ['.coveragerc', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/watcher/commit/ff89e942cadf4858239eb8d5910c005bd21a5771', 'message': 'Remove references to removed watcher/openstack directory\n\nSince we removed openstack/common this is not useful.\n\nChange-Id: Ifb8e1cdacd1879874be7496a8bc4bc8349085456\n'}]",1,254737,ff89e942cadf4858239eb8d5910c005bd21a5771,14,5,3,16495,,,0,"Remove references to removed watcher/openstack directory

Since we removed openstack/common this is not useful.

Change-Id: Ifb8e1cdacd1879874be7496a8bc4bc8349085456
",git fetch https://review.opendev.org/openstack/watcher refs/changes/37/254737/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,0222255f19cda13b76b818a627dc60b639266ec2,tox/remove-openstack-common-tox,"envlist = py34,py27,pep8commands = python setup.py testr --coverage --omit=""watcher/tests/*"" --testr-args='{posargs}'exclude=.venv,.git,.tox,dist,doc,*lib/python*,*egg,build,*sqlalchemy/alembic/versions/*,demo/","envlist = py33,py34,py27,pypy,pep8commands = python setup.py testr --coverage --omit=""watcher/tests/*,watcher/openstack/*"" --testr-args='{posargs}'exclude=.venv,.git,.tox,dist,doc,*openstack/common*,*lib/python*,*egg,build,*sqlalchemy/alembic/versions/*,demo/",3,3
openstack%2Fdevstack~master~I245e8fbc966d7809705ba3b458345d376d9b532c,openstack/devstack,master,I245e8fbc966d7809705ba3b458345d376d9b532c,Add toggle to run Ironic API under Apache,ABANDONED,2015-11-04 10:04:02.000000000,2015-12-11 08:42:24.000000000,,"[{'_account_id': 3}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 13636}]","[{'number': 1, 'created': '2015-11-04 10:04:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/3562876092aa03daa2e7c73365f318abe53adb8d', 'message': 'Add toggle to run Ironic API under Apache\n\nThis change adds possibility to deploy Ironic API under Apache.\n\nDepends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0\nChange-Id: I245e8fbc966d7809705ba3b458345d376d9b532c\n'}, {'number': 2, 'created': '2015-11-04 10:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/09251911a0a10f3370b62a6eac8aedd64a44abd7', 'message': 'Add toggle to run Ironic API under Apache\n\nThis change adds possibility to deploy Ironic API under Apache.\n\nDepends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0\nChange-Id: I245e8fbc966d7809705ba3b458345d376d9b532c\n'}, {'number': 3, 'created': '2015-11-04 13:14:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/2d9e2070b3bb8f9b4aa5bbd7ce90edfb51eb6330', 'message': 'Add toggle to run Ironic API under Apache\n\nThis change adds possibility to deploy Ironic API under Apache.\n\nDepends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0\nChange-Id: I245e8fbc966d7809705ba3b458345d376d9b532c\n'}, {'number': 4, 'created': '2015-11-04 13:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/67c4d5a08f85d7a44ff51fed75e05f7efa0ca6cc', 'message': 'Add toggle to run Ironic API under Apache\n\nThis change adds possibility to deploy Ironic API under Apache.\n\nDepends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0\nChange-Id: I245e8fbc966d7809705ba3b458345d376d9b532c\n'}, {'number': 5, 'created': '2015-11-05 12:01:08.000000000', 'files': ['lib/ironic', 'doc/source/configuration.rst'], 'web_link': 'https://opendev.org/openstack/devstack/commit/c2aa0abf74605b65acc858f02d555e7a7a112d7f', 'message': 'Add toggle to run Ironic API under Apache\n\nThis change adds possibility to deploy Ironic API under Apache.\n\nDepends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0\nChange-Id: I245e8fbc966d7809705ba3b458345d376d9b532c\n'}]",0,241555,c2aa0abf74605b65acc858f02d555e7a7a112d7f,15,4,5,13636,,,0,"Add toggle to run Ironic API under Apache

This change adds possibility to deploy Ironic API under Apache.

Depends-On: I437f7c1d220de61cf596502e7a15c9edae3678c0
Change-Id: I245e8fbc966d7809705ba3b458345d376d9b532c
",git fetch https://review.opendev.org/openstack/devstack refs/changes/55/241555/4 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'doc/source/configuration.rst']",2,3562876092aa03daa2e7c73365f318abe53adb8d,ironic-apache-toggle,"Example (Ironic): :: IRONIC_USE_MOD_WSGI=""True"" ",,84,2
openstack%2Fproject-config~master~Iae56d343bb2a084d889aee47d97fcb2731786791,openstack/project-config,master,Iae56d343bb2a084d889aee47d97fcb2731786791,Add install-distro-packages.sh job script,MERGED,2015-12-10 22:45:11.000000000,2015-12-11 08:36:59.000000000,2015-12-11 08:36:55.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-10 22:45:11.000000000', 'files': ['jenkins/scripts/install-distro-packages.sh'], 'web_link': 'https://opendev.org/openstack/project-config/commit/691528482b96f178bc5443d36af300f84b597ea1', 'message': 'Add install-distro-packages.sh job script\n\nThis script will be used in coming jobs to install system\ndependencies with bindep. The logic is taken from the content of the\ninstall-distro-packages builder macro which it will subsequently\nreplace.\n\nChange-Id: Iae56d343bb2a084d889aee47d97fcb2731786791\n'}]",0,256121,691528482b96f178bc5443d36af300f84b597ea1,7,3,1,5263,,,0,"Add install-distro-packages.sh job script

This script will be used in coming jobs to install system
dependencies with bindep. The logic is taken from the content of the
install-distro-packages builder macro which it will subsequently
replace.

Change-Id: Iae56d343bb2a084d889aee47d97fcb2731786791
",git fetch https://review.opendev.org/openstack/project-config refs/changes/21/256121/1 && git format-patch -1 --stdout FETCH_HEAD,['jenkins/scripts/install-distro-packages.sh'],1,691528482b96f178bc5443d36af300f84b597ea1,bindep,"#!/bin/bash -xe # figure out which bindep list to use if [ -e other-requirements.txt ] ; then # project has its own bindep list export DISTRO_PACKAGES=other-requirements.txt elif [ ""$ZUUL_PROJECT"" == ""openstack-infra/project-config"" ] ; then # test changes to the included fallback list in project-config jobs export DISTRO_PACKAGES=jenkins/data/bindep-fallback.txt else # use the bindep fallback list preinstalled on the worker export DISTRO_PACKAGES=/usr/local/jenkins/common_data/bindep-fallback.txt fi # install all requested packages from the appropriate bindep list if apt-get -v >/dev/null ; then sudo apt-get update sudo PATH=/usr/sbin:/sbin:$PATH DEBIAN_FRONTEND=noninteractive \ apt-get --option ""Dpkg::Options::=--force-confold"" \ --assume-yes install \ `/usr/bindep-env/bin/bindep -b -f $DISTRO_PACKAGES || true` else sudo PATH=/usr/sbin:/sbin:$PATH yum install -y \ `/usr/bindep-env/bin/bindep -b -f $DISTRO_PACKAGES || true` fi ",,25,0
openstack%2Fproject-config~master~I3a5a61b9d470005ff7fa0da418c7fdd0cedf8140,openstack/project-config,master,I3a5a61b9d470005ff7fa0da418c7fdd0cedf8140,tap-as-a-service: Enable check-requirements,MERGED,2015-12-11 04:57:27.000000000,2015-12-11 08:35:32.000000000,2015-12-11 08:35:31.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 04:57:27.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d60bfa0dbedd5a3a092993193e7ff5918a39a4fb', 'message': 'tap-as-a-service: Enable check-requirements\n\nPartial-Bug: #1525067\nChange-Id: I3a5a61b9d470005ff7fa0da418c7fdd0cedf8140\n'}]",0,256213,d60bfa0dbedd5a3a092993193e7ff5918a39a4fb,7,3,1,6854,,,0,"tap-as-a-service: Enable check-requirements

Partial-Bug: #1525067
Change-Id: I3a5a61b9d470005ff7fa0da418c7fdd0cedf8140
",git fetch https://review.opendev.org/openstack/project-config refs/changes/13/256213/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,d60bfa0dbedd5a3a092993193e7ff5918a39a4fb,bug/1525067, - name: check-requirements,,1,0
openstack%2Fproject-config~master~Ibb2d68d566f822f83300c4615718195787d45507,openstack/project-config,master,Ibb2d68d566f822f83300c4615718195787d45507,tap-as-a-service: Skip tempest for unrelated changes,MERGED,2015-12-11 05:13:14.000000000,2015-12-11 08:35:23.000000000,2015-12-11 08:35:22.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 05:13:14.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/32c833cba23d2cf6af5bbfead2aa4dad1c9abd8c', 'message': 'tap-as-a-service: Skip tempest for unrelated changes\n\nChange-Id: Ibb2d68d566f822f83300c4615718195787d45507\n'}]",0,256218,32c833cba23d2cf6af5bbfead2aa4dad1c9abd8c,7,3,1,6854,,,0,"tap-as-a-service: Skip tempest for unrelated changes

Change-Id: Ibb2d68d566f822f83300c4615718195787d45507
",git fetch https://review.opendev.org/openstack/project-config refs/changes/18/256218/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,32c833cba23d2cf6af5bbfead2aa4dad1c9abd8c,, - project: ^openstack/tap-as-a-service all-files-match-any: - ^.*\.rst$ - ^doc/.*$ - ^specs/.*$ - ^neutron_taas/tests/unit/.*$,,6,0
openstack%2Fproject-config~master~Idfb7fe873a9de37c3bdae005b7bed13281cf0bbb,openstack/project-config,master,Idfb7fe873a9de37c3bdae005b7bed13281cf0bbb,networking-midonet: Avoid running tempest for specs changes,MERGED,2015-12-11 05:08:20.000000000,2015-12-11 08:32:10.000000000,2015-12-11 08:32:08.000000000,"[{'_account_id': 3}, {'_account_id': 6133}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 05:08:20.000000000', 'files': ['zuul/layout.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c56905dd5d6c112a9580c059f4571267b3e88ed8', 'message': 'networking-midonet: Avoid running tempest for specs changes\n\nAdd another documentation directory ""specs"" to the filter.\nThe existing *.rst is enough for many cases but not always.\n\nChange-Id: Idfb7fe873a9de37c3bdae005b7bed13281cf0bbb\n'}]",0,256217,c56905dd5d6c112a9580c059f4571267b3e88ed8,7,3,1,6854,,,0,"networking-midonet: Avoid running tempest for specs changes

Add another documentation directory ""specs"" to the filter.
The existing *.rst is enough for many cases but not always.

Change-Id: Idfb7fe873a9de37c3bdae005b7bed13281cf0bbb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/17/256217/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul/layout.yaml'],1,c56905dd5d6c112a9580c059f4571267b3e88ed8,networking-midonet-exclude-specs, - ^specs/.*$,,1,0
openstack%2Fproject-config~master~I8724552e406c440bc7e9a589bf74992416dc9bae,openstack/project-config,master,I8724552e406c440bc7e9a589bf74992416dc9bae,Add an Ironic job to use devstack plugin,MERGED,2015-12-10 16:49:08.000000000,2015-12-11 08:30:23.000000000,2015-12-11 08:30:21.000000000,"[{'_account_id': 3}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 10343}]","[{'number': 1, 'created': '2015-12-10 16:49:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0d9401e13615eaa73202afc0ca25acf14ff600c8', 'message': 'Add an Ironic job to use devstack plugin\n\nIronic now has a devstack plugin in tree. Make a job to be able to test\nthat it works, non-voting, before we actually switch everything over and\ndrop the devstack code.\n\nChange-Id: I8724552e406c440bc7e9a589bf74992416dc9bae\nDepends-On: I147ea059f75720132dd82ff9e7cd3bfdff7fa584\n'}, {'number': 2, 'created': '2015-12-10 20:31:03.000000000', 'files': ['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e2d647ae9c8a160900f6e47ee3ec83aeaeca8209', 'message': 'Add an Ironic job to use devstack plugin\n\nIronic now has a devstack plugin in tree. Make a job to be able to test\nthat it works, non-voting, before we actually switch everything over and\ndrop the devstack code.\n\nChange-Id: I8724552e406c440bc7e9a589bf74992416dc9bae\n'}]",0,255981,e2d647ae9c8a160900f6e47ee3ec83aeaeca8209,11,4,2,10343,,,0,"Add an Ironic job to use devstack plugin

Ironic now has a devstack plugin in tree. Make a job to be able to test
that it works, non-voting, before we actually switch everything over and
drop the devstack code.

Change-Id: I8724552e406c440bc7e9a589bf74992416dc9bae
",git fetch https://review.opendev.org/openstack/project-config refs/changes/81/255981/1 && git format-patch -1 --stdout FETCH_HEAD,"['jenkins/jobs/projects.yaml', 'zuul/layout.yaml', 'jenkins/jobs/devstack-gate.yaml']",3,0d9401e13615eaa73202afc0ca25acf14ff600c8,ironic-devstack-plugin," # Allow using the devstack plugin in ironic's tree. # This is temporary until we ensure it's working as expected. export IRONIC_DEVSTACK_PLUGIN_ENABLED={devstack-plugin-enabled} if [ ""$IRONIC_DEVSTACK_PLUGIN_ENABLED"" == ""1"" ] ; then export DEVSTACK_LOCAL_CONFIG+=$'\n'""enable_plugin ironic git://git.openstack.org/openstack/ironic"" fi devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 branch-override: '{branch-override}' tempest-env: 'DEVSTACK_GATE_TEMPEST_REGEX=baremetal' devstack-timeout: 120 publishers: - devstack-logs - console-log - job-template: name: '{pipeline}-tempest-dsvm-ironic-pxe_ipa-dsplugin{job-suffix}' node: '{node}' wrappers: - build-timeout: timeout: 125 - timestamps builders: - print-template-name: template-name: ""{template-name}"" - link-logs - net-info - devstack-checkout - devstack-virtual-ironic: postgres: 0 build-ramdisk: 0 deploy_driver: pxe_ssh deploy-with-ipa: 1 client-from-source: 0 ironic-lib-from-source: 0 ipxe-enabled: 0 devstack-plugin-enabled: 1 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0 devstack-plugin-enabled: 0",,55,0
openstack%2Fwatcher~master~Ia4877c22188fae6217e07597a2dd939633414349,openstack/watcher,master,Ia4877c22188fae6217e07597a2dd939633414349,Remove unreachable code in basic_consolidation.py,MERGED,2015-12-10 16:57:38.000000000,2015-12-11 08:29:57.000000000,2015-12-11 08:29:57.000000000,"[{'_account_id': 3}, {'_account_id': 9562}, {'_account_id': 9708}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18599}, {'_account_id': 18600}, {'_account_id': 18602}, {'_account_id': 18603}, {'_account_id': 18971}]","[{'number': 1, 'created': '2015-12-10 16:57:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/6c53bdc357a1e82c0c86559acc4b4632d5477587', 'message': 'Remove unreachable code in basic_consodilation.py\n\nIn basic_consodilation.py there is a method called calculate_score_vm()\nwhich had two return statements following each other. The second one\n(which equals the first one) is unreachable as the first one returns.\n\nChange-Id: Ia4877c22188fae6217e07597a2dd939633414349\nCloses-Bug: #1524911\n'}, {'number': 2, 'created': '2015-12-10 17:20:45.000000000', 'files': ['watcher/decision_engine/strategy/basic_consolidation.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/a62553a6a5c5238d981d67ff6dc938cc04491afd', 'message': 'Remove unreachable code in basic_consolidation.py\n\nIn basic_consolidation.py there is a method called calculate_score_vm()\nwhich had two return statements following each other. The second one\n(which equals the first one) is unreachable as the first one returns.\n\nChange-Id: Ia4877c22188fae6217e07597a2dd939633414349\nCloses-Bug: #1524911\n'}]",2,255990,a62553a6a5c5238d981d67ff6dc938cc04491afd,13,10,2,18602,,,0,"Remove unreachable code in basic_consolidation.py

In basic_consolidation.py there is a method called calculate_score_vm()
which had two return statements following each other. The second one
(which equals the first one) is unreachable as the first one returns.

Change-Id: Ia4877c22188fae6217e07597a2dd939633414349
Closes-Bug: #1524911
",git fetch https://review.opendev.org/openstack/watcher refs/changes/90/255990/2 && git format-patch -1 --stdout FETCH_HEAD,['watcher/decision_engine/strategy/basic_consolidation.py'],1,6c53bdc357a1e82c0c86559acc4b4632d5477587,bug/1524911,," return self.calculate_weight(model, vm, total_cores_used, 0, 0) ",0,4
openstack%2Fglance~stable%2Fkilo~I5ec264614ae7ecf54b846ad0600442a18c61d24c,openstack/glance,stable/kilo,I5ec264614ae7ecf54b846ad0600442a18c61d24c,Add 'deactivated' status to image schema.,MERGED,2015-10-12 14:32:14.000000000,2015-12-11 08:22:17.000000000,2015-12-11 08:22:15.000000000,"[{'_account_id': 3}, {'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6159}, {'_account_id': 8158}, {'_account_id': 9303}, {'_account_id': 11391}, {'_account_id': 14676}, {'_account_id': 15054}, {'_account_id': 16237}, {'_account_id': 16658}, {'_account_id': 16683}, {'_account_id': 17116}]","[{'number': 1, 'created': '2015-10-12 14:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/b115b0e49bf2e56e814873cffc94aa726fc7761c', 'message': ""Add 'deactivated' status to image schema.\n\nNew 'deactivated' status was introduced in Kilo release,\nbut it doesn't listed in available image statuses in the schema.\n\nIt leads to issues  on the client side, when it can't validate\nthe image with this status against the schema and returns the error.\n\nChange-Id: I5ec264614ae7ecf54b846ad0600442a18c61d24c\nCloses-bug: #1505218\nRelated-bug: #1505134\n""}, {'number': 2, 'created': '2015-10-18 14:23:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1a1a26d24a25171483b8a996cf1635c19a87316b', 'message': ""Add 'deactivated' status to image schema.\n\nNew 'deactivated' status was introduced in Kilo release,\nbut it doesn't listed in available image statuses in the schema.\n\nIt leads to issues  on the client side, when it can't validate\nthe image with this status against the schema and returns the error.\n\nChange-Id: I5ec264614ae7ecf54b846ad0600442a18c61d24c\nCloses-bug: #1505218\nRelated-bug: #1505134\n""}, {'number': 3, 'created': '2015-10-22 17:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1ec9b1fdfc3183392cdccabf50564fef6dd9c9a2', 'message': ""Add 'deactivated' status to image schema.\n\nNew 'deactivated' status was introduced in Kilo release,\nbut it doesn't listed in available image statuses in the schema.\n\nIt leads to issues  on the client side, when it can't validate\nthe image with this status against the schema and returns the error.\n\nChange-Id: I5ec264614ae7ecf54b846ad0600442a18c61d24c\nCloses-bug: #1505218\nRelated-bug: #1505134\n(cherry picked from commit 135a946a2d1a74dda67fcc35ab31c9d83d4d0c40)\n""}, {'number': 4, 'created': '2015-10-23 10:31:33.000000000', 'files': ['glance/api/v2/images.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/67c3eb98dad93071089381f08a83a966d6f9da5f', 'message': ""Add 'deactivated' status to image schema.\n\nNew 'deactivated' status was introduced in Kilo release,\nbut it doesn't listed in available image statuses in the schema.\n\nIt leads to issues  on the client side, when it can't validate\nthe image with this status against the schema and returns the error.\n\nChange-Id: I5ec264614ae7ecf54b846ad0600442a18c61d24c\nCloses-bug: #1505218\nRelated-bug: #1505134\n(cherry picked from commit 135a946a2d1a74dda67fcc35ab31c9d83d4d0c40)\n""}]",0,233662,67c3eb98dad93071089381f08a83a966d6f9da5f,55,14,4,11391,,,0,"Add 'deactivated' status to image schema.

New 'deactivated' status was introduced in Kilo release,
but it doesn't listed in available image statuses in the schema.

It leads to issues  on the client side, when it can't validate
the image with this status against the schema and returns the error.

Change-Id: I5ec264614ae7ecf54b846ad0600442a18c61d24c
Closes-bug: #1505218
Related-bug: #1505134
(cherry picked from commit 135a946a2d1a74dda67fcc35ab31c9d83d4d0c40)
",git fetch https://review.opendev.org/openstack/glance refs/changes/62/233662/3 && git format-patch -1 --stdout FETCH_HEAD,['glance/api/v2/images.py'],1,b115b0e49bf2e56e814873cffc94aa726fc7761c,," 'deleted', 'pending_delete', 'deactivated'],"," 'deleted', 'pending_delete'],",1,1
openstack%2Fwatcher~master~I96af7fbdbe85eda8d4fc44b4b162e8ba9d4967fa,openstack/watcher,master,I96af7fbdbe85eda8d4fc44b4b162e8ba9d4967fa,Removed unnecessary code from basic_consolidation,MERGED,2015-12-10 17:55:25.000000000,2015-12-11 08:07:29.000000000,2015-12-11 08:07:28.000000000,"[{'_account_id': 3}, {'_account_id': 13289}, {'_account_id': 16495}, {'_account_id': 18971}]","[{'number': 1, 'created': '2015-12-10 17:55:25.000000000', 'files': ['watcher/decision_engine/strategy/basic_consolidation.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/ba4f5569d1a954f98a95a7f0845fb0dfb6110b2f', 'message': ""Removed unnecessary code from basic_consolidation\n\nIn basic_consolidation.py has a method, called calculate_score_vm().\nThis method used to get vm's id as a parameter, but it was replaced\nand now it gets the vm as a parameter. So we don't need to get the\nvm from our vm's id, as we already have the vm.\n\nChange-Id: I96af7fbdbe85eda8d4fc44b4b162e8ba9d4967fa\n""}]",0,256020,ba4f5569d1a954f98a95a7f0845fb0dfb6110b2f,7,4,1,18602,,,0,"Removed unnecessary code from basic_consolidation

In basic_consolidation.py has a method, called calculate_score_vm().
This method used to get vm's id as a parameter, but it was replaced
and now it gets the vm as a parameter. So we don't need to get the
vm from our vm's id, as we already have the vm.

Change-Id: I96af7fbdbe85eda8d4fc44b4b162e8ba9d4967fa
",git fetch https://review.opendev.org/openstack/watcher refs/changes/20/256020/1 && git format-patch -1 --stdout FETCH_HEAD,['watcher/decision_engine/strategy/basic_consolidation.py'],1,ba4f5569d1a954f98a95a7f0845fb0dfb6110b2f,, :param vm: the virtual machine, :param vm_id: the id of virtual machine vm = model.get_vm_from_id(vm.uuid) ,1,3
openstack%2Fdevstack~master~Iba0e1c4cbbe01bab682f2d39eb396807b4bfb31a,openstack/devstack,master,Iba0e1c4cbbe01bab682f2d39eb396807b4bfb31a,Enable ironic node pty console by default,ABANDONED,2015-11-17 11:19:52.000000000,2015-12-11 07:59:13.000000000,,"[{'_account_id': 3}, {'_account_id': 2889}, {'_account_id': 4656}, {'_account_id': 5805}, {'_account_id': 6610}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7118}, {'_account_id': 7711}, {'_account_id': 8106}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 12356}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-11-17 11:19:52.000000000', 'files': ['lib/ironic', 'tools/ironic/templates/vm.xml', 'tools/ironic/scripts/configure-vm'], 'web_link': 'https://opendev.org/openstack/devstack/commit/de243b2e8a29e5258feb088fdfcd3200f034008b', 'message': ""Enable ironic node pty console by default\n\nAs we try to use 'virsh console' to test shellinabox in Ironic,\nso make sure pty console enabled by default.\n\nChange-Id: Iba0e1c4cbbe01bab682f2d39eb396807b4bfb31a\n""}]",0,246338,de243b2e8a29e5258feb088fdfcd3200f034008b,10,16,1,6610,,,0,"Enable ironic node pty console by default

As we try to use 'virsh console' to test shellinabox in Ironic,
so make sure pty console enabled by default.

Change-Id: Iba0e1c4cbbe01bab682f2d39eb396807b4bfb31a
",git fetch https://review.opendev.org/openstack/devstack refs/changes/38/246338/1 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'tools/ironic/templates/vm.xml', 'tools/ironic/scripts/configure-vm']",3,de243b2e8a29e5258feb088fdfcd3200f034008b,bp/ssh-console-support,"CONSOLE_PTY = """""" <serial type='pty'> <target port='0'/> </serial> <console type='pty'> <target type='serial' port='0'/> </console> """""" params['console'] = CONSOLE_LOG % {'console_log': args.console_log} else: params['console'] = CONSOLE_PTY"," params['bios_serial'] = ""<bios useserial='yes'/>"" params['console_log'] = CONSOLE_LOG % {'console_log': args.console_log} else: params['bios_serial'] = '' params['console_log'] = ''",19,14
openstack%2Ftempest~master~If139b42734346639cfc947adfd0ad172c533ae3c,openstack/tempest,master,If139b42734346639cfc947adfd0ad172c533ae3c,DO NOT MERGE! test of ec2 tempest plugin,ABANDONED,2015-12-02 03:11:23.000000000,2015-12-11 07:46:58.000000000,,"[{'_account_id': 3}, {'_account_id': 5196}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-12-02 03:11:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/026f34035e5e7a67cc69a64e3a70c3f7940d8eb8', 'message': 'DO NOT MERGE! test of ec2 tempest plugin\n\nChange-Id: If139b42734346639cfc947adfd0ad172c533ae3c\n'}, {'number': 2, 'created': '2015-12-02 14:45:27.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest/commit/b3d31e88cb9f81cc04ef6830ca6a33bc83f47c95', 'message': 'DO NOT MERGE! test of ec2 tempest plugin\n\nChange-Id: If139b42734346639cfc947adfd0ad172c533ae3c\n'}]",0,252156,b3d31e88cb9f81cc04ef6830ca6a33bc83f47c95,8,3,2,5638,,,0,"DO NOT MERGE! test of ec2 tempest plugin

Change-Id: If139b42734346639cfc947adfd0ad172c533ae3c
",git fetch https://review.opendev.org/openstack/tempest refs/changes/56/252156/2 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,026f34035e5e7a67cc69a64e3a70c3f7940d8eb8,, -egit+https://github.com/dims/tempest_ec2#egg=tempest_ec2,,1,0
openstack%2Ffuel-main~master~I8e0d9b25fd483b3265d2f6906a36c176b0b4de41,openstack/fuel-main,master,I8e0d9b25fd483b3265d2f6906a36c176b0b4de41,Add ability to build DKMS modules on Ubuntu bootstrap,ABANDONED,2015-08-28 09:39:07.000000000,2015-12-11 07:32:32.000000000,,"[{'_account_id': 3}, {'_account_id': 3009}, {'_account_id': 7903}, {'_account_id': 9558}, {'_account_id': 11090}, {'_account_id': 12275}, {'_account_id': 13194}]","[{'number': 1, 'created': '2015-08-28 09:39:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/80ec708812adb84b2a9864d41f9f603886db3251', 'message': 'Add ability building DKMS modules on bootstrap Ubuntu\n\nChange-Id: I8e0d9b25fd483b3265d2f6906a36c176b0b4de41\nCloses-bug: #1484077\n'}, {'number': 2, 'created': '2015-08-28 09:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fdd7bd428399ca6222bcb2ce8990f92e8b697180', 'message': 'Add ability building DKMS modules on bootstrap Ubuntu\n\nChange-Id: I8e0d9b25fd483b3265d2f6906a36c176b0b4de41\nCloses-bug: #1484077\n'}, {'number': 3, 'created': '2015-08-28 09:45:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/6544cf70d346a4c68f59ff924559d0fbc19aacab', 'message': 'Add ability building DKMS modules on Ubuntu bootstrap\n\nChange-Id: I8e0d9b25fd483b3265d2f6906a36c176b0b4de41\nCloses-bug: #1484077\n'}, {'number': 4, 'created': '2015-08-28 09:47:21.000000000', 'files': ['fuel-bootstrap-image-builder/bin/fuel-bootstrap-image'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/fadf8b8d0a592181113a39e142e4d6aacd607b9f', 'message': 'Add ability to build DKMS modules on Ubuntu bootstrap\n\nChange-Id: I8e0d9b25fd483b3265d2f6906a36c176b0b4de41\nCloses-bug: #1484077\n'}]",7,218172,fadf8b8d0a592181113a39e142e4d6aacd607b9f,14,7,4,12275,,,0,"Add ability to build DKMS modules on Ubuntu bootstrap

Change-Id: I8e0d9b25fd483b3265d2f6906a36c176b0b4de41
Closes-bug: #1484077
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/72/218172/4 && git format-patch -1 --stdout FETCH_HEAD,['fuel-bootstrap-image-builder/bin/fuel-bootstrap-image'],1,80ec708812adb84b2a9864d41f9f603886db3251,,"# Add the DKMS package list to bootstrap if [ -n ""$DKMS_PACKAGES"" ] ; then BOOTSTRAP_PKGS=""$BOOTSTRAP_PKGS linux-headers{KERNEL_FLAVOR} $DKMS_PACKAGES"" fipopulate_dev () { local root=""$1"" if ! mountpoint -q ""$root/dev""; then mount -nvt tmpfs none ""$root/dev"" # Create devices mknod -m 622 ""$root/dev/console"" c 5 1 mknod -m 666 ""$root/dev/null"" c 1 3 mknod -m 666 ""$root/dev/zero"" c 1 5 mknod -m 666 ""$root/dev/ptmx"" c 5 2 mknod -m 666 ""$root/dev/tty"" c 5 0 mknod -m 444 ""$root/dev/random"" c 1 8 mknod -m 444 ""$root/dev/urandom"" c 1 9 chown -v root:tty ""$root/dev/""{console,ptmx,tty} # Create symlink for DKMS chroot ""$root"" env LC_ALL=C ln -sv /proc/self/fd /dev/fd fi } cleanup_after_dkms () { local root=""$1"" if [ -n ""$DKMS_PACKAGES"" ] ; then chroot ""$root"" env LC_ALL=C apt-get remove --yes linux-headers{KERNEL_FLAVOR} 2>/dev/null fi } # Clean up the DKMS required symlink and $root/dev rm -Rf ""${root}/dev/fd"" umount ""${root}/dev"" 2>/dev/null populate_dev ""$root"" cleanup_after_dkms ""$root"" for mnt in /tmp/local-apt /mnt/dst /mnt/src /mnt /proc /dev; do", for mnt in /tmp/local-apt /mnt/dst /mnt/src /mnt /proc; do,37,1
openstack%2Ffuel-main~stable%2F6.1~I8d021268607442e0cb8e7e5009d878fe188f524f,openstack/fuel-main,stable/6.1,I8d021268607442e0cb8e7e5009d878fe188f524f,Intel i40e driver ver 1.2.48 (X710 CNA) for Ubuntu,ABANDONED,2015-07-17 13:50:28.000000000,2015-12-11 07:30:54.000000000,,"[{'_account_id': 3}, {'_account_id': 8971}]","[{'number': 1, 'created': '2015-07-17 13:50:28.000000000', 'files': ['requirements-deb.txt'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/a6c5dc25d3f6f6a5ebb3af721b33e4459181b1f5', 'message': 'Intel i40e driver ver 1.2.48 (X710 CNA) for Ubuntu\n\nChange-Id: I8d021268607442e0cb8e7e5009d878fe188f524f\nCloses-bug: 1445562\n'}]",0,203039,a6c5dc25d3f6f6a5ebb3af721b33e4459181b1f5,5,2,1,12275,,,0,"Intel i40e driver ver 1.2.48 (X710 CNA) for Ubuntu

Change-Id: I8d021268607442e0cb8e7e5009d878fe188f524f
Closes-bug: 1445562
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/39/203039/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements-deb.txt'],1,a6c5dc25d3f6f6a5ebb3af721b33e4459181b1f5,,i40e-dkms,,1,0
openstack%2Ffuel-main~master~Id4772df490967b1d5ab7041cb5045f1cbbc21a78,openstack/fuel-main,master,Id4772df490967b1d5ab7041cb5045f1cbbc21a78,Don't review or merge. Check predictable interface naming policy with Fuel,ABANDONED,2015-11-13 14:37:19.000000000,2015-12-11 07:30:32.000000000,,"[{'_account_id': 3}, {'_account_id': 8777}, {'_account_id': 8971}, {'_account_id': 12275}]","[{'number': 1, 'created': '2015-11-13 14:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/24b9b40bc4650f9719f3571682bce04bc0e4630d', 'message': ""Don't review or merge. Check predictable interface naming policy with Fuel\n\nChange-Id: Id4772df490967b1d5ab7041cb5045f1cbbc21a78\n""}, {'number': 2, 'created': '2015-11-13 20:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/54d8f4ce6cee211961ddbbf838087fe9d75165be', 'message': ""Don't review or merge. Check predictable interface naming policy with Fuel\n\nChange-Id: Id4772df490967b1d5ab7041cb5045f1cbbc21a78\n""}, {'number': 3, 'created': '2015-11-16 11:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/5ad987312a6509638c4f5f7ce2ab6c7ea04311a0', 'message': ""Don't review or merge. Check predictable interface naming policy with Fuel\n\nChange-Id: Id4772df490967b1d5ab7041cb5045f1cbbc21a78\n""}, {'number': 4, 'created': '2015-11-16 16:43:34.000000000', 'files': ['image/centos/centos.ks', 'requirements-rpm.txt', 'bootstrap/module.mk', 'iso/module.mk', 'iso/ks.template', 'iso/isolinux/isolinux.cfg', 'iso/syslinux/syslinux.cfg'], 'web_link': 'https://opendev.org/openstack/fuel-main/commit/b69944105ecbad46b79015d2f969eb4eb2209c85', 'message': ""Don't review or merge. Check predictable interface naming policy with Fuel\n\nChange-Id: Id4772df490967b1d5ab7041cb5045f1cbbc21a78\n""}]",0,245181,b69944105ecbad46b79015d2f969eb4eb2209c85,18,4,4,12275,,,0,"Don't review or merge. Check predictable interface naming policy with Fuel

Change-Id: Id4772df490967b1d5ab7041cb5045f1cbbc21a78
",git fetch https://review.opendev.org/openstack/fuel-main refs/changes/81/245181/4 && git format-patch -1 --stdout FETCH_HEAD,"['iso/module.mk', 'iso/ks.template', 'iso/isolinux/isolinux.cfg', 'iso/syslinux/syslinux.cfg']",4,24b9b40bc4650f9719f3571682bce04bc0e4630d,, append initrd=initrd.img biosdevname=1 repo=hd:UUID=will_be_substituted_with_actual_uuid:/ ks=hd:UUID=will_be_substituted_with_actual_uuid:/ks.cfg ip=10.20.0.2 gw=10.20.0.1 dns1=10.20.0.1 netmask=255.255.255.0 hostname=fuel.domain.tld, append initrd=initrd.img biosdevname=0 repo=hd:UUID=will_be_substituted_with_actual_uuid:/ ks=hd:UUID=will_be_substituted_with_actual_uuid:/ks.cfg ip=10.20.0.2 gw=10.20.0.1 dns1=10.20.0.1 netmask=255.255.255.0 hostname=fuel.domain.tld,6,6
openstack%2Fnova-powervm~master~Ic522b8a1cfc984e114ec74e827ae1546236a7c55,openstack/nova-powervm,master,Ic522b8a1cfc984e114ec74e827ae1546236a7c55,Provide synchronization during the Vopt creation,MERGED,2015-11-30 10:00:12.000000000,2015-12-11 07:23:19.000000000,2015-12-01 14:16:11.000000000,"[{'_account_id': 3}, {'_account_id': 8190}, {'_account_id': 8662}, {'_account_id': 12994}]","[{'number': 1, 'created': '2015-11-30 10:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/6d628b93ad118836bb223ce524c37a0ee932f774', 'message': 'Provide synchronization during the Vopt creation\n\nDuring concurrent scale deploys sometime we hit the synchronization\nissue during the vopt creation.\n\nChange-Id: Ic522b8a1cfc984e114ec74e827ae1546236a7c55\nCloses-bug: #1521097\n'}, {'number': 2, 'created': '2015-11-30 13:25:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/e6abf58a9b644048a9a4a391c8238f32ef92e6f3', 'message': 'Provide synchronization during the Vopt creation\n\nDuring concurrent scale deploys sometime we hit the synchronization\nissue during the vopt validation.\n\nChange-Id: Ic522b8a1cfc984e114ec74e827ae1546236a7c55\nCloses-bug: #1521097\n'}, {'number': 3, 'created': '2015-12-01 13:53:38.000000000', 'files': ['nova_powervm/virt/powervm/media.py'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/026f3ad1b10dcdf3986e09b199742984db6ac43f', 'message': 'Provide synchronization during the Vopt creation\n\nDuring concurrent scale deploys sometime we hit the synchronization\nissue during the vopt validation.\n\nChange-Id: Ic522b8a1cfc984e114ec74e827ae1546236a7c55\nCloses-bug: #1521097\n'}]",3,251272,026f3ad1b10dcdf3986e09b199742984db6ac43f,16,4,3,14806,,,0,"Provide synchronization during the Vopt creation

During concurrent scale deploys sometime we hit the synchronization
issue during the vopt validation.

Change-Id: Ic522b8a1cfc984e114ec74e827ae1546236a7c55
Closes-bug: #1521097
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/72/251272/1 && git format-patch -1 --stdout FETCH_HEAD,['nova_powervm/virt/powervm/media.py'],1,6d628b93ad118836bb223ce524c37a0ee932f774,bug/1521097,from oslo_concurrency import lockutils @lockutils.synchronized('create_vopt'),,2,0
openstack%2Frelease-tools~master~Iba0384687d369a1372065b017d65d02693a42a89,openstack/release-tools,master,Iba0384687d369a1372065b017d65d02693a42a89,add URLs from links to the text output,MERGED,2015-12-09 21:14:04.000000000,2015-12-11 07:22:05.000000000,2015-12-11 07:22:05.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-09 21:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/11a35657c941abae65ac1e6fc92112a47e392a16', 'message': 'add URLs from links to the text output\n\nChange-Id: Iba0384687d369a1372065b017d65d02693a42a89\n'}, {'number': 2, 'created': '2015-12-09 23:21:46.000000000', 'files': ['releasetools/rst2txt.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/d04ca8059be680fad48d5172cbc4906fbe28d0f0', 'message': 'add URLs from links to the text output\n\nChange-Id: Iba0384687d369a1372065b017d65d02693a42a89\n'}]",0,255528,d04ca8059be680fad48d5172cbc4906fbe28d0f0,10,4,2,2472,,,0,"add URLs from links to the text output

Change-Id: Iba0384687d369a1372065b017d65d02693a42a89
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/28/255528/2 && git format-patch -1 --stdout FETCH_HEAD,['releasetools/rst2txt.py'],1,11a35657c941abae65ac1e6fc92112a47e392a16,add-reno-to-release-notes," pass def depart_target(self, node): self.add_text(' (%s)' % node['refuri'])", raise nodes.SkipNode,4,1
openstack%2Foslo.cache~master~I1bbca984d248fc432a043b8ea40cab90dfbfe077,openstack/oslo.cache,master,I1bbca984d248fc432a043b8ea40cab90dfbfe077,Delete python bytecode before every test run,ABANDONED,2015-12-11 05:56:47.000000000,2015-12-11 07:21:46.000000000,,[{'_account_id': 3}],"[{'number': 1, 'created': '2015-12-11 05:56:47.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.cache/commit/2f2a779fe1a54567d1c2faa0247fa1102a84db1a', 'message': 'Delete python bytecode before every test run\n\nChange-Id: I1bbca984d248fc432a043b8ea40cab90dfbfe077\nCloses-Bug: #1368661\n'}]",0,256223,2f2a779fe1a54567d1c2faa0247fa1102a84db1a,3,1,1,15699,,,0,"Delete python bytecode before every test run

Change-Id: I1bbca984d248fc432a043b8ea40cab90dfbfe077
Closes-Bug: #1368661
",git fetch https://review.opendev.org/openstack/oslo.cache refs/changes/23/256223/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,2f2a779fe1a54567d1c2faa0247fa1102a84db1a,bug/1368661,"whitelist_externals = find commands = find . -type f -name ""*.pyc"" -delete python setup.py testr --slowest --testr-args='{posargs}'",commands = python setup.py testr --slowest --testr-args='{posargs}',4,1
openstack%2Frelease-tools~master~If3c7a4f0eddadabdf35106c204b6fc01c0d6c04b,openstack/release-tools,master,If3c7a4f0eddadabdf35106c204b6fc01c0d6c04b,format reno section of release notes more nicely,MERGED,2015-12-09 21:14:04.000000000,2015-12-11 07:21:13.000000000,2015-12-11 07:21:13.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-09 21:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/release-tools/commit/6d992c0519d68658f2964f2b238f53c1d2e3f566', 'message': 'format reno section of release notes more nicely\n\nReno makes no attempt to format the reStructuredText output with wrapped\nparagraphs, etc. This change adds a slightly modified text formatter\nstolen from the Sphinx code and modified to be less tightly tied to\nSphinx itself.\n\nChange-Id: If3c7a4f0eddadabdf35106c204b6fc01c0d6c04b\n'}, {'number': 2, 'created': '2015-12-09 23:21:46.000000000', 'files': ['releasetools/rst2txt.py', 'requirements.txt', 'test-requirements.txt', 'releasetools/release_notes.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/b5234119389b06183daadcf00db63adc26ff7b55', 'message': 'format reno section of release notes more nicely\n\nReno makes no attempt to format the reStructuredText output with wrapped\nparagraphs, etc. This change adds a slightly modified text formatter\nstolen from the Sphinx code and modified to be less tightly tied to\nSphinx itself.\n\nChange-Id: If3c7a4f0eddadabdf35106c204b6fc01c0d6c04b\n'}]",0,255527,b5234119389b06183daadcf00db63adc26ff7b55,10,4,2,2472,,,0,"format reno section of release notes more nicely

Reno makes no attempt to format the reStructuredText output with wrapped
paragraphs, etc. This change adds a slightly modified text formatter
stolen from the Sphinx code and modified to be less tightly tied to
Sphinx itself.

Change-Id: If3c7a4f0eddadabdf35106c204b6fc01c0d6c04b
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/27/255527/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasetools/rst2txt.py', 'requirements.txt', 'releasetools/release_notes.py', 'test-requirements.txt']",4,6d992c0519d68658f2964f2b238f53c1d2e3f566,add-reno-to-release-notes,,"sphinx>=1.1.2,!=1.2.0,!=1.3b1,<1.3",973,3
openstack%2Frelease-tools~master~I66c8cb7cfa218f775654b93801b78d544796e9b3,openstack/release-tools,master,I66c8cb7cfa218f775654b93801b78d544796e9b3,add reno notes to announce script output,MERGED,2015-12-09 21:14:04.000000000,2015-12-11 07:21:07.000000000,2015-12-11 07:21:07.000000000,"[{'_account_id': 3}, {'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 5638}]","[{'number': 1, 'created': '2015-12-09 21:14:04.000000000', 'files': ['requirements.txt', 'releasetools/release_notes.py'], 'web_link': 'https://opendev.org/openstack/release-tools/commit/a3400ee6aafa8f3f2d43eb966bc5773040c2475e', 'message': 'add reno notes to announce script output\n\nLook for release notes in the default location and if they are found\ninclude them in the output of the announcement email script.\n\nChange-Id: I66c8cb7cfa218f775654b93801b78d544796e9b3\n'}]",0,255526,a3400ee6aafa8f3f2d43eb966bc5773040c2475e,8,4,1,2472,,,0,"add reno notes to announce script output

Look for release notes in the default location and if they are found
include them in the output of the announcement email script.

Change-Id: I66c8cb7cfa218f775654b93801b78d544796e9b3
",git fetch https://review.opendev.org/openstack/release-tools refs/changes/26/255526/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'releasetools/release_notes.py']",2,a3400ee6aafa8f3f2d43eb966bc5773040c2475e,add-reno-to-release-notes,"from reno import defaults as reno_defaults from reno import formatter from reno import scannerFor more details, please see below and:CHANGE_RELEASE_TPL = """"""{% if reno_notes %}{{ reno_notes }}{% endif %} {% if notables %} if not email_from: raise RuntimeError('No email-from specified') # Look for reno notes for this version. branch = None if is_stable: branch = 'origin/stable/%s' % series scanner_output = scanner.get_notes_by_version( reporoot=library_path, notesdir='%s/%s' % (reno_defaults.RELEASE_NOTES_SUBDIR, reno_defaults.NOTES_SUBDIR), branch=branch, ) if end_revision in scanner_output: reno_notes = formatter.format_report( reporoot=library_path, scanner_output=scanner_output, versions_to_include=[end_revision], ) else: reno_notes = '' 'reno_notes': reno_notes,","For more details, please see the git log history below and:CHANGE_RELEASE_TPL = """"""{% if notables %} if not email_from: raise RuntimeError('No email-from specified')",29,4
openstack%2Foslo.messaging~stable%2Fkilo~I928b30c9b5f9ee007532ff703e136640b0e8aaf4,openstack/oslo.messaging,stable/kilo,I928b30c9b5f9ee007532ff703e136640b0e8aaf4,Don't reply when we known that client is gone,ABANDONED,2015-06-19 10:04:15.000000000,2015-12-11 07:18:25.000000000,,"[{'_account_id': 3}, {'_account_id': 2813}, {'_account_id': 6159}, {'_account_id': 7823}]","[{'number': 1, 'created': '2015-06-19 10:04:15.000000000', 'files': ['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'requirements.txt', 'requirements-py3.txt', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/impl_rabbit.py', 'oslo_messaging/_drivers/amqp.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d3478b4c125a493eadaa69e674cdcbd81ff3677c', 'message': ""Don't reply when we known that client is gone\n\nIn case of a broker restart/failover a reply queue can be\nunreachable for short period the IncomingMessage.send_reply\nwill block for 60 seconds in this case or until rabbit recovers.\n\nBut in case of the reply queue is unreachable because the\nrpc client is really gone, we can have a ton of reply to send\nwaiting 60 seconds.\nThis leads to a starvation of connection of the pool\nThe rpc server take to much time to send reply, other rpc client will\nraise TimeoutError because their don't receive their replies in time.\n\nThis changes introduces an object cache that stores already known gone\nclient to not wait 60 seconds and hold a connection of the pool\nKeeping 200 last gone rpc client for 1 minute is enough\nand doesn't hold to much memory.\n\nThis also don't raise anymore a frightening exception when we can't send reply\nto the rpc client. But just logging a info about missing exchange and\na warning about unsend reply.\n\nCloses-bug: #1460652\n(cherry picked from commit 1ac7f03e053abf513a6b65b7c29ae4d0d04cbee3)\nChange-Id: I928b30c9b5f9ee007532ff703e136640b0e8aaf4\n""}]",0,193484,d3478b4c125a493eadaa69e674cdcbd81ff3677c,8,4,1,2813,,,0,"Don't reply when we known that client is gone

In case of a broker restart/failover a reply queue can be
unreachable for short period the IncomingMessage.send_reply
will block for 60 seconds in this case or until rabbit recovers.

But in case of the reply queue is unreachable because the
rpc client is really gone, we can have a ton of reply to send
waiting 60 seconds.
This leads to a starvation of connection of the pool
The rpc server take to much time to send reply, other rpc client will
raise TimeoutError because their don't receive their replies in time.

This changes introduces an object cache that stores already known gone
client to not wait 60 seconds and hold a connection of the pool
Keeping 200 last gone rpc client for 1 minute is enough
and doesn't hold to much memory.

This also don't raise anymore a frightening exception when we can't send reply
to the rpc client. But just logging a info about missing exchange and
a warning about unsend reply.

Closes-bug: #1460652
(cherry picked from commit 1ac7f03e053abf513a6b65b7c29ae4d0d04cbee3)
Change-Id: I928b30c9b5f9ee007532ff703e136640b0e8aaf4
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/84/193484/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/tests/drivers/test_impl_rabbit.py', 'requirements.txt', 'requirements-py3.txt', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/amqp.py', 'oslo_messaging/_drivers/impl_rabbit.py']",6,d3478b4c125a493eadaa69e674cdcbd81ff3677c,bug/1460652," time.sleep(0.25) elif exc.code == 404: msg = _(""The exchange %(exchange)s to send to "" ""%(routing_key)s still doesn't exist after "" ""%(duration)s sec abandonning..."") % { 'duration': 60, 'exchange': self.exchange, 'routing_key': self.routing_key} LOG.info(msg) raise rpc_amqp.AMQPDestinationNotFound(msg)", time.sleep(1),126,7
openstack%2Fmanila~master~Ib7367d80c263331341ca136b61fa8185e894db3b,openstack/manila,master,Ib7367d80c263331341ca136b61fa8185e894db3b,NetApp cDOT driver should support read-only CIFS shares,MERGED,2015-12-09 15:02:39.000000000,2015-12-11 07:16:10.000000000,2015-12-11 05:00:31.000000000,"[{'_account_id': 3}, {'_account_id': 2417}, {'_account_id': 6491}, {'_account_id': 8851}, {'_account_id': 9207}, {'_account_id': 10621}, {'_account_id': 11865}, {'_account_id': 12017}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 16657}, {'_account_id': 17565}, {'_account_id': 17623}, {'_account_id': 18128}, {'_account_id': 18402}]","[{'number': 1, 'created': '2015-12-09 15:02:39.000000000', 'files': ['manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/share/drivers/netapp/dataontap/protocols/cifs_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_cifs_cmode.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/d6b1c143b496af90c896e9ca2cf68d2140806d60', 'message': 'NetApp cDOT driver should support read-only CIFS shares\n\nRead-only shares are now a required Manila feature.  The cDOT driver\nsupports read-only access for NFS shares but not CIFS.  This commit\nadds CIFS read-only support.\n\nCloses-Bug: #1513509\nChange-Id: Ib7367d80c263331341ca136b61fa8185e894db3b\n'}]",0,255309,d6b1c143b496af90c896e9ca2cf68d2140806d60,24,15,1,11865,,,0,"NetApp cDOT driver should support read-only CIFS shares

Read-only shares are now a required Manila feature.  The cDOT driver
supports read-only access for NFS shares but not CIFS.  This commit
adds CIFS read-only support.

Closes-Bug: #1513509
Change-Id: Ib7367d80c263331341ca136b61fa8185e894db3b
",git fetch https://review.opendev.org/openstack/manila refs/changes/09/255309/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/share/drivers/netapp/dataontap/protocols/nfs_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/client/test_client_cmode.py', 'manila/share/drivers/netapp/dataontap/protocols/cifs_cmode.py', 'manila/tests/share/drivers/netapp/dataontap/protocols/test_cifs_cmode.py', 'manila/share/drivers/netapp/dataontap/client/client_cmode.py']",5,d6b1c143b496af90c896e9ca2cf68d2140806d60,bug/1513509," def add_cifs_share_access(self, share_name, user_name, readonly): api_args = { 'permission': 'read' if readonly else 'full_control',"," def add_cifs_share_access(self, share_name, user_name): api_args = { 'permission': 'full_control',",56,11
openstack%2Fopenstack-manuals~stable%2Fliberty~I7901039d3546e8e0486d780e40af0356c4bfc4d2,openstack/openstack-manuals,stable/liberty,I7901039d3546e8e0486d780e40af0356c4bfc4d2,Imported Translations from Zanata,MERGED,2015-12-11 06:16:56.000000000,2015-12-11 07:00:53.000000000,2015-12-11 07:00:51.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 06:16:56.000000000', 'files': ['doc/common-rst/source/locale/zh_CN/LC_MESSAGES/common-rst.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/1727af88af3b5a8c1bfed0d74e4305a0d3f54911', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: I7901039d3546e8e0486d780e40af0356c4bfc4d2\n'}]",0,256231,1727af88af3b5a8c1bfed0d74e4305a0d3f54911,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: I7901039d3546e8e0486d780e40af0356c4bfc4d2
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/31/256231/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/common-rst/source/locale/zh_CN/LC_MESSAGES/common-rst.po', 'doc/install-guide/source/locale/zh_CN/LC_MESSAGES/install-guide.po']",2,1727af88af3b5a8c1bfed0d74e4305a0d3f54911,zanata/translations,"""PO-Revision-Date: 2015-12-10 10:00+0000\n"" ""Last-Translator: liujunpeng <liujunpeng@inspur.com>\n""msgstr """" ""编辑 ``/etc/nova/nova.conf`` 文件，并在 ``[DEFAULT]`` 部分配置notifications：""msgstr ""启用对象存储计量""msgstr ""启动代理并配置它随系统一起启动：""""Telemetry 通过使用notifications和代理相结合收集计算服务的度量值。在每个计算节"" ""点上执行这些步骤。"" #, fuzzy""现在你的 Openstack 环境已经包含了 Telemetry 服务。你可参考:ref:`launch-"" ""instance` 或者添加更多的服务到你的环境中。""","""PO-Revision-Date: 2015-12-10 03:24+0000\n"" ""Last-Translator: lvyongfeng <344285741@qq.com>\n""msgstr ""编辑 ``/etc/nova/nova.conf`` 和在 ``[DEFAULT]`` 配置提醒：""msgstr ""启用对象计量""msgstr ""启动代理和配置它随系统一起启动：""""Telemetry 通过结合使用通知和代理来收集Computer度量值。在每个计算节点上执行这"" ""些步骤。"" ""你的 Openstack 环境现在已经包含了 Telemetry. 你可参考：'launch-instance' 或者"" ""添加更多的服务到你的环境中。""",150,11
openstack%2Fapi-site~master~Ie84ff38504dc78699421298597b876edf18a9bde,openstack/api-site,master,Ie84ff38504dc78699421298597b876edf18a9bde,Updated from openstack-manuals,MERGED,2015-12-11 06:44:02.000000000,2015-12-11 06:58:39.000000000,2015-12-11 06:58:37.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 06:44:02.000000000', 'files': ['common-rst/source/locale/ja/LC_MESSAGES/common-rst.po'], 'web_link': 'https://opendev.org/openstack/api-site/commit/a33632aa0a3c766ae7353efb603411f77fb8ca3d', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ie84ff38504dc78699421298597b876edf18a9bde\n'}]",0,256242,a33632aa0a3c766ae7353efb603411f77fb8ca3d,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ie84ff38504dc78699421298597b876edf18a9bde
",git fetch https://review.opendev.org/openstack/api-site refs/changes/42/256242/1 && git format-patch -1 --stdout FETCH_HEAD,['common-rst/source/locale/ja/LC_MESSAGES/common-rst.po'],1,a33632aa0a3c766ae7353efb603411f77fb8ca3d,openstack/openstack-manuals,"""POT-Creation-Date: 2015-12-11 04:02+0000\n""""PO-Revision-Date: 2015-12-10 05:44+0000\n""msgid ""Clustering service"" msgstr ""Clustering service"" msgid ""Creates and manages clustering services."" msgstr ""クラスタリングサービスの作成と管理。"" msgid ""The dashboard is generally installed on the controller node."" msgstr ""ダッシュボードは通常はコントローラーノードにインストールされます。""""`Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgstr """" ""`Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgid """"msgid ""``senlin`` - Clustering service API"" msgstr ""``senlin`` - Clustering service API"" msgid ""python-senlinclient"" msgstr ""python-senlinclient"" ","""POT-Creation-Date: 2015-12-09 06:00+0000\n""""PO-Revision-Date: 2015-12-08 05:53+0000\n""msgid """" ""The dashboard is available on the node with the ``nova-dashboard`` server "" ""role."" msgstr """" ""ダッシュボードは ``nova-dashboard`` サーバーロールを持つノードにおいて利用で"" ""きます。""",21,8
openstack%2Fsecurity-doc~master~Ifbc3f17a2681e14bee874f11a63329cbbb17d920,openstack/security-doc,master,Ifbc3f17a2681e14bee874f11a63329cbbb17d920,Updated from openstack-manuals,MERGED,2015-12-11 06:44:10.000000000,2015-12-11 06:54:21.000000000,2015-12-11 06:54:21.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 06:44:10.000000000', 'files': ['common-rst/source/locale/ja/LC_MESSAGES/common-rst.po'], 'web_link': 'https://opendev.org/openstack/security-doc/commit/f05bd5f6b4f599f91a8816aeba63a4ccaabf2545', 'message': 'Updated from openstack-manuals\n\nChange-Id: Ifbc3f17a2681e14bee874f11a63329cbbb17d920\n'}]",0,256243,f05bd5f6b4f599f91a8816aeba63a4ccaabf2545,6,2,1,11131,,,0,"Updated from openstack-manuals

Change-Id: Ifbc3f17a2681e14bee874f11a63329cbbb17d920
",git fetch https://review.opendev.org/openstack/security-doc refs/changes/43/256243/1 && git format-patch -1 --stdout FETCH_HEAD,['common-rst/source/locale/ja/LC_MESSAGES/common-rst.po'],1,f05bd5f6b4f599f91a8816aeba63a4ccaabf2545,openstack/openstack-manuals,"""POT-Creation-Date: 2015-12-11 04:02+0000\n""""PO-Revision-Date: 2015-12-10 05:44+0000\n""msgid ""Clustering service"" msgstr ""Clustering service"" msgid ""Creates and manages clustering services."" msgstr ""クラスタリングサービスの作成と管理。"" msgid ""The dashboard is generally installed on the controller node."" msgstr ""ダッシュボードは通常はコントローラーノードにインストールされます。""""`Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgstr """" ""`Bugs: Clustering service (senlin) <https://bugs.launchpad.net/senlin>`__"" msgid """"msgid ""``senlin`` - Clustering service API"" msgstr ""``senlin`` - Clustering service API"" msgid ""python-senlinclient"" msgstr ""python-senlinclient"" ","""POT-Creation-Date: 2015-12-09 06:00+0000\n""""PO-Revision-Date: 2015-12-08 05:53+0000\n""msgid """" ""The dashboard is available on the node with the ``nova-dashboard`` server "" ""role."" msgstr """" ""ダッシュボードは ``nova-dashboard`` サーバーロールを持つノードにおいて利用で"" ""きます。""",21,8
openstack%2Fapi-site~master~Ie3b19975ff8da9178be8a2be0bc07945aa1d4b10,openstack/api-site,master,Ie3b19975ff8da9178be8a2be0bc07945aa1d4b10,Imported Translations from Zanata,MERGED,2015-12-11 06:39:10.000000000,2015-12-11 06:53:17.000000000,2015-12-11 06:53:16.000000000,"[{'_account_id': 3}, {'_account_id': 10497}]","[{'number': 1, 'created': '2015-12-11 06:39:10.000000000', 'files': ['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-quick-start/source/locale/de/LC_MESSAGES/api-quick-start.po', 'api-ref/locale/ko_KR.po', 'api-ref-guides/locale/api-ref-guides.pot', 'api-quick-start/source/locale/ja/LC_MESSAGES/api-quick-start.po', 'api-quick-start/source/locale/ko_KR/LC_MESSAGES/api-quick-start.po', 'api-ref-guides/locale/ja.po', 'firstapp/source/locale/firstapp.pot', 'api-quick-start/source/locale/api-quick-start.pot'], 'web_link': 'https://opendev.org/openstack/api-site/commit/085629ac6daef0fc81dd767e003c216b0804e607', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ie3b19975ff8da9178be8a2be0bc07945aa1d4b10\n'}]",0,256240,085629ac6daef0fc81dd767e003c216b0804e607,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ie3b19975ff8da9178be8a2be0bc07945aa1d4b10
",git fetch https://review.opendev.org/openstack/api-site refs/changes/40/256240/1 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/locale/api-ref.pot', 'api-ref/locale/fr.po', 'api-quick-start/source/locale/de/LC_MESSAGES/api-quick-start.po', 'api-ref-guides/locale/api-ref-guides.pot', 'api-ref/locale/ko_KR.po', 'api-quick-start/source/locale/ja/LC_MESSAGES/api-quick-start.po', 'api-quick-start/source/locale/ko_KR/LC_MESSAGES/api-quick-start.po', 'api-ref-guides/locale/ja.po', 'firstapp/source/locale/firstapp.pot', 'api-quick-start/source/locale/api-quick-start.pot']",10,085629ac6daef0fc81dd767e003c216b0804e607,zanata/translations,"""POT-Creation-Date: 2015-12-11 06:38+0000\n""#: ../api-quick-start.rst:99#: ../api-quick-start.rst:110#: ../api-quick-start.rst:335#: ../api-quick-start.rst:337#: ../api-quick-start.rst:341#: ../api-quick-start.rst:347#: ../api-quick-start.rst:349#: ../api-quick-start.rst:432#: ../api-quick-start.rst:574#: ../api-quick-start.rst:576#: ../api-quick-start.rst:582#: ../api-quick-start.rst:586#: ../api-quick-start.rst:588#: ../api-quick-start.rst:593#: ../api-quick-start.rst:596#: ../api-quick-start.rst:602#: ../api-quick-start.rst:604#: ../api-quick-start.rst:610#: ../api-quick-start.rst:616#: ../api-quick-start.rst:622#: ../api-quick-start.rst:625#: ../api-quick-start.rst:631#: ../api-quick-start.rst:633#: ../api-quick-start.rst:636#: ../api-quick-start.rst:651#: ../api-quick-start.rst:671#: ../api-quick-start.rst:673#: ../api-quick-start.rst:715""see `Firewalls and default ports <http://docs.openstack.org/liberty/ config-"" ""reference/content/firewalls-default-ports.html>`_ in the *OpenStack "" ""Configuration Reference*.""","""POT-Creation-Date: 2015-11-26 06:40+0000\n""#: ../api-quick-start.rst:98#: ../api-quick-start.rst:109#: ../api-quick-start.rst:334#: ../api-quick-start.rst:336#: ../api-quick-start.rst:340#: ../api-quick-start.rst:346#: ../api-quick-start.rst:348#: ../api-quick-start.rst:431#: ../api-quick-start.rst:575#: ../api-quick-start.rst:577#: ../api-quick-start.rst:583#: ../api-quick-start.rst:587#: ../api-quick-start.rst:589#: ../api-quick-start.rst:594#: ../api-quick-start.rst:597#: ../api-quick-start.rst:603#: ../api-quick-start.rst:605#: ../api-quick-start.rst:611#: ../api-quick-start.rst:617#: ../api-quick-start.rst:623#: ../api-quick-start.rst:626#: ../api-quick-start.rst:632#: ../api-quick-start.rst:634#: ../api-quick-start.rst:637#: ../api-quick-start.rst:652#: ../api-quick-start.rst:672#: ../api-quick-start.rst:674#: ../api-quick-start.rst:716""see `Firewalls and default ports`_ in the *OpenStack Configuration "" ""Reference*.""",585,557
openstack%2Fopenstack-manuals~master~Ife76adf36b022a6657d7ef2e17c46006206fdc2d,openstack/openstack-manuals,master,Ife76adf36b022a6657d7ef2e17c46006206fdc2d,Imported Translations from Zanata,MERGED,2015-12-11 06:16:17.000000000,2015-12-11 06:37:44.000000000,2015-12-11 06:37:43.000000000,"[{'_account_id': 3}, {'_account_id': 6547}]","[{'number': 1, 'created': '2015-12-11 06:16:17.000000000', 'files': ['doc/image-guide/source/locale/ja/LC_MESSAGES/image-guide.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/install-guide/source/locale/install-guide.pot', 'doc/common/locale/common.pot', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/image-guide/source/locale/image-guide.pot', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/common-rst/source/locale/ja/LC_MESSAGES/common-rst.po', 'doc/common-rst/source/locale/common-rst.pot', 'doc/user-guide/source/locale/user-guide.pot', 'doc/install-guide/source/locale/cs/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/499bb456938141b3e7d9ce8c68dad6385fc75269', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://wiki.openstack.org/wiki/Translations/Infrastructure\n\nChange-Id: Ife76adf36b022a6657d7ef2e17c46006206fdc2d\n'}]",0,256230,499bb456938141b3e7d9ce8c68dad6385fc75269,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://wiki.openstack.org/wiki/Translations/Infrastructure

Change-Id: Ife76adf36b022a6657d7ef2e17c46006206fdc2d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/30/256230/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/image-guide/source/locale/ja/LC_MESSAGES/image-guide.po', 'doc/user-guide/source/locale/ja/LC_MESSAGES/user-guide.po', 'doc/install-guide/source/locale/install-guide.pot', 'doc/common/locale/common.pot', 'doc/networking-guide/source/locale/networking-guide.pot', 'doc/image-guide/source/locale/image-guide.pot', 'doc/networking-guide/source/locale/ja/LC_MESSAGES/networking-guide.po', 'doc/install-guide/source/locale/ja/LC_MESSAGES/install-guide.po', 'doc/common-rst/source/locale/ja/LC_MESSAGES/common-rst.po', 'doc/common-rst/source/locale/common-rst.pot', 'doc/user-guide/source/locale/user-guide.pot', 'doc/install-guide/source/locale/cs/LC_MESSAGES/install-guide.po']",12,499bb456938141b3e7d9ce8c68dad6385fc75269,zanata/translations,"""POT-Creation-Date: 2015-12-11 04:02+0000\n""","""POT-Creation-Date: 2015-12-03 22:53+0000\n""msgid ""Controller Node: 1 processor, 2 GB memory, and 5 GB storage"" msgstr ""Uzel kontroléru: 1 procesor, 2 GB paměti a 5 GB diskové kapacity"" ""For best performance, we recommend that your environment meets or exceeds "" ""the hardware requirements in :ref:`figure-hwreqs`. However, OpenStack does "" ""not require a significant amount of resources and the following minimum "" ""requirements should support a proof-of-concept environment with core "" ""services and several :term:`CirrOS` instances:"" msgstr """" ""Pro nejlepší výkon doporučujeme, aby vaše prostředí splňovalo, či "" ""překračovalo požadavky na hardware uvedené v :ref:`figure-hwreqs`. Nicméně "" ""OpenStack není náročný na zdroje a uvedené minimální požadavky by měly "" ""stačit na zkušební prostředí s hlavními službami a několika instancemi :term:"" ""`CirrOS`:"" msgid """"",1506,1334
openstack%2Fnova~master~I3c7202524857e2205b2442bbbcce9468cb2172c3,openstack/nova,master,I3c7202524857e2205b2442bbbcce9468cb2172c3,Ignore Cinder error when shutdown instance,MERGED,2015-05-08 16:36:10.000000000,2015-12-11 06:35:12.000000000,2015-07-30 00:02:41.000000000,"[{'_account_id': 3}, {'_account_id': 1779}, {'_account_id': 2750}, {'_account_id': 5170}, {'_account_id': 5638}, {'_account_id': 6062}, {'_account_id': 7198}, {'_account_id': 8119}, {'_account_id': 8300}, {'_account_id': 8574}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10118}, {'_account_id': 14039}, {'_account_id': 14819}, {'_account_id': 15286}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-05-08 16:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9d580f0fd59d66666c738e7ff0d08237b3eedd20', 'message': ""Ignore Cinder error when shutdown instance\n\nIgnore cinder errors when doing shutdown, thus we will continue\nthe cleanup even if some exceptions there, so we won't get\na couple of instance which can't be deleted.\n\nChange-Id: I3c7202524857e2205b2442bbbcce9468cb2172c3\nCloses-Bug: 1450658\n""}, {'number': 2, 'created': '2015-05-12 08:13:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/11d76cb80a8ebc000a17347d28f34945ab1ef541', 'message': ""Ignore Cinder error when shutdown instance\n\nIgnore cinder errors when doing shutdown, thus we will continue\nthe cleanup even if some exceptions there, so we won't get\na couple of instance which can't be deleted.\n\nChange-Id: I3c7202524857e2205b2442bbbcce9468cb2172c3\nCloses-Bug: 1450658\n""}, {'number': 3, 'created': '2015-06-02 15:42:08.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/e6d700b0d26c3ede357331add58f2037cb565a0f', 'message': ""Ignore Cinder error when shutdown instance\n\nIgnore cinder errors when doing shutdown, thus we will continue\nthe cleanup even if some exceptions there, so we won't get\na couple of instance which can't be deleted\n\nChange-Id: I3c7202524857e2205b2442bbbcce9468cb2172c3\nCloses-Bug: 1450658\n""}]",4,181454,e6d700b0d26c3ede357331add58f2037cb565a0f,55,17,3,6062,,,0,"Ignore Cinder error when shutdown instance

Ignore cinder errors when doing shutdown, thus we will continue
the cleanup even if some exceptions there, so we won't get
a couple of instance which can't be deleted

Change-Id: I3c7202524857e2205b2442bbbcce9468cb2172c3
Closes-Bug: 1450658
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/181454/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,9d580f0fd59d66666c738e7ff0d08237b3eedd20,bug/1450658-1," except cinder_exception.ClientException as exc: LOG.warning(_LW('Ignoring Unknown cinder exception: %s'), exc, instance=instance)",,13,2
openstack%2Ffuel-specs~master~Ie1274e0b4b8353a07a671c54150a07ada351da7a,openstack/fuel-specs,master,Ie1274e0b4b8353a07a671c54150a07ada351da7a,Naming policy for deb packages,MERGED,2015-12-02 19:55:34.000000000,2015-12-11 06:27:23.000000000,2015-12-10 18:20:06.000000000,"[{'_account_id': 3}, {'_account_id': 6476}, {'_account_id': 7562}, {'_account_id': 7613}, {'_account_id': 8777}, {'_account_id': 8787}, {'_account_id': 9582}, {'_account_id': 13194}, {'_account_id': 15784}]","[{'number': 1, 'created': '2015-12-02 19:55:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/dac565de526b791ccb1daaa2ca1992ef7ced6741', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 2, 'created': '2015-12-02 19:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/4519caf14f4a91d8eabb8d2eeb1b8fee76598755', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 3, 'created': '2015-12-02 20:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/79a4c5969631b365832c02bb6cecd0fe74cf6c5c', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 4, 'created': '2015-12-03 11:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/96e8c4881549ae605a73202a7f30436a7ce7ebb9', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 5, 'created': '2015-12-07 15:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d46db3904f45006725b03cdc43d93e0c5c5859f0', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 6, 'created': '2015-12-07 16:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/0e8c33e24cb2b8daa5f359a222c5ce4acbb9eec5', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 7, 'created': '2015-12-09 16:02:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d5e1ee33da317db140ccaf75a794bd7d74582b5a', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 8, 'created': '2015-12-10 14:36:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/d57dc7fb994757fdf85f58a563cb1c9bc934e969', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 9, 'created': '2015-12-10 17:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/c57923d9618b78368e5ca8af8ff75447c6667a8c', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}, {'number': 10, 'created': '2015-12-10 17:21:57.000000000', 'files': ['specs/8.0/deb-packages-naming-policy.rst'], 'web_link': 'https://opendev.org/openstack/fuel-specs/commit/b157b8a291a0c2c81c356146160128196b3602b8', 'message': 'Naming policy for deb packages\n\n * We need to use similar approaches as for RPM as for DEB packages\n   within naming guidelines.\n\nChange-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a\n'}]",17,252580,b157b8a291a0c2c81c356146160128196b3602b8,48,9,10,7613,,,0,"Naming policy for deb packages

 * We need to use similar approaches as for RPM as for DEB packages
   within naming guidelines.

Change-Id: Ie1274e0b4b8353a07a671c54150a07ada351da7a
",git fetch https://review.opendev.org/openstack/fuel-specs refs/changes/80/252580/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/8.0/deb-packages-naming-policy.rst'],1,dac565de526b791ccb1daaa2ca1992ef7ced6741,deb_pkg_versions,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================== Naming policy for deb packages must be similar as used for RPM ============================================================== ------------------- Problem description ------------------- Old versioning scheme does not represents proper meta-data for *deb* packages. For *rpm* packages we have agreed scheme (`separate-mos-from-centos`_) wich is representing proper meta-data at package suffix part and know *deb* packages need to be renamed with the account of specific of distribution. ---------------- Proposed changes ---------------- Need to introduce into CI/Build new naming and version policy for *deb* packages instead of using elaborated previously `old scheme`_. ------------------------------- Package versioning requirements ------------------------------- Package version string, as well as package metadata for a *MOS specific* or *divergent* package must not include registered trademarks of base distro vendors, and should include ""mos"" keyword. ----------------------- DEB packages versioning ----------------------- Package name constructs from:: <name>-<version><deb-revision>~<base-distro-release>+mos<subrevision> For example:: python-nova-12.0.0-1~u14.04+mos8.0.5 Where: - python-nova - name - 12.0.0 - code version - 1 - debian package revision - u14.04 - base Linux distribution - mos8.0.5 - mos<subversion> Where: - mos8 - major MOS release version - 0 - minor MOS release version - 5 - amount of commits into code since last tag change in current code branch At present moment *MOS subversion* part represented as amount of commits into code since code brach was created. **Version in changelog file should be modified by CI/Build:** CI/Build system should modify deb *changelog* value before build process to ensure that package version and release represents truth: Example:: was: nova (2:12.0.0-1~u14.04+mos823) mos8.0; urgency=medium became: nova (2:12.0.0-1~u14.04+mos8.0.5) mos8.0; urgency=medium This modification leads to transformations as follows:: python-nova-12.0.0-1~u14.04+mos823 -> python-nova-12.0.0-1~u14.04+mos8.0.5 **Subversion:** This number represents amount of commits into code since last tag change in current code branch and must be added after **mosX.X**. Example:: python-nova-12.0.0-1~u14.04+mos8.0.5 -> python-nova-12.0.0-1~u14.04+mos8.0.6 **Structure of Subversion for packages maintained by Mirantis:** python-nova-12.0.0-1~u14.04+mos8.0.5 Where: - + separator from base Linux distribution. - mosX.X - X.X represents major and minor version of MOS release. - 3rd X - represents commits number since last tag/branch update in code. For example we have python-nova package with code version = *12.0.0* - debian package revision = *1*, - Linux distro short name(Ubuntu 14.04) = *u14.04*, - MOS release = *mos8.0*, - commits number into code within code version 12.0.0 = *5*. Only packages from *security* repository should have security update bundle number at the very end! Regular packages should only have commits number for the very last value in version string. -------- Backport -------- If package needs to be backported by any reason - name and version must be kept. Modification required for *subversion* part, initial revision of debian package also should be preserved. Any further modifications of package will be represented in commits number which follows after *mosX.X*. By default this value will be always set to 1 and will be increased in case of package modification. Example:: python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.1 -> python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.2 python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.3 -> python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.3 -------------- Package update -------------- If required to update package build manifests (debian/* folder) or add patch or make any other modifications not related to code version update, debian package revision number must be increased. If a major change (new version of the software being packaged) occurs, the version number is changed to reflect the new software version, and debian package release number is reset to 1. In case of packages maintained by MOS this is **valid for OpenStack** projects. For **non OpenStack** projects, like dependencies and back-ported packages all updates will be represented in commits number part of release. After code version update Commits number value resets to 1 and will be increased in cases of further modifications of a package. Update of dependencies within one code version(*non OpenStack*):: python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.1 -> python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.2 Update of dependencies in case of code version update(*non OpenStack*):: python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.2 -> python-zzzeeksphinx_1.0.19-1~u14.04+mos8.0.1 Update of OpenStack project - debian/* changed:: python-nova-12.0.0-1~u14.04+mos8.0.5 -> python-nova-12.0.0-2~u14.04+mos8.0.5 Update of OpenStack project - code tag/branch changed:: python-nova-12.0.0-2~u14.04+mos8.0.5 -> python-nova-13.0.0-1~u14.04+mos8.0.1 ---------------------------------------------- Versioning of packages in post-release updates ---------------------------------------------- **Updates:** Since MOS reaches GA status, ie officially released, all updated packages will be published into separate *updates* repository. Updated package will have higher commit number value in the release part then package from stable repository. Example:: python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.20 -> python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.21 python-nova-12.0.0-1~u14.04+mos8.0.15 -> python-nova-12.0.0-1~u14.04+mos8.0.16 **Security updates:** Security updates will also be published in a separate repository and based on package from *updates* repository. Additional subsequent digit will be added to the version of a package which represents security bundle number. Example:: python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.21 -> python-zzzeeksphinx_1.0.17-1~u14.04+mos8.0.21.1 python-nova-12.0.0-1~u14.04+mos8.0.16 -> python-nova-12.0.0-1~u14.04+mos8.0.16.1 Web UI ====== None Nailgun ======= None Data model ---------- None REST API -------- None Orchestration ============= None RPC Protocol ------------ None Fuel Client =========== None Plugins ======= None Fuel Library ============ None ------------ Alternatives ------------ None -------------- Upgrade impact -------------- None --------------- Security impact --------------- None -------------------- Notifications impact -------------------- None --------------- End user impact --------------- None ------------------ Performance impact ------------------ None ----------------- Deployment impact ----------------- None ---------------- Developer impact ---------------- None --------------------- Infrastructure impact --------------------- None -------------------- Documentation impact -------------------- ToDO -------------- Implementation -------------- Assignee(s) =========== Primary assignee: `Dmitry Burmistrov`_ `Alexander Tsamutali`_ Build-team: `Dmitry Burmistrov`_ Mandatory Design Reviewers: - `Dmitry Burmistrov`_ - `Roman Vyalov`_ - `Dmitry Borodaenko`_ Work Items ========== - Update CI/Build jenkins jobs. - Rebuild ded packages according to this policy. Dependencies ============ - `separate-mos-from-centos`_ ------------ Testing, QA ------------ None Acceptance criteria =================== * Packages at MOS repository has **mos8.0.X** in their names. ---------- References ---------- .. _`Alexander Tsamutali`: https://launchpad.net/~astsmtl .. _`Dmitry Borodaenko`: https://launchpad.net/~angdraug .. _`Dmitry Burmistrov`: https://launchpad.net/~dburmistrov .. _`Igor Yozhikov`: https://launchpad.net/~iyozhikov .. _`Roman Vyalov`: https://launchpad.net/~r0mikiam .. _`separate-mos-from-centos`: https://github.com/openstack/fuel-specs/blob/master/specs/8.0/separate-mos-from-centos.rst .. _`old scheme`: https://github.com/openstack/fuel-specs/blob/master/specs/6.1/separate-mos-from-linux.rst ",,363,0
openstack%2Fproject-config~master~I6229a91d709860d581a00eee7b74bf4f7a49ae97,openstack/project-config,master,I6229a91d709860d581a00eee7b74bf4f7a49ae97,Normalize projects.yaml,MERGED,2015-12-11 06:02:27.000000000,2015-12-11 06:24:48.000000000,2015-12-11 06:24:47.000000000,"[{'_account_id': 3}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 06:02:27.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/e03b359dbeefb445c4a6ed26dc4bb1b301a7a8e6', 'message': 'Normalize projects.yaml\n\nChange-Id: I6229a91d709860d581a00eee7b74bf4f7a49ae97\n'}]",0,256225,e03b359dbeefb445c4a6ed26dc4bb1b301a7a8e6,8,4,1,11131,,,0,"Normalize projects.yaml

Change-Id: I6229a91d709860d581a00eee7b74bf4f7a49ae97
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/256225/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,e03b359dbeefb445c4a6ed26dc4bb1b301a7a8e6,project-yaml-normalization,, upstream: https://github.com/pabelanger/ansible-role-diskimage-builder.git upstream: https://github.com/pabelanger/ansible-role-jenkins-job-builder.git upstream: https://github.com/os-cloud/openstack-ansible-galera_client upstream: https://github.com/os-cloud/openstack-ansible-galera_server upstream: https://github.com/os-cloud/openstack-ansible-memcached_server upstream: https://github.com/os-cloud/openstack-ansible-pip_lock_down upstream: https://github.com/os-cloud/openstack-ansible-rabbitmq_server upstream: https://github.com/os-cloud/openstack-ansible-repo_server upstream: https://github.com/os-cloud/openstack-ansible-rsyslog_server,0,9
openstack%2Frequirements~master~I0865e9a2357518bc8b3c943f77f8c6195b8662ce,openstack/requirements,master,I0865e9a2357518bc8b3c943f77f8c6195b8662ce,Updated from generate-constraints,MERGED,2015-12-09 06:36:57.000000000,2015-12-11 06:23:57.000000000,2015-12-10 12:17:01.000000000,"[{'_account_id': 3}, {'_account_id': 5638}, {'_account_id': 6854}]","[{'number': 1, 'created': '2015-12-09 06:36:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/3a86bbed9f297f33c70802a169124c0794de38d0', 'message': 'Updated from generate-constraints\n\nChange-Id: I0865e9a2357518bc8b3c943f77f8c6195b8662ce\n'}, {'number': 2, 'created': '2015-12-10 06:35:04.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/c5101bb1805aed63689bc2adee2b9ebcfb1c9a74', 'message': 'Updated from generate-constraints\n\nChange-Id: I0865e9a2357518bc8b3c943f77f8c6195b8662ce\n'}]",1,255098,c5101bb1805aed63689bc2adee2b9ebcfb1c9a74,14,3,2,11131,,,0,"Updated from generate-constraints

Change-Id: I0865e9a2357518bc8b3c943f77f8c6195b8662ce
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/255098/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,3a86bbed9f297f33c70802a169124c0794de38d0,openstack/requirements/constraints,botocore===1.3.12frozendict===0.5jsonpath-rw-ext===0.3.0os-win===0.0.7wrapt===1.10.6,botocore===1.3.11jsonpath-rw-ext===0.1.9os-win===0.0.6wrapt===1.10.5,5,4
openstack%2Fnova~master~Iead42f60c9e0cb703fc963e423e7bb99ca71094c,openstack/nova,master,Iead42f60c9e0cb703fc963e423e7bb99ca71094c,update API samples to use endpoints,MERGED,2015-12-10 14:17:07.000000000,2015-12-11 06:20:05.000000000,2015-12-11 06:20:01.000000000,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9578}, {'_account_id': 10385}, {'_account_id': 15751}]","[{'number': 1, 'created': '2015-12-10 14:17:07.000000000', 'files': ['nova/tests/functional/api_sample_tests/api_samples/os-user-data/userdata-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/functional/api_sample_tests/test_multiple_create.py', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/v2-version-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-availability-zone/availability-zone-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-scheduler-hints/scheduler-hints-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-create-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-manage/flavor-create-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/image-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_access_ips.py', 'nova/tests/functional/api_sample_tests/api_samples/images/images-details-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/images-list-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-no-resv-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers-sort/server-sort-keys-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_user_data.py', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_disk_config.py', 'nova/tests/functional/api_sample_tests/api_samples/os-availability-zone/availability-zone-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-update-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-post-req.json.tpl', 'nova/tests/functional/api_samples_test_base.py', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-scheduler-hints/scheduler-hints-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/v21-version-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/list-servers-detail-get.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-action-rebuild-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-show-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild-preserve-ephemeral-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/versions-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-no-resv-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-user-data/userdata-post-req.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/e31f9a9811478ab864adfff53d9e0266e35cab3d', 'message': 'update API samples to use endpoints\n\nThe use of %(host) and an hardcoded project_id makes the templates\nless semantically meaningful or flexible than they should be. It means\nall manner of hackery will need to be done to run a set of tests\nwithout project_id.\n\nThis introduces two new semantic variables, ``compute_endpoint`` which\nis the unversioned compute endpoint (i.e. schema://host/project_id)\nand the ``versioned_compute_endpoint`` which includes the API version.\n\nChange-Id: Iead42f60c9e0cb703fc963e423e7bb99ca71094c\n'}]",6,255895,e31f9a9811478ab864adfff53d9e0266e35cab3d,17,8,1,2750,,,0,"update API samples to use endpoints

The use of %(host) and an hardcoded project_id makes the templates
less semantically meaningful or flexible than they should be. It means
all manner of hackery will need to be done to run a set of tests
without project_id.

This introduces two new semantic variables, ``compute_endpoint`` which
is the unversioned compute endpoint (i.e. schema://host/project_id)
and the ``versioned_compute_endpoint`` which includes the API version.

Change-Id: Iead42f60c9e0cb703fc963e423e7bb99ca71094c
",git fetch https://review.opendev.org/openstack/nova refs/changes/95/255895/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/api_samples/os-user-data/userdata-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-unrescue.json.tpl', 'nova/tests/functional/api_sample_tests/test_multiple_create.py', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/v2-version-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-availability-zone/availability-zone-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-scheduler-hints/scheduler-hints-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-create-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-manage/flavor-create-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/image-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_access_ips.py', 'nova/tests/functional/api_sample_tests/api_samples/images/images-details-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_servers.py', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-server-usage/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/images/images-list-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-no-resv-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-server-attributes/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers-sort/server-sort-keys-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_user_data.py', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/servers-config-drive-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/test_disk_config.py', 'nova/tests/functional/api_sample_tests/api_samples/os-availability-zone/availability-zone-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-update-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-personality/server-post-req.json.tpl', 'nova/tests/functional/api_samples_test_base.py', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-scheduler-hints/scheduler-hints-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/v21-version-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/list-servers-detail-get.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-action-rebuild-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-volumes/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-security-groups/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavor-access/flavor-access-show-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-config-drive-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavor-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-put-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/server-action-rebuild-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-config-drive/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-post-req.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-preserve-ephemeral-rebuild/server-action-rebuild-preserve-ephemeral-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-hide-server-addresses/servers-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-availability-zone/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-extended-status/servers-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-access-ips/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-disk-config/server-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/versions/versions-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-rescue/server-get-resp-rescue.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-flavor-rxtx/flavor-rxtx-list-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/all_extensions/servers-details-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/flavors/flavors-detail-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-multiple-create/multiple-create-no-resv-post-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/servers/v2.9/server-get-resp.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-user-data/userdata-post-req.json.tpl']",90,e31f9a9811478ab864adfff53d9e0266e35cab3d,api_samples_2," ""imageRef"" : ""%(compute_endpoint)s/images/%(image_id)s"", ""flavorRef"" : ""%(compute_endpoint)s/flavors/1"","," ""imageRef"" : ""%(host)s/openstack/images/%(image_id)s"", ""flavorRef"" : ""%(host)s/openstack/flavors/1"",",341,322
openstack%2Fpython-monascaclient~master~Ic99204f9b23430a477905ca99897e69ee20ed5ad,openstack/python-monascaclient,master,Ic99204f9b23430a477905ca99897e69ee20ed5ad,Adding oslo.concurrency to requirements,MERGED,2015-12-11 06:04:08.000000000,2015-12-11 06:10:11.000000000,2015-12-11 06:10:11.000000000,"[{'_account_id': 3}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-12-11 06:04:08.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/35926a03871d027f5fff3df9e25b45d637acf538', 'message': 'Adding oslo.concurrency to requirements\n\noslo.service requires an unbounded version of oslo.concurrency and that causes\nan issue with the agent since it wants a version of oslo.config that differs\nfrom what the current version of oslo.concurrency wants.\n\nChange-Id: Ic99204f9b23430a477905ca99897e69ee20ed5ad\n'}]",0,256226,35926a03871d027f5fff3df9e25b45d637acf538,6,2,1,14273,,,0,"Adding oslo.concurrency to requirements

oslo.service requires an unbounded version of oslo.concurrency and that causes
an issue with the agent since it wants a version of oslo.config that differs
from what the current version of oslo.concurrency wants.

Change-Id: Ic99204f9b23430a477905ca99897e69ee20ed5ad
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/26/256226/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,35926a03871d027f5fff3df9e25b45d637acf538,,oslo.concurrency<2.7.0,,1,0
openstack%2Fmonasca-agent~master~I4878641bba3887df0ce5d4781b368151b853d89e,openstack/monasca-agent,master,I4878641bba3887df0ce5d4781b368151b853d89e,Adding liberty versions of oslo to requirements.txt,MERGED,2015-12-10 22:46:33.000000000,2015-12-11 06:07:58.000000000,2015-12-11 06:07:58.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 14273}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-12-10 22:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/634d0e75f9ae52ddfef835c7b3345a17e43c09dd', 'message': 'Adding liberty versions of oslo to requirements.txt\n\nChange-Id: I4878641bba3887df0ce5d4781b368151b853d89e\n'}, {'number': 2, 'created': '2015-12-11 06:01:15.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-agent/commit/453ba0b99ee9796fa187e969ca2acabac4b61db9', 'message': 'Adding liberty versions of oslo to requirements.txt\n\nChange-Id: I4878641bba3887df0ce5d4781b368151b853d89e\n'}]",0,256124,453ba0b99ee9796fa187e969ca2acabac4b61db9,14,4,2,14273,,,0,"Adding liberty versions of oslo to requirements.txt

Change-Id: I4878641bba3887df0ce5d4781b368151b853d89e
",git fetch https://review.opendev.org/openstack/monasca-agent refs/changes/24/256124/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,634d0e75f9ae52ddfef835c7b3345a17e43c09dd,(HEAD, oslo.config<2.5.0 oslo.i18n<=2.6.0 oslo.log<1.12.0 oslo.middleware<2.9.0 oslo.serialization<1.10.0 oslo.utils<2.6.0 ,oslo.serialization<1.9,8,1
openstack%2Fneutron-vpnaas~stable%2Fliberty~Id99008f00bfc711155ec882360541ceac63c35fc,openstack/neutron-vpnaas,stable/liberty,Id99008f00bfc711155ec882360541ceac63c35fc,Add first reno based release note,MERGED,2015-12-03 15:35:54.000000000,2015-12-11 05:59:21.000000000,2015-12-11 05:59:20.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 4395}, {'_account_id': 6659}, {'_account_id': 7787}, {'_account_id': 10692}, {'_account_id': 10980}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-12-03 15:35:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/851dafb4b44e4d2a988bfa50cd1ce6efce7aee24', 'message': 'Add first reno based release note\n\nThis needs to merge in stable/liberty so the reno job on master works.\n\nChange-Id: Id99008f00bfc711155ec882360541ceac63c35fc\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 2, 'created': '2015-12-09 01:29:24.000000000', 'files': ['releasenotes/notes/start-using-reno-928202c562738816.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/6226f5709e9d2c3810de123efb5a0bc04a599618', 'message': 'Add first reno based release note\n\nThis needs to merge in stable/liberty so the reno job on master works.\n\nChange-Id: Id99008f00bfc711155ec882360541ceac63c35fc\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}]",0,253018,6226f5709e9d2c3810de123efb5a0bc04a599618,16,11,2,105,,,0,"Add first reno based release note

This needs to merge in stable/liberty so the reno job on master works.

Change-Id: Id99008f00bfc711155ec882360541ceac63c35fc
Signed-off-by: Kyle Mestery <mestery@mestery.com>
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/18/253018/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/start-using-reno-928202c562738816.yaml', 'test-requirements.txt']",2,851dafb4b44e4d2a988bfa50cd1ce6efce7aee24,reno,reno>=0.1.1 # Apache2,,4,0
openstack%2Fneutron-fwaas~stable%2Fliberty~I189cc90539a579110415ace976c5b86a70c7f7f4,openstack/neutron-fwaas,stable/liberty,I189cc90539a579110415ace976c5b86a70c7f7f4,Add first reno based release note,MERGED,2015-12-03 15:34:13.000000000,2015-12-11 05:59:19.000000000,2015-12-11 05:59:19.000000000,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 2472}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 10692}, {'_account_id': 12999}, {'_account_id': 14605}, {'_account_id': 16707}]","[{'number': 1, 'created': '2015-12-03 15:34:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/f302096fc1f9036253c8665970097932f361f530', 'message': 'Add first reno based release note\n\nThis needs to merge in stable/liberty so the reno job on master works.\n\nChange-Id: I189cc90539a579110415ace976c5b86a70c7f7f4\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}, {'number': 2, 'created': '2015-12-09 01:24:48.000000000', 'files': ['releasenotes/notes/start-using-reno-e45e439ce1a0965d.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/12c76d278bc8297d0bdecdb803ee9440d2c9381a', 'message': 'Add first reno based release note\n\nThis needs to merge in stable/liberty so the reno job on master works.\n\nChange-Id: I189cc90539a579110415ace976c5b86a70c7f7f4\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n'}]",0,253014,12c76d278bc8297d0bdecdb803ee9440d2c9381a,20,10,2,105,,,0,"Add first reno based release note

This needs to merge in stable/liberty so the reno job on master works.

Change-Id: I189cc90539a579110415ace976c5b86a70c7f7f4
Signed-off-by: Kyle Mestery <mestery@mestery.com>
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/14/253014/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'releasenotes/notes/start-using-reno-e45e439ce1a0965d.yaml']",2,f302096fc1f9036253c8665970097932f361f530,add-reno-liberty,--- other: - Start using reno to manage release notes. ,,4,0
openstack%2Fneutron-fwaas~stable%2Fliberty~Ice756c9d916e6a8686c2b56da361b376db14b158,openstack/neutron-fwaas,stable/liberty,Ice756c9d916e6a8686c2b56da361b376db14b158,Add reno for release notes management,MERGED,2015-12-09 01:24:48.000000000,2015-12-11 05:59:08.000000000,2015-12-11 05:59:05.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 4656}, {'_account_id': 7244}, {'_account_id': 7787}, {'_account_id': 10980}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-12-09 01:24:48.000000000', 'files': ['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/a137f3624a4295ca759fd199c70fbd6cbdd5f0d5', 'message': 'Add reno for release notes management\n\nChange-Id: Ice756c9d916e6a8686c2b56da361b376db14b158\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n(cherry picked from commit bffe8c1175673161959176d5d45853bbc32f868e)\n'}]",0,255026,a137f3624a4295ca759fd199c70fbd6cbdd5f0d5,12,7,1,105,,,0,"Add reno for release notes management

Change-Id: Ice756c9d916e6a8686c2b56da361b376db14b158
Signed-off-by: Kyle Mestery <mestery@mestery.com>
(cherry picked from commit bffe8c1175673161959176d5d45853bbc32f868e)
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/26/255026/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py']",10,a137f3624a4295ca759fd199c70fbd6cbdd5f0d5,reno,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # Neutron FWaaS Release Notes documentation build configuration file, created # by # sphinx-quickstart on Tue Nov 3 17:40:50 2015. # # This file is execfile()d with the current directory set to its # containing dir. # # Note that not all possible configuration values are present in this # autogenerated file. # # All configuration values have a default; values that are commented out # serve to show the default. # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # sys.path.insert(0, os.path.abspath('.')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'oslosphinx', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'Neutron FWaaS Release Notes' copyright = u'2015, Neutron FWaaS Developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. from neutron_fwaas.version import version_info as neutron_fwaas_version # The full version, including alpha/beta/rc tags. release = neutron_fwaas_version.version_string_with_vcs() # The short X.Y version. version = neutron_fwaas_version.canonical_version_string() # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'default' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. # html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'NeutronFWaaSReleaseNotesdoc' # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'NeutronFWaaSReleaseNotes.tex', u'Neutron FWaaS Release Notes Documentation', u'Neutron FWaaS Developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'neutronfwaasreleasenotes', u'Neutron FWaaS Release Notes ' 'Documentation', [u'Neutron FWaaS Developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'NeutronFWaaSReleaseNotes', u'Neutron FWaaS Release Notes ' 'Documentation', u'Neutron FWaaS Developers', 'NeutronFWaaSReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False ",,302,0
openstack%2Fpuppet-nova~master~I34c88ab9601b8b0bbf77588005422620eb575d6a,openstack/puppet-nova,master,I34c88ab9601b8b0bbf77588005422620eb575d6a,Rewrite nova_network provider with using only nova client,MERGED,2015-09-30 17:50:40.000000000,2015-12-11 05:49:54.000000000,2015-12-11 05:49:53.000000000,"[{'_account_id': 3}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7155}, {'_account_id': 7423}, {'_account_id': 7468}, {'_account_id': 7604}, {'_account_id': 7732}, {'_account_id': 7745}, {'_account_id': 8482}, {'_account_id': 9410}, {'_account_id': 13343}, {'_account_id': 13752}, {'_account_id': 14007}, {'_account_id': 14525}, {'_account_id': 14985}, {'_account_id': 15519}]","[{'number': 1, 'created': '2015-09-30 17:50:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c4b855976fd89072d3b031fa248acac99c9de09d', 'message': ""Rewrite nova_network provider with using only nova client\n\nCurrently nova_network provider uses admin tool nova-manage for\nmanaging nova-networks, but this tool doesn't have any authentication\nand doesn't provide all features of nova client. This patch avoids\nproblem with authentication by using nova client for managing networks.\n\nAnother goal of this patch, with using nova client, is that all\nproviders should use one way for authentication, based on\nopenstack client and openstacklib [1] But the problem is that\nopenstack client doesn't provide possibility to manage nova-networks.\nSo, this provider will be used with nova client, until nova-network\nexists.\n\nAlso added new tests.\n\n[1] blueprint use-openstackclient-in-module-resources\n\nChange-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a\n""}, {'number': 2, 'created': '2015-10-02 15:30:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7e635d780f45bf52be2d5d501b1332596df91a0d', 'message': ""Rewrite nova_network provider with using only nova client\n\nCurrently nova_network provider uses admin tool nova-manage for\nmanaging nova-networks, but this tool doesn't have any authentication\nand doesn't provide all features of nova client. This patch avoids\nproblem with authentication by using nova client for managing networks.\n\nAnother goal of this patch, with using nova client, is that all\nproviders should use one way for authentication, based on\nopenstack client and openstacklib [1] But the problem is that\nopenstack client doesn't provide possibility to manage nova-networks.\nSo, this provider will be used with nova client, until nova-network\nexists.\n\nAlso added new tests.\n\n[1] blueprint use-openstackclient-in-module-resources\n\nChange-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a\n""}, {'number': 3, 'created': '2015-10-06 16:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/88ecb8b21c37f273d2b999b8e93ce91c438ead3f', 'message': ""Rewrite nova_network provider with using only nova client\n\nCurrently nova_network provider uses admin tool nova-manage for\nmanaging nova-networks, but this tool doesn't have any authentication\nand doesn't provide all features of nova client. This patch avoids\nproblem with authentication by using nova client for managing networks.\n\nAnother goal of this patch, with using nova client, is that all\nproviders should use one way for authentication, based on\nopenstack client and openstacklib [1] But the problem is that\nopenstack client doesn't provide possibility to manage nova-networks.\nSo, this provider will be used with nova client, until nova-network\nexists.\n\nAlso added new tests.\n\n[1] blueprint use-openstackclient-in-module-resources\n\nChange-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a\n""}, {'number': 4, 'created': '2015-10-20 10:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/0836cdc194e53feaca2433e7bea42af2a5be784c', 'message': ""Rewrite nova_network provider with using only nova client\n\nCurrently nova_network provider uses admin tool nova-manage for\nmanaging nova-networks, but this tool doesn't have any authentication\nand doesn't provide all features of nova client. This patch avoids\nproblem with authentication by using nova client for managing networks.\n\nAnother goal of this patch, with using nova client, is that all\nproviders should use one way for authentication, based on\nopenstack client and openstacklib [1] But the problem is that\nopenstack client doesn't provide possibility to manage nova-networks.\nSo, this provider will be used with nova client, until nova-network\nexists.\n\nAlso added new tests.\n\n[1] blueprint use-openstackclient-in-module-resources\n\nChange-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a\n""}, {'number': 5, 'created': '2015-12-10 17:25:48.000000000', 'files': ['lib/puppet/provider/nova_network/nova_manage.rb', 'spec/unit/provider/nova_network/nova_spec.rb', 'lib/puppet/provider/nova_network/nova.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/21a7a682e9c03ee46e18f2ee7aff0ebc61289703', 'message': ""Rewrite nova_network provider with using only nova client\n\nCurrently nova_network provider uses admin tool nova-manage for\nmanaging nova-networks, but this tool doesn't have any authentication\nand doesn't provide all features of nova client. This patch avoids\nproblem with authentication by using nova client for managing networks.\n\nAnother goal of this patch, with using nova client, is that all\nproviders should use one way for authentication, based on\nopenstack client and openstacklib [1] But the problem is that\nopenstack client doesn't provide possibility to manage nova-networks.\nSo, this provider will be used with nova client, until nova-network\nexists.\n\nAlso added new tests.\n\n[1] blueprint use-openstackclient-in-module-resources\n\nChange-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a\n""}]",0,229548,21a7a682e9c03ee46e18f2ee7aff0ebc61289703,52,17,5,7745,,,0,"Rewrite nova_network provider with using only nova client

Currently nova_network provider uses admin tool nova-manage for
managing nova-networks, but this tool doesn't have any authentication
and doesn't provide all features of nova client. This patch avoids
problem with authentication by using nova client for managing networks.

Another goal of this patch, with using nova client, is that all
providers should use one way for authentication, based on
openstack client and openstacklib [1] But the problem is that
openstack client doesn't provide possibility to manage nova-networks.
So, this provider will be used with nova client, until nova-network
exists.

Also added new tests.

[1] blueprint use-openstackclient-in-module-resources

Change-Id: I34c88ab9601b8b0bbf77588005422620eb575d6a
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/48/229548/5 && git format-patch -1 --stdout FETCH_HEAD,"['lib/puppet/provider/nova_network/nova_manage.rb', 'lib/puppet/provider/nova_network/nova.rb', 'spec/unit/provider/nova_network/nova_spec.rb']",3,c4b855976fd89072d3b031fa248acac99c9de09d,bp/use-openstackclient-in-module-resources,"require 'puppet' require 'puppet/provider/nova_network/nova' require 'tempfile' provider_class = Puppet::Type.type(:nova_network).provider(:nova) describe provider_class do let :net_attrs do { :network => '10.20.0.0/16', :label => 'nova-network', :ensure => 'present', } end let :resource do Puppet::Type::Nova_network.new(net_attrs) end let :provider do provider_class.new(resource) end shared_examples 'nova_network' do describe '#exists?' do it 'should check non-existsing network' do provider.class.stubs(:network_exists?).returns(false) provider.expects(:auth_nova).with(""network-list"") .returns('""+--------------------------------------+-------------+-------------+\n| ID | Label | Cidr |\n+--------------------------------------+-------------+-------------+\n| 703edc62-36ab-4c41-9d73-884b30e9acbd | novanetwork | 10.0.0.0/16 |\n+--------------------------------------+-------------+-------------+\n"" ') provider.exists? end it 'should check existsing network' do resource[:network] = '10.0.0.0/16' resource[:label] = 'novanetwork' provider.class.stubs(:network_exists?).returns(true) provider.expects(:auth_nova).with(""network-list"") .returns('""+--------------------------------------+-------------+-------------+\n| ID | Label | Cidr |\n+--------------------------------------+-------------+-------------+\n| 703edc62-36ab-4c41-9d73-884b30e9acbd | novanetwork | 10.0.0.0/16 |\n+--------------------------------------+-------------+-------------+\n"" ') provider.exists? end end describe '#create' do it 'should create network' do provider.expects(:auth_nova).with(""network-create"", ['nova-network', '--fixed-range-v4', '10.20.0.0/16'] ) .returns('""+--------------------------------------+-------------+-------------+\n| ID | Label | Cidr |\n+--------------------------------------+-------------+-------------+\n| 703edc62-36ab-4c41-9d73-88sdfsdfsdfsd | nova-network | 10.20.0.0/16 |\n+--------------------------------------+-------------+-------------+\n"" ') provider.create end end describe '#destroy' do it 'should destroy network' do resource[:ensure] = :absent provider.expects(:auth_nova).with(""network-delete"", ""nova-network"") .returns('""+--------------------------------------+-------------+-------------+\n| ID | Label | Cidr |\n+--------------------------------------+-------------+-------------+\n ') provider.destroy end end end it_behaves_like('nova_network') end ",,117,71
openstack%2Fneutron-vpnaas~stable%2Fliberty~Id0d5f4b4975ec87de441d0bbcae65666ec6a7640,openstack/neutron-vpnaas,stable/liberty,Id0d5f4b4975ec87de441d0bbcae65666ec6a7640,Add reno for release notes management,MERGED,2015-12-09 01:29:24.000000000,2015-12-11 05:47:21.000000000,2015-12-11 05:47:20.000000000,"[{'_account_id': 3}, {'_account_id': 4395}, {'_account_id': 7787}, {'_account_id': 10692}, {'_account_id': 14605}]","[{'number': 1, 'created': '2015-12-09 01:29:24.000000000', 'files': ['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/668267cd46a9682f5ce70d3d67344b855f0773cf', 'message': 'Add reno for release notes management\n\nChange-Id: Id0d5f4b4975ec87de441d0bbcae65666ec6a7640\nSigned-off-by: Kyle Mestery <mestery@mestery.com>\n(cherry picked from commit 71741e1f1c7036d2c06b8244ce1af01c22f4c674)\n'}]",0,255029,668267cd46a9682f5ce70d3d67344b855f0773cf,9,5,1,105,,,0,"Add reno for release notes management

Change-Id: Id0d5f4b4975ec87de441d0bbcae65666ec6a7640
Signed-off-by: Kyle Mestery <mestery@mestery.com>
(cherry picked from commit 71741e1f1c7036d2c06b8244ce1af01c22f4c674)
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/29/255029/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/.placeholder', 'releasenotes/source/unreleased.rst', '.gitignore', 'test-requirements.txt', 'releasenotes/source/_static/.placeholder', 'releasenotes/source/liberty.rst', 'releasenotes/source/_templates/.placeholder', 'releasenotes/source/index.rst', 'tox.ini', 'releasenotes/source/conf.py']",10,668267cd46a9682f5ce70d3d67344b855f0773cf,reno,"# -*- coding: utf-8 -*- # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. # Neutron VPNaaS Release Notes documentation build configuration file, created # by # sphinx-quickstart on Tue Nov 3 17:40:50 2015. # # This file is execfile()d with the current directory set to its # containing dir. # # Note that not all possible configuration values are present in this # autogenerated file. # # All configuration values have a default; values that are commented out # serve to show the default. # If extensions (or modules to document with autodoc) are in another directory, # add these directories to sys.path here. If the directory is relative to the # documentation root, use os.path.abspath to make it absolute, like shown here. # sys.path.insert(0, os.path.abspath('.')) # -- General configuration ------------------------------------------------ # If your documentation needs a minimal Sphinx version, state it here. # needs_sphinx = '1.0' # Add any Sphinx extension module names here, as strings. They can be # extensions coming with Sphinx (named 'sphinx.ext.*') or your custom # ones. extensions = [ 'oslosphinx', 'reno.sphinxext', ] # Add any paths that contain templates here, relative to this directory. templates_path = ['_templates'] # The suffix of source filenames. source_suffix = '.rst' # The encoding of source files. # source_encoding = 'utf-8-sig' # The master toctree document. master_doc = 'index' # General information about the project. project = u'Neutron VPNaaS Release Notes' copyright = u'2015, Neutron VPNaaS Developers' # The version info for the project you're documenting, acts as replacement for # |version| and |release|, also used in various other places throughout the # built documents. # # The short X.Y version. from neutron_vpnaas.version import version_info as neutron_vpnaas_version # The full version, including alpha/beta/rc tags. release = neutron_vpnaas_version.version_string_with_vcs() # The short X.Y version. version = neutron_vpnaas_version.canonical_version_string() # The language for content autogenerated by Sphinx. Refer to documentation # for a list of supported languages. # language = None # There are two options for replacing |today|: either, you set today to some # non-false value, then it is used: # today = '' # Else, today_fmt is used as the format for a strftime call. # today_fmt = '%B %d, %Y' # List of patterns, relative to source directory, that match files and # directories to ignore when looking for source files. exclude_patterns = [] # The reST default role (used for this markup: `text`) to use for all # documents. # default_role = None # If true, '()' will be appended to :func: etc. cross-reference text. # add_function_parentheses = True # If true, the current module name will be prepended to all description # unit titles (such as .. function::). # add_module_names = True # If true, sectionauthor and moduleauthor directives will be shown in the # output. They are ignored by default. # show_authors = False # The name of the Pygments (syntax highlighting) style to use. pygments_style = 'sphinx' # A list of ignored prefixes for module index sorting. # modindex_common_prefix = [] # If true, keep warnings as ""system message"" paragraphs in the built documents. # keep_warnings = False # -- Options for HTML output ---------------------------------------------- # The theme to use for HTML and HTML Help pages. See the documentation for # a list of builtin themes. html_theme = 'default' # Theme options are theme-specific and customize the look and feel of a theme # further. For a list of options available for each theme, see the # documentation. # html_theme_options = {} # Add any paths that contain custom themes here, relative to this directory. # html_theme_path = [] # The name for this set of Sphinx documents. If None, it defaults to # ""<project> v<release> documentation"". # html_title = None # A shorter title for the navigation bar. Default is the same as html_title. # html_short_title = None # The name of an image file (relative to this directory) to place at the top # of the sidebar. # html_logo = None # The name of an image file (within the static path) to use as favicon of the # docs. This file should be a Windows icon file (.ico) being 16x16 or 32x32 # pixels large. # html_favicon = None # Add any paths that contain custom static files (such as style sheets) here, # relative to this directory. They are copied after the builtin static files, # so a file named ""default.css"" will overwrite the builtin ""default.css"". html_static_path = ['_static'] # Add any extra paths that contain custom files (such as robots.txt or # .htaccess) here, relative to this directory. These files are copied # directly to the root of the documentation. # html_extra_path = [] # If not '', a 'Last updated on:' timestamp is inserted at every page bottom, # using the given strftime format. # html_last_updated_fmt = '%b %d, %Y' # If true, SmartyPants will be used to convert quotes and dashes to # typographically correct entities. # html_use_smartypants = True # Custom sidebar templates, maps document names to template names. # html_sidebars = {} # Additional templates that should be rendered to pages, maps page names to # template names. # html_additional_pages = {} # If false, no module index is generated. # html_domain_indices = True # If false, no index is generated. # html_use_index = True # If true, the index is split into individual pages for each letter. # html_split_index = False # If true, links to the reST sources are added to the pages. # html_show_sourcelink = True # If true, ""Created using Sphinx"" is shown in the HTML footer. Default is True. # html_show_sphinx = True # If true, ""(C) Copyright ..."" is shown in the HTML footer. Default is True. # html_show_copyright = True # If true, an OpenSearch description file will be output, and all pages will # contain a <link> tag referring to it. The value of this option must be the # base URL from which the finished HTML is served. # html_use_opensearch = '' # This is the file name suffix for HTML files (e.g. "".xhtml""). # html_file_suffix = None # Output file base name for HTML help builder. htmlhelp_basename = 'NeutronVPNaaSReleaseNotesdoc' # -- Options for LaTeX output --------------------------------------------- latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } # Grouping the document tree into LaTeX files. List of tuples # (source start file, target name, title, # author, documentclass [howto, manual, or own class]). latex_documents = [ ('index', 'NeutronVPNaaSReleaseNotes.tex', u'Neutron VPNaaS Release Notes Documentation', u'Neutron VPNaaS Developers', 'manual'), ] # The name of an image file (relative to this directory) to place at the top of # the title page. # latex_logo = None # For ""manual"" documents, if this is true, then toplevel headings are parts, # not chapters. # latex_use_parts = False # If true, show page references after internal links. # latex_show_pagerefs = False # If true, show URL addresses after external links. # latex_show_urls = False # Documents to append as an appendix to all manuals. # latex_appendices = [] # If false, no module index is generated. # latex_domain_indices = True # -- Options for manual page output --------------------------------------- # One entry per manual page. List of tuples # (source start file, name, description, authors, manual section). man_pages = [ ('index', 'neutronvpnaasreleasenotes', u'Neutron VPNaaS Release Notes ' 'Documentation', [u'Neutron VPNaaS Developers'], 1) ] # If true, show URL addresses after external links. # man_show_urls = False # -- Options for Texinfo output ------------------------------------------- # Grouping the document tree into Texinfo files. List of tuples # (source start file, target name, title, author, # dir menu entry, description, category) texinfo_documents = [ ('index', 'NeutronVPNaaSReleaseNotes', u'Neutron VPNaaS Release Notes ' 'Documentation', u'Neutron VPNaaS Developers', 'NeutronVPNaaSReleaseNotes', 'One line description of project.', 'Miscellaneous'), ] # Documents to append as an appendix to all manuals. # texinfo_appendices = [] # If false, no module index is generated. # texinfo_domain_indices = True # How to display URL addresses: 'footnote', 'no', or 'inline'. # texinfo_show_urls = 'footnote' # If true, do not generate a @detailmenu in the ""Top"" node's menu. # texinfo_no_detailmenu = False ",,303,0
openstack%2Fneutron~master~I526a7e329be41f6eb3b0e296987f820f685d2eb6,openstack/neutron,master,I526a7e329be41f6eb3b0e296987f820f685d2eb6,Pass proxy environment variables to tox,ABANDONED,2015-12-10 16:30:22.000000000,2015-12-11 05:43:59.000000000,,"[{'_account_id': 6524}, {'_account_id': 9681}, {'_account_id': 10153}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15752}]","[{'number': 1, 'created': '2015-12-10 16:30:22.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron/commit/07b44ca23a0601814d5519a4b029eb755c50d931', 'message': 'Pass proxy environment variables to tox\n\nwho run tests under firewall should pass proxy env variables to tox\nso that it can install dependencies for proper testing.\n\n*_proxy will get all env variables like http_proxy, https_proxy and\nno_proxy etc.\n\nChange-Id: I526a7e329be41f6eb3b0e296987f820f685d2eb6\n'}]",0,255969,07b44ca23a0601814d5519a4b029eb755c50d931,8,6,1,17120,,,0,"Pass proxy environment variables to tox

who run tests under firewall should pass proxy env variables to tox
so that it can install dependencies for proper testing.

*_proxy will get all env variables like http_proxy, https_proxy and
no_proxy etc.

Change-Id: I526a7e329be41f6eb3b0e296987f820f685d2eb6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/69/255969/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,07b44ca23a0601814d5519a4b029eb755c50d931,,passenv = TRACE_FAILONLY *_proxy *_PROXY,passenv = TRACE_FAILONLY,1,1
openstack%2Fpython-monascaclient~master~I170ca56b5e0fc64ae9b49b5c04be19e1b1d45a1f,openstack/python-monascaclient,master,I170ca56b5e0fc64ae9b49b5c04be19e1b1d45a1f,Further restrictions on oslo.service,MERGED,2015-12-11 05:30:39.000000000,2015-12-11 05:43:18.000000000,2015-12-11 05:43:18.000000000,"[{'_account_id': 3}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-12-11 05:30:39.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-monascaclient/commit/5c677fe8095106b0d3ab47375d82f67d517ceb45', 'message': 'Further restrictions on oslo.service\n\noslo.service has versions past 0.9 that are not part of their stable liberty\nbranch.\n\nChange-Id: I170ca56b5e0fc64ae9b49b5c04be19e1b1d45a1f\n'}]",0,256221,5c677fe8095106b0d3ab47375d82f67d517ceb45,6,2,1,14273,,,0,"Further restrictions on oslo.service

oslo.service has versions past 0.9 that are not part of their stable liberty
branch.

Change-Id: I170ca56b5e0fc64ae9b49b5c04be19e1b1d45a1f
",git fetch https://review.opendev.org/openstack/python-monascaclient refs/changes/21/256221/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,5c677fe8095106b0d3ab47375d82f67d517ceb45,,oslo.service<0.10,oslo.service<1.0,1,1
openstack%2Fneutron-lbaas~master~Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2,openstack/neutron-lbaas,master,Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2,Allow lower case protocol values for listener,ABANDONED,2015-10-26 18:07:23.000000000,2015-12-11 05:28:03.000000000,,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 6951}, {'_account_id': 7293}, {'_account_id': 9828}, {'_account_id': 10477}, {'_account_id': 10980}, {'_account_id': 12999}, {'_account_id': 14605}, {'_account_id': 17120}, {'_account_id': 17275}, {'_account_id': 17776}]","[{'number': 1, 'created': '2015-10-26 18:07:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/4275b2251f2ce7a3ebbc7e97550b731820623427', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired in api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}, {'number': 2, 'created': '2015-10-28 14:51:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/fa92acc9186b6be881e9588947011f71871d73f2', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired on api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}, {'number': 3, 'created': '2015-10-30 15:45:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/f40c83f3cb23e037656195954469ec780d464580', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired on api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}, {'number': 4, 'created': '2015-10-30 15:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/0b350ae3bcc8a01d08c9783b00d421acb7339ba6', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired on api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}, {'number': 5, 'created': '2015-12-03 17:33:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/ba0e68fdc9e9d3a17f2049872ee2511025a0fbb6', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired on api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}, {'number': 6, 'created': '2015-12-04 21:55:59.000000000', 'files': ['neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/tests/tempest/v2/api/test_listeners_non_admin.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/7c49cba1fee16aaa9d6efd5681d0e83add460cf0', 'message': 'Allow lower case protocol values for listener\n\nThis patch will make listener protocol value case insensitive. This is\nrequired on api side if different clients can be used.\n\nChange-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2\nCloses-Bug: #1508687\n'}]",20,239500,7c49cba1fee16aaa9d6efd5681d0e83add460cf0,62,12,6,17120,,,0,"Allow lower case protocol values for listener

This patch will make listener protocol value case insensitive. This is
required on api side if different clients can be used.

Change-Id: Ib566e1321c8f8b90b260da6cfeb7590c4dac17a2
Closes-Bug: #1508687
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/00/239500/6 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/extensions/loadbalancerv2.py', 'neutron_lbaas/tests/unit/services/loadbalancer/test_loadbalancer_plugin.py']",2,4275b2251f2ce7a3ebbc7e97550b731820623427,239500," def test_listener_create_with_lowercase_protocol(self): listener_id = _uuid() protocol = 'tcp' data = {'listener': {'tenant_id': _uuid(), 'name': 'listen-name-1', 'description': 'listen-1-desc', 'protocol': loadbalancerv2.convert_protocol( protocol), 'protocol_port': 80, 'default_tls_container_ref': None, 'sni_container_refs': [], 'connection_limit': 100, 'admin_state_up': True, 'loadbalancer_id': _uuid()}} return_value = copy.copy(data['listener']) return_value.update({'id': listener_id}) del return_value['loadbalancer_id'] instance = self.plugin.return_value instance.create_listener.return_value = return_value res = self.api.post(_get_path('lbaas/listeners', fmt=self.fmt), self.serialize(data), content_type='application/{0}'.format(self.fmt)) instance.create_listener.assert_called_with(mock.ANY, listener=data) self.assertEqual(exc.HTTPCreated.code, res.status_int) res = self.deserialize(res) self.assertIn('listener', res) self.assertEqual(return_value, res['listener']) ",,59,3
openstack%2Fmonasca-persister~master~I4d6bfb4251eb23cf86b3173ac9cb0b889ebbf674,openstack/monasca-persister,master,I4d6bfb4251eb23cf86b3173ac9cb0b889ebbf674,Adjustments to support new oslo libraries,MERGED,2015-12-10 22:45:33.000000000,2015-12-11 05:09:35.000000000,2015-12-11 05:09:35.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 14273}]","[{'number': 1, 'created': '2015-12-10 22:45:33.000000000', 'files': ['openstack/common/fileutils.py', 'openstack/common/local.py', 'openstack/common/service.py', 'openstack/common/fixture/__init__.py', 'openstack/common/fixture/config.py', 'openstack/common/jsonutils.py', 'monasca_persister/persister.py', 'openstack/common/fixture/mockpatch.py', 'requirements.txt', 'openstack/common/fixture/moxstubout.py', 'openstack/common/log.py', 'openstack/common/strutils.py', 'openstack/common/__init__.py', 'openstack/common/fixture/lockutils.py', 'monasca_persister/service.py', 'openstack/common/excutils.py', 'openstack/common/lockutils.py', 'openstack/__init__.py', 'openstack/common/loopingcall.py', 'openstack/common/eventlet_backdoor.py', 'openstack/common/timeutils.py', 'openstack/common/gettextutils.py', 'openstack/common/systemd.py', 'openstack/common/fixture/logging.py', 'openstack/common/importutils.py', 'setup.cfg', 'openstack/common/threadgroup.py'], 'web_link': 'https://opendev.org/openstack/monasca-persister/commit/023646b3a225c9d5d752a7e2b2fdffa2b3b6fa72', 'message': 'Adjustments to support new oslo libraries\n\nRemoved the old openstack directory and replaced it with oslo libraries.\n\nUpdated requirements for liberty versions of oslo libraries.\n\nChange-Id: I4d6bfb4251eb23cf86b3173ac9cb0b889ebbf674\n'}]",0,256123,023646b3a225c9d5d752a7e2b2fdffa2b3b6fa72,7,3,1,14273,,,0,"Adjustments to support new oslo libraries

Removed the old openstack directory and replaced it with oslo libraries.

Updated requirements for liberty versions of oslo libraries.

Change-Id: I4d6bfb4251eb23cf86b3173ac9cb0b889ebbf674
",git fetch https://review.opendev.org/openstack/monasca-persister refs/changes/23/256123/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/common/fileutils.py', 'openstack/common/local.py', 'openstack/common/service.py', 'openstack/common/fixture/__init__.py', 'openstack/common/fixture/config.py', 'openstack/common/jsonutils.py', 'monasca_persister/persister.py', 'openstack/common/fixture/mockpatch.py', 'requirements.txt', 'openstack/common/fixture/moxstubout.py', 'openstack/common/log.py', 'openstack/common/strutils.py', 'openstack/common/__init__.py', 'openstack/common/fixture/lockutils.py', 'monasca_persister/service.py', 'openstack/common/excutils.py', 'openstack/common/lockutils.py', 'openstack/__init__.py', 'openstack/common/loopingcall.py', 'openstack/common/eventlet_backdoor.py', 'openstack/common/timeutils.py', 'openstack/common/gettextutils.py', 'openstack/common/systemd.py', 'openstack/common/fixture/logging.py', 'openstack/common/importutils.py', 'setup.cfg', 'openstack/common/threadgroup.py']",27,023646b3a225c9d5d752a7e2b2fdffa2b3b6fa72,,,"# Copyright 2012 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import threading import eventlet from eventlet import greenpool from openstack.common import log as logging from openstack.common import loopingcall LOG = logging.getLogger(__name__) def _thread_done(gt, *args, **kwargs): """"""Callback function to be passed to GreenThread.link() when we spawn() Calls the :class:`ThreadGroup` to notify if. """""" kwargs['group'].thread_done(kwargs['thread']) class Thread(object): """"""Wrapper around a greenthread, that holds a reference to the :class:`ThreadGroup`. The Thread will notify the :class:`ThreadGroup` when it has done so it can be removed from the threads list. """""" def __init__(self, thread, group): self.thread = thread self.thread.link(_thread_done, group=group, thread=self) def stop(self): self.thread.kill() def wait(self): return self.thread.wait() def link(self, func, *args, **kwargs): self.thread.link(func, *args, **kwargs) class ThreadGroup(object): """"""The point of the ThreadGroup class is to: * keep track of timers and greenthreads (making it easier to stop them when need be). * provide an easy API to add timers. """""" def __init__(self, thread_pool_size=10): self.pool = greenpool.GreenPool(thread_pool_size) self.threads = [] self.timers = [] def add_dynamic_timer(self, callback, initial_delay=None, periodic_interval_max=None, *args, **kwargs): timer = loopingcall.DynamicLoopingCall(callback, *args, **kwargs) timer.start(initial_delay=initial_delay, periodic_interval_max=periodic_interval_max) self.timers.append(timer) def add_timer(self, interval, callback, initial_delay=None, *args, **kwargs): pulse = loopingcall.FixedIntervalLoopingCall(callback, *args, **kwargs) pulse.start(interval=interval, initial_delay=initial_delay) self.timers.append(pulse) def add_thread(self, callback, *args, **kwargs): gt = self.pool.spawn(callback, *args, **kwargs) th = Thread(gt, self) self.threads.append(th) return th def thread_done(self, thread): self.threads.remove(thread) def _stop_threads(self): current = threading.current_thread() # Iterate over a copy of self.threads so thread_done doesn't # modify the list while we're iterating for x in self.threads[:]: if x is current: # don't kill the current thread. continue try: x.stop() except Exception as ex: LOG.exception(ex) def stop_timers(self): for x in self.timers: try: x.stop() except Exception as ex: LOG.exception(ex) self.timers = [] def stop(self, graceful=False): """"""stop function has the option of graceful=True/False. * In case of graceful=True, wait for all threads to be finished. Never kill threads. * In case of graceful=False, kill threads immediately. """""" self.stop_timers() if graceful: # In case of graceful=True, wait for all threads to be # finished, never kill threads self.wait() else: # In case of graceful=False(Default), kill threads # immediately self._stop_threads() def wait(self): for x in self.timers: try: x.wait() except eventlet.greenlet.GreenletExit: pass except Exception as ex: LOG.exception(ex) current = threading.current_thread() # Iterate over a copy of self.threads so thread_done doesn't # modify the list while we're iterating for x in self.threads[:]: if x is current: continue try: x.wait() except eventlet.greenlet.GreenletExit: pass except Exception as ex: LOG.exception(ex) ",18,3982
openstack%2Fmonasca-common~master~I2aba39f64af722341bad8b4e54c55c942ec857e1,openstack/monasca-common,master,I2aba39f64af722341bad8b4e54c55c942ec857e1,Adding liberty versions of oslo to requirements.txt,MERGED,2015-12-10 22:49:37.000000000,2015-12-11 05:08:26.000000000,2015-12-11 05:08:21.000000000,"[{'_account_id': 3}, {'_account_id': 2419}, {'_account_id': 14273}, {'_account_id': 15027}]","[{'number': 1, 'created': '2015-12-10 22:49:37.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/monasca-common/commit/78f0bda226e17af1eaf2987fa02ba16254ade6e3', 'message': 'Adding liberty versions of oslo to requirements.txt\n\nChange-Id: I2aba39f64af722341bad8b4e54c55c942ec857e1\n'}]",0,256127,78f0bda226e17af1eaf2987fa02ba16254ade6e3,8,4,1,14273,,,0,"Adding liberty versions of oslo to requirements.txt

Change-Id: I2aba39f64af722341bad8b4e54c55c942ec857e1
",git fetch https://review.opendev.org/openstack/monasca-common refs/changes/27/256127/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,78f0bda226e17af1eaf2987fa02ba16254ade6e3,,oslo.config<2.5.0,oslo.config>=1.2.1,1,1
openstack%2Fkuryr~master~I1902cf8ec6c5119545d5c70fcb70038d145a89ab,openstack/kuryr,master,I1902cf8ec6c5119545d5c70fcb70038d145a89ab,/NetworkDriver.CreateEndpoint cleanup,ABANDONED,2015-12-09 09:31:53.000000000,2015-12-11 04:52:26.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 12069}, {'_account_id': 14352}, {'_account_id': 15967}]","[{'number': 1, 'created': '2015-12-09 09:31:53.000000000', 'files': ['kuryr/tests/unit/test_kuryr_endpoint.py', 'kuryr/tests/unit/test_kuryr.py', 'kuryr/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/91b4dc00693d01837f430d514ab7fa0e306113b8', 'message': '/NetworkDriver.CreateEndpoint cleanup\n\nAdd logic to search for port created by ipam and remove subnet creation\nlogic. Now subnets are created using IPv4Data and IPv6Data in\n/NetworkDriver.CreateNetwork\n\nChange-Id: I1902cf8ec6c5119545d5c70fcb70038d145a89ab\nAuthored-By: Vikas Choudhary <choudharyvikas16@gmail.com>\nCloses-Bug: #1521111\n'}]",0,255153,91b4dc00693d01837f430d514ab7fa0e306113b8,4,6,1,11343,,,0,"/NetworkDriver.CreateEndpoint cleanup

Add logic to search for port created by ipam and remove subnet creation
logic. Now subnets are created using IPv4Data and IPv6Data in
/NetworkDriver.CreateNetwork

Change-Id: I1902cf8ec6c5119545d5c70fcb70038d145a89ab
Authored-By: Vikas Choudhary <choudharyvikas16@gmail.com>
Closes-Bug: #1521111
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/53/255153/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr/tests/unit/test_kuryr_endpoint.py', 'kuryr/tests/unit/test_kuryr.py', 'kuryr/controllers.py']",3,91b4dc00693d01837f430d514ab7fa0e306113b8,,"def _get_subnets_by_interface_cidr(neutron_network_id, interface_cidr): subnet_network = cidr.network subnet_cidr = '/'.join([str(subnet_network), return subnets def _create_port(endpoint_id, neutron_network_id, interface_mac, fixed_ips): port = { 'name': utils.get_neutron_port_name(endpoint_id), 'admin_state_up': True, 'network_id': neutron_network_id, 'device_owner': constants.DEVICE_OWNER, 'device_id': endpoint_id, 'binding:host_id': utils.get_hostname() } if interface_mac: port['mac_address'] = interface_mac port['fixed_ips'] = fixed_ips try: rcvd_port = app.neutron.create_port({'port': port}) except n_exceptions.NeutronClientException as ex: app.logger.error(""Error happend during creating a "" ""Neutron port: {0}"".format(ex)) raise return rcvd_port['port'] def _update_port(port, endpoint_id): port['name'] = '-'.join([endpoint_id, 'port']) try: response_port = app.neutron.update_port({'port': port}) except n_exceptions.NeutronClientException as ex: app.logger.error(""Error happend during creating a "" ""Neutron port: {0}"".format(ex)) raise return response_port def _get_fixed_ips_by_interface_cidr(subnets, interface_cidrv4, interface_cidrv6, fixed_ips): for subnet in subnets: fixed_ip = {'subnet_id': subnet['id']} if interface_cidrv4 or interface_cidrv6: if subnet['ip_version'] == 4 and interface_cidrv4: cidr = netaddr.IPNetwork(interface_cidrv4) elif subnet['ip_version'] == 6 and interface_cidrv6: cidr = netaddr.IPNetwork(interface_cidrv6) subnet_cidr = '/'.join([str(cidr.network), str(cidr.prefixlen)]) if subnet['cidr'] != subnet_cidr: continue fixed_ip['ip_address'] = str(cidr.ip) fixed_ips.append(fixed_ip) def _create_or_update_port(interface, neutron_network_id, endpoint_id): subnets = [] fixed_ips = [] if interface_cidrv4: subnetsv4 = _get_subnets_by_interface_cidr( neutron_network_id, interface_cidrv4) if interface_cidrv6: subnetsv6 = _get_subnets_by_interface_cidr( neutron_network_id, interface_cidrv6) else: app.logger.error(""Interface address not given."") subnets = subnetsv4 + subnetsv6 if not len(subnets): raise exceptions.NoResourceException( ""No subnet exist for the cidrs {0} and {1} "" .format(interface_cidrv4, interface_cidrv6)) if len(subnets) > 2: raise exceptions.DuplicatedResourceException( ""Multiple subnets exist for the cidrs {0} and {1}"" .format(interface_cidrv4, interface_cidrv6)) _get_fixed_ips_by_interface_cidr(subnets, interface_cidrv4, interface_cidrv6, fixed_ips) filtered_ports = app.neutron.list_ports(fixed_ips=fixed_ips) num_port = len(filtered_ports.get('ports', [])) if not num_port: response_port = _create_port(endpoint_id, neutron_network_id, interface_mac, fixed_ips) elif num_port == 1: port = filtered_ports['ports'][0] response_port = _update_port(port, endpoint_id) else: raise n_exceptions.DuplicatedResourceException( ""Multiple ports exist for the cidrs {0} and {1}"" .format(interface_cidrv4, interface_cidrv6)) if not interface_mac: response_interface['MacAddress'] = response_port['mac_address'] response_interface = _create_or_update_port(","def _process_subnet(neutron_network_id, endpoint_id, interface_cidr, new_subnets, existing_subnets, pool_id=None): subnet_network = str(cidr.network) subnet_cidr = '/'.join([subnet_network, if subnets: existing_subnets += subnets else: new_subnet = { 'name': '-'.join([endpoint_id, subnet_network]), 'network_id': neutron_network_id, 'ip_version': cidr.version, 'cidr': subnet_cidr, 'enable_dhcp': app.enable_dhcp, } if pool_id: del new_subnet['cidr'] new_subnet['subnetpool_id'] = pool_id new_subnets.append(new_subnet) def _get_or_create_subnet_by_pools(subnetpool_names, neutron_network_id, endpoint_id, new_subnets, existing_subnets): for subnetpool_name in subnetpool_names: pools = _get_subnetpools_by_attrs(name=subnetpool_name) if pools: pool = pools[0] prefixes = pool['prefixes'] for prefix in prefixes: _process_subnet(neutron_network_id, endpoint_id, prefix, new_subnets, existing_subnets, pool_id=pool['id']) if not (new_subnets or existing_subnets): raise exceptions.NoResourceException( ""No subnetpools with name {0} is found."" .format(', '.join(subnetpool_names))) def _handle_allocation_from_pools(neutron_network_id, endpoint_id, new_subnets, existing_subnets): _get_or_create_subnet_by_pools(SUBNET_POOLS_V4, neutron_network_id, endpoint_id, new_subnets, existing_subnets) _get_or_create_subnet_by_pools(SUBNET_POOLS_V6, neutron_network_id, endpoint_id, new_subnets, existing_subnets) created_subnets_response = {'subnets': []} if new_subnets: created_subnets_response = app.neutron.create_subnet( {'subnets': new_subnets}) return created_subnets_response def _handle_explicit_allocation(neutron_network_id, endpoint_id, interface_cidrv4, interface_cidrv6, new_subnets, existing_subnets): if interface_cidrv4: _process_subnet(neutron_network_id, endpoint_id, interface_cidrv4, new_subnets, existing_subnets) if interface_cidrv6: _process_subnet(neutron_network_id, endpoint_id, interface_cidrv6, new_subnets, existing_subnets) created_subnets_response = {'subnets': []} if new_subnets: # Bulk create operation of subnets created_subnets_response = app.neutron.create_subnet( {'subnets': new_subnets}) return created_subnets_response def _process_interface_address(port_dict, subnets_dict_by_id, response_interface): assigned_address = port_dict['ip_address'] subnet_id = port_dict['subnet_id'] subnet = subnets_dict_by_id[subnet_id] cidr = netaddr.IPNetwork(subnet['cidr']) assigned_address += '/' + str(cidr.prefixlen) if cidr.version == 4: response_interface['Address'] = assigned_address else: response_interface['AddressIPv6'] = assigned_address def _create_subnets_and_or_port(interface, neutron_network_id, endpoint_id): existing_subnets = [] created_subnets_response = {'subnets': []} # v4 and v6 Subnets for bulk creation. new_subnets = [] if interface_cidrv4 or interface_cidrv6: created_subnets_response = _handle_explicit_allocation( neutron_network_id, endpoint_id, interface_cidrv4, interface_cidrv6, new_subnets, existing_subnets) else: app.logger.info(""Retrieving or creating subnets with the default "" ""subnetpool because Address and AddressIPv6 are "" ""not given."") created_subnets_response = _handle_allocation_from_pools( neutron_network_id, endpoint_id, new_subnets, existing_subnets) try: port = { 'name': utils.get_neutron_port_name(endpoint_id), 'admin_state_up': True, ""binding:host_id"": utils.get_hostname(), 'network_id': neutron_network_id, 'device_owner': constants.DEVICE_OWNER, 'device_id': endpoint_id, } if interface_mac: port['mac_address'] = interface_mac created_subnets = created_subnets_response.get('subnets', []) all_subnets = created_subnets + existing_subnets fixed_ips = port['fixed_ips'] = [] for subnet in all_subnets: fixed_ip = {'subnet_id': subnet['id']} if interface_cidrv4 or interface_cidrv6: if subnet['ip_version'] == 4 and interface_cidrv4: cidr = netaddr.IPNetwork(interface_cidrv4) elif subnet['ip_version'] == 6 and interface_cidrv6: cidr = netaddr.IPNetwork(interface_cidrv6) subnet_cidr = '/'.join([str(cidr.network), str(cidr.prefixlen)]) if subnet['cidr'] != subnet_cidr: continue fixed_ip['ip_address'] = str(cidr.ip) fixed_ips.append(fixed_ip) created_port = app.neutron.create_port({'port': port}) created_port = created_port['port'] created_fixed_ips = created_port['fixed_ips'] subnets_dict_by_id = {subnet['id']: subnet for subnet in all_subnets} if not interface_mac: response_interface['MacAddress'] = created_port['mac_address'] if not (interface_cidrv4 or interface_cidrv6): if 'ip_address' in created_port: _process_interface_address( created_port, subnets_dict_by_id, response_interface) for fixed_ip in created_fixed_ips: _process_interface_address( fixed_ip, subnets_dict_by_id, response_interface) except n_exceptions.NeutronClientException as ex: app.logger.error(""Error happened during creating a "" ""Neutron port: {0}"".format(ex)) # Rollback the subnets creation for subnet in created_subnets: app.neutron.delete_subnet(subnet['id']) raise response_interface = _create_subnets_and_or_port(",124,449
openstack%2Fkuryr~master~I5ce106111a093163f79c0bd19dce065fbe2df9dc,openstack/kuryr,master,I5ce106111a093163f79c0bd19dce065fbe2df9dc,Create subnets in /NetworkDriver.CreateNetwork using IPv4Data and IPv6Data,ABANDONED,2015-12-09 09:14:44.000000000,2015-12-11 04:52:14.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 12069}, {'_account_id': 14352}, {'_account_id': 15967}]","[{'number': 1, 'created': '2015-12-09 09:14:44.000000000', 'files': ['kuryr/tests/unit/test_kuryr.py', 'kuryr/controllers.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/054218962e957e4e4ed65d8d2d0f95a5b16342c3', 'message': 'Create subnets in /NetworkDriver.CreateNetwork using IPv4Data and IPv6Data\n\nCurrently subnets are created in ./createEndpoint but to be compatible\nwith latest libnetwork changes , subnets should be created in\n/NetworkDriver.CreateNetwork.\n\nChange-Id: I5ce106111a093163f79c0bd19dce065fbe2df9dc\nAuthored-By: Vikas Choudhary <choudharyvikas16@gmail.com>\nCloses-Bug: #1520744\n'}]",0,255143,054218962e957e4e4ed65d8d2d0f95a5b16342c3,4,6,1,11343,,,0,"Create subnets in /NetworkDriver.CreateNetwork using IPv4Data and IPv6Data

Currently subnets are created in ./createEndpoint but to be compatible
with latest libnetwork changes , subnets should be created in
/NetworkDriver.CreateNetwork.

Change-Id: I5ce106111a093163f79c0bd19dce065fbe2df9dc
Authored-By: Vikas Choudhary <choudharyvikas16@gmail.com>
Closes-Bug: #1520744
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/43/255143/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr/tests/unit/test_kuryr.py', 'kuryr/controllers.py']",2,054218962e957e4e4ed65d8d2d0f95a5b16342c3,," pool_cidr = json_data['IPv4Data'][0]['Pool'] {'network': {'name': neutron_network_name, ""admin_state_up"": True}}) cidr = netaddr.IPNetwork(pool_cidr) subnet_network = str(cidr.network) subnet_cidr = '/'.join([subnet_network, str(cidr.prefixlen)]) subnets = _get_subnets_by_attrs( network_id=network['network']['id'], cidr=subnet_cidr) if not subnets: new_subnets = [] new_subnet = { 'name': pool_cidr, 'network_id': network['network']['id'], 'ip_version': cidr.version, 'cidr': subnet_cidr, } new_subnets.append(new_subnet) app.neutron.create_subnet({'subnets': new_subnets}) "," {'network': {'name': neutron_network_name, ""admin_state_up"": True}})",53,4
openstack%2Fkuryr~master~I02dbc0a41bd1b568123af2becf0b2dae31c058c9,openstack/kuryr,master,I02dbc0a41bd1b568123af2becf0b2dae31c058c9,Add Docker pluggable IPAM implementation to Kuryr,ABANDONED,2015-12-09 08:51:42.000000000,2015-12-11 04:52:05.000000000,,"[{'_account_id': 3}, {'_account_id': 1923}, {'_account_id': 6598}, {'_account_id': 12069}, {'_account_id': 14352}, {'_account_id': 15967}]","[{'number': 1, 'created': '2015-12-09 08:51:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/3cf28b16a80defe8c6853d2cbb2b921bc69cf4de', 'message': 'Add Docker pluggable IPAM implementation to Kuryr\n\nThis patch was authored by Vikas and i am only re posting\nthis as a new patch.\n\nAuthored-By: Vikas Choudhary <choudharyvikas16@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\n\nChange-Id: I02dbc0a41bd1b568123af2becf0b2dae31c058c9\nPartially-Implements: blueprint remote-ipam-driver\nCloses-Bug: #1520080\nRelated-bug: #1518249\n'}, {'number': 2, 'created': '2015-12-11 03:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr/commit/188a3a67d0da56224a772af7db1561f4421e3f76', 'message': ""Add Docker pluggable IPAM implementation to Kuryr\n\nThis patch implements libnetwork's remote IPAM driver. The following\nAPIs are implemented in this patch:\n    - POST /IpamDriver.GetDefaultAddressSpaces\n    - POST /IpamDriver.RequestPool\n    - POST /IpamDriver.ReleasePool\n    - POST /IpamDriver.RequestAddress\n    - POST /IpamDriver.ReleaseAddress\n\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\nChange-Id: I02dbc0a41bd1b568123af2becf0b2dae31c058c9\nImplements: blueprint remote-ipam-driver\nCloses-Bug: #1520080\nRelated-bug: #1518249\n""}, {'number': 3, 'created': '2015-12-11 03:54:18.000000000', 'files': ['kuryr/schemata/request_address.py', 'kuryr/schemata/release_pool.py', 'kuryr/tests/unit/test_ipam_pool.py', 'kuryr/tests/unit/test_kuryr_ipam.py', 'kuryr/tests/unit/test_utils.py', 'kuryr/utils.py', 'kuryr/common/constants.py', 'kuryr/controllers.py', 'kuryr/schemata/request_pool.py', 'kuryr/schemata/__init__.py', 'kuryr/schemata/commons.py', 'kuryr/tests/unit/base.py', 'kuryr/schemata/release_address.py', 'kuryr/common/config.py'], 'web_link': 'https://opendev.org/openstack/kuryr/commit/c34bfc5809f1b95c727fbf30aba4bf944b31ea67', 'message': ""Add Docker pluggable IPAM implementation to Kuryr\n\nThis patch implements libnetwork's remote IPAM driver. The following\nAPIs are implemented in this patch:\n    - POST /IpamDriver.GetDefaultAddressSpaces\n    - POST /IpamDriver.RequestPool\n    - POST /IpamDriver.ReleasePool\n    - POST /IpamDriver.RequestAddress\n    - POST /IpamDriver.ReleaseAddress\n\nAuthored-By: Vikas Choudhary <choudharyvikas16@gmail.com>\nCo-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>\nChange-Id: I02dbc0a41bd1b568123af2becf0b2dae31c058c9\nImplements: blueprint remote-ipam-driver\nCloses-Bug: #1520080\nRelated-bug: #1518249\n""}]",0,255132,c34bfc5809f1b95c727fbf30aba4bf944b31ea67,7,6,3,11343,,,0,"Add Docker pluggable IPAM implementation to Kuryr

This patch implements libnetwork's remote IPAM driver. The following
APIs are implemented in this patch:
    - POST /IpamDriver.GetDefaultAddressSpaces
    - POST /IpamDriver.RequestPool
    - POST /IpamDriver.ReleasePool
    - POST /IpamDriver.RequestAddress
    - POST /IpamDriver.ReleaseAddress

Authored-By: Vikas Choudhary <choudharyvikas16@gmail.com>
Co-Authored-By: Taku Fukushima <f.tac.mac@gmail.com>
Change-Id: I02dbc0a41bd1b568123af2becf0b2dae31c058c9
Implements: blueprint remote-ipam-driver
Closes-Bug: #1520080
Related-bug: #1518249
",git fetch https://review.opendev.org/openstack/kuryr refs/changes/32/255132/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr/schemata/request_address.py', 'kuryr/schemata/release_pool.py', 'kuryr/tests/unit/test_ipam_pool.py', 'kuryr/tests/unit/test_kuryr_ipam.py', 'kuryr/tests/unit/test_utils.py', 'kuryr/utils.py', 'kuryr/common/constants.py', 'kuryr/controllers.py', 'kuryr/schemata/request_pool.py', 'kuryr/schemata/__init__.py', 'kuryr/schemata/commons.py', 'kuryr/tests/unit/base.py', 'kuryr/schemata/release_address.py', 'kuryr/common/config.py']",14,3cf28b16a80defe8c6853d2cbb2b921bc69cf4de,bug/1520080," cfg.StrOpt('subnetpool_name_prefix', default='kuryrPool', help=_('Neutron subnetpool name will be prefixed by this.')), cfg.StrOpt('local_default_address_space', default='global_as', help=_('The default neutron local address-scope name')), cfg.StrOpt('global_default_address_space', default='global_as', help=_('The default neutron global address-scope name.'))",,929,11
openstack%2Fmagnum~master~Id4878e6f834aab095a74ef116257292aff09d6e1,openstack/magnum,master,Id4878e6f834aab095a74ef116257292aff09d6e1,Add retrieve_bay_uuid in conductor_utils,MERGED,2015-12-10 10:05:40.000000000,2015-12-11 04:45:46.000000000,2015-12-11 04:45:45.000000000,"[{'_account_id': 3}, {'_account_id': 8143}, {'_account_id': 10263}, {'_account_id': 12053}, {'_account_id': 12175}]","[{'number': 1, 'created': '2015-12-10 10:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5384c5ad0ad57d45625ae7693fdd48806f71da7e', 'message': ""Add retrieve_bay_uuid in conductor_utils\n\nIn k8s_conductor, lots of code will use bay_ident to get bay_uuid, kinds of\nduplicated code, use retrieve_bay_uuid in conductor_utils to replace them.\n\nretrieve_bay_uuid will return bay's uuid from bay_ident\n\nChange-Id: Id4878e6f834aab095a74ef116257292aff09d6e1\n""}, {'number': 2, 'created': '2015-12-10 10:09:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/aa67eb70afa0c987ce97ccc086d38ad6b76c1ed6', 'message': ""Add retrieve_bay_uuid in conductor_utils\n\nIn k8s_conductor, lots of code will use bay_ident to get bay_uuid, kinds of\nduplicated code, use retrieve_bay_uuid in conductor_utils to replace them.\n\nretrieve_bay_uuid will return bay's uuid from bay_ident\n\nChange-Id: Id4878e6f834aab095a74ef116257292aff09d6e1\n""}, {'number': 3, 'created': '2015-12-10 12:22:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a01c10372eee59470c0789ad755088c237a6a870', 'message': ""Add retrieve_bay_uuid in conductor_utils\n\nIn k8s_conductor, lots of code will use bay_ident to get bay_uuid, kinds of\nduplicated code, use retrieve_bay_uuid in conductor_utils to replace them.\n\nretrieve_bay_uuid will return bay's uuid from bay_ident\n\nChange-Id: Id4878e6f834aab095a74ef116257292aff09d6e1\n""}, {'number': 4, 'created': '2015-12-11 00:48:57.000000000', 'files': ['magnum/conductor/handlers/k8s_conductor.py', 'magnum/tests/unit/conductor/test_utils.py', 'magnum/conductor/utils.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/d7881f4c75254759b7fef59353079e9360d02903', 'message': ""Add retrieve_bay_uuid in conductor_utils\n\nIn k8s_conductor, lots of code will use bay_ident to get bay_uuid, kinds of\nduplicated code, use retrieve_bay_uuid in conductor_utils to replace them.\n\nretrieve_bay_uuid will return bay's uuid from bay_ident\n\nCloses-Bug: #1525035\nChange-Id: Id4878e6f834aab095a74ef116257292aff09d6e1\n""}]",1,255767,d7881f4c75254759b7fef59353079e9360d02903,18,5,4,12175,,,0,"Add retrieve_bay_uuid in conductor_utils

In k8s_conductor, lots of code will use bay_ident to get bay_uuid, kinds of
duplicated code, use retrieve_bay_uuid in conductor_utils to replace them.

retrieve_bay_uuid will return bay's uuid from bay_ident

Closes-Bug: #1525035
Change-Id: Id4878e6f834aab095a74ef116257292aff09d6e1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/67/255767/4 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/conductor/handlers/k8s_conductor.py', 'magnum/tests/unit/conductor/test_utils.py', 'magnum/conductor/utils.py']",3,5384c5ad0ad57d45625ae7693fdd48806f71da7e,add_retrieve_bayuuid,"from magnum.common import utilsdef retrieve_bay_uuid(context, bay_ident): if not utils.is_uuid_like(bay_ident): bay_obj = bay.Bay.get_by_name(context, bay_ident) return bay_obj.uuid else: return bay_ident ",,41,60
openstack%2Foslo.messaging~master~I4d81a4e8496f04d62e48317829d5dd8b942d501c,openstack/oslo.messaging,master,I4d81a4e8496f04d62e48317829d5dd8b942d501c,notif: Check the driver features in dispatcher,MERGED,2015-12-01 09:36:48.000000000,2015-12-11 04:17:22.000000000,2015-12-11 04:17:21.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 5638}, {'_account_id': 8601}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-12-01 09:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/36b123b6109965dd23c3af1aad623aea2c8a6d03', 'message': 'notif: Check the driver features in dispatcher\n\nThe transport/driver features check is done into the get listener\nmethods.\nSo when these methods are not used the driver features checks is not\ndone.\n\nThis change moves it into the dispatcher layer to ensure the\nrequirements are always checked.\n\nThis changes a bit the behavior of when the check occurs. Before\nit was during the listener object initialisation. Now this\nwhen the listener server start.\n\nChange-Id: I4d81a4e8496f04d62e48317829d5dd8b942d501c\n'}, {'number': 2, 'created': '2015-12-01 09:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/eca53e4b9b403d8aef7dbadbd474c71f55ceb292', 'message': 'notif: Check the driver features in dispatcher\n\nThe transport/driver features check is done into the get listener\nmethods.\nSo when these methods are not used the driver features checks is not\ndone.\n\nThis change moves it into the dispatcher layer to ensure the\nrequirements are always checked.\n\nThis changes a bit the behavior of when the check occurs. Before\nit was during the listener object initialisation. Now this\nwhen the listener server start.\n\nChange-Id: I4d81a4e8496f04d62e48317829d5dd8b942d501c\n'}, {'number': 3, 'created': '2015-12-01 12:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/aaff674b5547dfa706918cc76bea38f6094bc25a', 'message': 'notif: Check the driver features in dispatcher\n\nThe transport/driver features check is done into the get listener\nmethods.\nSo when these methods are not used the driver features checks is not\ndone.\n\nThis change moves it into the dispatcher layer to ensure the\nrequirements are always checked.\n\nThis changes a bit the behavior of when the check occurs. Before\nit was during the listener object initialisation. Now this\nwhen the listener server start.\n\nChange-Id: I4d81a4e8496f04d62e48317829d5dd8b942d501c\n'}, {'number': 4, 'created': '2015-12-08 08:15:55.000000000', 'files': ['oslo_messaging/notify/dispatcher.py', 'oslo_messaging/notify/listener.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/185f94c013442d87edcea3d81b133d26fdf8a945', 'message': 'notif: Check the driver features in dispatcher\n\nThe transport/driver features check is done into the get listener\nmethods.\nSo when these methods are not used the driver features checks is not\ndone.\n\nThis change moves it into the dispatcher layer to ensure the\nrequirements are always checked.\n\nThis changes a bit the behavior of when the check occurs. Before\nit was during the listener object initialisation. Now this\nwhen the listener server start.\n\nChange-Id: I4d81a4e8496f04d62e48317829d5dd8b942d501c\n'}]",0,251737,185f94c013442d87edcea3d81b133d26fdf8a945,15,5,4,2813,,,0,"notif: Check the driver features in dispatcher

The transport/driver features check is done into the get listener
methods.
So when these methods are not used the driver features checks is not
done.

This change moves it into the dispatcher layer to ensure the
requirements are always checked.

This changes a bit the behavior of when the check occurs. Before
it was during the listener object initialisation. Now this
when the listener server start.

Change-Id: I4d81a4e8496f04d62e48317829d5dd8b942d501c
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/37/251737/4 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/notify/dispatcher.py', 'oslo_messaging/notify/listener.py']",2,36b123b6109965dd23c3af1aad623aea2c8a6d03,sileht/batch-dispatcher,, transport._require_driver_features(requeue=allow_requeue) transport._require_driver_features(requeue=allow_requeue),1,2
openstack%2Foslo.messaging~master~I16184da24b8661aff7f4fba6196ecf33165f1a77,openstack/oslo.messaging,master,I16184da24b8661aff7f4fba6196ecf33165f1a77,batch notification listener,MERGED,2015-10-14 10:53:57.000000000,2015-12-11 04:16:59.000000000,2015-12-11 04:16:57.000000000,"[{'_account_id': 3}, {'_account_id': 1297}, {'_account_id': 2813}, {'_account_id': 5638}, {'_account_id': 8601}, {'_account_id': 8770}, {'_account_id': 9107}, {'_account_id': 13290}]","[{'number': 1, 'created': '2015-10-14 10:53:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/d4f3b4660b56574064876306c2f5b8abd8f6e147', 'message': 'PoC: batch notification listener\n\nGnocchi performs better is measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 2, 'created': '2015-10-14 14:05:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/6484352befa727870384f79a1334ba9c0b635806', 'message': 'PoC: batch notification listener\n\nGnocchi performs better is measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 3, 'created': '2015-10-14 14:06:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/16481313e8b58fbf00a636e427815a162f7b6fc7', 'message': 'PoC: batch notification listener\n\nGnocchi performs better is measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 4, 'created': '2015-10-14 14:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/34611a2326f91f4f83bb087063268ebbfbd4dbe8', 'message': 'PoC: batch notification listener\n\nGnocchi performs better is measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 5, 'created': '2015-10-14 14:56:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/79119cbea844d281894f2848f55c0314cd19b9df', 'message': 'batch notification listener\n\nGnocchi performs better is measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 6, 'created': '2015-10-15 05:46:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/a5d9e7eeca1b1d72e6fab5f1e59c971c79052eba', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 7, 'created': '2015-11-18 14:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4d10bc8b5254a5a38932b52081fe885baff05b6f', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 8, 'created': '2015-11-23 07:35:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/2d7da4306baffee1816f3b7c5361e74c00446778', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 9, 'created': '2015-11-23 08:42:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/c676edc5cea0f7a9d7335467a2c0e7f2dd56d072', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 10, 'created': '2015-11-23 08:56:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/9a8daa9ee5e83761deb0797bcf54401854520529', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 11, 'created': '2015-11-25 13:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5fe8672feb570863196b1d1d0e894a92a1c8ed22', 'message': 'batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n'}, {'number': 12, 'created': '2015-11-25 15:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/019d1d0cb52664943d2dd5ed129619b3682c7c26', 'message': ""batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nOn the driver side, a default batch implementation is provided.\nIt's just call the legacy poll method many times.\n\nDriver can override it to provide a better implementation.\nFor example, kafka handles batch natively and take benefit of this.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n""}, {'number': 13, 'created': '2015-12-01 09:36:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/59dbbeca63aa11b73a160c0b380c55de4a7e5b27', 'message': ""batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nOn the driver side, a default batch implementation is provided.\nIt's just call the legacy poll method many times.\n\nDriver can override it to provide a better implementation.\nFor example, kafka handles batch natively and take benefit of this.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n""}, {'number': 14, 'created': '2015-12-01 09:59:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/5df16189ed208470eeb5ef997c2f33514356d2c0', 'message': ""batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nOn the driver side, a default batch implementation is provided.\nIt's just call the legacy poll method many times.\n\nDriver can override it to provide a better implementation.\nFor example, kafka handles batch natively and take benefit of this.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n""}, {'number': 15, 'created': '2015-12-01 12:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/dce1d9415fbf776ffd9b0fa0e42874c1dabf13e8', 'message': ""batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nOn the driver side, a default batch implementation is provided.\nIt's just call the legacy poll method many times.\n\nDriver can override it to provide a better implementation.\nFor example, kafka handles batch natively and take benefit of this.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n""}, {'number': 16, 'created': '2015-12-08 08:15:55.000000000', 'files': ['tools/simulator.py', 'oslo_messaging/_drivers/impl_kafka.py', 'oslo_messaging/notify/dispatcher.py', 'oslo_messaging/dispatcher.py', 'oslo_messaging/tests/notify/test_listener.py', 'oslo_messaging/notify/listener.py', 'oslo_messaging/_drivers/impl_rabbit.py', 'oslo_messaging/tests/executors/test_executor.py', 'oslo_messaging/_drivers/base.py', 'oslo_messaging/tests/rpc/test_dispatcher.py', 'oslo_messaging/tests/functional/test_functional.py', 'oslo_messaging/tests/drivers/zmq/test_impl_zmq.py', 'oslo_messaging/_drivers/protocols/amqp/driver.py', 'oslo_messaging/tests/functional/utils.py', 'oslo_messaging/_drivers/amqpdriver.py', 'oslo_messaging/_drivers/zmq_driver/server/zmq_server.py', 'oslo_messaging/_executors/impl_pooledexecutor.py', 'oslo_messaging/tests/drivers/test_impl_rabbit.py', 'oslo_messaging/rpc/dispatcher.py', 'oslo_messaging/notify/__init__.py', 'oslo_messaging/_drivers/impl_fake.py', 'oslo_messaging/tests/test_amqp_driver.py', 'oslo_messaging/tests/drivers/test_impl_kafka.py', 'oslo_messaging/tests/notify/test_dispatcher.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/4dd644ac201ee0fe247d648a2f735998416bf2c7', 'message': ""batch notification listener\n\nGnocchi performs better if measurements are write in batch\nWhen Ceilometer is used with Gnocchi, this is not possible.\n\nThis change introduce a new notification listener that allows that.\n\nOn the driver side, a default batch implementation is provided.\nIt's just call the legacy poll method many times.\n\nDriver can override it to provide a better implementation.\nFor example, kafka handles batch natively and take benefit of this.\n\nChange-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77\n""}]",16,234716,4dd644ac201ee0fe247d648a2f735998416bf2c7,54,8,16,2813,,,0,"batch notification listener

Gnocchi performs better if measurements are write in batch
When Ceilometer is used with Gnocchi, this is not possible.

This change introduce a new notification listener that allows that.

On the driver side, a default batch implementation is provided.
It's just call the legacy poll method many times.

Driver can override it to provide a better implementation.
For example, kafka handles batch natively and take benefit of this.

Change-Id: I16184da24b8661aff7f4fba6196ecf33165f1a77
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/16/234716/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_messaging/notify/dispatcher.py', 'oslo_messaging/notify/listener.py', 'oslo_messaging/_executors/impl_pooledexecutor.py']",3,d4f3b4660b56574064876306c2f5b8abd8f6e147,sileht/batch-dispatcher,"from oslo_utils import timeutils batch_size = getattr(self.dispatcher, 'batch_size') batch_time = getattr(self.dispatcher, 'batch_time') watch = timeutils.StopWatch(duration=batch_time) with watch: while not self._tombstone.is_set(): incoming = [] for __ in range(batch_size): msg = self.listener.poll( timeout=watch.leftover(return_none=True)) if msg is not None: incoming.append(msg) if watch.expired(): break if not incoming: continue if batch_time is None and batch_size is None: incoming = incoming[0] callback = self.dispatcher(incoming, self._executor_callback) was_submitted = self._do_submit(callback) if not was_submitted: break"," while not self._tombstone.is_set(): incoming = self.listener.poll() if incoming is None: continue callback = self.dispatcher(incoming, self._executor_callback) was_submitted = self._do_submit(callback) if not was_submitted: break",140,34
openstack%2Fironic~master~I3fabefa686cad4bc50f6a5603fd95c96d1a21e68,openstack/ironic,master,I3fabefa686cad4bc50f6a5603fd95c96d1a21e68,Copy devstack code to ironic tree,MERGED,2015-12-10 13:47:30.000000000,2015-12-11 04:15:46.000000000,2015-12-11 04:15:45.000000000,"[{'_account_id': 3}, {'_account_id': 5805}, {'_account_id': 10239}, {'_account_id': 10343}, {'_account_id': 14629}, {'_account_id': 14760}]","[{'number': 1, 'created': '2015-12-10 13:47:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/04a7aae0849690580c7e346b71d4e93dbba7c912', 'message': ""Copy devstack code to ironic tree\n\nThis begins work toward moving our devstack code to a devstack plugin\nwithin our tree. This allows us to experiment with the devstack code\nmore easily, as well as take some load off of the devstack team.\n\nNote that the plugin is not enabled until we enable it in\nproject-config, so this doesn't actually affect devstack runs yet.\n\nThe files that exist for us in devstack are listed below.\n\n$ find . -name *ironic*\n./lib/ironic\n./lib/nova_plugins/hypervisor-ironic\n./files/rpms/ironic\n./files/apache-ironic.template\n./files/debs/ironic\n./extras.d/50-ironic.sh\n./tools/ironic\n\n$ tree tools/ironic\ntools/ironic\n├── scripts\n│\xa0\xa0 ├── cleanup-node\n│\xa0\xa0 ├── configure-vm\n│\xa0\xa0 ├── create-node\n│\xa0\xa0 └── setup-network\n└── templates\n    ├── brbm.xml\n    ├── tftpd-xinetd.template\n    └── vm.xml\n\nAll of these files are copied here, except:\nlib/nova_plugins/hypervisor-ironic: this is nova code and will not move.\nextras.d/50-ironic.sh: this will become the base for plugin.sh.\n\nChange-Id: I3fabefa686cad4bc50f6a5603fd95c96d1a21e68\nDepends-On: Id01d97fd13fa9f866d645ec5077834ddb78b2b89\n""}, {'number': 2, 'created': '2015-12-10 15:23:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4e7736e970125d8e65ea06eb2981ffd45befbcda', 'message': ""Copy devstack code to ironic tree\n\nThis begins work toward moving our devstack code to a devstack plugin\nwithin our tree. This allows us to experiment with the devstack code\nmore easily, as well as take some load off of the devstack team.\n\nNote that the plugin is not enabled until we enable it in\nproject-config, so this doesn't actually affect devstack runs yet.\n\nThe files that exist for us in devstack are listed below.\n\n$ find . -name *ironic*\n./lib/ironic\n./lib/nova_plugins/hypervisor-ironic\n./files/rpms/ironic\n./files/apache-ironic.template\n./files/debs/ironic\n./extras.d/50-ironic.sh\n./tools/ironic\n\n$ tree tools/ironic\ntools/ironic\n├── scripts\n│\xa0\xa0 ├── cleanup-node\n│\xa0\xa0 ├── configure-vm\n│\xa0\xa0 ├── create-node\n│\xa0\xa0 └── setup-network\n└── templates\n    ├── brbm.xml\n    ├── tftpd-xinetd.template\n    └── vm.xml\n\nAll of these files are copied here, except:\nlib/nova_plugins/hypervisor-ironic: this is nova code and will not move.\nextras.d/50-ironic.sh: this will become the base for plugin.sh.\n\nChange-Id: I3fabefa686cad4bc50f6a5603fd95c96d1a21e68\n""}, {'number': 3, 'created': '2015-12-10 15:38:12.000000000', 'files': ['devstack/tools/ironic/scripts/cleanup-node', 'devstack/tools/ironic/scripts/setup-network', 'devstack/tools/ironic/templates/brbm.xml', 'devstack/lib/ironic', 'devstack/tools/ironic/templates/vm.xml', 'devstack/tools/ironic/scripts/create-node', 'devstack/tools/ironic/templates/tftpd-xinetd.template', 'devstack/files/apache-ironic.template', 'devstack/tools/ironic/scripts/configure-vm', 'devstack/files/rpms/ironic', 'devstack/files/debs/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/b21873588abf56096f3971d21766920e06a569e9', 'message': ""Copy devstack code to ironic tree\n\nThis begins work toward moving our devstack code to a devstack plugin\nwithin our tree. This allows us to experiment with the devstack code\nmore easily, as well as take some load off of the devstack team.\n\nNote that the plugin is not enabled until we enable it in\nproject-config, so this doesn't actually affect devstack runs yet.\n\nThe files that exist for us in devstack are listed below.\n\n$ find . -name *ironic*\n./lib/ironic\n./lib/nova_plugins/hypervisor-ironic\n./files/rpms/ironic\n./files/apache-ironic.template\n./files/debs/ironic\n./extras.d/50-ironic.sh\n./tools/ironic\n\n$ tree tools/ironic\ntools/ironic\n├── scripts\n│\xa0\xa0 ├── cleanup-node\n│\xa0\xa0 ├── configure-vm\n│\xa0\xa0 ├── create-node\n│\xa0\xa0 └── setup-network\n└── templates\n    ├── brbm.xml\n    ├── tftpd-xinetd.template\n    └── vm.xml\n\nAll of these files are copied here, except:\nlib/nova_plugins/hypervisor-ironic: this is nova code and will not move.\nextras.d/50-ironic.sh: this will become the base for plugin.sh.\n\nChange-Id: I3fabefa686cad4bc50f6a5603fd95c96d1a21e68\nDepends-On: Id01d97fd13fa9f866d645ec5077834ddb78b2b89\n""}]",0,255879,b21873588abf56096f3971d21766920e06a569e9,18,6,3,10343,,,0,"Copy devstack code to ironic tree

This begins work toward moving our devstack code to a devstack plugin
within our tree. This allows us to experiment with the devstack code
more easily, as well as take some load off of the devstack team.

Note that the plugin is not enabled until we enable it in
project-config, so this doesn't actually affect devstack runs yet.

The files that exist for us in devstack are listed below.

$ find . -name *ironic*
./lib/ironic
./lib/nova_plugins/hypervisor-ironic
./files/rpms/ironic
./files/apache-ironic.template
./files/debs/ironic
./extras.d/50-ironic.sh
./tools/ironic

$ tree tools/ironic
tools/ironic
├── scripts
│   ├── cleanup-node
│   ├── configure-vm
│   ├── create-node
│   └── setup-network
└── templates
    ├── brbm.xml
    ├── tftpd-xinetd.template
    └── vm.xml

All of these files are copied here, except:
lib/nova_plugins/hypervisor-ironic: this is nova code and will not move.
extras.d/50-ironic.sh: this will become the base for plugin.sh.

Change-Id: I3fabefa686cad4bc50f6a5603fd95c96d1a21e68
Depends-On: Id01d97fd13fa9f866d645ec5077834ddb78b2b89
",git fetch https://review.opendev.org/openstack/ironic refs/changes/79/255879/2 && git format-patch -1 --stdout FETCH_HEAD,"['devstack/tools/ironic/scripts/cleanup-node', 'devstack/tools/ironic/scripts/setup-network', 'devstack/lib/ironic', 'devstack/tools/ironic/templates/brbm.xml', 'devstack/tools/ironic/templates/vm.xml', 'devstack/tools/ironic/scripts/create-node', 'devstack/tools/ironic/templates/tftpd-xinetd.template', 'devstack/files/apache-ironic.template', 'devstack/tools/ironic/scripts/configure-vm', 'devstack/files/rpms/ironic', 'devstack/files/debs/ironic']",11,04a7aae0849690580c7e346b71d4e93dbba7c912,ironic-devstack-plugin,docker.io ipmitool iptables ipxe libguestfs0 libvirt-bin open-iscsi openssh-client openvswitch-datapath-dkms openvswitch-switch python-libguestfs python-libvirt qemu qemu-kvm qemu-utils sgabios syslinux tftpd-hpa xinetd ,,1206,0
openstack%2Fsenlin~master~I870e2591a90858b33c04224a3cd9ab1708d9e822,openstack/senlin,master,I870e2591a90858b33c04224a3cd9ab1708d9e822,Fix typo,MERGED,2015-12-10 17:44:59.000000000,2015-12-11 04:03:45.000000000,2015-12-11 04:03:44.000000000,"[{'_account_id': 3}, {'_account_id': 6348}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 15857}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 17:44:59.000000000', 'files': ['doc/source/developer/cluster.rst'], 'web_link': 'https://opendev.org/openstack/senlin/commit/4743d4f3d61d72a455d76109af45f2d8aa3017da', 'message': 'Fix typo\n\ns/failes/failed/\n\nChange-Id: I870e2591a90858b33c04224a3cd9ab1708d9e822\n'}]",0,256014,4743d4f3d61d72a455d76109af45f2d8aa3017da,18,7,1,6763,,,0,"Fix typo

s/failes/failed/

Change-Id: I870e2591a90858b33c04224a3cd9ab1708d9e822
",git fetch https://review.opendev.org/openstack/senlin refs/changes/14/256014/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/developer/cluster.rst'],1,4743d4f3d61d72a455d76109af45f2d8aa3017da,,"any verification failed, a ``HTTPBadRequest`` exception is thrown and the","any verification failes, a ``HTTPBadRequest`` exception is thrown and the",1,1
openstack%2Fsenlin~master~I09ef59686ca849da8a16bf8b9390816870befbda,openstack/senlin,master,I09ef59686ca849da8a16bf8b9390816870befbda,Fix action status setting logic,MERGED,2015-12-10 15:05:17.000000000,2015-12-11 04:02:55.000000000,2015-12-11 04:02:54.000000000,"[{'_account_id': 3}, {'_account_id': 6763}, {'_account_id': 8246}, {'_account_id': 8358}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-12-10 15:05:17.000000000', 'files': ['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/09657fb171d7b0f81b1b35d3ae3eba632a7ff701', 'message': ""Fix action status setting logic\n\nThis patch fixes the existing logic related to setting action status.\nThe 'set_status' function of the Action class is supposed to be used\nwhen an action has finished execution. It will determin action status\nbased on the execution result. Previously, the function was mistakenly\nused in many places when we want to signal that an action can be\nstarted. This is terribly and sadly wrong. It is creating a lot of\nproblems related to action management.\n\nThis patch replaces the incorrect calls with 'action_update' DB API.\n\nChange-Id: I09ef59686ca849da8a16bf8b9390816870befbda\n""}]",0,255925,09657fb171d7b0f81b1b35d3ae3eba632a7ff701,16,5,1,8246,,,0,"Fix action status setting logic

This patch fixes the existing logic related to setting action status.
The 'set_status' function of the Action class is supposed to be used
when an action has finished execution. It will determin action status
based on the execution result. Previously, the function was mistakenly
used in many places when we want to signal that an action can be
started. This is terribly and sadly wrong. It is creating a lot of
problems related to action management.

This patch replaces the incorrect calls with 'action_update' DB API.

Change-Id: I09ef59686ca849da8a16bf8b9390816870befbda
",git fetch https://review.opendev.org/openstack/senlin refs/changes/25/255925/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/actions/cluster_action.py', 'senlin/tests/unit/engine/actions/test_cluster_action.py']",2,09657fb171d7b0f81b1b35d3ae3eba632a7ff701,fix-cluster-actions," @mock.patch.object(db_api, 'action_update') mock_node, mock_index, mock_update, mock_load): mock_update.assert_called_once_with( action.context, n_action.id, {'status': n_action.READY}) @mock.patch.object(db_api, 'action_update') mock_node, mock_index, mock_update, mock_load): update_calls = [ mock.call(action.context, node_action_1.id, {'status': node_action_1.READY}), mock.call(action.context, node_action_2.id, {'status': node_action_2.READY}) ] mock_update.assert_has_calls(update_calls) @mock.patch.object(db_api, 'action_update') mock_update, mock_load): @mock.patch.object(db_api, 'action_update') def test_do_update_multi(self, mock_wait, mock_start, mock_dep, mock_update, mock_load): update_calls = [ mock.call(action.context, n_action_1.id, {'status': n_action_1.READY}), mock.call(action.context, n_action_2.id, {'status': n_action_2.READY}) ] mock_update.assert_has_calls(update_calls) @mock.patch.object(db_api, 'action_update') mock_update, mock_load): mock_update.assert_called_once_with( action.context, n_action.id, {'status': n_action.READY}) @mock.patch.object(db_api, 'action_update') mock_update, mock_load): mock_update.assert_called_once_with( action.context, n_action.id, {'status': n_action.READY}) @mock.patch.object(db_api, 'action_update') mock_update, mock_load): update_calls = [ mock.call(action.context, n_action_1.id, {'status': n_action_1.READY}), mock.call(action.context, n_action_2.id, {'status': n_action_2.READY}) ] mock_update.assert_has_calls(update_calls) @mock.patch.object(db_api, 'action_update') mock_update, mock_load): @mock.patch.object(db_api, 'action_update') mock_update, mock_load): @mock.patch.object(db_api, 'action_update') mock_load_node, mock_update, mock_load): mock_update.assert_called_once_with( action.context, 'NODE_ACTION_ID', {'status': node_action.READY}) @mock.patch.object(db_api, 'action_update') mock_load_node, mock_update, mock_load): mock_update.assert_has_calls([ mock.call(action.context, 'NODE_ACTION_ID_1', {'status': node_action_1.READY}), mock.call(action.context, 'NODE_ACTION_ID_2', {'status': node_action_2.READY}) ]) @mock.patch.object(db_api, 'action_update') mock_load_node, mock_update, mock_load): mock_update.assert_called_once_with( action.context, 'NODE_ACTION_ID', {'status': node_action.READY})"," mock_node, mock_index, mock_load): mock_status = self.patchobject(n_action, 'set_status') mock_status.assert_called_once_with(n_action.READY) mock_node, mock_index, mock_load): mock_status_1 = self.patchobject(node_action_1, 'set_status') mock_status_2 = self.patchobject(node_action_2, 'set_status') mock_status_1.assert_called_once_with(node_action_1.READY) mock_status_2.assert_called_once_with(node_action_2.READY) mock_load): self.patchobject(n_action_1, 'set_status') self.patchobject(n_action_2, 'set_status') def test_do_update_multi(self, mock_wait, mock_start, mock_dep, mock_load): self.assertEqual(1, n_action_1.set_status.call_count) self.assertEqual(1, n_action_2.set_status.call_count) mock_load): self.assertEqual(1, n_action.set_status.call_count) mock_load): n_action.set_status.assert_called_once_with(n_action.READY) mock_load): n_action_1.set_status.assert_called_once_with(n_action_1.READY) n_action_2.set_status.assert_called_once_with(n_action_2.READY) mock_load): mock_load): mock_load_node, mock_load): node_action.set_status.assert_called_once_with(action.READY) mock_load_node, mock_load): node_action_1.set_status.assert_called_once_with(action.READY) node_action_2.set_status.assert_called_once_with(action.READY) mock_load_node, mock_load):",77,33
openstack%2Fopenstack-manuals~master~Ie99b48ff8b20fa6e53c4c65d1c9602f0e7e12469,openstack/openstack-manuals,master,Ie99b48ff8b20fa6e53c4c65d1c9602f0e7e12469,[config-ref] Fix minor issues with IBM FlashSystem,MERGED,2015-12-11 00:03:10.000000000,2015-12-11 04:01:06.000000000,2015-12-11 04:01:05.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 6635}, {'_account_id': 10497}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-11 00:03:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/277c8baacfae52c4955bc5c15a4a61c86bd2eea7', 'message': '[config-ref] Fix minor issues with IBM FlashSystem\n\nFixes some minor formatting issues with the IBM FlashSystem volume\ndriver RST conversion.\n\nChange-Id: Ie99b48ff8b20fa6e53c4c65d1c9602f0e7e12469\nImplements: blueprint config-ref-rst\n'}, {'number': 2, 'created': '2015-12-11 00:26:39.000000000', 'files': ['doc/config-ref-rst/source/block-storage/drivers/ibm-flashsystem-volume-driver.rst'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/9b5502664bde18a98c1265de5fcb84f6aa7f902b', 'message': '[config-ref] Fix minor issues with IBM FlashSystem\n\nFixes some minor formatting issues with the IBM FlashSystem volume\ndriver RST conversion.\n\nChange-Id: Ie99b48ff8b20fa6e53c4c65d1c9602f0e7e12469\nImplements: blueprint config-ref-rst\n'}]",2,256147,9b5502664bde18a98c1265de5fcb84f6aa7f902b,12,5,2,6635,,,0,"[config-ref] Fix minor issues with IBM FlashSystem

Fixes some minor formatting issues with the IBM FlashSystem volume
driver RST conversion.

Change-Id: Ie99b48ff8b20fa6e53c4c65d1c9602f0e7e12469
Implements: blueprint config-ref-rst
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/47/256147/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/config-ref-rst/source/block-storage/drivers/ibm-flashsystem-volume-driver.rst'],1,277c8baacfae52c4955bc5c15a4a61c86bd2eea7,bp/config-ref-rst,"set to ``True`` in the cinder configuration file, the driver uses all - ``True`` - ``True`` - Set to the id of the ``iscsi_ip_address`` obtained by FlashSystem GUI or CLI [4]_ On the cluster of the FlashSystem, the ``iscsi_ip_address`` column is theLimitations and known issues","set to ``True`` in the Cinder configuration file, the driver uses all - True - True - Set to the id of the iscsi_ip_address obtained by FlashSystem GUI or CLI [4]_ On the cluster of the FlashSystem, the iSCSI IP address column is theLimitation and known issues",6,6
openstack%2Fsenlin~master~I4046e1659311f1573f6e202dc54d5bcabb5904f0,openstack/senlin,master,I4046e1659311f1573f6e202dc54d5bcabb5904f0,Fix SDK test case,MERGED,2015-12-11 03:11:30.000000000,2015-12-11 03:38:52.000000000,2015-12-11 03:38:52.000000000,"[{'_account_id': 3}, {'_account_id': 11034}]","[{'number': 1, 'created': '2015-12-11 03:11:30.000000000', 'files': ['senlin/tests/unit/drivers/test_sdk.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/dae9d9395df5dd4fd451d4a6a3cb677d01219722', 'message': 'Fix SDK test case\n\nThere are some exceptions moved from SDK to keystoneauth. To adapt to\nthis change, senlin test case needs to be revised.\n\nChange-Id: I4046e1659311f1573f6e202dc54d5bcabb5904f0\n'}]",0,256191,dae9d9395df5dd4fd451d4a6a3cb677d01219722,7,2,1,8246,,,0,"Fix SDK test case

There are some exceptions moved from SDK to keystoneauth. To adapt to
this change, senlin test case needs to be revised.

Change-Id: I4046e1659311f1573f6e202dc54d5bcabb5904f0
",git fetch https://review.opendev.org/openstack/senlin refs/changes/91/256191/1 && git format-patch -1 --stdout FETCH_HEAD,['senlin/tests/unit/drivers/test_sdk.py'],1,dae9d9395df5dd4fd451d4a6a3cb677d01219722,fix-sdk-tests," raw = sdk.exc.InvalidResponse('INVALID') self.assertEqual('InvalidResponse', six.text_type(ex))"," raw = sdk.exc.AuthorizationFailure() self.assertEqual('AuthorizationFailure', six.text_type(ex))",2,2
openstack%2Fnetworking-ofagent~stable%2Fliberty~Ic1b1f363e3aac642e8e77dc09368df117a7d4827,openstack/networking-ofagent,stable/liberty,Ic1b1f363e3aac642e8e77dc09368df117a7d4827,Fix a pep8 error for an import order in ofagent,MERGED,2015-12-02 03:46:25.000000000,2015-12-11 03:38:02.000000000,2015-12-11 03:22:53.000000000,"[{'_account_id': 3}, {'_account_id': 105}, {'_account_id': 4395}, {'_account_id': 6854}, {'_account_id': 8344}, {'_account_id': 9681}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-02 03:46:25.000000000', 'files': ['networking_ofagent/plugins/ofagent/agent/main.py', 'networking_ofagent/plugins/ofagent/agent/__init__.py'], 'web_link': 'https://opendev.org/openstack/networking-ofagent/commit/392818deb92ae8ae447ea2532279929f1d69bd96', 'message': 'Fix a pep8 error for an import order in ofagent\n\nCloses-Bug: #1521542\nChange-Id: Ic1b1f363e3aac642e8e77dc09368df117a7d4827\n(cherry picked from commit 4dad45b50a228b69eae2962c8270a1c77df89f46)\n'}]",0,252166,392818deb92ae8ae447ea2532279929f1d69bd96,10,7,1,8344,,,0,"Fix a pep8 error for an import order in ofagent

Closes-Bug: #1521542
Change-Id: Ic1b1f363e3aac642e8e77dc09368df117a7d4827
(cherry picked from commit 4dad45b50a228b69eae2962c8270a1c77df89f46)
",git fetch https://review.opendev.org/openstack/networking-ofagent refs/changes/66/252166/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ofagent/plugins/ofagent/agent/main.py', 'networking_ofagent/plugins/ofagent/agent/__init__.py']",2,392818deb92ae8ae447ea2532279929f1d69bd96,,"# Copyright (C) 2015 VA Linux Systems Japan K.K. # Copyright (C) 2015 Fumihiko Kakuma <kakuma at valinux co jp> # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from ryu.lib import hub hub.patch() ",,21,5
openstack%2Fopenstacksdk~master~Ie86329155fffeef2a2f9f6c9927295380dc72671,openstack/openstacksdk,master,Ie86329155fffeef2a2f9f6c9927295380dc72671,Skip orchestration functional tests,MERGED,2015-12-10 22:37:50.000000000,2015-12-11 03:34:36.000000000,2015-12-11 03:34:35.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-10 22:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/812c70f9eef68c6bed1aa350fc1f4b59820c878d', 'message': 'Skip orchestration functional tests\n\nThere no longer seems to be enough resources on the gate to\nconsistently create a heat stack with one instance *and* a\nrun compute.server_create. It is more important to test compute\nthan orchestration, so disable those tests for now and fix\norchestration or delete the test in the future.\n\nBug to track:\nhttps://bugs.launchpad.net/python-openstacksdk/+bug/1525005\n\nChange-Id: Ie86329155fffeef2a2f9f6c9927295380dc72671\n'}, {'number': 2, 'created': '2015-12-10 23:29:12.000000000', 'files': ['openstack/tests/functional/orchestration/v1/test_stack.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d29c8bb74c71f0ae235b960eae627cc1a84bd09d', 'message': 'Skip orchestration functional tests\n\nThere no longer seems to be enough resources on the gate to\nconsistently create a heat stack with one instance *and* a\nrun compute.server_create. It is more important to test compute\nthan orchestration, so disable those tests for now and fix\norchestration or delete the test in the future.\n\nBug to track:\nhttps://bugs.launchpad.net/python-openstacksdk/+bug/1525005\n\nChange-Id: Ie86329155fffeef2a2f9f6c9927295380dc72671\n'}]",0,256120,d29c8bb74c71f0ae235b960eae627cc1a84bd09d,9,3,2,8736,,,0,"Skip orchestration functional tests

There no longer seems to be enough resources on the gate to
consistently create a heat stack with one instance *and* a
run compute.server_create. It is more important to test compute
than orchestration, so disable those tests for now and fix
orchestration or delete the test in the future.

Bug to track:
https://bugs.launchpad.net/python-openstacksdk/+bug/1525005

Change-Id: Ie86329155fffeef2a2f9f6c9927295380dc72671
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/20/256120/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/functional/orchestration/v1/test_stack.py'],1,812c70f9eef68c6bed1aa350fc1f4b59820c878d,orcfunc,"@unittest.skip(""bug/1525005"")",,1,0
openstack%2Fkolla~master~I88fe83a0eb3f3f6fbb9f69e522ff53e77c935098,openstack/kolla,master,I88fe83a0eb3f3f6fbb9f69e522ff53e77c935098,remove extra space,ABANDONED,2015-12-10 06:05:10.000000000,2015-12-11 03:25:24.000000000,,"[{'_account_id': 3}, {'_account_id': 1390}, {'_account_id': 13039}, {'_account_id': 16237}]","[{'number': 1, 'created': '2015-12-10 06:05:10.000000000', 'files': ['specs/ansible-multi.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/10a1694cb01b104063bf7e4eed529e2e907d1460', 'message': 'remove extra space\n\nChange-Id: I88fe83a0eb3f3f6fbb9f69e522ff53e77c935098\n'}]",0,255684,10a1694cb01b104063bf7e4eed529e2e907d1460,6,4,1,7488,,,0,"remove extra space

Change-Id: I88fe83a0eb3f3f6fbb9f69e522ff53e77c935098
",git fetch https://review.opendev.org/openstack/kolla refs/changes/84/255684/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ansible-multi.rst'],1,10a1694cb01b104063bf7e4eed529e2e907d1460,fix_typo,"To the untrained eye, this looks like a bunch of heavy wizardy. I personally","To the untrained eye, this looks like a bunch of heavy wizardy. I personally",1,1
openstack%2Fswift~master~I47a3127ef698b4bd1537b1562901ee9c2b5924d4,openstack/swift,master,I47a3127ef698b4bd1537b1562901ee9c2b5924d4,"Unification of manpages and conf-samples (default values, etc)",MERGED,2015-11-30 14:39:59.000000000,2015-12-11 03:20:54.000000000,2015-12-11 03:20:52.000000000,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 13052}, {'_account_id': 14867}, {'_account_id': 16896}, {'_account_id': 18015}]","[{'number': 1, 'created': '2015-11-30 14:39:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/9d14c804902dccb6bcd6e4e76b2bcbc277440875', 'message': 'Unification of manpages and conf-samples (default values, etc)\n\nChange-Id: I47a3127ef698b4bd1537b1562901ee9c2b5924d4\n'}, {'number': 2, 'created': '2015-11-30 18:08:30.000000000', 'files': ['doc/source/deployment_guide.rst', 'doc/manpages/dispersion.conf.5', 'etc/proxy-server.conf-sample', 'doc/manpages/proxy-server.conf.5', 'swift/account/reaper.py', 'doc/manpages/object-server.conf.5', 'etc/account-server.conf-sample', 'doc/manpages/object-expirer.conf.5', 'doc/manpages/account-server.conf.5', 'doc/manpages/container-server.conf.5'], 'web_link': 'https://opendev.org/openstack/swift/commit/28c4b7310fead32f7ce073ee4bb503a450e521f1', 'message': 'Unification of manpages and conf-samples (default values, etc)\n\nChange-Id: I47a3127ef698b4bd1537b1562901ee9c2b5924d4\n'}]",2,251396,28c4b7310fead32f7ce073ee4bb503a450e521f1,18,7,2,18015,,,0,"Unification of manpages and conf-samples (default values, etc)

Change-Id: I47a3127ef698b4bd1537b1562901ee9c2b5924d4
",git fetch https://review.opendev.org/openstack/swift refs/changes/96/251396/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/deployment_guide.rst', 'doc/manpages/dispersion.conf.5', 'etc/proxy-server.conf-sample', 'doc/manpages/proxy-server.conf.5', 'swift/account/reaper.py', 'doc/manpages/object-server.conf.5', 'etc/account-server.conf-sample', 'doc/manpages/account-server.conf.5', 'doc/manpages/object-expirer.conf.5', 'doc/manpages/container-server.conf.5']",10,9d14c804902dccb6bcd6e4e76b2bcbc277440875,config-manpages,".IP ""\fBbind_timeout\fR"" Timeout to bind socket. The default is 30..IP \fBmax_clients\fR This is a comma separated list of hosts allowed in the X-Container-Sync-To field for containers. This is the old-style of using container sync. It is strongly recommended to use the new style of a separate container-sync-realms.conf -- see container-sync-realms.conf-sample allowed_sync_hosts = 127.0.0.1.IP \fBdisable_fallocate\fR Disable pre-allocate disk space for a file. The default is false..IP \fBlog_max_line_length\fR The following caps the length of log lines to the value given; no limit if set to 0, the default. .IP \fBlog_custom_handlers\fR Comma separated list of functions to call to setup custom log handlers. functions get passed: conf, name, log_to_console, log_route, fmt, logger, adapted_logger. The default is empty. .IP \fBlog_udp_host\fR If set, log_udp_host will override log_address. .IP ""\fBlog_udp_port\fR UDP log port, the default is 514. .IP \fBlog_statsd_host\fR = localhost log_statsd_* enable StatsD logging. .IP \fBlog_statsd_port\fR The default is 8125. .IP \fBlog_statsd_default_sample_rate\fR The default is 1. .IP \fBlog_statsd_sample_rate_factor\fR The default is 1. .IP \fBlog_statsd_metric_prefix\fR The default is empty. .IP \fBdb_preallocation\fR If you don't mind the extra disk space usage in overhead, you can turn this on to preallocate disk space with SQLite databases to decrease fragmentation. The default is false. .IP \fBeventlet_debug\fR Debug mode for eventlet library. The default is false. .IP \fBfallocate_reserve\fR You can set fallocate_reserve to the number of bytes you'd like fallocate to reserve, whether there is space for the given file size or not. The default is 0..IP \fBallow_versions\fR The default is false. .IP \fBauto_create_account_prefix\fR The default is '.'. .IP \fBreplication_server\fR Configure parameter for creating specific server. To handle all verbs, including replication verbs, do not specify ""replication_server"" (this is the default). To only handle replication, set to a True value (e.g. ""True"" or ""1""). To handle only non-replication verbs, set to ""False"". Unless you have a separate replication network, you should not specify any value for ""replication_server""..RS 0 .IP ""\fB[filter:xprofile]\fR"" .RS 3 .IP ""\fBuse\fR"" Entry point for paste.deploy for the xprofile middleware. This is the reference to the installed python egg. This is normally \fBegg:swift#xprofile\fR. .IP ""\fBprofile_module\fR"" This option enable you to switch profilers which should inherit from python standard profiler. Currently the supported value can be 'cProfile', 'eventlet.green.profile' etc. .IP ""\fBlog_filename_prefix\fR"" This prefix will be used to combine process ID and timestamp to name the profile data file. Make sure the executing user has permission to write into this path (missing path segments will be created, if necessary). If you enable profiling in more than one type of daemon, you must override it with an unique value like, the default is /var/log/swift/profile/account.profile. .IP ""\fBdump_interval\fR"" The profile data will be dumped to local disk based on above naming rule in this interval. The default is 5.0. .IP ""\fBdump_timestamp\fR"" Be careful, this option will enable profiler to dump data into the file with time stamp which means there will be lots of files piled up in the directory. The default is false .IP ""\fBpath\fR"" This is the path of the URL to access the mini web UI. The default is __profile__. .IP ""\fBflush_at_shutdown\fR"" Clear the data when the wsgi server shutdown. The default is false. .IP ""\fBunwind\fR"" Unwind the iterator of applications. Default is false. .RE .PD.IP \fBper_diff\fR.IP \fBrsync_compress\fR Allow rsync to compress data which is transmitted to destination node during sync. However, this is applicable only when destination node is in a different region than the local one. The default is false. .IP \fBrsync_module\fR Format of the rysnc module where the replicator will send data. See etc/rsyncd.conf-sample for some usage examples. .IP \fBrecon_cache_path\fR Path to recon cache directory. The default is /var/cache/swift..IP \fBrecon_cache_path\fR Path to recon cache directory. The default is /var/cache/swift..IP \fBrecon_cache_path\fR Path to recon cache directory. The default is /var/cache/swift..IP \fBconn_timeout\fR Connection timeout to external services. The default is 5 seconds. .IP \fBrequest_tries\fR Server errors from requests will be retried by default. The default is 3.",.IP \fBer_diff\fR.IP \fBrequest_retries\fR Server errors from requests will be retried by default.,1620,418
openstack%2Fdevstack~master~Iebdb31b5f0888613e0454f09a426933d6fcd71b3,openstack/devstack,master,Iebdb31b5f0888613e0454f09a426933d6fcd71b3,only set admin_* options for eventlet,MERGED,2015-12-10 19:59:17.000000000,2015-12-11 03:20:29.000000000,2015-12-11 03:20:27.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 6482}, {'_account_id': 7191}, {'_account_id': 10118}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-12-10 19:59:17.000000000', 'files': ['lib/keystone'], 'web_link': 'https://opendev.org/openstack/devstack/commit/e42306d9db86a6cbb7cf1c062d8a5bdcd8479654', 'message': ""only set admin_* options for eventlet\n\nkeystone+apache don't need these values set.\n\nChange-Id: Iebdb31b5f0888613e0454f09a426933d6fcd71b3\nsee: http://lists.openstack.org/pipermail/openstack-dev/2015-December/081984.html\n""}]",0,256078,e42306d9db86a6cbb7cf1c062d8a5bdcd8479654,14,7,1,6537,,,0,"only set admin_* options for eventlet

keystone+apache don't need these values set.

Change-Id: Iebdb31b5f0888613e0454f09a426933d6fcd71b3
see: http://lists.openstack.org/pipermail/openstack-dev/2015-December/081984.html
",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/256078/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/keystone'],1,e42306d9db86a6cbb7cf1c062d8a5bdcd8479654,stop-using-deprecated-options," else iniset $KEYSTONE_CONF eventlet_server admin_bind_host ""$KEYSTONE_ADMIN_BIND_HOST"" iniset $KEYSTONE_CONF eventlet_server admin_workers ""$API_WORKERS"" # Public workers will use the server default, typically number of CPU."," iniset $KEYSTONE_CONF eventlet_server admin_bind_host ""$KEYSTONE_ADMIN_BIND_HOST"" iniset $KEYSTONE_CONF eventlet_server admin_workers ""$API_WORKERS"" # Public workers will use the server default, typically number of CPU. ",4,5
openstack%2Fmagnum~master~I8517024c77c6dc4082bf2ff6d0205d86e32fbfdc,openstack/magnum,master,I8517024c77c6dc4082bf2ff6d0205d86e32fbfdc,Refactor image check in Baymodel,MERGED,2015-12-08 14:32:14.000000000,2015-12-11 03:15:17.000000000,2015-12-11 03:15:16.000000000,"[{'_account_id': 3}, {'_account_id': 8143}, {'_account_id': 9591}, {'_account_id': 10263}, {'_account_id': 10515}, {'_account_id': 11536}, {'_account_id': 12053}, {'_account_id': 18386}]","[{'number': 1, 'created': '2015-12-08 14:32:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8cd4fc1540b8eea696b2e856f05b9a65abbd0b0c', 'message': 'Refactor image check in Baymodel\n\nA new magnum.api.attr_validator.py module is introduced to do the\nvalidation towards OpenStack resources. Currently in Baymodel-creation,\nthe image validation code is duplicated. We should reduce the\nduplicated code and unify the validation both in Bay and Baymodel.\n\nChange-Id: I8517024c77c6dc4082bf2ff6d0205d86e32fbfdc\nPartial-Bug: #1522060\n'}, {'number': 2, 'created': '2015-12-09 12:52:46.000000000', 'files': ['magnum/api/controllers/v1/baymodel.py', 'magnum/tests/unit/api/controllers/v1/test_baymodel.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/a9dc34257841e402c6e9982764135175f84b4c8a', 'message': 'Refactor image check in Baymodel\n\nA new magnum.api.attr_validator.py module is introduced to do the\nvalidation towards OpenStack resources. Currently in Baymodel-creation,\nthe image validation code is duplicated. We should reduce the\nduplicated code and unify the validation both in Bay and Baymodel.\n\nChange-Id: I8517024c77c6dc4082bf2ff6d0205d86e32fbfdc\nPartial-Bug: #1522060\n'}]",4,254784,a9dc34257841e402c6e9982764135175f84b4c8a,16,8,2,10515,,,0,"Refactor image check in Baymodel

A new magnum.api.attr_validator.py module is introduced to do the
validation towards OpenStack resources. Currently in Baymodel-creation,
the image validation code is duplicated. We should reduce the
duplicated code and unify the validation both in Bay and Baymodel.

Change-Id: I8517024c77c6dc4082bf2ff6d0205d86e32fbfdc
Partial-Bug: #1522060
",git fetch https://review.opendev.org/openstack/magnum refs/changes/84/254784/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/api/controllers/v1/baymodel.py', 'magnum/tests/unit/api/controllers/v1/test_baymodel.py']",2,8cd4fc1540b8eea696b2e856f05b9a65abbd0b0c,bug/1522060," @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') mock.patch('magnum.api.attr_validator.validate_image')\ as mock_image_data: @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') mock_image_data.side_effect = exception.OSDistroFieldNotFound('img') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image') mock_image_data): mock_image = {'name': 'mock_name', 'os_distro': 'fedora-atomic'} mock_image_data.return_value = mock_image @mock.patch('magnum.api.attr_validator.validate_image') mock_image_data): mock_image_data.side_effect = exception.ResourceNotFound('test-img') @mock.patch('magnum.api.attr_validator.validate_image') mock_image_data): mock_image_data.side_effect = exception.Conflict('Multiple images') @mock.patch('magnum.api.attr_validator.validate_image') @mock.patch('magnum.api.attr_validator.validate_image')","from magnum.common.clients import OpenStackClients as openstack_client @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') as mock_image_data: @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') mock_image_data.return_value = {'name': 'mock_name'} @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(openstack_client, 'glance') mock_glance_client): mock_images = [{'name': 'mock_name', 'os_distro': 'fedora-atomic'}] mock_glance = mock.MagicMock() mock_glance.images.list.return_value = mock_images mock_glance_client.return_value = mock_glance @mock.patch.object(openstack_client, 'glance') mock_glance_client): mock_images = [] mock_glance = mock.MagicMock() mock_glance.images.list.return_value = mock_images mock_glance_client.return_value = mock_glance @mock.patch.object(openstack_client, 'glance') mock_glance_client): mock_images = [{'name': 'mock_name', 'os_distro': 'fedora-atomic'}, {'name': 'mock_name', 'os_distro': 'fedora-atomic'}] mock_glance = mock.MagicMock() mock_glance.images.list.return_value = mock_images mock_glance_client.return_value = mock_glance @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data') @mock.patch.object(api_baymodel.BayModelsController, '_get_image_data')",31,61
openstack%2Fops-tags-team~master~I9cdd8a8314274bd6ba4d1e4384b3a6239f3ccb4f,openstack/ops-tags-team,master,I9cdd8a8314274bd6ba4d1e4384b3a6239f3ccb4f,RDO install now available for liberty,MERGED,2015-12-08 06:04:58.000000000,2015-12-11 03:09:18.000000000,2015-12-11 03:09:17.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 12651}]","[{'number': 1, 'created': '2015-12-08 06:04:58.000000000', 'files': ['liberty/ops-docs-install-guide.json'], 'web_link': 'https://opendev.org/openstack/ops-tags-team/commit/f11888cbcbe0c6fbf27fcc6b17ce748776b73372', 'message': 'RDO install now available for liberty\n\nthe RDO install guide is now available on docs.openstack.org for\nthe liberty release. This patch removes the caveat that says it\nwas not.\n\nChange-Id: I9cdd8a8314274bd6ba4d1e4384b3a6239f3ccb4f\n'}]",0,254556,f11888cbcbe0c6fbf27fcc6b17ce748776b73372,8,3,1,612,,,0,"RDO install now available for liberty

the RDO install guide is now available on docs.openstack.org for
the liberty release. This patch removes the caveat that says it
was not.

Change-Id: I9cdd8a8314274bd6ba4d1e4384b3a6239f3ccb4f
",git fetch https://review.opendev.org/openstack/ops-tags-team refs/changes/56/254556/1 && git format-patch -1 --stdout FETCH_HEAD,['liberty/ops-docs-install-guide.json'],1,f11888cbcbe0c6fbf27fcc6b17ce748776b73372,fix-docs-liberty-rdo," ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"" ""status"": ""available"""," ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }] ""status"": ""available"", ""caveats"": [{ ""status"": ""not available"", ""label"": ""Not available for RHEL, Fedora, CentOS"", ""description"": ""Due to the unavailability of RDO packages, no install guide is yet available for RHEL, Fedora or CentOS. http://lists.openstack.org/pipermail/openstack-docs/2015-October/007622.html"" }]",9,64
openstack%2Fops-tags-team~master~I2c7533a7db3fb858373626ddfcba3df04f897435,openstack/ops-tags-team,master,I2c7533a7db3fb858373626ddfcba3df04f897435,Remove ubuntu heat packaging caveat,MERGED,2015-12-08 06:11:54.000000000,2015-12-11 03:09:09.000000000,2015-12-11 03:09:09.000000000,"[{'_account_id': 3}, {'_account_id': 612}, {'_account_id': 12651}]","[{'number': 1, 'created': '2015-12-08 06:11:54.000000000', 'files': ['liberty/ops-packaged.json'], 'web_link': 'https://opendev.org/openstack/ops-tags-team/commit/d1b79b6954abccacc06616a9800ed9577caefccb', 'message': 'Remove ubuntu heat packaging caveat\n\nUbuntu fixed the bug applied to heat packages, so the caveat\nshould be removed.\n\nChange-Id: I2c7533a7db3fb858373626ddfcba3df04f897435\n'}]",0,254560,d1b79b6954abccacc06616a9800ed9577caefccb,7,3,1,612,,,0,"Remove ubuntu heat packaging caveat

Ubuntu fixed the bug applied to heat packages, so the caveat
should be removed.

Change-Id: I2c7533a7db3fb858373626ddfcba3df04f897435
",git fetch https://review.opendev.org/openstack/ops-tags-team refs/changes/60/254560/1 && git format-patch -1 --stdout FETCH_HEAD,['liberty/ops-packaged.json'],1,d1b79b6954abccacc06616a9800ed9577caefccb,fix-packaging-liberty," ""status"": ""good"""," ""status"": ""good"", ""caveats"": [{ ""status"": ""warning"", ""description"": ""Ubuntu packaging suffers from a bug: https://bugs.launchpad.net/ubuntu/+source/heat/+bug/1505444"" }]",1,6
openstack%2Fdevstack~master~Id01d97fd13fa9f866d645ec5077834ddb78b2b89,openstack/devstack,master,Id01d97fd13fa9f866d645ec5077834ddb78b2b89,Ironic: add flag for using plugin,MERGED,2015-12-10 13:47:25.000000000,2015-12-11 03:06:37.000000000,2015-12-11 03:06:36.000000000,"[{'_account_id': 3}, {'_account_id': 2750}, {'_account_id': 5196}, {'_account_id': 5805}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14510}, {'_account_id': 14525}, {'_account_id': 14760}, {'_account_id': 17207}]","[{'number': 1, 'created': '2015-12-10 13:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/a0636cda2fbc6e57c3fb3553fbdbd725d2b10f23', 'message': ""Ironic: add flag for using plugin\n\nThis adds a flag to skip ironic code if the ironic devstack plugin is in\nuse. This flag will be set to true in ironic's devstack plugin to\nindicate that the plugin should be in control, rather than devstack.\n\nThis is for the transition period only, and will be removed with the\nrest of the ironic code in the devstack tree, once the gate is\nconfigured to use the ironic plugin.\n\nChange-Id: Id01d97fd13fa9f866d645ec5077834ddb78b2b89\n""}, {'number': 2, 'created': '2015-12-10 14:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/devstack/commit/00c2418418df3f07b815898f644e316d2dd54066', 'message': ""Ironic: add flag for using plugin\n\nThis adds a flag to skip ironic code if the ironic devstack plugin is in\nuse. This flag will be set to true in ironic's devstack plugin to\nindicate that the plugin should be in control, rather than devstack.\n\nThis is for the transition period only, and will be removed with the\nrest of the ironic code in the devstack tree, once the gate is\nconfigured to use the ironic plugin.\n\nChange-Id: Id01d97fd13fa9f866d645ec5077834ddb78b2b89\n""}, {'number': 3, 'created': '2015-12-10 15:41:55.000000000', 'files': ['lib/ironic', 'extras.d/50-ironic.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/9fc3ba408a97d0dd39ce26dd8dbcdb3b110cde71', 'message': ""Ironic: add flag for using plugin\n\nThis adds a flag to skip ironic code if the ironic devstack plugin is in\nuse. This flag will be set to true in ironic's devstack plugin to\nindicate that the plugin should be in control, rather than devstack.\n\nThis is for the transition period only, and will be removed with the\nrest of the ironic code in the devstack tree, once the gate\nis configured to use the ironic plugin.\n\nChange-Id: Id01d97fd13fa9f866d645ec5077834ddb78b2b89\n""}]",0,255878,9fc3ba408a97d0dd39ce26dd8dbcdb3b110cde71,22,10,3,10343,,,0,"Ironic: add flag for using plugin

This adds a flag to skip ironic code if the ironic devstack plugin is in
use. This flag will be set to true in ironic's devstack plugin to
indicate that the plugin should be in control, rather than devstack.

This is for the transition period only, and will be removed with the
rest of the ironic code in the devstack tree, once the gate
is configured to use the ironic plugin.

Change-Id: Id01d97fd13fa9f866d645ec5077834ddb78b2b89
",git fetch https://review.opendev.org/openstack/devstack refs/changes/78/255878/2 && git format-patch -1 --stdout FETCH_HEAD,"['lib/ironic', 'extras.d/50-ironic.sh']",2,a0636cda2fbc6e57c3fb3553fbdbd725d2b10f23,ironic-devstack-plugin,"# NOTE(jroll) this is used for the transition to a devstack plugin in # the ironic tree. IRONIC_USING_PLUGIN=$(trueorfalse False IRONIC_USING_PLUGIN) if [[ ""$IRONIC_USING_PLUGIN"" == ""True"" ]] ; then exit 0 fi ",,14,0
openstack%2Fneutron~master~I78c432c35f3f3339607cd533019ae6d0fa2a5cd6,openstack/neutron,master,I78c432c35f3f3339607cd533019ae6d0fa2a5cd6,ML2: Add tests to validate quota usage tracking,MERGED,2015-09-24 13:15:13.000000000,2015-12-11 03:03:36.000000000,2015-12-11 03:03:34.000000000,"[{'_account_id': 3}, {'_account_id': 261}, {'_account_id': 748}, {'_account_id': 1653}, {'_account_id': 5170}, {'_account_id': 7787}, {'_account_id': 8124}, {'_account_id': 8873}, {'_account_id': 9681}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 9970}, {'_account_id': 10153}, {'_account_id': 10184}, {'_account_id': 14208}, {'_account_id': 14212}, {'_account_id': 14213}, {'_account_id': 14323}, {'_account_id': 14571}, {'_account_id': 15296}, {'_account_id': 15443}, {'_account_id': 15752}, {'_account_id': 17500}, {'_account_id': 18695}]","[{'number': 1, 'created': '2015-09-24 13:15:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/95cb2ef24f4ad71ab8ceec1078a1b158885e7baa', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso, validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #TBD\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 2, 'created': '2015-09-24 13:39:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/47213acc6414fbb0bb11a28576f6325147d11111', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 3, 'created': '2015-09-24 22:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/13376e1aa10e046f54d892d96ad233f369d7b9cf', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 4, 'created': '2015-09-25 08:19:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a4474d11b97b4239d9fa0d1eb8a9b88752d266aa', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 5, 'created': '2015-10-15 13:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/50ddf18a07dc16c572af47501bbcfbcd5ff5fa3b', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 6, 'created': '2015-10-15 15:30:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/69607ab6eaba0eb6c17609dbea795116e09c5b4e', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 7, 'created': '2015-11-03 17:30:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/b5dbddc15b7eb4b48fbf52e4c435f48feb0184d8', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 8, 'created': '2015-12-09 14:42:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/56fb16bb2002497906969e1bdcf3b1e59b5e3684', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThis are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}, {'number': 9, 'created': '2015-12-09 23:17:40.000000000', 'files': ['tools/check_unit_test_structure.sh', 'neutron/quota/resource.py', 'neutron/tests/unit/plugins/ml2/test_tracked_resources.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/cdd049e4c4d7e6ba1ca377e50fc6e8c29c85ab3d', 'message': ""ML2: Add tests to validate quota usage tracking\n\nEnsure that event handlers are invoked upon completion of\nML2 operations which add or remove tracked resources.\nAlso validate that the event handlers are called for the\nappropriate resources and that quota usage's dirty bit\nis set and unset as expected.\n\nThese are not unit tests, but added in the unit test tree\nas they leverage code both from the DB unit test and the ML2\nunit test framework. This module has indeed been added to\nthe 'exclusion list' in check_unit_test_structure.sh, and\nshould be moved to the functional test tree together with\nthe other modules.\n\nCloses-Bug: #1499358\n\nChange-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6\n""}]",10,227282,cdd049e4c4d7e6ba1ca377e50fc6e8c29c85ab3d,114,24,9,261,,,0,"ML2: Add tests to validate quota usage tracking

Ensure that event handlers are invoked upon completion of
ML2 operations which add or remove tracked resources.
Also validate that the event handlers are called for the
appropriate resources and that quota usage's dirty bit
is set and unset as expected.

These are not unit tests, but added in the unit test tree
as they leverage code both from the DB unit test and the ML2
unit test framework. This module has indeed been added to
the 'exclusion list' in check_unit_test_structure.sh, and
should be moved to the functional test tree together with
the other modules.

Closes-Bug: #1499358

Change-Id: I78c432c35f3f3339607cd533019ae6d0fa2a5cd6
",git fetch https://review.opendev.org/openstack/neutron refs/changes/82/227282/8 && git format-patch -1 --stdout FETCH_HEAD,"['tools/check_unit_test_structure.sh', 'neutron/tests/unit/plugins/ml2/test_tracked_resources.py']",2,95cb2ef24f4ad71ab8ceec1078a1b158885e7baa,bug/1499358,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import mock from oslo_utils import uuidutils from neutron import context from neutron.db.quota import api as quota_db_api from neutron.quota import resource from neutron.quota import resource_registry from neutron.tests.unit.extensions import test_securitygroup from neutron.tests.unit.plugins.ml2 import test_plugin original_handler = resource.TrackedResource._db_event_handler class SgTestCaseWrapper(test_securitygroup.SecurityGroupDBTestCase): # This wrapper calss enables Ml2PluginV2TestCase to correctly call the # setup method in SecurityGroupDBTestCase which does not accept the # service_plugins keyword parameter. def setUp(self, plugin, **kwargs): super(SgTestCaseWrapper, self).setUp(plugin) class TestTrackedResources(test_plugin.Ml2PluginV2TestCase, SgTestCaseWrapper): def setUp(self): self.ctx = context.get_admin_context() handler_patch = mock.patch( 'neutron.quota.resource.TrackedResource._db_event_handler') self.handler_mock = handler_patch.start() self.handler_mock.side_effect = self._db_event_handler_side_effect # Prevent noise from default security group operations def_sec_group_patch = mock.patch( 'neutron.db.securitygroups_db.SecurityGroupDbMixin.' '_ensure_default_security_group') def_sec_group_patch.start() get_sec_group_port_patch = mock.patch( 'neutron.db.securitygroups_db.SecurityGroupDbMixin.' '_get_security_groups_on_port') get_sec_group_port_patch.start() self.resource_name = None super(TestTrackedResources, self).setUp() self._tenant_id = uuidutils.generate_uuid() self.addCleanup(self._cleanup_actions) def _cleanup_actions(self): # These operations must be executed in this order otherwise event # listener removal will fail becuase it will try to remove the patched # listener instead of the actual one. This will trigger a sqlalchemy # InvalidRequestError self.handler_mock.stop() res_reg = resource_registry.ResourceRegistry.get_instance() res_reg.unregister_resources() def _db_event_handler_side_effect(self, *args, **kwargs): resource = resource_registry.get_resource(self.resource_name) return original_handler(resource, *args, **kwargs) def _verify_dirty_bit(self, expected_value=True): usage = quota_db_api.get_quota_usage_by_resource_and_tenant( self.ctx, self.resource_name, self._tenant_id) self.assertEqual(expected_value, usage.dirty) def _verify_event_handler_call(self, data, expected_call_count=1, call_index=-1): self.assertEqual(expected_call_count, self.handler_mock.call_count) model_instance = self.handler_mock.call_args_list[call_index][0][-1] self.assertEqual(model_instance['id'], data['id']) self.assertEqual(model_instance['tenant_id'], data['tenant_id']) def _test_init(self, resource_name): self.resource_name = resource_name quota_db_api.set_quota_usage( self.ctx, self.resource_name, self._tenant_id) def test_create_delete_network_marks_dirty(self): self._test_init('network') net = self._make_network('json', 'meh', True)['network'] self._verify_event_handler_call(net) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('networks', net['id']) self._verify_event_handler_call(net, expected_call_count=2) self._verify_dirty_bit() def test_list_networks_clears_dirty(self): self._test_init('network') net = self._make_network('json', 'meh', True)['network'] self.ctx.tenant_id = net['tenant_id'] self._list('networks', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) def test_create_delete_port_marks_dirty(self): self._test_init('port') net = self._make_network('json', 'meh', True)['network'] port = self._make_port('json', net['id'])['port'] # Expecting 2 calls - 1 for the network, 1 for the port self._verify_event_handler_call(port, expected_call_count=2) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('ports', port['id']) self._verify_event_handler_call(port, expected_call_count=3) self._verify_dirty_bit() def test_list_ports_clears_dirty(self): self._test_init('port') net = self._make_network('json', 'meh', True)['network'] port = self._make_port('json', net['id'])['port'] self.ctx.tenant_id = port['tenant_id'] self._list('ports', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) def test_create_delete_subnet_marks_dirty(self): self._test_init('subnet') net = self._make_network('json', 'meh', True) subnet = self._make_subnet('json', net, '10.0.0.1', '10.0.0.0/24')['subnet'] # Expecting 2 calls - 1 for the network, 1 for the subnet self._verify_event_handler_call(subnet, expected_call_count=2) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('subnets', subnet['id']) self._verify_event_handler_call(subnet, expected_call_count=3) self._verify_dirty_bit() def test_list_subnets_clears_dirty(self): self._test_init('subnet') net = self._make_network('json', 'meh', True) subnet = self._make_subnet('json', net, '10.0.0.1', '10.0.0.0/24')['subnet'] self.ctx.tenant_id = subnet['tenant_id'] self._list('subnets', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) def test_create_delete_subnetpool_marks_dirty(self): self._test_init('subnetpool') pool = self._make_subnetpool('json', ['10.0.0.0/8'], name='meh', tenant_id=self._tenant_id)['subnetpool'] self._verify_event_handler_call(pool) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('subnetpools', pool['id']) self._verify_event_handler_call(pool, expected_call_count=2) self._verify_dirty_bit() def test_list_subnetpools_clears_dirty(self): self._test_init('subnetpool') pool = self._make_subnetpool('json', ['10.0.0.0/8'], name='meh', tenant_id=self._tenant_id)['subnetpool'] self.ctx.tenant_id = pool['tenant_id'] self._list('subnetpools', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) def test_create_delete_securitygroup_marks_dirty(self): self._test_init('security_group') sec_group = self._make_security_group( 'json', 'meh', 'meh', tenant_id=self._tenant_id)['security_group'] # When a security group is created it also creates 2 rules, therefore # there will be three calls and we need to verify the first self._verify_event_handler_call(sec_group, expected_call_count=3, call_index=0) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('security-groups', sec_group['id']) # When a security group is deleted it also removes the 2 rules # generated upon creation self._verify_event_handler_call(sec_group, expected_call_count=6) self._verify_dirty_bit() def test_list_securitygroups_clears_dirty(self): self._test_init('security_group') self._make_security_group( 'json', 'meh', 'meh', tenant_id=self._tenant_id)['security_group'] self.ctx.tenant_id = self._tenant_id self._list('security-groups', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) def test_create_delete_securitygrouprule_marks_dirty(self): self._test_init('security_group_rule') sec_group = self._make_security_group( 'json', 'meh', 'meh', tenant_id=self._tenant_id)['security_group'] rule_req = self._build_security_group_rule( sec_group['id'], 'ingress', 'TCP', tenant_id=self._tenant_id) sec_group_rule = self._make_security_group_rule( 'json', rule_req)['security_group_rule'] # When a security group is created it also creates 2 rules, therefore # there will be four calls in total to the event handler self._verify_event_handler_call(sec_group_rule, expected_call_count=4) self._verify_dirty_bit() # Clear the dirty bit quota_db_api.set_quota_usage_dirty( self.ctx, self.resource_name, self._tenant_id, dirty=False) self._delete('security-group-rules', sec_group_rule['id']) self._verify_event_handler_call(sec_group_rule, expected_call_count=5) self._verify_dirty_bit() def test_list_securitygrouprules_clears_dirty(self): self._test_init('security_group_rule') self._make_security_group( 'json', 'meh', 'meh', tenant_id=self._tenant_id)['security_group'] # As the security group create operation also creates 2 security group # rules there is no need to explicitly create any rule self.ctx.tenant_id = self._tenant_id self._list('security-group-rules', neutron_context=self.ctx) self._verify_dirty_bit(expected_value=False) ",,255,0
openstack%2Fnova~master~I18457627a63bbc71219504685d1f99866a83078b,openstack/nova,master,I18457627a63bbc71219504685d1f99866a83078b,Cleanup usage of fake_InstanceMetadata,ABANDONED,2015-12-01 21:15:04.000000000,2015-12-11 03:03:05.000000000,,"[{'_account_id': 3}, {'_account_id': 5170}, {'_account_id': 9008}, {'_account_id': 9578}, {'_account_id': 10385}]","[{'number': 1, 'created': '2015-12-01 21:15:04.000000000', 'files': ['nova/tests/unit/test_metadata.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a9978ba0920c71b5b8d533eeb882c1b4e08ddaf8', 'message': 'Cleanup usage of fake_InstanceMetadata\n\nThe stubs parameter is no longer used so remove it.\n\nAlso cleans up the two cases where address=None was passed in, which\nwas pointless.\n\nChange-Id: I18457627a63bbc71219504685d1f99866a83078b\n'}]",0,252068,a9978ba0920c71b5b8d533eeb882c1b4e08ddaf8,8,5,1,6873,,,0,"Cleanup usage of fake_InstanceMetadata

The stubs parameter is no longer used so remove it.

Also cleans up the two cases where address=None was passed in, which
was pointless.

Change-Id: I18457627a63bbc71219504685d1f99866a83078b
",git fetch https://review.opendev.org/openstack/nova refs/changes/68/252068/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/unit/test_metadata.py'],1,a9978ba0920c71b5b8d533eeb882c1b4e08ddaf8,bug/1521675,"def fake_InstanceMetadata(inst_data, address=None, md = fake_InstanceMetadata(self.instance.obj_clone()) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(self.instance.obj_clone()) md = fake_InstanceMetadata(self.instance.obj_clone()) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(inst) md = fake_InstanceMetadata(self.instance, md = fake_InstanceMetadata(self.instance, network_info=nw_info) md = fake_InstanceMetadata(self.instance, md = fake_InstanceMetadata(instance) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(self.instance) mdinst = fake_InstanceMetadata(self.instance) mdinst = fake_InstanceMetadata(self.instance) mdinst = fake_InstanceMetadata(self.instance) mdinst = fake_InstanceMetadata(inst, content=content) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst, extra_md=extra) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(self.instance) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst, vd_driver=myVdriver) mdinst = fake_InstanceMetadata(inst) mdinst = fake_InstanceMetadata(inst, network_metadata=nw_data) self.mdinst = fake_InstanceMetadata(self.instance) self.mdinst = fake_InstanceMetadata(self.instance)","def fake_InstanceMetadata(stubs, inst_data, address=None, md = fake_InstanceMetadata(self.stubs, self.instance.obj_clone()) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, self.instance.obj_clone()) md = fake_InstanceMetadata(self.stubs, self.instance.obj_clone()) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, inst) md = fake_InstanceMetadata(self.stubs, self.instance, md = fake_InstanceMetadata(self.stubs, self.instance, network_info=nw_info) md = fake_InstanceMetadata(self.stubs, self.instance, md = fake_InstanceMetadata(self.stubs, instance) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, self.instance) mdinst = fake_InstanceMetadata(self.stubs, self.instance) mdinst = fake_InstanceMetadata(self.stubs, self.instance) mdinst = fake_InstanceMetadata(self.stubs, self.instance) mdinst = fake_InstanceMetadata(self.stubs, inst, content=content) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst, extra_md=extra) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, self.instance) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst, vd_driver=myVdriver) mdinst = fake_InstanceMetadata(self.stubs, inst) mdinst = fake_InstanceMetadata(self.stubs, inst, network_metadata=nw_data) self.mdinst = fake_InstanceMetadata(self.stubs, self.instance, address=None) self.mdinst = fake_InstanceMetadata(self.stubs, self.instance, address=None)",36,41
openstack%2Fopenstacksdk~master~I0c58e62674284366c6b6656b9e0d58fb29ccaaa7,openstack/openstacksdk,master,I0c58e62674284366c6b6656b9e0d58fb29ccaaa7,Replace 'value' arguments in identity proxies,MERGED,2015-12-10 21:55:06.000000000,2015-12-11 02:58:23.000000000,2015-12-11 02:58:22.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-10 21:55:06.000000000', 'files': ['openstack/identity/v3/_proxy.py', 'openstack/identity/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9e6ad7c7e19bfde13e770ed4adc05e077989e3d2', 'message': ""Replace 'value' arguments in identity proxies\n\nReplace 'value' arguments with more appropriate names.\n\nChange-Id: I0c58e62674284366c6b6656b9e0d58fb29ccaaa7\n""}]",0,256109,9e6ad7c7e19bfde13e770ed4adc05e077989e3d2,7,3,1,8257,,,0,"Replace 'value' arguments in identity proxies

Replace 'value' arguments with more appropriate names.

Change-Id: I0c58e62674284366c6b6656b9e0d58fb29ccaaa7
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/09/256109/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/identity/v3/_proxy.py', 'openstack/identity/v2/_proxy.py']",2,9e6ad7c7e19bfde13e770ed4adc05e077989e3d2,update_identity_value_names,"from openstack.identity.v2 import role as _role from openstack.identity.v2 import tenant as _tenant from openstack.identity.v2 import user as _user return self._create(_role.Role, **attrs) def delete_role(self, role, ignore_missing=True): :param role: The value can be either the ID of a role or a :class:`~openstack.identity.v2.role.Role` instance. self._delete(_role.Role, role, ignore_missing=ignore_missing) return self._find(_role.Role, name_or_id, ignore_missing=ignore_missing) def get_role(self, role): :param role: The value can be the ID of a role or a :class:`~openstack.identity.v2.role.Role` instance. return self._get(_role.Role, role) return self._list(_role.Role, paginated=True, **query) def update_role(self, role, **attrs): :param role: Either the id of a role or a :class:`~openstack.identity.v2.role.Role` instance. return self._update(_role.Role, role, **attrs) return self._create(_tenant.Tenant, **attrs) def delete_tenant(self, tenant, ignore_missing=True): :param tenant: The value can be either the ID of a tenant or a :class:`~openstack.identity.v2.tenant.Tenant` instance. self._delete(_tenant.Tenant, tenant, ignore_missing=ignore_missing) return self._find(_tenant.Tenant, name_or_id, def get_tenant(self, tenant): :param tenant: The value can be the ID of a tenant or a :class:`~openstack.identity.v2.tenant.Tenant` instance. return self._get(_tenant.Tenant, tenant) return self._list(_tenant.Tenant, paginated=True, **query) def update_tenant(self, tenant, **attrs): :param tenant: Either the id of a tenant or a return self._update(_tenant.Tenant, tenant, **attrs) return self._create(_user.User, **attrs) def delete_user(self, user, ignore_missing=True): :param user: The value can be either the ID of a user or a :class:`~openstack.identity.v2.user.User` instance. self._delete(_user.User, user, ignore_missing=ignore_missing) return self._find(_user.User, name_or_id, ignore_missing=ignore_missing) def get_user(self, user): :param user: The value can be the ID of a user or a :class:`~openstack.identity.v2.user.User` instance. return self._get(_user.User, user) return self._list(_user.User, paginated=True, **query) def update_user(self, user, **attrs): :param user: Either the id of a user or a :class:`~openstack.identity.v2.user.User` instance. return self._update(_user.User, user, **attrs)","from openstack.identity.v2 import role from openstack.identity.v2 import tenant from openstack.identity.v2 import user return self._create(role.Role, **attrs) def delete_role(self, value, ignore_missing=True): :param value: The value can be either the ID of a role or a :class:`~openstack.identity.v2.role.Role` instance. self._delete(role.Role, value, ignore_missing=ignore_missing) return self._find(role.Role, name_or_id, ignore_missing=ignore_missing) def get_role(self, value): :param value: The value can be the ID of a role or a :class:`~openstack.identity.v2.role.Role` instance. return self._get(role.Role, value) return self._list(role.Role, paginated=True, **query) def update_role(self, value, **attrs): :param value: Either the id of a role or a :class:`~openstack.identity.v2.role.Role` instance. return self._update(role.Role, value, **attrs) return self._create(tenant.Tenant, **attrs) def delete_tenant(self, value, ignore_missing=True): :param value: The value can be either the ID of a tenant or a :class:`~openstack.identity.v2.tenant.Tenant` instance. self._delete(tenant.Tenant, value, ignore_missing=ignore_missing) return self._find(tenant.Tenant, name_or_id, def get_tenant(self, value): :param value: The value can be the ID of a tenant or a :class:`~openstack.identity.v2.tenant.Tenant` instance. return self._get(tenant.Tenant, value) return self._list(tenant.Tenant, paginated=True, **query) def update_tenant(self, value, **attrs): :param value: Either the id of a tenant or a return self._update(tenant.Tenant, value, **attrs) return self._create(user.User, **attrs) def delete_user(self, value, ignore_missing=True): :param value: The value can be either the ID of a user or a :class:`~openstack.identity.v2.user.User` instance. self._delete(user.User, value, ignore_missing=ignore_missing) return self._find(user.User, name_or_id, ignore_missing=ignore_missing) def get_user(self, value): :param value: The value can be the ID of a user or a :class:`~openstack.identity.v2.user.User` instance. return self._get(user.User, value) return self._list(user.User, paginated=True, **query) def update_user(self, value, **attrs): :param value: Either the id of a user or a :class:`~openstack.identity.v2.user.User` instance. return self._update(user.User, value, **attrs)",203,201
openstack%2Fopenstacksdk~master~Ib05cbdebad19d9dcbaf96a7fb1ef024145830d1c,openstack/openstacksdk,master,Ib05cbdebad19d9dcbaf96a7fb1ef024145830d1c,Replace 'value' arguments in database proxy,MERGED,2015-12-10 21:31:03.000000000,2015-12-11 02:58:21.000000000,2015-12-11 02:58:20.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-10 21:31:03.000000000', 'files': ['openstack/database/v1/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/bc2d90d5922287db204c64e0ed5315f7e3c649c3', 'message': ""Replace 'value' arguments in database proxy\n\nReplace 'value' arguments with more appropriate names.\n\nChange-Id: Ib05cbdebad19d9dcbaf96a7fb1ef024145830d1c\n""}]",0,256103,bc2d90d5922287db204c64e0ed5315f7e3c649c3,7,3,1,8257,,,0,"Replace 'value' arguments in database proxy

Replace 'value' arguments with more appropriate names.

Change-Id: Ib05cbdebad19d9dcbaf96a7fb1ef024145830d1c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/03/256103/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/database/v1/_proxy.py'],1,bc2d90d5922287db204c64e0ed5315f7e3c649c3,update_database_value_names,"from openstack.database.v1 import database as _database from openstack.database.v1 import flavor as _flavor from openstack.database.v1 import instance as _instance from openstack.database.v1 import user as _user return self._create(_database.Database, **attrs) def delete_database(self, database, ignore_missing=True): :param database: The value can be either the ID of a database or a self._delete(_database.Database, database, ignore_missing=ignore_missing) return self._find(_database.Database, name_or_id, return self._list(_database.Database, paginated=False, **query) def get_database(self, database): :param database: The value can be the ID of a database or a :class:`~openstack.database.v1.database.Database` instance. return self._get(_database.Database, database) return self._find(_flavor.Flavor, name_or_id, def get_flavor(self, flavor): :param flavor: The value can be the ID of a flavor or a :class:`~openstack.database.v1.flavor.Flavor` instance. return self._get(_flavor.Flavor, flavor) return self._list(_flavor.Flavor, paginated=False, **query) return self._create(_instance.Instance, **attrs) def delete_instance(self, instance, ignore_missing=True): :param instance: The value can be either the ID of an instance or a self._delete(_instance.Instance, instance, ignore_missing=ignore_missing) return self._find(_instance.Instance, name_or_id, def get_instance(self, instance): :param instance: The value can be the ID of an instance or a :class:`~openstack.database.v1.instance.Instance` instance. return self._get(_instance.Instance, instance) return self._list(_instance.Instance, paginated=False, **query) def update_instance(self, instance, **attrs): :param instance: Either the id of a instance or a :class:`~openstack.database.v1.instance.Instance` instance. return self._update(_instance.Instance, instance, **attrs) return self._create(_user.User, **attrs) def delete_user(self, user, ignore_missing=True): :param user: The value can be either the ID of a user or a :class:`~openstack.database.v1.user.User` instance. self._delete(_user.User, user, ignore_missing=ignore_missing) return self._find(_user.User, name_or_id, ignore_missing=ignore_missing) return self._list(_user.User, paginated=False, **query) def get_user(self, user): :param user: The value can be the ID of a user or a :class:`~openstack.database.v1.user.User` instance. return self._get(_user.User, user)","from openstack.database.v1 import database from openstack.database.v1 import flavor from openstack.database.v1 import instance from openstack.database.v1 import user return self._create(database.Database, **attrs) def delete_database(self, value, ignore_missing=True): :param value: The value can be either the ID of a database or a self._delete(database.Database, value, ignore_missing=ignore_missing) return self._find(database.Database, name_or_id, return self._list(database.Database, paginated=False, **query) def get_database(self, value): :param value: The value can be the ID of a database or a :class:`~openstack.database.v1.database.Database` instance. return self._get(database.Database, value) return self._find(flavor.Flavor, name_or_id, def get_flavor(self, value): :param value: The value can be the ID of a flavor or a :class:`~openstack.database.v1.flavor.Flavor` instance. return self._get(flavor.Flavor, value) return self._list(flavor.Flavor, paginated=False, **query) return self._create(instance.Instance, **attrs) def delete_instance(self, value, ignore_missing=True): :param value: The value can be either the ID of an instance or a self._delete(instance.Instance, value, ignore_missing=ignore_missing) return self._find(instance.Instance, name_or_id, def get_instance(self, value): :param value: The value can be the ID of an instance or a :class:`~openstack.database.v1.instance.Instance` instance. return self._get(instance.Instance, value) return self._list(instance.Instance, paginated=False, **query) def update_instance(self, value, **attrs): :param value: Either the id of a instance or a :class:`~openstack.database.v1.instance.Instance` instance. return self._update(instance.Instance, value, **attrs) return self._create(user.User, **attrs) def delete_user(self, value, ignore_missing=True): :param value: The value can be either the ID of a user or a :class:`~openstack.database.v1.user.User` instance. self._delete(user.User, value, ignore_missing=ignore_missing) return self._find(user.User, name_or_id, ignore_missing=ignore_missing) return self._list(user.User, paginated=False, **query) def get_user(self, value): :param value: The value can be the ID of a user or a :class:`~openstack.database.v1.user.User` instance. return self._get(user.User, value)",51,48
openstack%2Fopenstack-ansible~liberty~I6028952e7260388873f57db47cc3e08126ecc530,openstack/openstack-ansible,liberty,I6028952e7260388873f57db47cc3e08126ecc530,Convert AIO bootstrap from bash to Ansible,MERGED,2015-12-09 18:16:00.000000000,2015-12-11 02:55:36.000000000,2015-12-11 02:55:35.000000000,"[{'_account_id': 3}, {'_account_id': 538}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}]","[{'number': 1, 'created': '2015-12-09 18:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/398e8d027827fe38ef3155adb5fb6f26c58b2097', 'message': 'Convert AIO bootstrap from bash to Ansible\n\nThis patch converts the AIO bootstrap process to use Ansible\ninstead of bash scripting. The patch also minimises the options\navailable to focus the role concerned to just handle an AIO\nbootstrap, but gives it just enough flexibility to allow the\nuse of an external MongoDB database for Ceilometer/Aodh and\nfor a deployer to specify a secondary disk for the AIO to\nconsume.\n\nA major change is that the AIO bootstrap process no longer\nassumes that it can destroy a secondary boot device. It\nrequires a device name to be provided. This prevents horrible\nsurprises.\n\nTODO (in subsequent patches):\n - update the developer AIO docs\n - convert run-playbooks.sh into an Ansible playbook\n\nImplements: blueprint convert-aio-bootstrap-to-ansible\nCo-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>\nChange-Id: I6028952e7260388873f57db47cc3e08126ecc530\n(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)\n'}, {'number': 2, 'created': '2015-12-10 10:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/fe1bfb94a7aac547d8dec07259470c0f426d3c22', 'message': 'Convert AIO bootstrap from bash to Ansible\n\nThis patch converts the AIO bootstrap process to use Ansible\ninstead of bash scripting. The patch also minimises the options\navailable to focus the role concerned to just handle an AIO\nbootstrap, but gives it just enough flexibility to allow the\nuse of an external MongoDB database for Ceilometer/Aodh and\nfor a deployer to specify a secondary disk for the AIO to\nconsume.\n\nA major change is that the AIO bootstrap process no longer\nassumes that it can destroy a secondary boot device. It\nrequires a device name to be provided. This prevents horrible\nsurprises.\n\nTODO (in subsequent patches):\n - update the developer AIO docs\n - convert run-playbooks.sh into an Ansible playbook\n\nImplements: blueprint convert-aio-bootstrap-to-ansible\nCo-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>\nChange-Id: I6028952e7260388873f57db47cc3e08126ecc530\n(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)\n'}, {'number': 3, 'created': '2015-12-10 12:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ab89c57a2e9bc6b89ff82e56e6779d28068b0a67', 'message': 'Convert AIO bootstrap from bash to Ansible\n\nThis patch converts the AIO bootstrap process to use Ansible\ninstead of bash scripting. The patch also minimises the options\navailable to focus the role concerned to just handle an AIO\nbootstrap, but gives it just enough flexibility to allow the\nuse of an external MongoDB database for Ceilometer/Aodh and\nfor a deployer to specify a secondary disk for the AIO to\nconsume.\n\nA major change is that the AIO bootstrap process no longer\nassumes that it can destroy a secondary boot device. It\nrequires a device name to be provided. This prevents horrible\nsurprises.\n\nTODO (in subsequent patches):\n - update the developer AIO docs\n - convert run-playbooks.sh into an Ansible playbook\n\nImplements: blueprint convert-aio-bootstrap-to-ansible\nCo-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>\nChange-Id: I6028952e7260388873f57db47cc3e08126ecc530\n(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)\n'}, {'number': 4, 'created': '2015-12-10 14:42:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4620681b9609a518db0a4aa801e84dbb6ee73a96', 'message': 'Convert AIO bootstrap from bash to Ansible\n\nThis patch converts the AIO bootstrap process to use Ansible\ninstead of bash scripting. The patch also minimises the options\navailable to focus the role concerned to just handle an AIO\nbootstrap, but gives it just enough flexibility to allow the\nuse of an external MongoDB database for Ceilometer/Aodh and\nfor a deployer to specify a secondary disk for the AIO to\nconsume.\n\nA major change is that the AIO bootstrap process no longer\nassumes that it can destroy a secondary boot device. It\nrequires a device name to be provided. This prevents horrible\nsurprises.\n\nTODO (in subsequent patches):\n - update the developer AIO docs\n - convert run-playbooks.sh into an Ansible playbook\n\nImplements: blueprint convert-aio-bootstrap-to-ansible\nCo-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>\nChange-Id: I6028952e7260388873f57db47cc3e08126ecc530\n(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)\n'}, {'number': 5, 'created': '2015-12-10 21:19:29.000000000', 'files': ['tests/roles/bootstrap-host/tasks/install-apt.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_nova.yml', 'scripts/gate-check-commit.sh', 'tests/roles/bootstrap-host/tasks/main.yml', 'tests/bootstrap-aio.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_cinder.yml', 'tests/roles/bootstrap-host/tasks/prepare_mongodb_users.yml', 'tests/roles/bootstrap-host/tasks/prepare_ssh_keys.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swap.yml', 'scripts/run-playbooks.sh', 'tests/roles/bootstrap-host/vars/ubuntu.yml', 'tests/roles/bootstrap-host/tasks/prepare_aio_config.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swift.yml', 'tests/roles/bootstrap-host/tasks/prepare_networking.yml', 'etc/openstack_deploy/openstack_user_config.yml.aio', 'tests/roles/bootstrap-host/defaults/main.yml', 'ansible-role-requirements.yml', 'tests/ansible.cfg', 'scripts/bootstrap-aio.sh', 'tests/roles/bootstrap-host/tasks/check-requirements.yml', 'tests/roles/bootstrap-host/tasks/prepare_data_disk.yml', 'scripts/scripts-library.sh', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2', 'tests/roles/bootstrap-host/templates/osa_interfaces.cfg.j2', 'tests/roles/bootstrap-host/tasks/prepare_mongodb_service.yml', 'tests/roles/bootstrap-host/templates/apt-sources.list.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/097e2d895c54e69727a74474b27c6ae9175ca7ec', 'message': 'Convert AIO bootstrap from bash to Ansible\n\nThis patch converts the AIO bootstrap process to use Ansible\ninstead of bash scripting. The patch also minimises the options\navailable to focus the role concerned to just handle an AIO\nbootstrap, but gives it just enough flexibility to allow the\nuse of an external MongoDB database for Ceilometer/Aodh and\nfor a deployer to specify a secondary disk for the AIO to\nconsume.\n\nA major change is that the AIO bootstrap process no longer\nassumes that it can destroy a secondary boot device. It\nrequires a device name to be provided. This prevents horrible\nsurprises.\n\nTODO (in subsequent patches):\n - update the developer AIO docs\n - convert run-playbooks.sh into an Ansible playbook\n\nImplements: blueprint convert-aio-bootstrap-to-ansible\nCo-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>\nChange-Id: I6028952e7260388873f57db47cc3e08126ecc530\n(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)\n'}]",0,255412,097e2d895c54e69727a74474b27c6ae9175ca7ec,22,5,5,6816,,,0,"Convert AIO bootstrap from bash to Ansible

This patch converts the AIO bootstrap process to use Ansible
instead of bash scripting. The patch also minimises the options
available to focus the role concerned to just handle an AIO
bootstrap, but gives it just enough flexibility to allow the
use of an external MongoDB database for Ceilometer/Aodh and
for a deployer to specify a secondary disk for the AIO to
consume.

A major change is that the AIO bootstrap process no longer
assumes that it can destroy a secondary boot device. It
requires a device name to be provided. This prevents horrible
surprises.

TODO (in subsequent patches):
 - update the developer AIO docs
 - convert run-playbooks.sh into an Ansible playbook

Implements: blueprint convert-aio-bootstrap-to-ansible
Co-Authored-By: Jesse Pretorius <jesse.pretorius@rackspace.co.uk>
Change-Id: I6028952e7260388873f57db47cc3e08126ecc530
(cherry picked from commit 892c7fe46c68bc36e76f21a6b699349167534f46)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/12/255412/5 && git format-patch -1 --stdout FETCH_HEAD,"['tests/roles/bootstrap-host/tasks/install-apt.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_nova.yml', 'scripts/gate-check-commit.sh', 'tests/roles/bootstrap-host/tasks/main.yml', 'tests/bootstrap-aio.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_cinder.yml', 'tests/roles/bootstrap-host/tasks/prepare_mongodb_users.yml', 'tests/roles/bootstrap-host/tasks/prepare_ssh_keys.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swap.yml', 'scripts/run-playbooks.sh', 'tests/roles/bootstrap-host/vars/ubuntu.yml', 'tests/roles/bootstrap-host/tasks/prepare_aio_config.yml', 'tests/roles/bootstrap-host/tasks/prepare_loopback_swift.yml', 'tests/roles/bootstrap-host/tasks/prepare_networking.yml', 'etc/openstack_deploy/openstack_user_config.yml.aio', 'tests/roles/bootstrap-host/defaults/main.yml', 'ansible-role-requirements.yml', 'tests/ansible.cfg', 'scripts/bootstrap-aio.sh', 'tests/roles/bootstrap-host/tasks/check-requirements.yml', 'tests/roles/bootstrap-host/tasks/prepare_data_disk.yml', 'scripts/scripts-library.sh', 'tests/roles/bootstrap-host/templates/user_variables.aio.yml.j2', 'tests/roles/bootstrap-host/templates/osa_interfaces.cfg.j2', 'tests/roles/bootstrap-host/tasks/prepare_mongodb_service.yml', 'tests/roles/bootstrap-host/templates/apt-sources.list.j2']",26,398e8d027827fe38ef3155adb5fb6f26c58b2097,bp/convert-aio-bootstrap-to-ansible,# {{ ansible_managed }} # Base repositories deb {{ bootstrap_host_ubuntu_repo }} {{ ansible_distribution_release }} main restricted universe multiverse # Updates repositories deb {{ bootstrap_host_ubuntu_repo }} {{ ansible_distribution_release }}-updates main restricted universe multiverse # Backports repositories deb {{ bootstrap_host_ubuntu_repo }} {{ ansible_distribution_release }}-backports main restricted universe multiverse # Security repositories deb {{ bootstrap_host_ubuntu_security_repo }} {{ ansible_distribution_release }}-security main restricted universe multiverse ,,1377,634
openstack%2Fpython-openstackclient~master~I2602426b966045b15b96e5e41d0df6524ed05119,openstack/python-openstackclient,master,I2602426b966045b15b96e5e41d0df6524ed05119,The format_exc method does not take an exception,MERGED,2015-12-08 16:22:41.000000000,2015-12-11 02:34:39.000000000,2015-12-11 02:34:37.000000000,"[{'_account_id': 3}, {'_account_id': 6482}, {'_account_id': 8410}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-08 16:22:41.000000000', 'files': ['openstackclient/shell.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/23486176063fb97c811af92c8af63ef833508d40', 'message': ""The format_exc method does not take an exception\n\nFor py35, this call blows up.  Seems to be ignored for py27, but\neven in py27, it doesn't take an exception.\n\nhttps://docs.python.org/2.7/library/traceback.html\nhttps://docs.python.org/3/library/traceback.html\n\nChange-Id: I2602426b966045b15b96e5e41d0df6524ed05119\n""}]",0,254849,23486176063fb97c811af92c8af63ef833508d40,12,4,1,8736,,,0,"The format_exc method does not take an exception

For py35, this call blows up.  Seems to be ignored for py27, but
even in py27, it doesn't take an exception.

https://docs.python.org/2.7/library/traceback.html
https://docs.python.org/3/library/traceback.html

Change-Id: I2602426b966045b15b96e5e41d0df6524ed05119
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/49/254849/1 && git format-patch -1 --stdout FETCH_HEAD,['openstackclient/shell.py'],1,23486176063fb97c811af92c8af63ef833508d40,netlist, self.log.error(traceback.format_exc()), self.log.error(traceback.format_exc(e)),1,1
openstack%2Fopenstacksdk~master~Ie59ffba71a0e284fe1a24698a5c83d9566eb45a4,openstack/openstacksdk,master,Ie59ffba71a0e284fe1a24698a5c83d9566eb45a4,Replace 'value' arguments in compute proxy,MERGED,2015-12-10 21:18:19.000000000,2015-12-11 02:30:19.000000000,2015-12-11 02:30:17.000000000,"[{'_account_id': 3}, {'_account_id': 8246}, {'_account_id': 8736}]","[{'number': 1, 'created': '2015-12-10 21:18:19.000000000', 'files': ['openstack/compute/v2/_proxy.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/145ac3d7935d6b40bc58e591846fbdb2885c1835', 'message': ""Replace 'value' arguments in compute proxy\n\nReplace 'value' arguments with more appropriate names.\n\nChange-Id: Ie59ffba71a0e284fe1a24698a5c83d9566eb45a4\n""}]",0,256097,145ac3d7935d6b40bc58e591846fbdb2885c1835,7,3,1,8257,,,0,"Replace 'value' arguments in compute proxy

Replace 'value' arguments with more appropriate names.

Change-Id: Ie59ffba71a0e284fe1a24698a5c83d9566eb45a4
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/97/256097/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/compute/v2/_proxy.py'],1,145ac3d7935d6b40bc58e591846fbdb2885c1835,update_compute_value_names,"from openstack.compute.v2 import flavor as _flavorfrom openstack.compute.v2 import keypair as _keypairfrom openstack.compute.v2 import server_interface as _server_interface return self._find(_flavor.Flavor, name_or_id, return self._create(_flavor.Flavor, **attrs) def delete_flavor(self, flavor, ignore_missing=True): :param flavor: The value can be either the ID of a flavor or a :class:`~openstack.compute.v2.flavor.Flavor` instance. self._delete(_flavor.Flavor, flavor, ignore_missing=ignore_missing) def get_flavor(self, flavor): :param flavor: The value can be the ID of a flavor or a :class:`~openstack.compute.v2.flavor.Flavor` instance. return self._get(_flavor.Flavor, flavor) flv = _flavor.FlavorDetail if details else _flavor.Flavor def update_flavor(self, flavor, **attrs): :param flavor: Either the id of a flavor or a return self._update(_flavor.Flavor, flavor, **attrs) def delete_image(self, image, ignore_missing=True): :param image: The value can be either the ID of an image or a self._delete(_image.Image, image, ignore_missing=ignore_missing) def get_image(self, image): :param image: The value can be the ID of an image or a return self._get(_image.Image, image) return self._create(_keypair.Keypair, **attrs) def delete_keypair(self, keypair, ignore_missing=True): :param keypair: The value can be either the ID of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. self._delete(_keypair.Keypair, keypair, ignore_missing=ignore_missing) def get_keypair(self, keypair): :param keypair: The value can be the ID of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. return self._get(_keypair.Keypair, keypair) return self._find(_keypair.Keypair, name_or_id, return self._list(_keypair.Keypair, paginated=False, **query) def update_keypair(self, keypair, **attrs): :param keypair: Either the id of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. by ``keypair``. return self._update(_keypair.Keypair, keypair, **attrs) def delete_server(self, server, ignore_missing=True): :param server: The value can be either the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. self._delete(_server.Server, server, ignore_missing=ignore_missing) def get_server(self, server): :param server: The value can be the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. return self._get(_server.Server, server) def update_server(self, server, **attrs): :param server: Either the id of a server or a :class:`~openstack.compute.v2.server.Server` instance. by ``server``. return self._update(_server.Server, server, **attrs) def wait_for_server(self, server, status='ACTIVE', failures=['ERROR'], interval=2, wait=120): return resource.wait_for_status(self.session, server, status, return self._create(_server_interface.ServerInterface, def delete_server_interface(self, server_interface, server=None, ignore_missing=True): :param server_interface: The value can be either the ID of a server interface or a :class:`~openstack.compute.v2.server_interface.ServerInterface` instance. if isinstance(server_interface, _server_interface.ServerInterface): server_id = server_interface.server_id self._delete(_server_interface.ServerInterface, server_interface, def get_server_interface(self, server_interface, server=None): :param server_interface: The value can be the ID of a server interface or a :class:`~openstack.compute.v2.server_interface.ServerInterface` instance. if isinstance(server_interface, _server_interface.ServerInterface): server_id = server_interface.server_id return self._get(_server_interface.ServerInterface, server_interface, return self._list(_server_interface.ServerInterface, paginated=False, def resize_server(self, server, flavor): :param server: Either the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. server = _server.Server.from_id(server) def confirm_resize_server(self, server): :param server: Either the ID of a server or a server = _server.Server.from_id(server) def revert_resize_server(self, server): :param server: Either the ID of a server or a server = _server.Server.from_id(server) def rebuild_server(self, server, image, name=None, admin_password=None, :param server: Either the ID of a server or a server = _server.Server.from_id(server)","from openstack.compute.v2 import flavorfrom openstack.compute.v2 import keypairfrom openstack.compute.v2 import server_interface return self._find(flavor.Flavor, name_or_id, return self._create(flavor.Flavor, **attrs) def delete_flavor(self, value, ignore_missing=True): :param value: The value can be either the ID of a flavor or a :class:`~openstack.compute.v2.flavor.Flavor` instance. self._delete(flavor.Flavor, value, ignore_missing=ignore_missing) def get_flavor(self, value): :param value: The value can be the ID of a flavor or a :class:`~openstack.compute.v2.flavor.Flavor` instance. return self._get(flavor.Flavor, value) flv = flavor.FlavorDetail if details else flavor.Flavor def update_flavor(self, value, **attrs): :param value: Either the id of a flavor or a return self._update(flavor.Flavor, value, **attrs) def delete_image(self, value, ignore_missing=True): :param value: The value can be either the ID of an image or a self._delete(_image.Image, value, ignore_missing=ignore_missing) def get_image(self, value): :param value: The value can be the ID of an image or a return self._get(_image.Image, value) return self._create(keypair.Keypair, **attrs) def delete_keypair(self, value, ignore_missing=True): :param value: The value can be either the ID of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. self._delete(keypair.Keypair, value, ignore_missing=ignore_missing) def get_keypair(self, value): :param value: The value can be the ID of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. return self._get(keypair.Keypair, value) return self._find(keypair.Keypair, name_or_id, return self._list(keypair.Keypair, paginated=False, **query) def update_keypair(self, value, **attrs): :param value: Either the id of a keypair or a :class:`~openstack.compute.v2.keypair.Keypair` instance. by ``value``. return self._update(keypair.Keypair, value, **attrs) def delete_server(self, value, ignore_missing=True): :param value: The value can be either the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. self._delete(_server.Server, value, ignore_missing=ignore_missing) def get_server(self, value): :param value: The value can be the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. return self._get(_server.Server, value) def update_server(self, value, **attrs): :param value: Either the id of a server or a :class:`~openstack.compute.v2.server.Server` instance. by ``value``. return self._update(_server.Server, value, **attrs) def wait_for_server(self, value, status='ACTIVE', failures=['ERROR'], interval=2, wait=120): return resource.wait_for_status(self.session, value, status, return self._create(server_interface.ServerInterface, def delete_server_interface(self, value, server=None, ignore_missing=True): :param value: The value can be either the ID of a server interface or a :class:`~openstack.compute.v2.server_interface.ServerInterface` instance. if isinstance(value, server_interface.ServerInterface): server_id = value.server_id self._delete(server_interface.ServerInterface, value, def get_server_interface(self, value, server=None): :param value: The value can be the ID of a server interface or a :class:`~openstack.compute.v2.server_interface.ServerInterface` instance. if isinstance(value, server_interface.ServerInterface): server_id = value.server_id return self._get(server_interface.ServerInterface, value, return self._list(server_interface.ServerInterface, paginated=False, def resize_server(self, value, flavor): :param value: Either the ID of a server or a :class:`~openstack.compute.v2.server.Server` instance. server = _server.Server.from_id(value) def confirm_resize_server(self, value): :param value: Either the ID of a server or a server = _server.Server.from_id(value) def revert_resize_server(self, value): :param value: Either the ID of a server or a server = _server.Server.from_id(value) def rebuild_server(self, value, image, name=None, admin_password=None, :param value: Either the ID of a server or a server = _server.Server.from_id(value)",89,83
openstack%2Fnetworking-ovn~master~I252d70527d9a24307a1363429a7e45a49718f896,openstack/networking-ovn,master,I252d70527d9a24307a1363429a7e45a49718f896,"DON""T BOTHER LOOKING AT",ABANDONED,2015-11-06 21:11:55.000000000,2015-12-11 02:23:20.000000000,,"[{'_account_id': 3}, {'_account_id': 1561}]","[{'number': 1, 'created': '2015-11-06 21:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/8a9c13aab328bab5b18409b95320ff165fa64458', 'message': 'DON""T BOTHER LOOKING AT\n\nChange-Id: I252d70527d9a24307a1363429a7e45a49718f896\n'}, {'number': 2, 'created': '2015-11-06 21:14:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5ac8bd35aff53717d64b3a6ab4c99be92d9d9f5e', 'message': 'DON""T BOTHER LOOKING AT\n\nChange-Id: I252d70527d9a24307a1363429a7e45a49718f896\n'}, {'number': 3, 'created': '2015-11-06 21:26:41.000000000', 'files': ['networking_ovn/plugin.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/db2524546eb00363c6598d44fa90b452c9c1575e', 'message': 'DON""T BOTHER LOOKING AT\n\nChange-Id: I252d70527d9a24307a1363429a7e45a49718f896\n'}]",0,242632,db2524546eb00363c6598d44fa90b452c9c1575e,6,2,3,4395,,,0,"DON""T BOTHER LOOKING AT

Change-Id: I252d70527d9a24307a1363429a7e45a49718f896
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/32/242632/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/plugin.py'],1,8a9c13aab328bab5b18409b95320ff165fa64458,," print ""BEFORE"" print updated_port print ""AFTER"" print updated_port",,4,0
