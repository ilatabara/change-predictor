id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Fopenstack-ansible-os_cloudkitty~master~I23a9dcd017b32551bee2f3f63efce7d916defe3b,openstack/openstack-ansible-os_cloudkitty,master,I23a9dcd017b32551bee2f3f63efce7d916defe3b,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:14.000000000,2018-09-28 13:13:47.000000000,2018-09-28 13:13:46.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:14.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cloudkitty/commit/172faa5a79ed6003098d3c070dc0f669ca9e413d', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I23a9dcd017b32551bee2f3f63efce7d916defe3b\n'}]",0,605939,172faa5a79ed6003098d3c070dc0f669ca9e413d,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I23a9dcd017b32551bee2f3f63efce7d916defe3b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cloudkitty refs/changes/39/605939/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,172faa5a79ed6003098d3c070dc0f669ca9e413d,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fproject-config~master~Idf0d8a784f11aa4004a909ca911782f7c7496763,openstack/project-config,master,Idf0d8a784f11aa4004a909ca911782f7c7496763,Temporarily bump up capacity by 50 VMs,MERGED,2018-09-28 12:44:48.000000000,2018-09-28 13:06:55.000000000,2018-09-28 13:06:55.000000000,"[{'_account_id': 6547}, {'_account_id': 9061}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 12:44:48.000000000', 'files': ['nodepool/nl03.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c8cdfa8b12cbcadda0766d0e202644360a252dfa', 'message': ""Temporarily bump up capacity by 50 VMs\n\nTimes are hard.  Gates are long.  Let's help flush them out.\n\nPlease revert this once we've cleared the gate.\n\nChange-Id: Idf0d8a784f11aa4004a909ca911782f7c7496763\n""}]",0,606058,c8cdfa8b12cbcadda0766d0e202644360a252dfa,7,3,1,1004,,,0,"Temporarily bump up capacity by 50 VMs

Times are hard.  Gates are long.  Let's help flush them out.

Please revert this once we've cleared the gate.

Change-Id: Idf0d8a784f11aa4004a909ca911782f7c7496763
",git fetch https://review.opendev.org/openstack/project-config refs/changes/58/606058/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nl03.openstack.org.yaml'],1,c8cdfa8b12cbcadda0766d0e202644360a252dfa,POWAAAA, max-servers: 75 max-servers: 75, max-servers: 50 max-servers: 50,2,2
openstack%2Fopenstack-ansible-os_blazar~master~I1ade0f2eff296578d8cf0e64edad8c4718f6d74b,openstack/openstack-ansible-os_blazar,master,I1ade0f2eff296578d8cf0e64edad8c4718f6d74b,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:52.000000000,2018-09-28 13:05:11.000000000,2018-09-28 13:05:11.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:52.000000000', 'files': ['tasks/mq_setup.yml', 'Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_blazar/commit/97c189387011797625fb0c732b8d0833bace2e62', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1ade0f2eff296578d8cf0e64edad8c4718f6d74b\n'}]",0,605936,97c189387011797625fb0c732b8d0833bace2e62,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1ade0f2eff296578d8cf0e64edad8c4718f6d74b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_blazar refs/changes/36/605936/1 && git format-patch -1 --stdout FETCH_HEAD,"['Vagrantfile', 'tasks/mq_setup.yml']",2,97c189387011797625fb0c732b8d0833bace2e62,openstack/openstack-ansible-tests/sync-tests, # WARNING:# https://git.openstack.org/cgit/openstack/openstack-ansible-tests/tree/sync/tasks/mq_setup.yml no_log: true , # WARNING:# https://git.openstack.org/cgit/openstack/openstack-ansible-tests/tree/sync/mq_setup.yml no_log: true,9,3
openstack%2Fnova~master~I02241936cf2fd3c4dc6a35b2592169bfc30affb0,openstack/nova,master,I02241936cf2fd3c4dc6a35b2592169bfc30affb0,Consider nested allocations during allocation cleanup,ABANDONED,2018-09-28 12:27:20.000000000,2018-09-28 12:58:55.000000000,,[{'_account_id': 15751}],"[{'number': 1, 'created': '2018-09-28 12:27:20.000000000', 'files': ['nova/scheduler/utils.py', 'nova/scheduler/client/report.py', 'nova/conductor/tasks/live_migrate.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'nova/compute/resource_tracker.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6042a3621205a8c3de7bed5029e9f05a6861d8a6', 'message': 'Consider nested allocations during allocation cleanup\n\nNova calls remove_provider_from_instance_allocation() in couple of\ncleanup cases. As the name of the function suggests this does not handle\nallocations against nested compute RP trees. This leads to leaking\nallocations on the child providers during cleanup. As the functional\ntests previously shown mostly evacuation is directly affect by this call\npath most probably becase evacuation still uses the instance_uuid as the\nconsumer for both the source host and the destination host allocation.\n\nThis patch replaces remove_provider_from_instance_allocation() with\nremove_provider_tree_from_instance_allocation() and as the name suggests\nthis call removes allocation agains the RP tree. After this change most\nof the evacuation functional tests passes without resource leak, except\nforce evacuation. That will be handled in a subsequent patch.\n\nAlso as this change made the scheduler/utils\nremove_allocation_from_compute just a proxy call of\nremove_provider_from_instance_allocation and therefore\nremove_allocation_from_compute is deleted.\n\nTODO:\n* make the unit test pass\n\nChange-Id: I2af45a9540e7ccd60ace80d9fcadc79972da7df7\nBlueprint: use-nested-allocation-candidates\n\nrefactor: inline remove_allocation_from_compute\n\nThe scheduler/utils remove_allocation_from_compute() call become just a\nsimple proxy call so it is inlined.\n\nChange-Id: I02241936cf2fd3c4dc6a35b2592169bfc30affb0\nBlueprint: use-nested-allocation-candidates\n'}]",0,606055,6042a3621205a8c3de7bed5029e9f05a6861d8a6,3,1,1,9708,,,0,"Consider nested allocations during allocation cleanup

Nova calls remove_provider_from_instance_allocation() in couple of
cleanup cases. As the name of the function suggests this does not handle
allocations against nested compute RP trees. This leads to leaking
allocations on the child providers during cleanup. As the functional
tests previously shown mostly evacuation is directly affect by this call
path most probably becase evacuation still uses the instance_uuid as the
consumer for both the source host and the destination host allocation.

This patch replaces remove_provider_from_instance_allocation() with
remove_provider_tree_from_instance_allocation() and as the name suggests
this call removes allocation agains the RP tree. After this change most
of the evacuation functional tests passes without resource leak, except
force evacuation. That will be handled in a subsequent patch.

Also as this change made the scheduler/utils
remove_allocation_from_compute just a proxy call of
remove_provider_from_instance_allocation and therefore
remove_allocation_from_compute is deleted.

TODO:
* make the unit test pass

Change-Id: I2af45a9540e7ccd60ace80d9fcadc79972da7df7
Blueprint: use-nested-allocation-candidates

refactor: inline remove_allocation_from_compute

The scheduler/utils remove_allocation_from_compute() call become just a
simple proxy call so it is inlined.

Change-Id: I02241936cf2fd3c4dc6a35b2592169bfc30affb0
Blueprint: use-nested-allocation-candidates
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/606055/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/scheduler/utils.py', 'nova/scheduler/client/report.py', 'nova/conductor/tasks/live_migrate.py', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'nova/compute/resource_tracker.py']",6,6042a3621205a8c3de7bed5029e9f05a6861d8a6,bp/use-nested-allocation-candidates," if not self.reportclient.remove_provider_tree_from_instance_allocation( context, instance.uuid, cn_uuid): if not self.reportclient.remove_provider_tree_from_instance_allocation( context, instance.uuid, cn.uuid):","from nova.scheduler import utils as scheduler_utils if not scheduler_utils.remove_allocation_from_compute( context, instance, cn_uuid, self.reportclient): if not scheduler_utils.remove_allocation_from_compute( context, instance, cn.uuid, self.reportclient, flavor):",36,148
openstack%2Fopenstack-ansible-lxc_hosts~master~I5be04a9a37de2c855d2b1440d774bb4967074cab,openstack/openstack-ansible-lxc_hosts,master,I5be04a9a37de2c855d2b1440d774bb4967074cab,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:43.000000000,2018-09-28 12:57:39.000000000,2018-09-28 12:57:39.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:43.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e04749a9daee0513dc163986a0ec74c44df7276a', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I5be04a9a37de2c855d2b1440d774bb4967074cab\n'}]",0,605927,e04749a9daee0513dc163986a0ec74c44df7276a,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I5be04a9a37de2c855d2b1440d774bb4967074cab
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/27/605927/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,e04749a9daee0513dc163986a0ec74c44df7276a,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_keystone~master~I1172dc99f3dfe2f795fc4cf31b96f1f95a58fb63,openstack/openstack-ansible-os_keystone,master,I1172dc99f3dfe2f795fc4cf31b96f1f95a58fb63,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:17.000000000,2018-09-28 12:57:28.000000000,2018-09-28 12:57:28.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:17.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_keystone/commit/9fcbcf34778b834f8c7ba179abda3852ab715c6f', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1172dc99f3dfe2f795fc4cf31b96f1f95a58fb63\n'}]",0,605947,9fcbcf34778b834f8c7ba179abda3852ab715c6f,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1172dc99f3dfe2f795fc4cf31b96f1f95a58fb63
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_keystone refs/changes/47/605947/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,9fcbcf34778b834f8c7ba179abda3852ab715c6f,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_nova~master~I1a998397b452d918a1b48014d6dfef025c9f1e43,openstack/openstack-ansible-os_nova,master,I1a998397b452d918a1b48014d6dfef025c9f1e43,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:07.000000000,2018-09-28 12:57:27.000000000,2018-09-28 12:57:27.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:07.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/b4dcc77cd7811f3f009a8c2e8d0776be14d27757', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1a998397b452d918a1b48014d6dfef025c9f1e43\n'}]",0,605952,b4dcc77cd7811f3f009a8c2e8d0776be14d27757,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1a998397b452d918a1b48014d6dfef025c9f1e43
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/52/605952/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,b4dcc77cd7811f3f009a8c2e8d0776be14d27757,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-lxc_container_create~master~Ib39f05b2381109e778b1d56dc4c52b15cafcef13,openstack/openstack-ansible-lxc_container_create,master,Ib39f05b2381109e778b1d56dc4c52b15cafcef13,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:35.000000000,2018-09-28 12:57:10.000000000,2018-09-28 12:57:10.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:35.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/3930c20a0f1c6d0f5513b602e95370f238c72fa6', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ib39f05b2381109e778b1d56dc4c52b15cafcef13\n'}]",0,605926,3930c20a0f1c6d0f5513b602e95370f238c72fa6,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ib39f05b2381109e778b1d56dc4c52b15cafcef13
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/26/605926/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,3930c20a0f1c6d0f5513b602e95370f238c72fa6,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-apt_package_pinning~master~I3f0412fadb39573f5a7e6a3fd48eb1c596cd801c,openstack/openstack-ansible-apt_package_pinning,master,I3f0412fadb39573f5a7e6a3fd48eb1c596cd801c,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:16:59.000000000,2018-09-28 12:57:07.000000000,2018-09-28 12:57:07.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:16:59.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-apt_package_pinning/commit/398ae826d538a6ddeb12daf1f69696e7e35b15e9', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I3f0412fadb39573f5a7e6a3fd48eb1c596cd801c\n'}]",0,605921,398ae826d538a6ddeb12daf1f69696e7e35b15e9,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I3f0412fadb39573f5a7e6a3fd48eb1c596cd801c
",git fetch https://review.opendev.org/openstack/openstack-ansible-apt_package_pinning refs/changes/21/605921/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,398ae826d538a6ddeb12daf1f69696e7e35b15e9,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-haproxy_server~master~I1ffcec44e42d94dd9dea7332cc0f7105753a0083,openstack/openstack-ansible-haproxy_server,master,I1ffcec44e42d94dd9dea7332cc0f7105753a0083,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:28.000000000,2018-09-28 12:57:06.000000000,2018-09-28 12:57:06.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:28.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-haproxy_server/commit/c92a608222dd4ef2d22c9206489d0aece83354b3', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1ffcec44e42d94dd9dea7332cc0f7105753a0083\n'}]",0,605925,c92a608222dd4ef2d22c9206489d0aece83354b3,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1ffcec44e42d94dd9dea7332cc0f7105753a0083
",git fetch https://review.opendev.org/openstack/openstack-ansible-haproxy_server refs/changes/25/605925/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,c92a608222dd4ef2d22c9206489d0aece83354b3,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-nspawn_hosts~master~I466b6e0a245024f94e00946d6c1ab02721057df8,openstack/openstack-ansible-nspawn_hosts,master,I466b6e0a245024f94e00946d6c1ab02721057df8,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:03.000000000,2018-09-28 12:56:46.000000000,2018-09-28 12:56:45.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:03.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-nspawn_hosts/commit/4180594e1ec8dac2ed356aa26fe2af0ab7040a7c', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I466b6e0a245024f94e00946d6c1ab02721057df8\n'}]",0,605930,4180594e1ec8dac2ed356aa26fe2af0ab7040a7c,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I466b6e0a245024f94e00946d6c1ab02721057df8
",git fetch https://review.opendev.org/openstack/openstack-ansible-nspawn_hosts refs/changes/30/605930/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,4180594e1ec8dac2ed356aa26fe2af0ab7040a7c,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-galera_client~master~I8c65382185c14c20e97cdc5de14a4c7241a03591,openstack/openstack-ansible-galera_client,master,I8c65382185c14c20e97cdc5de14a4c7241a03591,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:13.000000000,2018-09-28 12:56:46.000000000,2018-09-28 12:56:46.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:13.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/142736d0fc00ca4e920370a0903628fabdda920c', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I8c65382185c14c20e97cdc5de14a4c7241a03591\n'}]",0,605923,142736d0fc00ca4e920370a0903628fabdda920c,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I8c65382185c14c20e97cdc5de14a4c7241a03591
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/23/605923/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,142736d0fc00ca4e920370a0903628fabdda920c,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-memcached_server~master~I7cca53b1a1f5b8e62fa21dc6bf91ffdb673283d5,openstack/openstack-ansible-memcached_server,master,I7cca53b1a1f5b8e62fa21dc6bf91ffdb673283d5,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:50.000000000,2018-09-28 12:56:42.000000000,2018-09-28 12:56:42.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:50.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/e7642a643fe664f7525252c131122254297130cc', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7cca53b1a1f5b8e62fa21dc6bf91ffdb673283d5\n'}]",0,605928,e7642a643fe664f7525252c131122254297130cc,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I7cca53b1a1f5b8e62fa21dc6bf91ffdb673283d5
",git fetch https://review.opendev.org/openstack/openstack-ansible-memcached_server refs/changes/28/605928/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,e7642a643fe664f7525252c131122254297130cc,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-ceph_client~master~I37bece7caeb1f409fdb44623b78e2fccdbf7acac,openstack/openstack-ansible-ceph_client,master,I37bece7caeb1f409fdb44623b78e2fccdbf7acac,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:17:06.000000000,2018-09-28 12:55:52.000000000,2018-09-28 12:55:51.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:17:06.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/35aaac527499fd8388034b0f3d1b03c07caf8aec', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I37bece7caeb1f409fdb44623b78e2fccdbf7acac\n'}]",0,605922,35aaac527499fd8388034b0f3d1b03c07caf8aec,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I37bece7caeb1f409fdb44623b78e2fccdbf7acac
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/22/605922/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,35aaac527499fd8388034b0f3d1b03c07caf8aec,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_masakari~master~I06503533b8d11735946c8d7dc2c6ad9262fad1d4,openstack/openstack-ansible-os_masakari,master,I06503533b8d11735946c8d7dc2c6ad9262fad1d4,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:31.000000000,2018-09-28 12:54:49.000000000,2018-09-28 12:54:49.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:31.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/9575ecc77af0ee13365c1cd2ea09ccbc34430915', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I06503533b8d11735946c8d7dc2c6ad9262fad1d4\n'}]",0,605949,9575ecc77af0ee13365c1cd2ea09ccbc34430915,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I06503533b8d11735946c8d7dc2c6ad9262fad1d4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/49/605949/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,9575ecc77af0ee13365c1cd2ea09ccbc34430915,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_almanach~master~I816038dd3eaca6ca0b2ccb9518747051540ff36d,openstack/openstack-ansible-os_almanach,master,I816038dd3eaca6ca0b2ccb9518747051540ff36d,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:30.000000000,2018-09-28 12:54:08.000000000,2018-09-28 12:54:08.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:30.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_almanach/commit/2de30886b79c1dccbcc3ec0816d73516fc988019', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I816038dd3eaca6ca0b2ccb9518747051540ff36d\n'}]",0,605933,2de30886b79c1dccbcc3ec0816d73516fc988019,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I816038dd3eaca6ca0b2ccb9518747051540ff36d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_almanach refs/changes/33/605933/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,2de30886b79c1dccbcc3ec0816d73516fc988019,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_monasca~master~I7aa6cd64f6403c3096eb62abd6e35618cc2f1f9a,openstack/openstack-ansible-os_monasca,master,I7aa6cd64f6403c3096eb62abd6e35618cc2f1f9a,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:43.000000000,2018-09-28 12:53:27.000000000,2018-09-28 12:53:27.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:43.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca/commit/67432e65140414d59b10494f7ed94becd360175d', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I7aa6cd64f6403c3096eb62abd6e35618cc2f1f9a\n'}]",0,605950,67432e65140414d59b10494f7ed94becd360175d,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I7aa6cd64f6403c3096eb62abd6e35618cc2f1f9a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_monasca refs/changes/50/605950/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,67432e65140414d59b10494f7ed94becd360175d,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_barbican~master~I5f5ac0c2e5e93cf7f2b235d722a6fc5f404927e9,openstack/openstack-ansible-os_barbican,master,I5f5ac0c2e5e93cf7f2b235d722a6fc5f404927e9,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:45.000000000,2018-09-28 12:53:27.000000000,2018-09-28 12:53:26.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:45.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/841fb306e0dc881bc7478249fdb0aad05fa687a0', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I5f5ac0c2e5e93cf7f2b235d722a6fc5f404927e9\n'}]",0,605935,841fb306e0dc881bc7478249fdb0aad05fa687a0,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I5f5ac0c2e5e93cf7f2b235d722a6fc5f404927e9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/35/605935/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,841fb306e0dc881bc7478249fdb0aad05fa687a0,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_trove~master~I26e7a2e27f526776f8b4c4d567cf792ee310161c,openstack/openstack-ansible-os_trove,master,I26e7a2e27f526776f8b4c4d567cf792ee310161c,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:15.000000000,2018-09-28 12:52:55.000000000,2018-09-28 12:52:55.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:15.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_trove/commit/fe5ec09aa7e58eaabee99dc0e43ac3cd68075395', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I26e7a2e27f526776f8b4c4d567cf792ee310161c\n'}]",0,605961,fe5ec09aa7e58eaabee99dc0e43ac3cd68075395,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I26e7a2e27f526776f8b4c4d567cf792ee310161c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_trove refs/changes/61/605961/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,fe5ec09aa7e58eaabee99dc0e43ac3cd68075395,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_designate~master~Ic00295257fa003989f0a28c6f0ef8a8700f8fad3,openstack/openstack-ansible-os_designate,master,Ic00295257fa003989f0a28c6f0ef8a8700f8fad3,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:28.000000000,2018-09-28 12:52:40.000000000,2018-09-28 12:52:40.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:28.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_designate/commit/da4ca1c9c33fd6d2051ffa4d70c9ec4e9ded67a3', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ic00295257fa003989f0a28c6f0ef8a8700f8fad3\n'}]",0,605941,da4ca1c9c33fd6d2051ffa4d70c9ec4e9ded67a3,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ic00295257fa003989f0a28c6f0ef8a8700f8fad3
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_designate refs/changes/41/605941/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,da4ca1c9c33fd6d2051ffa4d70c9ec4e9ded67a3,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_aodh~master~Iaef53bc45f7f13e3c6c6b5e6bc533f7717313acc,openstack/openstack-ansible-os_aodh,master,Iaef53bc45f7f13e3c6c6b5e6bc533f7717313acc,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:37.000000000,2018-09-28 12:52:27.000000000,2018-09-28 12:52:27.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:37.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/3fda2a7a47e259a13bb090b45d1d0e90cc531fe3', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Iaef53bc45f7f13e3c6c6b5e6bc533f7717313acc\n'}]",0,605934,3fda2a7a47e259a13bb090b45d1d0e90cc531fe3,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Iaef53bc45f7f13e3c6c6b5e6bc533f7717313acc
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/34/605934/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,3fda2a7a47e259a13bb090b45d1d0e90cc531fe3,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_rally~master~Ie39da3808a8743e422f7ffadbfb1ae43e78ccba8,openstack/openstack-ansible-os_rally,master,Ie39da3808a8743e422f7ffadbfb1ae43e78ccba8,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:29.000000000,2018-09-28 12:52:00.000000000,2018-09-28 12:52:00.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:29.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_rally/commit/4c8810199fcad8783e40e7fe6147f03e5b7b061b', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie39da3808a8743e422f7ffadbfb1ae43e78ccba8\n'}]",0,605955,4c8810199fcad8783e40e7fe6147f03e5b7b061b,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ie39da3808a8743e422f7ffadbfb1ae43e78ccba8
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_rally refs/changes/55/605955/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,4c8810199fcad8783e40e7fe6147f03e5b7b061b,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_magnum~master~I785d5674c44e5b00f7cfc4d4dc3c29712434e69a,openstack/openstack-ansible-os_magnum,master,I785d5674c44e5b00f7cfc4d4dc3c29712434e69a,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:24.000000000,2018-09-28 12:51:42.000000000,2018-09-28 12:51:42.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:24.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_magnum/commit/cb62d31bee7fb39825faec12658440ca752db391', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I785d5674c44e5b00f7cfc4d4dc3c29712434e69a\n'}]",0,605948,cb62d31bee7fb39825faec12658440ca752db391,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I785d5674c44e5b00f7cfc4d4dc3c29712434e69a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_magnum refs/changes/48/605948/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,cb62d31bee7fb39825faec12658440ca752db391,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_horizon~master~Idfd2994c4be168a2f620126008b32fd67f123f9d,openstack/openstack-ansible-os_horizon,master,Idfd2994c4be168a2f620126008b32fd67f123f9d,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:58.000000000,2018-09-28 12:51:42.000000000,2018-09-28 12:51:42.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:58.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/abd859ca91dc738cdc020584182904b452040ba9', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Idfd2994c4be168a2f620126008b32fd67f123f9d\n'}]",0,605945,abd859ca91dc738cdc020584182904b452040ba9,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Idfd2994c4be168a2f620126008b32fd67f123f9d
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/45/605945/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,abd859ca91dc738cdc020584182904b452040ba9,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_tacker~master~I3382341a8c29828e9dbf0926ce440b02eb0c69e0,openstack/openstack-ansible-os_tacker,master,I3382341a8c29828e9dbf0926ce440b02eb0c69e0,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:59.000000000,2018-09-28 12:50:58.000000000,2018-09-28 12:50:57.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:59.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tacker/commit/b30927d52bf45d7f3b6403ad0275ec63af40d2cb', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I3382341a8c29828e9dbf0926ce440b02eb0c69e0\n'}]",0,605959,b30927d52bf45d7f3b6403ad0275ec63af40d2cb,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I3382341a8c29828e9dbf0926ce440b02eb0c69e0
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tacker refs/changes/59/605959/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,b30927d52bf45d7f3b6403ad0275ec63af40d2cb,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_neutron~master~If23ecbc058a765eaf42993ea974c5a0c8030778f,openstack/openstack-ansible-os_neutron,master,If23ecbc058a765eaf42993ea974c5a0c8030778f,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:59.000000000,2018-09-28 12:50:58.000000000,2018-09-28 12:50:58.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:59.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/4143ec32c13d4d8a57a55fe778eda1d706366419', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: If23ecbc058a765eaf42993ea974c5a0c8030778f\n'}]",0,605951,4143ec32c13d4d8a57a55fe778eda1d706366419,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: If23ecbc058a765eaf42993ea974c5a0c8030778f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/51/605951/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,4143ec32c13d4d8a57a55fe778eda1d706366419,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_ironic~master~I07cf2feb1f9eccabb007f1e10af545b3b499fe0c,openstack/openstack-ansible-os_ironic,master,I07cf2feb1f9eccabb007f1e10af545b3b499fe0c,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:20:05.000000000,2018-09-28 12:50:23.000000000,2018-09-28 12:50:23.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:20:05.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/1395eb7f549c88dc446553c0195abf0c7516d22b', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I07cf2feb1f9eccabb007f1e10af545b3b499fe0c\n'}]",0,605946,1395eb7f549c88dc446553c0195abf0c7516d22b,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I07cf2feb1f9eccabb007f1e10af545b3b499fe0c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/46/605946/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,1395eb7f549c88dc446553c0195abf0c7516d22b,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_ceilometer~master~Ia04ca96c9e47029a65b721f68cdc1220e5da71b3,openstack/openstack-ansible-os_ceilometer,master,Ia04ca96c9e47029a65b721f68cdc1220e5da71b3,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:18:59.000000000,2018-09-28 12:49:53.000000000,2018-09-28 12:49:53.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:18:59.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/cbe06538f12278421028fe6c6f6779027efec425', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ia04ca96c9e47029a65b721f68cdc1220e5da71b3\n'}]",0,605937,cbe06538f12278421028fe6c6f6779027efec425,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ia04ca96c9e47029a65b721f68cdc1220e5da71b3
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/37/605937/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,cbe06538f12278421028fe6c6f6779027efec425,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_panko~master~I75cd16652f689869c88823aa6eff75f2b1aa684a,openstack/openstack-ansible-os_panko,master,I75cd16652f689869c88823aa6eff75f2b1aa684a,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:22.000000000,2018-09-28 12:49:29.000000000,2018-09-28 12:49:29.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:22.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_panko/commit/d56a9669621eb9161981d6ef44529e227ae60295', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I75cd16652f689869c88823aa6eff75f2b1aa684a\n'}]",0,605954,d56a9669621eb9161981d6ef44529e227ae60295,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I75cd16652f689869c88823aa6eff75f2b1aa684a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_panko refs/changes/54/605954/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,d56a9669621eb9161981d6ef44529e227ae60295,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_swift~master~I42c6a13b6f9ac332cca916bddf9582e60d0713b2,openstack/openstack-ansible-os_swift,master,I42c6a13b6f9ac332cca916bddf9582e60d0713b2,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:52.000000000,2018-09-28 12:49:01.000000000,2018-09-28 12:49:01.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:52.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/1a029b2bb10a1741041ba2ec9cb8bf8e12957a94', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I42c6a13b6f9ac332cca916bddf9582e60d0713b2\n'}]",0,605958,1a029b2bb10a1741041ba2ec9cb8bf8e12957a94,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I42c6a13b6f9ac332cca916bddf9582e60d0713b2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/58/605958/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,1a029b2bb10a1741041ba2ec9cb8bf8e12957a94,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_searchlight~master~I1d3b0edc01dd67003658cacbd444a22ed25aa147,openstack/openstack-ansible-os_searchlight,master,I1d3b0edc01dd67003658cacbd444a22ed25aa147,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:44.000000000,2018-09-28 12:49:01.000000000,2018-09-28 12:49:00.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:44.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_searchlight/commit/af31119d03ddfa086442b0b174306e47f6fcc6fc', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1d3b0edc01dd67003658cacbd444a22ed25aa147\n'}]",0,605957,af31119d03ddfa086442b0b174306e47f6fcc6fc,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1d3b0edc01dd67003658cacbd444a22ed25aa147
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_searchlight refs/changes/57/605957/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,af31119d03ddfa086442b0b174306e47f6fcc6fc,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_octavia~master~I575080447f1bc1376956e13c1093fdab5f0d62b7,openstack/openstack-ansible-os_octavia,master,I575080447f1bc1376956e13c1093fdab5f0d62b7,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:15.000000000,2018-09-28 12:48:45.000000000,2018-09-28 12:48:44.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:15.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_octavia/commit/fb41c3f162eb9b8a9ebca80c200bb405e38921a1', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I575080447f1bc1376956e13c1093fdab5f0d62b7\n'}]",0,605953,fb41c3f162eb9b8a9ebca80c200bb405e38921a1,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I575080447f1bc1376956e13c1093fdab5f0d62b7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_octavia refs/changes/53/605953/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,fb41c3f162eb9b8a9ebca80c200bb405e38921a1,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-config_template~master~I8bc8a11b8c7a5f543ef219d056dd2be95acadbd2,openstack/ansible-config_template,master,I8bc8a11b8c7a5f543ef219d056dd2be95acadbd2,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:39.000000000,2018-09-28 12:48:34.000000000,2018-09-28 12:48:34.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:39.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/71ed57acaf7e76f64d67e834493a14581e016432', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I8bc8a11b8c7a5f543ef219d056dd2be95acadbd2\n'}]",0,605972,71ed57acaf7e76f64d67e834493a14581e016432,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I8bc8a11b8c7a5f543ef219d056dd2be95acadbd2
",git fetch https://review.opendev.org/openstack/ansible-config_template refs/changes/72/605972/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,71ed57acaf7e76f64d67e834493a14581e016432,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-hardening~master~Id0ea515e4788dce927b0321387dc12db03d77f7b,openstack/ansible-hardening,master,Id0ea515e4788dce927b0321387dc12db03d77f7b,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:47.000000000,2018-09-28 12:48:29.000000000,2018-09-28 12:48:28.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:47.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-hardening/commit/f2452bd32729479338e3e0b81de56ab5cc769263', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Id0ea515e4788dce927b0321387dc12db03d77f7b\n'}]",0,605973,f2452bd32729479338e3e0b81de56ab5cc769263,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Id0ea515e4788dce927b0321387dc12db03d77f7b
",git fetch https://review.opendev.org/openstack/ansible-hardening refs/changes/73/605973/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,f2452bd32729479338e3e0b81de56ab5cc769263,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_sahara~master~I6a3cc94b0a4cb1494e794624cdfee308b465c691,openstack/openstack-ansible-os_sahara,master,I6a3cc94b0a4cb1494e794624cdfee308b465c691,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:21:37.000000000,2018-09-28 12:48:18.000000000,2018-09-28 12:48:18.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:21:37.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/09e698798745e7413f7e56271f08536acce877b2', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I6a3cc94b0a4cb1494e794624cdfee308b465c691\n'}]",0,605956,09e698798745e7413f7e56271f08536acce877b2,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I6a3cc94b0a4cb1494e794624cdfee308b465c691
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/56/605956/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,09e698798745e7413f7e56271f08536acce877b2,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_watcher~master~I11283a8f1364641794b7cb1de7a2d1f5c6724dc3,openstack/openstack-ansible-os_watcher,master,I11283a8f1364641794b7cb1de7a2d1f5c6724dc3,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:22.000000000,2018-09-28 12:48:06.000000000,2018-09-28 12:48:06.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:22.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_watcher/commit/4d5feaf59c97f1691d3ec5eeff0059693de006bd', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I11283a8f1364641794b7cb1de7a2d1f5c6724dc3\n'}]",0,605962,4d5feaf59c97f1691d3ec5eeff0059693de006bd,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I11283a8f1364641794b7cb1de7a2d1f5c6724dc3
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_watcher refs/changes/62/605962/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,4d5feaf59c97f1691d3ec5eeff0059693de006bd,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-role-systemd_networkd~master~I0eb03845e2ebdae4507fc70eaee03503fb890782,openstack/ansible-role-systemd_networkd,master,I0eb03845e2ebdae4507fc70eaee03503fb890782,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:24:07.000000000,2018-09-28 12:47:30.000000000,2018-09-28 12:47:30.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:24:07.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/ac85ec555e0cb8a04c2cbba41e8bf94c1d50600d', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I0eb03845e2ebdae4507fc70eaee03503fb890782\n'}]",0,605976,ac85ec555e0cb8a04c2cbba41e8bf94c1d50600d,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I0eb03845e2ebdae4507fc70eaee03503fb890782
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_networkd refs/changes/76/605976/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,ac85ec555e0cb8a04c2cbba41e8bf94c1d50600d,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_cinder~master~Ibe9e10b943472cc3cff6402488dc1e9ba51da11e,openstack/openstack-ansible-os_cinder,master,Ibe9e10b943472cc3cff6402488dc1e9ba51da11e,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:07.000000000,2018-09-28 12:47:26.000000000,2018-09-28 12:47:26.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:07.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/2d07c3ed68475e4925b18d9d56f1c4fe1846ddee', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ibe9e10b943472cc3cff6402488dc1e9ba51da11e\n'}]",0,605938,2d07c3ed68475e4925b18d9d56f1c4fe1846ddee,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ibe9e10b943472cc3cff6402488dc1e9ba51da11e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/38/605938/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,2d07c3ed68475e4925b18d9d56f1c4fe1846ddee,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-repo_server~master~I1e8096af54308a3c9a7fb7b603587e05cf564e02,openstack/openstack-ansible-repo_server,master,I1e8096af54308a3c9a7fb7b603587e05cf564e02,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:14.000000000,2018-09-28 12:47:23.000000000,2018-09-28 12:47:23.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:14.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/2a5fcfe889a62714de20df45a25fc9d52cba29b5', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1e8096af54308a3c9a7fb7b603587e05cf564e02\n'}]",0,605969,2a5fcfe889a62714de20df45a25fc9d52cba29b5,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1e8096af54308a3c9a7fb7b603587e05cf564e02
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/69/605969/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,2a5fcfe889a62714de20df45a25fc9d52cba29b5,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-plugins~master~I2b748eaaf1c73526de10c6c206c50eb7f9631592,openstack/openstack-ansible-plugins,master,I2b748eaaf1c73526de10c6c206c50eb7f9631592,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:51.000000000,2018-09-28 12:47:03.000000000,2018-09-28 12:47:03.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:51.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-plugins/commit/f33d5576943f09a98df724900f7fbb45ca68520d', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I2b748eaaf1c73526de10c6c206c50eb7f9631592\n'}]",0,605966,f33d5576943f09a98df724900f7fbb45ca68520d,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I2b748eaaf1c73526de10c6c206c50eb7f9631592
",git fetch https://review.opendev.org/openstack/openstack-ansible-plugins refs/changes/66/605966/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,f33d5576943f09a98df724900f7fbb45ca68520d,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-rsyslog_server~master~Ie2882e416c52bd239a07f5e5d8a23e27bce875d2,openstack/openstack-ansible-rsyslog_server,master,Ie2882e416c52bd239a07f5e5d8a23e27bce875d2,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:28.000000000,2018-09-28 12:46:56.000000000,2018-09-28 12:46:56.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:28.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/07bf9bd4b4bf60f09b0092534d03ee709eb417d3', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ie2882e416c52bd239a07f5e5d8a23e27bce875d2\n'}]",0,605971,07bf9bd4b4bf60f09b0092534d03ee709eb417d3,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ie2882e416c52bd239a07f5e5d8a23e27bce875d2
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/71/605971/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,07bf9bd4b4bf60f09b0092534d03ee709eb417d3,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-repo_build~master~Ib9ec72074b40a69914ec1ab47bb9b00426cde7bd,openstack/openstack-ansible-repo_build,master,Ib9ec72074b40a69914ec1ab47bb9b00426cde7bd,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:06.000000000,2018-09-28 12:46:16.000000000,2018-09-28 12:46:16.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:06.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/31d981871fa99c1f144d34f145fcfa5a1285c911', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ib9ec72074b40a69914ec1ab47bb9b00426cde7bd\n'}]",0,605968,31d981871fa99c1f144d34f145fcfa5a1285c911,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ib9ec72074b40a69914ec1ab47bb9b00426cde7bd
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/68/605968/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,31d981871fa99c1f144d34f145fcfa5a1285c911,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-role-systemd_mount~master~Ic621928ce5452fa88314f820f7ccb1f02d371447,openstack/ansible-role-systemd_mount,master,Ic621928ce5452fa88314f820f7ccb1f02d371447,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:24:00.000000000,2018-09-28 12:46:15.000000000,2018-09-28 12:46:15.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:24:00.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_mount/commit/b0b54f2fd59d48611aadff0050e9e141d1034bfb', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ic621928ce5452fa88314f820f7ccb1f02d371447\n'}]",0,605975,b0b54f2fd59d48611aadff0050e9e141d1034bfb,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ic621928ce5452fa88314f820f7ccb1f02d371447
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_mount refs/changes/75/605975/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,b0b54f2fd59d48611aadff0050e9e141d1034bfb,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_zun~master~Ieb86edb5f43f8b4190077ac48ed737bb6be27468,openstack/openstack-ansible-os_zun,master,Ieb86edb5f43f8b4190077ac48ed737bb6be27468,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:36.000000000,2018-09-28 12:46:08.000000000,2018-09-28 12:46:08.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:36.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zun/commit/bf83ba58c5599ee7c6d65af9eddf5f2ff273cc76', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ieb86edb5f43f8b4190077ac48ed737bb6be27468\n'}]",0,605964,bf83ba58c5599ee7c6d65af9eddf5f2ff273cc76,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ieb86edb5f43f8b4190077ac48ed737bb6be27468
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zun refs/changes/64/605964/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,bf83ba58c5599ee7c6d65af9eddf5f2ff273cc76,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_congress~master~I5d8e11e9ecefe7bf40f04e24fec123f2e7c29ca5,openstack/openstack-ansible-os_congress,master,I5d8e11e9ecefe7bf40f04e24fec123f2e7c29ca5,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:21.000000000,2018-09-28 12:45:36.000000000,2018-09-28 12:45:35.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:21.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_congress/commit/db42f256b1b31ee4ad695db0530ec95c4aeba3ba', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I5d8e11e9ecefe7bf40f04e24fec123f2e7c29ca5\n'}]",0,605940,db42f256b1b31ee4ad695db0530ec95c4aeba3ba,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I5d8e11e9ecefe7bf40f04e24fec123f2e7c29ca5
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_congress refs/changes/40/605940/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,db42f256b1b31ee4ad695db0530ec95c4aeba3ba,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_gnocchi~master~I21fb5da823d3622b370584d511d78264cf596f67,openstack/openstack-ansible-os_gnocchi,master,I21fb5da823d3622b370584d511d78264cf596f67,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:43.000000000,2018-09-28 12:44:58.000000000,2018-09-28 12:44:58.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:43.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_gnocchi/commit/85e9a9a36ec98329b9bd026048d14de811f353d7', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I21fb5da823d3622b370584d511d78264cf596f67\n'}]",0,605943,85e9a9a36ec98329b9bd026048d14de811f353d7,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I21fb5da823d3622b370584d511d78264cf596f67
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_gnocchi refs/changes/43/605943/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,85e9a9a36ec98329b9bd026048d14de811f353d7,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-role-systemd_service~master~Ifb0f61e699d62ea89feeb6efbf176c50444ac2d0,openstack/ansible-role-systemd_service,master,Ifb0f61e699d62ea89feeb6efbf176c50444ac2d0,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:24:15.000000000,2018-09-28 12:44:46.000000000,2018-09-28 12:44:46.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:24:15.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/c92c3e622bb46e424eb42fe9d2e6a8b365b7c333', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ifb0f61e699d62ea89feeb6efbf176c50444ac2d0\n'}]",0,605977,c92c3e622bb46e424eb42fe9d2e6a8b365b7c333,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ifb0f61e699d62ea89feeb6efbf176c50444ac2d0
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/77/605977/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,c92c3e622bb46e424eb42fe9d2e6a8b365b7c333,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-pip_install~master~Ifaf71768c16bc7b045a897b2ad967bebf19f1990,openstack/openstack-ansible-pip_install,master,Ifaf71768c16bc7b045a897b2ad967bebf19f1990,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:43.000000000,2018-09-28 12:44:38.000000000,2018-09-28 12:44:38.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:43.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/d79fcda37efad06c7469850c7fa6023eeeedeadf', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ifaf71768c16bc7b045a897b2ad967bebf19f1990\n'}]",0,605965,d79fcda37efad06c7469850c7fa6023eeeedeadf,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ifaf71768c16bc7b045a897b2ad967bebf19f1990
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/65/605965/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,d79fcda37efad06c7469850c7fa6023eeeedeadf,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_zaqar~master~Ifbb47b181e5ac4300ba1d5c716454382c20b9486,openstack/openstack-ansible-os_zaqar,master,Ifbb47b181e5ac4300ba1d5c716454382c20b9486,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:29.000000000,2018-09-28 12:43:29.000000000,2018-09-28 12:43:29.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:29.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zaqar/commit/6a961e108acd0010b9973c14f190a63af94cfa88', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: Ifbb47b181e5ac4300ba1d5c716454382c20b9486\n'}]",0,605963,6a961e108acd0010b9973c14f190a63af94cfa88,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: Ifbb47b181e5ac4300ba1d5c716454382c20b9486
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zaqar refs/changes/63/605963/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,6a961e108acd0010b9973c14f190a63af94cfa88,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_glance~master~I99acd1f9d62a0e380a763a41b47a663d4b08e66a,openstack/openstack-ansible-os_glance,master,I99acd1f9d62a0e380a763a41b47a663d4b08e66a,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:36.000000000,2018-09-28 12:43:01.000000000,2018-09-28 12:43:01.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:36.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_glance/commit/6771d516cf11dc24494cd5057f24243a5961302f', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I99acd1f9d62a0e380a763a41b47a663d4b08e66a\n'}]",0,605942,6771d516cf11dc24494cd5057f24243a5961302f,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I99acd1f9d62a0e380a763a41b47a663d4b08e66a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_glance refs/changes/42/605942/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,6771d516cf11dc24494cd5057f24243a5961302f,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-rsyslog_client~master~I149b7c7c159a0a3d8de06442242e2d71cda945a8,openstack/openstack-ansible-rsyslog_client,master,I149b7c7c159a0a3d8de06442242e2d71cda945a8,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:21.000000000,2018-09-28 12:42:53.000000000,2018-09-28 12:42:53.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:21.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/cdc4378d4461e4e2300a029b0c5275027331b2d7', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I149b7c7c159a0a3d8de06442242e2d71cda945a8\n'}]",0,605970,cdc4378d4461e4e2300a029b0c5275027331b2d7,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I149b7c7c159a0a3d8de06442242e2d71cda945a8
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/70/605970/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,cdc4378d4461e4e2300a029b0c5275027331b2d7,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-rabbitmq_server~master~I1dbb91f2aa69919609028c89b1cae8d454b11749,openstack/openstack-ansible-rabbitmq_server,master,I1dbb91f2aa69919609028c89b1cae8d454b11749,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:22:59.000000000,2018-09-28 12:42:49.000000000,2018-09-28 12:42:49.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:22:59.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/e45e7c4a13a80ebe9720fb40fd7374e193b8f818', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1dbb91f2aa69919609028c89b1cae8d454b11749\n'}]",0,605967,e45e7c4a13a80ebe9720fb40fd7374e193b8f818,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1dbb91f2aa69919609028c89b1cae8d454b11749
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/67/605967/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,e45e7c4a13a80ebe9720fb40fd7374e193b8f818,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fansible-role-python_venv_build~master~I8bcbff62aa1d4181f5ea992ad335ac2198aafff6,openstack/ansible-role-python_venv_build,master,I8bcbff62aa1d4181f5ea992ad335ac2198aafff6,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:23:54.000000000,2018-09-28 12:42:33.000000000,2018-09-28 12:42:33.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:23:54.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/040de8994db3150c40902e3f7db1b6d3541637a1', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I8bcbff62aa1d4181f5ea992ad335ac2198aafff6\n'}]",0,605974,040de8994db3150c40902e3f7db1b6d3541637a1,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I8bcbff62aa1d4181f5ea992ad335ac2198aafff6
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/74/605974/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,040de8994db3150c40902e3f7db1b6d3541637a1,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Fopenstack-ansible-os_heat~master~I1e5833147ee78463c6349b9a8dc643b2fdaabf8c,openstack/openstack-ansible-os_heat,master,I1e5833147ee78463c6349b9a8dc643b2fdaabf8c,Updated from OpenStack Ansible Tests,MERGED,2018-09-28 06:19:50.000000000,2018-09-28 12:41:43.000000000,2018-09-28 12:41:43.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 06:19:50.000000000', 'files': ['Vagrantfile'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/91e309a3223f15c63e9900b2422585274dd22260', 'message': 'Updated from OpenStack Ansible Tests\n\nChange-Id: I1e5833147ee78463c6349b9a8dc643b2fdaabf8c\n'}]",0,605944,91e309a3223f15c63e9900b2422585274dd22260,6,2,1,11131,,,0,"Updated from OpenStack Ansible Tests

Change-Id: I1e5833147ee78463c6349b9a8dc643b2fdaabf8c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/44/605944/1 && git format-patch -1 --stdout FETCH_HEAD,['Vagrantfile'],1,91e309a3223f15c63e9900b2422585274dd22260,openstack/openstack-ansible-tests/sync-tests," config.vm.define ""ubuntu1804"" do |bionic| bionic.disksize.size = ""40GB"" bionic.vm.box = ""ubuntu/bionic64"" end ",,5,0
openstack%2Ftripleo-specs~master~Ib99f82227d045c07d1e8b602627c8bcd6a88114c,openstack/tripleo-specs,master,Ib99f82227d045c07d1e8b602627c8bcd6a88114c,Validation Framework specifications,MERGED,2018-08-06 14:11:48.000000000,2018-09-28 12:31:04.000000000,2018-09-28 12:31:04.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 9317}, {'_account_id': 10873}, {'_account_id': 11491}, {'_account_id': 14985}, {'_account_id': 17888}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-08-06 14:11:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/f10fb582621d57fc8bc3557e304c8aada1acf4f4', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmit Iffaa3c99ac401626c70211437dd98f214b4973e4 previously merged\ntoo fast.\n\nBlueprint: validation-framework\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 2, 'created': '2018-08-06 14:18:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/a916155b528cec147c7d7d3dda43034f0783a9dc', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 3, 'created': '2018-08-09 13:00:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/ef5314cb536660b72f9abefd19c2c3189e1d9c30', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 4, 'created': '2018-08-10 13:33:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/aa41bd27f41a82d02aafaa6868242b1c478c7a27', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 5, 'created': '2018-08-22 05:50:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/4027877789f07efe0e6aa42e442627cf1b20d111', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 6, 'created': '2018-09-12 11:13:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/868d4ff53cfe986cc8c2dcc696ebc581787f3baa', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 7, 'created': '2018-09-12 13:56:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2b5681f7c2e93fbc27605fb7afb92069888f25ef', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 8, 'created': '2018-09-12 14:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/93412f800db661f5fc67013bcd0e0e39bfa97719', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}, {'number': 9, 'created': '2018-09-28 11:22:46.000000000', 'files': ['specs/stein/validation-framework.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/42edb218bd9c0ca0ef658f7ef9e9039f1f760ae5', 'message': 'Validation Framework specifications\n\nProvide a common, unified validation framework inside tripleoclient.\n\nThis resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously\nmerged too fast.\n\nThis reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.\n\nBlueprint: validation-framework\nChange-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c\n'}]",45,589169,42edb218bd9c0ca0ef658f7ef9e9039f1f760ae5,57,11,9,28223,,,0,"Validation Framework specifications

Provide a common, unified validation framework inside tripleoclient.

This resubmits Iffaa3c99ac401626c70211437dd98f214b4973e4 previously
merged too fast.

This reverts commit 20fc7a387af043809ec96a6ac1c3bac29f60516b.

Blueprint: validation-framework
Change-Id: Ib99f82227d045c07d1e8b602627c8bcd6a88114c
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/69/589169/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/validation-framework.rst'],1,f10fb582621d57fc8bc3557e304c8aada1acf4f4,bp/validation-framework,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================================= Provide a common Validation Framework inside python-tripleoclient ================================================================= https://blueprints.launchpad.net/tripleo/+spec/validation-framework Currently, we're lacking a common validation framework in tripleoclient. This framework should provide an easy way to validate environment prior deploy and prior update/upgrade, on both undercloud and overcloud. Problem Description =================== Currently, we have two types of validations: * Those launched prior the undercloud deploy, embedded into the deploy itself * Those launched at will via a Mistral Workflow There isn't any unified way to call any validations by itself in an easy way, and we lack the capacity to easily add new validations for the undercloud preflight checks. This situation isn't good, and leads to issues when an operator wants to update or upgrade its environment, because he's not really able to validate its state in an independent way (i.e. they must run the deploy command that will trigger the validations, at least from the CLI). Moreover, there is a need to make the CLI and UI converge. The latter already uses the full list of validations. Adding the full support of tripleo-validations to the CLI will improve the overall quality, usability and maintenance of the validations. Creating a proper framework inside the CLI, based on the UI state, is the best way to ensure every Openstack-related projects will have a chance for proper validations. Proposed Change =============== Overview -------- In order to correct the current situation, we propose to create a new ""branching"" in the tripleoclient commands: `openstack validator` This new subcommand will allow to list and run validations in an independent way. Doing so will allow to get a clear and clean view on the validations we can run depending on the stage we're in. The following subcommands should be supported: * openstack validator list: will display all the available validations with a small description, like ""validate network capabilities on undercloud"" * openstack validator run: will run the validations. Should take options, like: * --validation-name: run only the passed validation. * --undercloud: runs all undercloud-related validations * --overcloud: runs all overcloud-related validations * --use-mistral: runs validations through Mistral * --use-ansible: runs validations directly via Ansible * openstack validator selfcheck: will run checks in order to ensure it has the proper services to run the other validations (ansible is working, playbooks are valid, Mistral is running and in good shape, and so on). * in addition, common options for all the subcommands: * --extra-playbooks: path to a local directory containing validation playbook maintained by the operator * --output: points to a valid Ansible output_callback, such as the native *json*, or custom *validation_output*. The default one should be the latter as it renders a ""human readable"" output. More callbacks can be added later. The default engine will be determined by the presence of Mistral: if Mistral is present and accepting requests (meaning the Undercloud is most probably deployed), the validator has to use it by default. If no Mistral is present, it must fallback on the ansible-playbook. (Note: the command path has yet to be defined - this is only a ""mock-up"".) The validations should be in the form of Ansible playbook, in order to be easily accessed from Mistral as well (as it is currently the case). It will also allow to get a proper documentation, canvas and gives the possibility to validate the playbook before running it (ensuring there are metadata, output, and so on). Speaking of the UI: currently, it runs validations through a Mistral workflow. The new validation framework should be able to populate Mistral workflows on the fly, by listing the existing validations. That way, the operators using the UI will be able to do the same things as the CLI. In the end, all the validation playbooks should be in one and only one location: tripleo-validations. We also must ensure we can navigate and find validations in an easy way in this repository. Thus we need a proper tree schema, maybe per-service directories with service-dedicated validations, for instance: * nova * validate-listen-port-xxx.yaml * validate-listen-socket-xxx.yaml * .... * memcached * validate-listen-port-xxx.yaml * .... * dashboard * validate-public-access.yaml * validate-listen-socket-xxx.yaml * .... * keystone * validate-listen-port-xxx.yaml * validate-dummy-auth.yaml * .... * .... In addition, a proper documentation with examples describing the Good Practices regarding the playbooks content, format and outputs should be created. For instance, a playbook should contain a description, a ""human readable error output"", and if applicable a possible solution. We might want to add support for ""nagios-compatible outputs"" and exit codes, but it is not sure running those validations through any monitoring tool is a good idea due to the possible load it might create. This has to be discussed later, once we get the framework in place. Alternatives ------------ No real alternatives in fact. Currently, we have many ways to validate, but they are all unrelated, not concerted. If we don't provide a unified framework, we will get more and more ""side validations ways"" and it won't be maintainable. Security Impact --------------- Rights might be needed for some validations - they should be added accordingly in the system sudoers, in a way that limits unwanted privilege escalations. Other End User Impact --------------------- The end user will get a proper way to validate the environment prior to any action. This will give more confidence in the final product, and ease the update and upgrade processes. It will also provide a good way to collect information about the systems in case of failures. If a ""nagios-compatible output"" is to be created (mix of ansible JSON output, parsing and compatibility stuff), it might provide a way to get a daily report about the health of the stack - this might be a nice feature, but not in the current scope (will need a new stdout_callback for instance). Performance Impact ------------------ The more validations we get, the more time it might take IF we decide to run them by default prior any action. The current way to disable them, either with a configuration file or a CLI option will stay. In addition, we can make a great use of ""groups"" in order to filter out greedy validations. Other Deployer Impact --------------------- Providing a dedicated path for validation will make the deployment easier. Providing a unified framework will allow an operator to run the validations either from the UI, or from the CLI, without any surprise regarding the validation list. Developer Impact ---------------- A refactoring will be needed in python-tripleoclient in order to get a proper subcommand and options. A correct way to call Ansible from Python is to be decided (ansible-runner?). The usage of Mistral is to be assessed (Do we really need it for the UI?). A correct way to populate Mistral Workflows is to be decided if we keep Mistral. In the end, the framework will allow other Openstack projects to push their own validations, since they are the ones knowing how and what to validate in the different services making Openstack. All validations will be centralized in the tripleo-validations repository. This means we might want to create a proper tree in order to avoid having 100+ validations in the same directory. Implementation ============== Assignee(s) ----------- Primary assignee: cjeanner Other contributors: ccamacho dpeacock florianf Work Items ---------- * List current existing validations in both undercloud_preflight.py and openstack-tripleo-validations. * Decide if we integrate ansible-runner as a dependency (needs to be packaged). * Implement the undercloud_preflight validations as Ansible playbook. * Implement a proper way to call Ansible from the tripleoclient code. * Implement support for a configuration file dedicated for the validations. * Implement the new subcommand tree in tripleoclient. * Validate, Validate, Validate. Dependencies ============ * Ansible-runner: https://github.com/ansible/ansible-runner * Openstack-tripleo-validations: https://github.com/openstack/tripleo-validations Testing ======= The CI can't possibly provide the ""right"" environment with all the requirements. The code has to implement a way to configure the validations so that the CI can override the *productive* values we will set in the validations. Documentation Impact ==================== A new entry in the documentation must be created in order to describe this new framework (for the devs) and new subcommand (for the operators). References ========== * http://lists.openstack.org/pipermail/openstack-dev/2018-July/132263.html * https://bugzilla.redhat.com/show_bug.cgi?id=1599829 * https://bugzilla.redhat.com/show_bug.cgi?id=1601739 ",,274,0
openstack%2Fmolteniron~master~I085b7983460e3616a9df8d29505271f94ea5b846,openstack/molteniron,master,I085b7983460e3616a9df8d29505271f94ea5b846,add python 3.6 unit test job,MERGED,2018-08-16 13:52:43.000000000,2018-09-28 12:22:32.000000000,2018-09-28 12:22:32.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-16 13:52:43.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/molteniron/commit/796e694f8d0ed109d53f8b69193e7034b3073cef', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I085b7983460e3616a9df8d29505271f94ea5b846\nStory: #2002586\nTask: #24302\n'}]",0,592405,796e694f8d0ed109d53f8b69193e7034b3073cef,8,4,1,2472,,,0,"add python 3.6 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.6 as part of the python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I085b7983460e3616a9df8d29505271f94ea5b846
Story: #2002586
Task: #24302
",git fetch https://review.opendev.org/openstack/molteniron refs/changes/05/592405/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,796e694f8d0ed109d53f8b69193e7034b3073cef,python3-first, - openstack-python36-jobs,,1,0
openstack%2Fhorizon~master~I276eebf0f11406bf354f5d8bbecef7b244d6d340,openstack/horizon,master,I276eebf0f11406bf354f5d8bbecef7b244d6d340,Add enabled check in Backups panel,MERGED,2018-09-26 14:38:34.000000000,2018-09-28 12:20:56.000000000,2018-09-27 13:33:31.000000000,"[{'_account_id': 1736}, {'_account_id': 6737}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2018-09-26 14:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/92388cc77bd6604aa0c4ca04d928d0e7fa17208c', 'message': 'Add enabled check in Backups panel\n\nIf enable_backup is False in OPENSTACK_CINDER_FEATURES\nthen we should not display the backups panel.\n\nChange-Id: I276eebf0f11406bf354f5d8bbecef7b244d6d340\nCloses-Bug: #1778771\n'}, {'number': 2, 'created': '2018-09-26 14:42:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/b63cd5fe9b2d4df9190ecde6a612d37fdde52e60', 'message': 'Add enabled check in Backups panel\n\nIf enable_backup is False in OPENSTACK_CINDER_FEATURES\nthen we should not display the backups panel.\n\nChange-Id: I276eebf0f11406bf354f5d8bbecef7b244d6d340\nCloses-Bug: #1778771\n'}, {'number': 3, 'created': '2018-09-26 15:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8b78e5afb1e015f95a41268dbb25e85fb27a9888', 'message': 'Add enabled check in Backups panel\n\nIf enable_backup is False in OPENSTACK_CINDER_FEATURES\nthen we should not display the backups panel.\n\nChange-Id: I276eebf0f11406bf354f5d8bbecef7b244d6d340\nCloses-Bug: #1778771\n'}, {'number': 4, 'created': '2018-09-27 08:37:27.000000000', 'files': ['openstack_dashboard/dashboards/project/backups/panel.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/6c2225bab8b007023e031d829bc72e8e50e6f1df', 'message': 'Add enabled check in Backups panel\n\nIf enable_backup is False in OPENSTACK_CINDER_FEATURES\nthen we should not display the backups panel.\n\nChange-Id: I276eebf0f11406bf354f5d8bbecef7b244d6d340\nCloses-Bug: #1778771\n'}]",0,605442,6c2225bab8b007023e031d829bc72e8e50e6f1df,17,4,4,6737,,,0,"Add enabled check in Backups panel

If enable_backup is False in OPENSTACK_CINDER_FEATURES
then we should not display the backups panel.

Change-Id: I276eebf0f11406bf354f5d8bbecef7b244d6d340
Closes-Bug: #1778771
",git fetch https://review.opendev.org/openstack/horizon refs/changes/42/605442/4 && git format-patch -1 --stdout FETCH_HEAD,['openstack_dashboard/dashboards/project/backups/panel.py'],1,92388cc77bd6604aa0c4ca04d928d0e7fa17208c,bug/1778771,from openstack_dashboard import api def can_register(self): return api.cinder.volume_backup_supported(None),,5,0
openstack%2Fironic-python-agent-builder~master~I520e4b2ccd50ea74cf1320362aa59cab088650d3,openstack/ironic-python-agent-builder,master,I520e4b2ccd50ea74cf1320362aa59cab088650d3,switch documentation job to new PTI,MERGED,2018-08-16 13:52:24.000000000,2018-09-28 12:20:55.000000000,2018-09-28 12:20:54.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-16 13:52:24.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/9f04837bdf0da97b470465538700625e0cbd6021', 'message': 'switch documentation job to new PTI\n\nThis is a mechanically generated patch to switch the documentation\njobs to use the new PTI versions of the jobs as part of the\npython3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I520e4b2ccd50ea74cf1320362aa59cab088650d3\nStory: #2002586\nTask: #24302\n'}]",0,592397,9f04837bdf0da97b470465538700625e0cbd6021,8,3,1,2472,,,0,"switch documentation job to new PTI

This is a mechanically generated patch to switch the documentation
jobs to use the new PTI versions of the jobs as part of the
python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I520e4b2ccd50ea74cf1320362aa59cab088650d3
Story: #2002586
Task: #24302
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/97/592397/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,9f04837bdf0da97b470465538700625e0cbd6021,python3-first, - publish-openstack-docs-pti - release-notes-jobs-python3, - publish-openstack-sphinx-docs - release-notes-jobs,2,2
openstack%2Ftripleo-specs~master~I199b5b9bda971e812edb10356ad930a5601539af,openstack/tripleo-specs,master,I199b5b9bda971e812edb10356ad930a5601539af,Remove the redundant word,MERGED,2018-08-22 04:47:59.000000000,2018-09-28 12:19:19.000000000,2018-09-28 12:19:19.000000000,"[{'_account_id': 9317}, {'_account_id': 10873}, {'_account_id': 20868}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-22 04:47:59.000000000', 'files': ['specs/policy/ci-team-structure.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/2562f10f086703983f8b1333d475fb8d247c9df9', 'message': 'Remove the redundant word\n\nChange-Id: I199b5b9bda971e812edb10356ad930a5601539af\n'}]",0,594799,2562f10f086703983f8b1333d475fb8d247c9df9,8,4,1,17130,,,0,"Remove the redundant word

Change-Id: I199b5b9bda971e812edb10356ad930a5601539af
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/99/594799/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/policy/ci-team-structure.rst'],1,2562f10f086703983f8b1333d475fb8d247c9df9,duplicated, * If the Ruck is overwhelmed with any of their responsibilities the, * If the Ruck is overwhelmed with any of the their responsibilities the,1,1
openstack%2Fmolteniron~master~Ibd5e462c444367336a40b4ae0d7ac007b09bf792,openstack/molteniron,master,Ibd5e462c444367336a40b4ae0d7ac007b09bf792,import zuul job settings from project-config,MERGED,2018-08-16 13:52:43.000000000,2018-09-28 12:19:18.000000000,2018-09-28 12:19:18.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-16 13:52:43.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/molteniron/commit/28e9321cd4e603bf9e7f7abb36835f60fd059463', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: Ibd5e462c444367336a40b4ae0d7ac007b09bf792\nStory: #2002586\nTask: #24302\n'}]",0,592404,28e9321cd4e603bf9e7f7abb36835f60fd059463,8,4,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: Ibd5e462c444367336a40b4ae0d7ac007b09bf792
Story: #2002586
Task: #24302
",git fetch https://review.opendev.org/openstack/molteniron refs/changes/04/592404/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,28e9321cd4e603bf9e7f7abb36835f60fd059463,python3-first,- project: templates: - openstack-python-jobs - openstack-python35-jobs - check-requirements ,,5,0
openstack%2Fneutron-lib~master~Ic2f7d63f02d5e874d469e29d11110c7ffe8ce5d7,openstack/neutron-lib,master,Ic2f7d63f02d5e874d469e29d11110c7ffe8ce5d7,Add get_supported_vnic_types to MechanismDriver,ABANDONED,2018-09-25 13:53:49.000000000,2018-09-28 12:18:01.000000000,,"[{'_account_id': 5367}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 15554}, {'_account_id': 16688}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 13:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/278bb4ea9aae0841ef6d86ecd65e6cb3be55e9b6', 'message': 'Add get_supported_vnic_types to MechanismDriver\n\nChange-Id: Ic2f7d63f02d5e874d469e29d11110c7ffe8ce5d7\nPartial-Bug: #1578989\nSee-Also: https://review.openstack.org/502306 (nova spec)\nSee-Also: https://review.openstack.org/508149 (neutron spec)\n'}, {'number': 2, 'created': '2018-09-26 13:00:30.000000000', 'files': ['releasenotes/notes/add-get-supported-vnic-types-to-MechanismDriver-fbe0bc9b68d5e329.yaml', 'neutron_lib/plugins/ml2/api.py'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/2f54c9c982c06298365910473af0a8d8e01ef58a', 'message': 'Add get_supported_vnic_types to MechanismDriver\n\nChange-Id: Ic2f7d63f02d5e874d469e29d11110c7ffe8ce5d7\nPartial-Bug: #1578989\nSee-Also: https://review.openstack.org/502306 (nova spec)\nSee-Also: https://review.openstack.org/508149 (neutron spec)\n'}]",6,605079,2f54c9c982c06298365910473af0a8d8e01ef58a,11,6,2,8313,,,0,"Add get_supported_vnic_types to MechanismDriver

Change-Id: Ic2f7d63f02d5e874d469e29d11110c7ffe8ce5d7
Partial-Bug: #1578989
See-Also: https://review.openstack.org/502306 (nova spec)
See-Also: https://review.openstack.org/508149 (neutron spec)
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/79/605079/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-get-supported-vnic-types-to-MechanismDriver-fbe0bc9b68d5e329.yaml', 'neutron_lib/plugins/ml2/api.py']",2,278bb4ea9aae0841ef6d86ecd65e6cb3be55e9b6,minimum-bandwidth-allocation-placement-api," def get_supported_vnic_types(self): """"""Return the mechanism driver's supported vnic_types."""""" return self.supported_vnic_types ",,9,0
openstack%2Fironic-python-agent-builder~master~I906e387d8f389b4c9718feac96cdede1ffb7487b,openstack/ironic-python-agent-builder,master,I906e387d8f389b4c9718feac96cdede1ffb7487b,import zuul job settings from project-config,MERGED,2018-08-16 13:52:24.000000000,2018-09-28 12:17:42.000000000,2018-09-28 12:17:42.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-16 13:52:24.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3f186b64639f3f2d15f79856de50e0374ceeccbf', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I906e387d8f389b4c9718feac96cdede1ffb7487b\nStory: #2002586\nTask: #24302\n'}]",0,592396,3f186b64639f3f2d15f79856de50e0374ceeccbf,8,3,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I906e387d8f389b4c9718feac96cdede1ffb7487b
Story: #2002586
Task: #24302
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/96/592396/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3f186b64639f3f2d15f79856de50e0374ceeccbf,python3-first,- project: templates: - publish-openstack-sphinx-docs - check-requirements - release-notes-jobs check: jobs: - openstack-tox-pep8 gate: jobs: - openstack-tox-pep8 post: jobs: - publish-openstack-python-branch-tarball ,,14,0
openstack%2Ftripleo-heat-templates~master~I4e52bdc18885f13793550e5032fb1316a13b248c,openstack/tripleo-heat-templates,master,I4e52bdc18885f13793550e5032fb1316a13b248c,"Remove ""when failed"" from debug task names",MERGED,2018-08-30 16:09:15.000000000,2018-09-28 12:14:39.000000000,2018-09-28 00:54:50.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-30 16:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9be37f0c8234bb391d82830b1207e429a6c60ed2', 'message': 'Remove ""when failed"" from debug task names\n\nThis commit removes the ""when failed"" from the task title to eliminate\nconfusion.\n\nThese tasks always run to show the debug output for the previous task,\nregardless of whether the the previous task failed or not. They will\nshow the debug output as long as the previous task finished (success or\nfailure).\n\nChange-Id: I4e52bdc18885f13793550e5032fb1316a13b248c\n'}, {'number': 2, 'created': '2018-09-17 23:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/78492b8e1d1805ad67a98a5b292da564f77cf5dc', 'message': 'Remove ""when failed"" from debug task names\n\nThis commit removes the ""when failed"" from the task title to eliminate\nconfusion.\n\nThese tasks always run to show the debug output for the previous task,\nregardless of whether the the previous task failed or not. They will\nshow the debug output as long as the previous task finished (success or\nfailure).\n\nChange-Id: I4e52bdc18885f13793550e5032fb1316a13b248c\n'}, {'number': 3, 'created': '2018-09-18 12:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3223f8052670e20cf51710e5cc619877249d9357', 'message': 'Remove ""when failed"" from debug task names\n\nThis commit removes the ""when failed"" from the task title to eliminate\nconfusion.\n\nThese tasks always run to show the debug output for the previous task,\nregardless of whether the the previous task failed or not. They will\nshow the debug output as long as the previous task finished (success or\nfailure).\n\nChange-Id: I4e52bdc18885f13793550e5032fb1316a13b248c\n'}, {'number': 4, 'created': '2018-09-19 18:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1cc5c546fbaa59fc486c4d5c6801248041f9e57b', 'message': 'Remove ""when failed"" from debug task names\n\nThis commit removes the ""when failed"" from the task title to eliminate\nconfusion.\n\nThese tasks always run to show the debug output for the previous task,\nregardless of whether the the previous task failed or not. They will\nshow the debug output as long as the previous task finished (success or\nfailure).\n\nChange-Id: I4e52bdc18885f13793550e5032fb1316a13b248c\n'}, {'number': 5, 'created': '2018-09-24 14:11:36.000000000', 'files': ['common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13aaf52a468bf020ce74ec34bb38ce8c8a908788', 'message': 'Remove ""when failed"" from debug task names\n\nThis commit removes the ""when failed"" from the task title to eliminate\nconfusion.\n\nThese tasks always run to show the debug output for the previous task,\nregardless of whether the the previous task failed or not. They will\nshow the debug output as long as the previous task finished (success or\nfailure).\n\nChange-Id: I4e52bdc18885f13793550e5032fb1316a13b248c\n'}]",0,598221,13aaf52a468bf020ce74ec34bb38ce8c8a908788,39,5,5,7144,,,0,"Remove ""when failed"" from debug task names

This commit removes the ""when failed"" from the task title to eliminate
confusion.

These tasks always run to show the debug output for the previous task,
regardless of whether the the previous task failed or not. They will
show the debug output as long as the previous task finished (success or
failure).

Change-Id: I4e52bdc18885f13793550e5032fb1316a13b248c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/598221/4 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-tasks.yaml'],1,9be37f0c8234bb391d82830b1207e429a6c60ed2,check-mode," - name: ""Debug output for task: Run puppet host configuration for step {{ step }}"" - name: ""Debug output for task: Run docker-puppet tasks (generate config) during step {{ step }}"" - name: ""Debug output for task: Start containers for step {{ step }}"" - name: ""Debug output for task: Run docker-puppet tasks (bootstrap tasks) for step {{ step }}"""," - name: ""Debug output for task which failed: Run puppet host configuration for step {{ step }}"" - name: ""Debug output for task which failed: Run docker-puppet tasks (generate config) during step {{ step }}"" - name: ""Debug output for task which failed: Start containers for step {{ step }}"" - name: ""Debug output for task which failed: Run docker-puppet tasks (bootstrap tasks) for step {{ step }}""",4,4
openstack%2Ftripleo-heat-templates~master~Ic705afbf174b4597d98c2b83041ff88dd8d6664c,openstack/tripleo-heat-templates,master,Ic705afbf174b4597d98c2b83041ff88dd8d6664c,Tag step plays,MERGED,2018-08-31 20:59:49.000000000,2018-09-28 12:14:18.000000000,2018-09-28 00:54:48.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8871}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-31 20:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cb7908e7487b64122fce82b5097c1a0d3fb2f3d1', 'message': ""Tag step plays\n\nThis adds a tag step[1-5] to each of the plays within the jinja2 loop to\ncreate our 5 deployment steps. Using these tags, it's possible to run\nthese plays individually if desired.\n\nChange-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c\n""}, {'number': 2, 'created': '2018-09-17 23:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a03ab75cd1689b1604748c5d0c78851d904fa53c', 'message': ""Tag step plays\n\nThis adds a tag step[1-5] to each of the plays within the jinja2 loop to\ncreate our 5 deployment steps. Using these tags, it's possible to run\nthese plays individually if desired.\n\nChange-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c\n""}, {'number': 3, 'created': '2018-09-18 12:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ca8a63a8b04cf05ee644ba846d2ea13600306e08', 'message': ""Tag step plays\n\nThis adds a tag step[1-5] to each of the plays within the jinja2 loop to\ncreate our 5 deployment steps. Using these tags, it's possible to run\nthese plays individually if desired.\n\nChange-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c\n""}, {'number': 4, 'created': '2018-09-19 18:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/750e110ce69feffadcfb9429f2dbfb61fde8da5f', 'message': ""Tag step plays\n\nThis adds a tag step[1-5] to each of the plays within the jinja2 loop to\ncreate our 5 deployment steps. Using these tags, it's possible to run\nthese plays individually if desired.\n\nChange-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c\n""}, {'number': 5, 'created': '2018-09-24 14:11:36.000000000', 'files': ['releasenotes/notes/tag-step-plays-b1b1ea7584f1665d.yaml', 'common/deploy-steps.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf6efb06c7f15c3577deb8432c12295f40af30a0', 'message': ""Tag step plays\n\nThis adds a tag step[1-5] to each of the plays within the jinja2 loop to\ncreate our 5 deployment steps. Using these tags, it's possible to run\nthese plays individually if desired.\n\nChange-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c\n""}]",2,599072,bf6efb06c7f15c3577deb8432c12295f40af30a0,32,7,5,7144,,,0,"Tag step plays

This adds a tag step[1-5] to each of the plays within the jinja2 loop to
create our 5 deployment steps. Using these tags, it's possible to run
these plays individually if desired.

Change-Id: Ic705afbf174b4597d98c2b83041ff88dd8d6664c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/72/599072/4 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/tag-step-plays-b1b1ea7584f1665d.yaml', 'common/deploy-steps.j2']",2,cb7908e7487b64122fce82b5097c1a0d3fb2f3d1,check-mode, - step{{step}} - step{{step}} - step{{step}},,8,0
openstack%2Ftripleo-common~master~I5df6193a0d72e8b52a2d95e1827173fc74885d37,openstack/tripleo-common,master,I5df6193a0d72e8b52a2d95e1827173fc74885d37,Don't fail tripleo-bootstrap on package installs,MERGED,2018-09-17 17:53:22.000000000,2018-09-28 12:11:50.000000000,2018-09-28 03:57:43.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-17 17:53:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ac0c529d60a4e2cefc7cdcb1ebedbaad2defea0b', 'message': ""Don't fail tripleo-bootstrap on package installs\n\nThis changes the package install task to not fail if there is a problem\ninstalling the bootstrap packages. This is inline with existing\nexpectations that we don't require a working package manager with\nenabled repos on initial images.\n\nA followup task is added which will cause an error if any of the\nrequired bootstrap packages are not already installed.\n\nChange-Id: I5df6193a0d72e8b52a2d95e1827173fc74885d37\nCloses-Bug: #1792994\n""}, {'number': 2, 'created': '2018-09-24 18:04:50.000000000', 'files': ['image-yaml/overcloud-hardened-images-uefi.yaml', 'image-yaml/overcloud-odl-rhel7.yaml', 'image-yaml/overcloud-hardened-images.yaml', 'releasenotes/notes/dont-fail-tripleo-bootstrap-on-package-install-a00cd921b0af7168.yaml', 'roles/tripleo-bootstrap/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/108942079bacd6ebaa5fa5c7ace99c05faa883a8', 'message': ""Don't fail tripleo-bootstrap on package installs\n\nThis changes the package install task to not fail if there is a problem\ninstalling the bootstrap packages. This is inline with existing\nexpectations that we don't require a working package manager with\nenabled repos on initial images.\n\nA followup task is added which will cause an error if any of the\nrequired bootstrap packages are not already installed.\n\nThis patch also fixes the image yaml files that were not using the\nparent package openstack-heat-agents which uncovered this issue.\n\nChange-Id: I5df6193a0d72e8b52a2d95e1827173fc74885d37\nCloses-Bug: #1792994\n""}]",1,603196,108942079bacd6ebaa5fa5c7ace99c05faa883a8,24,7,2,7144,,,0,"Don't fail tripleo-bootstrap on package installs

This changes the package install task to not fail if there is a problem
installing the bootstrap packages. This is inline with existing
expectations that we don't require a working package manager with
enabled repos on initial images.

A followup task is added which will cause an error if any of the
required bootstrap packages are not already installed.

This patch also fixes the image yaml files that were not using the
parent package openstack-heat-agents which uncovered this issue.

Change-Id: I5df6193a0d72e8b52a2d95e1827173fc74885d37
Closes-Bug: #1792994
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/96/603196/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/dont-fail-tripleo-bootstrap-on-package-install-a00cd921b0af7168.yaml', 'roles/tripleo-bootstrap/tasks/main.yml']",2,ac0c529d60a4e2cefc7cdcb1ebedbaad2defea0b,600183, ignore_errors: true - name: Check required packages are installed command: rpm -q python-heat-agent python-heat-agent-puppet python-heat-agent-hiera python-heat-agent-ansible,,13,0
openstack%2Fopenstack-planet~master~I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2,openstack/openstack-planet,master,I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2,Add iranzo to Planet OpenStack,MERGED,2018-09-28 05:51:19.000000000,2018-09-28 12:10:48.000000000,2018-09-28 12:10:47.000000000,"[{'_account_id': 308}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 9061}, {'_account_id': 16448}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 05:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/608fe1099da9d394f9c338b0f252b2ac89779c3d', 'message': 'Add iranzo to Planet OpenStack\n\nChange-Id: I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2\n'}, {'number': 2, 'created': '2018-09-28 09:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/7585bcb27e698b32d6374998616d6752dc39ce2f', 'message': 'Add iranzo to Planet OpenStack\n\nChange-Id: I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2\n'}, {'number': 3, 'created': '2018-09-28 10:45:59.000000000', 'files': ['images/iranzo.jpg', 'planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/933d72cd4e4a19c9a53d9560d6824086ebd75b87', 'message': 'Add iranzo to Planet OpenStack\n\nChange-Id: I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2\nSigned-off-by: Pablo Iranzo Gmez <Pablo.Iranzo@gmail.com>\n'}]",0,605920,933d72cd4e4a19c9a53d9560d6824086ebd75b87,11,6,3,16448,,,0,"Add iranzo to Planet OpenStack

Change-Id: I5ed71e2225ced0bc44aee6056a54bcd97a8f35c2
Signed-off-by: Pablo Iranzo Gmez <Pablo.Iranzo@gmail.com>
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/20/605920/1 && git format-patch -1 --stdout FETCH_HEAD,"['images/iranzo.jpg', 'planet.ini']",2,608fe1099da9d394f9c338b0f252b2ac89779c3d,add-iranzo, [https://iranzo.github.io/feeds/tag_openstack.rss] name = Pablo Iranzo Gmez face = iranzo.jpg nick = iranzo,,5,0
openstack%2Fopenstack-ansible~master~I90a90f2ff6c99ba9b2317d33246382d4d13a09be,openstack/openstack-ansible,master,I90a90f2ff6c99ba9b2317d33246382d4d13a09be,Unfreeze networking-odl,MERGED,2018-09-13 06:34:48.000000000,2018-09-28 12:04:47.000000000,2018-09-28 12:04:47.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-13 06:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/371eb1a3f5e3bb0a70286d5b472a0a19b51309fc', 'message': 'Unfreeze networking-odl and networking-bgpvpn\n\nThe problem is gone because ceilometer is already installed by this\npatch:\n\nhttps://review.openstack.org/#/c/569949/\n\nNote that ceilometer library is needed in networking_odl in order to\ncollect statistics from the network:\n\nhttps://github.com/openstack/networking-odl/tree/master/networking_odl/ceilometer/network/statistics/opendaylight_v2\n\nChange-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 2, 'created': '2018-09-21 12:47:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/269d4eea68882455550a68a976950daa17919853', 'message': 'Unfreeze networking-odl\n\nThe problem is gone because ceilometer is already installed by this\npatch:\n\nhttps://review.openstack.org/#/c/569949/\n\nand ceilometer_git_project_group: all after this patch:\n\nhttps://review.openstack.org/#/c/603400/1/playbooks/defaults/repo_packages/openstack_services.yml\n\nwhich means ceilometer will get installed when deploying n-odl and thus\nsatisfying the requirements. ceilometer_git_project_group will be\nchanged back to ceilometer_all as soon as this patch gets merged:\n\nhttps://review.openstack.org/#/c/602622/\n\nChange-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 3, 'created': '2018-09-21 12:57:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6214ebdcd2297546a5d08274701852cf0094a385', 'message': 'Unfreeze networking-odl\n\nThe problem is gone because ceilometer is already installed by this\npatch:\n\nhttps://review.openstack.org/#/c/569949/\n\nand ceilometer_git_project_group: all after this patch:\n\nhttps://review.openstack.org/#/c/603400/1/playbooks/defaults/repo_packages/openstack_services.yml\n\nwhich means ceilometer will get installed when deploying n-odl and thus\nsatisfying the requirements. ceilometer_git_project_group will be\nchanged back to ceilometer_all as soon as this patch gets merged:\n\nhttps://review.openstack.org/#/c/602622/\n\nChange-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 4, 'created': '2018-09-21 15:39:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c92485b7e72f28280c4d52dc03aecd93deb61d3a', 'message': 'Unfreeze networking-odl\n\nThe problem is gone because ceilometer is already installed by this\npatch:\n\nhttps://review.openstack.org/#/c/569949/\n\nand ceilometer_git_project_group: all after this patch:\n\nhttps://review.openstack.org/#/c/603400/1/playbooks/defaults/repo_packages/openstack_services.yml\n\nwhich means ceilometer will get installed when deploying n-odl and thus\nsatisfying the requirements. ceilometer_git_project_group will be\nchanged back to ceilometer_all as soon as this patch gets merged:\n\nhttps://review.openstack.org/#/c/602622/\n\nChange-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}, {'number': 5, 'created': '2018-09-24 07:36:57.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ef43604882091c9f808837bb99ad6737a19faa96', 'message': 'Unfreeze networking-odl\n\nThe problem is gone because ceilometer is already installed by this\npatch:\n\nhttps://review.openstack.org/#/c/569949/\n\nand ceilometer_git_project_group: all after this patch:\n\nhttps://review.openstack.org/#/c/603400/1/playbooks/defaults/repo_packages/openstack_services.yml\n\nwhich means ceilometer will get installed when deploying n-odl and thus\nsatisfying the requirements. ceilometer_git_project_group will be\nchanged back to ceilometer_all as soon as this patch gets merged:\n\nhttps://review.openstack.org/#/c/602622/\n\nChange-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be\nSigned-off-by: Manuel Buil <mbuil@suse.com>\n'}]",3,602243,ef43604882091c9f808837bb99ad6737a19faa96,21,6,5,21883,,,0,"Unfreeze networking-odl

The problem is gone because ceilometer is already installed by this
patch:

https://review.openstack.org/#/c/569949/

and ceilometer_git_project_group: all after this patch:

https://review.openstack.org/#/c/603400/1/playbooks/defaults/repo_packages/openstack_services.yml

which means ceilometer will get installed when deploying n-odl and thus
satisfying the requirements. ceilometer_git_project_group will be
changed back to ceilometer_all as soon as this patch gets merged:

https://review.openstack.org/#/c/602622/

Change-Id: I90a90f2ff6c99ba9b2317d33246382d4d13a09be
Signed-off-by: Manuel Buil <mbuil@suse.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/43/602243/5 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/defaults/repo_packages/openstack_services.yml'],1,371eb1a3f5e3bb0a70286d5b472a0a19b51309fc,,"networking_odl_git_install_branch: ecde0a165f6145d8257fd52d50ee6f417b0b6ff0 # HEAD of ""master"" as of 08.08.2018networking_bgpvpn_git_install_branch: dda00b209e4f31a1344908e358767b007d9bb53d # HEAD of ""master"" as of 08.08.2018","# ODL is frozen until further notice due to # https://github.com/openstack/networking-odl/commit/391c1d89ef2b8133d3aafbe7612c7908be106e73#diff-b4ef698db8ca845e5845c4618278f29anetworking_odl_git_install_branch: 53ff740b2a78626d5b077278997bdcec6b1b0892 # FROZEN HEAD of ""master"" as of 31.03.2018# BGPVPN is frozen until further notice due to # https://github.com/openstack/networking-bgpvpn/commit/e9a0ea199b47f76f69545e04bdb4db44869c388b#diff-b4ef698db8ca845e5845c4618278f29anetworking_bgpvpn_git_install_branch: 3b93ddacd390d92fb144e5660324d4da064ad9a4 # FROZEN HEAD of ""master"" as of 31.03.2018",2,6
openstack%2Ftripleo-heat-templates~master~Ia7476da222218411caddae887f99c029b4bccf23,openstack/tripleo-heat-templates,master,Ia7476da222218411caddae887f99c029b4bccf23,Tag tasks in in common tasks,MERGED,2018-09-17 23:48:23.000000000,2018-09-28 11:37:13.000000000,2018-09-28 11:37:13.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8871}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-17 23:48:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d6d2ebde4bdd36456f42688fd1290d7279c2e283', 'message': ""Tag tasks in in common tasks\n\nAdds the following tags to relevant tasks in deploy-steps-tasks.yaml\nthat are common to all roles:\n\n- host_config\n- container_config\n- container_config_tasks\n- container_config_scripts\n- container_startup_configs\n\nThe tags are tool agnostic, so hopefully they won't have to be updated\nover time. They allow users to run only specific parts of the common\ntasks.\n\nChange-Id: Ia7476da222218411caddae887f99c029b4bccf23\n""}, {'number': 2, 'created': '2018-09-18 12:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f3ca27467b97c2149e7cfacc6c56f2735abb5047', 'message': ""Tag tasks in in common tasks\n\nAdds the following tags to relevant tasks in deploy-steps-tasks.yaml\nthat are common to all roles:\n\n- host_config\n- container_config\n- container_config_tasks\n- container_config_scripts\n- container_startup_configs\n\nThe tags are tool agnostic, so hopefully they won't have to be updated\nover time. They allow users to run only specific parts of the common\ntasks.\n\nChange-Id: Ia7476da222218411caddae887f99c029b4bccf23\n""}, {'number': 3, 'created': '2018-09-19 18:46:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4df7cf4aab09beb281c51804f7871242e5cc4db4', 'message': ""Tag tasks in in common tasks\n\nAdds the following tags to relevant tasks in deploy-steps-tasks.yaml\nthat are common to all roles:\n\n- host_config\n- container_config\n- container_config_tasks\n- container_config_scripts\n- container_startup_configs\n\nThe tags are tool agnostic, so hopefully they won't have to be updated\nover time. They allow users to run only specific parts of the common\ntasks.\n\nChange-Id: Ia7476da222218411caddae887f99c029b4bccf23\n""}, {'number': 4, 'created': '2018-09-24 14:11:36.000000000', 'files': ['releasenotes/notes/tag-common-tasks-4a78275787655fdd.yaml', 'common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/961fdc22ee19a4c6d61a3de7ab08540662825303', 'message': ""Tag tasks in in common tasks\n\nAdds the following tags to relevant tasks in deploy-steps-tasks.yaml\nthat are common to all roles:\n\n- host_config\n- container_config\n- container_config_tasks\n- container_config_scripts\n- container_startup_configs\n\nThe tags are tool agnostic, so hopefully they won't have to be updated\nover time. They allow users to run only specific parts of the common\ntasks.\n\nChange-Id: Ia7476da222218411caddae887f99c029b4bccf23\n""}]",1,603250,961fdc22ee19a4c6d61a3de7ab08540662825303,26,7,4,7144,,,0,"Tag tasks in in common tasks

Adds the following tags to relevant tasks in deploy-steps-tasks.yaml
that are common to all roles:

- host_config
- container_config
- container_config_tasks
- container_config_scripts
- container_startup_configs

The tags are tool agnostic, so hopefully they won't have to be updated
over time. They allow users to run only specific parts of the common
tasks.

Change-Id: Ia7476da222218411caddae887f99c029b4bccf23
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/603250/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/tag-common-tasks-4a78275787655fdd.yaml', 'common/deploy-steps-tasks.yaml']",2,d6d2ebde4bdd36456f42688fd1290d7279c2e283,check-mode," tags: - host_config - container_config - container_config_tasks - container_config_scripts - container_startup_configs tags: - host_config tags: - container_config tags: - container_config tags: - container_config_scripts tags: - container_startup_configs tags: - container_config_scripts tags: - container_startup_configs tags: - container_startup_configs tags: - container_startup_configs tags: - container_startup_configs tags: - container_startup_configs tags: - container_startup_configs tags: - container_config_tasks tags: - container_config_tasks host_config_config_debug: ""--debug --verbose"" tags: - host_config tags: - host_config puppet apply {{ host_config_config_debug | default('') }} tags: - host_config tags: - host_config tags: - container_config tags: - container_config tags: - container_startup_configs tags: - container_startup_configs tags: - container_config_tasks tags: - container_config_tasks tags: - container_config_tasks"," host_puppet_config_debug: ""--debug --verbose"" puppet apply {{ host_puppet_config_debug | default('') }}",64,3
openstack%2Ftripleo-common~master~Ic0333c0726b16d284a7cc54bc68e16ea1c9ebc4d,openstack/tripleo-common,master,Ic0333c0726b16d284a7cc54bc68e16ea1c9ebc4d,Handle non-existant plan when getting deployment status,MERGED,2018-09-14 21:02:14.000000000,2018-09-28 11:29:26.000000000,2018-09-28 00:54:55.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-14 21:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/2dceb57ca929f5c6053ed50d6ab5af6ab3073c50', 'message': 'Handle non-existant plan when getting deployment status\n\nInstead of failing the workflow when requesting the deployment status of\na non-existant plan, return a useful message instead.\n\nChange-Id: Ic0333c0726b16d284a7cc54bc68e16ea1c9ebc4d\nPartial-Bug: #1792637\n'}, {'number': 2, 'created': '2018-09-24 18:04:50.000000000', 'files': ['workbooks/deployment.yaml', 'releasenotes/notes/handle-no-deployment-status-a70a4b950171afbe.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/1e13e461cd4e5a1187cd8182ec74e8a5eb576e59', 'message': 'Handle non-existant plan when getting deployment status\n\nInstead of failing the workflow when requesting the deployment status of\na non-existant plan, return a useful message instead.\n\nChange-Id: Ic0333c0726b16d284a7cc54bc68e16ea1c9ebc4d\nPartial-Bug: #1792637\n'}]",0,602753,1e13e461cd4e5a1187cd8182ec74e8a5eb576e59,18,7,2,7144,,,0,"Handle non-existant plan when getting deployment status

Instead of failing the workflow when requesting the deployment status of
a non-existant plan, return a useful message instead.

Change-Id: Ic0333c0726b16d284a7cc54bc68e16ea1c9ebc4d
Partial-Bug: #1792637
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/53/602753/2 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/deployment.yaml', 'releasenotes/notes/handle-no-deployment-status-a70a4b950171afbe.yaml']",2,2dceb57ca929f5c6053ed50d6ab5af6ab3073c50,600183,--- fixes: - The tripleo.deployment.v1.get_deployment_status workflow will no longer error when requesting the deployment status for a non-existant plan. A message is sent in the output instead of failing the workflow. ,,7,2
openstack%2Fpython-openstackclient~master~I377a018a4e3c7b6fa44ce9323d1ee2edbd0e4728,openstack/python-openstackclient,master,I377a018a4e3c7b6fa44ce9323d1ee2edbd0e4728,Add monascaclient to `not plugins` list,MERGED,2018-09-28 08:45:19.000000000,2018-09-28 11:08:33.000000000,2018-09-28 11:08:33.000000000,"[{'_account_id': 6482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 08:45:19.000000000', 'files': ['doc/source/contributor/plugins.rst'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/424ab43a0e2b7c0dbffdbf9e410e887e1abb0295', 'message': 'Add monascaclient to `not plugins` list\n\nChange-Id: I377a018a4e3c7b6fa44ce9323d1ee2edbd0e4728\n'}]",0,606002,424ab43a0e2b7c0dbffdbf9e410e887e1abb0295,6,2,1,16222,,,0,"Add monascaclient to `not plugins` list

Change-Id: I377a018a4e3c7b6fa44ce9323d1ee2edbd0e4728
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/02/606002/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/plugins.rst'],1,424ab43a0e2b7c0dbffdbf9e410e887e1abb0295,,- python-monascaclient,,1,0
openstack%2Fnetworking-ovn~stable%2Fpike~I9dca4ba494082a0bf37833b13b05609c715a492d,openstack/networking-ovn,stable/pike,I9dca4ba494082a0bf37833b13b05609c715a492d,Fix stable/pike gate,MERGED,2018-08-23 18:10:04.000000000,2018-09-28 11:04:44.000000000,2018-09-28 11:04:44.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-08-23 18:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/49edf807e7f8e886df6b8818bd3722b8a39046ee', 'message': ""Fix gate: PEP8 and ovs-master jobs\n\nThis patch is fixing the by:\n\n1. Update code to reflect stricter PEP8 handling\n\n2. Adding a /bin/bash in front of the ovn-ctl commands.\n\nThe reason for 2. still unknown to me, perhaps something has changed in\nUbuntu Xenial (it doens't fail on CentOS for example) which was causing\nthe error below:\n\n$ /usr/local/share/openvswitch/scripts/ovn-ctl --no-monitor start_northd\n/usr/local/share/openvswitch/scripts/ovn-ctl: 1: local: -vfile:info: bad\nvariable name\n\nBackport note:\nThe original patch in master branch included some hack for OVS. At the\nmoment of the cherry-pick, OVS was fixed so I removed it in\ndevstack/lib/networking-ovn.\n\nConflicts:\n\tdevstack/lib/networking-ovn\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/5c198d2723b6_add_ovn_revision_resource_type_as_pk.py\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/f48286668608_add_ovn_revision_numbers_table.py\n\tnetworking_ovn/journal/exceptions.py\n\tnetworking_ovn/ovsdb/impl_idl_ovn.py\n\nChange-Id: I9dca4ba494082a0bf37833b13b05609c715a492d\n(cherry picked from commit 1af6ea97bbba0b08f63ece59569ebc398a0721a7)\n(cherry picked from commit c7c16d41f82b2b245d42abdf1a73e0281dc7727e)\n""}, {'number': 2, 'created': '2018-08-23 18:42:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/55fe7c5dbc81ba0a4bc58d89dafa56e97513a650', 'message': ""Fix gate: PEP8 and ovs-master jobs\n\nThis patch is fixing the by:\n\n1. Update code to reflect stricter PEP8 handling\n\n2. Adding a /bin/bash in front of the ovn-ctl commands.\n\nThe reason for 2. still unknown to me, perhaps something has changed in\nUbuntu Xenial (it doens't fail on CentOS for example) which was causing\nthe error below:\n\n$ /usr/local/share/openvswitch/scripts/ovn-ctl --no-monitor start_northd\n/usr/local/share/openvswitch/scripts/ovn-ctl: 1: local: -vfile:info: bad\nvariable name\n\nBackport note:\nThe original patch in master branch included some hack for OVS. At the\nmoment of the cherry-pick, OVS was fixed so I removed it in\ndevstack/lib/networking-ovn.\n\nConflicts:\n\tdevstack/lib/networking-ovn\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/5c198d2723b6_add_ovn_revision_resource_type_as_pk.py\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/f48286668608_add_ovn_revision_numbers_table.py\n\tnetworking_ovn/journal/exceptions.py\n\tnetworking_ovn/ovsdb/impl_idl_ovn.py\n\nChange-Id: I9dca4ba494082a0bf37833b13b05609c715a492d\n(cherry picked from commit 1af6ea97bbba0b08f63ece59569ebc398a0721a7)\n(cherry picked from commit c7c16d41f82b2b245d42abdf1a73e0281dc7727e)\n""}, {'number': 3, 'created': '2018-09-04 15:51:57.000000000', 'files': ['zuul.d/networkin-ovn-rally-task.yaml', 'networking_ovn/agent/metadata/server.py', '.gitignore', 'test-requirements.txt', 'networking_ovn/tests/unit/ovsdb/test_impl_idl_ovn.py', 'networking_ovn/db/migration/alembic_migrations/versions/pike/expand/e229b8aad9f2_add_journal_and_maintenance_tables.py', 'playbooks/legacy/rally-dsvm-networking-ovn/run.yaml', 'networking_ovn/db/migration/alembic_migrations/script.py.mako', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'tools/tox_install.sh', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/tests/contrib/post_test_hook.sh', 'playbooks/legacy/rally-dsvm-networking-ovn/post.yaml', 'zuul.d/legacy-networking-ovn-jobs.yaml', 'zuul.d/project.yaml', '.stestr.conf', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/386543b978b869c529c531fc7126b537e0f52c37', 'message': ""Fix stable/pike gate\n\nThis patch is fixing the by:\n\n1. Update code to reflect stricter PEP8 handling\n\n2. Adding a /bin/bash in front of the ovn-ctl commands.\n\n3. Use a native zuul v3 job for rally\n\n4. Fix post gate hook to accommodate for new os-testr\n\nThe reason for 2. still unknown to me, perhaps something has changed in\nUbuntu Xenial (it doens't fail on CentOS for example) which was causing\nthe error below:\n\n$ /usr/local/share/openvswitch/scripts/ovn-ctl --no-monitor start_northd\n/usr/local/share/openvswitch/scripts/ovn-ctl: 1: local: -vfile:info: bad\nvariable name\n\nBackport note:\nThe original patch in master branch included some hack for OVS. At the\nmoment of the cherry-pick, OVS was fixed so I removed it in\ndevstack/lib/networking-ovn.\n\nConflicts:\n\tdevstack/lib/networking-ovn\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/5c198d2723b6_add_ovn_revision_resource_type_as_pk.py\n\tnetworking_ovn/db/migration/alembic_migrations/versions/queens/expand/f48286668608_add_ovn_revision_numbers_table.py\n\tnetworking_ovn/journal/exceptions.py\n\tnetworking_ovn/ovsdb/impl_idl_ovn.py\n\nChange-Id: I9dca4ba494082a0bf37833b13b05609c715a492d\n(cherry picked from commit 1af6ea97bbba0b08f63ece59569ebc398a0721a7)\n(cherry picked from commit c7c16d41f82b2b245d42abdf1a73e0281dc7727e)\n""}]",0,595853,386543b978b869c529c531fc7126b537e0f52c37,18,5,3,5756,,,0,"Fix stable/pike gate

This patch is fixing the by:

1. Update code to reflect stricter PEP8 handling

2. Adding a /bin/bash in front of the ovn-ctl commands.

3. Use a native zuul v3 job for rally

4. Fix post gate hook to accommodate for new os-testr

The reason for 2. still unknown to me, perhaps something has changed in
Ubuntu Xenial (it doens't fail on CentOS for example) which was causing
the error below:

$ /usr/local/share/openvswitch/scripts/ovn-ctl --no-monitor start_northd
/usr/local/share/openvswitch/scripts/ovn-ctl: 1: local: -vfile:info: bad
variable name

Backport note:
The original patch in master branch included some hack for OVS. At the
moment of the cherry-pick, OVS was fixed so I removed it in
devstack/lib/networking-ovn.

Conflicts:
	devstack/lib/networking-ovn
	networking_ovn/db/migration/alembic_migrations/versions/queens/expand/5c198d2723b6_add_ovn_revision_resource_type_as_pk.py
	networking_ovn/db/migration/alembic_migrations/versions/queens/expand/f48286668608_add_ovn_revision_numbers_table.py
	networking_ovn/journal/exceptions.py
	networking_ovn/ovsdb/impl_idl_ovn.py

Change-Id: I9dca4ba494082a0bf37833b13b05609c715a492d
(cherry picked from commit 1af6ea97bbba0b08f63ece59569ebc398a0721a7)
(cherry picked from commit c7c16d41f82b2b245d42abdf1a73e0281dc7727e)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/53/595853/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/agent/metadata/server.py', 'networking_ovn/tests/unit/ml2/test_mech_driver.py', 'tools/tox_install.sh', 'networking_ovn/ovsdb/impl_idl_ovn.py', 'networking_ovn/tests/unit/ovsdb/test_impl_idl_ovn.py', 'networking_ovn/db/migration/alembic_migrations/versions/pike/expand/e229b8aad9f2_add_journal_and_maintenance_tables.py', 'networking_ovn/db/migration/alembic_migrations/script.py.mako', 'releasenotes/source/conf.py']",8,49edf807e7f8e886df6b8818bd3722b8a39046ee,, from networking_ovn.version import version_info as ovn_version ,# The short X.Y version. from networking_ovn.version import version_info as ovn_version,28,26
openstack%2Fcompute-hyperv~master~I2d70b3d96f630507adba770d4d4ccf4c9d4e8d01,openstack/compute-hyperv,master,I2d70b3d96f630507adba770d4d4ccf4c9d4e8d01,Switch nova uuidsentinel with oslo_utils' uuidsentinel,MERGED,2018-09-28 09:02:40.000000000,2018-09-28 10:55:00.000000000,2018-09-28 10:55:00.000000000,"[{'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 09:02:40.000000000', 'files': ['compute_hyperv/tests/unit/test_imagecache.py'], 'web_link': 'https://opendev.org/openstack/compute-hyperv/commit/87fdd92f3d4bcc9d98ac1da20c5c1dcb0ddb5f81', 'message': ""Switch nova uuidsentinel with oslo_utils' uuidsentinel\n\nuuidsentinel has been removed from nova in favor of the oslo_utils\none.\n\nChange-Id: I2d70b3d96f630507adba770d4d4ccf4c9d4e8d01\n""}]",0,606008,87fdd92f3d4bcc9d98ac1da20c5c1dcb0ddb5f81,6,2,1,8213,,,0,"Switch nova uuidsentinel with oslo_utils' uuidsentinel

uuidsentinel has been removed from nova in favor of the oslo_utils
one.

Change-Id: I2d70b3d96f630507adba770d4d4ccf4c9d4e8d01
",git fetch https://review.opendev.org/openstack/compute-hyperv refs/changes/08/606008/1 && git format-patch -1 --stdout FETCH_HEAD,['compute_hyperv/tests/unit/test_imagecache.py'],1,87fdd92f3d4bcc9d98ac1da20c5c1dcb0ddb5f81,,from oslo_utils.fixture import uuidsentinel as uuids,from nova.tests import uuidsentinel as uuids,1,1
openstack%2Fhorizon~master~I7aeeddf838923d110703bfd7a04699b056c2abd5,openstack/horizon,master,I7aeeddf838923d110703bfd7a04699b056c2abd5,Move to 404 page if specified navigation not found,MERGED,2018-07-04 09:48:40.000000000,2018-09-28 10:43:25.000000000,2018-09-28 10:43:25.000000000,"[{'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 16352}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 27336}, {'_account_id': 27822}, {'_account_id': 28957}]","[{'number': 1, 'created': '2018-07-04 09:48:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5491220e763719c9e36be0fe4f7509738812b4db', 'message': 'Move to 404 page if specified navigation not found\n\nWhen refresh or link directly to ngdetails without correct navigation\nto be set, ngdetails view can not reproduce navigations, i.e. sidebar\nand breadcrumb.\ne.g. when the ordinary user try to open the URL specified as admin side.\n\nIn this situation, ngdetails view should show 404 page.\nSo this patch move to 404 page if the navigation does not exist.\n\nChange-Id: I7aeeddf838923d110703bfd7a04699b056c2abd5\nCloses-Bug: #1761036\n'}, {'number': 2, 'created': '2018-07-10 00:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/020a7d24b5c5848865782440dc91c14784748e36', 'message': 'Move to 404 page if specified navigation not found\n\nWhen refresh or link directly to ngdetails without correct navigation\nto be set, ngdetails view can not reproduce navigations, i.e. sidebar\nand breadcrumb.\ne.g. when the ordinary user try to open the URL specified as admin side.\n\nIn this situation, ngdetails view should show 404 page.\nSo this patch move to 404 page if the navigation does not exist.\n\nChange-Id: I7aeeddf838923d110703bfd7a04699b056c2abd5\nCloses-Bug: #1761036\n'}, {'number': 3, 'created': '2018-07-24 00:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cf1489a64af505e2eded15236c0e176796ee8638', 'message': 'Move to 404 page if specified navigation not found\n\nWhen refresh or link directly to ngdetails without correct navigation\nto be set, ngdetails view can not reproduce navigations, i.e. sidebar\nand breadcrumb.\ne.g. when the ordinary user try to open the URL specified as admin side.\n\nIn this situation, ngdetails view should show 404 page.\nSo this patch move to 404 page if the navigation does not exist.\n\nChange-Id: I7aeeddf838923d110703bfd7a04699b056c2abd5\nCloses-Bug: #1761036\n'}, {'number': 4, 'created': '2018-09-26 14:23:26.000000000', 'files': ['horizon/static/framework/util/navigations/navigations.service.js', 'horizon/static/framework/util/navigations/navigations.service.spec.js', 'horizon/static/framework/widgets/details/routed-details-view.controller.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/8c03ce0bcc56631752da0cfb6d3fdf261b238a20', 'message': 'Move to 404 page if specified navigation not found\n\nWhen refresh or link directly to ngdetails without correct navigation\nto be set, ngdetails view can not reproduce navigations, i.e. sidebar\nand breadcrumb.\ne.g. when the ordinary user try to open the URL specified as admin side.\n\nIn this situation, ngdetails view should show 404 page.\nSo this patch move to 404 page if the navigation does not exist.\n\nChange-Id: I7aeeddf838923d110703bfd7a04699b056c2abd5\nCloses-Bug: #1761036\n'}]",0,580113,8c03ce0bcc56631752da0cfb6d3fdf261b238a20,31,9,4,16352,,,0,"Move to 404 page if specified navigation not found

When refresh or link directly to ngdetails without correct navigation
to be set, ngdetails view can not reproduce navigations, i.e. sidebar
and breadcrumb.
e.g. when the ordinary user try to open the URL specified as admin side.

In this situation, ngdetails view should show 404 page.
So this patch move to 404 page if the navigation does not exist.

Change-Id: I7aeeddf838923d110703bfd7a04699b056c2abd5
Closes-Bug: #1761036
",git fetch https://review.opendev.org/openstack/horizon refs/changes/13/580113/3 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/util/navigations/navigations.service.js', 'horizon/static/framework/util/navigations/navigations.service.spec.js', 'horizon/static/framework/widgets/details/routed-details-view.controller.js']",3,5491220e763719c9e36be0fe4f7509738812b4db,bug/1761036, // check navigation from url if (!navigationsService.isNavigationExists(url)) { pageNotFound(); },,23,1
openstack%2Fcinder~master~Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960,openstack/cinder,master,Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960,Fix multiattach set to false after retype,ABANDONED,2018-09-20 11:08:02.000000000,2018-09-28 10:39:54.000000000,,"[{'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9535}, {'_account_id': 9732}, {'_account_id': 10058}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23561}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-20 11:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/12acd67e500fc213e7bc9a4bc4269b9c334e08b8', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}, {'number': 2, 'created': '2018-09-20 18:11:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/5b9e6a75c534cfdffafb1b81abff136da1a0e0e2', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}, {'number': 3, 'created': '2018-09-24 04:38:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4b330d582a96ab8544e302a0220e7cdd79b7df92', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}, {'number': 4, 'created': '2018-09-24 12:18:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/51119d90ea5d6f3d33a3c99f07dd0f940d9e0383', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}, {'number': 5, 'created': '2018-09-25 18:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4f52fb41b07a0e1de93b2d076aec66f37a021f95', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}, {'number': 6, 'created': '2018-09-26 14:24:56.000000000', 'files': ['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_volume_migration.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/b9dc2c1325024edcdd8b7d1ea7f460f16853b848', 'message': 'Fix multiattach set to false after retype\n\nWhenever we retype a volume within the same backend, the multiattach\nfield is not updated and is set to false (irrespective of the volume\ntype specified in the extra-specs).\nThis patch assigns the multiattach to the value in volume type it\nis being retyped to.\n\nChange-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960\nCloses-Bug: 1790840\n'}]",5,604040,b9dc2c1325024edcdd8b7d1ea7f460f16853b848,164,38,6,27615,,,0,"Fix multiattach set to false after retype

Whenever we retype a volume within the same backend, the multiattach
field is not updated and is set to false (irrespective of the volume
type specified in the extra-specs).
This patch assigns the multiattach to the value in volume type it
is being retyped to.

Change-Id: Idc03bf9bb02c70d7a143f91d57e0d255ce5c0960
Closes-Bug: 1790840
",git fetch https://review.opendev.org/openstack/cinder refs/changes/40/604040/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/manager.py', 'cinder/tests/unit/volume/test_volume_migration.py']",2,12acd67e500fc213e7bc9a4bc4269b9c334e08b8,bug/1790840," replica_new=None, multiattach=False): if multiattach: new_specs['multiattach'] = '<is> True' elif multiattach: self.assertEqual(vol_type['id'], volume.volume_type_id) self.assertEqual('available', volume.status) self.assertEqual(CONF.host, volume.host) self.assertEqual(1, volumes_in_use) self.assertTrue(volume.multiattach) self.assert_notify_called(mock_notify, (['INFO', 'volume.retype'],)) def test_retype_volume_multiattach(self): self._retype_volume_exec(False, multiattach=True) ", replica_new=None):,20,2
openstack%2Fkolla-ansible~stable%2Focata~Iae8451e70d1f77993b9c0732f719fe8388b96bca,openstack/kolla-ansible,stable/ocata,Iae8451e70d1f77993b9c0732f719fe8388b96bca,Add warning while upgrading with dockerhub images N->O,ABANDONED,2017-06-20 13:49:53.000000000,2018-09-28 10:33:53.000000000,,"[{'_account_id': 3}, {'_account_id': 6488}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 26355}, {'_account_id': 28003}]","[{'number': 1, 'created': '2017-06-20 13:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/364122c7b00c84407e3dd79415d77e1ef6457e55', 'message': 'Add warning while upgrading with dockerhub images N->O\n\nMinimun nova version needed for upgrade from newton to\nocata is 14.0.4. Binary images published in dockerhub\ncame with 14.0.3 installed on it. This is caused because\nwe released the images before packages promoted the fix\nto stable versions.\n\nManually building images is fine since current nova release from\nrepositories is > 14.0.4\n\nChange-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca\nCloses-Bug: #1699153\n'}, {'number': 2, 'created': '2017-06-20 14:00:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/65ddb7d00ec11a96293a04d3f2478ca3a42f7497', 'message': 'Add warning while upgrading with dockerhub images N->O\n\nMinimun nova version needed for upgrade from newton to\nocata is 14.0.4. Binary images published in dockerhub\ncame with 14.0.3 installed on it. This is caused because\nwe released the images before packages promoted the fix\nto stable versions.\n\nManually building images is fine since current nova release from\nrepositories is > 14.0.4\n\nChange-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca\nCloses-Bug: #1699153\n'}, {'number': 3, 'created': '2017-06-20 14:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/34fc5784bfbb077ed2385e664aa4d94b02a81877', 'message': 'Add warning while upgrading with dockerhub images N->O\n\nMinimun nova version needed for upgrade from newton to\nocata is 14.0.4. Binary images published in dockerhub\ncame with 14.0.3 installed on it. This is caused because\nwe released the images before packages promoted the fix\nto stable versions.\n\nManually building images is fine since current nova release from\nrepositories is > 14.0.4\n\nChange-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca\nCloses-Bug: #1699153\n'}, {'number': 4, 'created': '2017-06-20 14:20:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5ab4785784be532466c30bf89e63d4dbb448fbf5', 'message': 'Add warning while upgrading with dockerhub images N->O\n\nMinimun nova version needed for upgrade from newton to\nocata is 14.0.4. Binary images published in dockerhub\ncame with 14.0.3 installed on it. This is caused because\nwe released the images before packages promoted the fix\nto stable versions.\n\nManually building images is fine since current nova release from\nrepositories is > 14.0.4\n\nChange-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca\nCloses-Bug: #1699153\n'}, {'number': 5, 'created': '2017-07-10 14:02:03.000000000', 'files': ['releasenotes/notes/create-nova-cells-upgrade-ccddf7259eba16dd.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3c3e4a8f1610a4c5d2ec0eaa9c8779dbec0dd36f', 'message': 'Add warning while upgrading with dockerhub images N->O\n\nMinimun nova version needed for upgrade from newton to\nocata is 14.0.4. Binary images published in dockerhub\ncame with 14.0.3 installed on it. This is caused because\nwe released the images before packages promoted the fix\nto stable versions.\n\nManually building images is fine since current nova release from\nrepositories is > 14.0.4\n\nChange-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca\nCloses-Bug: #1699153\n'}]",1,475802,3c3e4a8f1610a4c5d2ec0eaa9c8779dbec0dd36f,16,7,5,19316,,,0,"Add warning while upgrading with dockerhub images N->O

Minimun nova version needed for upgrade from newton to
ocata is 14.0.4. Binary images published in dockerhub
came with 14.0.3 installed on it. This is caused because
we released the images before packages promoted the fix
to stable versions.

Manually building images is fine since current nova release from
repositories is > 14.0.4

Change-Id: Iae8451e70d1f77993b9c0732f719fe8388b96bca
Closes-Bug: #1699153
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/02/475802/4 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/create-nova-cells-upgrade-ccddf7259eba16dd.yaml'],1,364122c7b00c84407e3dd79415d77e1ef6457e55,bug/1699153," WARNING: Binary kolla images version 3.0.3 from Docker Hub are not valid for upgrade, nova minimum version needed is 14.0.4",,2,0
openstack%2Fpuppet-openstack_spec_helper~master~I221bc3e3685789031c2466868b81bbbd4c0fa0d5,openstack/puppet-openstack_spec_helper,master,I221bc3e3685789031c2466868b81bbbd4c0fa0d5,Pin r10k to 2.6.4,ABANDONED,2018-09-28 09:46:59.000000000,2018-09-28 10:16:18.000000000,,"[{'_account_id': 13861}, {'_account_id': 17216}]","[{'number': 1, 'created': '2018-09-28 09:46:59.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/cb772dce60c53ea8abee91f5a12067b9696961f2', 'message': ""Pin r10k to 2.6.4\n\nr10k > 2.6.4 requires gem 'cri' which requires ruby >= 2.3,\nwhich is not available, so let's pin r10k.\n\nChange-Id: I221bc3e3685789031c2466868b81bbbd4c0fa0d5\n""}]",0,606018,cb772dce60c53ea8abee91f5a12067b9696961f2,4,2,1,13861,,,0,"Pin r10k to 2.6.4

r10k > 2.6.4 requires gem 'cri' which requires ruby >= 2.3,
which is not available, so let's pin r10k.

Change-Id: I221bc3e3685789031c2466868b81bbbd4c0fa0d5
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/18/606018/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,cb772dce60c53ea8abee91f5a12067b9696961f2,," spec.add_dependency 'r10k', ['= 2.6.4']", spec.add_dependency 'r10k',1,1
openstack%2Fpython-keystoneclient~master~I0257d5d42916e3b4d008e592d54eeeebec591633,openstack/python-keystoneclient,master,I0257d5d42916e3b4d008e592d54eeeebec591633,Deprecate region enabled parameter,MERGED,2018-08-22 10:06:18.000000000,2018-09-28 10:06:14.000000000,2018-09-28 10:06:14.000000000,"[{'_account_id': 2218}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-08-22 10:06:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3a6eefad57a0ac5e0039f3dc6d90a8a00c821c16', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 2, 'created': '2018-08-27 09:22:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ec6f591b7fc95a4f4aec231a356c93ca2c53d1ab', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 3, 'created': '2018-08-27 09:26:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/d443675a9371dda009db446988f31af4f2f73687', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 4, 'created': '2018-08-27 09:30:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/7d00a4962f461d0ce7f813345f2e359a094882ba', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 5, 'created': '2018-08-28 03:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/940cb0bac3602decf2e3c1ed897c98707f754c3e', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 6, 'created': '2018-09-07 06:14:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/2632f81923ce18fd0db64e4ef9d21abf3b26e48f', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 7, 'created': '2018-09-07 08:18:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/3859d4e808e63211649302ef5974aa9a11873cd2', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 8, 'created': '2018-09-18 07:52:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/e10063a80ddc1adbc0a733ddb1565294b80987d8', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 9, 'created': '2018-09-21 05:33:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/f707415c52a7f1bbc37a4d8a773732ca4f3c4a24', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 10, 'created': '2018-09-25 09:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/83f107afae9fd833f8187d70e17e94d71551a232', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 11, 'created': '2018-09-26 02:42:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/ce052776a720a3a1f06ed82199d8b029ef1326a7', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 12, 'created': '2018-09-27 04:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/dbd50b3182382a24c0acd5549c22070bcb44fbbd', 'message': 'create() call in v3.regions.py is wrong\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus removing it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nCloses-Bug: #1615076\n'}, {'number': 13, 'created': '2018-09-28 01:50:49.000000000', 'files': ['keystoneclient/v3/regions.py', 'releasenotes/notes/bug-1615076-26962c85aeaf288c.yaml', 'keystoneclient/tests/unit/v3/utils.py'], 'web_link': 'https://opendev.org/openstack/python-keystoneclient/commit/b7db5668c1223908987060a767078f010c83df6f', 'message': 'Deprecate region enabled parameter\n\nWe don\'t check for ""enabled"" in the region\nanywhere thus deprecating it from the create()\nand update calls of the v3/region.py. We dont\nuse it in schema [1] as well as [2].\n\n[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34\n[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49\n\nChange-Id: I0257d5d42916e3b4d008e592d54eeeebec591633\nPartial-Bug: #1615076\n'}]",23,594921,b7db5668c1223908987060a767078f010c83df6f,43,5,13,27621,,,0,"Deprecate region enabled parameter

We don't check for ""enabled"" in the region
anywhere thus deprecating it from the create()
and update calls of the v3/region.py. We dont
use it in schema [1] as well as [2].

[1] https://github.com/openstack/keystone/blob/master/keystone/catalog/schema.py#L34
[2] https://github.com/openstack/keystone/blob/master/keystone/catalog/backends/sql.py#L33-L49

Change-Id: I0257d5d42916e3b4d008e592d54eeeebec591633
Partial-Bug: #1615076
",git fetch https://review.opendev.org/openstack/python-keystoneclient refs/changes/21/594921/2 && git format-patch -1 --stdout FETCH_HEAD,"['keystoneclient/tests/unit/v3/test_regions.py', 'keystoneclient/v3/regions.py']",2,3a6eefad57a0ac5e0039f3dc6d90a8a00c821c16,bug/1615076," id=id, description=description,"," * enabled: determines whether the endpoint appears in the catalog. :param bool enabled: whether the region is enabled or not, determining if it appears in the catalog. id=id, description=description, enabled=enabled, :param bool enabled: determining if the region appears in the catalog by enabling or disabling it. enabled=enabled,",1,8
openstack%2Fopenstack-ansible~stable%2Fpike~I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,openstack/openstack-ansible,stable/pike,I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,Use loop_control for haproxy keystone back-end enablement,MERGED,2018-09-26 20:05:25.000000000,2018-09-28 09:59:06.000000000,2018-09-28 09:59:06.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 20:05:25.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/f267ff90c47cde755a453092e54ccf398971a7e6', 'message': 'Use loop_control for haproxy keystone back-end enablement\n\nIn I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop\ncontrol specification from in the common tasks to the parent task,\nbut forgot to implement the loop control for the task which enables\nthe back-end again later. This patch corrects that.\n\nChange-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b\n(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)\n'}]",0,605518,f267ff90c47cde755a453092e54ccf398971a7e6,19,5,1,6816,,,0,"Use loop_control for haproxy keystone back-end enablement

In I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop
control specification from in the common tasks to the parent task,
but forgot to implement the loop control for the task which enables
the back-end again later. This patch corrects that.

Change-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b
(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/18/605518/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,f267ff90c47cde755a453092e54ccf398971a7e6,keystone_admin_port-stable/pike," haproxy_backend: ""{{ backend_name }}"" loop_control: loop_var: backend_name"," haproxy_backend: ""{{ item }}""",3,1
openstack%2Fopenstack-manuals~master~I2769a7a146da8ecb1062014bb87c2ba28099d64d,openstack/openstack-manuals,master,I2769a7a146da8ecb1062014bb87c2ba28099d64d,Imported Translations from Zanata,MERGED,2018-09-28 07:59:03.000000000,2018-09-28 09:49:50.000000000,2018-09-28 09:49:50.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 07:59:03.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/install-guide/source/locale/en_GB/LC_MESSAGES/install-guide.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/db2dac28997048fcfb0dd7d4871a7979b9aa84b1', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I2769a7a146da8ecb1062014bb87c2ba28099d64d\n'}]",0,605992,db2dac28997048fcfb0dd7d4871a7979b9aa84b1,6,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I2769a7a146da8ecb1062014bb87c2ba28099d64d
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/92/605992/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'releasenotes/source/locale/en_GB/LC_MESSAGES/releasenotes.po', 'doc/install-guide/source/locale/en_GB/LC_MESSAGES/install-guide.po', 'releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po']",4,db2dac28997048fcfb0dd7d4871a7979b9aa84b1,zanata/translations,"""POT-Creation-Date: 2018-09-21 23:44+0000\n""""X-Generator: Zanata 4.3.3\n""","""POT-Creation-Date: 2018-02-23 17:16+0000\n""""X-Generator: Zanata 3.9.6\n""msgid ""TBD"" msgstr ""TBD"" ",54,20
openstack%2Fkolla~master~Icf80c902ebd962a3034a1948209a357f768f533f,openstack/kolla,master,Icf80c902ebd962a3034a1948209a357f768f533f,base: remove pinning of dh-python for ubuntu,MERGED,2018-09-27 07:58:30.000000000,2018-09-28 09:36:49.000000000,2018-09-28 09:36:49.000000000,"[{'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 23717}]","[{'number': 1, 'created': '2018-09-27 07:58:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/26faf45658ca436044647b01e613e505a8cc64b5', 'message': 'base: remove pinning of dh-python for ubuntu\n\nDuring Xenial cycle we had to pin dh-python. With Bionic we no longer\nhave to.\n\nChange-Id: Icf80c902ebd962a3034a1948209a357f768f533f\n'}, {'number': 2, 'created': '2018-09-27 15:50:26.000000000', 'files': ['docker/base/apt_preferences.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/57c0b23b5e48383c38b67ceb35273cf8a2277f8e', 'message': 'base: remove pinning of dh-python for ubuntu\n\nDuring Xenial cycle we had to pin dh-python. With Bionic we no longer\nhave to.\n\nChange-Id: Icf80c902ebd962a3034a1948209a357f768f533f\n'}]",0,605608,57c0b23b5e48383c38b67ceb35273cf8a2277f8e,15,5,2,24072,,,0,"base: remove pinning of dh-python for ubuntu

During Xenial cycle we had to pin dh-python. With Bionic we no longer
have to.

Change-Id: Icf80c902ebd962a3034a1948209a357f768f533f
",git fetch https://review.opendev.org/openstack/kolla refs/changes/08/605608/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/base/apt_preferences.ubuntu'],1,26faf45658ca436044647b01e613e505a8cc64b5,605608,,# FIXME Workaround for https://bugs.launchpad.net/kolla/+bug/1759796 Package: dh-python Pin: version 2.20151103ubuntu1 Pin-Priority: 550 ,0,4
openstack%2Fkolla~stable%2Frocky~I791e479ba265ba61ffd882da18f85cdbece67e55,openstack/kolla,stable/rocky,I791e479ba265ba61ffd882da18f85cdbece67e55,ceph: stick to luminous on Ubuntu (in proper way),MERGED,2018-09-27 15:07:03.000000000,2018-09-28 09:33:18.000000000,2018-09-28 09:33:18.000000000,"[{'_account_id': 13039}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}]","[{'number': 1, 'created': '2018-09-27 15:07:03.000000000', 'files': ['docker/ceph/ceph-base/Dockerfile.j2', 'docker/base/apt_preferences.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/2a31ae40976f7dd51659510cb261f82957fa0802', 'message': 'ceph: stick to luminous on Ubuntu (in proper way)\n\nPrevious attempt broke Debian builds.\n\nPinning Ceph packages instead of giving version during install.\n\nChange-Id: I791e479ba265ba61ffd882da18f85cdbece67e55\n(cherry picked from commit 7826ba2984911d894ff188be476bc6691290ebc8)\n'}]",2,605772,2a31ae40976f7dd51659510cb261f82957fa0802,9,4,1,19316,,,0,"ceph: stick to luminous on Ubuntu (in proper way)

Previous attempt broke Debian builds.

Pinning Ceph packages instead of giving version during install.

Change-Id: I791e479ba265ba61ffd882da18f85cdbece67e55
(cherry picked from commit 7826ba2984911d894ff188be476bc6691290ebc8)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/72/605772/1 && git format-patch -1 --stdout FETCH_HEAD,"['docker/ceph/ceph-base/Dockerfile.j2', 'docker/base/apt_preferences.ubuntu']",2,2a31ae40976f7dd51659510cb261f82957fa0802,stick-luminous-ubuntu-stable/rocky, # We want Ceph/Luminous Package: ceph* *cephfs* librbd* *rados* python-rbd librgw* Pin: version 13.* Pin-Priority: -1,,8,16
openstack%2Fopenstack-planet~master~I9a3f6793b7133240a2a818a66425008f92905c1f,openstack/openstack-planet,master,I9a3f6793b7133240a2a818a66425008f92905c1f,Add Feed for Juan Antonio Osorio (jaosorior),MERGED,2018-09-27 14:01:14.000000000,2018-09-28 09:15:35.000000000,2018-09-28 09:15:35.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 287}, {'_account_id': 308}, {'_account_id': 964}, {'_account_id': 1106}, {'_account_id': 2472}, {'_account_id': 4146}, {'_account_id': 4162}, {'_account_id': 5263}, {'_account_id': 6133}, {'_account_id': 7069}, {'_account_id': 7118}, {'_account_id': 9061}, {'_account_id': 10348}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 14:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/631efbab8096fa2003d3306c325e7cab88b5db51', 'message': 'Add Feed for Juan Antonio Osorio (jaosorior)\n\nChange-Id: I9a3f6793b7133240a2a818a66425008f92905c1f\nSigned-off-by: Juan Antonio Osorio Robles <jaosorior@redhat.com>\n'}, {'number': 2, 'created': '2018-09-27 20:18:17.000000000', 'files': ['images/jaosorior.jpg', 'planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/5174b2468c0d1565377fb29cd184f8522c73320b', 'message': 'Add Feed for Juan Antonio Osorio (jaosorior)\n\nChange-Id: I9a3f6793b7133240a2a818a66425008f92905c1f\nSigned-off-by: Juan Antonio Osorio Robles <jaosorior@redhat.com>\n'}]",0,605729,5174b2468c0d1565377fb29cd184f8522c73320b,10,17,2,10873,,,0,"Add Feed for Juan Antonio Osorio (jaosorior)

Change-Id: I9a3f6793b7133240a2a818a66425008f92905c1f
Signed-off-by: Juan Antonio Osorio Robles <jaosorior@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/29/605729/1 && git format-patch -1 --stdout FETCH_HEAD,"['images/jaosorior.jpg', 'planet.ini']",2,631efbab8096fa2003d3306c325e7cab88b5db51,jaosorior-feed, [https://jaormx.github.io/openstack-feed.xml] name = Juan Antonio Osorio robles face = jaosorior.png nick = jaosorior,,5,0
openstack%2Fcharm-nova-cloud-controller~master~I852f24b21784f6de05232107a5cdf6e779f18b23,openstack/charm-nova-cloud-controller,master,I852f24b21784f6de05232107a5cdf6e779f18b23,"Enable {Different,Same}HostFilter",MERGED,2018-09-26 14:39:49.000000000,2018-09-28 09:14:47.000000000,2018-09-28 09:14:47.000000000,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 14:39:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/cbf07583db9157ef1f4495a173d7e8dfd8634374', 'message': 'Enable {Different,Same}HostFilter\n\nThe SameHostFilter and DifferentHostFilter have been present in Nova\nsince Icehouse; add both of these simple filters to the default\nenabled filters to provide simple affinity/anti-affinity hints.\n\nThis plugs some holes in our tempest test coverage as tests relating\nto these features are currently disabled.\n\nChange-Id: I852f24b21784f6de05232107a5cdf6e779f18b23\n'}, {'number': 2, 'created': '2018-09-27 08:23:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/e959fe368b269046d55df265258c2bb0848b89e8', 'message': 'Enable {Different,Same}HostFilter\n\nThe SameHostFilter and DifferentHostFilter have been present in Nova\nsince Icehouse; add both of these simple filters to the default\nenabled filters to provide simple affinity/anti-affinity hints.\n\nThis plugs some holes in our tempest test coverage as tests relating\nto these features are currently disabled.\n\nChange-Id: I852f24b21784f6de05232107a5cdf6e779f18b23\n'}, {'number': 3, 'created': '2018-09-27 14:11:26.000000000', 'files': ['config.yaml'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/d3a843ea4caa467df1c2a280ba7a7b6f134e1faa', 'message': 'Enable {Different,Same}HostFilter\n\nThe SameHostFilter and DifferentHostFilter have been present in Nova\nsince Icehouse; add both of these simple filters to the default\nenabled filters to provide simple affinity/anti-affinity hints.\n\nThis plugs some holes in our tempest test coverage as tests relating\nto these features are currently disabled.\n\nChange-Id: I852f24b21784f6de05232107a5cdf6e779f18b23\n'}]",0,605444,d3a843ea4caa467df1c2a280ba7a7b6f134e1faa,17,4,3,935,,,0,"Enable {Different,Same}HostFilter

The SameHostFilter and DifferentHostFilter have been present in Nova
since Icehouse; add both of these simple filters to the default
enabled filters to provide simple affinity/anti-affinity hints.

This plugs some holes in our tempest test coverage as tests relating
to these features are currently disabled.

Change-Id: I852f24b21784f6de05232107a5cdf6e779f18b23
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/44/605444/2 && git format-patch -1 --stdout FETCH_HEAD,['config.yaml'],1,cbf07583db9157ef1f4495a173d7e8dfd8634374,add-refstack-filters," default: ""RetryFilter,AvailabilityZoneFilter,CoreFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter,DifferentHostFilter,SameHostFilter"""," default: ""RetryFilter,AvailabilityZoneFilter,CoreFilter,RamFilter,ComputeFilter,ComputeCapabilitiesFilter,ImagePropertiesFilter,ServerGroupAntiAffinityFilter,ServerGroupAffinityFilter""",1,1
openstack%2Fcharm-nova-cloud-controller~master~Ic99d841b4a69f6ce5d26fe081f8abf70d105c113,openstack/charm-nova-cloud-controller,master,Ic99d841b4a69f6ce5d26fe081f8abf70d105c113,rocky: resolve issues with live migration,MERGED,2018-09-27 08:22:53.000000000,2018-09-28 09:14:02.000000000,2018-09-28 09:14:02.000000000,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 08:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/337934ee359f8a8b570d4230b0fe683f8e142475', 'message': 'rocky: resolve issues with live migration\n\nAdd requires keystone access and authentication details, resolving\nissues with live migration @ rocky.\n\nChange-Id: Ic99d841b4a69f6ce5d26fe081f8abf70d105c113\nCloses-Bug: 1794697\n'}, {'number': 2, 'created': '2018-09-27 14:11:26.000000000', 'files': ['templates/pike/nova.conf'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/74161785a2023706ce19efab5dc47aa2c1d5b6e2', 'message': 'rocky: resolve issues with live migration\n\nAdd requires keystone access and authentication details, resolving\nissues with live migration @ rocky.\n\nChange-Id: Ic99d841b4a69f6ce5d26fe081f8abf70d105c113\nCloses-Bug: 1794697\n'}]",0,605612,74161785a2023706ce19efab5dc47aa2c1d5b6e2,11,4,2,935,,,0,"rocky: resolve issues with live migration

Add requires keystone access and authentication details, resolving
issues with live migration @ rocky.

Change-Id: Ic99d841b4a69f6ce5d26fe081f8abf70d105c113
Closes-Bug: 1794697
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/12/605612/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/pike/nova.conf'],1,337934ee359f8a8b570d4230b0fe683f8e142475,add-refstack-filters,{% if auth_host -%} auth_url = {{ auth_protocol }}://{{ auth_host }}:{{ auth_port }}{% if admin_domain_name -%} project_domain_name = {{ admin_domain_name }} user_domain_name = {{ admin_domain_name }} {% else -%} project_domain_name = default user_domain_name = default {% endif -%} project_name = {{ admin_tenant_name }} username = {{ admin_user }} password = {{ admin_password }} signing_dir = {{ signing_dir }} {% endif -%},auth_strategy = keystone auth_section = keystone_authtoken,14,2
openstack%2Ftempest~master~I8927de56a7e5f3354900fba10c2497035559a390,openstack/tempest,master,I8927de56a7e5f3354900fba10c2497035559a390,Cleanup irrelevant-files list in .zuul.yaml,MERGED,2018-09-23 15:20:18.000000000,2018-09-28 09:09:52.000000000,2018-09-27 15:59:55.000000000,"[{'_account_id': 5689}, {'_account_id': 6547}, {'_account_id': 8871}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-09-23 15:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/95985356c418301706f3a21311b8605fdd3dfb10', 'message': ""Cleanup irrelevant-files list in .zuul.yaml\n\nPeriodic jobs ignore irrelevant-files, so remove this from periodic\njobs.\n\nThe list of irrelevant-files is the same everywhere, let's define it\nonly once - and then use it everywhere.\n\nChange-Id: I8927de56a7e5f3354900fba10c2497035559a390\n""}, {'number': 2, 'created': '2018-09-23 15:22:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a006f8e3bb41b851a0542764e1f3521214439ca0', 'message': ""Cleanup irrelevant-files list in .zuul.yaml\n\nPeriodic jobs ignore irrelevant-files, so remove this from periodic\njobs.\n\nThe list of irrelevant-files is the same everywhere, let's define it\nonly once - and then use it everywhere.\n\nChange-Id: I8927de56a7e5f3354900fba10c2497035559a390\n""}, {'number': 3, 'created': '2018-09-24 07:11:25.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/ff122de40651cfe3d4cbf0e3a9371797456e1678', 'message': ""Cleanup irrelevant-files list in .zuul.yaml\n\nPeriodic jobs ignore irrelevant-files, so remove this from periodic\njobs.\n\nThe list of irrelevant-files is the same everywhere, let's define it\nonly once - and then use it everywhere.\n\nChange-Id: I8927de56a7e5f3354900fba10c2497035559a390\n""}]",0,604634,ff122de40651cfe3d4cbf0e3a9371797456e1678,30,6,3,6547,,,0,"Cleanup irrelevant-files list in .zuul.yaml

Periodic jobs ignore irrelevant-files, so remove this from periodic
jobs.

The list of irrelevant-files is the same everywhere, let's define it
only once - and then use it everywhere.

Change-Id: I8927de56a7e5f3354900fba10c2497035559a390
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/604634/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,95985356c418301706f3a21311b8605fdd3dfb10,import-jobs, # Define list of irrelevant files to use everywhere else irrelevant-files:&tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - tempest-full-py36: irrelevant-files: *tempest-irrelevant-files - tempest-full-rocky: irrelevant-files: *tempest-irrelevant-files - tempest-full-rocky-py3: irrelevant-files: *tempest-irrelevant-files - tempest-full-queens: irrelevant-files: *tempest-irrelevant-files - tempest-full-queens-py3: irrelevant-files: *tempest-irrelevant-files - tempest-full-pike: irrelevant-files: *tempest-irrelevant-files - tempest-multinode-full: irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - nova-cells-v1: irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - neutron-grenade-multinode: irrelevant-files: *tempest-irrelevant-files - neutron-grenade: irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - neutron-tempest-dvr: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-neutron-full-ocata: irrelevant-files: *tempest-irrelevant-files - tempest-full: irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - tempest-slow: irrelevant-files: *tempest-irrelevant-files - neutron-grenade-multinode: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-neutron-full: irrelevant-files: *tempest-irrelevant-files - neutron-grenade: irrelevant-files: *tempest-irrelevant-files irrelevant-files: *tempest-irrelevant-files - legacy-periodic-tempest-dsvm-all-master: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-multinode-full: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-neutron-dvr-multinode-full: irrelevant-files: *tempest-irrelevant-files - neutron-tempest-dvr-ha-multinode-full: irrelevant-files: *tempest-irrelevant-files - tempest-full-test-accounts-identity-v2: irrelevant-files: *tempest-irrelevant-files - tempest-full-test-accounts-identity-v3: irrelevant-files: *tempest-irrelevant-files - tempest-full-neutron-non-admin: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-nova-v20-api: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-lvm-multibackend: irrelevant-files: *tempest-irrelevant-files - tempest-cinder-v1-api: irrelevant-files: *tempest-irrelevant-files - devstack-plugin-ceph-tempest-py3: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-neutron-pg-full: irrelevant-files: *tempest-irrelevant-files - legacy-tempest-dsvm-neutron-full-opensuse-423: irrelevant-files: *tempest-irrelevant-files - legacy-periodic-tempest-dsvm-neutron-full-ocata - legacy-periodic-tempest-dsvm-full-test-accounts-master - legacy-periodic-tempest-dsvm-neutron-full-test-accounts-master - legacy-periodic-tempest-dsvm-neutron-full-non-admin-master - legacy-periodic-tempest-dsvm-all-master, irrelevant-files: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-py36: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-rocky: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-rocky-py3: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-queens: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-queens-py3: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-pike: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-multinode-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - nova-cells-v1: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - neutron-grenade-multinode: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - neutron-grenade: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - ^test-requirements.txt$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - ^test-requirements.txt$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - ^test-requirements.txt$ irrelevant-files: - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - ^test-requirements.txt$ - neutron-tempest-dvr: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-neutron-full-ocata: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-slow: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - neutron-grenade-multinode: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-neutron-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - neutron-grenade: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-all-master: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-multinode-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-neutron-dvr-multinode-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - neutron-tempest-dvr-ha-multinode-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-test-accounts-identity-v2: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-test-accounts-identity-v3: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-full-neutron-non-admin: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-nova-v20-api: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-lvm-multibackend: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - tempest-cinder-v1-api: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - devstack-plugin-ceph-tempest-py3: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-neutron-pg-full: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-tempest-dsvm-neutron-full-opensuse-423: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-neutron-full-ocata: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-full-test-accounts-master: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-neutron-full-test-accounts-master: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-neutron-full-non-admin-master: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ - legacy-periodic-tempest-dsvm-all-master: irrelevant-files: - ^(test-|)requirements.txt$ - ^.*\.rst$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tempest/hacking/.*$ - ^tempest/tests/.*$ ,47,408
openstack%2Fcharm-nova-cloud-controller~master~Ia21b3a6782ab944b7c41564e889e6b12d264b731,openstack/charm-nova-cloud-controller,master,Ia21b3a6782ab944b7c41564e889e6b12d264b731,Use v2.1 API for >= Queens,MERGED,2018-09-25 10:18:33.000000000,2018-09-28 09:09:26.000000000,2018-09-28 09:09:26.000000000,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 10:18:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/2193cff041f47dfdd9f3c6cb0c486ffd78338797', 'message': 'Use v2.1 API for >= Queens\n\nSwitch to using the v2.1 API endpoint for OpenStack Queens or later.\n\nCloses-Bug: 1794271\n\nChange-Id: Ia21b3a6782ab944b7c41564e889e6b12d264b731\n'}, {'number': 2, 'created': '2018-09-27 08:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/57c2e6ad34b28281584a72ca29676f7015559ec1', 'message': 'Use v2.1 API for >= Queens\n\nSwitch to using the v2.1 API endpoint for OpenStack Queens or later.\n\nCloses-Bug: 1794271\n\nChange-Id: Ia21b3a6782ab944b7c41564e889e6b12d264b731\n'}, {'number': 3, 'created': '2018-09-27 14:11:26.000000000', 'files': ['hooks/charmhelpers/core/host.py', 'unit_tests/test_nova_cc_utils.py', 'hooks/nova_cc_utils.py', 'hooks/charmhelpers/contrib/openstack/context.py', 'hooks/charmhelpers/contrib/openstack/amulet/utils.py', 'hooks/charmhelpers/contrib/hahelpers/apache.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/935d30571c7e813ccbfecb9cbbf980f7f2835b08', 'message': 'Use v2.1 API for >= Queens\n\nSwitch to using the v2.1 API endpoint for OpenStack Queens or later.\n\nCloses-Bug: 1794271\n\nChange-Id: Ia21b3a6782ab944b7c41564e889e6b12d264b731\n'}]",0,605030,935d30571c7e813ccbfecb9cbbf980f7f2835b08,16,4,3,935,,,0,"Use v2.1 API for >= Queens

Switch to using the v2.1 API endpoint for OpenStack Queens or later.

Closes-Bug: 1794271

Change-Id: Ia21b3a6782ab944b7c41564e889e6b12d264b731
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/30/605030/2 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_utils.py', 'hooks/nova_cc_utils.py']",2,2193cff041f47dfdd9f3c6cb0c486ffd78338797,add-refstack-filters," if cmp_os_rel >= 'queens': nova_public_url = ( '%s:%s/v2.1' % (public_url, api_port('nova-api-os-compute')) ) nova_internal_url = ( '%s:%s/v2.1' % (internal_url, api_port('nova-api-os-compute')) ) nova_admin_url = ( '%s:%s/v2.1' % (admin_url, api_port('nova-api-os-compute')) ) ",,45,0
openstack%2Fproject-config~master~I14c15b9a4077fbc853b6b00aaae2821be724bc26,openstack/project-config,master,I14c15b9a4077fbc853b6b00aaae2821be724bc26,[manila-ui] Don't run python35 tests until Rocky,MERGED,2018-09-28 00:07:12.000000000,2018-09-28 09:01:04.000000000,2018-09-28 09:01:04.000000000,"[{'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 00:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e58dd24587a76d439ddcd549db740d3788687fbd', 'message': ""[manila-ui] Don't run python35 tests until Rocky\n\nmanila-ui is python3 compatible only since stable/rocky [1]\nWe don't intend to backport python3 compatibility fixes\nto earlier releases of this horizon plugin.\n\nTurn off jobs on stable/ocata, stable/pike and\nstable/queens here before the job config can\nbe ported to the manila-ui repos for the respective\nbranches.\n\n[1] https://review.openstack.org/#/c/552121/\n\nChange-Id: I14c15b9a4077fbc853b6b00aaae2821be724bc26\nNeeded-By: https://review.openstack.org/#/c/593878/\nNeeded-By: https://review.openstack.org/#/c/593881/\nNeeded-By: https://review.openstack.org/#/c/593884/\n""}, {'number': 2, 'created': '2018-09-28 00:13:00.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9a4d3ed75d48e784d37ea5d8f9afe6396cdbe73d', 'message': ""[manila-ui] Don't run python35 tests until Rocky\n\nmanila-ui is python3 compatible only since stable/rocky [1]\nWe don't intend to backport python3 compatibility fixes\nto earlier releases of this horizon plugin.\n\nTurn off jobs on stable/ocata, stable/pike and\nstable/queens here before the job config can\nbe ported to the manila-ui repos for the respective\nbranches.\n\n[1] https://review.openstack.org/#/c/552121/\n\nChange-Id: I14c15b9a4077fbc853b6b00aaae2821be724bc26\nNeeded-By: https://review.openstack.org/#/c/593878/\nNeeded-By: https://review.openstack.org/#/c/593881/\nNeeded-By: https://review.openstack.org/#/c/593884/\n""}]",1,605893,9a4d3ed75d48e784d37ea5d8f9afe6396cdbe73d,9,3,2,16643,,,0,"[manila-ui] Don't run python35 tests until Rocky

manila-ui is python3 compatible only since stable/rocky [1]
We don't intend to backport python3 compatibility fixes
to earlier releases of this horizon plugin.

Turn off jobs on stable/ocata, stable/pike and
stable/queens here before the job config can
be ported to the manila-ui repos for the respective
branches.

[1] https://review.openstack.org/#/c/552121/

Change-Id: I14c15b9a4077fbc853b6b00aaae2821be724bc26
Needed-By: https://review.openstack.org/#/c/593878/
Needed-By: https://review.openstack.org/#/c/593881/
Needed-By: https://review.openstack.org/#/c/593884/
",git fetch https://review.opendev.org/openstack/project-config refs/changes/93/605893/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,e58dd24587a76d439ddcd549db740d3788687fbd,python3-first, - openstack-python35-jobs-horizon: branches: ^(?!stable/(ocata|pike|queens)).*$,,2,0
openstack%2Fkeystone~master~I97ced2047964055966fd6c2e8acfec29b48bdfe3,openstack/keystone,master,I97ced2047964055966fd6c2e8acfec29b48bdfe3,Add python3 functional test job,MERGED,2018-09-26 11:39:21.000000000,2018-09-28 08:54:16.000000000,2018-09-28 04:24:24.000000000,"[{'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 11:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7f837e2e9531af3c83b4fdc0b9aed2e4753811af', 'message': 'Add python3 functional test job\n\nAs part of the python3-first goal, this patch ensures we have a voting\nfunctional job that uses python3. The choice to call it py3 rather than\npy35 is conscious, as the underlying python3 version is controlled by\nthe choice of test node which the job inherits from its ancestor jobs.\n\nChange-Id: I97ced2047964055966fd6c2e8acfec29b48bdfe3\n'}, {'number': 2, 'created': '2018-09-26 18:10:40.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/826f037ebbf2e6d47369c1162450e5f3b1188cdd', 'message': 'Add python3 functional test job\n\nAs part of the python3-first goal, this patch ensures we have a voting\nfunctional job that uses python3. The choice to call it py3 rather than\npy35 is conscious, as the underlying python3 version is controlled by\nthe choice of test node which the job inherits from its ancestor jobs.\n\nChange-Id: I97ced2047964055966fd6c2e8acfec29b48bdfe3\n'}]",2,605403,826f037ebbf2e6d47369c1162450e5f3b1188cdd,11,3,2,8482,,,0,"Add python3 functional test job

As part of the python3-first goal, this patch ensures we have a voting
functional job that uses python3. The choice to call it py3 rather than
py35 is conscious, as the underlying python3 version is controlled by
the choice of test node which the job inherits from its ancestor jobs.

Change-Id: I97ced2047964055966fd6c2e8acfec29b48bdfe3
",git fetch https://review.opendev.org/openstack/keystone refs/changes/03/605403/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,7f837e2e9531af3c83b4fdc0b9aed2e4753811af,python3-first, name: keystone-dsvm-py3-functional parent: keystone-dsvm-functional vars: devstack_localrc: TEMPEST_PLUGINS: '/opt/stack/keystone-tempest-plugin' USE_PYTHON3: True - job:,,8,0
openstack%2Fdevstack~master~I3a72f38b564b8b83b233fccba7685833b6394d45,openstack/devstack,master,I3a72f38b564b8b83b233fccba7685833b6394d45,Update cinder backup_driver to full class name,MERGED,2018-09-27 18:37:59.000000000,2018-09-28 08:42:02.000000000,2018-09-28 08:42:02.000000000,"[{'_account_id': 1004}, {'_account_id': 4690}, {'_account_id': 7118}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 13252}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 18:37:59.000000000', 'files': ['lib/cinder_backends/ceph'], 'web_link': 'https://opendev.org/openstack/devstack/commit/991b1f13f0aed578dccec2e761be69005357444f', 'message': 'Update cinder backup_driver to full class name\n\nLegacy backup service support was recently dropped from cinder in\nchange I3ada2dee1857074746b1893b82dd5f6641c6e579 and we need to\nadjust how we set the config option in devstack accordingly. This\nupdates the backup_driver option to specify a full class name instead\nof only the module name.\n\nCloses-Bug: #1794859\n\nChange-Id: I3a72f38b564b8b83b233fccba7685833b6394d45\n'}]",0,605833,991b1f13f0aed578dccec2e761be69005357444f,14,9,1,4690,,,0,"Update cinder backup_driver to full class name

Legacy backup service support was recently dropped from cinder in
change I3ada2dee1857074746b1893b82dd5f6641c6e579 and we need to
adjust how we set the config option in devstack accordingly. This
updates the backup_driver option to specify a full class name instead
of only the module name.

Closes-Bug: #1794859

Change-Id: I3a72f38b564b8b83b233fccba7685833b6394d45
",git fetch https://review.opendev.org/openstack/devstack refs/changes/33/605833/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/cinder_backends/ceph'],1,991b1f13f0aed578dccec2e761be69005357444f,bug/1794859," iniset $CINDER_CONF DEFAULT backup_driver ""cinder.backup.drivers.ceph.CephBackupDriver"""," iniset $CINDER_CONF DEFAULT backup_driver ""cinder.backup.drivers.ceph""",1,1
openstack%2Fcharm-rabbitmq-server~master~I0b87c457e5ef9fcf6bec41e3c78220e0250e00eb,openstack/charm-rabbitmq-server,master,I0b87c457e5ef9fcf6bec41e3c78220e0250e00eb,"Trivial grammar changes: 1. 'executing it is' => 'executing, it is' 2. 'may be' => 'are' for brevity",MERGED,2018-09-27 15:24:50.000000000,2018-09-28 08:40:20.000000000,2018-09-28 08:40:20.000000000,"[{'_account_id': 10068}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:24:50.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/d9ee17b26f42dbb4c4b6cf8927dec65d3e08d665', 'message': ""Trivial grammar changes:\n1. 'executing it is' => 'executing, it is'\n2. 'may be' => 'are' for brevity\n\nChange-Id: I0b87c457e5ef9fcf6bec41e3c78220e0250e00eb\n""}]",0,605780,d9ee17b26f42dbb4c4b6cf8927dec65d3e08d665,8,4,1,29201,,,0,"Trivial grammar changes:
1. 'executing it is' => 'executing, it is'
2. 'may be' => 'are' for brevity

Change-Id: I0b87c457e5ef9fcf6bec41e3c78220e0250e00eb
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/80/605780/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,d9ee17b26f42dbb4c4b6cf8927dec65d3e08d665,trivial-readme-change-for-testing-setup,"some time. Due to the nature of asynchronous hook execution, it is possible client relationship hooks are executed before the cluster is complete.",some time. Due to the nature of asynchronous hook execution it is possible client relationship hooks may be executed before the cluster is complete.,2,2
openstack%2Fplacement~master~I6cc311a8d7a3fefe259631916c32ff7f9a41974c,openstack/placement,master,I6cc311a8d7a3fefe259631916c32ff7f9a41974c,Fix member_of doc in RequestGroup.dict_from_request,MERGED,2018-09-26 13:53:36.000000000,2018-09-28 08:36:46.000000000,2018-09-28 08:36:46.000000000,"[{'_account_id': 1063}, {'_account_id': 7634}, {'_account_id': 11564}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2018-09-26 13:53:36.000000000', 'files': ['placement/lib.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/da49cde1bdf5339637d0e6985e814bab629e6267', 'message': 'Fix member_of doc in RequestGroup.dict_from_request\n\nIt was noticed in a previous patch [1] that the example in the\nRequestGroup.dict_from_request docstring had an incorrect member_of\ntranslation between the querystring and the result object. This was\nprobably missed while [2] and [3] were in flight at the same time.\n\n[1] https://review.openstack.org/#/c/602495/3/placement/lib.py@126\n[2] https://review.openstack.org/#/c/517757/\n[3] https://review.openstack.org/#/c/547990/\n\nChange-Id: I6cc311a8d7a3fefe259631916c32ff7f9a41974c\n'}]",0,605427,da49cde1bdf5339637d0e6985e814bab629e6267,11,5,1,14070,,,0,"Fix member_of doc in RequestGroup.dict_from_request

It was noticed in a previous patch [1] that the example in the
RequestGroup.dict_from_request docstring had an incorrect member_of
translation between the querystring and the result object. This was
probably missed while [2] and [3] were in flight at the same time.

[1] https://review.openstack.org/#/c/602495/3/placement/lib.py@126
[2] https://review.openstack.org/#/c/517757/
[3] https://review.openstack.org/#/c/547990/

Change-Id: I6cc311a8d7a3fefe259631916c32ff7f9a41974c
",git fetch https://review.opendev.org/openstack/placement refs/changes/27/605427/1 && git format-patch -1 --stdout FETCH_HEAD,['placement/lib.py'],1,da49cde1bdf5339637d0e6985e814bab629e6267,fix-member_of-docstring," &member_of=9323b2b1-82c9-4e91-bdff-e95e808ef954 &member_of=in:8592a199-7d73-4465-8df6-ab00a6243c82,ddbd9226-d6a6-475e-a85f-0609914dd058 # noqa"," &member_of=in:9323b2b1-82c9-4e91-bdff-e95e808ef954,8592a199-7d73-4465-8df6-ab00a6243c82 # noqa",2,1
openstack%2Fplacement~master~Ief5cb60c90268b079f2f9ada44ba997c316420d9,openstack/placement,master,Ief5cb60c90268b079f2f9ada44ba997c316420d9,Move qs parsing to placement.lib.RequestGroup,MERGED,2018-09-13 23:08:48.000000000,2018-09-28 08:36:10.000000000,2018-09-28 08:36:10.000000000,"[{'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2018-09-13 23:08:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/b6bf7e01f42672e31feb97877b9f0b38e7d7c231', 'message': 'Move qs parsing to placement.lib.RequestGroup\n\nSince it produces a dict of RequestGroup, move the\nparse_qs_request_groups to staticmethod RequestGroup.dict_from_request.\n\nThis is going to help when we want to split up that method to reduce\ncomplexity.\n\nChange-Id: Ief5cb60c90268b079f2f9ada44ba997c316420d9\n'}, {'number': 2, 'created': '2018-09-14 16:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/1a54928b74ef519f77cc25e2b4e2f032c9960da9', 'message': 'Move qs parsing to placement.lib.RequestGroup\n\nSince it produces a dict of RequestGroup, move the\nparse_qs_request_groups to staticmethod RequestGroup.dict_from_request.\n\nThis is going to help when we want to split up that method to reduce\ncomplexity.\n\nChange-Id: Ief5cb60c90268b079f2f9ada44ba997c316420d9\n'}, {'number': 3, 'created': '2018-09-14 22:16:55.000000000', 'files': ['placement/lib.py', 'placement/tests/unit/test_util.py', 'placement/util.py', 'placement/handlers/allocation_candidate.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/878268b2293e8fda7fd11ae86f56108a78ed5b23', 'message': 'Move qs parsing to placement.lib.RequestGroup\n\nSince it produces a dict of RequestGroup, move the\nparse_qs_request_groups to staticmethod RequestGroup.dict_from_request.\n\nThis is going to help when we want to split up that method to reduce\ncomplexity.\n\nChange-Id: Ief5cb60c90268b079f2f9ada44ba997c316420d9\n'}]",5,602495,878268b2293e8fda7fd11ae86f56108a78ed5b23,17,4,3,14070,,,0,"Move qs parsing to placement.lib.RequestGroup

Since it produces a dict of RequestGroup, move the
parse_qs_request_groups to staticmethod RequestGroup.dict_from_request.

This is going to help when we want to split up that method to reduce
complexity.

Change-Id: Ief5cb60c90268b079f2f9ada44ba997c316420d9
",git fetch https://review.opendev.org/openstack/placement refs/changes/95/602495/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/lib.py', 'placement/tests/unit/test_util.py', 'placement/util.py', 'placement/handlers/allocation_candidate.py']",4,b6bf7e01f42672e31feb97877b9f0b38e7d7c231,reduce-complexity,from placement import lib requests = lib.RequestGroup.dict_from_request(req), requests = util.parse_qs_request_groups(req),193,182
openstack%2Fswift~master~Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb,openstack/swift,master,Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb,Use latest eventlet in probe tests,MERGED,2018-09-14 04:43:00.000000000,2018-09-28 08:24:34.000000000,2018-09-28 08:24:33.000000000,"[{'_account_id': 7233}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-14 04:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/5a34f6a540b2ed5efc83b2d06e6c71779b55162f', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections. See also:\n\n   - https://github.com/eventlet/eventlet/commit/7f53465\n   - https://github.com/eventlet/eventlet/issues/188\n   - https://bugs.launchpad.net/keystone/+bug/1408612\n\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 2, 'created': '2018-09-14 04:44:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/52648d204677f8a72d45a61d8ffa54c824b39fe9', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections. See also:\n\n   - https://github.com/eventlet/eventlet/commit/7f53465\n   - https://github.com/eventlet/eventlet/issues/188\n   - https://bugs.launchpad.net/keystone/+bug/1408612\n\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 3, 'created': '2018-09-14 04:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c1fae944cbef66d27ec632842eec0550932a40d3', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections. See also:\n\n   - https://github.com/eventlet/eventlet/commit/7f53465\n   - https://github.com/eventlet/eventlet/issues/188\n   - https://bugs.launchpad.net/keystone/+bug/1408612\n\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 4, 'created': '2018-09-14 06:30:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/8fc8830e091a4986a8c1b74d5b5c8650e9737deb', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections. See also:\n\n   - https://github.com/eventlet/eventlet/commit/7f53465\n   - https://github.com/eventlet/eventlet/issues/188\n   - https://bugs.launchpad.net/keystone/+bug/1408612\n\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 5, 'created': '2018-09-14 17:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/61fcb997ec35da921b4f9ab99546b63588ceca94', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections.\n\nPartial-Bug: #1792615\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 6, 'created': '2018-09-14 19:12:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bccfc3351a30f2deb245f9ba378da6234c79ab8e', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections.\n\nPartial-Bug: #1792615\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}, {'number': 7, 'created': '2018-09-19 21:59:41.000000000', 'files': ['test/probe/test_signals.py', 'tools/playbooks/common/install_dependencies.yaml'], 'web_link': 'https://opendev.org/openstack/swift/commit/050f8799ca82f121f9d33c7e773b982b9763f074', 'message': 'Use latest eventlet in probe tests\n\nNote that eventlet 0.22.0+ closes connections between requests when\nit stops accepting connections.\n\nPartial-Bug: #1792615\nChange-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb\n'}]",1,602526,050f8799ca82f121f9d33c7e773b982b9763f074,19,3,7,15343,,,0,"Use latest eventlet in probe tests

Note that eventlet 0.22.0+ closes connections between requests when
it stops accepting connections.

Partial-Bug: #1792615
Change-Id: Ia8d9ab95e2aad40e8d797acc3423a917e809ffdb
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/602526/6 && git format-patch -1 --stdout FETCH_HEAD,"['test/probe/test_signals.py', 'tools/playbooks/saio_single_node_setup/install_dependencies.yaml']",2,5a34f6a540b2ed5efc83b2d06e6c71779b55162f,bug/1792615, - python-pip become: true - name: update pip version to be the latest pip: name: pip state: latest become: true - name: installing python dependencies pip: name: eventlet become: true, - python-eventlet,27,6
openstack%2Frequirements~stable%2Frocky~I20a1f5956941751174391be84a8f90851be2cd07,openstack/requirements,stable/rocky,I20a1f5956941751174391be84a8f90851be2cd07,update constraint for ovsdbapp to new release 0.12.2,MERGED,2018-09-27 15:58:50.000000000,2018-09-28 08:24:33.000000000,2018-09-28 08:24:32.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:58:50.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3f77a7ff4e08ccd29c4b0812b383963751fe91d3', 'message': 'update constraint for ovsdbapp to new release 0.12.2\n\nChange-Id: I20a1f5956941751174391be84a8f90851be2cd07\nmeta:version: 0.12.2\nmeta:diff-start: -\nmeta:series: rocky\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Change-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7\nmeta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605794,3f77a7ff4e08ccd29c4b0812b383963751fe91d3,10,2,1,11131,,,0,"update constraint for ovsdbapp to new release 0.12.2

Change-Id: I20a1f5956941751174391be84a8f90851be2cd07
meta:version: 0.12.2
meta:diff-start: -
meta:series: rocky
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Change-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7
meta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/94/605794/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,3f77a7ff4e08ccd29c4b0812b383963751fe91d3,new-release,ovsdbapp===0.12.2,ovsdbapp===0.12.1,1,1
openstack%2Frequirements~master~Ic35711ac9c3d641e4a07f9617a6d9856217e5eec,openstack/requirements,master,Ic35711ac9c3d641e4a07f9617a6d9856217e5eec,update constraint for oslo.versionedobjects to new release 1.34.1,MERGED,2018-09-25 20:01:59.000000000,2018-09-28 08:24:31.000000000,2018-09-28 08:24:31.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 20:01:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/96660ceaf0de4f9426b82fd52b6f32602eeb7dcc', 'message': 'update constraint for oslo.versionedobjects to new release 1.34.1\n\nChange-Id: Ic35711ac9c3d641e4a07f9617a6d9856217e5eec\nmeta:version: 1.34.1\nmeta:diff-start: 1.33.3\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2018-09-26 15:26:09.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e6ddeed4fa5bc7012f0d81e7afba4ca7a8e2d3e3', 'message': 'update constraint for oslo.versionedobjects to new release 1.34.1\n\nChange-Id: Ic35711ac9c3d641e4a07f9617a6d9856217e5eec\nmeta:version: 1.34.1\nmeta:diff-start: 1.33.3\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605219,e6ddeed4fa5bc7012f0d81e7afba4ca7a8e2d3e3,16,2,2,11131,,,0,"update constraint for oslo.versionedobjects to new release 1.34.1

Change-Id: Ic35711ac9c3d641e4a07f9617a6d9856217e5eec
meta:version: 1.34.1
meta:diff-start: 1.33.3
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/19/605219/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,96660ceaf0de4f9426b82fd52b6f32602eeb7dcc,new-release,oslo.versionedobjects===1.34.1,oslo.versionedobjects===1.33.3,1,1
openstack%2Fnova~master~I25a4f36027390def83cfe25f4f3b4af9660da502,openstack/nova,master,I25a4f36027390def83cfe25f4f3b4af9660da502,Null out instance.availability_zone on shelve offload,MERGED,2018-08-31 22:20:11.000000000,2018-09-28 08:24:27.000000000,2018-09-28 08:24:27.000000000,"[{'_account_id': 782}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-08-31 22:20:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6876b2a8e3cef6d599ab9174d8a08910b9decb81', 'message': ""Null out instance.availability_zone on shelve offload\n\nWhen a user shelve offloads a server, the compute manager\nnulls out the instance host and node attributes. However\nthe availability_zone attribute is left set on the instance\nso the API will show the instance as in an AZ when really\nit's not, because an instance that is not on a host is not\nin a host aggregate so it can't be in an AZ.\n\nKeep in mind that there are two ways an instance can be in\nan AZ:\n\n1. The user specifically requests to create the server in\n   the AZ.\n\n2. The user does not request an AZ and one is assigned via\n   the selected host during server create (or resize, etc).\n\nFor the first case, the server will always remain in the\nuser-requested AZ even after shelve/unshelve. But in the\nsecond case, unshelving the server can result in the server\nbeing spawned on a new host in a different AZ - the scheduler\ndoes not restrict the AZ in that second case.\n\nThis change nulls out the instance.availability_zone just like\nthe host and node fields on shelve offload since it's\nconfusing to show a shelved offloaded server in an AZ that\ndoesn't have a host.\n\nFinal note: the _nil_out_instance_obj_host_and_node method\nis also called during server create if the build fails and\nis aborted or rescheduled to another host, and in the case\nthat unshelve fails. In the case of a server build reschedule,\nconductor will set the instance.availability_zone appropriately\nbased on the alternate host for the reschedule. In the other\nfailure cases, leaving the instance AZ null is appropriate.\n\nChange-Id: I25a4f36027390def83cfe25f4f3b4af9660da502\nCloses-Bug: #1790221\n""}, {'number': 2, 'created': '2018-09-27 12:50:00.000000000', 'files': ['doc/notification_samples/instance-delete-end_not_scheduled.json', 'doc/notification_samples/instance-delete-start_not_scheduled.json', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'doc/notification_samples/instance-shelve_offload-end.json'], 'web_link': 'https://opendev.org/openstack/nova/commit/771b9eaa71742b7a158c2e7759a3046ea5a6fc3a', 'message': ""Null out instance.availability_zone on shelve offload\n\nWhen a user shelve offloads a server, the compute manager\nnulls out the instance host and node attributes. However\nthe availability_zone attribute is left set on the instance\nso the API will show the instance as in an AZ when really\nit's not, because an instance that is not on a host is not\nin a host aggregate so it can't be in an AZ.\n\nKeep in mind that there are two ways an instance can be in\nan AZ:\n\n1. The user specifically requests to create the server in\n   the AZ.\n\n2. The user does not request an AZ and one is assigned via\n   the selected host during server create (or resize, etc).\n\nFor the first case, the server will always remain in the\nuser-requested AZ even after shelve/unshelve. But in the\nsecond case, unshelving the server can result in the server\nbeing spawned on a new host in a different AZ - the scheduler\ndoes not restrict the AZ in that second case.\n\nThis change nulls out the instance.availability_zone just like\nthe host and node fields on shelve offload since it's\nconfusing to show a shelved offloaded server in an AZ that\ndoesn't have a host.\n\nFinal note: the _nil_out_instance_obj_host_and_node method\nis also called during server create if the build fails and\nis aborted or rescheduled to another host, and in the case\nthat unshelve fails. In the case of a server build reschedule,\nconductor will set the instance.availability_zone appropriately\nbased on the alternate host for the reschedule. In the other\nfailure cases, leaving the instance AZ null is appropriate.\n\nChange-Id: I25a4f36027390def83cfe25f4f3b4af9660da502\nCloses-Bug: #1790221\n""}]",0,599087,771b9eaa71742b7a158c2e7759a3046ea5a6fc3a,45,18,2,6873,,,0,"Null out instance.availability_zone on shelve offload

When a user shelve offloads a server, the compute manager
nulls out the instance host and node attributes. However
the availability_zone attribute is left set on the instance
so the API will show the instance as in an AZ when really
it's not, because an instance that is not on a host is not
in a host aggregate so it can't be in an AZ.

Keep in mind that there are two ways an instance can be in
an AZ:

1. The user specifically requests to create the server in
   the AZ.

2. The user does not request an AZ and one is assigned via
   the selected host during server create (or resize, etc).

For the first case, the server will always remain in the
user-requested AZ even after shelve/unshelve. But in the
second case, unshelving the server can result in the server
being spawned on a new host in a different AZ - the scheduler
does not restrict the AZ in that second case.

This change nulls out the instance.availability_zone just like
the host and node fields on shelve offload since it's
confusing to show a shelved offloaded server in an AZ that
doesn't have a host.

Final note: the _nil_out_instance_obj_host_and_node method
is also called during server create if the build fails and
is aborted or rescheduled to another host, and in the case
that unshelve fails. In the case of a server build reschedule,
conductor will set the instance.availability_zone appropriately
based on the alternate host for the reschedule. In the other
failure cases, leaving the instance AZ null is appropriate.

Change-Id: I25a4f36027390def83cfe25f4f3b4af9660da502
Closes-Bug: #1790221
",git fetch https://review.opendev.org/openstack/nova refs/changes/87/599087/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/compute/manager.py', 'nova/tests/functional/test_servers.py', 'doc/notification_samples/instance-shelve_offload-end.json']",3,6876b2a8e3cef6d599ab9174d8a08910b9decb81,bug/1790221," ""node"": null, ""availability_zone"": null"," ""node"": null",7,2
openstack%2Fwatcher~master~I64f234257043d8fe2b7932f3b8ddbd01d63957f1,openstack/watcher,master,I64f234257043d8fe2b7932f3b8ddbd01d63957f1,Fix link to Watcher API,MERGED,2018-09-25 13:52:48.000000000,2018-09-28 08:22:16.000000000,2018-09-28 08:22:16.000000000,"[{'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 13:52:48.000000000', 'files': ['doc/source/architecture.rst'], 'web_link': 'https://opendev.org/openstack/watcher/commit/bb2f6d230cb922c2246bcbb43eef5c92eb055b7d', 'message': 'Fix link to Watcher API\n\nChange-Id: I64f234257043d8fe2b7932f3b8ddbd01d63957f1\nCloses-Bug: #1769084\n'}]",0,605078,bb2f6d230cb922c2246bcbb43eef5c92eb055b7d,7,3,1,19055,,,0,"Fix link to Watcher API

Change-Id: I64f234257043d8fe2b7932f3b8ddbd01d63957f1
Closes-Bug: #1769084
",git fetch https://review.opendev.org/openstack/watcher refs/changes/78/605078/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/architecture.rst'],1,bb2f6d230cb922c2246bcbb43eef5c92eb055b7d,bug/1769084,.. _Watcher API: https://developer.openstack.org/api-ref/resource-optimization/,.. _Watcher API: webapi/v1.html,1,1
openstack%2Foslo.limit~master~If546c2492d05f3d0749a4effd0d6656e6dbea093,openstack/oslo.limit,master,If546c2492d05f3d0749a4effd0d6656e6dbea093,Make callbacks required for enforcement,ABANDONED,2018-09-24 14:14:42.000000000,2018-09-28 07:58:13.000000000,,"[{'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-24 14:14:42.000000000', 'files': ['oslo_limit/tests/test_limit.py', 'oslo_limit/limit.py'], 'web_link': 'https://opendev.org/openstack/oslo.limit/commit/2665084bce026f059c53e1db9ddc9db77bee6e8f', 'message': 'Make callbacks required for enforcement\n\nThe purpose of oslo.limit is to calculate\nusage and enforce it against a limit, the\ncallback will always be required. Removing\nthis as an optional parameter.\n\nChange-Id: If546c2492d05f3d0749a4effd0d6656e6dbea093\nCloses-Bug: #1790954\n'}]",0,604795,2665084bce026f059c53e1db9ddc9db77bee6e8f,4,2,1,27621,,,0,"Make callbacks required for enforcement

The purpose of oslo.limit is to calculate
usage and enforce it against a limit, the
callback will always be required. Removing
this as an optional parameter.

Change-Id: If546c2492d05f3d0749a4effd0d6656e6dbea093
Closes-Bug: #1790954
",git fetch https://review.opendev.org/openstack/oslo.limit refs/changes/95/604795/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_limit/tests/test_limit.py', 'oslo_limit/limit.py']",2,2665084bce026f059c53e1db9ddc9db77bee6e8f,bug/1790954, if not callable(callback):, if callback and not callable(callback):,4,3
openstack%2Fnetworking-onos~stable%2Focata~I61fa72570e1a605b17405e15d9edbb424e7a639a,openstack/networking-onos,stable/ocata,I61fa72570e1a605b17405e15d9edbb424e7a639a,Converts constants package from neutron.common to neutron_lib in floating_ip.py file.,MERGED,2018-09-19 06:17:54.000000000,2018-09-28 07:57:40.000000000,2018-09-28 07:57:40.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 28180}]","[{'number': 1, 'created': '2018-09-19 06:17:54.000000000', 'files': ['networking_onos/plugins/l3/floating_ip.py'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/96564e6b715581084ab08fa8d1647074b28dc617', 'message': 'Converts constants package from neutron.common to neutron_lib in floating_ip.py file.\n\nChange-Id: I61fa72570e1a605b17405e15d9edbb424e7a639a\n(cherry picked from commit b304ebcb33f24d74e2262ccb4775c299b2a0291f)\n'}]",0,603561,96564e6b715581084ab08fa8d1647074b28dc617,6,3,1,26288,,,0,"Converts constants package from neutron.common to neutron_lib in floating_ip.py file.

Change-Id: I61fa72570e1a605b17405e15d9edbb424e7a639a
(cherry picked from commit b304ebcb33f24d74e2262ccb4775c299b2a0291f)
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/61/603561/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_onos/plugins/l3/floating_ip.py'],1,96564e6b715581084ab08fa8d1647074b28dc617,floatingip-stable/ocata,from neutron_lib import constants,from neutron.common import constants,1,1
openstack%2Ffreezer-api~master~I31852ce0f6b1231af389b6284951c96518ea1736,openstack/freezer-api,master,I31852ce0f6b1231af389b6284951c96518ea1736,add python 3.6 unit test job,MERGED,2018-08-22 01:34:46.000000000,2018-09-28 07:53:10.000000000,2018-09-28 07:53:09.000000000,"[{'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14101}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 16768}, {'_account_id': 22348}, {'_account_id': 22405}, {'_account_id': 22484}, {'_account_id': 26285}, {'_account_id': 27068}, {'_account_id': 27153}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-08-22 01:34:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/ad3bf61693c9521637dd88dfb6f1016c4891212a', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I31852ce0f6b1231af389b6284951c96518ea1736\nStory: #2002586\nTask: #24296\n'}, {'number': 2, 'created': '2018-09-11 08:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/d42365722164bfddaee3cc0ad96ec219bf9616bb', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I31852ce0f6b1231af389b6284951c96518ea1736\nStory: #2002586\nTask: #24296\n'}, {'number': 3, 'created': '2018-09-11 11:08:30.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/14243954309cc2fdbbee1ffdfa991ecfe0ba371c', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I31852ce0f6b1231af389b6284951c96518ea1736\nStory: #2002586\nTask: #24296\n'}]",0,594599,14243954309cc2fdbbee1ffdfa991ecfe0ba371c,15,13,3,17499,,,0,"add python 3.6 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.6 as part of the python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I31852ce0f6b1231af389b6284951c96518ea1736
Story: #2002586
Task: #24296
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/99/594599/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,ad3bf61693c9521637dd88dfb6f1016c4891212a,python3-first, - openstack-python36-jobs,,1,0
openstack%2Fopenstack-ansible~master~I670bf4b343a1035827ae78ba75cbd65100d71261,openstack/openstack-ansible,master,I670bf4b343a1035827ae78ba75cbd65100d71261,Enable CentOS 7 basekit jobs,MERGED,2018-08-18 21:22:10.000000000,2018-09-28 07:42:29.000000000,2018-09-28 07:42:29.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 15007}, {'_account_id': 17068}, {'_account_id': 21314}, {'_account_id': 22348}, {'_account_id': 28008}]","[{'number': 1, 'created': '2018-08-18 21:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/b2b8cb58025dc0aba51096f4f412e5e10f4d29dd', 'message': 'WIP: Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 2, 'created': '2018-08-18 21:28:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/814ad66423a7dad2a3625a37fee59bf03bf5933f', 'message': 'WIP: Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 3, 'created': '2018-08-19 00:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/841ef20cfb604436f3e202a5a177ffa48b80945c', 'message': 'Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 4, 'created': '2018-08-23 14:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c2273a513aa85f31b16658c90cbcc129bf8fceac', 'message': 'Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 5, 'created': '2018-08-23 15:06:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/bd59f69c5d7b00209ac36086e21a99ee83d4f761', 'message': 'Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 6, 'created': '2018-08-23 15:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/947c9bf0de7938c3c2e225fb27af1dd96afbef44', 'message': 'Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}, {'number': 7, 'created': '2018-08-25 21:27:45.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/87296d11281eb90b84a9441c025db42232bf2010', 'message': 'Enable CentOS 7 basekit jobs\n\nThis will bring back container jobs into CentOS 7 again using\nthe basekit scenario which should be a bit faster.\n\nChange-Id: I670bf4b343a1035827ae78ba75cbd65100d71261\n'}]",0,593360,87296d11281eb90b84a9441c025db42232bf2010,34,8,7,1004,,,0,"Enable CentOS 7 basekit jobs

This will bring back container jobs into CentOS 7 again using
the basekit scenario which should be a bit faster.

Change-Id: I670bf4b343a1035827ae78ba75cbd65100d71261
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/60/593360/6 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,b2b8cb58025dc0aba51096f4f412e5e10f4d29dd,, - openstack-ansible-deploy-aio_basekit-centos-7 - openstack-ansible-deploy-aio_basekit-centos-7, # - openstack-ansible-deploy-aio_basekit-centos-7 # - openstack-ansible-deploy-aio_basekit-centos-7,2,2
openstack%2Fkolla~master~I790a18b3a40c22ec94bc6f6dba656ba4db518cfe,openstack/kolla,master,I790a18b3a40c22ec94bc6f6dba656ba4db518cfe,Remove '.. end' comments,MERGED,2018-09-28 02:01:19.000000000,2018-09-28 07:41:16.000000000,2018-09-28 07:41:16.000000000,"[{'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 28176}]","[{'number': 1, 'created': '2018-09-28 02:01:19.000000000', 'files': ['doc/source/admin/image-building.rst', 'doc/source/admin/template-override/opendaylight-source.rst', 'doc/source/admin/template-override/ovs-dpdk.rst', 'doc/source/contributor/running-tests.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/43e90216483d44749273cf2765e2fa3e4b008f08', 'message': ""Remove '.. end' comments\n\nFollowing by https://review.openstack.org/#/c/605097/\nThese were used by now-dead tooling. We can remove them.\n\nChange-Id: I790a18b3a40c22ec94bc6f6dba656ba4db518cfe\n""}]",0,605903,43e90216483d44749273cf2765e2fa3e4b008f08,9,5,1,19779,,,0,"Remove '.. end' comments

Following by https://review.openstack.org/#/c/605097/
These were used by now-dead tooling. We can remove them.

Change-Id: I790a18b3a40c22ec94bc6f6dba656ba4db518cfe
",git fetch https://review.opendev.org/openstack/kolla refs/changes/03/605903/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/image-building.rst', 'doc/source/admin/template-override/opendaylight-source.rst', 'doc/source/admin/template-override/ovs-dpdk.rst', 'doc/source/contributor/running-tests.rst']",4,43e90216483d44749273cf2765e2fa3e4b008f08,trivial,,.. end .. end .. end .. end .. end .. end .. end .. end .. end .. end .. end ,0,106
openstack%2Ffreezer-api~stable%2Fpike~I112ab13554c2aa8eaffacb161079e8627b926d9c,openstack/freezer-api,stable/pike,I112ab13554c2aa8eaffacb161079e8627b926d9c,import zuul job settings from project-config,MERGED,2018-08-22 01:37:32.000000000,2018-09-28 07:39:51.000000000,2018-09-28 07:39:51.000000000,"[{'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14101}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 16768}, {'_account_id': 22348}, {'_account_id': 22405}, {'_account_id': 22484}, {'_account_id': 26285}, {'_account_id': 27068}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-22 01:37:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/08f9e7741bb3cc72bf3a1ae125c8dc7c01a458e9', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I112ab13554c2aa8eaffacb161079e8627b926d9c\nStory: #2002586\nTask: #24296\n'}, {'number': 2, 'created': '2018-09-11 08:51:14.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/57a092f6d694d1ae63ac2ebc073cb30b24337d94', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I112ab13554c2aa8eaffacb161079e8627b926d9c\nStory: #2002586\nTask: #24296\n'}]",0,594630,57a092f6d694d1ae63ac2ebc073cb30b24337d94,11,12,2,17499,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I112ab13554c2aa8eaffacb161079e8627b926d9c
Story: #2002586
Task: #24296
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/30/594630/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,08f9e7741bb3cc72bf3a1ae125c8dc7c01a458e9,python3-first,- project: templates: - openstack-python-jobs - openstack-python35-jobs - openstack-python36-jobs - check-requirements - release-notes-jobs-python3 - release-notes-jobs check: jobs: - freezer-api-ubuntu-xenial - freezer-api-centos-7: voting: false - openstack-tox-lower-constraints - openstack-tox-pylint gate: jobs: - freezer-api-ubuntu-xenial - openstack-tox-lower-constraints - openstack-tox-pylint experimental: jobs: - freezer-api-opensuse-423 - job: name: freezer-api-ubuntu-xenial parent: legacy-dsvm-base run: playbooks/legacy/freezer-api-ubuntu-xenial/run.yaml post-run: playbooks/legacy/freezer-api-ubuntu-xenial/post.yaml timeout: 7800 required-projects: - openstack-infra/devstack-gate - openstack/freezer - openstack/freezer-api - openstack/freezer-web-ui - openstack/python-freezerclient - openstack/freezer-tempest-plugin - job: name: freezer-api-centos-7 parent: legacy-dsvm-base run: playbooks/legacy/freezer-api-centos-7/run.yaml post-run: playbooks/legacy/freezer-api-centos-7/post.yaml timeout: 7800 nodeset: legacy-centos-7 required-projects: - openstack-infra/devstack-gate - openstack/freezer - openstack/freezer-api - openstack/freezer-web-ui - openstack/python-freezerclient - openstack/freezer-tempest-plugin - job: name: freezer-api-opensuse-423 parent: legacy-dsvm-base run: playbooks/legacy/freezer-api-opensuse-423/run.yaml post-run: playbooks/legacy/freezer-api-opensuse-423/post.yaml timeout: 7800 nodeset: legacy-opensuse-423 required-projects: - openstack-infra/devstack-gate - openstack/freezer - openstack/freezer-api - openstack/freezer-web-ui - openstack/python-freezerclient - openstack/freezer-tempest-plugin ,,67,0
openstack%2Fkolla-ansible~master~I0953751044f038a3fdd1acd49b3d2b053ac4bec8,openstack/kolla-ansible,master,I0953751044f038a3fdd1acd49b3d2b053ac4bec8,Remove '.. end' comments,MERGED,2018-09-28 02:18:07.000000000,2018-09-28 07:38:38.000000000,2018-09-28 07:38:38.000000000,"[{'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23717}, {'_account_id': 28176}]","[{'number': 1, 'created': '2018-09-28 02:18:07.000000000', 'files': ['doc/source/reference/manila-hnas-guide.rst', 'doc/source/reference/external-mariadb-guide.rst', 'doc/source/user/multi-regions.rst', 'doc/source/reference/bifrost.rst', 'doc/source/reference/ceph-guide.rst', 'doc/source/admin/advanced-configuration.rst', 'doc/source/reference/cinder-guide.rst', 'doc/source/contributor/vagrant-dev-env.rst', 'doc/source/reference/skydive-guide.rst', 'doc/source/contributor/running-tests.rst', 'doc/source/reference/nova-fake-driver.rst', 'doc/source/reference/vmware-guide.rst', 'doc/source/reference/kuryr-guide.rst', 'doc/source/reference/networking-guide.rst', 'doc/source/contributor/kolla-for-openstack-development.rst', 'doc/source/reference/osprofiler-guide.rst', 'doc/source/reference/central-logging-guide.rst', 'doc/source/user/operating-kolla.rst', 'doc/source/reference/hyperv-guide.rst', 'doc/source/reference/ironic-guide.rst', 'doc/source/user/multinode.rst', 'doc/source/reference/resource-constraints.rst', 'doc/source/user/quickstart.rst', 'doc/source/reference/swift-guide.rst', 'doc/source/reference/external-ceph-guide.rst', 'doc/source/reference/zun-guide.rst', 'doc/source/user/troubleshooting.rst', 'doc/source/reference/tacker-guide.rst', 'doc/source/reference/cinder-guide-hnas.rst', 'doc/source/reference/manila-guide.rst', 'doc/source/reference/designate-guide.rst', 'doc/source/contributor/CONTRIBUTING.rst', 'doc/source/reference/horizon-guide.rst', 'doc/source/admin/deployment-philosophy.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/eaa9815ad210c8e307a8c45e57b8b0e2bceb8121', 'message': ""Remove '.. end' comments\n\nFollowing by https://review.openstack.org/#/c/605097/\nThese were used by now-dead tooling. We can remove them.\n\nChange-Id: I0953751044f038a3fdd1acd49b3d2b053ac4bec8\n""}]",0,605906,eaa9815ad210c8e307a8c45e57b8b0e2bceb8121,10,5,1,19779,,,0,"Remove '.. end' comments

Following by https://review.openstack.org/#/c/605097/
These were used by now-dead tooling. We can remove them.

Change-Id: I0953751044f038a3fdd1acd49b3d2b053ac4bec8
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/06/605906/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/reference/manila-hnas-guide.rst', 'doc/source/reference/external-mariadb-guide.rst', 'doc/source/user/multi-regions.rst', 'doc/source/reference/bifrost.rst', 'doc/source/reference/ceph-guide.rst', 'doc/source/admin/advanced-configuration.rst', 'doc/source/reference/cinder-guide.rst', 'doc/source/contributor/vagrant-dev-env.rst', 'doc/source/reference/skydive-guide.rst', 'doc/source/contributor/running-tests.rst', 'doc/source/reference/nova-fake-driver.rst', 'doc/source/reference/vmware-guide.rst', 'doc/source/reference/kuryr-guide.rst', 'doc/source/reference/networking-guide.rst', 'doc/source/contributor/kolla-for-openstack-development.rst', 'doc/source/reference/osprofiler-guide.rst', 'doc/source/reference/central-logging-guide.rst', 'doc/source/user/operating-kolla.rst', 'doc/source/reference/hyperv-guide.rst', 'doc/source/reference/ironic-guide.rst', 'doc/source/user/multinode.rst', 'doc/source/reference/resource-constraints.rst', 'doc/source/user/quickstart.rst', 'doc/source/reference/swift-guide.rst', 'doc/source/reference/external-ceph-guide.rst', 'doc/source/reference/zun-guide.rst', 'doc/source/user/troubleshooting.rst', 'doc/source/reference/tacker-guide.rst', 'doc/source/reference/cinder-guide-hnas.rst', 'doc/source/reference/manila-guide.rst', 'doc/source/reference/designate-guide.rst', 'doc/source/contributor/CONTRIBUTING.rst', 'doc/source/reference/horizon-guide.rst', 'doc/source/admin/deployment-philosophy.rst']",34,eaa9815ad210c8e307a8c45e57b8b0e2bceb8121,trivial,,.. end ,0,789
openstack%2Ffreezer-web-ui~master~I2f0f5a2c581a31117d88c5fea30b53dc329a5c62,openstack/freezer-web-ui,master,I2f0f5a2c581a31117d88c5fea30b53dc329a5c62,add python 3.6 unit test job,MERGED,2018-08-22 01:35:29.000000000,2018-09-28 07:38:32.000000000,2018-09-28 07:38:32.000000000,"[{'_account_id': 11151}, {'_account_id': 13940}, {'_account_id': 14101}, {'_account_id': 14340}, {'_account_id': 14509}, {'_account_id': 16768}, {'_account_id': 22348}, {'_account_id': 22405}, {'_account_id': 22484}, {'_account_id': 23735}, {'_account_id': 26285}, {'_account_id': 27068}, {'_account_id': 27153}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-08-22 01:35:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/1e1f7aa7417e8f4eedce6c43bd0271a53e1ea224', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I2f0f5a2c581a31117d88c5fea30b53dc329a5c62\nStory: #2002586\nTask: #24296\n'}, {'number': 2, 'created': '2018-08-30 10:21:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/a3e830ec6ec01ead21177ce52e32f61d05c0f0da', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I2f0f5a2c581a31117d88c5fea30b53dc329a5c62\nStory: #2002586\nTask: #24296\n'}, {'number': 3, 'created': '2018-09-12 04:56:39.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/freezer-web-ui/commit/f1effba0026c99b05503fbc82634fec533ab8371', 'message': 'add python 3.6 unit test job\n\nThis is a mechanically generated patch to add a unit test job running\nunder Python 3.6 as part of the python3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I2f0f5a2c581a31117d88c5fea30b53dc329a5c62\nStory: #2002586\nTask: #24296\n'}]",0,594613,f1effba0026c99b05503fbc82634fec533ab8371,15,14,3,17499,,,0,"add python 3.6 unit test job

This is a mechanically generated patch to add a unit test job running
under Python 3.6 as part of the python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I2f0f5a2c581a31117d88c5fea30b53dc329a5c62
Story: #2002586
Task: #24296
",git fetch https://review.opendev.org/openstack/freezer-web-ui refs/changes/13/594613/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,1e1f7aa7417e8f4eedce6c43bd0271a53e1ea224,python3-first, - openstack-python36-jobs,,1,0
openstack%2Fnova~stable%2Fqueens~Ib2dcbba7f447f54c36877a4e7c29d1b6839a0a80,openstack/nova,stable/queens,Ib2dcbba7f447f54c36877a4e7c29d1b6839a0a80,Skip more rebuild tests for cells v1 job,MERGED,2018-09-26 13:08:26.000000000,2018-09-28 07:36:20.000000000,2018-09-28 07:36:20.000000000,"[{'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 13:08:26.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/2e3912b14a14ab858c7aad06865d1d3b452922c0', 'message': 'Skip more rebuild tests for cells v1 job\n\nThis skips a couple more tempest rebuild tests for\nlatent intermittent rebuild race failures\ndue to status sync delays with cells v1.\n\nConflicts:\n      devstack/tempest-dsvm-cells-rc\n\nNOTE(mriedem): The conflict is due to not having change\nIff89b9714e2413716bf87db6f0d773787c06eda3 in Queens\nand is not needed because the 2.63 microversion was not\navailable nor tested in Queens.\n\nChange-Id: Ib2dcbba7f447f54c36877a4e7c29d1b6839a0a80\nRelated-Bug: #1709985\n(cherry picked from commit 4a1b08365c1f4a0c69ba68beb46f237c9032d837)\n'}]",0,605416,2e3912b14a14ab858c7aad06865d1d3b452922c0,10,6,1,6873,,,0,"Skip more rebuild tests for cells v1 job

This skips a couple more tempest rebuild tests for
latent intermittent rebuild race failures
due to status sync delays with cells v1.

Conflicts:
      devstack/tempest-dsvm-cells-rc

NOTE(mriedem): The conflict is due to not having change
Iff89b9714e2413716bf87db6f0d773787c06eda3 in Queens
and is not needed because the 2.63 microversion was not
available nor tested in Queens.

Change-Id: Ib2dcbba7f447f54c36877a4e7c29d1b6839a0a80
Related-Bug: #1709985
(cherry picked from commit 4a1b08365c1f4a0c69ba68beb46f237c9032d837)
",git fetch https://review.opendev.org/openstack/nova refs/changes/16/605416/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,2e3912b14a14ab858c7aad06865d1d3b452922c0,bug/1709985,"# tempest.api.compute.servers.test_servers_microversions.ServerShowV257Test.test_rebuild_server r=""$r|(?:.*id\-803df848\-080a\-4261\-8f11\-b020cd9b6f60.*)"" # tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_rebuild_server_in_stop_state r=""$r|(?:.*id\-30449a88\-5aff\-4f9b\-9866\-6ee9b17f906d.*)""",,4,0
openstack%2Fnova~stable%2Fqueens~Ic422a5d7ac795e6e6882f1f0ad82022a7bd42229,openstack/nova,stable/queens,Ic422a5d7ac795e6e6882f1f0ad82022a7bd42229,Skip ServerShowV247Test.test_update_rebuild_list_server in nova-cells-v1 job,MERGED,2018-09-25 23:27:58.000000000,2018-09-28 07:35:09.000000000,2018-09-28 07:35:09.000000000,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 23:27:58.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/7bd6220f0b2c3a9d65dd701ba2a153fe55896066', 'message': 'Skip ServerShowV247Test.test_update_rebuild_list_server in nova-cells-v1 job\n\nAnother rebuild test that intermittently fails the cells v1\njob because of latent races with status changes in cells v1.\n\nChange-Id: Ic422a5d7ac795e6e6882f1f0ad82022a7bd42229\nRelated-Bug: #1709985\n(cherry picked from commit 3780335b5b63cc7ee5700c9eda2d168eb54470f8)\n'}]",0,605271,7bd6220f0b2c3a9d65dd701ba2a153fe55896066,21,6,1,6873,,,0,"Skip ServerShowV247Test.test_update_rebuild_list_server in nova-cells-v1 job

Another rebuild test that intermittently fails the cells v1
job because of latent races with status changes in cells v1.

Change-Id: Ic422a5d7ac795e6e6882f1f0ad82022a7bd42229
Related-Bug: #1709985
(cherry picked from commit 3780335b5b63cc7ee5700c9eda2d168eb54470f8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/71/605271/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,7bd6220f0b2c3a9d65dd701ba2a153fe55896066,bug/1709985,"# tempest.api.compute.servers.test_servers.ServerShowV247Test.test_update_rebuild_list_server r=""$r|(?:.*id\-8de397c2\-57d0\-4b90\-aa30\-e5d668f21a8b.*)""",,2,0
openstack%2Ftripleo-heat-templates~stable%2Fpike~I57d421feb6356d28002e77fb9bfa50a397758cbf,openstack/tripleo-heat-templates,stable/pike,I57d421feb6356d28002e77fb9bfa50a397758cbf,Improve nova statedir ownership logic,MERGED,2018-07-30 13:54:39.000000000,2018-09-28 07:11:38.000000000,2018-09-28 07:11:37.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 17216}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2018-07-30 13:54:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/241c896515919f495abfa9022668e83ba35e0c22', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15018\n\nDownstream-Only\nResolves: rhbz#1608913\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}, {'number': 2, 'created': '2018-07-30 15:48:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f7ac80a28d393befb5647ba8f1f8be868f8fc043', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15067\n\nDownstream-Only\nResolves: rhbz#1608913\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}, {'number': 3, 'created': '2018-07-30 15:55:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/10bd96bf055f32584731eab0b81f0d568f7e6723', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15067\n\nDownstream-Only\nResolves: rhbz#1608913\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}, {'number': 4, 'created': '2018-08-08 12:08:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c36b7a04cee72b832bc2cb7dec9b27e9bfc36cf5', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15067\n\nDownstream-Only\nResolves: rhbz#1608913\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}, {'number': 5, 'created': '2018-09-10 09:07:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9f9b5badf693463ad2fcc656167e44313650815b', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15067\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}, {'number': 6, 'created': '2018-09-25 14:45:19.000000000', 'files': ['releasenotes/notes/nova_statedir_ownership-54c75dfe8ad64b4f.yaml', 'docker_config_scripts/nova_statedir_ownership.py', 'docker/services/nova-ironic.yaml', 'test-requirements.txt', 'docker/services/nova-compute-common.yaml', 'docker_config_scripts/tests/__init__.py', '.testr.conf', 'tox.ini', 'docker_config_scripts/tests/test_nova_statedir_ownership.py', 'docker_config_scripts/__init__.py', 'docker/services/nova-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/880556f89711b8d5457cd71e63b667d9fe80f0a3', 'message': 'Improve nova statedir ownership logic\n\nThe nova_compute container kolla config is currently set to recursively change\nthe ownership of /var/lib/nova to nova:nova on startup.\n\nThis is necessary when upgrading from an non-container deployment to a\ncontainerized deployment as the nova uids are not consistent across the host\nand container image.\n\nIf the nova instancedir is an NFS mount then open filehandles are\nbroken and every VM using that NFS export fails with I/O errors.\n\nThis change re-implements the nova statedir ownership logic to target only the\nfiles/directories controlled by nova.\n\nRequires dist-git change: https://review.rdoproject.org/r/15067\n\nChange-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf\nCloses-bug: 1778465\n(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)\n(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)\n'}]",3,587066,880556f89711b8d5457cd71e63b667d9fe80f0a3,68,9,6,17216,,,0,"Improve nova statedir ownership logic

The nova_compute container kolla config is currently set to recursively change
the ownership of /var/lib/nova to nova:nova on startup.

This is necessary when upgrading from an non-container deployment to a
containerized deployment as the nova uids are not consistent across the host
and container image.

If the nova instancedir is an NFS mount then open filehandles are
broken and every VM using that NFS export fails with I/O errors.

This change re-implements the nova statedir ownership logic to target only the
files/directories controlled by nova.

Requires dist-git change: https://review.rdoproject.org/r/15067

Change-Id: I57d421feb6356d28002e77fb9bfa50a397758cbf
Closes-bug: 1778465
(cherry picked from commit 58624abf5ff97cb1cb016ceae621ef04ac672145)
(cherry picked from commit aff9312637ad47873c6dca738def289ac4aa6ff3)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/66/587066/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/nova_statedir_ownership-54c75dfe8ad64b4f.yaml', 'docker_config_scripts/nova_statedir_ownership.py', 'docker/services/nova-ironic.yaml', 'test-requirements.txt', 'docker/services/nova-compute-common.yaml', 'docker_config_scripts/tests/__init__.py', '.testr.conf', 'tox.ini', 'docker_config_scripts/tests/test_nova_statedir_ownership.py', 'docker/services/nova-compute.yaml', 'docker_config_scripts/__init__.py']",11,241c896515919f495abfa9022668e83ba35e0c22,bug/1778465,,,536,9
openstack%2Fopenstack-ansible-ops~master~I18283354ea49b26e1716dcab1f6452948e52845f,openstack/openstack-ansible-ops,master,I18283354ea49b26e1716dcab1f6452948e52845f,Fix auditd logs using Filebeat,MERGED,2018-09-27 22:04:45.000000000,2018-09-28 06:36:26.000000000,2018-09-28 06:36:26.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 22:04:45.000000000', 'files': ['elk_metrics_6x/templates/logstash-pipelines.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/e5b3b6e68864a6cb88603455727d390c02ca14eb', 'message': 'Fix auditd logs using Filebeat\n\nFilebeat auditd module only works by using Ingest which means that\nthe dashboards are broken when using Logstash.  This patch adds\nsome basic information in order for the dashboard to become\nfunctional.\n\nChange-Id: I18283354ea49b26e1716dcab1f6452948e52845f\n'}]",0,605869,e5b3b6e68864a6cb88603455727d390c02ca14eb,7,2,1,1004,,,0,"Fix auditd logs using Filebeat

Filebeat auditd module only works by using Ingest which means that
the dashboards are broken when using Logstash.  This patch adds
some basic information in order for the dashboard to become
functional.

Change-Id: I18283354ea49b26e1716dcab1f6452948e52845f
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/69/605869/1 && git format-patch -1 --stdout FETCH_HEAD,['elk_metrics_6x/templates/logstash-pipelines.yml.j2'],1,e5b3b6e68864a6cb88603455727d390c02ca14eb,," # NOTE(mnaser): Filebeat doesn't support shipping to different outputs # which means we need to parse `auditd` fileset here rather # than rely on ingest. if [fileset][module] == ""auditd"" { grok { break_on_match => false match => { message => [ ""type=%{WORD:[auditd][log][record_type]}"", ""msg=audit\(%{NUMBER:timestamp}:%{NUMBER:[auditd][log][sequence]}\)"", ""a0=\""%{DATA:[auditd][log][a0]}\"""", ""acct=\""%{DATA:[auditd][log][acct]}\"""", ""addr=%{IPORHOST:[auditd][log][addr]}"" ] } } date { match => [ ""timestamp"", ""UNIX"" ] remove_field => ""timestamp"" } if [auditd][log][addr] { geoip { source => ""[auditd][log][addr]"" target => ""[auditd][geoip]"" } } # NOTE(mnaser): We don't match all fields so `grok` thinks that we # failed. mutate { remove_tag => [""_grokparsefailure""] } } ",,37,0
openstack%2Fopenstack-ansible-ops~master~Ic0d49541b5863d1bdff3138c36d9de6331a7cafa,openstack/openstack-ansible-ops,master,Ic0d49541b5863d1bdff3138c36d9de6331a7cafa,Fix blank microversion,MERGED,2018-09-27 19:48:52.000000000,2018-09-28 06:35:26.000000000,2018-09-28 06:35:26.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 19:48:52.000000000', 'files': ['elk_metrics_6x/templates/logstash-pipelines.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/3b8961beca1d78ee41a90b6baca879e56fc0f267', 'message': 'Fix blank microversion\n\nIt is possible that OpenStack has no microversion logged which\nwould fail to parse.  This fixes that.\n\nChange-Id: Ic0d49541b5863d1bdff3138c36d9de6331a7cafa\n'}]",0,605855,3b8961beca1d78ee41a90b6baca879e56fc0f267,6,2,1,1004,,,0,"Fix blank microversion

It is possible that OpenStack has no microversion logged which
would fail to parse.  This fixes that.

Change-Id: Ic0d49541b5863d1bdff3138c36d9de6331a7cafa
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/55/605855/1 && git format-patch -1 --stdout FETCH_HEAD,['elk_metrics_6x/templates/logstash-pipelines.yml.j2'],1,3b8961beca1d78ee41a90b6baca879e56fc0f267,," match => { ""logmessage"" => ""%{IPORHOST:client_ip} \""%{WORD:verb} %{NOTSPACE:request}\"" status\: %{NUMBER:response} len\: %{NUMBER:bytes} microversion\: (%{NUMBER:microversion}|\-) time\: %{NUMBER:duration:float}"" } match => { ""logmessage"" => ""%{IPORHOST:client_ip} \""%{WORD:verb} %{NOTSPACE:request}\"" status\: %{NUMBER:response} len\: %{NUMBER:bytes} microversion\: (%{NUMBER:microversion}|\-)"" }"," match => { ""logmessage"" => ""%{IPORHOST:client_ip} \""%{WORD:verb} %{NOTSPACE:request}\"" status\: %{NUMBER:response} len\: %{NUMBER:bytes} microversion\: %{NUMBER:microversion} time\: %{NUMBER:duration:float}"" } match => { ""logmessage"" => ""%{IPORHOST:client_ip} \""%{WORD:verb} %{NOTSPACE:request}\"" status\: %{NUMBER:response} len\: %{NUMBER:bytes} microversion\: %{NUMBER:microversion}"" }",2,2
openstack%2Fopenstack-ansible-ops~master~I9ad0c0e8d6101cca1fc3c4a7cb5cabc3504e6e28,openstack/openstack-ansible-ops,master,I9ad0c0e8d6101cca1fc3c4a7cb5cabc3504e6e28,Add Instance ID to logs,MERGED,2018-09-27 18:57:17.000000000,2018-09-28 06:33:17.000000000,2018-09-28 06:33:17.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 18:57:17.000000000', 'files': ['elk_metrics_6x/templates/logstash-pipelines.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/4f03c511186651f8e0ee6c6ce26b0e96a3c9fd0d', 'message': 'Add Instance ID to logs\n\nThis will parse the logs and grab the instance ID out of it.\n\nChange-Id: I9ad0c0e8d6101cca1fc3c4a7cb5cabc3504e6e28\n'}]",0,605838,4f03c511186651f8e0ee6c6ce26b0e96a3c9fd0d,9,2,1,1004,,,0,"Add Instance ID to logs

This will parse the logs and grab the instance ID out of it.

Change-Id: I9ad0c0e8d6101cca1fc3c4a7cb5cabc3504e6e28
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/38/605838/1 && git format-patch -1 --stdout FETCH_HEAD,['elk_metrics_6x/templates/logstash-pipelines.yml.j2'],1,4f03c511186651f8e0ee6c6ce26b0e96a3c9fd0d,," # Instance ID from logs (i.e. ""[instance: 5ee83c6e-3604-467a-be54-e48429086e3f]"") grok { match => { ""logmessage"" => [""(\[instance\: %{NOTSPACE:instance_id}\] )?%{GREEDYDATA:logmessage}?""] } overwrite => [ ""logmessage"" ] } ",,8,0
openstack%2Fopenstacksdk~master~Ie259944de003c2afbd768ae118a768fffce474da,openstack/openstacksdk,master,Ie259944de003c2afbd768ae118a768fffce474da,Implement network update,MERGED,2018-09-05 14:02:30.000000000,2018-09-28 06:30:16.000000000,2018-09-28 06:30:16.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 17860}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-05 14:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9d0310cccc5815e5737730f7767f5b205f5b7a3c', 'message': 'Implement network update\n\nUnlike other networking resources, a network could not be updated yet.\n\nStory: 2003669\nTask: 26187\n\nChange-Id: Ie259944de003c2afbd768ae118a768fffce474da\n'}, {'number': 2, 'created': '2018-09-08 01:20:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/8a86e408111a3238a7c771402768ccdfe6b0dc4c', 'message': 'Implement network update\n\nUnlike other networking resources, a network could not be updated yet.\n\nStory: #2003669\nTask: #26187\n\nChange-Id: Ie259944de003c2afbd768ae118a768fffce474da\n'}, {'number': 3, 'created': '2018-09-08 01:36:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9aa72bbf154a897b9fdff3e66f22aac86397556a', 'message': 'Implement network update\n\nUnlike other networking resources, a network could not be updated yet.\n\nStory: #2003669\nTask: #26187\n\nChange-Id: Ie259944de003c2afbd768ae118a768fffce474da\n'}, {'number': 4, 'created': '2018-09-08 01:50:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/9a5549146a1620dd089ca8f958e2ba049b86ca1b', 'message': 'Implement network update\n\nUnlike other networking resources, a network could not be updated yet.\n\nStory: #2003669\nTask: #26187\n\nChange-Id: Ie259944de003c2afbd768ae118a768fffce474da\n'}, {'number': 5, 'created': '2018-09-13 00:02:07.000000000', 'files': ['openstack/cloud/openstackcloud.py', 'openstack/tests/functional/cloud/test_network.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c3e5eeb09b616e83b2bba01d133f9ba31e1f8da0', 'message': 'Implement network update\n\nUnlike other networking resources, a network could not be updated yet.\n\nStory: #2003669\nTask: #26187\n\nChange-Id: Ie259944de003c2afbd768ae118a768fffce474da\n'}]",12,600050,c3e5eeb09b616e83b2bba01d133f9ba31e1f8da0,38,4,5,17860,,,0,"Implement network update

Unlike other networking resources, a network could not be updated yet.

Story: #2003669
Task: #26187

Change-Id: Ie259944de003c2afbd768ae118a768fffce474da
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/50/600050/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/cloud/openstackcloud.py'],1,9d0310cccc5815e5737730f7767f5b205f5b7a3c,2003669," @_utils.valid_kwargs(""name"", ""shared"", ""admin_state_up"", ""external"", ""provider"", ""mtu_size"", ""port_security_enabled"") def update_network(self, name_or_id, **kwargs): if 'provider' in kwargs: if not isinstance(kwargs['provider'], dict): raise exc.OpenStackCloudException( ""Parameter 'provider' must be a dict"") # Only pass what we know for attr in kwargs['provider']: if attr not in ('physical_network', 'network_type', 'segmentation_id'): del kwargs['provider'][attr] else: kwargs['provider']['provider:' + attr] = kwargs['provider'].pop(attr) if 'external' in kwargs: kwargs['router:external'] = kwargs.pop('external') if 'port_security_enabled' in kwargs: if not isinstance(kwargs['port_security_enabled'], bool): raise exc.OpenStackCloudException( ""Parameter 'port_security_enabled' must be a bool"") if 'mtu_size' in kwargs: if not isinstance(kwargs['mtu_size'], int): raise exc.OpenStackCloudException( ""Parameter 'mtu_size' must be an integer."") if not kwargs['mtu_size'] >= 68: raise exc.OpenStackCloudException( ""Parameter 'mtu_size' must be greater than 67."") kwargs['mtu'] = kwargs.pop('mtu_size') curr_network = self.get_network(name_or_id) if not curr_network: raise exc.OpenStackCloudException( ""Network %s not found."" % name_or_id) data = self._network_client.put( ""/networks/{network_id}.json"".format(network_id=curr_network['id']), json={""network"": kwargs}, error_message=""Error updating network {0}"".format(name_or_id)) # Reset cache so the new network is picked up self._reset_network_caches() return self._get_and_munchify('network', data) ",,48,0
openstack%2Fpython-openstackclient~master~Ic6491203c2fb9085543d69f0bb5f38e5a96039da,openstack/python-openstackclient,master,Ic6491203c2fb9085543d69f0bb5f38e5a96039da,Fix some spaces in help messages,MERGED,2018-09-17 18:45:33.000000000,2018-09-28 06:11:50.000000000,2018-09-28 06:11:50.000000000,"[{'_account_id': 2}, {'_account_id': 1131}, {'_account_id': 6482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-17 18:45:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/e36d87fda00e011242b5aaddf70a2ad67088b82d', 'message': 'Fix some spaces in help messages\n\nFix some missing and not necessary trailing spaces in\nthe network v2 API files.  Also fixed one block indent\nthat was different from all its friends.\n\nTrivialfix\n\nChange-Id: Ic6491203c2fb9085543d69f0bb5f38e5a96039da\n'}, {'number': 2, 'created': '2018-09-27 21:54:59.000000000', 'files': ['openstackclient/network/v2/router.py', 'openstackclient/network/v2/port.py'], 'web_link': 'https://opendev.org/openstack/python-openstackclient/commit/3c5824415f93b86d62b7d778d5bb52a23b961a40', 'message': 'Fix some spaces in help messages\n\nFix some missing and not necessary trailing spaces in\nthe network v2 API files.  Also fixed one block indent\nthat was different from all its friends.\n\nTrivialfix\n\nChange-Id: Ic6491203c2fb9085543d69f0bb5f38e5a96039da\n'}]",0,603206,3c5824415f93b86d62b7d778d5bb52a23b961a40,12,4,2,1131,,,0,"Fix some spaces in help messages

Fix some missing and not necessary trailing spaces in
the network v2 API files.  Also fixed one block indent
that was different from all its friends.

Trivialfix

Change-Id: Ic6491203c2fb9085543d69f0bb5f38e5a96039da
",git fetch https://review.opendev.org/openstack/python-openstackclient refs/changes/06/603206/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackclient/network/v2/router.py', 'openstackclient/network/v2/subnet_pool.py', 'openstackclient/network/v2/port.py']",3,e36d87fda00e011242b5aaddf70a2ad67088b82d,fix-spaces," ""default: normal)"") help=_(""Clear existing information of binding:profile. "" help=_(""Clear existing allowed-address pairs associated "" ""with this port. "" ""(Specify both --allowed-address and --no-allowed-address "" help=_(""Desired key which should be removed from binding:profile "" ""from this port: ip-address=<ip-address>"" ""[,mac-address=<mac-address>] (repeat option to unset """," "" default: normal)"") help=_(""Clear existing information of binding:profile."" help=_(""Clear existing allowed-address pairs associated"" ""with this port."" ""(Specify both --allowed-address and --no-allowed-address"" help=_(""Desired key which should be removed from binding:profile"" ""from this port: ip-address=<ip-address> "" ""[,mac-address=<mac-address>] (repeat option to set """,14,14
openstack%2Fcinder-specs~master~I4a0a48768aa12e52eb0a144f85241c036eb4efd5,openstack/cinder-specs,master,I4a0a48768aa12e52eb0a144f85241c036eb4efd5,Force delete invalid attached volume,ABANDONED,2018-09-07 03:56:59.000000000,2018-09-28 06:10:43.000000000,,"[{'_account_id': 2243}, {'_account_id': 11904}, {'_account_id': 15961}, {'_account_id': 22348}, {'_account_id': 23083}, {'_account_id': 28459}, {'_account_id': 28948}]","[{'number': 1, 'created': '2018-09-07 03:56:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/e8950181a9122a02731e405b81b73a2be2850e60', 'message': ""Force delete invalid attached volume\n\nIn case of a failure in communication between Nova and Cinder,\ndeleteing an instance will not detach volumes correctly. As\na result, Cinder can't detach and delete the volumes. This is\nto resolve this problem.\n\nChange-Id: I4a0a48768aa12e52eb0a144f85241c036eb4efd5\nImplements: blueprint enhanced-force-deletion\n""}, {'number': 2, 'created': '2018-09-10 13:25:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3bc856e3c56d07de730cff203bb8edd2da6674e5', 'message': ""Force delete invalid attached volume\n\nIn case of a failure in communication between Nova and Cinder,\ndeleteing an instance will not detach volumes correctly. As\na result, Cinder can't detach and delete the volumes. This is\nto resolve this problem.\n\nChange-Id: I4a0a48768aa12e52eb0a144f85241c036eb4efd5\nImplements: blueprint enhanced-force-deletion\nRelated-bugs: #1791212\n""}, {'number': 3, 'created': '2018-09-10 16:32:40.000000000', 'files': ['specs/stein/enhanced-force-deletion.rst'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/3259512acb1d32c981429f268fe28d8325f71aa7', 'message': ""Force delete invalid attached volume\n\nIn case of a failure in communication between Nova and Cinder,\ndeleteing an instance will not detach volumes correctly. As\na result, Cinder can't detach and delete the volumes. This is\nto resolve this problem.\n\nChange-Id: I4a0a48768aa12e52eb0a144f85241c036eb4efd5\nImplements: blueprint enhanced-force-deletion\nRelated-bugs: bug #1791213\n""}]",10,600638,3259512acb1d32c981429f268fe28d8325f71aa7,12,7,3,15961,,,0,"Force delete invalid attached volume

In case of a failure in communication between Nova and Cinder,
deleteing an instance will not detach volumes correctly. As
a result, Cinder can't detach and delete the volumes. This is
to resolve this problem.

Change-Id: I4a0a48768aa12e52eb0a144f85241c036eb4efd5
Implements: blueprint enhanced-force-deletion
Related-bugs: bug #1791213
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/38/600638/2 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein/enhanced-force-deletion.rst'],1,e8950181a9122a02731e405b81b73a2be2850e60,bp/enhanced-force-deletion,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================== Enhanced force deletion ================================================== https://blueprints.launchpad.net/cinder/+spec/enhanced-force-deletion This spec proposes enhancement of force-deletion volumes. Problem description =================== In case of a failure in commmunication between Nova and Cinder volume service, to delete an instance with attached volumes, the instance can be deleted, but the attached volume can't be detached. After the volume service recovers, the volumes are in attached state and current force-deletion can't delete them successfully. Use Cases ========= When communication between Nova and Cinder volume service is lost, delete an instance with attached volumes. Proposed change =============== The proposal is to - Allow 'attach_status' to be 'attached' with force deletion. - If 'attach_status' is 'attached', Cinder will check whether its attached instances still exist. If the instances are gone, Cinder will detach the volumes and delete them. Alternatives ------------ None Data model impact ----------------- None REST API impact --------------- None. Cinder-client impact -------------------- None. Security impact --------------- None. Notifications impact -------------------- None. Other end user impact --------------------- User can force-delete orphan attached volumes. Performance Impact ------------------ None. Other deployer impact --------------------- None. Developer impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: Lisa Li (xiaoyan.li@intel.com) Work Items ---------- * Update API interface to allow force deletion of attached volumes. * Add logic to check whether attached instances exist. If yes, detach the volumes in Cinder and then delete them. * Add related unit testcases. Dependencies ============ None Testing ======= * Add unit tests to cover this change. Documentation Impact ==================== * Add documents about the enhancement. References ========== None. ",,124,0
openstack%2Fsahara~master~I51c8daebe42345ee5d610356d2c1710a069f0355,openstack/sahara,master,I51c8daebe42345ee5d610356d2c1710a069f0355,"Force the format of ssh key to PEM, at least for now",MERGED,2018-09-25 10:00:42.000000000,2018-09-28 06:02:38.000000000,2018-09-28 06:02:38.000000000,"[{'_account_id': 6476}, {'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 16312}, {'_account_id': 22348}, {'_account_id': 23078}]","[{'number': 1, 'created': '2018-09-25 10:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/sahara/commit/cf255e0f87cce07aef3dca1ba8eab0a6d5239dfa', 'message': 'Force the format of ssh key to PEM, at least for now\n\nUnfortunately it is not possible to switch to the new, more secure, native\nformat of OpenSSH >=6.5, because paramiko does not support it:\nhttps://github.com/paramiko/paramiko/issues/602\n\nThis change should fix the unit test (and probably the behavior)\nwhen sahara services are executed on distributions which ships\nOpenSSL 1.1 and which switched to the new format by default\n(at least the current Debian Sid and Fedora 28).\n\nStory: 2003674\nTask: 26193\nChange-Id: I51c8daebe42345ee5d610356d2c1710a069f0355\n'}, {'number': 2, 'created': '2018-09-25 12:37:16.000000000', 'files': ['sahara/utils/crypto.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/e0fd845de1f40c5c69de7caf61116ebc6ab808a4', 'message': 'Force the format of ssh key to PEM, at least for now\n\nUnfortunately it is not possible to switch to the new, more secure, native\nformat of OpenSSH >=6.5, because paramiko does not support it:\nhttps://github.com/paramiko/paramiko/issues/602\n\nThis change should fix the unit test (and probably the behavior)\nwhen sahara services are executed on distributions which ships\nOpenSSL 1.1 and which switched to the new format by default\n(at least the current Debian Sid and Fedora 28).\n\nStory: 2003674\nTask: 26193\nChange-Id: I51c8daebe42345ee5d610356d2c1710a069f0355\n'}]",0,605028,e0fd845de1f40c5c69de7caf61116ebc6ab808a4,15,6,2,10459,,,0,"Force the format of ssh key to PEM, at least for now

Unfortunately it is not possible to switch to the new, more secure, native
format of OpenSSH >=6.5, because paramiko does not support it:
https://github.com/paramiko/paramiko/issues/602

This change should fix the unit test (and probably the behavior)
when sahara services are executed on distributions which ships
OpenSSL 1.1 and which switched to the new format by default
(at least the current Debian Sid and Fedora 28).

Story: 2003674
Task: 26193
Change-Id: I51c8daebe42345ee5d610356d2c1710a069f0355
",git fetch https://review.opendev.org/openstack/sahara refs/changes/28/605028/2 && git format-patch -1 --stdout FETCH_HEAD,['sahara/utils/crypto.py'],1,cf255e0f87cce07aef3dca1ba8eab0a6d5239dfa,fix-ssh-key-format-openssl11," # The key is generated in the old PEM format, instead of the native # format of OpenSSH >=6.5, because paramiko does not support it: # https://github.com/paramiko/paramiko/issues/602 '-m', 'PEM', # old PEM format",,4,0
openstack%2Ffreezer-api~master~I53fb97831497a1008e0a2fd11a322593e074c491,openstack/freezer-api,master,I53fb97831497a1008e0a2fd11a322593e074c491,"Modifying code comments errors.  ""v1"" modified to ""v2"",and add new parameter {project_id}",MERGED,2018-09-27 11:35:41.000000000,2018-09-28 05:58:28.000000000,2018-09-28 05:58:28.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 27068}]","[{'number': 1, 'created': '2018-09-27 11:35:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/0a4d2e7bbdefca02378bef6b7e44c2393a4ffcb3', 'message': 'Modifying code comments errors.\n ""v1"" modified to ""v2"",and add new parameter {project_id}\n\neg:\n  old comment:\n    """"""\n    Handler for endpoint: /v1/jobs\n    """"""\n  new comment:\n    """"""\n    Handler for endpoint: /v2/{project-id}/jobs\n    """"""\n\nChange-Id: I53fb97831497a1008e0a2fd11a322593e074c491\n'}, {'number': 2, 'created': '2018-09-28 00:26:09.000000000', 'files': ['freezer_api/api/v2/clients.py', 'freezer_api/api/v2/sessions.py', 'freezer_api/api/v2/jobs.py', 'freezer_api/api/v2/backups.py', 'freezer_api/api/v2/actions.py'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/45b9bc93aba56cbea75bda57cea785c2796868a0', 'message': 'Modifying code comments errors.\n ""v1"" modified to ""v2"",and add new parameter {project_id}\n\neg:\n  old comment:\n    """"""\n    Handler for endpoint: /v1/jobs\n    """"""\n  new comment:\n    """"""\n    Handler for endpoint: /v2/{project-id}/jobs\n    """"""\n\nChange-Id: I53fb97831497a1008e0a2fd11a322593e074c491\n'}]",11,605655,45b9bc93aba56cbea75bda57cea785c2796868a0,12,4,2,21069,,,0,"Modifying code comments errors.
 ""v1"" modified to ""v2"",and add new parameter {project_id}

eg:
  old comment:
    """"""
    Handler for endpoint: /v1/jobs
    """"""
  new comment:
    """"""
    Handler for endpoint: /v2/{project-id}/jobs
    """"""

Change-Id: I53fb97831497a1008e0a2fd11a322593e074c491
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/55/605655/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezer_api/api/v2/clients.py', 'freezer_api/api/v2/sessions.py', 'freezer_api/api/v2/jobs.py', 'freezer_api/api/v2/backups.py', 'freezer_api/api/v2/actions.py']",5,0a4d2e7bbdefca02378bef6b7e44c2393a4ffcb3,patch1," Handler for endpoint: /v2/{project_id}/actions # GET /v2/{project_id}/actions(?limit,offset) Lists actions # POST /v2/{project_id}/actions Creates action entry Handler for endpoint: /v2/{project_id}/actions/{action_id} # GET /v2/{project_id}/actions/{action_id} retrieves the specified action # DELETE /v2/{project_id}/actions/{action_id} Deletes the specified action # PATCH /v2/{project_id}/actions/{action_id} updates the specified action # PUT /v2/{project_id}/actions/{action_id} creates/replaces the specified action"," Handler for endpoint: /v1/actions # GET /v1/actions(?limit,offset) Lists actions # POST /v1/actions Creates action entry Handler for endpoint: /v1/actions/{action_id} # GET /v1/actions/{action_id} retrieves the specified action # DELETE /v1/actions/{action_id} Deletes the specified action # PATCH /v1/actions/{action_id} updates the specified action # PUT /v1/actions/{action_id} creates/replaces the specified action",40,40
openstack%2Fproject-config~master~Iad1b5667fd6d1d4bfa9fe50706ad71debd01d5c6,openstack/project-config,master,Iad1b5667fd6d1d4bfa9fe50706ad71debd01d5c6,Grafana: set zuul node requests yaxis min,MERGED,2018-09-27 23:40:53.000000000,2018-09-28 05:57:53.000000000,2018-09-28 05:57:53.000000000,"[{'_account_id': 4162}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 23:40:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/a86980df7ef4a350c0f4a0529ed0666d3450687d', 'message': ""Grafana: set zuul node requests yaxis min\n\nSince node requests are something that we generally want to see\nreduced to 0, it can be misleading to show a graph where the lowest\npoint on the y axis is, for example (as I write this) nearly 4,000.\nFix the minimum to zero so it's easier to see what the overall trend\ntoward zero is.\n\nChange-Id: Iad1b5667fd6d1d4bfa9fe50706ad71debd01d5c6\n""}, {'number': 2, 'created': '2018-09-28 03:45:51.000000000', 'files': ['grafana/zuul-status.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f0f6190d0b195732f9670460e239c87037cf24c7', 'message': ""Grafana: set zuul node requests yaxis min\n\nSince node requests are something that we generally want to see\nreduced to 0, it can be misleading to show a graph where the lowest\npoint on the y axis is, for example (as I write this) nearly 4,000.\nFix the minimum to zero so it's easier to see what the overall trend\ntoward zero is.\n\nChange-Id: Iad1b5667fd6d1d4bfa9fe50706ad71debd01d5c6\n""}]",1,605886,f0f6190d0b195732f9670460e239c87037cf24c7,10,3,2,1,,,0,"Grafana: set zuul node requests yaxis min

Since node requests are something that we generally want to see
reduced to 0, it can be misleading to show a graph where the lowest
point on the y axis is, for example (as I write this) nearly 4,000.
Fix the minimum to zero so it's easier to see what the overall trend
toward zero is.

Change-Id: Iad1b5667fd6d1d4bfa9fe50706ad71debd01d5c6
",git fetch https://review.opendev.org/openstack/project-config refs/changes/86/605886/1 && git format-patch -1 --stdout FETCH_HEAD,['grafana/zuul-status.yaml'],1,a86980df7ef4a350c0f4a0529ed0666d3450687d,605886, yaxes: min: 0,,2,0
openstack%2Fzaqar-specs~master~I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78,openstack/zaqar-specs,master,I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78,Spec of bp delete-message-with-claim-id support,MERGED,2018-01-05 03:55:45.000000000,2018-09-28 05:30:58.000000000,2018-09-28 05:30:58.000000000,"[{'_account_id': 6484}, {'_account_id': 6547}, {'_account_id': 8846}, {'_account_id': 14203}, {'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 28035}]","[{'number': 1, 'created': '2018-01-05 03:55:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/b669686c71f1da47a856c167a7745fe6d83a5cb8', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 2, 'created': '2018-01-05 09:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/843781708b0baabcdbc5c00798c3589099776edf', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 3, 'created': '2018-01-10 09:06:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/d0b3e5e445bdc39aeaebb7a1d08cbc777ebe30ca', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 4, 'created': '2018-09-06 01:35:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/a99ca1cb19bef186387f32174a75c86c8007d9c9', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 5, 'created': '2018-09-13 07:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/57f3b66ffe1be33c4830b9c4aad61c17250072ad', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 6, 'created': '2018-09-13 07:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/6434fd89cd4db27dd22ddf69c53f4eac8c5b5608', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}, {'number': 7, 'created': '2018-09-28 02:35:33.000000000', 'files': ['specs/stein/index.rst', 'specs/stein/delete-message-with-claim-id.rst'], 'web_link': 'https://opendev.org/openstack/zaqar-specs/commit/c180ddf93ebce4d3b3283832159e887e0552407c', 'message': 'Spec of bp delete-message-with-claim-id support\n\nDelete Message with claim id means that when a user deletes a message, the\nmessage must be claimed. If you want to delete a message, you will have to use\nboth message id and claim id. This can improve the security of the message.\n\nChange-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78\nblueprint: delete-message-with-claim-id\n'}]",34,531286,c180ddf93ebce4d3b3283832159e887e0552407c,44,8,7,14203,,,0,"Spec of bp delete-message-with-claim-id support

Delete Message with claim id means that when a user deletes a message, the
message must be claimed. If you want to delete a message, you will have to use
both message id and claim id. This can improve the security of the message.

Change-Id: I81f505e6ac3ee8f8ab42ce0c1b80ecc878f67b78
blueprint: delete-message-with-claim-id
",git fetch https://review.opendev.org/openstack/zaqar-specs refs/changes/86/531286/7 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/delete-message-with-claim-id.rst'],1,b669686c71f1da47a856c167a7745fe6d83a5cb8,bp/delete-message-with-claim-id,".. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/zaqar/+spec/awesome-thing should be named awesome-thing.rst. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ============================= Delete Message With Claim ID ============================= https://blueprints.launchpad.net/zaqar/+spec/delete-message-with-claim-id Delete Message with claim id means that when a user deletes a message, the message must be claimed. If you want to delete a message, you will have to use both message id and claim id. This can improve the security of the message. Problem description =================== Currently, any client who knows the message ID can delete the message if it not be claimed. It could cause some unexpected problems. A better way to delete a message is make sure the message is deleted by the client who is claiming the message. Amazon SQS use receipt handler to delete a message[1]. Zaqar can use claim id and message id to delete messages. Proposed change =============== 1. Modify the logic to delete messages. Changing the original logic to that you must use the claim id and the message id whenever you want to delete a message. If the claim ID is invalid, the message can not be deleted. You must re-claim the messages, and then delete it. Specific changes are as follows: * If you just use the message id will not be able to delete the message. * The message can only be deleted after it has been claimed. 2. Add automatic delete message function after the messages be claimed. When claim message, the user can choose whether to automatically delete these messages. If you choose to automatically delete, zaqar will return the message, and these messages are deleted from the backend. Specific changes are as follows: * The claim POST api need add a parameter named ``auto_delete``. It is a boolean type. * The messages be claimed will be deleted when ``auto_delete`` is ``True``. Drawbacks --------- None Alternatives ------------ None Implementation ============== Assignee(s) ----------- Primary assignee: cdyangzhenyu <cdyangzhenyu@gmail.com> Milestones ---------- Target Milestone for completion: Queens Q-4 Work Items ---------- #. Modify message delete code. #. Add release note for this feature. #. Update API reference. #. Add user/developer document for this feature. #. Change unit, functional and tempest tests accordingly. Dependencies ============ None References ========== [1]:https://docs.aws.amazon.com/AWSSimpleQueueService/latest/SQSDeveloperGuide/sqs-queue-message-identifiers.html",,99,0
openstack%2Fopenstack-ansible-ops~master~I1b34eef0913dc0cda1c58d27e8f53ffdcfc3aa22,openstack/openstack-ansible-ops,master,I1b34eef0913dc0cda1c58d27e8f53ffdcfc3aa22,[Trivial Fix] Replace Chinese punctuation with English punctuation,MERGED,2018-09-28 01:41:43.000000000,2018-09-28 05:30:11.000000000,2018-09-28 05:30:11.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-28 01:41:43.000000000', 'files': ['elk_metrics/templates/kibana.yml.j2', 'elk_metrics_6x/roles/elastic_kibana/templates/kibana.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/3af2caebb88fb42fef67c07e3f30d9e28bcfa1ee', 'message': '[Trivial Fix] Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input method.\nWhen read from english context, it makes some confusion.\n\nChange-Id: I1b34eef0913dc0cda1c58d27e8f53ffdcfc3aa22\n'}]",0,605901,3af2caebb88fb42fef67c07e3f30d9e28bcfa1ee,6,2,1,27565,,,0,"[Trivial Fix] Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input method.
When read from english context, it makes some confusion.

Change-Id: I1b34eef0913dc0cda1c58d27e8f53ffdcfc3aa22
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/01/605901/1 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics/templates/kibana.yml.j2', 'elk_metrics_6x/roles/elastic_kibana/templates/kibana.yml.j2']",2,3af2caebb88fb42fef67c07e3f30d9e28bcfa1ee,fix_punctuation,"# When this setting's value is true Kibana uses the hostname specified in the server.host# dashboards. Kibana creates a new index if the index doesn't already exist.# To disregard the validity of SSL certificates, change this setting's value to false.","# When this settings value is true Kibana uses the hostname specified in the server.host# dashboards. Kibana creates a new index if the index doesnt already exist.# To disregard the validity of SSL certificates, change this settings value to false.",6,6
openstack%2Fnova~stable%2Fqueens~I42f08ee2a7282c9cad761bbe0daa111e79678791,openstack/nova,stable/queens,I42f08ee2a7282c9cad761bbe0daa111e79678791,Skip ServerShowV254Test.test_rebuild_server in cells v1 job,MERGED,2018-09-25 23:27:58.000000000,2018-09-28 05:26:55.000000000,2018-09-28 05:26:55.000000000,"[{'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 23:27:58.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/9a72b720859ccea305db17cf9b8047300aba604e', 'message': 'Skip ServerShowV254Test.test_rebuild_server in cells v1 job\n\nThis adds yet another rebuild test to the blacklist for the\ncells v1 job. Rebuild status updates are racy in the cells v1\njob because of the async status updates.\n\nChange-Id: I42f08ee2a7282c9cad761bbe0daa111e79678791\nRelated-Bug: #1709985\n(cherry picked from commit 771a736818b5c64e3a5796e809f17cd759542ad4)\n'}]",0,605270,9a72b720859ccea305db17cf9b8047300aba604e,19,6,1,6873,,,0,"Skip ServerShowV254Test.test_rebuild_server in cells v1 job

This adds yet another rebuild test to the blacklist for the
cells v1 job. Rebuild status updates are racy in the cells v1
job because of the async status updates.

Change-Id: I42f08ee2a7282c9cad761bbe0daa111e79678791
Related-Bug: #1709985
(cherry picked from commit 771a736818b5c64e3a5796e809f17cd759542ad4)
",git fetch https://review.opendev.org/openstack/nova refs/changes/70/605270/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,9a72b720859ccea305db17cf9b8047300aba604e,bug/1709985,"# tempest.api.compute.servers.test_servers_microversions.ServerShowV254Test.test_rebuild_server r=""$r|(?:.*id\-09170a98\-4940\-4637\-add7\-1a35121f1a5a.*)""",,2,0
openstack%2Fnova~master~I597dee74d33de337913eddda74ab056fbf81a23c,openstack/nova,master,I597dee74d33de337913eddda74ab056fbf81a23c,Enforce case-sensitive hostnames in aggregate host add,MERGED,2018-09-24 20:49:26.000000000,2018-09-28 05:26:48.000000000,2018-09-28 05:26:48.000000000,"[{'_account_id': 7}, {'_account_id': 4393}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9373}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23312}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-24 20:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c3a7f80b4f409d3476d5b20a12a9b9b1ab134aa', 'message': 'Enforce case-sensitive hostnames in aggregate host add\n\nIf we are using a case-insensitive backend database like mysql, a\nuser can request an aggregate host add with a non-matching hostname\nand we will not signal failure. We will create a mapping which will\nnot actually include that host in the aggregate, which will be\nconfusing later. This change makes us fail if the host name does not\nmatch exactly, which is the same behavior as if we are using a\ncase-sensitive backend (like postgres).\n\nChange-Id: I597dee74d33de337913eddda74ab056fbf81a23c\nCloses-Bug: #1709260\n'}, {'number': 2, 'created': '2018-09-24 20:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/75f75c0946959e156d6a94200af272de3a1519b8', 'message': 'Enforce case-sensitive hostnames in aggregate host add\n\nIf we are using a case-insensitive backend database like mysql, a\nuser can request an aggregate host add with a non-matching hostname\nand we will not signal failure. We will create a mapping which will\nnot actually include that host in the aggregate, which will be\nconfusing later. This change makes us fail if the host name does not\nmatch exactly, which is the same behavior as if we are using a\ncase-sensitive backend (like postgres).\n\nChange-Id: I597dee74d33de337913eddda74ab056fbf81a23c\nCloses-Bug: #1709260\n'}, {'number': 3, 'created': '2018-09-24 21:15:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0aa2cf0aee8000223844b2e68a4a968fb302015a', 'message': 'Enforce case-sensitive hostnames in aggregate host add\n\nIf we are using a case-insensitive backend database like mysql, a\nuser can request an aggregate host add with a non-matching hostname\nand we will not signal failure. We will create a mapping which will\nnot actually include that host in the aggregate, which will be\nconfusing later. This change makes us fail if the host name does not\nmatch exactly, which is the same behavior as if we are using a\ncase-sensitive backend (like postgres).\n\nChange-Id: I597dee74d33de337913eddda74ab056fbf81a23c\nCloses-Bug: #1709260\n'}, {'number': 4, 'created': '2018-09-25 23:00:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/61b61991b61397f7e4a7daf58d70645047f413ea', 'message': 'Enforce case-sensitive hostnames in aggregate host add\n\nIf we are using a case-insensitive backend database like mysql, a\nuser can request an aggregate host add with a non-matching hostname\nand we will not signal failure. We will create a mapping which will\nnot actually include that host in the aggregate, which will be\nconfusing later. This change makes us fail if the host name does not\nmatch exactly, which is the same behavior as if we are using a\ncase-sensitive backend (like postgres).\n\nChange-Id: I597dee74d33de337913eddda74ab056fbf81a23c\nCloses-Bug: #1709260\n'}, {'number': 5, 'created': '2018-09-25 23:05:39.000000000', 'files': ['nova/tests/unit/compute/test_compute.py', 'nova/tests/unit/compute/test_host_api.py', 'nova/compute/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c8e2de668434861b87495e0a0f715b2f90d8ec05', 'message': 'Enforce case-sensitive hostnames in aggregate host add\n\nIf we are using a case-insensitive backend database like mysql, a\nuser can request an aggregate host add with a non-matching hostname\nand we will not signal failure. We will create a mapping which will\nnot actually include that host in the aggregate, which will be\nconfusing later. This change makes us fail if the host name does not\nmatch exactly, which is the same behavior as if we are using a\ncase-sensitive backend (like postgres).\n\nChange-Id: I597dee74d33de337913eddda74ab056fbf81a23c\nCloses-Bug: #1709260\n'}]",1,604906,c8e2de668434861b87495e0a0f715b2f90d8ec05,55,19,5,4393,,,0,"Enforce case-sensitive hostnames in aggregate host add

If we are using a case-insensitive backend database like mysql, a
user can request an aggregate host add with a non-matching hostname
and we will not signal failure. We will create a mapping which will
not actually include that host in the aggregate, which will be
confusing later. This change makes us fail if the host name does not
match exactly, which is the same behavior as if we are using a
case-sensitive backend (like postgres).

Change-Id: I597dee74d33de337913eddda74ab056fbf81a23c
Closes-Bug: #1709260
",git fetch https://review.opendev.org/openstack/nova refs/changes/06/604906/4 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute.py', 'nova/compute/api.py']",2,5c3a7f80b4f409d3476d5b20a12a9b9b1ab134aa,bug/1709260," service = objects.Service.get_by_compute_host(context, host_name) service = _find_service_in_cell(context, service_host=host_name) if service.host != host_name: # NOTE(danms): If we found a servicebut it is not an # exact match, we may have a case-insensitive backend # database (like mysql) which will end up with us # adding the host-aggregate mapping with a # non-matching hostname. raise exception.ComputeHostNotFound(host=host_name) "," objects.Service.get_by_compute_host(context, host_name) _find_service_in_cell(context, service_host=host_name)",34,2
openstack%2Fironic~master~I5d66333796c8cdc00d0cca1e1dd4c7828ceb5612,openstack/ironic,master,I5d66333796c8cdc00d0cca1e1dd4c7828ceb5612,Minor fixes for docs on changing hardware types,MERGED,2018-09-27 11:38:53.000000000,2018-09-28 05:21:08.000000000,2018-09-28 05:21:08.000000000,"[{'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14208}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}]","[{'number': 1, 'created': '2018-09-27 11:38:53.000000000', 'files': ['doc/source/admin/drivers.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8a75ebf42d0ef7cb8ddd4f052d3bdd91f51e995c', 'message': 'Minor fixes for docs on changing hardware types\n\nAddresses comments on https://review.openstack.org/#/c/585463/\nFollow-up for story #2002868.\n\nChange-Id: I5d66333796c8cdc00d0cca1e1dd4c7828ceb5612\n'}]",2,605656,8a75ebf42d0ef7cb8ddd4f052d3bdd91f51e995c,10,6,1,10239,,,0,"Minor fixes for docs on changing hardware types

Addresses comments on https://review.openstack.org/#/c/585463/
Follow-up for story #2002868.

Change-Id: I5d66333796c8cdc00d0cca1e1dd4c7828ceb5612
",git fetch https://review.opendev.org/openstack/ironic refs/changes/56/605656/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/drivers.rst'],1,8a75ebf42d0ef7cb8ddd4f052d3bdd91f51e995c,story/2002868,"interfaces can be changed later via the node update API. Changing Hardware InterfacesHardware interfaces can be changed by the following command::Changing Hardware Type .. note:: This feature is available starting with ironic 11.1.0 (Rocky series, API version 1.45). .. note:: This feature is available starting with ironic 11.1.0 (Rocky series, API version 1.45).",interfaces can be changed later. Changing hardware interfacesA hardware interfaces can be changed by the following command::Changing hardware type .. note:: This feature is available starting with the Rocky release. .. note:: This feature is available starting with the Rocky release.,8,6
openstack%2Fzun~master~Ibc781695903308ba2f26423b56f54b533845c909,openstack/zun,master,Ibc781695903308ba2f26423b56f54b533845c909,Pass database model object to _add_filters,MERGED,2018-09-25 01:18:41.000000000,2018-09-28 04:48:48.000000000,2018-09-28 04:48:48.000000000,"[{'_account_id': 22348}, {'_account_id': 23365}]","[{'number': 1, 'created': '2018-09-25 01:18:41.000000000', 'files': ['zun/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/zun/commit/091791939550d94de34114e3b9a128208368adbf', 'message': 'Pass database model object to _add_filters\n\nThe _add_filters is for populating database query for filtering.\nIt needs to know which table that the query is for.\n\nChange-Id: Ibc781695903308ba2f26423b56f54b533845c909\n'}]",0,604949,091791939550d94de34114e3b9a128208368adbf,6,2,1,11536,,,0,"Pass database model object to _add_filters

The _add_filters is for populating database query for filtering.
It needs to know which table that the query is for.

Change-Id: Ibc781695903308ba2f26423b56f54b533845c909
",git fetch https://review.opendev.org/openstack/zun refs/changes/49/604949/1 && git format-patch -1 --stdout FETCH_HEAD,['zun/db/sqlalchemy/api.py'],1,091791939550d94de34114e3b9a128208368adbf,," def _add_filters(self, query, model, filters=None, filter_names=None): column = getattr(model, name) column = getattr(model, name) query = query.filter(column == value) return self._add_filters(query, models.Container, filters=filters, return self._add_filters(query, models.VolumeMapping, filters=filters, return self._add_filters(query, models.ZunService, filters=filters, return self._add_filters(query, models.Image, filters=filters, return self._add_filters(query, models.ResourceProvider, filters=filters, return self._add_filters(query, models.Inventory, filters=filters, return self._add_filters(query, models.Allocation, filters=filters, return self._add_filters(query, models.ComputeNode, filters=filters, return self._add_filters(query, models.Capsule, filters=filters, return self._add_filters(query, models.ExecInstance, filters=filters,"," def _add_filters(self, query, filters=None, filter_names=None): column = getattr(models.Container, name) query = query.filter_by(**{name: value}) return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters, return self._add_filters(query, filters=filters,",15,13
openstack%2Fdevstack~stable%2Focata~I163fc48c860bae2a92c83cfdaed26b2e54630e20,openstack/devstack,stable/ocata,I163fc48c860bae2a92c83cfdaed26b2e54630e20,Remove fping requirement,MERGED,2018-09-24 17:34:21.000000000,2018-09-28 04:43:15.000000000,2018-09-28 04:43:15.000000000,"[{'_account_id': 7118}, {'_account_id': 9003}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16376}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-24 17:34:21.000000000', 'files': ['files/debs/n-api', 'files/rpms-suse/n-api', 'files/rpms/n-api'], 'web_link': 'https://opendev.org/openstack/devstack/commit/601e71064cea082c6c72373d7e734e2628e3f3a3', 'message': ""Remove fping requirement\n\nThe os-fping API was deprecated in nova in\nI92064cbcb5f6414da0c9d294f912a860428af698.  I can't see anything\nobviously using it on codesearch.\n\nThis is only in EPEL for centos, which I'm trying to remove.  But I\nthink less dependencies is always better than more in general hence\nthe removal.\n\nThis is essentially a revert of\nIbdc7479a9038321e4fc3953774a6f3e1dac90530\n\nChange-Id: I163fc48c860bae2a92c83cfdaed26b2e54630e20\n(cherry picked from commit bc6c992e3c5cf7ae48e64203cc83cb7665c5050e)\n""}]",0,604857,601e71064cea082c6c72373d7e734e2628e3f3a3,26,7,1,16643,,,0,"Remove fping requirement

The os-fping API was deprecated in nova in
I92064cbcb5f6414da0c9d294f912a860428af698.  I can't see anything
obviously using it on codesearch.

This is only in EPEL for centos, which I'm trying to remove.  But I
think less dependencies is always better than more in general hence
the removal.

This is essentially a revert of
Ibdc7479a9038321e4fc3953774a6f3e1dac90530

Change-Id: I163fc48c860bae2a92c83cfdaed26b2e54630e20
(cherry picked from commit bc6c992e3c5cf7ae48e64203cc83cb7665c5050e)
",git fetch https://review.opendev.org/openstack/devstack refs/changes/57/604857/1 && git format-patch -1 --stdout FETCH_HEAD,"['files/debs/n-api', 'files/rpms-suse/n-api', 'files/rpms/n-api']",3,601e71064cea082c6c72373d7e734e2628e3f3a3,fping-rm-stable/ocata,,fping ,0,3
openstack%2Ftripleo-heat-templates~master~Ifc6a809a45a2a08e5bb11f95b04ac4d69dada3c4,openstack/tripleo-heat-templates,master,Ifc6a809a45a2a08e5bb11f95b04ac4d69dada3c4,Expose IronicImageDownloadSource as a parameter,MERGED,2018-09-19 13:37:38.000000000,2018-09-28 03:57:41.000000000,2018-09-28 03:57:41.000000000,"[{'_account_id': 6796}, {'_account_id': 10239}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-19 13:37:38.000000000', 'files': ['puppet/services/ironic-conductor.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/edd5b8faee9702698aab323c5a62e9442c77c0d4', 'message': 'Expose IronicImageDownloadSource as a parameter\n\nSetting this to ""http"" allows using the direct deploy interface\nwithout Swift. It is particularly useful in the Edge case, as it\nallows to download an image once to the conductor, and serve it\nto all nodes within the location, without having Swift there.\n\nDepends-On: https://review.openstack.org/#/c/601314/\nChange-Id: Ifc6a809a45a2a08e5bb11f95b04ac4d69dada3c4\n'}]",0,603796,edd5b8faee9702698aab323c5a62e9442c77c0d4,10,5,1,10239,,,0,"Expose IronicImageDownloadSource as a parameter

Setting this to ""http"" allows using the direct deploy interface
without Swift. It is particularly useful in the Edge case, as it
allows to download an image once to the conductor, and serve it
to all nodes within the location, without having Swift there.

Depends-On: https://review.openstack.org/#/c/601314/
Change-Id: Ifc6a809a45a2a08e5bb11f95b04ac4d69dada3c4
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/96/603796/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/ironic-conductor.yaml'],1,edd5b8faee9702698aab323c5a62e9442c77c0d4,image-download-source," IronicImageDownloadSource: default: swift description: Image delivery method for the ""direct"" deploy interface. Use ""swift"" for the Object Storage temporary URLs, use ""http"" for the local HTTP server (the same as for iPXE). type: string ironic::drivers::agent::image_download_source: {get_param: IronicImageDownloadSource}",,7,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd,openstack/tripleo-heat-templates,stable/queens,I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd,Fix syntax for set_fact module.,MERGED,2018-09-24 13:10:47.000000000,2018-09-28 03:57:39.000000000,2018-09-28 03:57:39.000000000,"[{'_account_id': 8042}, {'_account_id': 20172}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 13:10:47.000000000', 'files': ['docker/services/pacemaker/database/redis.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/54f702ef378c529bc5166de601448731c5b2a262', 'message': ""Fix syntax for set_fact module.\n\nFix issue that arise during upgrade:\n error while evaluating conditional (redis_pcs_res|bool):\n  'redis_pcs_res' is undefined\n\nChange-Id: I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd\n(cherry picked from commit 33e49507a53c825554bd9f03c71b02754f5951fc)\n(cherry picked from commit ab9c7b95b1bdf3037d88be9d9d4e90e46d8de0ba)\n""}]",0,604774,54f702ef378c529bc5166de601448731c5b2a262,9,5,1,8042,,,0,"Fix syntax for set_fact module.

Fix issue that arise during upgrade:
 error while evaluating conditional (redis_pcs_res|bool):
  'redis_pcs_res' is undefined

Change-Id: I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd
(cherry picked from commit 33e49507a53c825554bd9f03c71b02754f5951fc)
(cherry picked from commit ab9c7b95b1bdf3037d88be9d9d4e90e46d8de0ba)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/604774/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/pacemaker/database/redis.yaml'],1,54f702ef378c529bc5166de601448731c5b2a262,redis-typo-fix-stable/rocky-stable/queens," set_fact: redis_pcs_res: ""{{redis_pcs_res_result|succeeded}}"""," set_fact: ""{{redis_pcs_res_result|succeeded}}""",2,1
openstack%2Fpython-tripleoclient~stable%2Frocky~I2a02d567bbc9e95c198d8cfe3e368d97b43be9a9,openstack/python-tripleoclient,stable/rocky,I2a02d567bbc9e95c198d8cfe3e368d97b43be9a9,Fix typo in upgrade playbook's name.,MERGED,2018-09-24 06:13:46.000000000,2018-09-28 03:57:38.000000000,2018-09-28 03:57:38.000000000,"[{'_account_id': 8042}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-24 06:13:46.000000000', 'files': ['tripleoclient/v1/overcloud_upgrade.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b87344325263abc0faedcee7c4e47e1ce17ab9d0', 'message': ""Fix typo in upgrade playbook's name.\n\nFix typo to avoid error when wrong playbook is referenced:\n  openstack overcloud upgrade run \\\n    --stack overcloud --roles Controller \\\n    --playbook post_upgrade_steps_playbooks.yaml\n  ...\n  u'ERROR! playbooks must be a list of plays'\n\nChange-Id: I2a02d567bbc9e95c198d8cfe3e368d97b43be9a9\n(cherry picked from commit 0b14c258a1d8ff9e243c8746926b3a4db1bf0954)\n""}]",0,604685,b87344325263abc0faedcee7c4e47e1ce17ab9d0,13,4,1,21537,,,0,"Fix typo in upgrade playbook's name.

Fix typo to avoid error when wrong playbook is referenced:
  openstack overcloud upgrade run \
    --stack overcloud --roles Controller \
    --playbook post_upgrade_steps_playbooks.yaml
  ...
  u'ERROR! playbooks must be a list of plays'

Change-Id: I2a02d567bbc9e95c198d8cfe3e368d97b43be9a9
(cherry picked from commit 0b14c258a1d8ff9e243c8746926b3a4db1bf0954)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/85/604685/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/overcloud_upgrade.py'],1,b87344325263abc0faedcee7c4e47e1ce17ab9d0,upg-name-typo-stable/rocky," ""post_upgrade_steps_playbook.yaml. Set """," ""post_upgrade_steps_playbooks.yaml. Set """,1,1
openstack%2Ftripleo-common~master~Icce658f803a608ee4b7df34b0b8297ecabcdb0ee,openstack/tripleo-common,master,Icce658f803a608ee4b7df34b0b8297ecabcdb0ee,Update swift_rings_backup workflow to also backup ceph fetch dir,MERGED,2018-08-28 19:54:10.000000000,2018-09-28 03:31:22.000000000,2018-09-28 03:31:22.000000000,"[{'_account_id': 6796}, {'_account_id': 6968}, {'_account_id': 8871}, {'_account_id': 9712}, {'_account_id': 10873}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-28 19:54:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/604ed5e709d39dd102caf0a1d6db79ea63d8dccf', 'message': 'Generalize swift_rings_backup workflow\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 2, 'created': '2018-08-28 21:36:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8641553b938560d6d55b2e155252c294b68758c9', 'message': 'Generalize swift_rings_backup workflow\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 3, 'created': '2018-08-31 22:39:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5e6e46445c74c2dfc4cbf16377fef45cfe6f2d0b', 'message': 'Generalize swift_rings_backup workflow\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 4, 'created': '2018-09-01 00:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/85ec82a03c63b99a7db7ec9368a7b75b091489e1', 'message': 'Generalize swift_rings_backup workflow\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 5, 'created': '2018-09-03 12:52:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/87c596fe352c2487967d1165aae955f801387167', 'message': 'Update swift_rings_backup workflow to also backup ceph fetch dir\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nUpdate deployment and plan management workflows to also create\nor update the ceph-ansible fetch directory swift container.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 6, 'created': '2018-09-03 13:29:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/16bddc84d6871279c47efbe09ec935a3e6f14be9', 'message': 'Update swift_rings_backup workflow to also backup ceph fetch dir\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nUpdate deployment and plan management workflows to also create\nor update the ceph-ansible fetch directory swift container.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 7, 'created': '2018-09-07 02:01:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b5947376adb5c07cb078beabb8d1b56290e9cb76', 'message': 'Update swift_rings_backup workflow to also backup ceph fetch dir\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nUpdate deployment and plan management workflows to also create\nor update the ceph-ansible fetch directory swift container.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}, {'number': 8, 'created': '2018-09-07 11:15:19.000000000', 'files': ['workbooks/deployment.yaml', 'workbooks/plan_management.yaml', 'workbooks/swift_backup.yaml', 'workbooks/swift_rings_backup.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/bdde61dec0ce2882bd9a591acfb94502b27a297e', 'message': 'Update swift_rings_backup workflow to also backup ceph fetch dir\n\nRename swift_rings_backup to swift_backup because we might wish\nto use swift on the undercloud to backup more than just the\novercloud swift rings. For example the same workflow is useful\nfor backing up the ceph-ansible fetch directory in the undercloud\nswift.\n\nUpdate deployment and plan management workflows to also create\nor update the ceph-ansible fetch directory swift container.\n\nChange-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee\nRelated-Bug: #1769769\n'}]",19,597221,bdde61dec0ce2882bd9a591acfb94502b27a297e,88,8,8,18002,,,0,"Update swift_rings_backup workflow to also backup ceph fetch dir

Rename swift_rings_backup to swift_backup because we might wish
to use swift on the undercloud to backup more than just the
overcloud swift rings. For example the same workflow is useful
for backing up the ceph-ansible fetch directory in the undercloud
swift.

Update deployment and plan management workflows to also create
or update the ceph-ansible fetch directory swift container.

Change-Id: Icce658f803a608ee4b7df34b0b8297ecabcdb0ee
Related-Bug: #1769769
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/21/597221/8 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/deployment.yaml', 'workbooks/plan_management.yaml', 'workbooks/swift_backup.yaml']",3,604ed5e709d39dd102caf0a1d6db79ea63d8dccf,bug/1769769,"name: tripleo.swift_backup.v1 description: TripleO Swift backup container Deployment Workflow v1 create_swift_backup_container_plan: Ensures the existence of containers for backups, e.g. swift_rings - purpose: swift-rings swift_container: publish: swift_container: ""<% $.container %>-<% $.purpose %>"" swift_tar: ""<% $.purpose %>.tar.gz"" workflow: tripleo.swift.v1.container_exists container=<% $.swift_container %> container: <% $.swift_container %> obj: <% $.swift_tar %> container: <% $.swift_container %> obj: <% $.swift_tar %>","name: tripleo.swift_rings_backup.v1 description: TripleO Swift Rings backup container Deployment Workflow v1 create_swift_rings_backup_container_plan: This plan ensures existence of container for Swift Rings backup. swift_rings_container: publish: swift_rings_container: ""<% $.container %>-swift-rings"" swift_rings_tar: ""swift-rings.tar.gz"" workflow: tripleo.swift.v1.container_exists container=<% $.swift_rings_container %> container: <% $.swift_rings_container %> obj: <% $.swift_rings_tar %> container: <% $.swift_rings_container %> obj: <% $.swift_rings_tar %>",17,14
openstack%2Frequirements~master~Iff5f74e3cc3d96cdff9910bb0961764f9177bc67,openstack/requirements,master,Iff5f74e3cc3d96cdff9910bb0961764f9177bc67,update constraint for oslo.db to new release 4.41.1,MERGED,2018-09-25 19:58:24.000000000,2018-09-28 03:31:01.000000000,2018-09-28 03:31:01.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:58:24.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f862c4e15b5b1e8ea9f6c33bcc960ed602561b0e', 'message': 'update constraint for oslo.db to new release 4.41.1\n\nChange-Id: Iff5f74e3cc3d96cdff9910bb0961764f9177bc67\nmeta:version: 4.41.1\nmeta:diff-start: 4.40.0\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605211,f862c4e15b5b1e8ea9f6c33bcc960ed602561b0e,16,2,1,11131,,,0,"update constraint for oslo.db to new release 4.41.1

Change-Id: Iff5f74e3cc3d96cdff9910bb0961764f9177bc67
meta:version: 4.41.1
meta:diff-start: 4.40.0
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/11/605211/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,f862c4e15b5b1e8ea9f6c33bcc960ed602561b0e,new-release,oslo.db===4.41.1,oslo.db===4.40.0,1,1
openstack%2Ftripleo-ci~master~Iad24f265648fa41abfe28155877cbc2d0cedaf58,openstack/tripleo-ci,master,Iad24f265648fa41abfe28155877cbc2d0cedaf58,Remove toci_jobtype definition from v3 jobs,MERGED,2018-08-20 18:55:58.000000000,2018-09-28 03:13:49.000000000,2018-09-28 03:13:48.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 21686}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-20 18:55:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/da63460170fd9244a399dd73313cc0788c1a83bf', 'message': 'Remove toci_jobtype definition from v3 jobs\n\nZuulV3 native jobs parenting to tripleo-ci-base no longer use\n`toci_jobtype` after 603ee03a32fbacb636146031cb10750204472fc8.\n\nChange-Id: Iad24f265648fa41abfe28155877cbc2d0cedaf58\n'}, {'number': 2, 'created': '2018-09-26 18:22:07.000000000', 'files': ['zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c883535fffa7924311e13ea9e47a645473b07ac6', 'message': 'Remove toci_jobtype definition from v3 jobs\n\nZuulV3 native jobs parenting to tripleo-ci-base no longer use\n`toci_jobtype` after 603ee03a32fbacb636146031cb10750204472fc8.\n\nChange-Id: Iad24f265648fa41abfe28155877cbc2d0cedaf58\n'}]",0,593863,c883535fffa7924311e13ea9e47a645473b07ac6,14,7,2,8175,,,0,"Remove toci_jobtype definition from v3 jobs

ZuulV3 native jobs parenting to tripleo-ci-base no longer use
`toci_jobtype` after 603ee03a32fbacb636146031cb10750204472fc8.

Change-Id: Iad24f265648fa41abfe28155877cbc2d0cedaf58
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/63/593863/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/multinode-jobs.yaml'],1,da63460170fd9244a399dd73313cc0788c1a83bf,toci_jobtype,, toci_jobtype: multinode-1ctlr-featureset010 toci_jobtype: multinode-1ctlr-featureset055,0,2
openstack%2Fopenstack-ansible-ops~master~I2a091669d6a77fd2c89a073cf9071292793e2f6b,openstack/openstack-ansible-ops,master,I2a091669d6a77fd2c89a073cf9071292793e2f6b,Refactor Filebeat configuration file,MERGED,2018-09-27 18:55:48.000000000,2018-09-28 03:04:36.000000000,2018-09-28 03:04:36.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 18:55:48.000000000', 'files': ['elk_metrics_6x/roles/elastic_filebeat/defaults/main.yml', 'elk_metrics_6x/roles/elastic_filebeat/tasks/main.yml', 'elk_metrics_6x/roles/elastic_filebeat/templates/filebeat.yml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/aa647953e0976e1f26ab241e42beaca371112f91', 'message': 'Refactor Filebeat configuration file\n\n- Avoid checking item by item, we always enable modules and\n  prospectors, with an option to disable with opt-in\n- Updated MySQL and Apache modules to point to right path\n- Improved and clean-up tagging\n- All the prospectors are managed using a variable\n\nChange-Id: I2a091669d6a77fd2c89a073cf9071292793e2f6b\n'}]",0,605837,aa647953e0976e1f26ab241e42beaca371112f91,7,2,1,1004,,,0,"Refactor Filebeat configuration file

- Avoid checking item by item, we always enable modules and
  prospectors, with an option to disable with opt-in
- Updated MySQL and Apache modules to point to right path
- Improved and clean-up tagging
- All the prospectors are managed using a variable

Change-Id: I2a091669d6a77fd2c89a073cf9071292793e2f6b
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/37/605837/1 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics_6x/roles/elastic_filebeat/defaults/main.yml', 'elk_metrics_6x/roles/elastic_filebeat/tasks/main.yml', 'elk_metrics_6x/roles/elastic_filebeat/templates/filebeat.yml.j2']",3,aa647953e0976e1f26ab241e42beaca371112f91,," enabled: ""{{ filebeat_syslog_enabled | default(true) }}"" access: enabled: ""{{ filebeat_httpd_enabled | default(true) }}"" var.paths: - /openstack/log/*horizon*/horizon/*access.log error: enabled: ""{{ filebeat_httpd_enabled | default(true) }}"" var.paths: - /openstack/log/*horizon*/horizon/horizon-error.log enabled: ""{{ filebeat_auditd_enabled | default(true) }}"" error: enabled: ""{{ filebeat_galera_enabled | default(true) }}"" var.paths: - /openstack/log/*galera*/mysql_logs/galera_server_error.log - /var/log/mysql_logs/galera_server_error.log slowlog: enabled: false access: enabled: ""{{ filebeat_nginx_enabled | default(true) }}"" var.paths: - /openstack/log/*repo_container*/nginx/*access.log - /openstack/log/*keystone*/nginx/*access.log error: enabled: ""{{ filebeat_nginx_enabled | default(true) }}"" var.paths: - /openstack/log/*repo_container*/nginx/*error.log - /openstack/log/*keystone*/nginx/*error.log enabled: ""{{ filebeat_osquery_enabled | default(true) }}""{% for p in filebeat_prospectors %} - type: {{ p['type'] }} enabled: {{ p['enabled'] }} paths: {% for path in p['paths'] %} - {{ path }} {% endfor %} {% if 'multiline' in p %} multiline.pattern: '{{ p['multiline']['pattern'] }}' multiline.negate: {{ p['multiline']['negate'] }} multiline.match: {{ p['multiline']['match'] }} {% endif %} tags: {% for tag in p['tags'] %} - {{ tag }} {% endfor %} {% endfor %}"," enabled: true # Access logs access: enabled: {{ apache_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: # Error logs error: enabled: {{ apache_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: enabled: {{ apache_enabled | bool }} # Error logs error: enabled: {{ mysql_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. var.paths: - /var/log/mysql_logs - /var/log/mysql # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: # Slow logs slowlog: enabled: {{ mysql_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: # Access logs access: enabled: {{ nginx_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: # Error logs error: enabled: {{ nginx_enabled | bool }} # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Prospector configuration (advanced). Any prospector configuration option # can be added under this section. #prospector: enabled: {{ osquery_enabled | bool }}- type: log # Change to true to enable this prospector configuration. enabled: {{ designate_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/designate/*.log - /openstack/log/*designate*/*.log - /openstack/log/*designate*/designate/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - designate symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ cinder_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/cinder/*.log - /openstack/log/*cinder*/*.log - /openstack/log/*cinder*/cinder/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - cinder symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ glance_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/glance/*.log - /openstack/log/*glance*/*.log - /openstack/log/*glance*/glance/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - glance symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ heat_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/heat/*.log - /openstack/log/*heat*/*.log - /openstack/log/*heat*/heat/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - heat symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ horizon_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/horizon/*.log - /openstack/log/*horizon*/*.log - /openstack/log/*horizon*/horizon/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - horizon symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ keystone_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/keystone/*.log - /openstack/log/*keystone*/*.log - /openstack/log/*keystone*/keystone/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - keystone symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ neutron_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/neutron/*.log - /openstack/log/*neutron*/*.log - /openstack/log/*neutron*/neutron/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - neutron symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ nova_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/nova/*.log - /openstack/log/*nova*/*.log - /openstack/log/*nova*/nova/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - nova symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ octavia_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/octavia/*.log - /openstack/log/*octavia*/*.log - /openstack/log/*octavia*/octavia/*.log ### Multiline options # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ multiline.pattern: '^[0-9-]{10} +[0-9:\.]+ +[0-9]+ +[A-Z]+ +[A-Za-z0-9\._]+ \[|Traceback' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - octavia symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ swift_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/swift/account*.log - /openstack/log/*swift*/account*.log ### Multiline options # Month Day Time Host Python Module Status multiline.pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ account-replicator: +[A-Za-z0-9-\ ]+' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: false # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - swift - swift-account symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ swift_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/swift/container*.log - /openstack/log/*swift*/container*.log ### Multiline options # Month Day Time Host Python Module Status multiline.pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ container-replicator: +[A-Za-z0-9-\ ]+' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: false # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - swift - swift-container symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ swift_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/swift/object*.log - /openstack/log/*swift*/object*.log ### Multiline options # Month Day Time Host Python Module Status multiline.pattern: '^[A-Za-z]+[[:space:]]* +[0-9]{1,2} +[0-9:\.]+ +[A-Za-z0-9-]+ object-replicator: +[A-Za-z0-9-\ ]+' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: false # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - swift - swift-object symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ swift_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/swift/proxy*.log - /openstack/log/*swift*/proxy*.log # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - openstack - swift - swift-proxy symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ rabbitmq_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/rabbit*/*.log - /openstack/log/*rabbit*/*.log - /openstack/log/*rabbit*/rabbit*/*.log ### Multiline options multiline.pattern: '^=' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: true # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - rabbitmq - infrastructure symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ ceph_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/ceph/ceph-mon.*.log - /openstack/log/*ceph*/ceph-mon*.log ### Multiline options multiline.pattern: '^[a-z_]* ' # Defines if the pattern set under pattern should be negated or not. Default is false. multiline.negate: false # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. multiline.timeout: 5s # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - ceph-mon - ceph - infrastructure symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: {{ ceph_enabled | bool }} # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/ceph/ceph-osd.*.log - /openstack/log/*ceph*/ceph-osd*.log # NOTE(mnaser): Workaround for following Ceph bug # http://tracker.ceph.com/issues/35716 exclude_lines: - '.*challenging authorizer.*' # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - ceph-osd - ceph - infrastructure symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/beats/*.log - /openstack/log/*/beats/*.log - /var/log/curator/curator - /openstack/log/*/curator/curator - /var/log/elasticsearch/*.log - /openstack/log/*/elasticsearch/*.log # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering tags: - beats symlinks: false - type: log # Change to true to enable this prospector configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. # To fetch all "".log"" files from a specific level of subdirectories # /var/log/*/*.log can be used. # For each file found under this path, a harvester is started. # Make sure not file is defined twice as this can lead to unexpected behaviour. paths: - /var/log/*.log - /var/log/haproxy/*.log - /var/log/libvirt/*.log - /var/log/libvirt/*/*.log - /var/log/lxc/*.log - /openstack/log/ansible-logging/*.log #- c:\programdata\elasticsearch\logs\* # Configure the file encoding for reading files with international characters # following the W3C recommendation for HTML5 (http://www.w3.org/TR/encoding). # Some sample encodings: # plain, utf-8, utf-16be-bom, utf-16be, utf-16le, big5, gb18030, gbk, # hz-gb-2312, euc-kr, euc-jp, iso-2022-jp, shift-jis, ... #encoding: plain # Exclude lines. A list of regular expressions to match. It drops the lines that are # matching any regular expression from the list. The include_lines is called before # exclude_lines. By default, no lines are dropped. #exclude_lines: ['^DBG'] # Include lines. A list of regular expressions to match. It exports the lines that are # matching any regular expression from the list. The include_lines is called before # exclude_lines. By default, all the lines are exported. #include_lines: ['^ERR', '^WARN'] # Exclude files. A list of regular expressions to match. Filebeat drops the files that # are matching any regular expression from the list. By default, no files are dropped. #exclude_files: ['.gz$'] # Optional additional fields. These fields can be freely picked # to add additional information to the crawled log files for filtering #fields: # level: debug # review: 1 # Set to true to store the additional fields as top level fields instead # of under the ""fields"" sub-dictionary. In case of name conflicts with the # fields added by Filebeat itself, the custom fields overwrite the default # fields. #fields_under_root: false # Ignore files which were modified more then the defined timespan in the past. # ignore_older is disabled by default, so no files are ignored by setting it to 0. # Time strings like 2h (2 hours), 5m (5 minutes) can be used. #ignore_older: 0 # How often the prospector checks for new files in the paths that are specified # for harvesting. Specify 1s to scan the directory as frequently as possible # without causing Filebeat to scan too frequently. Default: 10s. #scan_frequency: 10s # Defines the buffer size every harvester uses when fetching the file #harvester_buffer_size: 16384 # Maximum number of bytes a single log event can have # All bytes after max_bytes are discarded and not sent. The default is 10MB. # This is especially useful for multiline log messages which can get large. #max_bytes: 10485760 ### Recursive glob configuration # Expand ""**"" patterns into regular glob patterns. #recursive_glob.enabled: true ### JSON configuration # Decode JSON options. Enable this if your logs are structured in JSON. # JSON key on which to apply the line filtering and multiline settings. This key # must be top level and its value must be string, otherwise it is ignored. If # no text key is defined, the line filtering and multiline features cannot be used. #json.message_key: # By default, the decoded JSON is placed under a ""json"" key in the output document. # If you enable this setting, the keys are copied top level in the output document. #json.keys_under_root: false # If keys_under_root and this setting are enabled, then the values from the decoded # JSON object overwrite the fields that Filebeat normally adds (type, source, offset, etc.) # in case of conflicts. #json.overwrite_keys: false # If this setting is enabled, Filebeat adds a ""error.message"" and ""error.key: json"" key in case of JSON # unmarshaling errors or when a text key is defined in the configuration but cannot # be used. #json.add_error_key: false ### Multiline options # Mutiline can be used for log messages spanning multiple lines. This is common # for Java Stack Traces or C-Line Continuation # The regexp Pattern that has to be matched. The example pattern matches all lines starting with [ #multiline.pattern: ^\[ # Defines if the pattern set under pattern should be negated or not. Default is false. #multiline.negate: false # Match can be set to ""after"" or ""before"". It is used to define if lines should be append to a pattern # that was (not) matched before or after or as long as a pattern is not matched based on negate. # Note: After is the equivalent to previous and before is the equivalent to to next in Logstash #multiline.match: after # The maximum number of lines that are combined to one event. # In case there are more the max_lines the additional lines are discarded. # Default is 500 #multiline.max_lines: 500 # After the defined timeout, an multiline event is sent even if no new pattern was found to start a new event # Default is 5s. #multiline.timeout: 5s # Setting tail_files to true means filebeat starts reading new files at the end # instead of the beginning. If this is used in combination with log rotation # this can mean that the first entries of a new file are skipped. #tail_files: false # The Ingest Node pipeline ID associated with this prospector. If this is set, it # overwrites the pipeline option from the Elasticsearch output. #pipeline: # If symlinks is enabled, symlinks are opened and harvested. The harvester is openening the # original for harvesting but will report the symlink name as source. symlinks: false # Backoff values define how aggressively filebeat crawls new files for updates # The default values can be used in most cases. Backoff defines how long it is waited # to check a file again after EOF is reached. Default is 1s which means the file # is checked every second if new lines were added. This leads to a near real time crawling. # Every time a new line appears, backoff is reset to the initial value. #backoff: 1s # Max backoff defines what the maximum backoff time is. After having backed off multiple times # from checking the files, the waiting time will never exceed max_backoff independent of the # backoff factor. Having it set to 10s means in the worst case a new line can be added to a log # file after having backed off multiple times, it takes a maximum of 10s to read the new line #max_backoff: 10s # The backoff factor defines how fast the algorithm backs off. The bigger the backoff factor, # the faster the max_backoff value is reached. If this value is set to 1, no backoff will happen. # The backoff value will be multiplied each time with the backoff_factor until max_backoff is reached #backoff_factor: 2 # Max number of harvesters that are started in parallel. # Default is 0 which means unlimited #harvester_limit: 0 ### Harvester closing options # Close inactive closes the file handler after the predefined period. # The period starts when the last line of the file was, not the file ModTime. # Time strings like 2h (2 hours), 5m (5 minutes) can be used. #close_inactive: 5m # Close renamed closes a file handler when the file is renamed or rotated. # Note: Potential data loss. Make sure to read and understand the docs for this option. #close_renamed: false # When enabling this option, a file handler is closed immediately in case a file can't be found # any more. In case the file shows up again later, harvesting will continue at the last known position # after scan_frequency. #close_removed: true # Closes the file handler as soon as the harvesters reaches the end of the file. # By default this option is disabled. # Note: Potential data loss. Make sure to read and understand the docs for this option. #close_eof: false ### State options # Files for the modification data is older then clean_inactive the state from the registry is removed # By default this is disabled. #clean_inactive: 0 # Removes the state for file which cannot be found on disk anymore immediately #clean_removed: true # Close timeout closes the harvester after the predefined time. # This is independent if the harvester did finish reading the file or not. # By default this option is disabled. # Note: Potential data loss. Make sure to read and understand the docs for this option. #close_timeout: 0 # Defines if prospectors is enabled #enabled: true",304,1076
openstack%2Fopenstack-ansible-ops~master~Ic0e0bc0f93a12298c1e2f634cf5a1b4c6be2995e,openstack/openstack-ansible-ops,master,Ic0e0bc0f93a12298c1e2f634cf5a1b4c6be2995e,Add changes to the sysconfig defaults file,MERGED,2018-09-27 05:32:56.000000000,2018-09-28 03:02:05.000000000,2018-09-28 03:02:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 05:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/ee62cdb584599fdf9e2a8ec254d12de415dcd5d6', 'message': ""Add changes to the sysconfig defaults file\n\nThese changes mirror systemd tunables for elasticsearch and are needed\nto ensure any OS without systemd (like Ubuntu 14.04) has the same\ncapabilities and OS's with systemd. This also adds a specific sysctl\nfile to use when making sysctl changes. This will ensure we're not\nsubjecting our deployment to other changes from other sources, like an\nOSA playbook run.\n\nChange-Id: Ic0e0bc0f93a12298c1e2f634cf5a1b4c6be2995e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}, {'number': 2, 'created': '2018-09-27 14:44:16.000000000', 'files': ['elk_metrics_6x/roles/elasticsearch/vars/suse.yml', 'elk_metrics_6x/roles/elasticsearch/vars/redhat.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/suse.yml', 'elk_metrics_6x/roles/elastic_logstash/tasks/main.yml', 'elk_metrics_6x/roles/elastic_dependencies/tasks/main.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/redhat.yml', 'elk_metrics_6x/tests/functional.yml', 'elk_metrics_6x/roles/elasticsearch/vars/ubuntu.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/ubuntu.yml', 'elk_metrics_6x/roles/elasticsearch/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/4c86cb9be208b9ed7bba67339249ad91e319f2cc', 'message': ""Add changes to the sysconfig defaults file\n\nThese changes mirror systemd tunables for elasticsearch and are needed\nto ensure any OS without systemd (like Ubuntu 14.04) has the same\ncapabilities and OS's with systemd. This also adds a specific sysctl\nfile to use when making sysctl changes. This will ensure we're not\nsubjecting our deployment to other changes from other sources, like an\nOSA playbook run.\n\nChange-Id: Ic0e0bc0f93a12298c1e2f634cf5a1b4c6be2995e\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n""}]",0,605586,4c86cb9be208b9ed7bba67339249ad91e319f2cc,8,2,2,7353,,,0,"Add changes to the sysconfig defaults file

These changes mirror systemd tunables for elasticsearch and are needed
to ensure any OS without systemd (like Ubuntu 14.04) has the same
capabilities and OS's with systemd. This also adds a specific sysctl
file to use when making sysctl changes. This will ensure we're not
subjecting our deployment to other changes from other sources, like an
OSA playbook run.

Change-Id: Ic0e0bc0f93a12298c1e2f634cf5a1b4c6be2995e
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/86/605586/2 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics_6x/roles/elasticsearch/vars/suse.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/suse.yml', 'elk_metrics_6x/roles/elasticsearch/vars/redhat.yml', 'elk_metrics_6x/roles/elastic_logstash/tasks/main.yml', 'elk_metrics_6x/roles/elastic_dependencies/tasks/main.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/redhat.yml', 'elk_metrics_6x/tests/functional.yml', 'elk_metrics_6x/roles/elasticsearch/vars/ubuntu.yml', 'elk_metrics_6x/roles/elastic_logstash/vars/ubuntu.yml', 'elk_metrics_6x/roles/elasticsearch/tasks/main.yml']",10,ee62cdb584599fdf9e2a8ec254d12de415dcd5d6,,"- name: Set sysconfig service defaults lineinfile: path: ""{{ elasticsearch_sysconfig_path }}"" regexp: '^{{ item.key }}=' line: '{{ item.key }}={{ item.value }}' with_items: - key: MAX_OPEN_FILES value: 65536 - key: MAX_LOCKED_MEMORY value: unlimited - key: MAX_MAP_COUNT value: 524288 ",,38,0
openstack%2Fpython-troveclient~stable%2Fqueens~Id873df2246b39e63f6da137cc136c17ef42d6607,openstack/python-troveclient,stable/queens,Id873df2246b39e63f6da137cc136c17ef42d6607,import zuul job settings from project-config,MERGED,2018-09-11 12:22:49.000000000,2018-09-28 01:51:28.000000000,2018-09-28 01:51:28.000000000,"[{'_account_id': 6873}, {'_account_id': 11904}, {'_account_id': 14151}, {'_account_id': 22348}, {'_account_id': 27153}, {'_account_id': 28646}, {'_account_id': 28695}]","[{'number': 1, 'created': '2018-09-11 12:22:49.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/d79bb270d04707cab15d10df1029b485f6a983e8', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: Id873df2246b39e63f6da137cc136c17ef42d6607\nStory: #2002586\nTask: #24342\n'}]",2,601577,d79bb270d04707cab15d10df1029b485f6a983e8,13,7,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: Id873df2246b39e63f6da137cc136c17ef42d6607
Story: #2002586
Task: #24342
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/77/601577/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d79bb270d04707cab15d10df1029b485f6a983e8,python3-first, - check-requirements - publish-openstack-sphinx-docs - openstack-python-jobs - openstack-python35-jobs - release-notes-jobs - trove-functional-mysql - trove-functional-mysql,,7,0
openstack%2Ftrove~stable%2Fqueens~I9c08a1d3306cc793b887c8e0b42db515195c925e,openstack/trove,stable/queens,I9c08a1d3306cc793b887c8e0b42db515195c925e,import zuul job settings from project-config,MERGED,2018-09-11 12:22:53.000000000,2018-09-28 01:51:26.000000000,2018-09-28 01:51:26.000000000,"[{'_account_id': 6873}, {'_account_id': 11904}, {'_account_id': 14151}, {'_account_id': 22348}, {'_account_id': 27153}, {'_account_id': 28646}, {'_account_id': 28695}]","[{'number': 1, 'created': '2018-09-11 12:22:53.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/trove/commit/93839e241bf15624cce805703064e648ed68d379', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I9c08a1d3306cc793b887c8e0b42db515195c925e\nStory: #2002586\nTask: #24342\n'}]",0,601578,93839e241bf15624cce805703064e648ed68d379,11,7,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I9c08a1d3306cc793b887c8e0b42db515195c925e
Story: #2002586
Task: #24342
",git fetch https://review.opendev.org/openstack/trove refs/changes/78/601578/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,93839e241bf15624cce805703064e648ed68d379,python3-first, templates: - openstack-python-jobs - openstack-python35-jobs - publish-openstack-sphinx-docs - periodic-stable-jobs - check-requirements - release-notes-jobs - openstack-tox-pylint - openstack-tox-pylint post: jobs: - openstack-tox-cover,,12,0
openstack%2Fopenstack-ansible-tests~master~Ice6caa239555abe0b54cedc1e6b4a60e9e644de6,openstack/openstack-ansible-tests,master,Ice6caa239555abe0b54cedc1e6b4a60e9e644de6,zuul: Add template for jobs using distribution packages,MERGED,2018-09-27 14:04:01.000000000,2018-09-28 01:49:14.000000000,2018-09-28 01:49:14.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 14:04:01.000000000', 'files': ['zuul.d/project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/83dae0b96a2a262c94c952da477501f8668f4dc6', 'message': 'zuul: Add template for jobs using distribution packages\n\nChange-Id: Ice6caa239555abe0b54cedc1e6b4a60e9e644de6\n'}]",0,605734,83dae0b96a2a262c94c952da477501f8668f4dc6,7,3,1,23163,,,0,"zuul: Add template for jobs using distribution packages

Change-Id: Ice6caa239555abe0b54cedc1e6b4a60e9e644de6
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/34/605734/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project-templates.yaml'],1,83dae0b96a2a262c94c952da477501f8668f4dc6,add-template-distro-install, - project-template: name: openstack-ansible-role-distro_install-jobs check: jobs: - openstack-ansible-functional-distro_install-centos-7 - openstack-ansible-functional-distro_install-opensuse-150 - openstack-ansible-functional-distro_install-opensuse-423 - openstack-ansible-functional-distro_install-ubuntu-bionic gate: jobs: - openstack-ansible-functional-distro_install-centos-7 - openstack-ansible-functional-distro_install-opensuse-150 - openstack-ansible-functional-distro_install-opensuse-423 - openstack-ansible-functional-distro_install-ubuntu-bionic,,15,0
openstack%2Fhorizon~master~I9809cfde11b8d69e0e5324477272df250821113f,openstack/horizon,master,I9809cfde11b8d69e0e5324477272df250821113f,Ugly fix to clear memo cache every request,ABANDONED,2018-09-24 23:39:48.000000000,2018-09-28 01:47:11.000000000,,"[{'_account_id': 1736}, {'_account_id': 10420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-24 23:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/5086950bdbbadb9785aa2ad9ae3184ae552e4554', 'message': 'Ugly fix to clear memo cache every request\n\nChange-Id: I9809cfde11b8d69e0e5324477272df250821113f\n'}, {'number': 2, 'created': '2018-09-24 23:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/f1dc71c55a8699406cc533aa6bc6901cd1d87422', 'message': 'Ugly fix to clear memo cache every request\n\nChange-Id: I9809cfde11b8d69e0e5324477272df250821113f\n'}, {'number': 3, 'created': '2018-09-27 07:24:40.000000000', 'files': ['horizon/utils/memoized.py', 'horizon/middleware/base.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/7de98b2e6e0ca9533c24aabdbb4fcf825a136107', 'message': 'Ugly fix to clear memo cache every request\n\nChange-Id: I9809cfde11b8d69e0e5324477272df250821113f\n'}]",2,604934,7de98b2e6e0ca9533c24aabdbb4fcf825a136107,12,3,3,10420,,,0,"Ugly fix to clear memo cache every request

Change-Id: I9809cfde11b8d69e0e5324477272df250821113f
",git fetch https://review.opendev.org/openstack/horizon refs/changes/34/604934/1 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/utils/memoized.py', 'horizon/middleware/base.py']",2,5086950bdbbadb9785aa2ad9ae3184ae552e4554,bug/memo_leak,from horizon.utils.memoized import MEMOIZED_CACHES MEMOIZED_CACHES.clear() MEMOIZED_CACHES.clear(),,20,43
openstack%2Fhorizon~master~Iaa8ec0e7d371e22e5d89d95a0d09f6a214b9c3dc,openstack/horizon,master,Iaa8ec0e7d371e22e5d89d95a0d09f6a214b9c3dc,Always have a weakref in memoized keys,ABANDONED,2018-09-28 00:15:39.000000000,2018-09-28 01:47:00.000000000,,"[{'_account_id': 1736}, {'_account_id': 8648}, {'_account_id': 10420}]","[{'number': 1, 'created': '2018-09-28 00:15:39.000000000', 'files': ['horizon/utils/memoized.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1f7c1a591689cea134582da60583b9fbeef630fe', 'message': 'Always have a weakref in memoized keys\n\nWe introduce an object we can weakref when no other keys\nare able to be made into a weakref, and ensure it keeps\nthe key consistent by making it always return a consistent\nhash.\n\nChange-Id: Iaa8ec0e7d371e22e5d89d95a0d09f6a214b9c3dc\n'}]",0,605895,1f7c1a591689cea134582da60583b9fbeef630fe,4,3,1,10420,,,0,"Always have a weakref in memoized keys

We introduce an object we can weakref when no other keys
are able to be made into a weakref, and ensure it keeps
the key consistent by making it always return a consistent
hash.

Change-Id: Iaa8ec0e7d371e22e5d89d95a0d09f6a214b9c3dc
",git fetch https://review.opendev.org/openstack/horizon refs/changes/95/605895/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/utils/memoized.py'],1,1f7c1a591689cea134582da60583b9fbeef630fe,605024,"class ConsistentHash(object): """"""An object we can weakref that has a consistent hash This allows an object to be added to keys safely when a key would otherwise have no weakrefs, in such a way that the overall key hash will still be consistent. """""" def __hash__(self): return 1 """"""Calculate the cache key, using weak references where possible Where not, we insert a ConsistentHash weakref. """""" # NOTE(adriant): Using a list because python2 doesn't support nonlocal has_weakref = [] def _try_weakref(arg, remove_callback): """"""Return a weak reference to arg if possible, or arg itself if not."""""" try: arg = weakref.ref(arg, remove_callback) has_weakref.append(True) except TypeError: # Not all types can have a weakref. That includes strings # and floats and such, so just pass them through directly. pass return arg weak_args = [] for arg in args: weak_args.append(_try_weakref(arg, remove_callback)) weak_kwargs = [] for key, value in sorted(kwargs.items()): weak_kwargs.append(_try_weakref(value, remove_callback)) # Use tuples, because lists are not hashable. if has_weakref: return tuple(weak_args), tuple(weak_kwargs) else: extra_weak_ref = weakref.ref(ConsistentHash(), remove_callback) return tuple(weak_args), tuple(weak_kwargs), extra_weak_ref","def _try_weakref(arg, remove_callback): """"""Return a weak reference to arg if possible, or arg itself if not."""""" try: arg = weakref.ref(arg, remove_callback) except TypeError: # Not all types can have a weakref. That includes strings # and floats and such, so just pass them through directly. pass return arg """"""Calculate the cache key, using weak references where possible."""""" # Use tuples, because lists are not hashable. weak_args = tuple(_try_weakref(arg, remove_callback) for arg in args) weak_kwargs = tuple(sorted( (key, _try_weakref(value, remove_callback)) for (key, value) in kwargs.items())) return weak_args, weak_kwargs",41,16
openstack%2Ffreezer-api~master~I1b907e3115c15f0fe82ecb2d54457209cfcf21e6,openstack/freezer-api,master,I1b907e3115c15f0fe82ecb2d54457209cfcf21e6,Remove ababdoned code.,MERGED,2018-09-26 07:43:15.000000000,2018-09-28 01:25:19.000000000,2018-09-28 01:25:19.000000000,"[{'_account_id': 21387}, {'_account_id': 22348}, {'_account_id': 22484}, {'_account_id': 27068}]","[{'number': 1, 'created': '2018-09-26 07:43:15.000000000', 'files': ['etc/freezer/freezer-paste.ini', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/freezer-api/commit/fc088216b27ca737330fa1cb0e704dbb7b890771', 'message': 'Remove ababdoned code.\n\nThe entry_point ""service_v1"" has changed to appv1 & appv2.\nThe extra code in files is cleaned up.\n\nChange-Id: I1b907e3115c15f0fe82ecb2d54457209cfcf21e6\nId: I0d3d3982ea29bfb6a9af1c85dbd244025104c152\n'}]",0,605345,fc088216b27ca737330fa1cb0e704dbb7b890771,8,4,1,21069,,,0,"Remove ababdoned code.

The entry_point ""service_v1"" has changed to appv1 & appv2.
The extra code in files is cleaned up.

Change-Id: I1b907e3115c15f0fe82ecb2d54457209cfcf21e6
Id: I0d3d3982ea29bfb6a9af1c85dbd244025104c152
",git fetch https://review.opendev.org/openstack/freezer-api refs/changes/45/605345/1 && git format-patch -1 --stdout FETCH_HEAD,"['etc/freezer/freezer-paste.ini', 'setup.cfg']",2,fc088216b27ca737330fa1cb0e704dbb7b890771,,,paste.app_factory = service_v1 = freezer_api.service:freezer_app_factory,0,5
openstack%2Fneutron-vpnaas~master~Ic2839a32ec742bf25c9414650c24f17b91ae44c3,openstack/neutron-vpnaas,master,Ic2839a32ec742bf25c9414650c24f17b91ae44c3,use common rpc and exceptions from neutron-lib,MERGED,2018-09-26 15:28:32.000000000,2018-09-28 01:22:11.000000000,2018-09-28 01:22:11.000000000,"[{'_account_id': 6854}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 15:28:32.000000000', 'files': ['neutron_vpnaas/services/vpn/service_drivers/ipsec.py', 'neutron_vpnaas/tests/unit/dummy_ipsec.py', 'neutron_vpnaas/services/vpn/service_drivers/__init__.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/7434a1e5eb17a1389211f412c106f54ebf1eff5a', 'message': ""use common rpc and exceptions from neutron-lib\n\nThe neutron.common.rpc and exceptions were rehomed into neutron-lib and\nare currently shimmed in neutron [1]\n\nThis patch consumes those modules from neutron-lib by using lib's\nmodules rather than neutrons.\n\n[1] https://review.openstack.org/#/c/586525/\n\nChange-Id: Ic2839a32ec742bf25c9414650c24f17b91ae44c3\n""}]",0,605460,7434a1e5eb17a1389211f412c106f54ebf1eff5a,7,3,1,5367,,,0,"use common rpc and exceptions from neutron-lib

The neutron.common.rpc and exceptions were rehomed into neutron-lib and
are currently shimmed in neutron [1]

This patch consumes those modules from neutron-lib by using lib's
modules rather than neutrons.

[1] https://review.openstack.org/#/c/586525/

Change-Id: Ic2839a32ec742bf25c9414650c24f17b91ae44c3
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/60/605460/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/services/vpn/service_drivers/ipsec.py', 'neutron_vpnaas/tests/unit/dummy_ipsec.py', 'neutron_vpnaas/services/vpn/service_drivers/__init__.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py']",4,7434a1e5eb17a1389211f412c106f54ebf1eff5a,use-lib-rpc,from neutron_lib import rpc as n_rpc,from neutron.common import rpc as n_rpc,4,4
openstack%2Fneutron-vpnaas~master~I7bd4d8e75601a7291692d6256925f46fb4fa5464,openstack/neutron-vpnaas,master,I7bd4d8e75601a7291692d6256925f46fb4fa5464,add local pep8 tox target,MERGED,2018-09-26 15:18:07.000000000,2018-09-28 01:22:10.000000000,2018-09-28 01:22:10.000000000,"[{'_account_id': 6854}, {'_account_id': 15905}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 15:18:07.000000000', 'files': ['neutron_vpnaas/extensions/vpn_endpoint_groups.py', 'neutron_vpnaas/__init__.py', 'test-requirements.txt', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'neutron_vpnaas/extensions/vpn_flavors.py', 'neutron_vpnaas/services/vpn/device_drivers/libreswan_ipsec.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/d1d60b93bc78dec429b315bae98c92bd5ef5cc2c', 'message': 'add local pep8 tox target\n\nThis patch adds the pep8-dev tox target for running pep8 locally as per\n[1]. In addition it updates the pylint version to work with python 3.x\nand addresses some pylint errors in the code.\n\n[1] https://etherpad.openstack.org/p/neutron-sibling-setup\n\nChange-Id: I7bd4d8e75601a7291692d6256925f46fb4fa5464\n'}]",2,605456,d1d60b93bc78dec429b315bae98c92bd5ef5cc2c,7,3,1,5367,,,0,"add local pep8 tox target

This patch adds the pep8-dev tox target for running pep8 locally as per
[1]. In addition it updates the pylint version to work with python 3.x
and addresses some pylint errors in the code.

[1] https://etherpad.openstack.org/p/neutron-sibling-setup

Change-Id: I7bd4d8e75601a7291692d6256925f46fb4fa5464
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/56/605456/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/extensions/vpn_endpoint_groups.py', 'neutron_vpnaas/__init__.py', 'test-requirements.txt', 'neutron_vpnaas/services/vpn/service_drivers/base_ipsec.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/services/vpn/device_drivers/ipsec.py', 'neutron_vpnaas/extensions/vpn_flavors.py', 'neutron_vpnaas/services/vpn/device_drivers/libreswan_ipsec.py', 'tox.ini']",9,d1d60b93bc78dec429b315bae98c92bd5ef5cc2c,neutronlib-zuulv3,[testenv:pep8-dev] basepython = python3 deps = {[testenv]deps} commands = {[testenv:dev]commands} {[testenv:pep8]commands} ,,17,12
openstack%2Ftripleo-common~stable%2Frocky~I0221311f3b17e9a60440681c42542c46af5e8903,openstack/tripleo-common,stable/rocky,I0221311f3b17e9a60440681c42542c46af5e8903,Add override_ansible_cfg,MERGED,2018-09-24 19:18:53.000000000,2018-09-28 00:57:18.000000000,2018-09-28 00:57:18.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 19:18:53.000000000', 'files': ['workbooks/deployment.yaml', 'tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0b41bc23b33ef896691f8137addfc2e3623109c5', 'message': 'Add override_ansible_cfg\n\nAdd a new workflow input for config_download_deploy for\noverride_ansible_cfg which is a string of ansible config file contents.\n\nThe contents will override any configured ansible.cfg values set by the\naction, allowing users to set any arbitrary ansible.cfg they want.\n\nChange-Id: I0221311f3b17e9a60440681c42542c46af5e8903\n(cherry picked from commit edacca490bab21acdaf5cbaebae4151fea8bf63e)\n'}]",0,604879,0b41bc23b33ef896691f8137addfc2e3623109c5,7,3,1,7144,,,0,"Add override_ansible_cfg

Add a new workflow input for config_download_deploy for
override_ansible_cfg which is a string of ansible config file contents.

The contents will override any configured ansible.cfg values set by the
action, allowing users to set any arbitrary ansible.cfg they want.

Change-Id: I0221311f3b17e9a60440681c42542c46af5e8903
(cherry picked from commit edacca490bab21acdaf5cbaebae4151fea8bf63e)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/79/604879/1 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/deployment.yaml', 'tripleo_common/actions/ansible.py', 'tripleo_common/tests/actions/test_ansible.py']",3,0b41bc23b33ef896691f8137addfc2e3623109c5,," ssh_private_key=None, override_ansible_cfg=None) def test_override_ansible_cfg(self): with tempfile.NamedTemporaryFile() as ansible_cfg_file: ansible_cfg_path = ansible_cfg_file.name work_dir = tempfile.mkdtemp(prefix='ansible-mistral-action-test') # Needed for the configparser to be able to read this file. ansible_cfg_file.write(b'[defaults]\n') ansible_cfg_file.write(b'[ssh_connection]\n') ansible_cfg_file.flush() override_ansible_cfg = ( ""[defaults]\n"" ""forks=10\n"" ""[ssh_connection]\n"" ""custom_option=custom_value\n"" ) resulting_ansible_config = ansible.write_default_ansible_cfg( work_dir, None, None, None, base_ansible_cfg=ansible_cfg_path, override_ansible_cfg=override_ansible_cfg) ansible_cfg = configparser.ConfigParser() ansible_cfg.read(resulting_ansible_config) self.assertEqual('10', ansible_cfg.get('defaults', 'forks')) self.assertEqual('custom_value', ansible_cfg.get('ssh_connection', 'custom_option')) def test_override_ansible_cfg_empty(self): with tempfile.NamedTemporaryFile() as ansible_cfg_file: ansible_cfg_path = ansible_cfg_file.name work_dir = tempfile.mkdtemp(prefix='ansible-mistral-action-test') # Needed for the configparser to be able to read this file. ansible_cfg_file.write(b'[defaults]\n') ansible_cfg_file.write(b'[ssh_connection]\n') ansible_cfg_file.flush() override_ansible_cfg = """" resulting_ansible_config = ansible.write_default_ansible_cfg( work_dir, None, None, None, base_ansible_cfg=ansible_cfg_path, override_ansible_cfg=override_ansible_cfg) ansible_cfg = configparser.ConfigParser() ansible_cfg.read(resulting_ansible_config) self.assertEqual('25', ansible_cfg.get('defaults', 'forks'))", ssh_private_key=None),66,3
openstack%2Finstack-undercloud~stable%2Frocky~I3946e23cc5955d7c1a4dc4771d2708a6c8c2974b,openstack/instack-undercloud,stable/rocky,I3946e23cc5955d7c1a4dc4771d2708a6c8c2974b,Include missing config classes,MERGED,2018-09-24 14:26:53.000000000,2018-09-28 00:51:18.000000000,2018-09-28 00:51:17.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 14:26:53.000000000', 'files': ['elements/puppet-stack-config/puppet-stack-config.pp'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/15cda5ada3e93463a2b987f29e3e30b9f2ecfecd', 'message': 'Include missing config classes\n\nIf an operator wanted to configure something currently not available via\nhieradata, they would only be able to do so for nova as it includes\n::nova::config. This change addes the config classes for aodh, gnocchi,\nkeystone, neutron, swift, heat, ironic, mistral, and zaqar.\n\nChange-Id: I3946e23cc5955d7c1a4dc4771d2708a6c8c2974b\nCloses-Bug: #1793361\n(cherry picked from commit 1a0714a864fa9365888acf5fe5fac4ce4bd44165)\n'}]",0,604799,15cda5ada3e93463a2b987f29e3e30b9f2ecfecd,9,5,1,14985,,,0,"Include missing config classes

If an operator wanted to configure something currently not available via
hieradata, they would only be able to do so for nova as it includes
::nova::config. This change addes the config classes for aodh, gnocchi,
keystone, neutron, swift, heat, ironic, mistral, and zaqar.

Change-Id: I3946e23cc5955d7c1a4dc4771d2708a6c8c2974b
Closes-Bug: #1793361
(cherry picked from commit 1a0714a864fa9365888acf5fe5fac4ce4bd44165)
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/99/604799/1 && git format-patch -1 --stdout FETCH_HEAD,['elements/puppet-stack-config/puppet-stack-config.pp'],1,15cda5ada3e93463a2b987f29e3e30b9f2ecfecd,bug/1793361-stable/rocky, include ::aodh::config include ::gnocchi::configinclude ::keystone::configinclude ::neutron::configinclude ::swift::configinclude ::heat::configinclude ::ironic::configinclude ::mistral::configinclude ::zaqar::config,,9,0
openstack%2Fpython-tripleoclient~stable%2Frocky~I56c5f3a094094f7ba2158d8a434122ccb496f6b4,openstack/python-tripleoclient,stable/rocky,I56c5f3a094094f7ba2158d8a434122ccb496f6b4,Start websocket client before workflows,MERGED,2018-09-26 18:17:40.000000000,2018-09-28 00:51:17.000000000,2018-09-28 00:51:17.000000000,"[{'_account_id': 3153}, {'_account_id': 7385}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-26 18:17:40.000000000', 'files': ['tripleoclient/workflows/deployment.py', 'tripleoclient/workflows/support.py', 'tripleoclient/workflows/plan_management.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/dae0133410348363e916d0a398a3132ebdd2688c', 'message': ""Start websocket client before workflows\n\nWhen we start a workflow in the client, we need to create the websocket\nconnection beforehand. If the workflow is very quick (like\ncreate_overcloudrc), it could be finished before we subscribe to the\nZaqar queue properly, and thus we wouldn't get the message.\n\nChange-Id: I56c5f3a094094f7ba2158d8a434122ccb496f6b4\nCloses-Bug: #1794418\n(cherry picked from commit 2a26ef2cf19571e39fc3071b19500808c6d14fcc)\n""}]",0,605499,dae0133410348363e916d0a398a3132ebdd2688c,7,4,1,14985,,,0,"Start websocket client before workflows

When we start a workflow in the client, we need to create the websocket
connection beforehand. If the workflow is very quick (like
create_overcloudrc), it could be finished before we subscribe to the
Zaqar queue properly, and thus we wouldn't get the message.

Change-Id: I56c5f3a094094f7ba2158d8a434122ccb496f6b4
Closes-Bug: #1794418
(cherry picked from commit 2a26ef2cf19571e39fc3071b19500808c6d14fcc)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/99/605499/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/deployment.py', 'tripleoclient/workflows/support.py', 'tripleoclient/workflows/plan_management.py']",3,dae0133410348363e916d0a398a3132ebdd2688c,bug/1783646-stable/rocky," with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.plan_management.v1.delete_deployment_plan', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.plan_management.v1.export_deployment_plan', workflow_input=workflow_input ) "," execution = base.start_workflow( workflow_client, 'tripleo.plan_management.v1.delete_deployment_plan', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.plan_management.v1.export_deployment_plan', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws:",66,66
openstack%2Ftripleo-heat-templates~stable%2Frocky~If3bda98425e68bcd2ac221d36a968adbe25b7c69,openstack/tripleo-heat-templates,stable/rocky,If3bda98425e68bcd2ac221d36a968adbe25b7c69,Add CephOSD service to roles/Standalone.yaml,MERGED,2018-09-19 13:11:55.000000000,2018-09-28 00:51:15.000000000,2018-09-28 00:51:15.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 18002}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-19 13:11:55.000000000', 'files': ['roles/Standalone.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfa3eca393beb592d15094527a7a726b9c32138b', 'message': 'Add CephOSD service to roles/Standalone.yaml\n\nChange-Id: If3bda98425e68bcd2ac221d36a968adbe25b7c69\nCloses-Bug: #1793020\n(cherry picked from commit 7905fe07d21d444f9929150812db8d3eb5e83b17)\n'}]",0,603758,dfa3eca393beb592d15094527a7a726b9c32138b,7,4,1,14985,,,0,"Add CephOSD service to roles/Standalone.yaml

Change-Id: If3bda98425e68bcd2ac221d36a968adbe25b7c69
Closes-Bug: #1793020
(cherry picked from commit 7905fe07d21d444f9929150812db8d3eb5e83b17)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/603758/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/Standalone.yaml'],1,dfa3eca393beb592d15094527a7a726b9c32138b,bug/1793020-stable/rocky, - OS::TripleO::Services::CephOSD,,1,0
openstack%2Ftripleo-heat-templates~master~Ica13d1aaee259d831d32698466ef8971e526483a,openstack/tripleo-heat-templates,master,Ica13d1aaee259d831d32698466ef8971e526483a,Fix openshift new node detection,MERGED,2018-09-05 11:51:35.000000000,2018-09-28 00:51:13.000000000,2018-09-28 00:51:13.000000000,"[{'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18851}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-05 11:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/396ae3d3aede3ef250f7c2a339bbea2163b57212', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 2, 'created': '2018-09-05 14:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fab7af24ba7735264636ef934e1394b806035096', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 3, 'created': '2018-09-06 07:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4b1afdfa41d4328d972d62a8802a575e1a011863', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 4, 'created': '2018-09-07 06:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/193dd93af4c110a87631dededf432a5ccda7638e', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 5, 'created': '2018-09-17 12:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/34ac23b8458064bd248a2724c8afb93df80c3f70', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 6, 'created': '2018-09-17 13:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55a9c0627f8c603bc0aa60bd2e89f7513bf91845', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 7, 'created': '2018-09-17 13:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/59b86bc569c10961d6e76634fa421554c0696d8c', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 8, 'created': '2018-09-17 13:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4c5987c148815020913f3380cfb86de34b323c3d', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 9, 'created': '2018-09-19 07:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13da46c651b85188e7957a428a3abb0d516c98b8', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 10, 'created': '2018-09-19 07:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/61b6e3f9c8ea82534f869ed77ccf022d95b992c3', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 11, 'created': '2018-09-19 13:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b1744f044c6c57e926c758ad86451bbb9b265eaa', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 12, 'created': '2018-09-24 10:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/634146a0b3169f6c723bb5819ed6735ce900e43a', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}, {'number': 13, 'created': '2018-09-25 16:47:08.000000000', 'files': ['extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-node.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8629bf4ab5ca72735932c7e4fd4aebf9fdfb5854', 'message': 'Fix openshift new node detection\n\nFor openshift deployment it is important to know which nodes are new to\nthe cluster so that can be added to the appropriate groups. The new node\ndetection was broken due to the recent switch to containerized\nundercloud and move to openshift 3.10. This commit fixes the issues by\nrelying on the systemd status rather than docker directly.\n\nChange-Id: Ica13d1aaee259d831d32698466ef8971e526483a\n'}]",0,600012,8629bf4ab5ca72735932c7e4fd4aebf9fdfb5854,39,8,13,13039,,,0,"Fix openshift new node detection

For openshift deployment it is important to know which nodes are new to
the cluster so that can be added to the appropriate groups. The new node
detection was broken due to the recent switch to containerized
undercloud and move to openshift 3.10. This commit fixes the issues by
relying on the systemd status rather than docker directly.

Change-Id: Ica13d1aaee259d831d32698466ef8971e526483a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/600012/8 && git format-patch -1 --stdout FETCH_HEAD,"['extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-node.yaml']",2,396ae3d3aede3ef250f7c2a339bbea2163b57212,tripleo-openshift," # NOTE(flaper87): Check if origin-node is running in the openshift # nodes so we can flag the node as new later on. - name: Check if origin-node is running command: systemctl is-active --quiet origin-node register: origin_nodes delegate_to: ""{{item}}"" with_items: ""{{ groups[tripleo_role_name] | default([]) }}"" failed_when: false - new_node: ""{{origin_nodes.results | selectattr('item', 'equalto', item) | selectattr('stdout', 'greaterthan', 0) | list | count > 0}}"""," # FIXME(mandre) This task always fails: # - become:true doesn't work in that context (containerized undercloud issue?) # - there is no origin-master-api docker container # We should be checking for systemd service status instead. # NOTE(flaper87): Check if origin-node is running in the openshift # nodes so we can flag the node as new later on. # # This task ignores errors because docker inspect exits with 1 if # origin-node doesn't exist. Perhaps we could use failed_when # instead of ignoring the errors. Future improvement. - name: Check if origin-node is running become: true shell: > docker inspect atomic-enterprise-master-api > /dev/null 2>&1 || docker inspect origin-master-api > /dev/null 2>&1 || echo ""false"" register: origin_nodes delegate_to: ""{{item}}"" with_items: ""{{ groups[tripleo_role_name] | default([]) }}"" - new_node: ""{{origin_nodes.results | selectattr('item', 'equalto', item) | selectattr('stdout', 'equalto', 'false') | list | count > 0}}""",12,34
openstack%2Ftripleo-common~master~Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983,openstack/tripleo-common,master,Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983,Tag openshift images for Infra service,MERGED,2018-09-17 08:39:58.000000000,2018-09-28 00:51:12.000000000,2018-09-28 00:51:12.000000000,"[{'_account_id': 4328}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-17 08:39:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/095ddbce33e1df924fd79d6e4ac6d9429bce7fd9', 'message': ""Tag openshift images for Infra role\n\nThis commit updates the container image services after we've split the\ninfra service from the master one.\n\nThis also fixes missing Worker service for\nDockerOpenShiftDeployerImage.\n\nChange-Id: Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983\n""}, {'number': 2, 'created': '2018-09-17 08:42:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/78081219ee92a686c64a26ebd2f55efe7b4202a2', 'message': ""Tag openshift images for Infra service\n\nThis commit updates the container image services after we've split the\ninfra service from the master one.\n\nThis also fixes missing Worker service for\nDockerOpenShiftDeployerImage.\n\nChange-Id: Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983\n""}, {'number': 3, 'created': '2018-09-19 13:10:17.000000000', 'files': ['container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0442e4fe41d31a4ccc870ded6133c14abefd098e', 'message': ""Tag openshift images for Infra service\n\nThis commit updates the container image services after we've split the\ninfra service from the master one.\n\nThis also fixes missing Worker service for\nDockerOpenShiftDeployerImage.\n\nChange-Id: Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983\n""}]",0,603050,0442e4fe41d31a4ccc870ded6133c14abefd098e,17,5,3,13039,,,0,"Tag openshift images for Infra service

This commit updates the container image services after we've split the
infra service from the master one.

This also fixes missing Worker service for
DockerOpenShiftDeployerImage.

Change-Id: Ibc98e699d34dc6ab9ff6dce0d41f275b6403d983
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/50/603050/2 && git format-patch -1 --stdout FETCH_HEAD,['container-images/overcloud_containers.yaml.j2'],1,095ddbce33e1df924fd79d6e4ac6d9429bce7fd9,3.10, - OS::TripleO::Services::OpenShift::Infra - OS::TripleO::Services::OpenShift::Infra - OS::TripleO::Services::OpenShift::Worker - OS::TripleO::Services::OpenShift::Infra - OS::TripleO::Services::OpenShift::Infra - OS::TripleO::Services::OpenShift::Infra, - OS::TripleO::Services::OpenShift::Worker - OS::TripleO::Services::OpenShift::Master - OS::TripleO::Services::OpenShift::Worker,6,3
openstack%2Fcinder~stable%2Fpike~I42c00b7df6aa0576b928e49f6eb21f45b56fa647,openstack/cinder,stable/pike,I42c00b7df6aa0576b928e49f6eb21f45b56fa647,VMware: Add 'managedBy' info,ABANDONED,2018-09-06 20:09:24.000000000,2018-09-28 00:47:02.000000000,,"[{'_account_id': 9171}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12369}, {'_account_id': 15670}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24236}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-06 20:09:24.000000000', 'files': ['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/unit/volume/drivers/vmware/test_vmware_volumeops.py', 'releasenotes/notes/vmware_vmdk_managed_by-3de05504d0f9a65a.yaml'], 'web_link': 'https://opendev.org/openstack/cinder/commit/d22ed606a2c1fdef7452ef00853e02a5d0cf2e62', 'message': ""VMware: Add 'managedBy' info\n\nAdd vCenter managedBy info to volumes in the backend so that\nthey would be displayed as 'managed by OpenStack Cinder'. It\nalso warns the vSphere admin if an operation is attempted\nusing vSphere client.\n\nChange-Id: I42c00b7df6aa0576b928e49f6eb21f45b56fa647\n(cherry picked from commit 14ff0cc2bd5d6cb91766f7ff6cf83f18d23ac8cd)\n""}]",1,600545,d22ed606a2c1fdef7452ef00853e02a5d0cf2e62,13,12,1,14892,,,0,"VMware: Add 'managedBy' info

Add vCenter managedBy info to volumes in the backend so that
they would be displayed as 'managed by OpenStack Cinder'. It
also warns the vSphere admin if an operation is attempted
using vSphere client.

Change-Id: I42c00b7df6aa0576b928e49f6eb21f45b56fa647
(cherry picked from commit 14ff0cc2bd5d6cb91766f7ff6cf83f18d23ac8cd)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/600545/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/unit/volume/drivers/vmware/test_vmware_volumeops.py', 'releasenotes/notes/vmware_vmdk_managed_by-3de05504d0f9a65a.yaml']",5,d22ed606a2c1fdef7452ef00853e02a5d0cf2e62,vmware_fixes,"--- features: - | The volumes created by VMware VMDK driver will be displayed as ""managed by OpenStack Cinder"" in vCenter server. ",,117,8
openstack%2Fpython-troveclient~stable%2Frocky~I0248b29b46d5bc9549c000b462ecb58c8c1b3d2a,openstack/python-troveclient,stable/rocky,I0248b29b46d5bc9549c000b462ecb58c8c1b3d2a,import zuul job settings from project-config,MERGED,2018-09-11 12:23:01.000000000,2018-09-28 00:35:45.000000000,2018-09-28 00:35:45.000000000,"[{'_account_id': 6873}, {'_account_id': 14151}, {'_account_id': 22348}, {'_account_id': 28646}, {'_account_id': 28695}]","[{'number': 1, 'created': '2018-09-11 12:23:01.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/python-troveclient/commit/af2a3aeb6e5c92b7974d7fc779d37d6e18639c31', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I0248b29b46d5bc9549c000b462ecb58c8c1b3d2a\nStory: #2002586\nTask: #24342\n'}]",0,601580,af2a3aeb6e5c92b7974d7fc779d37d6e18639c31,9,5,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I0248b29b46d5bc9549c000b462ecb58c8c1b3d2a
Story: #2002586
Task: #24342
",git fetch https://review.opendev.org/openstack/python-troveclient refs/changes/80/601580/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,af2a3aeb6e5c92b7974d7fc779d37d6e18639c31,python3-first, - check-requirements - publish-openstack-sphinx-docs - openstack-python-jobs - openstack-python35-jobs - release-notes-jobs - trove-functional-mysql - trove-functional-mysql tox_envlist: full devstack_localrc: TEMPEST_PLUGINS: /opt/stack/trove-tempest-plugin, tox_envlist: 'full' devstack_localrc: TEMPEST_PLUGINS: '/opt/stack/trove-tempest-plugin',9,2
openstack%2Fmurano-dashboard~master~I3884c6a2497f34845a9f39b4eb521fd94522e1f9,openstack/murano-dashboard,master,I3884c6a2497f34845a9f39b4eb521fd94522e1f9,TEST,ABANDONED,2018-09-27 02:25:29.000000000,2018-09-28 00:35:16.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-27 02:25:29.000000000', 'files': ['karma.conf.js'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/a555a445ae687bca849084fb24d7d3b634fcddcb', 'message': 'TEST\n\nChange-Id: I3884c6a2497f34845a9f39b4eb521fd94522e1f9\n'}]",0,605569,a555a445ae687bca849084fb24d7d3b634fcddcb,3,1,1,14107,,,0,"TEST

Change-Id: I3884c6a2497f34845a9f39b4eb521fd94522e1f9
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/69/605569/1 && git format-patch -1 --stdout FETCH_HEAD,['karma.conf.js'],1,a555a445ae687bca849084fb24d7d3b634fcddcb,, './muranodashboard/static/app/**/*.spec.js'}; ," './muranodashboard/static/app/**/*.spec.js', /** * Angular external templates */ './muranodashboard/static/app/**/*.html'};",2,7
openstack%2Frequirements~stable%2Fqueens~If6d03eeeb58a469949c79c016ebee1fb50d9024d,openstack/requirements,stable/queens,If6d03eeeb58a469949c79c016ebee1fb50d9024d,update constraint for ovsdbapp to new release 0.10.2,MERGED,2018-09-27 15:56:06.000000000,2018-09-28 00:23:57.000000000,2018-09-28 00:23:57.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:56:06.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/13e8dd9c5983cea8916173506572edc4c65e53d0', 'message': 'update constraint for ovsdbapp to new release 0.10.2\n\nChange-Id: If6d03eeeb58a469949c79c016ebee1fb50d9024d\nmeta:version: 0.10.2\nmeta:diff-start: -\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Change-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7\nmeta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605793,13e8dd9c5983cea8916173506572edc4c65e53d0,6,2,1,11131,,,0,"update constraint for ovsdbapp to new release 0.10.2

Change-Id: If6d03eeeb58a469949c79c016ebee1fb50d9024d
meta:version: 0.10.2
meta:diff-start: -
meta:series: queens
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Change-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7
meta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/93/605793/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,13e8dd9c5983cea8916173506572edc4c65e53d0,new-release,ovsdbapp===0.10.2,ovsdbapp===0.10.1,1,1
openstack%2Fopenstack-ansible-os_ceilometer~stable%2Frocky~Id720f106a4ed3325a24007bc6cb293e359ac4968,openstack/openstack-ansible-os_ceilometer,stable/rocky,Id720f106a4ed3325a24007bc6cb293e359ac4968,Remove skip-metering-database deprecated param from ceilometer-upgrade,MERGED,2018-09-27 15:04:39.000000000,2018-09-28 00:18:28.000000000,2018-09-28 00:18:28.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:04:39.000000000', 'files': ['tasks/ceilometer_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/a2f89a680dd22caad4c53736ea369e8833b8d388', 'message': 'Remove skip-metering-database deprecated param from ceilometer-upgrade\n\nThe task fails to run because it has an unrecognized argument.\n\nThis param has been removed in ceilometer in commit \n9323f07f977f320882f8b536c3b54835274826fc\n\nCloses-Bug: #1794680\nChange-Id: Id720f106a4ed3325a24007bc6cb293e359ac4968\n(cherry picked from commit 866790e315eb3563326be8bba9565dca4c6075d0)\n'}]",0,605768,a2f89a680dd22caad4c53736ea369e8833b8d388,7,3,1,22018,,,0,"Remove skip-metering-database deprecated param from ceilometer-upgrade

The task fails to run because it has an unrecognized argument.

This param has been removed in ceilometer in commit 
9323f07f977f320882f8b536c3b54835274826fc

Closes-Bug: #1794680
Change-Id: Id720f106a4ed3325a24007bc6cb293e359ac4968
(cherry picked from commit 866790e315eb3563326be8bba9565dca4c6075d0)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/68/605768/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ceilometer_db_setup.yml'],1,a2f89a680dd22caad4c53736ea369e8833b8d388,," command: ""{{ ceilometer_bin }}/ceilometer-upgrade"""," command: ""{{ ceilometer_bin }}/ceilometer-upgrade --skip-metering-database""",1,1
openstack%2Ftrove~stable%2Frocky~I1105ddc52952b4ef9b559b5b82bc052c574790d1,openstack/trove,stable/rocky,I1105ddc52952b4ef9b559b5b82bc052c574790d1,import zuul job settings from project-config,MERGED,2018-09-11 12:23:06.000000000,2018-09-28 00:15:44.000000000,2018-09-28 00:15:44.000000000,"[{'_account_id': 6873}, {'_account_id': 14151}, {'_account_id': 22348}, {'_account_id': 25113}, {'_account_id': 27153}, {'_account_id': 28695}]","[{'number': 1, 'created': '2018-09-11 12:23:06.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/trove/commit/2953676e81fc22099e72ea7d0f27002a59aa779f', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I1105ddc52952b4ef9b559b5b82bc052c574790d1\nStory: #2002586\nTask: #24342\n'}]",0,601581,2953676e81fc22099e72ea7d0f27002a59aa779f,10,6,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I1105ddc52952b4ef9b559b5b82bc052c574790d1
Story: #2002586
Task: #24342
",git fetch https://review.opendev.org/openstack/trove refs/changes/81/601581/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2953676e81fc22099e72ea7d0f27002a59aa779f,python3-first, templates: - openstack-python-jobs - openstack-python35-jobs - publish-openstack-sphinx-docs - periodic-stable-jobs - check-requirements - release-notes-jobs - openstack-tox-pylint - openstack-tox-pylint post: jobs: - openstack-tox-cover SERVICE_HOST: '' HOST_IP: '' tox_envlist: bandit-baseline required-projects: - openstack/requirements irrelevant-files: - ^.*\.rst$ - ^.*\.txt$ - ^api-ref/.*$ - ^apidocs/.*$ - ^contrib/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^trove/hacking/.*$ - ^trove/tests/scenario/.*$ - ^trove/tests/unittests/.*$," SERVICE_HOST: """" HOST_IP: """" tox_envlist: bandit-baseline required-projects: - openstack/requirements irrelevant-files: - ^.*\.rst$ - ^.*\.txt$ - ^api-ref/.*$ - ^apidocs/.*$ - ^contrib/.*$ - ^doc/.*$ - ^etc/.*$ - ^releasenotes/.*$ - ^setup.cfg$ - ^tools/.*$ - ^trove/hacking/.*$ - ^trove/tests/scenario/.*$ - ^trove/tests/unittests/.*$",29,17
openstack%2Ftripleo-heat-templates~master~I9ad86185b01c88b609d320e2384c5644bd99bdae,openstack/tripleo-heat-templates,master,I9ad86185b01c88b609d320e2384c5644bd99bdae,Refactor openshift services for composable roles,MERGED,2018-09-04 14:38:08.000000000,2018-09-28 00:14:07.000000000,2018-09-28 00:14:07.000000000,"[{'_account_id': 4328}, {'_account_id': 10873}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-04 14:38:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5b6f4ccde6070f9ce71103ed140b9a7773329ba1', 'message': 'WIP Refactor openshift services for composable roles\n\nThis reworks the inventory files so that hosts are defined once and\nmade part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 2, 'created': '2018-09-05 11:51:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c728696aa00c46b0618fe91c4b94980a5c4930b1', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 3, 'created': '2018-09-05 14:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d015d8cf3b17e3c3af6e5304213362b0ab602ca4', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 4, 'created': '2018-09-06 07:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6b2904b4c7fcf326a86501c4282fdbc1786d6b88', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 5, 'created': '2018-09-07 06:27:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c7e331e8326cace52e6c15a945194ecd3d18f1b', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 6, 'created': '2018-09-17 12:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bbe8f6e37949105b4a83d328d77db845f4014ef5', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 7, 'created': '2018-09-17 13:21:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68805efeca34b06d4c43712c1bf8e7ac31669a17', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 8, 'created': '2018-09-17 13:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f4eac351b2fc39db4db6e9d00a6c6dcb98f4651', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 9, 'created': '2018-09-17 13:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7aa70288f2da8caacf9aa3ad490d7d9944e5fcd2', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 10, 'created': '2018-09-19 07:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4006444fcc0965a3cdadbb0e94de926749a81e69', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 11, 'created': '2018-09-19 07:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8b81216af784fdc01bc5a9659d30437aabf9fbe0', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 12, 'created': '2018-09-19 13:26:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8317fb22dcd8ad59cab53ff3eab20260ed0b05fc', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 13, 'created': '2018-09-24 10:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/eb157efb256aa13f668e65d4dd867886940c7435', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}, {'number': 14, 'created': '2018-09-25 16:47:08.000000000', 'files': ['roles/OpenShiftMaster.yaml', 'roles/OpenShiftWorker.yaml', 'extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-worker.yaml', 'roles/OpenShiftAllInOne.yaml', 'extraconfig/services/openshift-node.yaml', 'roles/OpenShiftInfra.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7373adc72e453a1b8bbbb88c53783e9ec1d5a624', 'message': 'Refactor openshift services for composable roles\n\nIntroduce an openshift_node template that serves as base for all\nopenshift services. This reworks the inventory files so that hosts are\ndefined once and made part of the appropriate groups.\n\nThe master node can now be split from the infra node, or bundled\ntogether with the Worker in the all-in-one role.\n\nProvide environment files to enable the Master, Worker, Infra or\nall-in-one role individually.\n\nChange-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae\n'}]",14,599618,7373adc72e453a1b8bbbb88c53783e9ec1d5a624,58,8,14,13039,,,0,"Refactor openshift services for composable roles

Introduce an openshift_node template that serves as base for all
openshift services. This reworks the inventory files so that hosts are
defined once and made part of the appropriate groups.

The master node can now be split from the infra node, or bundled
together with the Worker in the all-in-one role.

Provide environment files to enable the Master, Worker, Infra or
all-in-one role individually.

Change-Id: I9ad86185b01c88b609d320e2384c5644bd99bdae
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/18/599618/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/OpenShiftMaster.yaml', 'roles/OpenShiftWorker.yaml', 'extraconfig/services/openshift-master.yaml', 'extraconfig/services/openshift-worker.yaml', 'roles/OpenShiftAllInOne.yaml', 'extraconfig/services/openshift-node.yaml', 'roles/OpenShiftInfra.yaml']",7,5b6f4ccde6070f9ce71103ed140b9a7773329ba1,tripleo-openshift, RoleParametersDefault: OpenShiftNodeGroupName: 'node-config-infra', RoleParametersDefault: OpenShiftNodeGroupName: 'node-config-infra',507,386
openstack%2Frequirements~master~Iee47271cef650a3deb45bf24041328727975d803,openstack/requirements,master,Iee47271cef650a3deb45bf24041328727975d803,update constraint for openstackdocstheme to new release 1.25.0,MERGED,2018-09-27 15:53:51.000000000,2018-09-28 00:13:35.000000000,2018-09-28 00:13:35.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:53:51.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/4ba71ce94bf10b63e24fcc547dbf5752e22cb305', 'message': 'update constraint for openstackdocstheme to new release 1.25.0\n\nChange-Id: Iee47271cef650a3deb45bf24041328727975d803\nmeta:version: 1.25.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Thierry Carrez <thierry@openstack.org>\nmeta:release:Commit: Thierry Carrez <thierry@openstack.org>\nmeta:release:Change-Id: I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605791,4ba71ce94bf10b63e24fcc547dbf5752e22cb305,6,2,1,11131,,,0,"update constraint for openstackdocstheme to new release 1.25.0

Change-Id: Iee47271cef650a3deb45bf24041328727975d803
meta:version: 1.25.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Thierry Carrez <thierry@openstack.org>
meta:release:Commit: Thierry Carrez <thierry@openstack.org>
meta:release:Change-Id: I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/91/605791/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,4ba71ce94bf10b63e24fcc547dbf5752e22cb305,new-release,openstackdocstheme===1.25.0,openstackdocstheme===1.24.1,1,1
openstack%2Fneutron~master~Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c,openstack/neutron,master,Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c,use is_retriable from neutron-lib,MERGED,2018-09-18 21:28:26.000000000,2018-09-27 23:56:12.000000000,2018-09-27 23:56:11.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 5367}, {'_account_id': 6062}, {'_account_id': 8871}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10385}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-09-18 21:28:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/fb1dfac968ea39df13f5d3b8e35af8e6499977b3', 'message': ""use is_retriable from neutron-lib\n\nThe db api is_retriable function is now available in neutron-lib. This\npatch consumes it by removing is_retriable and related internal\nfunctions and using neutron-lib's version where applicable.\n\nNeutronLibImpact\n\nChange-Id: Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c\n""}, {'number': 2, 'created': '2018-09-20 19:13:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/20da313856fe5516c31dcba9a9ae745fc61d9d78', 'message': ""use is_retriable from neutron-lib\n\nThe db api is_retriable function is now available in neutron-lib. This\npatch consumes it by removing is_retriable and related internal\nfunctions and using neutron-lib's version where applicable.\n\nNeutronLibImpact\n\nChange-Id: Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c\n""}, {'number': 3, 'created': '2018-09-24 18:36:41.000000000', 'files': ['neutron/plugins/ml2/managers.py', 'neutron/db/api.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/9849209bbdc0ec110ac43b871f6f1140f95def17', 'message': ""use is_retriable from neutron-lib\n\nThe db api is_retriable function is now available in neutron-lib. This\npatch consumes it by removing is_retriable and related internal\nfunctions and using neutron-lib's version where applicable.\n\nNeutronLibImpact\n\nChange-Id: Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c\n""}]",2,603498,9849209bbdc0ec110ac43b871f6f1140f95def17,37,14,3,5367,,,0,"use is_retriable from neutron-lib

The db api is_retriable function is now available in neutron-lib. This
patch consumes it by removing is_retriable and related internal
functions and using neutron-lib's version where applicable.

NeutronLibImpact

Change-Id: Ie33a4eb4d1e52b2d985c9498edea2efb63ef569c
",git fetch https://review.opendev.org/openstack/neutron refs/changes/98/603498/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/managers.py', 'neutron/db/api.py']",2,fb1dfac968ea39df13f5d3b8e35af8e6499977b3,bp/neutronlib-decouple-db,,"from neutron_lib import exceptions from neutron_lib.objects import exceptions as obj_excfrom oslo_db import exception as db_excfrom oslo_utils import excutilsfrom sqlalchemy.orm import excdef is_retriable(e): if getattr(e, '_RETRY_EXCEEDED', False): return False if _is_nested_instance(e, (db_exc.DBDeadlock, exc.StaleDataError, db_exc.DBConnectionError, db_exc.DBDuplicateEntry, db_exc.RetryRequest, obj_exc.NeutronDbObjectDuplicateEntry)): return True # looking savepoints mangled by deadlocks. see bug/1590298 for details. return _is_nested_instance(e, db_exc.DBError) and '1305' in str(e) def _tag_retriables_as_unretriable(f): """"""Puts a flag on retriable exceptions so is_retriable returns False. This decorator can be used outside of a retry decorator to prevent decorators higher up from retrying again. """""" @six.wraps(f) def wrapped(*args, **kwargs): try: return f(*args, **kwargs) except Exception as e: with excutils.save_and_reraise_exception(): if is_retriable(e): setattr(e, '_RETRY_EXCEEDED', True) return wrapped def _is_nested_instance(e, etypes): """"""Check if exception or its inner excepts are an instance of etypes."""""" if isinstance(e, etypes): return True if isinstance(e, exceptions.MultipleExceptions): return any(_is_nested_instance(i, etypes) for i in e.inner_exceptions) if isinstance(e, db_exc.DBError): return _is_nested_instance(e.inner_exception, etypes) return False ",2,46
openstack%2Fopenstack-ansible-ceph_client~stable%2Focata~Ib95e96130a06d3dd92aa237080a04f762995a729,openstack/openstack-ansible-ceph_client,stable/ocata,Ib95e96130a06d3dd92aa237080a04f762995a729,Fix apt pinning for ceph,MERGED,2018-09-27 12:46:25.000000000,2018-09-27 23:51:46.000000000,2018-09-27 23:51:46.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:46:25.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/a2d17c34dcd844a725aae4b17419d520c0980819', 'message': 'Fix apt pinning for ceph\n\nCeph apt pinning need to pin to ceph.com instead of RedHat.\napt policy :\n\n1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages\n     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64\n     origin download.ceph.com\n\nChange-Id: Ib95e96130a06d3dd92aa237080a04f762995a729\n'}]",1,605677,a2d17c34dcd844a725aae4b17419d520c0980819,7,3,1,13095,,,0,"Fix apt pinning for ceph

Ceph apt pinning need to pin to ceph.com instead of RedHat.
apt policy :

1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages
     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64
     origin download.ceph.com

Change-Id: Ib95e96130a06d3dd92aa237080a04f762995a729
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/77/605677/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,a2d17c34dcd844a725aae4b17419d520c0980819,,"ceph_apt_pinned_packages: [{ package: ""*"", release: ""ceph.com"", priority: 1001 }]","ceph_apt_pinned_packages: [{ package: ""*"", release: ""RedHat"", priority: 1001 }]",1,1
openstack%2Fopenstack-ansible-ceph_client~stable%2Fpike~Ib95e96130a06d3dd92aa237080a04f762995a729,openstack/openstack-ansible-ceph_client,stable/pike,Ib95e96130a06d3dd92aa237080a04f762995a729,Fix apt pinning for ceph,MERGED,2018-09-27 12:36:18.000000000,2018-09-27 23:51:45.000000000,2018-09-27 23:51:45.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:36:18.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/449603262c8e95ec6582b797478a46cbeb7c2a68', 'message': 'Fix apt pinning for ceph\n\nCeph apt pinning need to pin to ceph.com instead of RedHat.\napt policy :\n\n1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages\n     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64\n     origin download.ceph.com\n\nChange-Id: Ib95e96130a06d3dd92aa237080a04f762995a729\n(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)\n'}]",0,605671,449603262c8e95ec6582b797478a46cbeb7c2a68,7,3,1,13095,,,0,"Fix apt pinning for ceph

Ceph apt pinning need to pin to ceph.com instead of RedHat.
apt policy :

1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages
     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64
     origin download.ceph.com

Change-Id: Ib95e96130a06d3dd92aa237080a04f762995a729
(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/71/605671/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,449603262c8e95ec6582b797478a46cbeb7c2a68,fix-apt-pinning-stable/pike,"ceph_apt_pinned_packages: [{ package: ""*"", release: ""ceph.com"", priority: 1001 }]","ceph_apt_pinned_packages: [{ package: ""*"", release: ""RedHat"", priority: 1001 }]",1,1
openstack%2Fopenstack-ansible-ceph_client~stable%2Fqueens~Ib95e96130a06d3dd92aa237080a04f762995a729,openstack/openstack-ansible-ceph_client,stable/queens,Ib95e96130a06d3dd92aa237080a04f762995a729,Fix apt pinning for ceph,MERGED,2018-09-27 12:36:05.000000000,2018-09-27 23:51:45.000000000,2018-09-27 23:51:45.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:36:05.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/17feb0e8834436895d3a803e89538014cb0e0fe0', 'message': 'Fix apt pinning for ceph\n\nCeph apt pinning need to pin to ceph.com instead of RedHat.\napt policy :\n\n1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages\n     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64\n     origin download.ceph.com\n\nChange-Id: Ib95e96130a06d3dd92aa237080a04f762995a729\n(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)\n'}]",0,605670,17feb0e8834436895d3a803e89538014cb0e0fe0,7,3,1,13095,,,0,"Fix apt pinning for ceph

Ceph apt pinning need to pin to ceph.com instead of RedHat.
apt policy :

1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages
     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64
     origin download.ceph.com

Change-Id: Ib95e96130a06d3dd92aa237080a04f762995a729
(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/70/605670/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,17feb0e8834436895d3a803e89538014cb0e0fe0,fix-apt-pinning-stable/queens,"ceph_apt_pinned_packages: [{ package: ""*"", release: ""ceph.com"", priority: 1001 }]","ceph_apt_pinned_packages: [{ package: ""*"", release: ""RedHat"", priority: 1001 }]",1,1
openstack%2Fopenstack-ansible-tests~master~I1c6db66525fccea461a72fa036bade3681f585ab,openstack/openstack-ansible-tests,master,I1c6db66525fccea461a72fa036bade3681f585ab,zuul.d: jobs: Restore voting for CentOS 7 functional jobs,ABANDONED,2018-06-13 14:45:49.000000000,2018-09-27 23:40:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-06-13 14:45:49.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/0d45b14f5aff564d35b9b83002fc91829640af3e', 'message': 'zuul.d: jobs: Restore voting for CentOS 7 functional jobs\n\nThe EPEL problems have been resolved in the lxc_hosts role so CentOS 7\ncan become a voting job again.\n\nChange-Id: I1c6db66525fccea461a72fa036bade3681f585ab\n'}]",0,575136,0d45b14f5aff564d35b9b83002fc91829640af3e,3,1,1,23163,,,0,"zuul.d: jobs: Restore voting for CentOS 7 functional jobs

The EPEL problems have been resolved in the lxc_hosts role so CentOS 7
can become a voting job again.

Change-Id: I1c6db66525fccea461a72fa036bade3681f585ab
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/36/575136/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,0d45b14f5aff564d35b9b83002fc91829640af3e,restore-centos-voting,, # Temporary nv until https://review.openstack.org/#/c/574382/ gets in voting: false,0,2
openstack%2Fopenstack-ansible-os_neutron~stable%2Frocky~Ic2f8a999cc084da76fade0000d2e6198b025c38a,openstack/openstack-ansible-os_neutron,stable/rocky,Ic2f8a999cc084da76fade0000d2e6198b025c38a,Clean up role tests,MERGED,2018-09-19 18:07:59.000000000,2018-09-27 23:38:51.000000000,2018-09-27 23:38:51.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-19 18:07:59.000000000', 'files': ['tests/test-neutron-upgrades.sh', 'tests/ansible-role-requirements.yml', 'tests/benchmark-upgrade.yml', 'tests/test-neutron-resources-upgrade.yml', 'tests/test-install-previous-neutron.yml', 'zuul.d/project.yaml', 'tests/test-upgrade.yml', 'tests/test-neutron-resources-results.yml', 'tox.ini', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/6244054ca7bb6d592834b858e3b44cb16b39668d', 'message': ""Clean up role tests\n\nNow that we're using the general templates, we can slim down\nthe role test definitions. We can also remove tests which are\nnot being watched, or which are fundamentally broken. With\nthis we can also remove unused scripts/plays.\n\nWe do the following:\n\n1. We remove the 'ssl' job, given that the person working on\n   that is no longer doing so, and no-one else has picked up\n   the work.\n2. We remove the 'upgrade' job, given that it's been broken\n   all cycle due to the way the job executes and we need to\n   regroup to figure out another way to do it.\n3. We promote the jobs which appear to be reliably working.\n4. We rename the tox target for 'func_ovs' to 'ovs' as the\n   'func_' prefix is pointless.\n5. We rename the '-nv' jobs to without that suffix, and move\n   the non-voting argument to the projects file to make it\n   more obvious and easier to change later.\n\nChange-Id: Ic2f8a999cc084da76fade0000d2e6198b025c38a\n(cherry picked from commit 2c847b53cbbaee5801c549c98b160f9b8c7786ae)\n""}]",0,603857,6244054ca7bb6d592834b858e3b44cb16b39668d,16,4,1,6816,,,0,"Clean up role tests

Now that we're using the general templates, we can slim down
the role test definitions. We can also remove tests which are
not being watched, or which are fundamentally broken. With
this we can also remove unused scripts/plays.

We do the following:

1. We remove the 'ssl' job, given that the person working on
   that is no longer doing so, and no-one else has picked up
   the work.
2. We remove the 'upgrade' job, given that it's been broken
   all cycle due to the way the job executes and we need to
   regroup to figure out another way to do it.
3. We promote the jobs which appear to be reliably working.
4. We rename the tox target for 'func_ovs' to 'ovs' as the
   'func_' prefix is pointless.
5. We rename the '-nv' jobs to without that suffix, and move
   the non-voting argument to the projects file to make it
   more obvious and easier to change later.

Change-Id: Ic2f8a999cc084da76fade0000d2e6198b025c38a
(cherry picked from commit 2c847b53cbbaee5801c549c98b160f9b8c7786ae)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/57/603857/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test-neutron-upgrades.sh', 'tests/ansible-role-requirements.yml', 'tests/benchmark-upgrade.yml', 'tests/test-neutron-resources-upgrade.yml', 'tests/test-install-previous-neutron.yml', 'zuul.d/project.yaml', 'tests/test-upgrade.yml', 'tests/test-neutron-resources-results.yml', 'tox.ini', 'zuul.d/jobs.yaml']",10,6244054ca7bb6d592834b858e3b44cb16b39668d,cleanup-role-tests-stable/rocky, name: openstack-ansible-ovs-ubuntu-xenial vars: tox_env: ovs name: openstack-ansible-calico-ubuntu-xenial name: openstack-ansible-dragonflow-ubuntu-xenial name: openstack-ansible-opendaylight-ubuntu-xenial, name: openstack-ansible-ovs-ubuntu-xenial-nv voting: false vars: tox_env: func_ovs name: openstack-ansible-calico-ubuntu-xenial-nv voting: false name: openstack-ansible-dragonflow-ubuntu-xenial-nv voting: false name: openstack-ansible-opendaylight-ubuntu-xenial-nv voting: false voting: false name: openstack-ansible-neutron-ssl-nv parent: openstack-ansible-functional-ubuntu-xenial voting: false vars: tox_env: ssl - job: voting: false voting: false,27,382
openstack%2Fopenstack-ansible-ops~master~Icf337447f7a9b4033af261910f77216a170937ed,openstack/openstack-ansible-ops,master,Icf337447f7a9b4033af261910f77216a170937ed,MNAIO: Ensure VM's are shut down before doing image save,MERGED,2018-09-27 17:09:14.000000000,2018-09-27 23:19:58.000000000,2018-09-27 23:19:58.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 17:09:14.000000000', 'files': ['multi-node-aio/playbooks/save-vms.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/9b0f2b5dbd0c6c08162e100d1989ff37f0589a15', 'message': ""MNAIO: Ensure VM's are shut down before doing image save\n\nWhen the virt module returns success for the shutdown state, it\nhas only sucessfully sent the signal to shut down. It may still\ntake a few more minutes for the VM's to actually complete their\nshut down. If we try to change the image while the machine is\nstill busy shutting down, the image conversion/compression fails\nand the resulting state is incomplete.\n\nIn this patch we do the following:\n\n1. Find and shut down the running VM's without needing to look\n   at the inventory. This reduces complexity in the play.\n2. Makes sure that the VM's are all in the 'shut off' state,\n   before continuing on to saving the images.\n\nChange-Id: Icf337447f7a9b4033af261910f77216a170937ed\n""}]",0,605814,9b0f2b5dbd0c6c08162e100d1989ff37f0589a15,7,2,1,6816,,,0,"MNAIO: Ensure VM's are shut down before doing image save

When the virt module returns success for the shutdown state, it
has only sucessfully sent the signal to shut down. It may still
take a few more minutes for the VM's to actually complete their
shut down. If we try to change the image while the machine is
still busy shutting down, the image conversion/compression fails
and the resulting state is incomplete.

In this patch we do the following:

1. Find and shut down the running VM's without needing to look
   at the inventory. This reduces complexity in the play.
2. Makes sure that the VM's are all in the 'shut off' state,
   before continuing on to saving the images.

Change-Id: Icf337447f7a9b4033af261910f77216a170937ed
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/14/605814/1 && git format-patch -1 --stdout FETCH_HEAD,['multi-node-aio/playbooks/save-vms.yml'],1,9b0f2b5dbd0c6c08162e100d1989ff37f0589a15,," - name: Get info about existing virt storage pools - name: Get info about existing VM's virt: command: list_vms register: _virt_list - name: Shut down all running VM's virt: name: ""{{ item }}"" command: shutdown failed_when: false with_items: ""{{ _virt_list.list_vms }}"" - name: Wait for shut down to complete command: | virsh domstate {{ item }} register: _vm_shutdown until: _vm_shutdown.stdout.find('shut off') != -1 retries: 5 delay: 60 with_items: ""{{ _virt_list.list_vms }}"" if [[ -e {{ item }}.img ]]; then if [[ -e {{ item }}-base.img ]]; then qemu-img commit {{ item }}.img qemu-img convert -O qcow2 -c {{ item }}.img {{ item }}-base.img qemu-img create -f qcow2 -b {{ item }}-base.img {{ item }}.img with_items: ""{{ _virt_list.list_vms }}"" src: ""/etc/libvirt/qemu/{{ item }}.xml"" with_items: ""{{ _virt_list.list_vms }}"""," - name: Gather variables for each operating system include_vars: ""{{ item }}"" with_first_found: - ""{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_version | lower }}.yml"" - ""{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}-{{ ansible_distribution_major_version | lower }}.yml"" - ""{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}-{{ ansible_distribution_major_version | lower }}.yml"" - ""{{ playbook_dir }}/vars/{{ ansible_distribution | lower }}.yml"" - ""{{ playbook_dir }}/vars/{{ ansible_os_family | lower }}.yml"" tags: - always - name: Get info about the virt storage pools tags: - always - name: Stop running VMs virt: name: ""{{ hostvars[item]['server_hostname'] }}"" state: shutdown when: - hostvars[item]['server_vm'] | default(false) | bool with_items: ""{{ groups['pxe_servers'] }}"" if [[ -e {{ hostvars[item]['server_hostname'] }}.img ]]; then if [[ -e {{ hostvars[item]['server_hostname'] }}-base.img ]]; then qemu-img commit {{ hostvars[item]['server_hostname'] }}.img qemu-img convert -O qcow2 -c {{ hostvars[item]['server_hostname'] }}.img {{ hostvars[item]['server_hostname'] }}-base.img qemu-img create -f qcow2 -b {{ hostvars[item]['server_hostname'] }}-base.img {{ hostvars[item]['server_hostname'] }}.img when: - hostvars[item]['server_vm'] | default(false) | bool with_items: ""{{ groups['pxe_servers'] }}"" src: ""/etc/libvirt/qemu/{{ hostvars[item]['server_hostname'] }}.xml"" when: - hostvars[item]['server_vm'] | default(false) | bool with_items: ""{{ groups['pxe_servers'] }}""",28,32
openstack%2Freleases~master~I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2,openstack/releases,master,I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2,[rally] Propose 1.2.1 release,MERGED,2018-09-26 21:33:29.000000000,2018-09-27 23:10:32.000000000,2018-09-27 23:10:32.000000000,"[{'_account_id': 2472}, {'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 21:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/f363bc3a500cb14f892d82616cc873f646b2c78b', 'message': '[rally] Propose 1.2.1 release\n\nDepends-On: I7a35debd44da6844b8e8626b34aaad23e3092dfb\nChange-Id: I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2\n'}, {'number': 2, 'created': '2018-09-27 13:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/8dc0b04ad4bbf96c3304adb4cf53cfd2882fab3b', 'message': '[rally] Propose 1.2.1 release\n\nDepends-On: I7a35debd44da6844b8e8626b34aaad23e3092dfb\nChange-Id: I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2\n'}, {'number': 3, 'created': '2018-09-27 13:44:06.000000000', 'files': ['deliverables/_independent/rally.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/c31202731abc964b4de6b539749e927bbb38d5c2', 'message': '[rally] Propose 1.2.1 release\n\nDepends-On: Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6\nChange-Id: I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2\n'}]",0,605538,c31202731abc964b4de6b539749e927bbb38d5c2,11,3,3,9545,,,0,"[rally] Propose 1.2.1 release

Depends-On: Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6
Change-Id: I10b1e8ad007ed50f4bc38de468bdc51619e5e0b2
",git fetch https://review.opendev.org/openstack/releases refs/changes/38/605538/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/rally.yaml'],1,f363bc3a500cb14f892d82616cc873f646b2c78b,rally_1.2.1, - version: 1.2.1 projects: - repo: openstack/rally hash: f606f72fb53dc146e1546642a13ebabe489c66f6,,4,0
openstack%2Fpatrole~master~Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84,openstack/patrole,master,Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84,Add tests to cover policy_minimum_bandwidth_rule,MERGED,2018-08-20 18:43:32.000000000,2018-09-27 22:30:39.000000000,2018-09-27 22:30:39.000000000,"[{'_account_id': 16274}, {'_account_id': 17896}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-08-20 18:43:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/b4e41f36b6ec8a8218249c472a4e6eec7b6dd302', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nStory: 2002641\nTask: 22321\n'}, {'number': 2, 'created': '2018-08-20 20:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/64d77214e529319a35e558d4faab62a62dc0bdba', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nStory: 2002641\nTask: 22321\n'}, {'number': 3, 'created': '2018-08-21 20:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/f9684dd80720f63a4dee7f0a7ddd152c3e71f6fe', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nDepends-On: https://review.openstack.org/594543\nStory: 2002641\nTask: 22321\n'}, {'number': 4, 'created': '2018-08-24 16:28:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/b4b4065eb31cbf37b4197e92ecc50ac3e43d764f', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nDepends-On: https://review.openstack.org/#/c/592762/\nStory: 2002641\nTask: 22321\n'}, {'number': 5, 'created': '2018-09-17 20:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/7f47aa06c988dc3d7c2b8ee0e6330f1a95da291b', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nDepends-On: https://review.openstack.org/#/c/592762/\nStory: 2002641\nTask: 22321\n'}, {'number': 6, 'created': '2018-09-19 16:24:10.000000000', 'files': ['patrole_tempest_plugin/tests/api/network/test_policy_minimum_bandwidth_rule_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/433bf50679fdf6606a7af53380491287b69e4203', 'message': 'Add tests to cover policy_minimum_bandwidth_rule\n\nThis patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].\nTest creates, showes, updates and deletes policy_minimum_bandwidth_rule.\nPart of ""Increase Neutron RBAC Coverage"" initiative [1]\n\n[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules\n[1] https://storyboard.openstack.org/#!/story/2002641\n\nChange-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84\nDepends-On: https://review.openstack.org/#/c/592762/\nStory: 2002641\nTask: 22321\n'}]",1,593847,433bf50679fdf6606a7af53380491287b69e4203,18,4,6,16274,,,0,"Add tests to cover policy_minimum_bandwidth_rule

This patch set adds tests to cover the policy_minimum_bandwidth_rule API [0].
Test creates, showes, updates and deletes policy_minimum_bandwidth_rule.
Part of ""Increase Neutron RBAC Coverage"" initiative [1]

[0] https://developer.openstack.org/api-ref/network/v2/index.html#qos-minimum-bandwidth-rules
[1] https://storyboard.openstack.org/#!/story/2002641

Change-Id: Ice4d20d20320f70ea0a8332bb53f1ebcde2c7a84
Depends-On: https://review.openstack.org/#/c/592762/
Story: 2002641
Task: 22321
",git fetch https://review.opendev.org/openstack/patrole refs/changes/47/593847/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/network/test_policy_minimum_bandwidth_rule_rbac.py'],1,b4e41f36b6ec8a8218249c472a4e6eec7b6dd302,,"# Copyright 2017 AT&T Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.common import utils from tempest.lib.common.utils import data_utils from tempest.lib.common.utils import test_utils from tempest.lib import decorators from patrole_tempest_plugin import rbac_rule_validation from patrole_tempest_plugin.tests.api.network import rbac_base as base class PolicyMinimumBandwidthRulePluginRbacTest(base.BaseNetworkPluginRbacTest): @classmethod def skip_checks(cls): super(PolicyMinimumBandwidthRulePluginRbacTest, cls).skip_checks() if not utils.is_extension_enabled('qos', 'network'): msg = ""qos extension not enabled."" raise cls.skipException(msg) @classmethod def resource_setup(cls): super(PolicyMinimumBandwidthRulePluginRbacTest, cls).resource_setup() name = data_utils.rand_name(cls.__class__.__name__ + '-qos') cls.policy_id = cls.ntp_client.create_qos_policy( name=name)[""policy""][""id""] cls.addClassResourceCleanup(test_utils.call_and_ignore_notfound_exc, cls.ntp_client.delete_qos_policy, cls.policy_id) def create_minimum_bandwidth_rule(self): rule = self.ntp_client.create_minimum_bandwidth_rule( self.policy_id, direction=""egress"", min_kbps=1000) rule_id = rule['minimum_bandwidth_rule']['id'] self.addCleanup(test_utils.call_and_ignore_notfound_exc, self.ntp_client.delete_minimum_bandwidth_rule, self.policy_id, rule_id) return rule_id @decorators.idempotent_id('25B5EF3A-DF2A-4C80-A498-3BE14A321D97') @rbac_rule_validation.action( service=""neutron"", rules=[""create_policy_minimum_bandwidth_rule""]) def test_create_policy_minimum_bandwidth_rule(self): """"""Create policy_minimum_bandwidth_rule. RBAC test for the neutron ""create_policy_minimum_bandwidth_rule"" policy """""" with self.rbac_utils.override_role(self): self.create_minimum_bandwidth_rule() @decorators.idempotent_id('01DD902C-47C5-45D2-9A0E-7AF05981DF21') @rbac_rule_validation.action(service=""neutron"", rules=[""get_policy_minimum_bandwidth_rule""], expected_error_codes=[404]) def test_show_policy_minimum_bandwidth_rule(self): """"""Show policy_minimum_bandwidth_rule. RBAC test for the neutron ""get_policy_minimum_bandwidth_rule"" policy """""" rule_id = self.create_minimum_bandwidth_rule() with self.rbac_utils.override_role(self): self.ntp_client.delete_minimum_bandwidth_rule( self.policy_id, rule_id) @decorators.idempotent_id('50AFE69B-455C-413A-BDC6-26B42DC8D55D') @rbac_rule_validation.action( service=""neutron"", rules=[""get_policy_minimum_bandwidth_rule"", ""update_policy_minimum_bandwidth_rule""], expected_error_codes=[404, 403]) def test_update_policy_minimum_bandwidth_rule(self): """"""Update policy_minimum_bandwidth_rule. RBAC test for the neutron ""update_policy_minimum_bandwidth_rule"" policy """""" rule_id = self.create_minimum_bandwidth_rule() with self.rbac_utils.override_role(self): self.ntp_client.update_minimum_bandwidth_rule( self.policy_id, rule_id, min_kbps=2000) @decorators.idempotent_id('2112E325-C3B2-4071-8A93-B218F275A83B') @rbac_rule_validation.action( service=""neutron"", rules=[""get_policy_minimum_bandwidth_rule"", ""delete_policy_minimum_bandwidth_rule""], expected_error_codes=[404, 403]) def test_delete_policy_minimum_bandwidth_rule(self): """"""Delete policy_minimum_bandwidth_rule. RBAC test for the neutron ""delete_policy_minimum_bandwidth_rule"" policy """""" rule_id = self.create_minimum_bandwidth_rule() with self.rbac_utils.override_role(self): self.ntp_client.delete_minimum_bandwidth_rule( self.policy_id, rule_id) ",,112,0
openstack%2Fopenstack-ansible-galera_server~stable%2Frocky~Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,openstack/openstack-ansible-galera_server,stable/rocky,Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,Enable the xinetd service for reboot,MERGED,2018-09-27 15:20:56.000000000,2018-09-27 22:25:49.000000000,2018-09-27 22:25:49.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:20:56.000000000', 'files': ['tasks/galera_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/a429f3cd33da0318d47c2dcf769ff12411b3dff9', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinetd service should be\nstarted. Otherwise the haproxy health check will fail and haproxy will\nnot forward database connections.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)\n'}]",0,605776,a429f3cd33da0318d47c2dcf769ff12411b3dff9,7,3,1,19298,,,0,"Enable the xinetd service for reboot

If the Galera container is rebooted, the xinetd service should be
started. Otherwise the haproxy health check will fail and haproxy will
not forward database connections.

Change-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d
(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/76/605776/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_post_install.yml', 'handlers/main.yml']",2,a429f3cd33da0318d47c2dcf769ff12411b3dff9,enable_xinetd-stable/rocky, enabled: true,,10,0
openstack%2Fpatrole~master~I9c7645a0f9b04609921a5ea607b203e8215fc32b,openstack/patrole,master,I9c7645a0f9b04609921a5ea607b203e8215fc32b,Use oslo_policy.policy.Rules.load to load rules,MERGED,2018-09-11 19:49:48.000000000,2018-09-27 22:23:32.000000000,2018-09-27 22:23:32.000000000,"[{'_account_id': 1921}, {'_account_id': 5196}, {'_account_id': 5689}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 8911}, {'_account_id': 17896}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23185}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-09-11 19:49:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/017eb94f8456909798f0708e26f549330e0610fb', 'message': 'Use oslo_policy.policy.Rules.load to load rules\n\nChange-Id: I9c7645a0f9b04609921a5ea607b203e8215fc32b\n'}, {'number': 2, 'created': '2018-09-11 22:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/92d1a365642417605c83b9ad8ad45bbaec9389dc', 'message': 'Use oslo_policy.policy.Rules.load to load rules\n\nChange-Id: I9c7645a0f9b04609921a5ea607b203e8215fc32b\n'}, {'number': 3, 'created': '2018-09-12 18:34:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/f827d0c6ebd12f1400ce81a4f299c509c2512d66', 'message': 'Use oslo_policy.policy.Rules.load to load rules\n\nChange-Id: I9c7645a0f9b04609921a5ea607b203e8215fc32b\n'}, {'number': 4, 'created': '2018-09-12 23:26:47.000000000', 'files': ['releasenotes/notes/yaml-policy-file-support-278d3edf64f98d69.yaml', 'patrole_tempest_plugin/config.py', 'patrole_tempest_plugin/tests/unit/test_policy_authority.py', 'patrole_tempest_plugin/tests/unit/resources/custom_rbac_policy.yaml', 'patrole_tempest_plugin/policy_authority.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/ef7047df40b674c72635b9dac9d7e6e1f22e9a86', 'message': 'Use oslo_policy.policy.Rules.load to load rules\n\nRe-using Rules.load function makes it possible to support parsing\ncustom YAML policy files, the new policy file extension since Ocata.\n\nChange-Id: I9c7645a0f9b04609921a5ea607b203e8215fc32b\n'}]",15,601680,ef7047df40b674c72635b9dac9d7e6e1f22e9a86,20,13,4,8911,,,0,"Use oslo_policy.policy.Rules.load to load rules

Re-using Rules.load function makes it possible to support parsing
custom YAML policy files, the new policy file extension since Ocata.

Change-Id: I9c7645a0f9b04609921a5ea607b203e8215fc32b
",git fetch https://review.opendev.org/openstack/patrole refs/changes/80/601680/4 && git format-patch -1 --stdout FETCH_HEAD,"['patrole_tempest_plugin/config.py', 'patrole_tempest_plugin/policy_authority.py']",2,017eb94f8456909798f0708e26f549330e0610fb,multi_policy_files_with_yaml," self.rules = self.get_rules() def get_rules(self): rules = policy.Rules(default_rule='default') for k, v in policy.Rules.load(fp.read()).items(): if k not in rules: rules[k] = v # If the policy name and rule are the same, no # ambiguity, so no reason to warn. elif str(v) != str(rules[k]): LOG.warning(""The same policy name: %s was found "" ""in multiple policies files for "" ""service %s. This can lead to policy "" ""rule ambiguity. Using rule: %s"", k, self.service, rules[k]) except (ValueError, IOError): LOG.warning(""Failed to read policy file '%s' for service %s."", path, self.service) if self.service in policy_generator: for rule in policy_generator[self.service]: if rule.name not in rules: rules[rule.name] = rule.check elif str(rule.check) != str(rules[rule.name]): LOG.warning(""The same policy name: %s was found "" ""in the policies files and in the code "" ""for service %s. This can lead to policy "" ""rule ambiguity. Using rule: %s"", rule.name, self.service, rules[rule.name]) if not rules: msg = ( 'files: {1}.'.format( self.service, [loc % self.service for loc in CONF.patrole.custom_policy_files])) raise rbac_exceptions.RbacParsingException(msg) return rules","import json self.rules = policy.Rules.load(self._get_policy_data(), 'default') def _get_policy_data(self): file_policy_data = {} mgr_policy_data = {} policy_data = {} for k, v in json.load(fp).items(): if k not in file_policy_data: file_policy_data[k] = v else: # If the policy name and rule are the same, no # ambiguity, so no reason to warn. if v != file_policy_data[k]: LOG.warning( ""The same policy name: %s was found in "" ""multiple policies files for service %s. "" ""This can lead to policy rule ambiguity. "" ""Using rule: %s"", k, self.service, file_policy_data[k]) except (IOError, ValueError) as e: msg = ""Failed to read policy file for service. "" if isinstance(e, IOError): msg += ""Please check that policy path exists."" else: msg += ""JSON may be improperly formatted."" LOG.debug(msg) on_load_failure_callback=None, if policy_generator and self.service in policy_generator: for rule in policy_generator[self.service]: mgr_policy_data[rule.name] = str(rule.check) # If data from both file and code exist, combine both together. if file_policy_data and mgr_policy_data: # Add the policy actions from code first. for action, rule in mgr_policy_data.items(): policy_data[action] = rule # Overwrite with any custom policy actions defined in policy.json. for action, rule in file_policy_data.items(): policy_data[action] = rule elif file_policy_data: policy_data = file_policy_data elif mgr_policy_data: policy_data = mgr_policy_data else: error_message = ( 'files: {1}.'.format(self.service, [loc % self.service for loc in CONF.patrole.custom_policy_files]) ) raise rbac_exceptions.RbacParsingException(error_message) try: policy_data = json.dumps(policy_data) except (TypeError, ValueError): error_message = 'Policy files for {0} service are invalid.'.format( self.service) raise rbac_exceptions.RbacParsingException(error_message) return policy_data",35,58
openstack%2Fpatrole~master~Ie5159166505d9bee3e99ca0d51949f6391c569b9,openstack/patrole,master,Ie5159166505d9bee3e99ca0d51949f6391c569b9,Add granularity for volume_extension:volume_type_encryption,MERGED,2018-06-04 16:10:44.000000000,2018-09-27 22:23:31.000000000,2018-09-27 22:23:31.000000000,"[{'_account_id': 17896}, {'_account_id': 19391}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-06-04 16:10:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/85ca7d31e72b14ef5e640d1bf735de044399231e', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update\nfor the corresponding create/delete/update volume_type_encryption test cases.\n\nDepends on https://review.openstack.org/#/c/571563\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 2, 'created': '2018-06-04 17:58:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/bf4fcc7151cb4bc165f235dcf73e0f519f6413bf', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update\nfor the corresponding create/delete/update volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 3, 'created': '2018-06-05 18:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/e069bf21722f2b5c9719a343ff2dd31ee65d024e', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 4, 'created': '2018-06-05 18:47:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/b956fe2da93726dc4b22dc734c42ccda4798912a', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 5, 'created': '2018-06-05 19:52:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/eb421a251745163af15e71913db9214e042b1b20', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 6, 'created': '2018-06-05 22:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/53fb599dac1612bda5a7aad72809b3cbbd4a9d99', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 7, 'created': '2018-06-06 21:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/de7d4abe83eed640e706eefa40d5c5dc926c3868', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 8, 'created': '2018-06-06 22:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/20a4a10763b4a6c436daf5ec20d2304678d66758', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 9, 'created': '2018-06-06 22:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/b8eaaa677294bd5f6bdc21f8313b263139a95330', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 10, 'created': '2018-06-06 23:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/2dd34c92e11d2977aad4e46991c8567df2ea03a3', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 11, 'created': '2018-06-07 18:05:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/4f1359bcbb9059e3f748ebf5b772370091e556fb', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 12, 'created': '2018-06-08 03:46:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/c6728ba38d0353aab48891ae739a42cc07a7c31e', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 13, 'created': '2018-06-08 14:20:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/da88538405b6db13e864d4e09da09a47f2038cf9', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 14, 'created': '2018-06-08 18:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/e12b116c7c6b1f8804073bcc50b7c26a2dd21f0a', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 15, 'created': '2018-06-19 20:29:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/3e41b7d285b44c01f64a1f1390adc8ad61600f83', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 16, 'created': '2018-06-19 21:30:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/154041417df8d7ecf28f585cdfd882f543ed1382', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rule volume_extension:volume_type_encryption_create/delete/update/show\nfor the corresponding create/delete/update/show volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 17, 'created': '2018-06-19 22:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/e5db02815178af1915db41f7b5f363d0a74a6cd5', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 18, 'created': '2018-06-20 14:34:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/949c02fba351f486b30d3ffd5b43cd8d547d12a6', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 19, 'created': '2018-06-20 17:10:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/ecf25565c5f07213351dec8a5dbd1fb96a214f8a', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 20, 'created': '2018-06-20 18:42:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/6c5c5daa02e967b1d9c989945aa86065d761c7d7', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 21, 'created': '2018-06-20 18:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/53f29883c988729be1322c83843ea41a6d9c2629', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 22, 'created': '2018-06-20 19:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/24d5e1ec9bc6dddc8264b0362be48f88d8312e4e', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 23, 'created': '2018-06-20 20:15:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/20f1b355d51ee000d5d7ce1daf57ba9dc0711974', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 24, 'created': '2018-06-22 18:09:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/9f6b00c549155f16d8af74e10240360259e30504', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 25, 'created': '2018-06-22 20:25:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/29278ae860502aa5275e85b5c71f8068c57efa62', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 26, 'created': '2018-06-25 14:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/5bba03c130a06e1aeb06620130f9bf4e6879b0d3', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 27, 'created': '2018-06-25 22:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/a7274a316fd1d9a03809d51ec65f9b2b70546a9d', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 28, 'created': '2018-09-25 16:50:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/f407dff1732d7db4171318009e524de94a239864', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 29, 'created': '2018-09-25 19:11:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/87b5cf56ebe3d20b23edd8d65e896b3f54cf82f7', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 30, 'created': '2018-09-25 20:16:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/patrole/commit/cc6726ada633230c999ea8e2cc86dbf0eec05239', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}, {'number': 31, 'created': '2018-09-25 21:35:36.000000000', 'files': ['patrole_tempest_plugin/rbac_rule_validation.py', 'patrole_tempest_plugin/config.py', 'patrole_tempest_plugin/tests/unit/test_rbac_rule_validation.py', 'releasenotes/notes/volume-type-encryption-policy-granularity-141ac283b9c0778e.yaml', 'devstack/plugin.sh', 'patrole_tempest_plugin/tests/api/volume/test_encryption_types_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/8c04bd87800ff8c428b58f0d8b990689916eff9e', 'message': 'Add granularity for volume_extension:volume_type_encryption\n\nUse granular rules:\nvolume_extension:volume_type_encryption:create\nvolume_extension:volume_type_encryption:delete\nvolume_extension:volume_type_encryption:update\nvolume_extension:volume_type_encryption:get\n\nfor the corresponding create, delete, update, and\nget volume_type_encryption test cases.\n\nDepends-On: Iba58e785df934d1c4175c0877d266193ac0167b7\n\nChange-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9\n'}]",36,572158,8c04bd87800ff8c428b58f0d8b990689916eff9e,90,4,31,19391,,,0,"Add granularity for volume_extension:volume_type_encryption

Use granular rules:
volume_extension:volume_type_encryption:create
volume_extension:volume_type_encryption:delete
volume_extension:volume_type_encryption:update
volume_extension:volume_type_encryption:get

for the corresponding create, delete, update, and
get volume_type_encryption test cases.

Depends-On: Iba58e785df934d1c4175c0877d266193ac0167b7

Change-Id: Ie5159166505d9bee3e99ca0d51949f6391c569b9
",git fetch https://review.opendev.org/openstack/patrole refs/changes/58/572158/26 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/volume/test_encryption_types_rbac.py'],1,85ca7d31e72b14ef5e640d1bf735de044399231e,policy-granularity," rule=""volume_extension:volume_type_encryption_create"") rule=""volume_extension:volume_type_encryption_delete"") rule=""volume_extension:volume_type_encryption_update"")"," rule=""volume_extension:volume_type_encryption"") rule=""volume_extension:volume_type_encryption"") rule=""volume_extension:volume_type_encryption"")",3,3
openstack%2Fopenstack-ansible-galera_server~stable%2Fqueens~Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,openstack/openstack-ansible-galera_server,stable/queens,Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,Enable the xinetd service for reboot,MERGED,2018-09-27 15:21:08.000000000,2018-09-27 22:14:26.000000000,2018-09-27 22:14:26.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:21:08.000000000', 'files': ['tasks/galera_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/3938048f62176671724a203a0178e0638c837368', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinetd service should be\nstarted. Otherwise the haproxy health check will fail and haproxy will\nnot forward database connections.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)\n'}]",0,605777,3938048f62176671724a203a0178e0638c837368,7,3,1,19298,,,0,"Enable the xinetd service for reboot

If the Galera container is rebooted, the xinetd service should be
started. Otherwise the haproxy health check will fail and haproxy will
not forward database connections.

Change-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d
(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/77/605777/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_post_install.yml', 'handlers/main.yml']",2,3938048f62176671724a203a0178e0638c837368,enable_xinetd-stable/queens, enabled: true,,10,0
openstack%2Fironic~master~I1ce941a16f080fce1699d8629a7e12a2c2d83ade,openstack/ironic,master,I1ce941a16f080fce1699d8629a7e12a2c2d83ade,Update docs to portgroup with creating windows images,MERGED,2018-07-25 03:35:05.000000000,2018-09-27 22:12:56.000000000,2018-09-27 22:12:55.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 13689}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 18320}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 25254}, {'_account_id': 28950}]","[{'number': 1, 'created': '2018-07-25 03:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c2dd773be84c171c2ab600e8b685f54c14ef358a', 'message': 'Update docs to portgroup with creating images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 2, 'created': '2018-07-26 08:19:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5b50cde70d01d1e6c6121111ea630c077a217d78', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 3, 'created': '2018-08-09 04:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/90592e339a62c182cc21b8c4d63dffb1aa3d1984', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 4, 'created': '2018-08-10 16:10:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bf77628660c47225e54a52acf026561a2204ef5e', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 5, 'created': '2018-08-23 07:06:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ba2e8b2a337a9dc6956e02b61c83b2ea656f7c49', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 6, 'created': '2018-09-06 09:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9b6fbfea207002bb2a0a232ced9def7f779ada85', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 7, 'created': '2018-09-07 08:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8a72c9f1e2ab030014ae80e65990597149e0d8a3', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}, {'number': 8, 'created': '2018-09-24 04:11:14.000000000', 'files': ['doc/source/admin/index.rst', 'tools/link_aggregation_on_windows.ps1', 'doc/source/admin/portgroups.rst', 'doc/source/admin/building-windows-images.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/edd0ff7f460776eb7be22f5d693597f03b01c39e', 'message': 'Update docs to portgroup with creating windows images\n\nThis change will add how to create windows images article\nin portgroup docs. these images will support to create port\nbounding through ironic services.\n\nThis feature has tested on Fujitsu servers successfully.\n\nChange-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade\n'}]",69,585613,edd0ff7f460776eb7be22f5d693597f03b01c39e,56,12,8,25254,,,0,"Update docs to portgroup with creating windows images

This change will add how to create windows images article
in portgroup docs. these images will support to create port
bounding through ironic services.

This feature has tested on Fujitsu servers successfully.

Change-Id: I1ce941a16f080fce1699d8629a7e12a2c2d83ade
",git fetch https://review.opendev.org/openstack/ironic refs/changes/13/585613/8 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/portgroups.rst'],1,c2dd773be84c171c2ab600e8b685f54c14ef358a,update_portgroup_docs,"Image Creation -------------- We use ``New-WindowsOnlineImage`` in ``windows-openstack-imaging-tools`` tool to create windows images (whole disk images) corresponding boot modes. In this scenario, we have a workflow as following items: Requirements: ~~~~~~~~~~~~~ * A windows server (WS) OS along with ``Hyper-V virtualization`` enabled, ``PowerShell`` version >=4 supported, ``windows assessment`` and ``deployment kit`` (ADK) items. * The windows compatible drivers, if required by the target environment. * Git environment in WS OS. Preparation: ~~~~~~~~~~~~ * Download A WS 2012R2/ 2016 installation ISO * Implement WS 2012R2/ 2016 OS on workstation PC along with following feature: - Enable Hyper-V virtualization. - Install PowerShell 4.0. - Install Git environment & import git proxy (if have). - Create new ``Path`` in WS OS which support for submodule update via ``git submodule update init`` command:: - Variable name: Path - Variable value: C:\Windows\System32\WindowsPowerShell\v1.0\;C:\Program Files\Git\bin - Rename virtual switch name in WS 2012R2/ 2016 in ``Virtual Switch Manager`` into `external` Implementation: ~~~~~~~~~~~~~~~ * ``Step 1``: Create folders: `C:\images`, `C:\drivers`. * ``Step 2``: Copy and extract driver in `C:\drivers`. * ``Step 3``: Insert or burn WS 2016 ISO to `D:\ `. * ``Step 4``: Download ``windows-openstack-imaging-tools`` tools. .. code-block:: bash git clone https://github.com/cloudbase/windows-openstack-imaging-tools.git * ``Step 5``: Create & running script `create-windows-cloud-image.ps1`: .. code-block:: bash git submodule update --init Import-Module WinImageBuilder.psm1 $windowsImagePath = ""C:\images\windows-ironic.qcow2"" $VirtIOISOPath = ""C:\images\virtio.iso"" $virtIODownloadLink = ""https://fedorapeople.org/groups/virt/virtio-win/direct-downloads/archive-virtio/virtio-win-0.1.133-2/virtio-win.iso"" (New-Object System.Net.WebClient).DownloadFile($virtIODownloadLink, $VirtIOISOPath) $wimFilePath = ""D:\sources\install.wim"" $extraDriversPath = ""C:\drivers\"" $image = (Get-WimFileImagesInfo -WimFilePath $wimFilePath)[1] $switchName = 'external' New-WindowsOnlineImage -WimFilePath $wimFilePath -ImageName $image.ImageName ` -WindowsImagePath $windowsImagePath -Type 'KVM' -ExtraFeatures @() ` -SizeBytes 20GB -CpuCores 2 -Memory 2GB -SwitchName $switchName ` -ProductKey $productKey -DiskLayout 'BIOS' ` -ExtraDriversPath $extraDriversPath ` -InstallUpdates:$false -AdministratorPassword 'Pa$$w0rd' ` -PurgeUpdates:$true -DisableSwap:$true .. note:: * We can change ``SizeBytes``, ``CpuCores`` and ``Memory`` depends on requirements. ",,73,0
openstack%2Fironic~master~Ida25b71ce4848db8355a7d133cdfcc4f00604d1e,openstack/ironic,master,Ida25b71ce4848db8355a7d133cdfcc4f00604d1e,Correct headings in README.rst,MERGED,2018-09-27 11:53:06.000000000,2018-09-27 22:11:29.000000000,2018-09-27 19:07:53.000000000,"[{'_account_id': 11655}, {'_account_id': 14208}, {'_account_id': 14826}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 11:53:06.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8f2d7587b04de93f22b9dfbb2846c6188f8251ad', 'message': 'Correct headings in README.rst\n\nCurrently it\'s titled ""Team and repository tags"", which is obviously\nnot the project name. Also the top-level title is duplicated twice.\n\nChange-Id: Ida25b71ce4848db8355a7d133cdfcc4f00604d1e\n'}]",1,605657,8f2d7587b04de93f22b9dfbb2846c6188f8251ad,10,5,1,10239,,,0,"Correct headings in README.rst

Currently it's titled ""Team and repository tags"", which is obviously
not the project name. Also the top-level title is duplicated twice.

Change-Id: Ida25b71ce4848db8355a7d133cdfcc4f00604d1e
",git fetch https://review.opendev.org/openstack/ironic refs/changes/57/605657/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8f2d7587b04de93f22b9dfbb2846c6188f8251ad,readme,====== Ironic ====== ------------------------Overview --------,================================================.. Change things from this point on ====== Ironic ======,7,7
openstack%2Fopenstack-ansible-galera_server~stable%2Focata~Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,openstack/openstack-ansible-galera_server,stable/ocata,Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,Enable the xinetd service for reboot,MERGED,2018-09-27 15:21:21.000000000,2018-09-27 22:07:39.000000000,2018-09-27 22:07:39.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:21:21.000000000', 'files': ['tasks/galera_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/dc3b8090713c31abc9a087ee1336b69ca475d363', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinetd service should be\nstarted. Otherwise the haproxy health check will fail and haproxy will\nnot forward database connections.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)\n'}]",0,605779,dc3b8090713c31abc9a087ee1336b69ca475d363,7,3,1,19298,,,0,"Enable the xinetd service for reboot

If the Galera container is rebooted, the xinetd service should be
started. Otherwise the haproxy health check will fail and haproxy will
not forward database connections.

Change-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d
(cherry picked from commit 9fee5107c24880c8365cc2c1905a804cb86ee770)
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/79/605779/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/galera_post_install.yml', 'handlers/main.yml']",2,dc3b8090713c31abc9a087ee1336b69ca475d363,enable_xinetd-stable/ocata, enabled: true,,10,0
openstack%2Fneutron-tempest-plugin~master~Ibd8c56c33dc36d3c3264039369bc185714cc3ebc,openstack/neutron-tempest-plugin,master,Ibd8c56c33dc36d3c3264039369bc185714cc3ebc,DNM: release note job test,ABANDONED,2018-09-13 19:34:44.000000000,2018-09-27 21:52:54.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-13 19:34:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/3376ffb841560b69b6e9c2c884ec39ca2b10f4e8', 'message': 'DNM: release note job test\n\nChange-Id: Ibd8c56c33dc36d3c3264039369bc185714cc3ebc\n'}, {'number': 2, 'created': '2018-09-13 20:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/8b2e556403e2b26cf5d7f9109e8e7ef9b7e5fa19', 'message': 'DNM: release note job test\n\nChange-Id: Ibd8c56c33dc36d3c3264039369bc185714cc3ebc\n'}, {'number': 3, 'created': '2018-09-13 20:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/7ab071f55633ef0b32780361b4ae06725053f31c', 'message': 'DNM: release note job test\n\nChange-Id: Ibd8c56c33dc36d3c3264039369bc185714cc3ebc\n'}, {'number': 4, 'created': '2018-09-13 21:00:51.000000000', 'files': ['releasenotes/notes/fake-relnote-1234.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/3cd0c7302f7b5704b151aa8ce3fce2180cfc0eef', 'message': 'DNM: release note job test\n\nChange-Id: Ibd8c56c33dc36d3c3264039369bc185714cc3ebc\n'}]",0,602427,3cd0c7302f7b5704b151aa8ce3fce2180cfc0eef,9,1,4,1131,,,0,"DNM: release note job test

Change-Id: Ibd8c56c33dc36d3c3264039369bc185714cc3ebc
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/27/602427/4 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/fake-relnote-1234.yaml'],1,3376ffb841560b69b6e9c2c884ec39ca2b10f4e8,test-releaesnote,--- features: - | Add new fake release note. ,,4,0
openstack%2Fneutron-vpnaas~master~Ib31a825cc101647ad6213bd5d7b144359074630a,openstack/neutron-vpnaas,master,Ib31a825cc101647ad6213bd5d7b144359074630a,Use SHA384 as the default auth algorithm.,ABANDONED,2017-03-07 18:20:50.000000000,2018-09-27 21:46:44.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 1131}, {'_account_id': 1528}, {'_account_id': 6854}, {'_account_id': 15905}]","[{'number': 1, 'created': '2017-03-07 18:20:50.000000000', 'files': ['rally-jobs/rally-configs/rally_config_non_dvr.yaml', 'neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'rally-jobs/plugins/vpn_base.py', 'rally-jobs/rally-configs/rally_config_dvr.yaml', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_db.py', 'neutron_vpnaas/tests/functional/common/test_scenario.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/tests/unit/extensions/test_vpnaas.py', 'neutron_vpnaas/tests/tempest/api/test_vpnaas.py'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/fb6dd2ff8166f33da55eddacc2f303513af48306', 'message': 'Use SHA384 as the default auth algorithm.\n\nSHA1 is weak, and should not be used if\npossible.\n\nhttps://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html\n\nChange-Id: Ib31a825cc101647ad6213bd5d7b144359074630a\n'}]",0,442661,fb6dd2ff8166f33da55eddacc2f303513af48306,16,6,1,1131,,,0,"Use SHA384 as the default auth algorithm.

SHA1 is weak, and should not be used if
possible.

https://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html

Change-Id: Ib31a825cc101647ad6213bd5d7b144359074630a
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/61/442661/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_vpnaas/tests/functional/strongswan/test_strongswan_driver.py', 'rally-jobs/rally-configs/rally_config_non_dvr.yaml', 'neutron_vpnaas/tests/unit/services/vpn/device_drivers/test_ipsec.py', 'rally-jobs/plugins/vpn_base.py', 'rally-jobs/rally-configs/rally_config_dvr.yaml', 'neutron_vpnaas/tests/unit/db/vpn/test_vpn_db.py', 'neutron_vpnaas/tests/functional/common/test_scenario.py', 'neutron_vpnaas/extensions/vpnaas.py', 'neutron_vpnaas/tests/unit/extensions/test_vpnaas.py', 'neutron_vpnaas/tests/tempest/api/test_vpnaas.py']",10,fb6dd2ff8166f33da55eddacc2f303513af48306,sha1," auth_algorithm=""sha384"", auth_algorithm=""sha384"")) 'auth_algorithm': 'sha384'}"," auth_algorithm=""sha1"", auth_algorithm=""sha1"")) 'auth_algorithm': 'sha1'}",45,45
openstack%2Fpython-neutronclient~master~I2ef08ee0eba135746e18d8f43821cc3de1308079,openstack/python-neutronclient,master,I2ef08ee0eba135746e18d8f43821cc3de1308079,Use SHA384 as the default auth algorithm.,ABANDONED,2017-03-07 18:21:21.000000000,2018-09-27 21:46:33.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 7018}, {'_account_id': 7787}]","[{'number': 1, 'created': '2017-03-07 18:21:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5414b4b26b7f4a2a6b8f2641c72c28c4bad96687', 'message': 'Use SHA384 as the default auth algorithm.\n\nSHA1 is weak, and should not be used if\npossible.\n\nhttps://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html\n\nChange-Id: I2ef08ee0eba135746e18d8f43821cc3de1308079\n'}, {'number': 2, 'created': '2017-03-09 23:35:41.000000000', 'files': ['neutronclient/neutron/v2_0/vpn/utils.py', 'neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ikepolicy.py'], 'web_link': 'https://opendev.org/openstack/python-neutronclient/commit/5ec754e5412f2c42b19d426c35607ceb86d93107', 'message': 'Use SHA384 as the default auth algorithm.\n\nSHA1 is weak, and should not be used if\npossible.\n\nhttps://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html\n\nChange-Id: I2ef08ee0eba135746e18d8f43821cc3de1308079\n'}]",3,442662,5ec754e5412f2c42b19d426c35607ceb86d93107,18,6,2,1131,,,0,"Use SHA384 as the default auth algorithm.

SHA1 is weak, and should not be used if
possible.

https://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html

Change-Id: I2ef08ee0eba135746e18d8f43821cc3de1308079
",git fetch https://review.opendev.org/openstack/python-neutronclient refs/changes/62/442662/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutronclient/tests/unit/vpn/test_cli20_ikepolicy.py', 'neutronclient/tests/unit/vpn/test_cli20_ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ipsecpolicy.py', 'neutronclient/neutron/v2_0/vpn/ikepolicy.py']",4,5414b4b26b7f4a2a6b8f2641c72c28c4bad96687,sha1," default='sha384' if is_create else argparse.SUPPRESS, help=_('Authentication algorithm, default:sha384.'))"," default='sha1' if is_create else argparse.SUPPRESS, help=_('Authentication algorithm, default:sha1.'))",10,10
openstack%2Fneutron-dynamic-routing~stable%2Fqueens~I7569557c8215329efc71de1051b01c6f9cd89d3a,openstack/neutron-dynamic-routing,stable/queens,I7569557c8215329efc71de1051b01c6f9cd89d3a,import zuul job settings from project-config,MERGED,2018-08-30 00:09:04.000000000,2018-09-27 21:41:02.000000000,2018-09-27 21:41:01.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-30 00:09:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/da32515a8b5aa4029837ea85a8dbe9bb348b32d1', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I7569557c8215329efc71de1051b01c6f9cd89d3a\nStory: #2002586\nTask: #24314\n'}, {'number': 2, 'created': '2018-09-22 10:59:38.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/bd5b57786ad526f52de4b00b1f187da62c4d8bbf', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I7569557c8215329efc71de1051b01c6f9cd89d3a\nStory: #2002586\nTask: #24314\n'}]",0,597942,bd5b57786ad526f52de4b00b1f187da62c4d8bbf,14,6,2,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I7569557c8215329efc71de1051b01c6f9cd89d3a
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/42/597942/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,da32515a8b5aa4029837ea85a8dbe9bb348b32d1,python3-first, templates: - check-requirements - openstack-python-jobs-neutron - openstack-python35-jobs-neutron - publish-openstack-sphinx-docs - release-notes-jobs - legacy-periodic-neutron-dynamic-routing-dsvm-tempest-with-ryu-master-scenario-ipv4 post: jobs: - openstack-tox-cover: required-projects: - openstack/neutron, name: openstack/neutron-dynamic-routing,12,1
openstack%2Fneutron-dynamic-routing~stable%2Focata~I3d83a084b2f867cd0eaf9c651d768d5fa26c14d9,openstack/neutron-dynamic-routing,stable/ocata,I3d83a084b2f867cd0eaf9c651d768d5fa26c14d9,import zuul job settings from project-config,MERGED,2018-08-30 00:07:19.000000000,2018-09-27 21:38:15.000000000,2018-09-27 21:38:15.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 6547}, {'_account_id': 6854}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-30 00:07:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/54e08b941b07fc6747f7eedf5699c6789781a086', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I3d83a084b2f867cd0eaf9c651d768d5fa26c14d9\nStory: #2002586\nTask: #24314\n'}, {'number': 2, 'created': '2018-09-22 11:01:48.000000000', 'files': ['tools/tox_install.sh', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/0949eeae20a18dcd89fda335df9bea3abf3ce26f', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nAlso, fix tools/tox_install.sh to work with changed\nbuild-openstack-sphinx-docs job.\n\nChange-Id: I3d83a084b2f867cd0eaf9c651d768d5fa26c14d9\nStory: #2002586\nTask: #24314\n'}]",0,597915,0949eeae20a18dcd89fda335df9bea3abf3ce26f,13,6,2,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Also, fix tools/tox_install.sh to work with changed
build-openstack-sphinx-docs job.

Change-Id: I3d83a084b2f867cd0eaf9c651d768d5fa26c14d9
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/15/597915/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,54e08b941b07fc6747f7eedf5699c6789781a086,python3-first, templates: - check-requirements - openstack-python-jobs-neutron - openstack-python35-jobs-neutron - publish-openstack-sphinx-docs - release-notes-jobs - legacy-periodic-neutron-dynamic-routing-dsvm-tempest-with-ryu-master-scenario-ipv4 post: jobs: - openstack-tox-cover: required-projects: - openstack/neutron,,12,0
openstack%2Fswift~master~I5a18df7b13de0db1f8d68ed145709e1b286f0f34,openstack/swift,master,I5a18df7b13de0db1f8d68ed145709e1b286f0f34,WIP: Implement S3 v2 formpost,NEW,2018-07-04 11:51:33.000000000,2018-09-27 21:30:40.000000000,,"[{'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 28111}]","[{'number': 1, 'created': '2018-07-04 11:51:33.000000000', 'files': ['swift/common/middleware/s3api/schema/post_response.rng', 'doc/s3api/rnc/post_response.rnc', 'swift/common/middleware/s3api/s3request.py', 'swift/common/middleware/s3api/utils.py', 'swift/common/middleware/s3api/s3formpost.py', 'test/unit/common/middleware/s3api/test_s3formpost.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/92c6598c005a2af645872c767d25b8973f867715', 'message': 'WIP: Implement S3 v2 formpost\n\nSimilar to formpost middleware, s3formpost middleware translates\nS3 POST requests to S3 PUT requests. But in s3formpost,\nwe make a not pre-auth subrequest with S3 auth info rather than\na pre-auth one. We also check form fields against policies.\n\nTODO:\n1.Add docs\n2.Check S3 max value length\n3.Consider buckets as host in a domain name\n4.Add form fields: Cache-Control, Content-Type,\nContent-Disposition, Content-Encoding, Expires\n5.Check query of subresources:\ndelete, partNumber, uploadId, restores\n6.Check validation of redirect url\n7.Reconsider and design code process of\n_validate_conditions and _format_condition\n\nChange-Id: I5a18df7b13de0db1f8d68ed145709e1b286f0f34\n'}]",0,580144,92c6598c005a2af645872c767d25b8973f867715,4,3,1,28111,,,0,"WIP: Implement S3 v2 formpost

Similar to formpost middleware, s3formpost middleware translates
S3 POST requests to S3 PUT requests. But in s3formpost,
we make a not pre-auth subrequest with S3 auth info rather than
a pre-auth one. We also check form fields against policies.

TODO:
1.Add docs
2.Check S3 max value length
3.Consider buckets as host in a domain name
4.Add form fields: Cache-Control, Content-Type,
Content-Disposition, Content-Encoding, Expires
5.Check query of subresources:
delete, partNumber, uploadId, restores
6.Check validation of redirect url
7.Reconsider and design code process of
_validate_conditions and _format_condition

Change-Id: I5a18df7b13de0db1f8d68ed145709e1b286f0f34
",git fetch https://review.opendev.org/openstack/swift refs/changes/44/580144/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/s3api/schema/post_response.rng', 'doc/s3api/rnc/post_response.rnc', 'swift/common/middleware/s3api/s3request.py', 'swift/common/middleware/s3api/utils.py', 'swift/common/middleware/s3api/s3formpost.py', 'test/unit/common/middleware/s3api/test_s3formpost.py']",6,92c6598c005a2af645872c767d25b8973f867715,s3-formpost,"# Copyright (c) 2010-2018 OpenStack Foundation. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or # implied. # See the License for the specific language governing permissions and # limitations under the License. import base64 import copy import six from six import BytesIO from six.moves.urllib.parse import quote import json import time import unittest from swift.common import swob from swift.common.swob import Request from test.unit.common.middleware.s3api import S3ApiTestCase from swift.common.middleware.s3api import s3formpost from swift.common.middleware.s3api.etree import fromstring from swift.common.middleware.s3api.utils import S3Timestamp BOUNDARY = '----WebKitFormBoundaryNcxTqxSlX7t4TDkR' class TestCappedFileLikeObject(unittest.TestCase): def test_whole(self): self.assertEqual( s3formpost._CappedFileLikeObject(BytesIO(b'abc'), 1, 5).read(), b'abc') def test_exceeded(self): exc = None try: s3formpost._CappedFileLikeObject(BytesIO(b'abcdef'), 1, 5).read() except EOFError as err: exc = err self.assertEqual(str(exc), 'max_file_size exceeded') def test_whole_readline(self): fp = s3formpost._CappedFileLikeObject(BytesIO(b'abc\ndef'), 1, 10) self.assertEqual(fp.readline(), b'abc\n') self.assertEqual(fp.readline(), b'def') self.assertEqual(fp.readline(), b'') def test_exceeded_readline(self): fp = s3formpost._CappedFileLikeObject(BytesIO(b'abc\ndef'), 1, 5) self.assertEqual(fp.readline(), b'abc\n') exc = None try: self.assertEqual(fp.readline(), b'def') except EOFError as err: exc = err self.assertEqual(str(exc), 'max_file_size exceeded') def test_read_sized(self): fp = s3formpost._CappedFileLikeObject(BytesIO(b'abcdefg'), 1, 10) self.assertEqual(fp.read(2), b'ab') self.assertEqual(fp.read(2), b'cd') self.assertEqual(fp.read(2), b'ef') self.assertEqual(fp.read(2), b'g') self.assertEqual(fp.read(2), b'') class TestS3FormPost(S3ApiTestCase): def setUp(self): super(TestS3FormPost, self).setUp() self.s3formpost = s3formpost.filter_factory({})(self.s3api) self.swift.register('PUT', '/v1/AUTH_test/bucket/object', swob.HTTPCreated, {'etag': 'etag'}, None) def _get_future_expiration(self, expire=86400): return S3Timestamp(time.time() + expire).isoformat + 'Z' def _get_req_body(self, attributes, policy, content): attributes = copy.deepcopy(attributes) policy = copy.deepcopy(policy) content = copy.deepcopy(content) if policy: if isinstance(policy, dict): policy = base64.b64encode(json.dumps(policy)) attributes.append(('policy', policy)) body = [] for name, value in attributes: body.extend([ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""%s""' % name, '', str(value) ]) if isinstance(content, list): for i, _content in enumerate(content): body.extend([ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""file%s""' % (i + 1), 'Content-Type: application/octet-stream', '', str(_content) ]) body.extend([ '--%s--' % BOUNDARY, '', ]) else: body.extend([ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""file1""', 'Content-Type: application/octet-stream', '', str(content), '--%s--' % BOUNDARY, '', ]) return body def _make_req(self, attributes=None, policy=None, content=None, body=None, bucket='bucket', path=None, user_agent=True): path = path or '/%s' % bucket if not body: body = self._get_req_body(attributes, policy, content) wsgi_input = '\r\n'.join(body) if six.PY3: wsgi_input = wsgi_input.encode('utf-8') wsgi_input = BytesIO(wsgi_input) wsgi_errors = six.StringIO() env = { 'CONTENT_TYPE': 'multipart/form-data; ' 'boundary=%s' % BOUNDARY, 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_ACCEPT_LANGUAGE': 'en-us', 'HTTP_ACCEPT': 'text/html,application/xhtml+xml,application/xml;' 'q=0.9,*/*;q=0.8', 'HTTP_CONNECTION': 'keep-alive', 'HTTP_HOST': 'ubuntu:8080', 'HTTP_ORIGIN': 'file://', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X ' '10_7_2) AppleWebKit/534.52.7 (KHTML, like Gecko) ' 'Version/5.1.2 Safari/534.52.7', 'PATH_INFO': path, 'REMOTE_ADDR': '172.16.83.1', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': '172.16.83.128', 'SERVER_PORT': '8080', 'SERVER_PROTOCOL': 'HTTP/1.0', 'swift.infocache': {}, 'wsgi.errors': wsgi_errors, 'wsgi.multiprocess': False, 'wsgi.multithread': True, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0), 'wsgi.input': wsgi_input, 'swift.trans_id': 'transid' } if user_agent is False: del env['HTTP_USER_AGENT'] return Request.blank(path, environ=env) def test_safari(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' path = '/bucket' wsgi_input = '\r\n'.join([ '------WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'Content-Disposition: form-data; name=""policy""', '', str(policy), '------WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'Content-Disposition: form-data; name=""signature""', '', str(signature), '------WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'Content-Disposition: form-data; name=""key""', '', str(key), '------WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '------WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'Content-Disposition: form-data; name=""file""; ' 'filename=""testfile1.txt""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '------WebKitFormBoundaryNcxTqxSlX7t4TDkR--', '', ]) if six.PY3: wsgi_input = wsgi_input.encode('utf-8') wsgi_input = BytesIO(wsgi_input) wsgi_errors = six.StringIO() env = { 'CONTENT_TYPE': 'multipart/form-data; ' 'boundary=----WebKitFormBoundaryNcxTqxSlX7t4TDkR', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_ACCEPT_LANGUAGE': 'en-us', 'HTTP_ACCEPT': 'text/html,application/xhtml+xml,application/xml;' 'q=0.9,*/*;q=0.8', 'HTTP_CONNECTION': 'keep-alive', 'HTTP_HOST': 'ubuntu:8080', 'HTTP_ORIGIN': 'file://', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X ' '10_7_2) AppleWebKit/534.52.7 (KHTML, like Gecko) ' 'Version/5.1.2 Safari/534.52.7', 'PATH_INFO': path, 'REMOTE_ADDR': '172.16.83.1', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': '172.16.83.128', 'SERVER_PORT': '8080', 'SERVER_PROTOCOL': 'HTTP/1.0', 'wsgi.errors': wsgi_errors, 'wsgi.input': wsgi_input, 'wsgi.multiprocess': False, 'wsgi.multithread': True, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0), 'swift.trans_id': 'transid' } req = Request.blank(path, environ=env) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_firefox(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' path = '/bucket' wsgi_input = '\r\n'.join([ '-----------------------------168072824752491622650073', 'Content-Disposition: form-data; name=""policy""', '', str(policy), '-----------------------------168072824752491622650073', 'Content-Disposition: form-data; name=""signature""', '', str(signature), '-----------------------------168072824752491622650073', 'Content-Disposition: form-data; name=""key""', '', str(key), '-----------------------------168072824752491622650073', 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '-----------------------------168072824752491622650073', 'Content-Disposition: form-data; name=""file""; ' 'filename=""testfile1.txt""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '-----------------------------168072824752491622650073--', '', ]) if six.PY3: wsgi_input = wsgi_input.encode('utf-8') wsgi_input = BytesIO(wsgi_input) wsgi_errors = six.StringIO() env = { 'CONTENT_TYPE': 'multipart/form-data; ' 'boundary=---------------------------168072824752491622650073', 'HTTP_ACCEPT_CHARSET': 'ISO-8859-1,utf-8;q=0.7,*;q=0.7', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_ACCEPT_LANGUAGE': 'en-us,en;q=0.5', 'HTTP_ACCEPT': 'text/html,application/xhtml+xml,application/xml;' 'q=0.9,*/*;q=0.8', 'HTTP_CONNECTION': 'keep-alive', 'HTTP_HOST': 'ubuntu:8080', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.7; ' 'rv:8.0.1) Gecko/20100101 Firefox/8.0.1', 'PATH_INFO': path, 'REMOTE_ADDR': '172.16.83.1', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': '172.16.83.128', 'SERVER_PORT': '8080', 'SERVER_PROTOCOL': 'HTTP/1.0', 'wsgi.errors': wsgi_errors, 'wsgi.input': wsgi_input, 'wsgi.multiprocess': False, 'wsgi.multithread': True, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0), 'swift.trans_id': 'transid' } req = Request.blank(path, environ=env) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_chrome(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' path = '/bucket' wsgi_input = '\r\n'.join([ '------WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'Content-Disposition: form-data; name=""policy""', '', str(policy), '------WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'Content-Disposition: form-data; name=""signature""', '', str(signature), '------WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'Content-Disposition: form-data; name=""key""', '', str(key), '------WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '------WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'Content-Disposition: form-data; name=""file""; ' 'filename=""testfile1.txt""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '------WebKitFormBoundaryq3CFxUjfsDMu8XsA--', '', ]) if six.PY3: wsgi_input = wsgi_input.encode('utf-8') wsgi_input = BytesIO(wsgi_input) wsgi_errors = six.StringIO() env = { 'CONTENT_TYPE': 'multipart/form-data; ' 'boundary=----WebKitFormBoundaryq3CFxUjfsDMu8XsA', 'HTTP_ACCEPT_CHARSET': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3', 'HTTP_ACCEPT_ENCODING': 'gzip,deflate,sdch', 'HTTP_ACCEPT_LANGUAGE': 'en-US,en;q=0.8', 'HTTP_ACCEPT': 'text/html,application/xhtml+xml,application/xml;' 'q=0.9,*/*;q=0.8', 'HTTP_CACHE_CONTROL': 'max-age=0', 'HTTP_CONNECTION': 'keep-alive', 'HTTP_HOST': 'ubuntu:8080', 'HTTP_ORIGIN': 'null', 'HTTP_USER_AGENT': 'Mozilla/5.0 (Macintosh; Intel Mac OS X ' '10_7_2) AppleWebKit/535.7 (KHTML, like Gecko) ' 'Chrome/16.0.912.63 Safari/535.7', 'PATH_INFO': path, 'REMOTE_ADDR': '172.16.83.1', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': '172.16.83.128', 'SERVER_PORT': '8080', 'SERVER_PROTOCOL': 'HTTP/1.0', 'wsgi.errors': wsgi_errors, 'wsgi.input': wsgi_input, 'wsgi.multiprocess': False, 'wsgi.multithread': True, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0), 'swift.trans_id': 'transid' } req = Request.blank(path, environ=env) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_explorer(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' path = '/bucket' wsgi_input = '\r\n'.join([ '-----------------------------7db20d93017c', 'Content-Disposition: form-data; name=""policy""', '', str(policy), '-----------------------------7db20d93017c', 'Content-Disposition: form-data; name=""signature""', '', str(signature), '-----------------------------7db20d93017c', 'Content-Disposition: form-data; name=""key""', '', str(key), '-----------------------------7db20d93017c', 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '-----------------------------7db20d93017c', 'Content-Disposition: form-data; name=""file""; ' 'filename=""C:\\testfile1.txt""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '-----------------------------7db20d93017c--', '', ]) if six.PY3: wsgi_input = wsgi_input.encode('utf-8') wsgi_input = BytesIO(wsgi_input) wsgi_errors = six.StringIO() env = { 'CONTENT_TYPE': 'multipart/form-data; ' 'boundary=---------------------------7db20d93017c', 'HTTP_ACCEPT_ENCODING': 'gzip, deflate', 'HTTP_ACCEPT_LANGUAGE': 'en-US', 'HTTP_ACCEPT': 'text/html, application/xhtml+xml, */*', 'HTTP_CACHE_CONTROL': 'no-cache', 'HTTP_CONNECTION': 'Keep-Alive', 'HTTP_HOST': '172.16.83.128:8080', 'HTTP_USER_AGENT': 'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT ' '6.1; WOW64; Trident/5.0)', 'PATH_INFO': path, 'REMOTE_ADDR': '172.16.83.129', 'REQUEST_METHOD': 'POST', 'SCRIPT_NAME': '', 'SERVER_NAME': '172.16.83.128', 'SERVER_PORT': '8080', 'SERVER_PROTOCOL': 'HTTP/1.0', 'wsgi.errors': wsgi_errors, 'wsgi.input': wsgi_input, 'wsgi.multiprocess': False, 'wsgi.multithread': True, 'wsgi.run_once': False, 'wsgi.url_scheme': 'http', 'wsgi.version': (1, 0), 'swift.trans_id': 'transid' } req = Request.blank(path, environ=env) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_policy_old_expiration(self): policy = { ""expiration"": ""1984-07-01T00:00:00Z"", ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(self._get_error_code(body), 'AccessDenied') self.assertEqual( self._get_error_message(body), 'Invalid according to Policy: Policy expired.') def test_policy_invalid_expiration(self): expiration = ""Wed, 27 Jun 2018 03:37:11 GMT"" policy = { ""expiration"": expiration, ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(self._get_error_code(body), 'InvalidPolicyDocument') self.assertEqual( self._get_error_message(body), ""Invalid Policy: Invalid 'expiration' value: '%s'"" % expiration) def test_policy_no_expiration(self): policy = { ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(self._get_error_code(body), 'InvalidPolicyDocument') self.assertEqual( self._get_error_message(body), ""Invalid Policy: Policy missing expiration."") def test_policy_bucket_matched(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ '', [""starts-with"", ""$key"", """"] ] } match_cases = [ {""bucket"": ""bucket""}, [""starts-with"", ""$bucket"", """"], [""starts-with"", ""$bucket"", ""buck""] ] location = 'http://ubuntu:8080/bucket/object' for case in match_cases: policy['conditions'][0] = case attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester')] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '204 No Content') self.assertEqual(headers['Etag'], '""etag""') self.assertEqual(headers['Location'], location) def test_policy_bucket_not_matched(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ '', [""starts-with"", ""$key"", """"] ] } not_match_cases = [ {""bucket"": ""nothing""}, [""starts-with"", ""$bucket"", ""nothing""]] for case in not_match_cases: policy['conditions'][0] = case attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) if type(case) is dict: case = [""eq"", ""$"" + case.keys()[0], case.values()[0]] self.assertEqual(status, '403 Forbidden') self.assertEqual(self._get_error_code(body), 'AccessDenied') self.assertEqual( self._get_error_message(body), 'Invalid according to Policy: Policy Condition failed: %s' % json.dumps(case)) def test_policy_content_length_range(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""content-length-range"", 5, '10'], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] # matched content = 'abcdef' location = 'http://ubuntu:8080/bucket/object' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '204 No Content') self.assertEqual(headers['Etag'], '""etag""') self.assertEqual(headers['Location'], location) # too small content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') self.assertEqual(self._get_error_code(body), 'EntityTooSmall') self.assertEqual( self._get_error_message(body), 'Your proposed upload is smaller than the minimum allowed size') # too large content = 'abc' * 4 req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') self.assertEqual(self._get_error_code(body), 'EntityTooLarge') self.assertEqual( self._get_error_message(body), 'Your proposed upload exceeds the maximum allowed size') def test_policy_bad_content_length_range(self): # string policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""content-length-range"", 'abc', 10], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abcdef' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') self.assertEqual(self._get_error_code(body), 'AccessDenied') self.assertEqual( self._get_error_message(body), 'Invalid according to Policy: Policy Condition failed: %s' % json.dumps(policy['conditions'][2])) # float policy['conditions'][2] = [""content-length-range"", 3.2, 10] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') self.assertEqual(self._get_error_code(body), 'InvalidPolicyDocument') self.assertEqual( self._get_error_message(body), 'Invalid Policy: Invalid JSON.') def test_redirect(self): content = 'abc' location = 'http://ubuntu:8080/bucket/object' etag = '""etag""' redirect = 'http://openstack.com' redirect2 = 'http://test.com' redirect_with_query = 'http://test.com?one=two' # no redirect policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '204 No Content') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], location) self.assertTrue('Content-Length' not in headers) # success_action_redirect policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_redirect"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_redirect', redirect), ] redirect_url = '%s?bucket=bucket&key=object&etag=%s' %\ (redirect, quote(etag)) content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '303 See Other') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], redirect_url) self.assertEqual(headers['Content-Length'], '0') # both success_action_redirect and redirect policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$redirect"", """"], [""starts-with"", ""$success_action_redirect"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_redirect', redirect2), ('redirect', redirect), ] redirect_url = '%s?bucket=bucket&key=object&etag=%s' % \ (redirect2, quote(etag)) req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '303 See Other') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], redirect_url) self.assertEqual(headers['Content-Length'], '0') # both success_action_redirect and success_action_status policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_redirect"", """"], [""eq"", ""$success_action_status"", 201] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_redirect', redirect), ('success_action_status', 201) ] redirect_url = '%s?bucket=bucket&key=object&etag=%s' % \ (redirect, quote(etag)) req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '303 See Other') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], redirect_url) self.assertEqual(headers['Content-Length'], '0') # success_action_redirect and mismatch success_action_status policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_redirect"", """"], [""starts-with"", ""$success_action_status"", ""20""] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_redirect', redirect), ('success_action_status', 'nothing') ] redirect_url = '%s?bucket=bucket&key=object&etag=%s' % \ (redirect, quote(etag)) req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, ""Invalid according to Policy: Policy Condition failed: %s"" % json.dumps([""starts-with"", ""$success_action_status"", ""20""])) # redirect with query policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_redirect"", """"] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_redirect', redirect_with_query), ] redirect_url = '%s&bucket=bucket&key=object&etag=%s' %\ (redirect_with_query, quote(etag)) content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '303 See Other') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], redirect_url) self.assertEqual(headers['Content-Length'], '0') def test_success_action_status(self): success_action_status = ['200', '204', '404', 'nothing'] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_status"", """"], ] } for action_status in success_action_status: attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_status', action_status), ] content = 'abc' location = 'http://ubuntu:8080/bucket/object' req = self._make_req(attributes, policy, content) resp_status, headers, body = self.call_app(req, self.s3formpost) if action_status == '200': status_str = '200 OK' else: status_str = '204 No Content' self.assertEqual(resp_status, status_str) self.assertEqual(body, '') self.assertEqual(headers['Etag'], '""etag""') self.assertEqual(headers['Location'], location) def test_success_action_status_201(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], {""success_action_status"": 201}, ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_status', '201'), ] content = 'abc' location = 'http://ubuntu:8080/bucket/object' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '201 Created') self.assertEqual(headers['Etag'], '""etag""') self.assertEqual(headers['Location'], location) elem = fromstring(body, 'PostResponse') self.assertEqual(elem.find('./Location').text, location) self.assertEqual(elem.find('./Bucket').text, 'bucket') self.assertEqual(elem.find('./Key').text, 'object') self.assertEqual(elem.find('./ETag').text, '""etag""') def test_redirect_and_success_action_status(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$success_action_status"", """"], [""starts-with"", ""$success_action_redirect"", """"], ] } redirect = 'http://openstack.com' etag = '""etag""' attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('success_action_status', '201'), ('success_action_redirect', redirect), ] redirect_url = '%s?bucket=bucket&key=object&etag=%s' % \ (redirect, quote(etag)) content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '303 See Other') self.assertEqual(body, '') self.assertEqual(headers['Etag'], etag) self.assertEqual(headers['Location'], redirect_url) def test_service_path(self): # POST / policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content, path='/') status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '405 Method Not Allowed') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'MethodNotAllowed') self.assertEqual( elem.find('./Message').text, 'The specified method is not allowed against this resource.') self.assertEqual(elem.find('./ResourceType').text, 'SERVICE') def test_object_path(self): # POST /bucket/object policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req( attributes, policy, content, path='/bucket/object') status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '405 Method Not Allowed') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'MethodNotAllowed') self.assertEqual( elem.find('./Message').text, 'The specified method is not allowed against this resource.') self.assertEqual(elem.find('./ResourceType').text, 'OBJECT') def test_missing_fields(self): # no key policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ] } attributes = [ ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'key'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'key') self.assertIsNone(elem.find('./ArgumentValue').text) # no policy policy = {} attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'policy'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'policy') self.assertIsNone(elem.find('./ArgumentValue').text) # no AWSAccesssKeyId policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'AWSAccessKeyId'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'AWSAccessKeyId') self.assertIsNone(elem.find('./ArgumentValue').text) # no Signature policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ] } attributes = [ ('key', 'object'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'signature'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text.lower(), 'signature') self.assertIsNone(elem.find('./ArgumentValue').text) # no AWSAccesssKeyId and Signature policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ] } attributes = [ ('key', 'object'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual(elem.find('./Message').text, ""Access Denied"") # no AWSAccesssKeyId and policy policy = {} attributes = [ ('key', 'object'), ('signature', 'hmac'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'AWSAccessKeyId'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'AWSAccessKeyId') self.assertIsNone(elem.find('./ArgumentValue').text) # no policy and Signature policy = {} attributes = [ ('key', 'object'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'policy'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'policy') self.assertIsNone(elem.find('./ArgumentValue').text) # no AWSAccesssKeyId and Signature and policy policy = {} attributes = [ ('key', 'object'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual(elem.find('./Message').text, ""Access Denied"") # nothing policy = {} attributes = [ ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, ""Bucket POST must contain a field named 'key'. "" ""If it is specified, please check the order of the fields."") self.assertEqual(elem.find('./ArgumentName').text, 'key') self.assertIsNone(elem.find('./ArgumentValue').text) def _test_extra_fields(self): # TODO # Content-MD5 # Others not in form field list # https://docs.aws.amazon.com/AmazonS3/latest/dev/HTTPPOSTForms.html#HTTPPOSTFormFields pass def test_missing_conditions(self): # key policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, ""Invalid according to Policy: Extra input fields: key"") # bucket policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ [""starts-with"", ""$key"", """"], ] } req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, ""Invalid according to Policy: Extra input fields: bucket"") # x-ignore policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('x-ignore-test', 'nothing'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '204 No Content') attrs = [ ('acl', 'private'), ('x-amz-meta-test', 'nothing'), ('Expires', 'Thu, 01 Dec 1994 16:00:00 GMT'), ('success_action_redirect', 'http://openstack.org'), ('success_action_status', '201'), ] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), '' ] for attr in attrs: attributes[3] = attr req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, ""Invalid according to Policy: Extra input fields: %s"" % attr[0]) def test_extra_conditions(self): conditions = [ ['starts-with', '$AWSAccessKeyId', ''], ['starts-with', '$AWSAccessKeyId', 'test'], ['eq', '$AWSAccessKeyId', 'test:tester'], ['starts-with', '$signature', ''], ['starts-with', '$policy', ''], ['starts-with', '$file', ''], ['starts-with', '$x-ignore-test', ''], ] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ['starts-with', '$key', ''], ['starts-with', '$AWSAccessKeyId', ''] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' for condition in conditions: policy['conditions'][2] = condition req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, ""Invalid according to Policy: Policy Condition failed: %s"" % json.dumps(policy['conditions'][2])) def test_simple_condition_too_many_property(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket"", ""key"": ""object""}, ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: Invalid Simple-Condition: Simple-Conditions "" ""must have exactly one property specified."") def test_simple_condition_empty(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, {}, ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: Invalid Simple-Condition: Simple-Conditions "" ""must have exactly one property specified."") def test_list_condition_empty(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, {""key"": ""object""}, [] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: Invalid Condition: missing operation identifier."") def test_condition_unknown_operation(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ['nothing', '$key', ''] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: Invalid Condition: unknown operation 'nothing'."") def test_condition_wrong_number_of_args(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, ['starts-with', '$key', 'nothing', ''] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: Invalid starts-with: wrong number of arguments."") def test_list_condition_invalid_field_name(self): invalid_cases = [ ['starts-with', 123, ''], ['starts-with', '', ''], ['starts-with', '$', ''], ['starts-with', 'key', ''], ] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' for case in invalid_cases: policy['conditions'][1] = case req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, 'Invalid according to Policy: Policy Condition failed: %s' % json.dumps(case)) def test_list_condition_invalid_value(self): invalid_cases = [ ['starts-with', '$key', 123], ['starts-with', '$key', {}], ] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' for case in invalid_cases: policy['conditions'][1] = case req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '403 Forbidden') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'AccessDenied') self.assertEqual( elem.find('./Message').text, 'Invalid according to Policy: Policy Condition failed: %s' % json.dumps(case)) def test_invalid_condition_type(self): invalid_cases = [ ""abc"", 123 ] policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [] ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = 'abc' for case in invalid_cases: policy['conditions'][1] = case req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, 'Invalid Policy: Invalid condition test: ' 'must be a List or Object.') def test_invalid_file_count(self): # no file policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = [] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) elem = fromstring(body, 'Error') self.assertEqual(status, '400 Bad Request') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, 'POST requires exactly one file upload per request.') self.assertEqual(elem.find('./ArgumentName').text, 'file') self.assertEqual(elem.find('./ArgumentValue').text, '0') # more than 1 file content = ['abc', 'def'] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) elem = fromstring(body, 'Error') self.assertEqual(status, '400 Bad Request') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, 'POST requires exactly one file upload per request.') self.assertEqual(elem.find('./ArgumentName').text, 'file') self.assertEqual(elem.find('./ArgumentValue').text, '2') # 1st file not match content-length-range policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""content-length-range"", 5, '10'], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = ['abc', 'abcdef'] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') self.assertEqual(self._get_error_code(body), 'EntityTooSmall') self.assertEqual( self._get_error_message(body), 'Your proposed upload is smaller than the minimum allowed size') # 2th file not match content-length-range policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""content-length-range"", 5, '10'], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] content = ['abcdef', 'abc'] req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) elem = fromstring(body, 'Error') self.assertEqual(status, '400 Bad Request') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, 'POST requires exactly one file upload per request.') self.assertEqual(elem.find('./ArgumentName').text, 'file') self.assertEqual(elem.find('./ArgumentValue').text, '2') def test_set_invalid_acl(self): policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$acl"", """"], [""starts-with"", ""$x-amz-meta-test"", """"], ] } attributes = [ ('key', 'object2'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ('x-amz-meta-test', 'nothing'), ('acl', 'nothing'), ] content = 'abc' req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) elem = fromstring(body, 'Error') self.assertEqual(status, '400 Bad Request') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual(elem.find('./ArgumentName').text, 'x-amz-acl') self.assertEqual(elem.find('./ArgumentValue').text, 'nothing') def test_query(self): content = 'abc' policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] queries = [ ('acl', None), ('uploads', None), ('abc', None), ('test', 'nothing')] for param, val in queries: if val is None: query = param else: query = '%s=%s' % (param, val) req = self._make_req(attributes, policy, content) req.query_string = query status, headers, body = self.call_app(req, self.s3formpost) self.assertTrue(status.startswith('4')) elem = fromstring(body, 'Error') self.assertIn( elem.find('./Code').text, ['InvalidRequest', 'MethodNotAllowed', 'InvalidArgument']) def test_put_subrequest_fails(self): fail_cases = [ (swob.HTTPNotFound, '404 Not Found', 'NoSuchBucket'), (swob.HTTPUnprocessableEntity, '400 Bad Request', 'BadDigest'), (swob.HTTPLengthRequired, '411 Length Required', 'MissingContentLength'), (swob.HTTPRequestTimeout, '400 Bad Request', 'RequestTimeout'), (swob.HTTPRequestEntityTooLarge, '400 Bad Request', 'EntityTooLarge'), (swob.HTTPUnauthorized, '403 Forbidden', 'SignatureDoesNotMatch'), (swob.HTTPForbidden, '403 Forbidden', 'AccessDenied'), (swob.HTTPBadRequest, '500 Internal Server Error', 'InternalError'), ] content = 'abc' policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ['key', ''], ['signature', 'hmac'], ['AWSAccessKeyId', 'test:tester'], ] for i, (resp_class, status_str, error_code) in enumerate(fail_cases): obj = 'nothing%s' % i self.swift.register('PUT', '/v1/AUTH_test/bucket/%s' % obj, resp_class, {}, None) attributes[0][1] = obj req = self._make_req(attributes, policy, content) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, status_str) elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, error_code) def test_without_useragent(self): content = 'abc' policy = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], ] } attributes = [ ('key', 'object'), ('signature', 'hmac'), ('AWSAccessKeyId', 'test:tester'), ] req = self._make_req(attributes, policy, content) req.user_agent = '' self.call_app(req, self.s3formpost) headers = dict(self.swift.calls_with_headers[0][-1]) self.assertEqual(headers.get('User-Agent'), 'S3FormPost') def test_body_field_attribute_filename_empty(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' body = [ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""policy""', '', str(policy), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""signature""', '', str(signature), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""key""', '', str(key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '--%s--' % BOUNDARY, '', ] req = self._make_req(body=body) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_body_field_attribute_name_empty(self): policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' body = [ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""policy""', '', str(policy), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""signature""', '', str(signature), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""key""', '', str(key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""""; ' 'filename=""test_file""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '--%s--' % BOUNDARY, '', ] req = self._make_req(body=body) status, headers, body = self.call_app(req, self.s3formpost) elem = fromstring(body, 'Error') self.assertEqual(status, '400 Bad Request') self.assertEqual(elem.find('./Code').text, 'InvalidArgument') self.assertEqual( elem.find('./Message').text, 'POST requires exactly one file upload per request.') self.assertEqual(elem.find('./ArgumentName').text, 'file') self.assertEqual(elem.find('./ArgumentValue').text, '0') def test_truncated_attr_value(self): meta = 'a' * s3formpost.MAX_VALUE_LENGTH meta += 'b' policy_document = { ""expiration"": self._get_future_expiration(), ""conditions"": [ {""bucket"": ""bucket""}, [""starts-with"", ""$key"", """"], [""starts-with"", ""$x-amz-meta-test"", """"] ] } access_key = 'test:tester' policy = base64.b64encode(json.dumps(policy_document)) signature = 'hmac' key = 'object' body = [ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""policy""', '', str(policy), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""signature""', '', str(signature), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""key""', '', str(key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""x-amz-meta-test""', '', str(meta), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""test_file""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '--%s--' % BOUNDARY, '', ] req = self._make_req(body=body) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status.split()[0], '204') def test_invalid_policy_cannot_decode(self): access_key = 'test:tester' policy = 'abc' # invalid encoded signature = 'hmac' key = 'object' body = [ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""policy""', '', str(policy), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""signature""', '', str(signature), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""key""', '', str(key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""test_file""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '--%s--' % BOUNDARY, '', ] req = self._make_req(body=body) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: invalid Base64 encoding."") def test_invalid_policy_not_json(self): access_key = 'test:tester' policy = base64.b64encode('abc') signature = 'hmac' key = 'object' body = [ '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""policy""', '', str(policy), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""signature""', '', str(signature), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""key""', '', str(key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""AWSAccessKeyId""', '', str(access_key), '--%s' % BOUNDARY, 'Content-Disposition: form-data; name=""file""; ' 'filename=""test_file""', 'Content-Type: text/plain', '', 'Test File\nOne\n', '--%s--' % BOUNDARY, '', ] req = self._make_req(body=body) status, headers, body = self.call_app(req, self.s3formpost) self.assertEqual(status, '400 Bad Request') elem = fromstring(body, 'Error') self.assertEqual(elem.find('./Code').text, 'InvalidPolicyDocument') self.assertEqual( elem.find('./Message').text, ""Invalid Policy: invalid Base64 encoding."") ",,2532,4
openstack%2Fironic~master~I4e0b4e8a45d60980ed0bd1ced20e63d067331bb8,openstack/ironic,master,I4e0b4e8a45d60980ed0bd1ced20e63d067331bb8,Test nova virt driver behavior logging test,ABANDONED,2018-07-22 15:15:38.000000000,2018-09-27 21:01:10.000000000,,"[{'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-22 15:15:38.000000000', 'files': ['ironic/common/context.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/31f925b3172e30551ea20379a6e2572fe3fc1f08', 'message': 'Test nova virt driver behavior logging test\n\nChange-Id: I4e0b4e8a45d60980ed0bd1ced20e63d067331bb8\nDepends-On: https://review.openstack.org/#/c/584645/\n'}]",0,584646,31f925b3172e30551ea20379a6e2572fe3fc1f08,5,3,1,11655,,,0,"Test nova virt driver behavior logging test

Change-Id: I4e0b4e8a45d60980ed0bd1ced20e63d067331bb8
Depends-On: https://review.openstack.org/#/c/584645/
",git fetch https://review.opendev.org/openstack/ironic refs/changes/46/584646/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/common/context.py'],1,31f925b3172e30551ea20379a6e2572fe3fc1f08,bug/1634635, without authentication., without authentication.,1,1
openstack%2Fironic-python-agent~master~I6c997576f7ffe00fe660ad51213e70369b325e0b,openstack/ironic-python-agent,master,I6c997576f7ffe00fe660ad51213e70369b325e0b,Correct headings in README.rst,MERGED,2018-09-27 12:01:06.000000000,2018-09-27 20:44:14.000000000,2018-09-27 20:44:14.000000000,"[{'_account_id': 11655}, {'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:01:06.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/8f700c4cefcd50a6e891d05de99d832fc4b31968', 'message': 'Correct headings in README.rst\n\nCurrently it\'s titled ""Team and repository tags"", which is obviously\nnot the project name. Also the top-level title is duplicated twice.\n\nAlso remove the link to wiki that contains no helpful information.\n\nChange-Id: I6c997576f7ffe00fe660ad51213e70369b325e0b\n'}]",0,605660,8f700c4cefcd50a6e891d05de99d832fc4b31968,7,3,1,10239,,,0,"Correct headings in README.rst

Currently it's titled ""Team and repository tags"", which is obviously
not the project name. Also the top-level title is duplicated twice.

Also remove the link to wiki that contains no helpful information.

Change-Id: I6c997576f7ffe00fe660ad51213e70369b325e0b
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/60/605660/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8f700c4cefcd50a6e891d05de99d832fc4b31968,readme,=================== Ironic Python Agent =================== Overview ========,========================.. Change things from this point on ironic-python-agent ===================Additional resources are linked from the project wiki page: https://wiki.openstack.org/wiki/Ironic-python-agent ,7,9
openstack%2Fopenstack-zuul-jobs~master~Ib040c032ad49beb5e2041e92efe41ce4e8b98799,openstack/openstack-zuul-jobs,master,Ib040c032ad49beb5e2041e92efe41ce4e8b98799,Add zuul envar for kata tests,MERGED,2018-09-27 15:09:09.000000000,2018-09-27 20:39:29.000000000,2018-09-27 20:39:29.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 10068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 15:09:09.000000000', 'files': ['roles/kata-setup/tasks/main.yaml', 'playbooks/kata-runsh/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/6d01e66ff03b93c5bf47703ce8ceb053c3ef8b8a', 'message': 'Add zuul envar for kata tests\n\nIn order to know we are running under a zuul slave,\nwe need to add an environment variable. In this case\nit is ZUUL=true. This will allow the kata-containers\nscripts to run the tests with the appropiate flags.\n\nChange-Id: Ib040c032ad49beb5e2041e92efe41ce4e8b98799\nSigned-off-by: Salvador Fuentes <salvador.fuentes@intel.com>\n'}]",0,605773,6d01e66ff03b93c5bf47703ce8ceb053c3ef8b8a,8,4,1,28489,,,0,"Add zuul envar for kata tests

In order to know we are running under a zuul slave,
we need to add an environment variable. In this case
it is ZUUL=true. This will allow the kata-containers
scripts to run the tests with the appropiate flags.

Change-Id: Ib040c032ad49beb5e2041e92efe41ce4e8b98799
Signed-off-by: Salvador Fuentes <salvador.fuentes@intel.com>
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/73/605773/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/kata-setup/tasks/main.yaml', 'playbooks/kata-runsh/run.yaml']",2,6d01e66ff03b93c5bf47703ce8ceb053c3ef8b8a,topic/add-zuulci-envar, export ZUUL=true,,2,0
openstack%2Fpuppet-designate~master~I2f5cc06d68cfcf399f1a64a3b63533bddce1a217,openstack/puppet-designate,master,I2f5cc06d68cfcf399f1a64a3b63533bddce1a217,"Revert ""Add ability to configure rndc controls""",ABANDONED,2018-08-24 19:28:05.000000000,2018-09-27 20:31:33.000000000,,"[{'_account_id': 3153}, {'_account_id': 6928}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 24245}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-08-24 19:28:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/2cca0d10ade17d17d77fc8d5cdd6249350d2164a', 'message': 'Revert ""Add ability to configure rndc controls""\n\nThis reverts commit df4991fbe2c9f7e5b457ae8ed0f6e401fc4e9c1d.\n\nChange-Id: I2f5cc06d68cfcf399f1a64a3b63533bddce1a217\n'}, {'number': 2, 'created': '2018-08-24 19:28:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/56939d3c5383e6f7ba102d9eaa7ba295478a1171', 'message': 'Revert ""Add ability to configure rndc controls""\n\nThis reverts commit df4991fbe2c9f7e5b457ae8ed0f6e401fc4e9c1d.\n\nRelated-Bug: #1788907\nChange-Id: I2f5cc06d68cfcf399f1a64a3b63533bddce1a217\n'}, {'number': 3, 'created': '2018-08-25 22:20:33.000000000', 'files': ['manifests/backend/bind9.pp'], 'web_link': 'https://opendev.org/openstack/puppet-designate/commit/b3990197b2c6e1f63494e9f7c06e2618c0a5bddd', 'message': 'Revert ""Add ability to configure rndc controls""\n\nThis reverts commit df4991fbe2c9f7e5b457ae8ed0f6e401fc4e9c1d.\n\nRelated-Bug: #1788907\nChange-Id: I2f5cc06d68cfcf399f1a64a3b63533bddce1a217\n'}]",0,596436,b3990197b2c6e1f63494e9f7c06e2618c0a5bddd,8,6,3,9592,,,0,"Revert ""Add ability to configure rndc controls""

This reverts commit df4991fbe2c9f7e5b457ae8ed0f6e401fc4e9c1d.

Related-Bug: #1788907
Change-Id: I2f5cc06d68cfcf399f1a64a3b63533bddce1a217
",git fetch https://review.opendev.org/openstack/puppet-designate refs/changes/36/596436/2 && git format-patch -1 --stdout FETCH_HEAD,['manifests/backend/bind9.pp'],1,2cca0d10ade17d17d77fc8d5cdd6249350d2164a,rndc-controls, include ::dns,"# [*rndc_controls*] # (optional) Hash defining controls configuration for rndc. # Defaults to undef, which uses the puppet-dns default # $rndc_controls = undef, if $rndc_controls { class { '::dns': controls => $rndc_controls, } } else { include ::dns }",1,12
openstack%2Ftripleo-quickstart~master~I86dd7118418956e3d986cd7805ae7e9f04e2ea61,openstack/tripleo-quickstart,master,I86dd7118418956e3d986cd7805ae7e9f04e2ea61,use the yaml stdout callback,ABANDONED,2018-09-20 19:36:16.000000000,2018-09-27 20:13:33.000000000,,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-09-20 19:36:16.000000000', 'files': ['ansible.cfg'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/1ed51cd1389b3f87cf39b899da2d06c4edc57cb0', 'message': 'use the yaml stdout callback\n\nJSON is for computers\nYAML is for humans\nhttps://docs.ansible.com/ansible/2.5/plugins/callback/yaml.html\n\nChange-Id: I86dd7118418956e3d986cd7805ae7e9f04e2ea61\n'}]",5,604194,1ed51cd1389b3f87cf39b899da2d06c4edc57cb0,18,12,1,9592,,,0,"use the yaml stdout callback

JSON is for computers
YAML is for humans
https://docs.ansible.com/ansible/2.5/plugins/callback/yaml.html

Change-Id: I86dd7118418956e3d986cd7805ae7e9f04e2ea61
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/94/604194/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible.cfg'],1,1ed51cd1389b3f87cf39b899da2d06c4edc57cb0,ansible-debug,stdout_callback = yaml,,1,0
openstack%2Fpython-ironicclient~master~Ica22437497cd66c45c2439c02e747b3debc13378,openstack/python-ironicclient,master,Ica22437497cd66c45c2439c02e747b3debc13378,fix typo,MERGED,2018-08-21 07:02:08.000000000,2018-09-27 20:09:24.000000000,2018-09-27 20:09:24.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-21 07:02:08.000000000', 'files': ['releasenotes/notes/osc-plugin-ff0d897d8441a9e1.yaml'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/ece9c83d2661127ec13f95f684326de585dd1976', 'message': 'fix typo\n\nChange-Id: Ica22437497cd66c45c2439c02e747b3debc13378\n'}]",0,594046,ece9c83d2661127ec13f95f684326de585dd1976,6,2,1,26285,,,0,"fix typo

Change-Id: Ica22437497cd66c45c2439c02e747b3debc13378
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/46/594046/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/osc-plugin-ff0d897d8441a9e1.yaml'],1,ece9c83d2661127ec13f95f684326de585dd1976,, * openstack baremetal node maintenance unset, * opnestack baremetal node maintenance unset,1,1
openstack%2Fneutron-vpnaas-dashboard~stable%2Fpike~I4d9b6fd204da691cef2188af2fda04923e8335bb,openstack/neutron-vpnaas-dashboard,stable/pike,I4d9b6fd204da691cef2188af2fda04923e8335bb,Modify the 'tox.ini' file,ABANDONED,2018-07-08 11:50:41.000000000,2018-09-27 20:05:07.000000000,,"[{'_account_id': 841}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 25254}]","[{'number': 1, 'created': '2018-07-08 11:50:41.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas-dashboard/commit/31539dbc1e3dd298ecf6ae8d21c6aed3f0a5bb09', 'message': ""Modify the 'tox.ini' file\n\nSince the horizon remove the 'run_tests.sh' file,\nso there should remove '.venv' from the '.tox.ini' file.\n\nChange-Id: I4d9b6fd204da691cef2188af2fda04923e8335bb\n""}]",0,580841,31539dbc1e3dd298ecf6ae8d21c6aed3f0a5bb09,10,5,1,14151,,,0,"Modify the 'tox.ini' file

Since the horizon remove the 'run_tests.sh' file,
so there should remove '.venv' from the '.tox.ini' file.

Change-Id: I4d9b6fd204da691cef2188af2fda04923e8335bb
",git fetch https://review.opendev.org/openstack/neutron-vpnaas-dashboard refs/changes/41/580841/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,31539dbc1e3dd298ecf6ae8d21c6aed3f0a5bb09,,"exclude = .git,.tox,dist,*lib/python*,*egg,build,node_modules,.tmp","exclude = .venv,.git,.tox,dist,*lib/python*,*egg,build,node_modules,.tmp",1,1
openstack%2Fkeystone-specs~master~Ib02bd11b3604c366db873c0f74d739dd04d322e2,openstack/keystone-specs,master,Ib02bd11b3604c366db873c0f74d739dd04d322e2,Fix broken link to Stein roadmap,MERGED,2018-09-27 14:44:38.000000000,2018-09-27 20:03:51.000000000,2018-09-27 20:03:51.000000000,"[{'_account_id': 8482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 14:44:38.000000000', 'files': ['doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/keystone-specs/commit/7a65d06a6ae9ff655b6eac0bddc76721f4b8e856', 'message': ""Fix broken link to Stein roadmap\n\nThe link to the Stein roadmap was populated before we actually went\nthrough the schedule for Stein. We actually used a copy of a previous\nroadmap to build the Stein roadmap, making it easier to manage carry\nover items. As a result, the original link isn't useful and was\nabandoned.\n\nThis commit updates the link to point to the correct roadmap.\n\nChange-Id: Ib02bd11b3604c366db873c0f74d739dd04d322e2\n""}]",0,605761,7a65d06a6ae9ff655b6eac0bddc76721f4b8e856,6,2,1,5046,,,0,"Fix broken link to Stein roadmap

The link to the Stein roadmap was populated before we actually went
through the schedule for Stein. We actually used a copy of a previous
roadmap to build the Stein roadmap, making it easier to manage carry
over items. As a result, the original link isn't useful and was
abandoned.

This commit updates the link to point to the correct roadmap.

Change-Id: Ib02bd11b3604c366db873c0f74d739dd04d322e2
",git fetch https://review.opendev.org/openstack/keystone-specs refs/changes/61/605761/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/index.rst'],1,7a65d06a6ae9ff655b6eac0bddc76721f4b8e856,,`Stein Roadmap <https://trello.com/b/rj0ECz2c/keystone-stein-roadmap>`_,`Stein Roadmap <https://trello.com/b/YX9ceRRn/keystone-stein-roadmap>`_,1,1
openstack%2Fpython-ironicclient~stable%2Fqueens~I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8,openstack/python-ironicclient,stable/queens,I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8,Add support for RESCUE and UNRESCUE provision states,ABANDONED,2018-09-14 12:09:18.000000000,2018-09-27 19:57:54.000000000,,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 13295}, {'_account_id': 22348}, {'_account_id': 27418}]","[{'number': 1, 'created': '2018-09-14 12:09:18.000000000', 'files': ['ironicclient/v1/node.py', 'ironicclient/common/http.py', 'ironicclient/tests/unit/v1/test_node.py', 'ironicclient/v1/utils.py', 'releasenotes/notes/add-rescue-unrescue-support-f78266514ca59346.yaml', 'setup.cfg', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'ironicclient/osc/v1/baremetal_node.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/5898c2b2d2eba8cea48f631b4631cf88a27c132b', 'message': 'Add support for RESCUE and UNRESCUE provision states\n\nBackport support for rescue and unrescue to OSC in stable/queens\nbranch\n\nCo-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>\nCo-Authored-By: Dao Cong Tien <tiendc@vn.fujitsu.com>\n\nChange-Id: I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8\nPartial-bug: 1526449\n'}]",0,602601,5898c2b2d2eba8cea48f631b4631cf88a27c132b,6,6,1,27418,,,0,"Add support for RESCUE and UNRESCUE provision states

Backport support for rescue and unrescue to OSC in stable/queens
branch

Co-Authored-By: Michael Turek <mjturek@linux.vnet.ibm.com>
Co-Authored-By: Dao Cong Tien <tiendc@vn.fujitsu.com>

Change-Id: I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8
Partial-bug: 1526449
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/01/602601/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node.py', 'ironicclient/common/http.py', 'ironicclient/tests/unit/v1/test_node.py', 'ironicclient/v1/utils.py', 'releasenotes/notes/add-rescue-unrescue-support-f78266514ca59346.yaml', 'setup.cfg', 'ironicclient/osc/v1/baremetal_node.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py']",8,5898c2b2d2eba8cea48f631b4631cf88a27c132b,bug/1526449," 'node_uuid', 'adopt', cleansteps=None, configdrive=None, rescuepassword=None) cleansteps=None, configdrive='path/to/drive', rescuepassword=None)class TestRescueBaremetalProvisionState(TestBaremetal): def setUp(self): super(TestRescueBaremetalProvisionState, self).setUp() # Get the command object to test self.cmd = baremetal_node.RescueBaremetalNode(self.app, None) def test_rescue_baremetal_no_wait(self): arglist = ['node_uuid', '--rescue-password', 'supersecret'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'rescue'), ('rescue_password', 'supersecret'), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) self.baremetal_mock.node.set_provision_state.assert_called_once_with( 'node_uuid', 'rescue', cleansteps=None, configdrive=None, rescuepassword='supersecret') def test_rescue_baremetal_provision_state_rescue_and_wait(self): arglist = ['node_uuid', '--wait', '15', '--rescue-password', 'supersecret'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'rescue'), ('rescue_password', 'supersecret'), ('wait_timeout', 15) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) test_node = self.baremetal_mock.node test_node.wait_for_provision_state.assert_called_once_with( 'node_uuid', expected_state='rescue', poll_interval=10, timeout=15) def test_rescue_baremetal_provision_state_default_wait(self): arglist = ['node_uuid', '--wait', '--rescue-password', 'supersecret'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'rescue'), ('rescue_password', 'supersecret'), ('wait_timeout', 0) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) test_node = self.baremetal_mock.node test_node.wait_for_provision_state.assert_called_once_with( 'node_uuid', expected_state='rescue', poll_interval=10, timeout=0) def test_rescue_baremetal_no_rescue_password(self): arglist = ['node_uuid'] verifylist = [('node', 'node_uuid'), ('provision_state', 'rescue')] self.assertRaises(oscutils.ParserException, self.check_parser, self.cmd, arglist, verifylist) cleansteps=None, configdrive='path/to/drive', rescuepassword=None) cleansteps=None, configdrive=None, rescuepassword=None)class TestUnrescueBaremetalProvisionState(TestBaremetal): def setUp(self): super(TestUnrescueBaremetalProvisionState, self).setUp() # Get the command object to test self.cmd = baremetal_node.UnrescueBaremetalNode(self.app, None) def test_unrescue_no_wait(self): arglist = ['node_uuid'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'unrescue'), ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) self.baremetal_mock.node.set_provision_state.assert_called_once_with( 'node_uuid', 'unrescue', cleansteps=None, configdrive=None, rescuepassword=None) def test_unrescue_baremetal_provision_state_active_and_wait(self): arglist = ['node_uuid', '--wait', '15'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'unrescue'), ('wait_timeout', 15) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) test_node = self.baremetal_mock.node test_node.wait_for_provision_state.assert_called_once_with( 'node_uuid', expected_state='active', poll_interval=10, timeout=15) def test_unrescue_baremetal_provision_state_default_wait(self): arglist = ['node_uuid', '--wait'] verifylist = [ ('node', 'node_uuid'), ('provision_state', 'unrescue'), ('wait_timeout', 0) ] parsed_args = self.check_parser(self.cmd, arglist, verifylist) self.cmd.take_action(parsed_args) test_node = self.baremetal_mock.node test_node.wait_for_provision_state.assert_called_once_with( 'node_uuid', expected_state='active', poll_interval=10, timeout=0) "," 'node_uuid', 'adopt', cleansteps=None, configdrive=None) cleansteps=None, configdrive='path/to/drive') cleansteps=None, configdrive='path/to/drive') cleansteps=None, configdrive=None)",204,8
openstack%2Fpython-ironicclient~stable%2Fqueens~I1d3e64c94d09d824dc84d5bd0ffe74aed84e9e13,openstack/python-ironicclient,stable/queens,I1d3e64c94d09d824dc84d5bd0ffe74aed84e9e13,Add rescue_interface to node and driver,ABANDONED,2018-09-14 12:29:58.000000000,2018-09-27 19:57:15.000000000,,"[{'_account_id': 10239}, {'_account_id': 11076}, {'_account_id': 11297}, {'_account_id': 18320}, {'_account_id': 22348}, {'_account_id': 27418}]","[{'number': 1, 'created': '2018-09-14 12:29:58.000000000', 'files': ['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/v1/node.py', 'releasenotes/notes/add-rescue-interface-to-node-and-driver-e3ff9b5df2628e5a.yaml', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_driver_shell.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_driver.py', 'ironicclient/v1/resource_fields.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py', 'ironicclient/osc/v1/baremetal_node.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/f85317f7a286218c9f542a87b128dca8d9b0b66e', 'message': 'Add rescue_interface to node and driver\n\nBackport support for rescue_interface to the commands below to\nstable/queenc branch:\n\n * openstack baremetal node create\n * openstack baremetal node show\n * openstack baremetal node set\n * openstack baremetal node unset\n * openstack baremetal driver list\n * openstack baremetal driver show\n\nDepends-On: I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8\nChange-Id: I1d3e64c94d09d824dc84d5bd0ffe74aed84e9e13\nPartial-Bug: #1526449\n'}]",0,602605,f85317f7a286218c9f542a87b128dca8d9b0b66e,6,6,1,27418,,,0,"Add rescue_interface to node and driver

Backport support for rescue_interface to the commands below to
stable/queenc branch:

 * openstack baremetal node create
 * openstack baremetal node show
 * openstack baremetal node set
 * openstack baremetal node unset
 * openstack baremetal driver list
 * openstack baremetal driver show

Depends-On: I555e72690d85cfe35b5ad780ecdd8f469cb0ebe8
Change-Id: I1d3e64c94d09d824dc84d5bd0ffe74aed84e9e13
Partial-Bug: #1526449
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/05/602605/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/tests/unit/osc/v1/fakes.py', 'ironicclient/v1/node.py', 'releasenotes/notes/add-rescue-interface-to-node-and-driver-e3ff9b5df2628e5a.yaml', 'ironicclient/tests/unit/v1/test_node_shell.py', 'ironicclient/tests/unit/v1/test_driver_shell.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_driver.py', 'ironicclient/v1/resource_fields.py', 'ironicclient/osc/v1/baremetal_node.py', 'ironicclient/tests/unit/osc/v1/test_baremetal_node.py']",9,f85317f7a286218c9f542a87b128dca8d9b0b66e,bug/1526449," def test_baremetal_create_with_rescue_interface(self): self.check_with_options(['--rescue-interface', 'rescue'], [('rescue_interface', 'rescue')], {'rescue_interface': 'rescue'}) 'Rescue Interface', 'Storage Interface', 'Vendor Interface') '', def test_baremetal_set_rescue_interface(self): self._test_baremetal_set_hardware_interface('rescue') def test_baremetal_unset_rescue_interface(self): self._test_baremetal_unset_hw_interface('rescue') "," 'Storage Interface', 'Vendor Interface')",81,10
openstack%2Fopenstack-ansible-os_ironic~master~I343c542dbb9b3a9fe17c364e827374b3512993f1,openstack/openstack-ansible-os_ironic,master,I343c542dbb9b3a9fe17c364e827374b3512993f1,Retrieve ilo drivers via webserver,MERGED,2017-01-19 23:13:03.000000000,2018-09-27 19:43:29.000000000,2018-09-27 19:43:29.000000000,"[{'_account_id': 7353}, {'_account_id': 10068}, {'_account_id': 14288}, {'_account_id': 17068}, {'_account_id': 21314}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-01-19 23:13:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/91e8a4289c3cf29116c1f76a90306919c412e44d', 'message': ""Retrieve ilo drivers via webserver\n\nThis enables the ability to bypass the ilo driver\ndependency on swift through implementation of support\nfor the 'use_http_web_server_for_images' variable\nand corresponding logic to bypass swift tasks\nwhen enabled\n\nAs per:\nhttps://specs.openstack.org/openstack/ironic-specs/specs/4.2/remove-swift-dependency-for-ilo-drivers.html\n\nChange-Id: I343c542dbb9b3a9fe17c364e827374b3512993f1\n""}, {'number': 2, 'created': '2018-09-12 15:51:02.000000000', 'files': ['templates/ironic.conf.j2', 'tasks/ironic_post_install.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/c8e719cca2e6d15c06a023f34b92229a2b0303ad', 'message': ""Retrieve ilo drivers via webserver\n\nThis enables the ability to bypass the ilo driver\ndependency on swift through implementation of support\nfor the 'use_http_web_server_for_images' variable\nand corresponding logic to bypass swift tasks\nwhen enabled\n\nAs per:\nhttps://specs.openstack.org/openstack/ironic-specs/specs/4.2/remove-swift-dependency-for-ilo-drivers.html\n\nChange-Id: I343c542dbb9b3a9fe17c364e827374b3512993f1\n""}]",0,422908,c8e719cca2e6d15c06a023f34b92229a2b0303ad,17,6,2,24908,,,0,"Retrieve ilo drivers via webserver

This enables the ability to bypass the ilo driver
dependency on swift through implementation of support
for the 'use_http_web_server_for_images' variable
and corresponding logic to bypass swift tasks
when enabled

As per:
https://specs.openstack.org/openstack/ironic-specs/specs/4.2/remove-swift-dependency-for-ilo-drivers.html

Change-Id: I343c542dbb9b3a9fe17c364e827374b3512993f1
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/08/422908/2 && git format-patch -1 --stdout FETCH_HEAD,"['templates/ironic.conf.j2', 'tasks/ironic_post_install.yml', 'defaults/main.yml']",3,91e8a4289c3cf29116c1f76a90306919c412e44d,enable-ironic-boot-media-src-config,"# ### Hosted Web Server # # Set this to True to use http web server to host floppy # images and generated boot ISO. This requires http_root and # http_url to be configured in the [deploy] section of the # config file. If this is set to False, then Ironic will use # Swift to host the floppy images and generated boot_iso. ironic_enable_web_server_for_images: False ironic_http_url: null ironic_http_root: null # ### Swift Config #",,27,1
openstack%2Fmonasca-thresh~master~Icc3c3fd183ced1db55a1236bef2de354f3d0560d,openstack/monasca-thresh,master,Icc3c3fd183ced1db55a1236bef2de354f3d0560d,Includes value_meta in generated alarms,NEW,2018-09-17 09:38:12.000000000,2018-09-27 19:40:15.000000000,,"[{'_account_id': 11809}, {'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 21922}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-17 09:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/087d9e3e9288f5985c3929cbff30760e01932119', 'message': 'Includes the value_meta field of a metric in generated alarms.\nStory: #2001282\n\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\n'}, {'number': 2, 'created': '2018-09-17 10:37:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/ec369c1afdc7d9afccdd6e2cd77b0447b574d752', 'message': 'Includes value_meta in generated alarms\n\nIncludes the value_meta field of metrics in generated alarms\nsuch that notifications as produced by monaca_notification\ncan include them for better descriptive alerts.\n\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\nStory: #2001282\n'}, {'number': 3, 'created': '2018-09-18 10:40:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/56f05d2d88c6b5b763cfea7481e1ff3034733cf9', 'message': 'Includes value_meta in generated alarms\n\nIncludes the value_meta field of metrics in generated alarms\nsuch that notifications as produced by monaca_notification\ncan include them for better descriptive alerts.\n\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\nStory: #2001282\nTask: #26492\n'}, {'number': 4, 'created': '2018-09-18 10:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/4c72e2e6b2a048de38b366c6d36709443823b06d', 'message': 'Includes value_meta in generated alarms\n\nIncludes the value_meta field of metrics in generated alarms\nsuch that notifications as produced by monaca_notification\ncan include them for better descriptive alerts.\n\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\nStory: #2001282\nTask: #26492\n'}, {'number': 5, 'created': '2018-09-24 12:53:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/9be25a2877a0095235e0518f588f7e845d094e4d', 'message': 'Includes value_meta in generated alarms\n\nIncludes the value_meta field of metrics in generated alarms\nsuch that notifications as produced by monaca_notification\ncan include them for better descriptive alerts.\n\nDepends-On: https://review.openstack.org/603099\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\nStory: #2001282\nTask: #26492\n'}, {'number': 6, 'created': '2018-09-24 13:11:27.000000000', 'files': ['thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBolt.java', 'thresh/src/test/java/monasca/thresh/domain/model/SubAlarmStatsTest.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBoltTest.java', 'thresh/src/main/java/monasca/thresh/domain/model/Alarm.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/MetricAggregationBolt.java', 'thresh/src/test/java/monasca/thresh/domain/model/AlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/persistence/AlarmDAOImpl.java', 'thresh/src/main/java/monasca/thresh/domain/service/AlarmDAO.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/MetricAggregationBoltTest.java', 'thresh/src/main/java/monasca/thresh/domain/model/SubAlarmStats.java', 'thresh/src/main/java/monasca/thresh/domain/model/SubAlarm.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineAlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/persistence/hibernate/AlarmSqlImpl.java'], 'web_link': 'https://opendev.org/openstack/monasca-thresh/commit/98b2f0955a2412413603a613880141efa73b9da9', 'message': 'Includes value_meta in generated alarms\n\nIncludes the value_meta field of metrics in generated alarms\nsuch that notifications as produced by monaca_notification\ncan include them for better descriptive alerts.\n\nDepends-On: https://review.openstack.org/603099\nChange-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d\nStory: #2001282\nTask: #26492\n'}]",33,603059,98b2f0955a2412413603a613880141efa73b9da9,23,5,6,28529,,,0,"Includes value_meta in generated alarms

Includes the value_meta field of metrics in generated alarms
such that notifications as produced by monaca_notification
can include them for better descriptive alerts.

Depends-On: https://review.openstack.org/603099
Change-Id: Icc3c3fd183ced1db55a1236bef2de354f3d0560d
Story: #2001282
Task: #26492
",git fetch https://review.opendev.org/openstack/monasca-thresh refs/changes/59/603059/1 && git format-patch -1 --stdout FETCH_HEAD,"['thresh/src/main/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBolt.java', 'thresh/src/test/java/monasca/thresh/domain/model/SubAlarmStatsTest.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/AlarmThresholdingBoltTest.java', 'thresh/src/main/java/monasca/thresh/domain/model/Alarm.java', 'thresh/src/main/java/monasca/thresh/infrastructure/thresholding/MetricAggregationBolt.java', 'thresh/src/test/java/monasca/thresh/domain/model/AlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/persistence/AlarmDAOImpl.java', 'thresh/src/main/java/monasca/thresh/domain/service/AlarmDAO.java', 'thresh/src/test/java/monasca/thresh/infrastructure/thresholding/MetricAggregationBoltTest.java', 'thresh/src/main/java/monasca/thresh/domain/model/SubAlarmStats.java', 'thresh/src/main/java/monasca/thresh/domain/model/SubAlarm.java', 'thresh/src/test/java/monasca/thresh/ThresholdingEngineAlarmTest.java', 'thresh/src/main/java/monasca/thresh/infrastructure/persistence/hibernate/AlarmSqlImpl.java']",13,087d9e3e9288f5985c3929cbff30760e01932119,slack-patch," public void updateSubAlarmState(String subAlarmId, AlarmState subAlarmState, Map<String, String> valueMeta) {"," public void updateSubAlarmState(String subAlarmId, AlarmState subAlarmState) {",248,111
openstack%2Fsahara~master~I95d71bafebd9d0a4fea499813135fac06d152ab6,openstack/sahara,master,I95d71bafebd9d0a4fea499813135fac06d152ab6,adds unit test for ssh_remote.replace_remote_line,MERGED,2018-09-25 14:13:10.000000000,2018-09-27 19:27:17.000000000,2018-09-27 19:27:17.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 14:13:10.000000000', 'files': ['sahara/tests/unit/utils/test_ssh_remote.py'], 'web_link': 'https://opendev.org/openstack/sahara/commit/4e39a45f4584ab2232b68f250be73a515b5bd521', 'message': 'adds unit test for ssh_remote.replace_remote_line\n\nAdding unit test for the new method added to\nsearch a line by string and replace the old line\nwith a new line\n\nChange-Id: I95d71bafebd9d0a4fea499813135fac06d152ab6\nStory: #2003176\nTask: #26708\n'}]",0,605085,4e39a45f4584ab2232b68f250be73a515b5bd521,7,3,1,26181,,,0,"adds unit test for ssh_remote.replace_remote_line

Adding unit test for the new method added to
search a line by string and replace the old line
with a new line

Change-Id: I95d71bafebd9d0a4fea499813135fac06d152ab6
Story: #2003176
Task: #26708
",git fetch https://review.opendev.org/openstack/sahara refs/changes/85/605085/1 && git format-patch -1 --stdout FETCH_HEAD,['sahara/tests/unit/utils/test_ssh_remote.py'],1,4e39a45f4584ab2232b68f250be73a515b5bd521,task-2003176-26708," def test_replace_remote_line(self, p_log_command, p_run_s): description = ('In file ""file"" replacing line begining with string' '""str"" with ""newline""') remote.replace_remote_line(""file"", ""str"", ""newline"") p_run_s.assert_called_once_with(ssh_remote._replace_remote_line, None, description, ""file"", ""str"", ""newline"") p_log_command.assert_called_with(description) @mock.patch('sahara.utils.ssh_remote.InstanceInteropHelper._run_s') @mock.patch('sahara.utils.ssh_remote.InstanceInteropHelper._log_command') def test_execute_on_vm_interactive(self, p_log_command, p_run_s): instance = FakeInstance('inst14', '123', '10.0.0.14', '10.0.0.14', 'user14', 'key14') remote = ssh_remote.InstanceInteropHelper(instance)"," def test_execute_on_vm_interactive(self, p_log_command, p_run_s):",17,1
openstack%2Ftraining-labs~stable%2Frocky~Iee5dea054ed2045bcf695b572d0fd48960439ee4,openstack/training-labs,stable/rocky,Iee5dea054ed2045bcf695b572d0fd48960439ee4,Update .gitreview for stable/rocky,MERGED,2018-09-27 13:45:40.000000000,2018-09-27 18:52:50.000000000,2018-09-27 18:52:50.000000000,"[{'_account_id': 6547}, {'_account_id': 11109}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 13:45:40.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/training-labs/commit/100b6d2ae7d98bc65286d79ff25df118caaa5e18', 'message': 'Update .gitreview for stable/rocky\n\nChange-Id: Iee5dea054ed2045bcf695b572d0fd48960439ee4\n'}]",0,605718,100b6d2ae7d98bc65286d79ff25df118caaa5e18,7,3,1,22816,,,0,"Update .gitreview for stable/rocky

Change-Id: Iee5dea054ed2045bcf695b572d0fd48960439ee4
",git fetch https://review.opendev.org/openstack/training-labs refs/changes/18/605718/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,100b6d2ae7d98bc65286d79ff25df118caaa5e18,create-rocky,defaultbranch=stable/rocky,,1,0
openstack%2Foctavia~master~If4f230dcba8c360c919f6c2d93705bf67089b2cf,openstack/octavia,master,If4f230dcba8c360c919f6c2d93705bf67089b2cf,Update HAProxy version for Centos,MERGED,2018-02-27 23:34:39.000000000,2018-09-27 18:45:34.000000000,2018-06-02 04:30:11.000000000,"[{'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 25564}]","[{'number': 1, 'created': '2018-02-27 23:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fffbb0d0731157ee437a01119514d79e1d502c16', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config -- will this work for 1.7?\nMaybe not? I probably need to figure out how to make this template\nvariable a bit.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 2, 'created': '2018-02-28 08:52:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f06f702b813a5dda19bbc665259da40f9509349f', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config -- will this work for 1.7?\nMaybe not? I probably need to figure out how to make this template\nvariable a bit.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 3, 'created': '2018-02-28 09:02:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d7878f128b3dd65f87cdbff9d1afb9bfdb1bec51', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config -- will this work for 1.7?\nMaybe not? I probably need to figure out how to make this template\nvariable a bit.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 4, 'created': '2018-03-01 09:21:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/2bf93e9361b292949a38dd0a70b1bae13ac4f282', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config -- will this work for 1.7?\nMaybe not? I probably need to figure out how to make this template\nvariable a bit.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 5, 'created': '2018-03-01 11:01:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d77b589c52c67b8ca79f1c811ec859ee4d55e119', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config -- will this work for 1.7?\nMaybe not? I probably need to figure out how to make this template\nvariable a bit.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 6, 'created': '2018-03-01 23:57:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/5bca63651da2e9fb9c9f08e422257af45bc36809', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 7, 'created': '2018-03-02 01:20:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4c49c3ad25b52f1d5e16dcf58a05016d82722a63', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 8, 'created': '2018-03-14 15:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/57e6d96835a3208d830657e5eb86b108549fe158', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 9, 'created': '2018-03-27 05:48:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fc87376f80d398eeff3ae96f7aef3f6eb8b791b2', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 10, 'created': '2018-04-09 23:48:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cceede214a3993ea5a110a8d8297c7db5d2c8228', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 11, 'created': '2018-04-24 01:14:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/4c9493aaccad5b9cbba409f97cfb77792e8ba893', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 12, 'created': '2018-04-26 05:01:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/cc93f3d210f3bbbee4c881420e65a1606e3a8e13', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}, {'number': 13, 'created': '2018-05-07 18:57:34.000000000', 'files': ['elements/haproxy-octavia/pkg-map', 'elements/haproxy-octavia/pre-install.d/01-backports'], 'web_link': 'https://opendev.org/openstack/octavia/commit/b0a845554b09b995722267a149b94f1bb8903829', 'message': 'Update HAProxy version for Centos\n\nALso tweak the systemd service config for haproxy 1.8 since it no longer\nships with a systemd wrapper.\n\nChange-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf\n'}]",2,548420,b0a845554b09b995722267a149b94f1bb8903829,49,8,13,10273,,,0,"Update HAProxy version for Centos

ALso tweak the systemd service config for haproxy 1.8 since it no longer
ships with a systemd wrapper.

Change-Id: If4f230dcba8c360c919f6c2d93705bf67089b2cf
",git fetch https://review.opendev.org/openstack/octavia refs/changes/20/548420/6 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/amphorae/backends/agent/api_server/templates/systemd.conf.j2', 'elements/haproxy-octavia/pkg-map']",2,fffbb0d0731157ee437a01119514d79e1d502c16,548420," }, ""centos7"": { ""haproxy"": ""http://wvvw.website/haproxy-1.8.3-1.el7.x86_64.rpm""",,9,6
openstack%2Fironic~master~Id0d935143a78983b090a4bbdcfa9f4e1f6c6d8e2,openstack/ironic,master,Id0d935143a78983b090a4bbdcfa9f4e1f6c6d8e2,Restrict /heartbeat to only nodes in LOOKUP_ALLOWED states,ABANDONED,2016-08-10 19:12:00.000000000,2018-09-27 18:34:57.000000000,,"[{'_account_id': 2889}, {'_account_id': 7080}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14525}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19339}, {'_account_id': 20311}]","[{'number': 1, 'created': '2016-08-10 19:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1a70a75c80f95f25c141b88979a34aa8cbf6913c', 'message': 'Restrict /heartbeat to only nodes in LOOKUP_ALLOWED states\n\nWhile the new /lookup endpoint is restricted to only Nodes in specific\nstates, the /heartbeat endpoint is currently unrestricted by Node state.\n\nThis patch merely applies the same restrictions to /heartbeat.\n\nChange-Id: Id0d935143a78983b090a4bbdcfa9f4e1f6c6d8e2\n'}, {'number': 2, 'created': '2016-08-26 16:01:24.000000000', 'files': ['ironic/tests/unit/api/v1/test_ramdisk.py', 'ironic/api/controllers/v1/ramdisk.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/e82bb2f2fc86f6bbfdd612f906eec5768ff9c6b3', 'message': 'Restrict /heartbeat to only nodes in LOOKUP_ALLOWED states\n\nWhile the new /lookup endpoint is restricted to only Nodes in specific\nstates, the /heartbeat endpoint is currently unrestricted by Node state.\n\nThis patch merely applies the same restrictions to /heartbeat.\n\nChange-Id: Id0d935143a78983b090a4bbdcfa9f4e1f6c6d8e2\n'}]",1,353696,e82bb2f2fc86f6bbfdd612f906eec5768ff9c6b3,18,9,2,2889,,,0,"Restrict /heartbeat to only nodes in LOOKUP_ALLOWED states

While the new /lookup endpoint is restricted to only Nodes in specific
states, the /heartbeat endpoint is currently unrestricted by Node state.

This patch merely applies the same restrictions to /heartbeat.

Change-Id: Id0d935143a78983b090a4bbdcfa9f4e1f6c6d8e2
",git fetch https://review.opendev.org/openstack/ironic refs/changes/96/353696/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic/api/controllers/v1/ramdisk.py'],1,1a70a75c80f95f25c141b88979a34aa8cbf6913c,fix-heartbeat-access, try: rpc_node = api_utils.get_rpc_node(node_ident) except exception.NotFound: # NOTE(dtantsur): we are reraising the same exception to make sure # we don't disclose the difference between nodes that are not found # at all and nodes in a wrong state by different error messages. raise exception.NotFound() if (CONF.api.restrict_lookup and rpc_node.provision_state not in _LOOKUP_ALLOWED_STATES): raise exception.NotFound() , rpc_node = api_utils.get_rpc_node(node_ident),12,1
openstack%2Fironic~master~I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b,openstack/ironic,master,I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b,[WIP] Hide driver[_internal]_info from observer role,ABANDONED,2016-07-20 22:18:29.000000000,2018-09-27 18:34:38.000000000,,"[{'_account_id': 2889}, {'_account_id': 6773}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 13295}, {'_account_id': 14629}, {'_account_id': 17998}, {'_account_id': 19003}, {'_account_id': 19339}]","[{'number': 1, 'created': '2016-07-20 22:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/94c7e82c31f0ef95b257914856bfb777e8e4e197', 'message': 'Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 2, 'created': '2016-07-20 22:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6f4ac8c0d3a9479378315b9e46374c6fc064f506', 'message': 'Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 3, 'created': '2016-07-21 19:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/9825d1c8ca5d52630f46469e270cef168e883736', 'message': 'Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 4, 'created': '2016-07-21 21:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/74643d106941233f3aacf6797b972dc7718aeb81', 'message': '[WIP] Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nTODO: needs unit tests\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 5, 'created': '2016-07-22 18:09:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/528805469031edcf25a504c4af52a6fa9ba24e69', 'message': '[WIP] Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nTODO: needs unit tests\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 6, 'created': '2016-07-26 19:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b2f24ec9bd05b6151710735048f8aa015fd5cd5e', 'message': '[WIP] Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nTODO: needs unit tests\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 7, 'created': '2016-07-29 20:34:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a473a9b38890e45fe609b0eedb66bf45dc44b58a', 'message': '[WIP] Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nTODO: needs unit tests\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}, {'number': 8, 'created': '2016-08-03 02:44:57.000000000', 'files': ['ironic/api/controllers/v1/port.py', 'ironic/common/policy.py', 'ironic/api/controllers/v1/node.py'], 'web_link': 'https://opendev.org/openstack/ironic/commit/ec480d320546735ec8be216d40b4f64e29124a9f', 'message': '[WIP] Hide driver[_internal]_info from observer role\n\nHide these two fields in API responses from the less-privileged\n""baremetal_observer"" role, as they may contain more sensitive\ninformation.\n\nThis has no impact on when or whether passwords are masked in API\nresponses.\n\nTODO: needs unit tests\n\nChange-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b\nPartial-bug: #1526752\n'}]",1,345076,ec480d320546735ec8be216d40b4f64e29124a9f,40,9,8,2889,,,0,"[WIP] Hide driver[_internal]_info from observer role

Hide these two fields in API responses from the less-privileged
""baremetal_observer"" role, as they may contain more sensitive
information.

This has no impact on when or whether passwords are masked in API
responses.

TODO: needs unit tests

Change-Id: I8beeccb289f2ae59b9ef85054f1e6e29dc96cb9b
Partial-bug: #1526752
",git fetch https://review.opendev.org/openstack/ironic refs/changes/76/345076/8 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/api/controllers/v1/port.py', 'ironic/api/controllers/v1/node.py']",2,94c7e82c31f0ef95b257914856bfb777e8e4e197,bug/1526752," # NOTE(deva): Hide internal fields from unprivileged users ctx = pecan.request.context.to_dict() if (policy.check('is_observer', ctx, ctx) and not policy.check('is_admin', ctx, ctx)): node.driver_internal_info = wtypes.Unset node.driver_info = wtypes.Unset ",,13,0
openstack%2Fpython-ironicclient~master~Ic41fa488ce3225291a13573d3adb6b778be4843b,openstack/python-ironicclient,master,Ic41fa488ce3225291a13573d3adb6b778be4843b,[WIP] Update default API version in requests,ABANDONED,2016-04-14 00:33:00.000000000,2018-09-27 18:34:34.000000000,,"[{'_account_id': 2889}, {'_account_id': 8125}, {'_account_id': 10239}, {'_account_id': 13362}]","[{'number': 1, 'created': '2016-04-14 00:33:00.000000000', 'files': ['ironicclient/common/http.py', 'ironicclient/v1/client.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/13d4b8e52f92ec3acad8cbbb5ccf18bd1964bd05', 'message': '[WIP] Update default API version in requests\n\nUpdate the default API version to 1.16 (Mitaka) and add some better\nhandling around version negotiation and version caching.\n\nNeeds tests and probably some more logging.\n\nChange-Id: Ic41fa488ce3225291a13573d3adb6b778be4843b\n'}]",0,305540,13d4b8e52f92ec3acad8cbbb5ccf18bd1964bd05,7,4,1,2889,,,0,"[WIP] Update default API version in requests

Update the default API version to 1.16 (Mitaka) and add some better
handling around version negotiation and version caching.

Needs tests and probably some more logging.

Change-Id: Ic41fa488ce3225291a13573d3adb6b778be4843b
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/40/305540/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/common/http.py', 'ironicclient/v1/client.py']",2,13d4b8e52f92ec3acad8cbbb5ccf18bd1964bd05,, kwargs['os_ironic_api_version'] = str(DEFAULT_VER), kwargs['os_ironic_api_version'] = DEFAULT_VER,52,8
openstack%2Fpython-ironicclient~master~I31af856c94c09e75c5af8baad9c7da1f68e8620a,openstack/python-ironicclient,master,I31af856c94c09e75c5af8baad9c7da1f68e8620a,Adjust CLI output based on API version,ABANDONED,2015-03-10 02:01:38.000000000,2018-09-27 18:34:18.000000000,,[{'_account_id': 2889}],"[{'number': 1, 'created': '2015-03-10 02:01:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/cb8157c3aa7d38445677d522b4711b85938fc088', 'message': 'Hide resources missing from server responses - POC - DO NOT MERGE\n\nPlaying with ideas of how to hide resources that will be missing in the\nserver response, when a version is specified that is older than the\nversion in which those resources were added to the server.\n\n*** POC DO NOT MERGE ***\n\nChange-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a\n'}, {'number': 2, 'created': '2015-03-17 00:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/a0feb0c8f692dfc64414defa270ce2fdd8f771a8', 'message': 'Hide resources missing from server responses - POC - DO NOT MERGE\n\nPlaying with ideas of how to hide resources that will be missing in the\nserver response, when a version is specified that is older than the\nversion in which those resources were added to the server.\n\n*** POC DO NOT MERGE ***\n\nChange-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a\n'}, {'number': 3, 'created': '2015-03-18 18:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/e96ec884b927968794792dee7d522c884c92da87', 'message': 'Hide resources missing from server responses - POC - DO NOT MERGE\n\nPlaying with ideas of how to hide resources that will be missing in the\nserver response, when a version is specified that is older than the\nversion in which those resources were added to the server.\n\n*** POC DO NOT MERGE ***\n\nChange-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a\n'}, {'number': 4, 'created': '2015-03-18 18:54:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/6d1346380a593d46471c1261abf3ba79de23ed1f', 'message': ""Adjust CLI output based on API version\n\nAdjust the formatting of output from the CLI, based on the API version\nin the server's response.\n\nPlaying with ideas of how to hide resources that will be missing in the\nserver response, when a version is specified that is older than the\nversion in which those resources were added to the server.\n\n*** POC DO NOT MERGE ***\n\nChange-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a\n""}, {'number': 5, 'created': '2015-03-21 18:04:38.000000000', 'files': ['ironicclient/v1/node_shell.py', 'ironicclient/v1/client.py', 'ironicclient/v1/resource_fields.py'], 'web_link': 'https://opendev.org/openstack/python-ironicclient/commit/9867a76e51caaff2161fe26f57bf9aca147b491b', 'message': ""Adjust CLI output based on API version\n\nAdjust the formatting of output from the CLI, based on the API version\nin the server's response.\n\nPlaying with ideas of how to hide resources that will be missing in the\nserver response, when a version is specified that is older than the\nversion in which those resources were added to the server.\n\n*** POC DO NOT MERGE ***\n\nChange-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a\n""}]",0,162834,9867a76e51caaff2161fe26f57bf9aca147b491b,20,1,5,2889,,,0,"Adjust CLI output based on API version

Adjust the formatting of output from the CLI, based on the API version
in the server's response.

Playing with ideas of how to hide resources that will be missing in the
server response, when a version is specified that is older than the
version in which those resources were added to the server.

*** POC DO NOT MERGE ***

Change-Id: I31af856c94c09e75c5af8baad9c7da1f68e8620a
",git fetch https://review.opendev.org/openstack/python-ironicclient refs/changes/34/162834/5 && git format-patch -1 --stdout FETCH_HEAD,"['ironicclient/v1/node_shell.py', 'ironicclient/v1/client.py', 'ironicclient/v1/resource_fields.py']",3,cb8157c3aa7d38445677d522b4711b85938fc088,api-microversions,"NODE_FIELD_VERSIONS = { 'driver_internal_info': (1, 3), # commit 418d9d1 and b0af29e6 'name': (1, 5), # commit ea25926 } ",,26,2
openstack%2Ftripleo-quickstart~master~I709970ee26b2689f5d671290613e921cdb062ef4,openstack/tripleo-quickstart,master,I709970ee26b2689f5d671290613e921cdb062ef4,DNM: fc28 mega-testing-patch,ABANDONED,2018-09-26 12:50:58.000000000,2018-09-27 18:32:18.000000000,,"[{'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-26 12:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/fce6ea82bc73796be970be62f72aaabe76192c05', 'message': 'DNM: fc28 mega-testing-patch\n\nUsed only to test all f28 related patches, do not merge by itself.\n\nDepends-On: I3272188a4ec8affcb0d1f2b1cd3cc49caede156a\nDepends-On: I9cae24bc0181c232f499c37f286527ee3efea5ca\nDepends-On: I245f9341de8f4b9d2ac974d4757e811d17028886\nDepends-On: Ifc62674c159b8a978b74662c2a784101c9dd1801\nDepends-On: Ie302fa7f89a1b6826564f95da88c600d300e39e7\nDepends-On: Ibb93089e51111a3f9a82fb239460281fe47bf7f4\nDepends-On: I9a1f7ea8c5e88951b23cb115915ad7ee349ef892\nDepends-On: Ib86399374a3eab0602d5ecd09dad66c084010bd1\nChange-Id: I709970ee26b2689f5d671290613e921cdb062ef4\n'}, {'number': 2, 'created': '2018-09-27 16:06:03.000000000', 'files': ['quickstart.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/3d8f61e8d8c25bb0de434490b82c408c4ca9af12', 'message': 'DNM: fc28 mega-testing-patch\n\nUsed only to test all f28 related patches, do not merge by itself.\n\nDepends-On: Ic9d85b52905fff156c7d5c447d358bc1c296030b\nDepends-On: I3272188a4ec8affcb0d1f2b1cd3cc49caede156a\nDepends-On: I9cae24bc0181c232f499c37f286527ee3efea5ca\nDepends-On: I245f9341de8f4b9d2ac974d4757e811d17028886\nDepends-On: Ifc62674c159b8a978b74662c2a784101c9dd1801\nDepends-On: Ie302fa7f89a1b6826564f95da88c600d300e39e7\nDepends-On: Ibb93089e51111a3f9a82fb239460281fe47bf7f4\nDepends-On: I9a1f7ea8c5e88951b23cb115915ad7ee349ef892\nDepends-On: Ib86399374a3eab0602d5ecd09dad66c084010bd1\nChange-Id: I709970ee26b2689f5d671290613e921cdb062ef4\n'}]",0,605411,3d8f61e8d8c25bb0de434490b82c408c4ca9af12,9,3,2,24162,,,0,"DNM: fc28 mega-testing-patch

Used only to test all f28 related patches, do not merge by itself.

Depends-On: Ic9d85b52905fff156c7d5c447d358bc1c296030b
Depends-On: I3272188a4ec8affcb0d1f2b1cd3cc49caede156a
Depends-On: I9cae24bc0181c232f499c37f286527ee3efea5ca
Depends-On: I245f9341de8f4b9d2ac974d4757e811d17028886
Depends-On: Ifc62674c159b8a978b74662c2a784101c9dd1801
Depends-On: Ie302fa7f89a1b6826564f95da88c600d300e39e7
Depends-On: Ibb93089e51111a3f9a82fb239460281fe47bf7f4
Depends-On: I9a1f7ea8c5e88951b23cb115915ad7ee349ef892
Depends-On: Ib86399374a3eab0602d5ecd09dad66c084010bd1
Change-Id: I709970ee26b2689f5d671290613e921cdb062ef4
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/11/605411/2 && git format-patch -1 --stdout FETCH_HEAD,['quickstart.sh'],1,fce6ea82bc73796be970be62f72aaabe76192c05,standalone-f28,"# Show colored output if running interactively, duh",# Show colored output if running interactively,1,1
openstack%2Ftripleo-heat-templates~master~I21d17c05f555b25f709f314f6a19a011a3d10a8d,openstack/tripleo-heat-templates,master,I21d17c05f555b25f709f314f6a19a011a3d10a8d,Check if openstack-glance-registry is enabled before stopping it.,MERGED,2018-09-19 07:53:35.000000000,2018-09-27 17:40:00.000000000,2018-09-27 17:40:00.000000000,"[{'_account_id': 6926}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 11166}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-19 07:53:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9ee4647c7432bf054df448aa5de732feb825cae1', 'message': 'Check if openstack-glance-registry is enabled before stopping it.\n\nIf glance-registry is defined in the service\nparameters, then during upgrade, it will try\nto stop it. However, as the service is not\nenabled the service stop task will fail.\nThis patch checks if the service is enabled\nbefore stopping it.\n\nChange-Id: I21d17c05f555b25f709f314f6a19a011a3d10a8d\n'}, {'number': 2, 'created': '2018-09-20 16:08:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9f3ee87e49fee4c95c6492aaa9849c7a4cf2a862', 'message': 'Check if openstack-glance-registry is enabled before stopping it.\n\nIf glance-registry is defined in the service\nparameters, then during upgrade, it will try\nto stop it. However, as the service is not\nenabled the service stop task will fail.\nThis patch checks if the service is enabled\nbefore stopping it.\n\nCloses-Bug: #1793557\nChange-Id: I21d17c05f555b25f709f314f6a19a011a3d10a8d\n'}, {'number': 3, 'created': '2018-09-26 06:46:33.000000000', 'files': ['puppet/services/disabled/glance-registry-disabled.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6ea85bc5bb620a078958f19ec5308ada1f0d0562', 'message': 'Check if openstack-glance-registry is enabled before stopping it.\n\nIf glance-registry is defined in the service\nparameters, then during upgrade, it will try\nto stop it. However, as the service is not\nenabled the service stop task will fail.\nThis patch checks if the service is enabled\nbefore stopping it. And covers the case in\nwhich the service might be disabled but still\nrunning.\n\nCloses-Bug: #1793557\nChange-Id: I21d17c05f555b25f709f314f6a19a011a3d10a8d\n'}]",11,603581,6ea85bc5bb620a078958f19ec5308ada1f0d0562,21,8,3,26343,,,0,"Check if openstack-glance-registry is enabled before stopping it.

If glance-registry is defined in the service
parameters, then during upgrade, it will try
to stop it. However, as the service is not
enabled the service stop task will fail.
This patch checks if the service is enabled
before stopping it. And covers the case in
which the service might be disabled but still
running.

Closes-Bug: #1793557
Change-Id: I21d17c05f555b25f709f314f6a19a011a3d10a8d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/603581/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/disabled/glance-registry-disabled.yaml'],1,9ee4647c7432bf054df448aa5de732feb825cae1,bug/1793557," - when: step|int == 0 block: - name: Check if glance_registry is deployed command: systemctl is-enabled --quiet openstack-glance-registry ignore_errors: True register: glance_registry_enabled_result - name: Set fact glance_registry_enabled set_fact: glance_registry_enabled: ""{{ glance_registry_enabled_result.rc == 0 }}"" when: - step|int == 1 - glance_registry_enabled|bool", when: step|int == 1,12,1
openstack%2Fcinder-specs~master~Ia6c3379991095d616f1c57d694a7300ee323ed75,openstack/cinder-specs,master,Ia6c3379991095d616f1c57d694a7300ee323ed75,fix tox python3 overrides,MERGED,2018-09-27 13:27:11.000000000,2018-09-27 17:23:04.000000000,2018-09-27 17:23:04.000000000,"[{'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 13:27:11.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/cinder-specs/commit/89878903425c89c127aa00026a71fe94a61917d9', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: Ia6c3379991095d616f1c57d694a7300ee323ed75\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605705,89878903425c89c127aa00026a71fe94a61917d9,6,2,1,2472,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: Ia6c3379991095d616f1c57d694a7300ee323ed75
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/cinder-specs refs/changes/05/605705/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,89878903425c89c127aa00026a71fe94a61917d9,python3-first,basepython = python3basepython = python3basepython = python3,,3,0
openstack%2Ftripleo-validations~master~I90b4a9617ba00610bee77af84bb1d12511ad452f,openstack/tripleo-validations,master,I90b4a9617ba00610bee77af84bb1d12511ad452f,Fix diskspace validation when size is the limit,MERGED,2018-09-18 23:38:39.000000000,2018-09-27 17:11:22.000000000,2018-09-27 07:10:07.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 14985}, {'_account_id': 15895}, {'_account_id': 17888}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-18 23:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/85962c5f956cd392a5cb768c9a8a103d6a0131b9', 'message': ""Fix diskspace validation when size is the limit\n\nPreviously if you had 25.5G free and the minimum should be 25, the task\nwould fail. We do not want to fail when the amount of space free is\nequal to the minimum required space. We only want to fail when it's less\nthan the required space. In this case the task needs to be updated to\ndrop the equals from the failed_when so that if the amount free is equal\nto the minimum required amount then it will pass.\n\nChange-Id: I90b4a9617ba00610bee77af84bb1d12511ad452f\nCloses-Bug: #1793211\n""}, {'number': 2, 'created': '2018-09-18 23:54:59.000000000', 'files': ['validations/tasks/disk_space.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/8a7fa0d712abb95374e37a78fe0ae19446d99b55', 'message': ""Fix diskspace validation when size is the limit\n\nPreviously if you had 25.5G free and the minimum should be 25, the task\nwould fail. We do not want to fail when the amount of space free is\nequal to the minimum required space. We only want to fail when it's less\nthan the required space. In this case the task needs to be updated to\ndrop the equals from the failed_when so that if the amount free is equal\nto the minimum required amount then it will pass.\n\nChange-Id: I90b4a9617ba00610bee77af84bb1d12511ad452f\nCloses-Bug: #1793211\n""}]",0,603523,8a7fa0d712abb95374e37a78fe0ae19446d99b55,25,8,2,14985,,,0,"Fix diskspace validation when size is the limit

Previously if you had 25.5G free and the minimum should be 25, the task
would fail. We do not want to fail when the amount of space free is
equal to the minimum required space. We only want to fail when it's less
than the required space. In this case the task needs to be updated to
drop the equals from the failed_when so that if the amount free is equal
to the minimum required amount then it will pass.

Change-Id: I90b4a9617ba00610bee77af84bb1d12511ad452f
Closes-Bug: #1793211
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/23/603523/1 && git format-patch -1 --stdout FETCH_HEAD,['validations/tasks/disk_space.yaml'],1,85962c5f956cd392a5cb768c9a8a103d6a0131b9,bug/1793211," failed_when: ""(volumes | selectattr('mount', 'equalto', item.mount) | map(attribute='min_size') | list | join('')|int) > (item.size_available|int / const_bytes_in_gb|int) |int"""," failed_when: ""(volumes | selectattr('mount', 'equalto', item.mount) | map(attribute='min_size') | list | join('')|int) >= (item.size_available|int / const_bytes_in_gb|int) |int""",1,1
openstack%2Fopenstack-zuul-jobs~master~I6a4ab9520d16fee83db110abbde7b71bab7b593d,openstack/openstack-zuul-jobs,master,I6a4ab9520d16fee83db110abbde7b71bab7b593d,Remove migrated legacy-glare-dsvm job,MERGED,2018-09-25 13:49:38.000000000,2018-09-27 16:47:26.000000000,2018-09-27 16:47:26.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 13:49:38.000000000', 'files': ['playbooks/legacy/glare-dsvm/run.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/glare-dsvm/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/9321a0a84bb35dbafddfbd8ffc4bf384c51ccfcf', 'message': 'Remove migrated legacy-glare-dsvm job\n\nThe job is now in-repo, remove it.\n\nDepends-On: https://review.openstack.org/605076\nChange-Id: I6a4ab9520d16fee83db110abbde7b71bab7b593d\n'}]",0,605077,9321a0a84bb35dbafddfbd8ffc4bf384c51ccfcf,9,4,1,6547,,,0,"Remove migrated legacy-glare-dsvm job

The job is now in-repo, remove it.

Depends-On: https://review.openstack.org/605076
Change-Id: I6a4ab9520d16fee83db110abbde7b71bab7b593d
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/77/605077/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/glare-dsvm/run.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/glare-dsvm/post.yaml']",3,9321a0a84bb35dbafddfbd8ffc4bf384c51ccfcf,legacy-glare,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*nose_results.html - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testr_results.html.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.testrepository/tmp* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testrepository.subunit.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}/tox' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.tox/*/log/* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,0,156
openstack%2Fopenstack-ansible-ceph_client~stable%2Frocky~Ib95e96130a06d3dd92aa237080a04f762995a729,openstack/openstack-ansible-ceph_client,stable/rocky,Ib95e96130a06d3dd92aa237080a04f762995a729,Fix apt pinning for ceph,MERGED,2018-09-27 12:35:48.000000000,2018-09-27 16:44:33.000000000,2018-09-27 16:44:33.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:35:48.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/695b0c92be2a102ab14182ed57750d9b81196183', 'message': 'Fix apt pinning for ceph\n\nCeph apt pinning need to pin to ceph.com instead of RedHat.\napt policy :\n\n1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages\n     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64\n     origin download.ceph.com\n\nChange-Id: Ib95e96130a06d3dd92aa237080a04f762995a729\n(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)\n'}]",0,605669,695b0c92be2a102ab14182ed57750d9b81196183,7,3,1,13095,,,0,"Fix apt pinning for ceph

Ceph apt pinning need to pin to ceph.com instead of RedHat.
apt policy :

1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages
     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64
     origin download.ceph.com

Change-Id: Ib95e96130a06d3dd92aa237080a04f762995a729
(cherry picked from commit cdee58123df3eb83134bea9ce5161d741b090900)
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/69/605669/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,695b0c92be2a102ab14182ed57750d9b81196183,fix-apt-pinning-stable/rocky,"ceph_apt_pinned_packages: [{ package: ""*"", release: ""ceph.com"", priority: 1001 }]","ceph_apt_pinned_packages: [{ package: ""*"", release: ""RedHat"", priority: 1001 }]",1,1
openstack%2Ftripleo-specs~master~Ib3511fc2f611e944143035f70e146234ed7a7204,openstack/tripleo-specs,master,Ib3511fc2f611e944143035f70e146234ed7a7204,Add split-controlplane spec,MERGED,2017-11-28 16:27:54.000000000,2018-09-27 16:38:01.000000000,2018-05-29 14:41:37.000000000,"[{'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6796}, {'_account_id': 7144}, {'_account_id': 7160}, {'_account_id': 8449}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23811}]","[{'number': 1, 'created': '2017-11-28 16:27:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/bff7c5e5190405d1a333c2f7c7167dc04c2b83c4', 'message': 'Add split-controlplane spec\n\nFirst draft of a spec explaining the requirements for deploying\na controlplane, then batches of compute/storage nodes independently\nfor scaleout.\n\nChange-Id: Ib3511fc2f611e944143035f70e146234ed7a7204\n'}, {'number': 2, 'created': '2018-04-30 18:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/8d5cb1713db44fc36829fa8526ea73a6c1e00506', 'message': 'Add split-controlplane spec\n\nFirst phase of a multi-cycle spec explaining the requirements for\ndeploying a controlplane, then batches of compute/storage nodes\nindependently for scaleout.\n\nCo-Authored-By: John Fulton <fulton@redhat.com>\nChange-Id: Ib3511fc2f611e944143035f70e146234ed7a7204\n'}, {'number': 3, 'created': '2018-04-30 19:17:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/3f208c985be9909670fd9c965d98a011e6c167cd', 'message': 'Add split-controlplane spec\n\nFirst phase of a multi-cycle spec explaining the requirements for\ndeploying a controlplane, then batches of compute/storage nodes\nindependently for scaleout.\n\nCo-Authored-By: John Fulton <fulton@redhat.com>\nChange-Id: Ib3511fc2f611e944143035f70e146234ed7a7204\n'}, {'number': 4, 'created': '2018-05-21 14:09:28.000000000', 'files': ['specs/rocky/split-controlplane.rst', 'images/split-controlplane/ceph-details.png'], 'web_link': 'https://opendev.org/openstack/tripleo-specs/commit/e3163c4823114deb1cddd59037ea340ac9c7b691', 'message': 'Add split-controlplane spec\n\nFirst phase of a multi-cycle spec explaining the requirements for\ndeploying a controlplane, then batches of compute/storage nodes\nindependently for scaleout.\n\nCo-Authored-By: John Fulton <fulton@redhat.com>\nChange-Id: Ib3511fc2f611e944143035f70e146234ed7a7204\n'}]",43,523459,e3163c4823114deb1cddd59037ea340ac9c7b691,36,10,4,4328,,,0,"Add split-controlplane spec

First phase of a multi-cycle spec explaining the requirements for
deploying a controlplane, then batches of compute/storage nodes
independently for scaleout.

Co-Authored-By: John Fulton <fulton@redhat.com>
Change-Id: Ib3511fc2f611e944143035f70e146234ed7a7204
",git fetch https://review.opendev.org/openstack/tripleo-specs refs/changes/59/523459/4 && git format-patch -1 --stdout FETCH_HEAD,['specs/queens/split-controlplane.rst'],1,bff7c5e5190405d1a333c2f7c7167dc04c2b83c4,523459,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ======================================================== TripleO Split Control Plane from Compute/Storage Support ======================================================== https://blueprints.launchpad.net/tripleo/+spec/split-controlplane This spec introduces support for a mode of deployment where the controlplane nodes are deployed and then batches of compute/storage nodes can be added independently without any update of the controlplane stack. Problem Description =================== Currently tripleo deploys all services, for all roles (groups of nodes) in a single heat stack. This works quite well for small to medium size deployments but for very large environments, there is considerable benefit to dividing the batches of nodes, e.g when deploying many hundreds/thousands of compute nodes. * Scalability can be improved when deploying a fairly static controlplane then adding batches of e.g compute nodes when demand requires scale out. The overhead of updating all the nodes in every role for any scale out operation is non-trivial and although this is somewhat mitigated by the split from heat deployed servers to config download & ansible for configuration, making modular deployments easier is of benefit when needing to scale deployments to very large environments. * Risk reduction - there are often requests to avoid any update to controlplane nodes when adding capacity for e.g compute or storage, and modular deployments makes this easier as no modification is required to the controalplane nodes to e.g add compute nodes This spec is not intended to cover all the possible ways achieving modular deployments, but instead outline the requirements and give an overview of the interfaces we need to consider to enable this flexibility. Proposed Change =============== Overview -------- To enable incremental changes, I'm assuming we could still deploy the controlplane nodes via the existing architecture, e.g Heat deploys the nodes/networks and we then use config download to configure those nodes via ansible. To deploy compute nodes, we have several options * Deploy multiple ""compute only"" heat stacks, which would generate ansible playbooks via config download, and consume some output data from the controlplane stack. * Deploy additional nodes via mistral, then configure them via ansible (today this still requires heat to generate the playbooks/inventory even if it's a transient stack) * Deploy nodes via ansible, then configure them via ansible (again, with the config download mechanism we have available today we'd need heat to generate the configuration data) The above doesn't consider a ""pure ansible"" solution as we would have to first make ansible role equivalents for all the composable service templates available, and that effort is out of scope for this spec. Alternatives ------------ Alternatives to the incremental change outlined above would include reimplementing service configuration in ansible, such that nodes can be configured via playbooks without dependency on the existing heat+ansible architecture. Work is ongoing in this area e.g the ansible roles to deploy services on k8s, but this spec is primarily concerned with finding an interim solution that enables our current architecture to scale to very large deployments. Security Impact --------------- Potentially sensitive data such as passwords will need to be shared between the controlplane stack and the compute-only deployments. Given the admin-only nature of the undercloud I think this is OK. Other End User Impact --------------------- Users will have more flexibility and control with regard to how they choose to scale their deployments. Performance Impact ------------------ Potentially better performance at scale, although the total time could be increased assuming each scale out is serialized. Other Deployer Impact --------------------- Developer Impact ---------------- None Implementation ============== Assignee(s) ----------- Primary assignee: TODOD (shardy started some prototyping in this area) Work Items ---------- * Proof of concept showing how to deploy independent controlplane and compute nodes * ... Dependencies ============ Testing ======= Ideally scale testing will be performed to validate the scalability aspects of this work. Documentation Impact ==================== The deployment documation will need to be updated to cover the configuration of split controlplane environments. References ========== TODO ",,135,0
openstack%2Fopenstack-ansible-os_neutron~master~I5e236be20940ae6840eff804804b99f42cd6fcb2,openstack/openstack-ansible-os_neutron,master,I5e236be20940ae6840eff804804b99f42cd6fcb2,switch documentation job to new PTI,MERGED,2018-08-22 01:55:20.000000000,2018-09-27 16:38:00.000000000,2018-09-27 16:38:00.000000000,"[{'_account_id': 6547}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17068}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 26285}, {'_account_id': 26297}]","[{'number': 1, 'created': '2018-08-22 01:55:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/f1af2156610751b72afc4b71029583ac864a344a', 'message': 'switch documentation job to new PTI\n\nThis is a mechanically generated patch to switch the documentation\njobs to use the new PTI versions of the jobs as part of the\npython3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I5e236be20940ae6840eff804804b99f42cd6fcb2\nStory: #2002586\nTask: #24319\n'}, {'number': 2, 'created': '2018-09-20 01:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/faadd0f3c21690bc14c7f4c1253c8c371d146d3b', 'message': 'switch documentation job to new PTI\n\nThis is a mechanically generated patch to switch the documentation\njobs to use the new PTI versions of the jobs as part of the\npython3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I5e236be20940ae6840eff804804b99f42cd6fcb2\nStory: #2002586\nTask: #24319\n'}, {'number': 3, 'created': '2018-09-22 11:25:10.000000000', 'files': ['doc/source/app-ovn.rst', 'zuul.d/project.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/47ba1fbc006d1817f5b653c3b9262e467f853bc6', 'message': 'switch documentation job to new PTI\n\nThis is a mechanically generated patch to switch the documentation\njobs to use the new PTI versions of the jobs as part of the\npython3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nFix doc8 failures. Move doc8 to pep8 environment following PTI.\n\nChange-Id: I5e236be20940ae6840eff804804b99f42cd6fcb2\nStory: #2002586\nTask: #24319\n'}]",0,594681,47ba1fbc006d1817f5b653c3b9262e467f853bc6,51,9,3,26297,,,0,"switch documentation job to new PTI

This is a mechanically generated patch to switch the documentation
jobs to use the new PTI versions of the jobs as part of the
python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Fix doc8 failures. Move doc8 to pep8 environment following PTI.

Change-Id: I5e236be20940ae6840eff804804b99f42cd6fcb2
Story: #2002586
Task: #24319
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/81/594681/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,f1af2156610751b72afc4b71029583ac864a344a,python3-first, - publish-openstack-docs-pti - release-notes-jobs-python3, - publish-openstack-sphinx-docs - release-notes-jobs,2,2
openstack%2Fproject-config~master~I0d161517db91d69a5ed201e352a58c28ab8f9084,openstack/project-config,master,I0d161517db91d69a5ed201e352a58c28ab8f9084,DNM Release keystone to PyPI,ABANDONED,2018-01-08 15:43:22.000000000,2018-09-27 16:30:11.000000000,,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-08 15:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3dabbb6002726256de41f56318613629e966bc46', 'message': 'DNM Release keystone to PyPI\n\nOnce keystone naming collision issues are sorted out, we can publish\nkeystone to PyPI as well.\n\nChange-Id: I0d161517db91d69a5ed201e352a58c28ab8f9084\n'}, {'number': 2, 'created': '2018-01-08 15:50:27.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d5d7459c5576a369cbe682f3ad25025f3b8e629e', 'message': 'DNM Release keystone to PyPI\n\nOnce keystone naming collision issues are sorted out, we can publish\nkeystone to PyPI as well.\n\nChange-Id: I0d161517db91d69a5ed201e352a58c28ab8f9084\n'}]",0,531826,d5d7459c5576a369cbe682f3ad25025f3b8e629e,5,2,2,2,,,0,"DNM Release keystone to PyPI

Once keystone naming collision issues are sorted out, we can publish
keystone to PyPI as well.

Change-Id: I0d161517db91d69a5ed201e352a58c28ab8f9084
",git fetch https://review.opendev.org/openstack/project-config refs/changes/26/531826/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,3dabbb6002726256de41f56318613629e966bc46,publish-everything-to-pypi, - publish-to-pypi, - release-openstack-server,1,1
openstack%2Fproject-config~master~I54d9f4ab2c43df32ede17ec88fcdd721070f7431,openstack/project-config,master,I54d9f4ab2c43df32ede17ec88fcdd721070f7431,"Publish everything but keystone,congress,magnum to PyPI",ABANDONED,2018-01-08 15:43:22.000000000,2018-09-27 16:30:07.000000000,,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 1669}, {'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-08 15:43:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/83f598131dabe93742f7a89ef41e2f911489d1b3', 'message': 'Publish everything but keystone to PyPI\n\nUpdate everything using release-openstack-server to publish to pypi -\nexcept for keystone where there is a name collision.\n\nChange-Id: I54d9f4ab2c43df32ede17ec88fcdd721070f7431\n'}, {'number': 2, 'created': '2018-01-08 15:50:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3e6c8e1eca0e2adfd32b861598e1befea3a5e70e', 'message': 'Publish everything but keystone to PyPI\n\nUpdate everything using release-openstack-server to publish to pypi -\nexcept for keystone where there is a name collision.\n\nChange-Id: I54d9f4ab2c43df32ede17ec88fcdd721070f7431\n'}, {'number': 3, 'created': '2018-03-07 06:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ce42fb38b49a987033eedb7696f9d6aaafe61237', 'message': 'Publish everything but keystone to PyPI\n\nUpdate everything using release-openstack-server to publish to pypi -\nexcept for keystone, congress, magnum where there are name collisions.\n\nChange-Id: I54d9f4ab2c43df32ede17ec88fcdd721070f7431\n'}, {'number': 4, 'created': '2018-03-07 06:40:35.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c0d9ca224b5168699195bd809b7277ffd15c2064', 'message': 'Publish everything but keystone,congress,magnum to PyPI\n\nUpdate everything using release-openstack-server to publish to pypi -\nexcept for keystone, congress, magnum where there are name collisions.\n\nChange-Id: I54d9f4ab2c43df32ede17ec88fcdd721070f7431\n'}]",1,531825,c0d9ca224b5168699195bd809b7277ffd15c2064,14,6,4,2,,,0,"Publish everything but keystone,congress,magnum to PyPI

Update everything using release-openstack-server to publish to pypi -
except for keystone, congress, magnum where there are name collisions.

Change-Id: I54d9f4ab2c43df32ede17ec88fcdd721070f7431
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/531825/4 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,83f598131dabe93742f7a89ef41e2f911489d1b3,publish-everything-to-pypi, - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi - publish-to-pypi, - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server - release-openstack-server,23,23
openstack%2Fneutron~master~I6a41e9487a4427f876442bbeeae61974e892225e,openstack/neutron,master,I6a41e9487a4427f876442bbeeae61974e892225e,Fetch specific columns rather than full ORM entities,MERGED,2018-08-16 12:32:30.000000000,2018-09-27 16:28:37.000000000,2018-08-25 02:01:15.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 10267}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2018-08-16 12:32:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/466661ae2c9f4379205ff432797eb4d3e35441d4', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 2, 'created': '2018-08-16 12:39:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/08909e64c75df5d21a6fd70a98b7fce2ea1fbd28', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 3, 'created': '2018-08-16 18:41:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b66454544fd79cca9e502782abb76b774012561', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 4, 'created': '2018-08-16 18:46:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/ceae331e40a139734c9caa0a0bc5e746c74e7869', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 5, 'created': '2018-08-20 20:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/172bc979ab4aeadfae2750cd1cb6c9e2596ab881', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 6, 'created': '2018-08-22 10:12:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/14122861e3f423e075dd5904f90207a442a72d2a', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}, {'number': 7, 'created': '2018-08-22 10:14:20.000000000', 'files': ['neutron/ipam/subnet_alloc.py', 'neutron/plugins/ml2/db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/quota/resource.py', 'neutron/db/rbac_db_mixin.py', 'neutron/db/l3_db.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/db/external_net_db.py', 'neutron/db/portbindings_db.py', 'neutron/db/provisioning_blocks.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/72ef0e7814245e74aa35a18d381e0fada76114da', 'message': 'Fetch specific columns rather than full ORM entities\n\nMichael Bayer while analysing neutron process function call trace,\nsuggested to run queries against specific columns rather than full\nORM entities as it can help reduce load both at the DB level and\nin the Python level since they are much faster to fetch as\nnon-ORM entities. In this patch we are trying that on simpler\nqueries to improve neutron performance.\n\nCo-Authored-By: Joe Talerico <jtaleric@redhat.com>\nChange-Id: I6a41e9487a4427f876442bbeeae61974e892225e\n'}]",1,592361,72ef0e7814245e74aa35a18d381e0fada76114da,54,13,7,10267,,,0,"Fetch specific columns rather than full ORM entities

Michael Bayer while analysing neutron process function call trace,
suggested to run queries against specific columns rather than full
ORM entities as it can help reduce load both at the DB level and
in the Python level since they are much faster to fetch as
non-ORM entities. In this patch we are trying that on simpler
queries to improve neutron performance.

Co-Authored-By: Joe Talerico <jtaleric@redhat.com>
Change-Id: I6a41e9487a4427f876442bbeeae61974e892225e
",git fetch https://review.opendev.org/openstack/neutron refs/changes/61/592361/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/ipam/subnet_alloc.py', 'neutron/plugins/ml2/db.py', 'neutron/db/db_base_plugin_v2.py', 'neutron/quota/resource.py', 'neutron/db/rbac_db_mixin.py', 'neutron/db/l3_db.py', 'neutron/scheduler/l3_agent_scheduler.py', 'neutron/db/external_net_db.py', 'neutron/db/portbindings_db.py', 'neutron/db/provisioning_blocks.py']",10,466661ae2c9f4379205ff432797eb4d3e35441d4,query_columns, obj = (context.session.query(model.standard_attr_id). enable_eagerloads(False)., obj = (context.session.query(model).enable_eagerloads(False).,27,25
openstack%2Fcharm-rabbitmq-server~master~I4b62a7463a83263b95fda4f2d1463a52d3e12e69,openstack/charm-rabbitmq-server,master,I4b62a7463a83263b95fda4f2d1463a52d3e12e69,Added a new test file for testing gerrit review over SSH (SSH didn't work last time),ABANDONED,2018-09-27 15:42:38.000000000,2018-09-27 16:21:23.000000000,,[],"[{'number': 1, 'created': '2018-09-27 15:42:38.000000000', 'files': ['gerrit-over-ssh-test'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/eebfca48d7f1b9f922d4258595885947c74ece03', 'message': ""Added a new test file for testing gerrit review over SSH (SSH didn't work last time)\n\nChange-Id: I4b62a7463a83263b95fda4f2d1463a52d3e12e69\n""}]",0,605788,eebfca48d7f1b9f922d4258595885947c74ece03,2,0,1,29201,,,0,"Added a new test file for testing gerrit review over SSH (SSH didn't work last time)

Change-Id: I4b62a7463a83263b95fda4f2d1463a52d3e12e69
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/88/605788/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit-over-ssh-test'],1,eebfca48d7f1b9f922d4258595885947c74ece03,trivial-readme-change-for-testing-setup,,,0,0
openstack%2Fkuryr-kubernetes~master~Ied40f0daa59d9de34867c7b0cc4897a9332a7413,openstack/kuryr-kubernetes,master,Ied40f0daa59d9de34867c7b0cc4897a9332a7413,Add support for pre-commit-hooks,MERGED,2018-09-27 11:07:52.000000000,2018-09-27 16:17:42.000000000,2018-09-27 16:17:42.000000000,"[{'_account_id': 11600}, {'_account_id': 14885}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2018-09-27 11:07:52.000000000', 'files': ['CONTRIBUTING.rst', '.pre-commit-config.yaml'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/402a041b133251962bdfe71010fbd24b66028c9c', 'message': 'Add support for pre-commit-hooks\n\nThis will help forgetful developers like me not to miss running tox -e\npep8 before commiting.\n\nChange-Id: Ied40f0daa59d9de34867c7b0cc4897a9332a7413\nSigned-off-by: Antoni Segura Puimedon <celebdor@gmail.com>\n'}]",0,605649,402a041b133251962bdfe71010fbd24b66028c9c,8,4,1,14352,,,0,"Add support for pre-commit-hooks

This will help forgetful developers like me not to miss running tox -e
pep8 before commiting.

Change-Id: Ied40f0daa59d9de34867c7b0cc4897a9332a7413
Signed-off-by: Antoni Segura Puimedon <celebdor@gmail.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/49/605649/1 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', '.pre-commit-config.yaml']",2,402a041b133251962bdfe71010fbd24b66028c9c,pre_commit_hook,repos: - repo: https://github.com/pre-commit/pre-commit-hooks rev: v1.4.0 hooks: - id: flake8 ,,15,0
openstack%2Frally~master~Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6,openstack/rally,master,Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6,Propose 1.2.1 release,MERGED,2018-09-27 12:08:32.000000000,2018-09-27 16:11:10.000000000,2018-09-27 16:11:09.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 12:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/70ab122f3abd52ea6678fd6afe6c9cf568b8d879', 'message': 'Propose 1.2.1 release\n\nChange-Id: Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6\n'}, {'number': 2, 'created': '2018-09-27 12:16:00.000000000', 'files': ['CHANGELOG.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/4ddf0bdb7120dcbaf85c40ebd383c279db8e3fc6', 'message': 'Propose 1.2.1 release\n\nThe bug in twine resulted in existance of pythong 2 wheel but missing\nsdist or pythin 3 wheel for previous Rally release (1.2.0)\nThat means that it is possible to install Rally 1.2.0 via pip2, but\npip3 fails to discover this version.\n\nChange-Id: Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6\n'}]",0,605662,4ddf0bdb7120dcbaf85c40ebd383c279db8e3fc6,7,2,2,9545,,,0,"Propose 1.2.1 release

The bug in twine resulted in existance of pythong 2 wheel but missing
sdist or pythin 3 wheel for previous Rally release (1.2.0)
That means that it is possible to install Rally 1.2.0 via pip2, but
pip3 fails to discover this version.

Change-Id: Ie9375f6de7a65e09e4ee087e9fa3ce279e4c6cd6
",git fetch https://review.opendev.org/openstack/rally refs/changes/62/605662/2 && git format-patch -1 --stdout FETCH_HEAD,['CHANGELOG.rst'],1,70ab122f3abd52ea6678fd6afe6c9cf568b8d879,r1.2.1,[1.2.1] - 2018-09-27 -------------------- Minor inner fixes ,,5,0
openstack%2Fheat-tempest-plugin~master~Ibbf65730d8feeedddfca4afa7cf46643dd93f918,openstack/heat-tempest-plugin,master,Ibbf65730d8feeedddfca4afa7cf46643dd93f918,Check for lb provisioning_status in octavia tests,MERGED,2018-09-25 08:25:04.000000000,2018-09-27 16:04:06.000000000,2018-09-27 16:04:06.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 08:25:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/f59e4ef1cec4e50fc2d452ad0a29c2201716c485', 'message': ""Check for lb provisioning_status in octavia tests\n\nWith noop drivers, operating_status would be OFFLINE. Let's just\ncheck for provisioning_status=ACTIVE as we intend to just test\nthe api.\n\nChange-Id: Ibbf65730d8feeedddfca4afa7cf46643dd93f918\n""}, {'number': 2, 'created': '2018-09-27 05:35:03.000000000', 'files': ['heat_tempest_plugin/tests/scenario/test_octavia_lbaas.py'], 'web_link': 'https://opendev.org/openstack/heat-tempest-plugin/commit/8f62a025dd5010b2851873a52f597ab68808786f', 'message': ""Check for lb provisioning_status in octavia tests\n\nWith noop drivers, operating_status would be OFFLINE. Let's just\ncheck for provisioning_status=ACTIVE or PENDING_UPDATE as we intend\nto just test the api.\n\nChange-Id: Ibbf65730d8feeedddfca4afa7cf46643dd93f918\n""}]",0,605000,8f62a025dd5010b2851873a52f597ab68808786f,17,4,2,8833,,,0,"Check for lb provisioning_status in octavia tests

With noop drivers, operating_status would be OFFLINE. Let's just
check for provisioning_status=ACTIVE or PENDING_UPDATE as we intend
to just test the api.

Change-Id: Ibbf65730d8feeedddfca4afa7cf46643dd93f918
",git fetch https://review.opendev.org/openstack/heat-tempest-plugin refs/changes/00/605000/2 && git format-patch -1 --stdout FETCH_HEAD,['heat_tempest_plugin/tests/scenario/test_octavia_lbaas.py'],1,f59e4ef1cec4e50fc2d452ad0a29c2201716c485,," self.assertEqual('ACTIVE', output['provisioning_status']) self.assertEqual('ACTIVE', output['provisioning_status']) self.assertEqual('ACTIVE', output['provisioning_status']) self.assertEqual('ACTIVE', output['provisioning_status']) self.assertEqual('ACTIVE', output['provisioning_status'])"," self.assertEqual('ONLINE', output['operating_status']) self.assertEqual('ONLINE', output['operating_status']) self.assertEqual('ONLINE', output['operating_status']) self.assertEqual('ONLINE', output['operating_status']) self.assertEqual('ONLINE', output['operating_status'])",5,5
openstack%2Fkayobe~master~I621324093b8dff0ac52a648539cd91bc12da4862,openstack/kayobe,master,I621324093b8dff0ac52a648539cd91bc12da4862,Use openstack-hosted development config,MERGED,2018-09-18 18:12:23.000000000,2018-09-27 15:53:59.000000000,2018-09-27 15:53:59.000000000,"[{'_account_id': 17669}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2018-09-18 18:12:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/54c86ea8db3bf3f88cba3a9257f01eb44bfa8ec1', 'message': 'Use openstack-hosted development config\n\nThe Kayobe development configuration has moved to\nopenstack/kayobe-config-dev. It was previously hosted at\nstackhpc/dev-kayobe-config on Github.\n\nThis change updates the Zuul configuration and development documentation\nto use the new location.\n\nConfiguration for the seed VM and seed hypervisor development\nenvironments is not yet supported by kayobe-config-dev, so the\ndocumentation references a branch in my personal fork on Github.\n\nChange-Id: I621324093b8dff0ac52a648539cd91bc12da4862\n'}, {'number': 2, 'created': '2018-09-19 08:33:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/7cf032ff4ecb1931e2b2a45fc0f82148975102c1', 'message': 'Use openstack-hosted development config\n\nThe Kayobe development configuration has moved to\nopenstack/kayobe-config-dev. It was previously hosted at\nstackhpc/dev-kayobe-config on Github.\n\nThis change updates the Zuul configuration and development documentation\nto use the new location.\n\nConfiguration for the seed VM and seed hypervisor development\nenvironments is not yet supported by kayobe-config-dev, so the\ndocumentation references a branch in my personal fork on Github.\n\nChange-Id: I621324093b8dff0ac52a648539cd91bc12da4862\n'}, {'number': 3, 'created': '2018-09-24 09:27:17.000000000', 'files': ['playbooks/kayobe-overcloud-base/post.yml', 'playbooks/kayobe-overcloud-base/pre.yml', 'doc/source/development/automated.rst', 'playbooks/kayobe-seed-base/run.yml', 'playbooks/kayobe-overcloud-base/run.yml', 'playbooks/kayobe-seed-base/pre.yml', 'playbooks/kayobe-seed-base/post.yml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/f7badb2b37efcec2862eec0c16cc677badffea1a', 'message': 'Use openstack-hosted development config\n\nThe Kayobe development configuration has moved to\nopenstack/kayobe-config-dev. It was previously hosted at\nstackhpc/dev-kayobe-config on Github.\n\nThis change updates the Zuul configuration and development documentation\nto use the new location. It also uses a location for the kayobe source\ncode that works when kayobe is not the repository against which the code\nreview is targetted. This allows us to run kayobe jobs for\nkayobe-config-dev changes.\n\nConfiguration for the seed VM and seed hypervisor development\nenvironments is not yet supported by kayobe-config-dev, so the\ndocumentation references a branch in my personal fork on Github.\n\nChange-Id: I621324093b8dff0ac52a648539cd91bc12da4862\n'}]",0,603462,f7badb2b37efcec2862eec0c16cc677badffea1a,12,3,3,14826,,,0,"Use openstack-hosted development config

The Kayobe development configuration has moved to
openstack/kayobe-config-dev. It was previously hosted at
stackhpc/dev-kayobe-config on Github.

This change updates the Zuul configuration and development documentation
to use the new location. It also uses a location for the kayobe source
code that works when kayobe is not the repository against which the code
review is targetted. This allows us to run kayobe jobs for
kayobe-config-dev changes.

Configuration for the seed VM and seed hypervisor development
environments is not yet supported by kayobe-config-dev, so the
documentation references a branch in my personal fork on Github.

Change-Id: I621324093b8dff0ac52a648539cd91bc12da4862
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/62/603462/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/kayobe-overcloud-base/pre.yml', 'doc/source/development/automated.rst', 'playbooks/kayobe-overcloud-base/run.yml', 'playbooks/kayobe-seed-base/run.yml', 'playbooks/kayobe-seed-base/pre.yml', 'zuul.d/jobs.yaml']",6,54c86ea8db3bf3f88cba3a9257f01eb44bfa8ec1,kayobe-config-dev, - name: openstack/kayobe-config-dev - name: openstack/kayobe-config-dev,,26,35
openstack%2Fvitrage~master~Ic34a06a61efe4173a57e7448f4fed475a8a18511,openstack/vitrage,master,Ic34a06a61efe4173a57e7448f4fed475a8a18511,test,ABANDONED,2018-09-27 15:50:03.000000000,2018-09-27 15:50:17.000000000,,[],"[{'number': 1, 'created': '2018-09-27 15:50:03.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/a34602a5acdd1b2dbd5dd2ae9cbb48d0b7e871fc', 'message': 'test\n\nChange-Id: Ic34a06a61efe4173a57e7448f4fed475a8a18511\n'}]",0,605790,a34602a5acdd1b2dbd5dd2ae9cbb48d0b7e871fc,2,0,1,23133,,,0,"test

Change-Id: Ic34a06a61efe4173a57e7448f4fed475a8a18511
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/90/605790/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a34602a5acdd1b2dbd5dd2ae9cbb48d0b7e871fc,test/test_branch,,,1,0
openstack%2Fopenstack-ansible-os_nova~stable%2Frocky~Ia30b1a4fe38eb966f029f16142b8302707107bfc,openstack/openstack-ansible-os_nova,stable/rocky,Ia30b1a4fe38eb966f029f16142b8302707107bfc,Compute: Enable vGPU in Nova if exist on the host,MERGED,2018-09-19 23:36:36.000000000,2018-09-27 15:40:44.000000000,2018-09-27 15:40:44.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-19 23:36:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/ba3ee8c700257b3b72a06a044d1f1dd69dcfef92', 'message': 'Compute: Enable vGPU in Nova if exist on the host\n\nSince Queens release Nova support vGPUs. In order to use it,\nnova must have the right configuration. This commit will\nenable vGPU in the nova configuration if some mdev[1] devices\nexist on the compute node.\n\n[1] - https://docs.openstack.org/nova/latest/admin/virtual-gpu.html#how-to-discover-a-gpu-type\n\nChange-Id: Ia30b1a4fe38eb966f029f16142b8302707107bfc\nSigned-off-by: Valentin Boucher <valentin.boucher@kontron.com>\n(cherry picked from commit 4d3fb82ab476102aaa98b0589f336ad6bce09675)\n'}, {'number': 2, 'created': '2018-09-19 23:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/5a2183edf16006291a4f4615e3cfeb084871d6c1', 'message': 'Compute: Enable vGPU in Nova if exist on the host\n\nSince Queens release Nova support vGPUs. In order to use it,\nnova must have the right configuration. This commit will\nenable vGPU in the nova configuration if some mdev[1] devices\nexist on the compute node.\n\n[1] - https://docs.openstack.org/nova/rocky/admin/virtual-gpu.html#how-to-discover-a-gpu-type\n\nChange-Id: Ia30b1a4fe38eb966f029f16142b8302707107bfc\nSigned-off-by: Valentin Boucher <valentin.boucher@kontron.com>\n(cherry picked from commit 4d3fb82ab476102aaa98b0589f336ad6bce09675)\n'}, {'number': 3, 'created': '2018-09-27 07:36:33.000000000', 'files': ['tasks/main.yml', 'templates/nova.conf.j2', 'tasks/nova_vgpu_detect.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/72e030bf2eb9f1a0f386779b53beaff422a0f632', 'message': 'Compute: Enable vGPU in Nova if exist on the host\n\nSince Queens release Nova support vGPUs. In order to use it,\nnova must have the right configuration. This commit will\nenable vGPU in the nova configuration if some mdev[1] devices\nexist on the compute node.\n\n[1] - https://docs.openstack.org/nova/rocky/admin/virtual-gpu.html#how-to-discover-a-gpu-type\n\nChange-Id: Ia30b1a4fe38eb966f029f16142b8302707107bfc\nSigned-off-by: Valentin Boucher <valentin.boucher@kontron.com>\n(cherry picked from commit 4d3fb82ab476102aaa98b0589f336ad6bce09675)\n'}]",0,603928,72e030bf2eb9f1a0f386779b53beaff422a0f632,12,4,3,6816,,,0,"Compute: Enable vGPU in Nova if exist on the host

Since Queens release Nova support vGPUs. In order to use it,
nova must have the right configuration. This commit will
enable vGPU in the nova configuration if some mdev[1] devices
exist on the compute node.

[1] - https://docs.openstack.org/nova/rocky/admin/virtual-gpu.html#how-to-discover-a-gpu-type

Change-Id: Ia30b1a4fe38eb966f029f16142b8302707107bfc
Signed-off-by: Valentin Boucher <valentin.boucher@kontron.com>
(cherry picked from commit 4d3fb82ab476102aaa98b0589f336ad6bce09675)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/28/603928/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/main.yml', 'templates/nova.conf.j2', 'tasks/nova_vgpu_detect.yml']",3,ba3ee8c700257b3b72a06a044d1f1dd69dcfef92,bp/osa-vgpu-stable/rocky,"--- # Copyright 2018, Kontron. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. - name: Check if the mdev folder exist stat: path=/sys/class/mdev_bus register: mdev_folder - name: Get mdev info content and store as var command: ""/bin/sh -c 'ls -1 /sys/class/mdev_bus/*/mdev_supported_types'"" register: mdev when: mdev_folder.stat.exists - name: Register a fact for nova enabled_vgpu_types set_fact: enabled_vgpu_types: ""{{ mdev.stdout_lines | unique }}"" when: - mdev.stdout_lines is defined - mdev.stdout_lines | length > 0 ",,40,0
openstack%2Fopenstack-helm-infra~master~I3eb28a037f7eb22016a29bc36e4a791a5bfda852,openstack/openstack-helm-infra,master,I3eb28a037f7eb22016a29bc36e4a791a5bfda852,Helm: Update helm to 2.11.0,MERGED,2018-09-25 18:12:21.000000000,2018-09-27 15:35:52.000000000,2018-09-27 15:35:52.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 20469}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}]","[{'number': 1, 'created': '2018-09-25 18:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/595472c37eb576d4dc341c047b43290ab29f3d0d', 'message': 'Helm: Update helm to 2.11.0\n\nThis helps to fix a bug when adding stable repos\n\nChange-Id: I3eb28a037f7eb22016a29bc36e4a791a5bfda852\n'}, {'number': 2, 'created': '2018-09-25 18:15:01.000000000', 'files': ['tools/images/kubeadm-aio/Dockerfile', 'tiller/values.yaml', 'roles/build-images/defaults/main.yml', 'roles/build-helm-packages/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e155c92f14664a0ba50239cb50289c3fd1203630', 'message': 'Helm: Update helm to 2.11.0\n\nThis helps to fix a bug when adding stable repos\n\nChange-Id: I3eb28a037f7eb22016a29bc36e4a791a5bfda852\n'}]",0,605162,e155c92f14664a0ba50239cb50289c3fd1203630,11,8,2,27950,,,0,"Helm: Update helm to 2.11.0

This helps to fix a bug when adding stable repos

Change-Id: I3eb28a037f7eb22016a29bc36e4a791a5bfda852
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/62/605162/1 && git format-patch -1 --stdout FETCH_HEAD,[],0,595472c37eb576d4dc341c047b43290ab29f3d0d,helm/update,,,0,0
openstack%2Freleases~master~I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7,openstack/releases,master,I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7,Release ovsdbapp for stable branches,MERGED,2018-09-27 09:17:22.000000000,2018-09-27 15:33:11.000000000,2018-09-27 15:33:11.000000000,"[{'_account_id': 841}, {'_account_id': 2472}, {'_account_id': 4694}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-09-27 09:17:22.000000000', 'files': ['deliverables/rocky/ovsdbapp.yaml', 'deliverables/queens/ovsdbapp.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/de9c02738f4a7a86615b7451a1f05cb0b73e6a46', 'message': 'Release ovsdbapp for stable branches\n\nThis patch is pushing a new release for the ovsdbapp library for Rocky\n(version 0.12.2) and Queens (version 0.10.2).\n\nBoth branches includes a important fix that prevents race conditions\nbetween multiple transactions [0][1].\n\n[0] https://review.openstack.org/#/c/604301/ (Rocky)\n[1] https://review.openstack.org/#/c/604302/ (Queens)\n\nChange-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7\n'}]",0,605627,de9c02738f4a7a86615b7451a1f05cb0b73e6a46,8,6,1,6773,,,0,"Release ovsdbapp for stable branches

This patch is pushing a new release for the ovsdbapp library for Rocky
(version 0.12.2) and Queens (version 0.10.2).

Both branches includes a important fix that prevents race conditions
between multiple transactions [0][1].

[0] https://review.openstack.org/#/c/604301/ (Rocky)
[1] https://review.openstack.org/#/c/604302/ (Queens)

Change-Id: I6c7bb70d4b446c2dbbe45f1137db74eefa5ad5f7
",git fetch https://review.opendev.org/openstack/releases refs/changes/27/605627/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/rocky/ovsdbapp.yaml', 'deliverables/queens/ovsdbapp.yaml']",2,de9c02738f4a7a86615b7451a1f05cb0b73e6a46,ovsdbapp-stable, - version: 0.10.2 projects: - repo: openstack/ovsdbapp hash: 1477c6cee6e3a192a897f50ae51100545fecd0ff,,8,0
openstack%2Freleases~master~I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9,openstack/releases,master,I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9,openstackdocstheme 1.25.0,MERGED,2018-09-27 08:59:22.000000000,2018-09-27 15:26:49.000000000,2018-09-27 15:26:49.000000000,"[{'_account_id': 2472}, {'_account_id': 11904}, {'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 08:59:22.000000000', 'files': ['deliverables/_independent/openstackdocstheme.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/b10050cf031898b32e11bdabbf2c5a4f352259b3', 'message': 'openstackdocstheme 1.25.0\n\nNew release to expose new features to be used by the\ngovernance.o.o collection of websites, allowing them\nto stop using an old fork of openstackdocstheme.\n\nChange-Id: I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9\n'}]",0,605623,b10050cf031898b32e11bdabbf2c5a4f352259b3,7,4,1,308,,,0,"openstackdocstheme 1.25.0

New release to expose new features to be used by the
governance.o.o collection of websites, allowing them
to stop using an old fork of openstackdocstheme.

Change-Id: I643a6a88eb7563cb9e48d77c08f3adb69a8c11b9
",git fetch https://review.opendev.org/openstack/releases refs/changes/23/605623/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/openstackdocstheme.yaml'],1,b10050cf031898b32e11bdabbf2c5a4f352259b3,openstackdocstheme, - projects: - hash: c3bf0d1f626670c4d991468621aff9fea7e66f54 repo: openstack/openstackdocstheme version: 1.25.0,,4,0
openstack%2Fopenstack-ansible-galera_server~master~Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,openstack/openstack-ansible-galera_server,master,Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d,Enable the xinetd service for reboot,MERGED,2018-09-26 18:22:05.000000000,2018-09-27 15:21:21.000000000,2018-09-27 03:33:30.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 17799}, {'_account_id': 19298}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 18:22:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/f77a8bdc5b005aff2761c0e627ac0535b8438837', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinted service should get\nstarted. Otherwise the haproxy health check will fail.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n'}, {'number': 2, 'created': '2018-09-26 18:24:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/e307af592307d6a3bd7f94d20345ab226df3cbd8', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinetd service should be\nstarted. Otherwise the haproxy health check will fail and haproxy will\nnot forward database connections.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n'}, {'number': 3, 'created': '2018-09-26 18:58:24.000000000', 'files': ['tasks/galera_post_install.yml', 'handlers/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/9fee5107c24880c8365cc2c1905a804cb86ee770', 'message': 'Enable the xinetd service for reboot\n\nIf the Galera container is rebooted, the xinetd service should be\nstarted. Otherwise the haproxy health check will fail and haproxy will\nnot forward database connections.\n\nChange-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d\n'}]",4,605500,9fee5107c24880c8365cc2c1905a804cb86ee770,17,5,3,19298,,,0,"Enable the xinetd service for reboot

If the Galera container is rebooted, the xinetd service should be
started. Otherwise the haproxy health check will fail and haproxy will
not forward database connections.

Change-Id: Iefa7b72ea1fa6743fb8486af663512c2ffe1c31d
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/00/605500/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/galera_post_install.yml'],1,f77a8bdc5b005aff2761c0e627ac0535b8438837,enable_xinetd,- name: Enable xinetd service service: name: xinetd enabled: yes ,,5,0
openstack%2Fkolla~master~I791e479ba265ba61ffd882da18f85cdbece67e55,openstack/kolla,master,I791e479ba265ba61ffd882da18f85cdbece67e55,ceph: stick to luminous on Ubuntu (in proper way),MERGED,2018-09-27 06:07:56.000000000,2018-09-27 15:07:03.000000000,2018-09-27 14:53:16.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 24250}]","[{'number': 1, 'created': '2018-09-27 06:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/d64bdcee242a6a27b830e6cfd9aca02c803d4ab3', 'message': 'Fix ceph version in debian\n\nIn order to fix the ceph version in ubuntu, we specified the specific\nversion to be installed, but this version is not consistent in debian,\nso the debian ceph build failed.\nThis patch fixes this problem by modifying the specified ceph version\nas a regular expression.\n\nChange-Id: I791e479ba265ba61ffd882da18f85cdbece67e55\n'}, {'number': 2, 'created': '2018-09-27 07:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/37c4d9621998ce7ee80f440d4b9cbf8d71345a79', 'message': 'ceph: stick to luminous on Ubuntu (in proper way)\n\nPrevious attempt broke Debian builds.\n\nPinning Ceph packages instead of giving version during install.\n\nChange-Id: I791e479ba265ba61ffd882da18f85cdbece67e55\n'}, {'number': 3, 'created': '2018-09-27 09:06:26.000000000', 'files': ['docker/ceph/ceph-base/Dockerfile.j2', 'docker/base/apt_preferences.ubuntu'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7826ba2984911d894ff188be476bc6691290ebc8', 'message': 'ceph: stick to luminous on Ubuntu (in proper way)\n\nPrevious attempt broke Debian builds.\n\nPinning Ceph packages instead of giving version during install.\n\nChange-Id: I791e479ba265ba61ffd882da18f85cdbece67e55\n'}]",0,605592,7826ba2984911d894ff188be476bc6691290ebc8,14,5,3,24250,,,0,"ceph: stick to luminous on Ubuntu (in proper way)

Previous attempt broke Debian builds.

Pinning Ceph packages instead of giving version during install.

Change-Id: I791e479ba265ba61ffd882da18f85cdbece67e55
",git fetch https://review.opendev.org/openstack/kolla refs/changes/92/605592/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/ceph/ceph-base/Dockerfile.j2'],1,d64bdcee242a6a27b830e6cfd9aca02c803d4ab3,stick-luminous-ubuntu," 'ceph=12.2.*', 'ceph-mgr=12.2.*', 'ceph-mon=12.2.*', 'ceph-osd=12.2.*', 'ceph-mds=12.2.*', 'ceph-base=12.2.*', 'ceph-common=12.2.*', 'librbd1=12.2.*', 'python-cephfs=12.2.*', 'python-rados=12.2.*', 'python-rbd=12.2.*', 'libcephfs2=12.2.*', 'librados2=12.2.*', 'libradosstriper1=12.2.*', 'radosgw=12.2.*', 'librgw2=12.2.*', 'ceph-fuse=12.2.*'"," 'ceph=12.2.4-0ubuntu1', 'ceph-mgr=12.2.4-0ubuntu1', 'ceph-mon=12.2.4-0ubuntu1', 'ceph-osd=12.2.4-0ubuntu1', 'ceph-mds=12.2.4-0ubuntu1', 'ceph-base=12.2.4-0ubuntu1', 'ceph-common=12.2.4-0ubuntu1', 'librbd1=12.2.4-0ubuntu1', 'python-cephfs=12.2.4-0ubuntu1', 'python-rados=12.2.4-0ubuntu1', 'python-rbd=12.2.4-0ubuntu1', 'libcephfs2=12.2.4-0ubuntu1', 'librados2=12.2.4-0ubuntu1', 'libradosstriper1=12.2.4-0ubuntu1', 'radosgw=12.2.4-0ubuntu1', 'librgw2=12.2.4-0ubuntu1', 'ceph-fuse'",17,17
openstack%2Fopenstack-ansible-os_ceilometer~master~Id720f106a4ed3325a24007bc6cb293e359ac4968,openstack/openstack-ansible-os_ceilometer,master,Id720f106a4ed3325a24007bc6cb293e359ac4968,Remove skip-metering-database deprecated param from ceilometer-upgrade,MERGED,2018-09-27 06:59:55.000000000,2018-09-27 15:04:39.000000000,2018-09-27 15:02:50.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 17068}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2018-09-27 06:59:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/0636c8a7f2af386f755ab30d3e65ec367cefb5cd', 'message': 'Remove deprecated param from ceilometer-upgrade\n\nFixes #1794680\n\nThe param has been removed in ceilometer in commit 9323f07f977f320882f8b536c3b54835274826fc\n\nChange-Id: Id720f106a4ed3325a24007bc6cb293e359ac4968\n'}, {'number': 2, 'created': '2018-09-27 09:17:45.000000000', 'files': ['tasks/ceilometer_db_setup.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/866790e315eb3563326be8bba9565dca4c6075d0', 'message': 'Remove skip-metering-database deprecated param from ceilometer-upgrade\n\nThe task fails to run because it has an unrecognized argument.\n\nThis param has been removed in ceilometer in commit \n9323f07f977f320882f8b536c3b54835274826fc\n\nCloses-Bug: #1794680\nChange-Id: Id720f106a4ed3325a24007bc6cb293e359ac4968\n'}]",1,605601,866790e315eb3563326be8bba9565dca4c6075d0,13,5,2,22018,,,0,"Remove skip-metering-database deprecated param from ceilometer-upgrade

The task fails to run because it has an unrecognized argument.

This param has been removed in ceilometer in commit 
9323f07f977f320882f8b536c3b54835274826fc

Closes-Bug: #1794680
Change-Id: Id720f106a4ed3325a24007bc6cb293e359ac4968
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/01/605601/2 && git format-patch -1 --stdout FETCH_HEAD,['tasks/ceilometer_db_setup.yml'],1,0636c8a7f2af386f755ab30d3e65ec367cefb5cd,," command: ""{{ ceilometer_bin }}/ceilometer-upgrade"""," command: ""{{ ceilometer_bin }}/ceilometer-upgrade --skip-metering-database""",1,1
openstack%2Fpatrole~master~Iafbdac8c0637c2ee7ec20b9d8bbe3f733e1ae454,openstack/patrole,master,Iafbdac8c0637c2ee7ec20b9d8bbe3f733e1ae454,Add IP Available test cases for RBAC.,ABANDONED,2018-09-21 10:53:34.000000000,2018-09-27 15:01:00.000000000,,"[{'_account_id': 5690}, {'_account_id': 5803}, {'_account_id': 6167}, {'_account_id': 7350}, {'_account_id': 8556}, {'_account_id': 16274}, {'_account_id': 18256}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 27589}, {'_account_id': 27977}]","[{'number': 1, 'created': '2018-09-21 10:53:34.000000000', 'files': ['patrole_tempest_plugin/tests/api/network/test_ip_availability_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/589d0781094947b918fe6bc16315899b13ba7b1c', 'message': ""Add IP Available test cases for RBAC.\n\nThis commit includes IP available tests cases for RBAC\nThe operations are\n1- List available IP's\n2- Show available IP's for a given network-ID\n\nThis commit is dependent on a commit of tempest\nhttps://review.openstack.org/#/c/603836/\n\nChange-Id: Iafbdac8c0637c2ee7ec20b9d8bbe3f733e1ae454\n""}]",0,604328,589d0781094947b918fe6bc16315899b13ba7b1c,4,11,1,27977,,,0,"Add IP Available test cases for RBAC.

This commit includes IP available tests cases for RBAC
The operations are
1- List available IP's
2- Show available IP's for a given network-ID

This commit is dependent on a commit of tempest
https://review.openstack.org/#/c/603836/

Change-Id: Iafbdac8c0637c2ee7ec20b9d8bbe3f733e1ae454
",git fetch https://review.opendev.org/openstack/patrole refs/changes/28/604328/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/network/test_ip_availability_rbac.py'],1,589d0781094947b918fe6bc16315899b13ba7b1c,,"# Copyright 2018 AT&T Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest import config from tempest.lib import decorators from patrole_tempest_plugin import rbac_exceptions from patrole_tempest_plugin import rbac_rule_validation from patrole_tempest_plugin.tests.api.network import rbac_base as base CONF = config.CONF class IPAvailabilityRbacTest(base.BaseNetworkRbacTest): @classmethod def resource_setup(cls): super(IPAvailabilityRbacTest, cls).resource_setup() cls.network = cls.create_network() cls.subnet = cls.create_subnet(cls.network, enable_dhcp=False) def _list_available_ip(self): body = self.ip_availability_client.\ list_available_ip(self.network['project_id']) return body def _show_available_ip(self): self.ip_availability_client.\ show_available_ip(self.network['id']) @rbac_rule_validation.action(service=""neutron"", rule=""get_network_ip_availability"") @decorators.idempotent_id('7d77d4da-bcc8-11e8-88fc-080027994ea3') def test_list_available_ip(self): """"""List available IPs. RBAC test for the neutron list available ip policy """""" available_ips = dict() with self.rbac_utils.override_role(self): available_ips = self._list_available_ip() # Rather than throwing a 403, # It returns an empty list of available IPs, so raise exc. if not available_ips['network_ip_availabilities']: raise rbac_exceptions.RbacMalformedResponse( attribute='network_ip_availabilities') @rbac_rule_validation.action(service=""neutron"", rules=[""get_network_ip_availability""], expected_error_codes=[404]) @decorators.idempotent_id('7d77d4da-bcc8-11e8-88fc-080027994ea3') def test_show_available_ip(self): """"""List available IPs. RBAC test for the neutron list available ip policy """""" with self.rbac_utils.override_role(self): self._show_available_ip() ",,71,0
openstack%2Ftempest~master~Ia53cf714aa8c349b77b605edffb8bfafa357a77d,openstack/tempest,master,Ia53cf714aa8c349b77b605edffb8bfafa357a77d,Add network ip availability client,ABANDONED,2018-09-19 16:00:17.000000000,2018-09-27 15:00:11.000000000,,"[{'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 22348}, {'_account_id': 23186}, {'_account_id': 27078}, {'_account_id': 27977}]","[{'number': 1, 'created': '2018-09-19 16:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/ee447e4d975787cbaf0910216fba99c01a45046d', 'message': 'Add network ip availability client\n\nThis patch creates the network v2.0 ip available client.\nThis client has only two api calls\n1- List ip available.\n2- Show the IP availables for a given network.\n\nThis patch also includes tests for the new ip available client.\n\nChange-Id: Ia53cf714aa8c349b77b605edffb8bfafa357a77d\n'}, {'number': 2, 'created': '2018-09-20 10:34:35.000000000', 'files': ['tempest/api/network/test_ip_availability.py', 'tempest/lib/services/network/__init__.py', 'tempest/tests/lib/services/network/test_ip_availability.py', 'tempest/clients.py', 'tempest/api/network/base.py', 'tempest/lib/services/network/ip_availability_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/6aca350cf1c4f0c5e3b3ea67b455a026cebd511b', 'message': 'Add network ip availability client\n\nThis patch creates the network v2.0 ip available client.\nThis client has only two api calls\n1- List ip available.\n2- Show the IP availables for a given network.\n\nThis patch also includes tests for the new ip available client.\n\nChange-Id: Ia53cf714aa8c349b77b605edffb8bfafa357a77d\n'}]",15,603836,6aca350cf1c4f0c5e3b3ea67b455a026cebd511b,14,9,2,27977,,,0,"Add network ip availability client

This patch creates the network v2.0 ip available client.
This client has only two api calls
1- List ip available.
2- Show the IP availables for a given network.

This patch also includes tests for the new ip available client.

Change-Id: Ia53cf714aa8c349b77b605edffb8bfafa357a77d
",git fetch https://review.opendev.org/openstack/tempest refs/changes/36/603836/1 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/network/test_ip_availability.py', 'tempest/lib/services/network/__init__.py', 'tempest/tests/lib/services/network/test_ip_availability.py', 'tempest/clients.py', 'tempest/api/network/base.py', 'tempest/lib/services/network/ip_availability_client.py']",6,ee447e4d975787cbaf0910216fba99c01a45046d,,"# Copyright 2018 AT&T Corporation. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from tempest.lib.services.network import base from tempest.lib.common import rest_client class IpAvailabilityClient(base.BaseNetworkClient): def list_available_ip(self, project_id): """"""List the available IPs."""""" uri = ""/network-ip-availabilities?ip_version=4&tenant_id={}"".\ format(project_id) return self.list_resources(uri) def show_available_ip(self, network_id): """"""Show the available IPs."""""" uri = ""/network-ip-availabilities/{}"".\ format(network_id) return self.list_resources(uri) ",,150,3
openstack%2Fplacement~master~I9da3075812138da71f95c9ebc733a1f3f1fcb687,openstack/placement,master,I9da3075812138da71f95c9ebc733a1f3f1fcb687,nova.context -> placement.context in doc strings,MERGED,2018-09-15 17:51:14.000000000,2018-09-27 14:59:38.000000000,2018-09-27 14:59:38.000000000,"[{'_account_id': 7}, {'_account_id': 7634}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 25625}]","[{'number': 1, 'created': '2018-09-15 17:51:14.000000000', 'files': ['placement/resource_class_cache.py', 'placement/objects/consumer.py', 'placement/objects/resource_provider.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/0c132f262b649dffb3ea57322e8bbd93e42e3346', 'message': 'nova.context -> placement.context in doc strings\n\nPlacement has used its own context for a long time, but the\ndocstrings were not kept up to date. Now is a good time to\nclean it up.\n\nChange-Id: I9da3075812138da71f95c9ebc733a1f3f1fcb687\n'}]",0,602873,0c132f262b649dffb3ea57322e8bbd93e42e3346,9,5,1,11564,,,0,"nova.context -> placement.context in doc strings

Placement has used its own context for a long time, but the
docstrings were not kept up to date. Now is a good time to
clean it up.

Change-Id: I9da3075812138da71f95c9ebc733a1f3f1fcb687
",git fetch https://review.opendev.org/openstack/placement refs/changes/73/602873/1 && git format-patch -1 --stdout FETCH_HEAD,"['placement/resource_class_cache.py', 'placement/objects/consumer.py', 'placement/objects/resource_provider.py']",3,0c132f262b649dffb3ea57322e8bbd93e42e3346,cd/de-nova-context, :param ctx: `placement.context.RequestContext` that may be used to grab a DB connection. :param ctx: `placement.context.RequestContext` that may be used to grab a DB connection. :param ctx: `placement.context.RequestContext` that may be used to grab a DB connection. :param ctx: `placement.context.RequestContext` that may be used to grab a DB connection. :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param ctx: `placement.context.RequestContext` that contains an oslo_db Session :param ctx: `placement.context.RequestContext` that has an oslo_db Session :param ctx: `placement.context.RequestContext` that has an oslo_db Session :param context: `placement.context.RequestContext` that may be used to grab a DB connection. :param ctx: `placement.context.RequestContext` that has an oslo_db Session :param ctx: placement.context.RequestContext object :param context: placement.context.RequestContext object :param ctx: placement.context.RequestContext object :param ctx: placement.context.RequestContext object :param ctx: placement.context.RequestContext object :param ctx: placement.context.RequestContext object :param ctx: placement.context.RequestContext object :param ctx: placement.context.RequestContext object, :param ctx: `nova.context.RequestContext` that may be used to grab a DB connection. :param ctx: `nova.context.RequestContext` that may be used to grab a DB connection. :param ctx: `nova.context.RequestContext` that may be used to grab a DB connection. :param ctx: `nova.context.RequestContext` that may be used to grab a DB connection. :param ctx: `nova.context.RequestContext` that contains an oslo_db Session :param ctx: `nova.context.RequestContext` that contains an oslo_db Session :param ctx: `nova.context.RequestContext` that contains an oslo_db Session :param ctx: `nova.context.RequestContext` that contains an oslo_db Session :param ctx: `nova.context.RequestContext` that has an oslo_db Session :param ctx: `nova.context.RequestContext` that has an oslo_db Session :param context: `nova.context.RequestContext` that may be used to grab a DB connection. :param ctx: `nova.context.RequestContext` that has an oslo_db Session :param ctx: nova.context.RequestContext object :param context: nova.context.RequestContext object :param ctx: nova.context.RequestContext object :param ctx: nova.context.RequestContext object :param ctx: nova.context.RequestContext object :param ctx: nova.context.RequestContext object :param ctx: nova.context.RequestContext object :param ctx: nova.context.RequestContext object,35,28
openstack%2Fkayobe~master~Ia200a5b0de42963643980bdfd3677e3fca833850,openstack/kayobe,master,Ia200a5b0de42963643980bdfd3677e3fca833850,Support custom config for Barbican,MERGED,2018-09-26 14:09:25.000000000,2018-09-27 14:58:49.000000000,2018-09-27 14:58:49.000000000,"[{'_account_id': 14826}, {'_account_id': 16984}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 14:09:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe/commit/072b2707c5bf202fcd0290550c8f0a5bf08b23db', 'message': 'Support custom config for Barbican\n\nStory: 2003880\nTask: 26741\nChange-Id: Ia200a5b0de42963643980bdfd3677e3fca833850\n'}, {'number': 2, 'created': '2018-09-27 10:19:30.000000000', 'files': ['ansible/roles/kolla-openstack/vars/main.yml', 'releasenotes/notes/add_support_for_custom_barbican_conf-b94272d73d53aa87.yaml', 'ansible/roles/kolla-openstack/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/53ee8293cd09716b935ec14df942af253add01c7', 'message': 'Support custom config for Barbican\n\nStory: 2003880\nTask: 26741\nChange-Id: Ia200a5b0de42963643980bdfd3677e3fca833850\n'}]",0,605433,53ee8293cd09716b935ec14df942af253add01c7,11,3,2,17669,,,0,"Support custom config for Barbican

Story: 2003880
Task: 26741
Change-Id: Ia200a5b0de42963643980bdfd3677e3fca833850
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/33/605433/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/kolla-openstack/vars/main.yml', 'releasenotes/notes/add_support_for_custom_barbican_conf-b94272d73d53aa87.yaml']",2,072b2707c5bf202fcd0290550c8f0a5bf08b23db,,--- features: - Adds support for custom Barbican configuration. ,,8,0
openstack%2Fcookbook-openstack-application-catalog~master~Ifbff370dcbb5493cf4f807d13f9a0e50e9f042d7,openstack/cookbook-openstack-application-catalog,master,Ifbff370dcbb5493cf4f807d13f9a0e50e9f042d7,Update the URL in README.md,MERGED,2018-09-23 15:27:33.000000000,2018-09-27 14:46:58.000000000,2018-09-27 14:46:57.000000000,"[{'_account_id': 14790}, {'_account_id': 19193}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-09-23 15:27:33.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/cookbook-openstack-application-catalog/commit/b8c38f3defc9c543f282898a01777c0235914c6f', 'message': 'Update the URL in README.md\n\nChange-Id: Ifbff370dcbb5493cf4f807d13f9a0e50e9f042d7\n'}]",0,604636,b8c38f3defc9c543f282898a01777c0235914c6f,8,4,1,17130,,,0,"Update the URL in README.md

Change-Id: Ifbff370dcbb5493cf4f807d13f9a0e50e9f042d7
",git fetch https://review.opendev.org/openstack/cookbook-openstack-application-catalog refs/changes/36/604636/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,b8c38f3defc9c543f282898a01777c0235914c6f,fix-url,https://docs.openstack.org/murano/latest/,http://docs.openstack.org/developer/murano/,1,1
openstack%2Fkayobe-config-dev~master~If4d7139175c8bb859e5731937c42c8c1356db833,openstack/kayobe-config-dev,master,If4d7139175c8bb859e5731937c42c8c1356db833,Update git review URL,ABANDONED,2018-09-27 14:30:05.000000000,2018-09-27 14:45:29.000000000,,[{'_account_id': 14826}],"[{'number': 1, 'created': '2018-09-27 14:30:05.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/ddaea3f395c46905506dbfbdb7f83cd732d35b67', 'message': 'Update git review URL\n\nthe repository name was changed from dev-kayobe-config to\nkayobe-config-dev when it was moved from the stackhpc\ngithub repository to openstack.\n\nThe symptom was that git review could not locate the\nkayobe-config-dev gerrit.\n\nTrivialFix\n\nChange-Id: If4d7139175c8bb859e5731937c42c8c1356db833\n'}]",0,605752,ddaea3f395c46905506dbfbdb7f83cd732d35b67,3,1,1,28048,,,0,"Update git review URL

the repository name was changed from dev-kayobe-config to
kayobe-config-dev when it was moved from the stackhpc
github repository to openstack.

The symptom was that git review could not locate the
kayobe-config-dev gerrit.

TrivialFix

Change-Id: If4d7139175c8bb859e5731937c42c8c1356db833
",git fetch https://review.opendev.org/openstack/kayobe-config-dev refs/changes/52/605752/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,ddaea3f395c46905506dbfbdb7f83cd732d35b67,gitreview,project=openstack/kayobe-config-dev.git,project=openstack/dev-kayobe-config.git,1,1
openstack%2Fkolla-ansible~master~I6e237438fbc0aa3c89a3c8bd706a53b74e71904b,openstack/kolla-ansible,master,I6e237438fbc0aa3c89a3c8bd706a53b74e71904b,Refactor haproxy config (split by service) V2.0,MERGED,2018-09-11 17:22:30.000000000,2018-09-27 14:44:20.000000000,2018-09-27 14:44:20.000000000,"[{'_account_id': 10273}, {'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 22629}]","[{'number': 1, 'created': '2018-09-11 17:22:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/911d948208a1b3e34ec82d19a681e5d11770cab1', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 2, 'created': '2018-09-13 17:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5fbaef7161c2f725e559dc2015d1375600a4b04e', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 3, 'created': '2018-09-13 19:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1f5856b56f1a96d67842ff23a81bf88afdc3466b', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 4, 'created': '2018-09-13 20:11:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/23a87fe5780b70314f830805aaab846f176fa39f', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 5, 'created': '2018-09-13 20:50:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/db99ce9c652b9d7d9601e9709993208925df53d2', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 6, 'created': '2018-09-16 00:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/126ad9ea6c90466b534ea02bd302e24199728945', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 7, 'created': '2018-09-17 19:14:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/34046da0bf939859f0bf712a2503384965303a55', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 8, 'created': '2018-09-18 18:00:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ac665f0e109db665c61ef2daad4b188436d0cef2', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 9, 'created': '2018-09-18 18:49:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7e766936a83717f6787a137307893b6e563e460a', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 10, 'created': '2018-09-18 20:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2c0c92dce7e84cd8792c279ca2f7c17226104487', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 11, 'created': '2018-09-19 17:16:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8ad30f6ca97acca5185d5eab67555edcac59835d', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 12, 'created': '2018-09-19 21:02:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ddc05797b1961c460539fdb6916b4477efd816c8', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 13, 'created': '2018-09-20 01:30:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/828a31063bed40844a8a5d11bf59b05b72396e3e', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 14, 'created': '2018-09-20 23:07:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/87d2ab6721e833974ff2e1fb2dd7628b666aefc0', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 15, 'created': '2018-09-26 00:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/13a1f5df784bd2188f403cd9d8581eb818ac8542', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}, {'number': 16, 'created': '2018-09-26 10:30:48.000000000', 'files': ['ansible/roles/haproxy/handlers/main.yml', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/designate/tasks/loadbalancer.yml', 'ansible/roles/memcached/tasks/loadbalancer.yml', 'ansible/roles/tacker/tasks/loadbalancer.yml', 'ansible/roles/haproxy/templates/haproxy_run.sh.j2', 'ansible/roles/watcher/tasks/loadbalancer.yml', 'ansible/roles/cloudkitty/defaults/main.yml', 'ansible/roles/haproxy-config/defaults/main.yml', 'ansible/roles/manila/tasks/loadbalancer.yml', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/mistral/tasks/loadbalancer.yml', 'ansible/roles/skydive/defaults/main.yml', 'ansible/roles/trove/tasks/loadbalancer.yml', 'ansible/roles/opendaylight/defaults/main.yml', 'ansible/roles/elasticsearch/defaults/main.yml', 'ansible/roles/cinder/tasks/loadbalancer.yml', 'ansible/roles/haproxy/tasks/config.yml', 'ansible/roles/haproxy/tasks/precheck.yml', 'ansible/roles/mongodb/tasks/loadbalancer.yml', 'ansible/roles/aodh/tasks/loadbalancer.yml', 'ansible/roles/kibana/tasks/loadbalancer.yml', 'ansible/roles/memcached/defaults/main.yml', 'ansible/roles/swift/tasks/loadbalancer.yml', 'ansible/roles/magnum/tasks/loadbalancer.yml', 'ansible/roles/ironic/defaults/main.yml', 'ansible/roles/watcher/defaults/main.yml', 'ansible/roles/freezer/defaults/main.yml', 'ansible/roles/haproxy-config/handlers/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/octavia/tasks/loadbalancer.yml', 'ansible/roles/haproxy/defaults/main.yml', 'ansible/roles/congress/tasks/loadbalancer.yml', 'ansible/roles/cloudkitty/tasks/loadbalancer.yml', 'ansible/roles/solum/tasks/loadbalancer.yml', 'ansible/roles/influxdb/defaults/main.yml', 'ansible/roles/keystone/tasks/loadbalancer.yml', 'ansible/roles/manila/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy.json.j2', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/monasca/defaults/main.yml', 'ansible/roles/influxdb/tasks/loadbalancer.yml', 'ansible/roles/swift/defaults/main.yml', 'ansible/roles/blazar/tasks/loadbalancer.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_listen.cfg.j2', 'ansible/roles/senlin/defaults/main.yml', 'ansible/roles/ceph/tasks/loadbalancer.yml', 'ansible/roles/designate/defaults/main.yml', 'ansible/roles/panko/tasks/loadbalancer.yml', 'ansible/roles/tacker/defaults/main.yml', 'ansible/roles/zun/tasks/loadbalancer.yml', 'ansible/roles/opendaylight/tasks/loadbalancer.yml', 'ansible/roles/karbor/tasks/loadbalancer.yml', 'ansible/roles/octavia/defaults/main.yml', 'ansible/roles/panko/defaults/main.yml', 'ansible/roles/senlin/tasks/loadbalancer.yml', 'ansible/group_vars/all.yml', 'ansible/roles/heat/tasks/loadbalancer.yml', 'ansible/roles/mongodb/defaults/main.yml', 'ansible/roles/horizon/tasks/loadbalancer.yml', 'ansible/roles/horizon/defaults/main.yml', 'ansible/site.yml', 'ansible/roles/grafana/tasks/loadbalancer.yml', 'ansible/roles/cinder/defaults/main.yml', 'ansible/roles/haproxy-config/tasks/main.yml', 'ansible/roles/vitrage/tasks/loadbalancer.yml', 'ansible/roles/congress/defaults/main.yml', 'ansible/roles/blazar/defaults/main.yml', 'ansible/roles/ceph/defaults/main.yml', 'ansible/roles/elasticsearch/tasks/loadbalancer.yml', 'ansible/roles/searchlight/defaults/main.yml', 'ansible/roles/solum/defaults/main.yml', 'ansible/roles/mariadb/defaults/main.yml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/mariadb/tasks/loadbalancer.yml', 'ansible/roles/monasca/tasks/loadbalancer.yml', 'ansible/roles/sahara/defaults/main.yml', 'ansible/roles/barbican/defaults/main.yml', 'ansible/roles/rabbitmq/defaults/main.yml', 'ansible/roles/trove/defaults/main.yml', 'ansible/roles/neutron/tasks/loadbalancer.yml', 'ansible/roles/aodh/defaults/main.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/freezer/tasks/loadbalancer.yml', 'ansible/roles/magnum/defaults/main.yml', 'ansible/roles/zun/defaults/main.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_split.cfg.j2', 'ansible/inventory/multinode', 'ansible/roles/mistral/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy.cfg.j2', 'ansible/roles/nova/tasks/loadbalancer.yml', 'ansible/inventory/all-in-one', 'ansible/roles/ironic/tasks/loadbalancer.yml', 'ansible/roles/prometheus/defaults/main.yml', 'ansible/roles/gnocchi/tasks/loadbalancer.yml', 'ansible/roles/prometheus/tasks/loadbalancer.yml', 'ansible/roles/barbican/tasks/loadbalancer.yml', 'ansible/roles/karbor/defaults/main.yml', 'ansible/roles/skydive/tasks/loadbalancer.yml', 'ansible/roles/vitrage/defaults/main.yml', 'releasenotes/notes/split-haproxy-config-by-service-90c2d89de1829e8a.yaml', 'ansible/roles/gnocchi/defaults/main.yml', 'ansible/roles/murano/tasks/loadbalancer.yml', 'ansible/roles/searchlight/tasks/loadbalancer.yml', 'ansible/roles/sahara/tasks/loadbalancer.yml', 'ansible/roles/rabbitmq/tasks/loadbalancer.yml', 'ansible/roles/kibana/defaults/main.yml', 'ansible/roles/glance/tasks/loadbalancer.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f1c81365562e2e222dbaf97a1f689298582ca127', 'message': 'Refactor haproxy config (split by service) V2.0\n\nHaving all services in one giant haproxy file makes altering\nconfiguration for a service both painful and dangerous. Each service\nshould be configured with a simple set of variables and rendered with a\nsingle unified template.\n\nAvailable are two new templates:\n\n* haproxy_single_service_listen.cfg.j2: close to the original style, but\nonly one service per file\n* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax\nfor separated frontend and backend\n\nFor now the default will be the single listen block, for ease of\ntransition.\n\nChange-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b\n'}]",74,601648,f1c81365562e2e222dbaf97a1f689298582ca127,67,6,16,10273,,,0,"Refactor haproxy config (split by service) V2.0

Having all services in one giant haproxy file makes altering
configuration for a service both painful and dangerous. Each service
should be configured with a simple set of variables and rendered with a
single unified template.

Available are two new templates:

* haproxy_single_service_listen.cfg.j2: close to the original style, but
only one service per file
* haproxy_single_service_split.cfg.j2: using the newer haproxy syntax
for separated frontend and backend

For now the default will be the single listen block, for ease of
transition.

Change-Id: I6e237438fbc0aa3c89a3c8bd706a53b74e71904b
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/48/601648/15 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/haproxy/handlers/main.yml', 'ansible/templates/haproxy_single_service_split.cfg.j2', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/designate/tasks/loadbalancer.yml', 'ansible/roles/memcached/tasks/loadbalancer.yml', 'ansible/roles/tacker/tasks/loadbalancer.yml', 'ansible/roles/haproxy/templates/haproxy_run.sh.j2', 'ansible/roles/watcher/tasks/loadbalancer.yml', 'ansible/roles/cloudkitty/defaults/main.yml', 'ansible/roles/haproxy-config/defaults/main.yml', 'ansible/roles/manila/tasks/loadbalancer.yml', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/mistral/tasks/loadbalancer.yml', 'ansible/roles/skydive/defaults/main.yml', 'ansible/roles/trove/tasks/loadbalancer.yml', 'ansible/roles/opendaylight/defaults/main.yml', 'ansible/roles/elasticsearch/defaults/main.yml', 'ansible/roles/cinder/tasks/loadbalancer.yml', 'ansible/roles/haproxy/tasks/config.yml', 'ansible/roles/mongodb/tasks/loadbalancer.yml', 'ansible/roles/aodh/tasks/loadbalancer.yml', 'ansible/roles/kibana/tasks/loadbalancer.yml', 'ansible/roles/memcached/defaults/main.yml', 'ansible/roles/swift/tasks/loadbalancer.yml', 'ansible/roles/magnum/tasks/loadbalancer.yml', 'ansible/roles/ironic/defaults/main.yml', 'ansible/roles/watcher/defaults/main.yml', 'ansible/roles/freezer/defaults/main.yml', 'ansible/roles/haproxy-config/handlers/main.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/octavia/tasks/loadbalancer.yml', 'ansible/roles/haproxy/defaults/main.yml', 'ansible/roles/congress/tasks/loadbalancer.yml', 'ansible/roles/cloudkitty/tasks/loadbalancer.yml', 'ansible/roles/solum/tasks/loadbalancer.yml', 'ansible/roles/influxdb/defaults/main.yml', 'ansible/roles/keystone/tasks/loadbalancer.yml', 'ansible/roles/manila/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy.json.j2', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/monasca/defaults/main.yml', 'ansible/roles/influxdb/tasks/loadbalancer.yml', 'ansible/roles/swift/defaults/main.yml', 'ansible/roles/blazar/tasks/loadbalancer.yml', 'ansible/roles/senlin/defaults/main.yml', 'ansible/roles/ceph/tasks/loadbalancer.yml', 'ansible/roles/designate/defaults/main.yml', 'ansible/roles/panko/tasks/loadbalancer.yml', 'ansible/roles/tacker/defaults/main.yml', 'ansible/roles/zun/tasks/loadbalancer.yml', 'ansible/roles/opendaylight/tasks/loadbalancer.yml', 'ansible/roles/karbor/tasks/loadbalancer.yml', 'ansible/roles/octavia/defaults/main.yml', 'ansible/roles/panko/defaults/main.yml', 'ansible/roles/senlin/tasks/loadbalancer.yml', 'ansible/roles/heat/tasks/loadbalancer.yml', 'ansible/roles/mongodb/defaults/main.yml', 'ansible/roles/horizon/tasks/loadbalancer.yml', 'ansible/roles/horizon/defaults/main.yml', 'ansible/site.yml', 'ansible/roles/grafana/tasks/loadbalancer.yml', 'ansible/roles/haproxy/tasks/loadbalancer.yml', 'ansible/roles/cinder/defaults/main.yml', 'ansible/roles/haproxy-config/tasks/main.yml', 'ansible/roles/vitrage/tasks/loadbalancer.yml', 'ansible/roles/congress/defaults/main.yml', 'ansible/roles/blazar/defaults/main.yml', 'ansible/roles/ceph/defaults/main.yml', 'ansible/roles/elasticsearch/tasks/loadbalancer.yml', 'ansible/roles/searchlight/defaults/main.yml', 'ansible/roles/solum/defaults/main.yml', 'ansible/roles/mariadb/defaults/main.yml', 'ansible/roles/grafana/defaults/main.yml', 'ansible/roles/mariadb/tasks/loadbalancer.yml', 'ansible/roles/monasca/tasks/loadbalancer.yml', 'ansible/roles/sahara/defaults/main.yml', 'ansible/roles/barbican/defaults/main.yml', 'ansible/roles/rabbitmq/defaults/main.yml', 'ansible/roles/trove/defaults/main.yml', 'ansible/roles/neutron/tasks/loadbalancer.yml', 'ansible/roles/aodh/defaults/main.yml', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/freezer/tasks/loadbalancer.yml', 'ansible/roles/magnum/defaults/main.yml', 'ansible/roles/zun/defaults/main.yml', 'ansible/inventory/multinode', 'ansible/roles/monasca/tasks/config.yml', 'ansible/roles/mistral/defaults/main.yml', 'ansible/roles/haproxy/templates/haproxy.cfg.j2', 'ansible/templates/haproxy_single_service_listen.cfg.j2', 'ansible/roles/nova/tasks/loadbalancer.yml', 'ansible/inventory/all-in-one', 'ansible/roles/ironic/tasks/loadbalancer.yml', 'ansible/roles/prometheus/defaults/main.yml', 'ansible/roles/gnocchi/tasks/loadbalancer.yml', 'ansible/roles/prometheus/tasks/loadbalancer.yml', 'ansible/roles/barbican/tasks/loadbalancer.yml', 'ansible/roles/karbor/defaults/main.yml', 'ansible/roles/skydive/tasks/loadbalancer.yml', 'ansible/roles/vitrage/defaults/main.yml', 'releasenotes/notes/split-haproxy-config-by-service-90c2d89de1829e8a.yaml', 'ansible/roles/gnocchi/defaults/main.yml', 'ansible/roles/murano/tasks/loadbalancer.yml', 'ansible/roles/searchlight/tasks/loadbalancer.yml', 'ansible/roles/sahara/tasks/loadbalancer.yml', 'ansible/roles/rabbitmq/tasks/loadbalancer.yml', 'ansible/roles/kibana/defaults/main.yml', 'ansible/roles/glance/tasks/loadbalancer.yml']",110,911d948208a1b3e34ec82d19a681e5d11770cab1,601648,"--- - name: ""Configure haproxy for {{ project_name }}"" import_role: role: haproxy-config vars: project_services: ""{{ glance_services }}"" tags: always ",,1727,1499
openstack%2Fnetworking-ovn~master~Ib7ccf48a30362b88eb1e852e69c8cc0b3b8fe322,openstack/networking-ovn,master,Ib7ccf48a30362b88eb1e852e69c8cc0b3b8fe322,Update reno for stable/rocky,MERGED,2018-08-09 21:52:22.000000000,2018-09-27 14:43:45.000000000,2018-09-27 14:43:45.000000000,"[{'_account_id': 6773}, {'_account_id': 8788}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2018-08-09 21:52:22.000000000', 'files': ['releasenotes/source/index.rst', 'releasenotes/source/rocky.rst'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/47028423141accc09c11c68c9100d3059c940b62', 'message': 'Update reno for stable/rocky\n\nChange-Id: Ib7ccf48a30362b88eb1e852e69c8cc0b3b8fe322\n'}]",2,590558,47028423141accc09c11c68c9100d3059c940b62,11,4,1,22816,,,0,"Update reno for stable/rocky

Change-Id: Ib7ccf48a30362b88eb1e852e69c8cc0b3b8fe322
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/58/590558/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/index.rst', 'releasenotes/source/rocky.rst']",2,47028423141accc09c11c68c9100d3059c940b62,reno-rocky,=================================== Rocky Series Release Notes =================================== .. release-notes:: :branch: stable/rocky ,,7,0
openstack%2Foctavia~stable%2Frocky~Ic110e0e73938743c1aba01aa28f393bae7141cbd,openstack/octavia,stable/rocky,Ic110e0e73938743c1aba01aa28f393bae7141cbd,Fix the API list performance regression,MERGED,2018-09-27 02:28:49.000000000,2018-09-27 14:39:36.000000000,2018-09-27 14:39:36.000000000,"[{'_account_id': 6469}, {'_account_id': 6579}, {'_account_id': 9531}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 02:28:49.000000000', 'files': ['octavia/api/v2/controllers/load_balancer.py', 'octavia/db/models.py', 'octavia/api/v2/controllers/pool.py', 'octavia/db/repositories.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/api/v2/controllers/l7rule.py', 'octavia/api/v2/controllers/member.py', 'octavia/api/v2/controllers/amphora.py', 'octavia/api/v2/controllers/health_monitor.py', 'releasenotes/notes/fix-API-list-performance-3b121deffbc3ce4a.yaml', 'octavia/api/v2/controllers/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/d3f8b566ae231c2903336dbb90e7df1341a31cb9', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n(cherry picked from commit f15b43ddf432d9c320db73325abe042b65df3970)\n'}]",0,605570,d3f8b566ae231c2903336dbb90e7df1341a31cb9,8,7,1,28329,,,0,"Fix the API list performance regression

This patch fixes the Octavia v2 API ""list"" performance regression.

It also corrects some database model forward reference issues.

Co-Authored-By: Adam Harwell <flux.adam@gmail.com>
Change-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd
Story: 2002933
Task: 22920
(cherry picked from commit f15b43ddf432d9c320db73325abe042b65df3970)
",git fetch https://review.opendev.org/openstack/octavia refs/changes/70/605570/1 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/api/v2/controllers/load_balancer.py', 'octavia/api/v2/controllers/pool.py', 'octavia/db/models.py', 'octavia/db/repositories.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/api/v2/controllers/l7rule.py', 'octavia/api/v2/controllers/member.py', 'octavia/api/v2/controllers/amphora.py', 'octavia/api/v2/controllers/health_monitor.py', 'releasenotes/notes/fix-API-list-performance-3b121deffbc3ce4a.yaml', 'octavia/api/v2/controllers/listener.py']",11,d3f8b566ae231c2903336dbb90e7df1341a31cb9,," db_listeners, links = self.repositories.listener.get_all_API_list("," db_listeners, links = self.repositories.listener.get_all(",265,54
openstack%2Fnova~master~I99427a52676826990d2a2ffc82cf30ad945b939c,openstack/nova,master,I99427a52676826990d2a2ffc82cf30ad945b939c,consumer gen: more tests for delete allocation cases,MERGED,2018-08-14 18:15:58.000000000,2018-09-27 14:38:56.000000000,2018-09-27 14:38:55.000000000,"[{'_account_id': 7}, {'_account_id': 6167}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-08-14 18:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4b68c86d306aa74e563d2205b4b8f4cfd1840b66', 'message': ""consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these paths for both the successful retry and the failed retry cases.\n\nTODO:\n* the functional test shows that if the deletion of the source\n  allocation of a confirmed migration fails then nova puts the instance\n  to ERROR state. We could put the instance to VERIFY_RESIZE state and\n  let the API user retry the confirm.\n* Also in the above case if the instance is in ERROR state is deleted\n  then nova leaks the migration allocation on the source host. This\n  needs to be fixed.\n* Similarly in case of live migration if nova fails do delete the\n  allocation on the source host after the migration is finished the\n  instance is put to ERROR state. Here we don't have a way to put it any\n  other intermittent state. However in this case the live migration was\n  successful from the end user perspective so the ERROR case might be\n  too much.\n* Also in the above case if the instance in ERROR state is deleted then\n  nova leaks the migration allocation on the source host. This needs to\n  be fixed.\n\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n""}, {'number': 2, 'created': '2018-08-15 08:07:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6e88adcac9663b1c580797593130610e4cdeba55', 'message': ""consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these paths for both the successful retry and the failed retry cases.\n\nTODO:\n* the functional test shows that if the deletion of the source\n  allocation of a confirmed migration fails then nova puts the instance\n  to ERROR state. We could put the instance to VERIFY_RESIZE state and\n  let the API user retry the confirm.\n* Also in the above case if the instance is in ERROR state is deleted\n  then nova leaks the migration allocation on the source host. This\n  needs to be fixed.\n* Similarly in case of live migration if nova fails do delete the\n  allocation on the source host after the migration is finished the\n  instance is put to ERROR state. Here we don't have a way to put it any\n  other intermittent state. However in this case the live migration was\n  successful from the end user perspective so the ERROR case might be\n  too much.\n* Also in the above case if the instance in ERROR state is deleted then\n  nova leaks the migration allocation on the source host. This needs to\n  be fixed.\n\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n""}, {'number': 3, 'created': '2018-09-13 16:29:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/25a4b3754f74b3b76fd8e35f83725b9307c04e55', 'message': 'consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these code paths.\n\nIf the deletion of the source allocation of a confirmed migration fails\nthen nova puts the instance to ERROR state. The instance still has two\nallocations in this state and deleting the instance only deletes the one that\nis held by the instance_uuid. This patch logs an ERROR describing that in this\ncase the allocation held by the migration_uuid is leaked. The same true\nfor live migration failing to delete allocaton on the source host.\n\nTODO:\n* Add a release notes explaining the possible leaks.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n'}, {'number': 4, 'created': '2018-09-17 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0599893c48ebf0a9a964714791cecd8b70d89885', 'message': 'consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these code paths.\n\nIf the deletion of the source allocation of a confirmed migration fails\nthen nova puts the instance to ERROR state. The instance still has two\nallocations in this state and deleting the instance only deletes the one that\nis held by the instance_uuid. This patch logs an ERROR describing that in this\ncase the allocation held by the migration_uuid is leaked. The same true\nfor live migration failing to delete allocaton on the source host.\n\nTODO:\n* Add a release notes explaining the possible leaks.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n'}, {'number': 5, 'created': '2018-09-26 09:01:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb866be9febbcff9fac0b03e2515ec95bee29b42', 'message': 'consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these code paths.\n\nIf the deletion of the source allocation of a confirmed migration fails\nthen nova puts the instance to ERROR state. The instance still has two\nallocations in this state and deleting the instance only deletes the one that\nis held by the instance_uuid. This patch logs an ERROR describing that in this\ncase the allocation held by the migration_uuid is leaked. The same true\nfor live migration failing to delete allocaton on the source host.\n\nAs this makes every caller of _delete_allocation_after_move logging the\nsame error for AllocationDeleteFailed exception this patch moves that logging\ninto _delete_allocation_after_move.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n'}, {'number': 6, 'created': '2018-09-26 12:31:36.000000000', 'files': ['releasenotes/notes/leaking_migration_allocations_in_placement-bd0a6f2a30e2e3d2.yaml', 'nova/compute/manager.py', 'nova/tests/functional/test_servers.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/3a43a931d4e46a0aa66683da22482f3e78f26cd7', 'message': 'consumer gen: more tests for delete allocation cases\n\nUser confirming migration as well as a successfull live migration also\ntriggers the delete allocation code path. This patch adds test coverage\nfor these code paths.\n\nIf the deletion of the source allocation of a confirmed migration fails\nthen nova puts the instance to ERROR state. The instance still has two\nallocations in this state and deleting the instance only deletes the one that\nis held by the instance_uuid. This patch logs an ERROR describing that in this\ncase the allocation held by the migration_uuid is leaked. The same true\nfor live migration failing to delete allocaton on the source host.\n\nAs this makes every caller of _delete_allocation_after_move logging the\nsame error for AllocationDeleteFailed exception this patch moves that logging\ninto _delete_allocation_after_move.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I99427a52676826990d2a2ffc82cf30ad945b939c\n'}]",9,591811,3a43a931d4e46a0aa66683da22482f3e78f26cd7,77,19,6,9708,,,0,"consumer gen: more tests for delete allocation cases

User confirming migration as well as a successfull live migration also
triggers the delete allocation code path. This patch adds test coverage
for these code paths.

If the deletion of the source allocation of a confirmed migration fails
then nova puts the instance to ERROR state. The instance still has two
allocations in this state and deleting the instance only deletes the one that
is held by the instance_uuid. This patch logs an ERROR describing that in this
case the allocation held by the migration_uuid is leaked. The same true
for live migration failing to delete allocaton on the source host.

As this makes every caller of _delete_allocation_after_move logging the
same error for AllocationDeleteFailed exception this patch moves that logging
into _delete_allocation_after_move.

Blueprint: use-nested-allocation-candidates
Change-Id: I99427a52676826990d2a2ffc82cf30ad945b939c
",git fetch https://review.opendev.org/openstack/nova refs/changes/11/591811/3 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/test_servers.py'],1,4b68c86d306aa74e563d2205b4b8f4cfd1840b66,bp/use-nested-allocation-candidates," def test_confirm_migrate_delete_alloc_on_source_retry_success(self): """"""When a migration is confirmed by the API user nova deletes the source host allocation held by the migration. This test verifies that such delete is retried successfully in case of consumer generation conflict. """""" source_hostname = self.compute1.host dest_hostname = self.compute2.host source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) dest_rp_uuid = self._get_provider_uuid_by_host(dest_hostname) server = self._boot_and_check_allocations(self.flavor, source_hostname) self._migrate_and_check_allocations( server, self.flavor, source_rp_uuid, dest_rp_uuid) migration_uuid = self.get_migration_uuid_for_instance(server['id']) # The reportclient does 3 retries after a conflict so make the first # the third (and last) retry succeed. We expect a successful migration # in this case orig_put = adapter.Adapter.put rsp = mock.Mock() rsp.status_code = 409 rsp.text = 'consumer generation conflict' results = [rsp, rsp, rsp] def fake_put(_self, url, **kwargs): if url == '/allocations/%s' % migration_uuid: return results.pop(0) if results else orig_put(_self, url, **kwargs) with mock.patch('keystoneauth1.adapter.Adapter.put', autospec=True) as mock_put: mock_put.side_effect = fake_put post = {'confirmResize': None} self.api.post_server_action( server['id'], post, check_response_status=[204]) # we have to give more time to nova to reach ACTIVE state as nova # also needs to retry the delete allocation and that takes time. self._wait_for_state_change(self.api, server, 'ACTIVE', max_retries=20) # 1 regular call + 2 failed retry + 1 succeeded retry self.assertEqual(4, mock_put.call_count) allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(1, len(allocations)) source_usages = self._get_provider_usages(source_rp_uuid) dest_usages = self._get_provider_usages(dest_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor, dest_usages) self.assertEqual({'VCPU': 0, 'MEMORY_MB': 0, 'DISK_GB': 0}, source_usages, 'The source host %s still has usages after the ' 'resize has been confirmed' % source_hostname) dest_allocation = allocations[dest_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor, dest_allocation) self._delete_and_check_allocations(server) def test_confirm_migrate_delete_alloc_on_source_retry_fails(self): source_hostname = self.compute1.host dest_hostname = self.compute2.host source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) dest_rp_uuid = self._get_provider_uuid_by_host(dest_hostname) server = self._boot_and_check_allocations(self.flavor, source_hostname) self._migrate_and_check_allocations( server, self.flavor, source_rp_uuid, dest_rp_uuid) rsp = mock.Mock() rsp.status_code = 409 rsp.text = 'consumer generation conflict' with mock.patch('keystoneauth1.adapter.Adapter.put', autospec=True) as mock_put: mock_put.return_value = rsp post = {'confirmResize': None} self.api.post_server_action( server['id'], post, check_response_status=[204]) # we have to give more time to nova to reach ACTIVE state as nova # also needs to retry the delete allocation and that takes time. # TODO(gibi): we could make this fault put the instance back to # VERIFY_RESIZE and allow the user to retry the confirmResize call server = self._wait_for_state_change(self.api, server, 'ERROR', max_retries=20) self.assertEqual(500, server['fault']['code']) self.assertIn('Failed to delete allocations', server['fault']['message']) # 1 regular call + 3 failed retry self.assertEqual(4, mock_put.call_count) # TODO(gibi): After delete we still leak the source host allocation # self._delete_and_check_allocations(server) def test_live_migrate_drop_allocation_on_source_retry_success(self): source_hostname = self.compute1.host dest_hostname = self.compute2.host source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) dest_rp_uuid = self._get_provider_uuid_by_host(dest_hostname) server = self._boot_and_check_allocations( self.flavor, source_hostname) fake_notifier.stub_notifier(self) self.addCleanup(fake_notifier.reset) orig_put = adapter.Adapter.put rsp = mock.Mock() rsp.status_code = 409 rsp.text = 'consumer generation conflict' results = [rsp, rsp, rsp] def fake_put(_self, url, *args, **kwargs): migration_uuid = self.get_migration_uuid_for_instance(server['id']) if url == '/allocations/%s' % migration_uuid: return results.pop(0) if results else orig_put( _self, url, *args, **kwargs) else: return orig_put(_self, url, *args, **kwargs) with mock.patch('keystoneauth1.adapter.Adapter.put', autospec=True) as mock_put: mock_put.side_effect = fake_put post = { 'os-migrateLive': { 'host': dest_hostname, 'block_migration': True, 'force': True, } } self.api.post_server_action(server['id'], post) # nova does the source host cleanup _after_ setting the migration # to completed and sending end notifications so we have to wait # here a bit. Note that current retry implementation waits maximum # 12 seconds altogether. Alternatively we could try to wait for the # source allocation to disappear instead. time.sleep(15) server = self._wait_for_server_parameter(self.api, server, {'OS-EXT-SRV-ATTR:host': dest_hostname, 'status': 'ACTIVE'}) self._wait_for_migration_status(server, ['completed']) fake_notifier.wait_for_versioned_notifications( 'instance.live_migration_post.end') # 1 claim on destination, 1 normal delete on dest that fails, # 2 failed retry, 1 successful retry self.assertEqual(5, mock_put.call_count) source_usages = self._get_provider_usages(source_rp_uuid) self.assertEqual({'VCPU': 0, 'MEMORY_MB': 0, 'DISK_GB': 0}, source_usages, 'Source host %s still has usage after the ' 'live migration has been finished' % source_hostname) dest_usages = self._get_provider_usages(dest_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor, dest_usages) allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(1, len(allocations)) self.assertNotIn(source_rp_uuid, allocations) dest_allocation = allocations[dest_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor, dest_allocation) self._delete_and_check_allocations(server) def test_live_migrate_drop_allocation_on_source_retry_fails(self): source_hostname = self.compute1.host dest_hostname = self.compute2.host source_rp_uuid = self._get_provider_uuid_by_host(source_hostname) dest_rp_uuid = self._get_provider_uuid_by_host(dest_hostname) server = self._boot_and_check_allocations( self.flavor, source_hostname) fake_notifier.stub_notifier(self) self.addCleanup(fake_notifier.reset) orig_put = adapter.Adapter.put rsp = mock.Mock() rsp.status_code = 409 rsp.text = 'consumer generation conflict' def fake_put(_self, url, *args, **kwargs): migration_uuid = self.get_migration_uuid_for_instance(server['id']) if url == '/allocations/%s' % migration_uuid: return rsp else: return orig_put(_self, url, *args, **kwargs) with mock.patch('keystoneauth1.adapter.Adapter.put', autospec=True) as mock_put: mock_put.side_effect = fake_put post = { 'os-migrateLive': { 'host': dest_hostname, 'block_migration': True, 'force': True, } } self.api.post_server_action(server['id'], post) # nova does the source host cleanup _after_ setting the migration # to completed and sending end notifications so we have to wait # here a bit. Note that current retry implementation waits maximum # 12 seconds altogether. time.sleep(15) # Nova failed to clean up on the source host. This right now puts # the instance to ERROR state and fails the migration. # However from the end user perspective the live migrations # finished successfully. # TODO(gibi): agree on if this ERROR state is the valid thing to do # or not server = self._wait_for_server_parameter(self.api, server, {'OS-EXT-SRV-ATTR:host': dest_hostname, 'status': 'ERROR'}) self._wait_for_migration_status(server, ['error']) fake_notifier.wait_for_versioned_notifications( 'instance.live_migration_post.end') # 1 claim on destination, 1 normal delete on dest that fails, # 2 failed retry, 1 successful retry self.assertEqual(5, mock_put.call_count) source_usages = self._get_provider_usages(source_rp_uuid) # As the cleanup on the source host failed Nova leaks the allocation # held by the migration. # TODO(gibi): fix it self.assertFlavorMatchesAllocation(self.flavor, source_usages) migration_uuid = self.get_migration_uuid_for_instance(server['id']) allocations = self._get_allocations_by_server_uuid(migration_uuid) self.assertEqual(1, len(allocations)) self.assertIn(source_rp_uuid, allocations) source_allocation = allocations[source_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor, source_allocation) dest_usages = self._get_provider_usages(dest_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor, dest_usages) allocations = self._get_allocations_by_server_uuid(server['id']) self.assertEqual(1, len(allocations)) self.assertNotIn(source_rp_uuid, allocations) dest_allocation = allocations[dest_rp_uuid]['resources'] self.assertFlavorMatchesAllocation(self.flavor, dest_allocation) # TODO(gibi): Fix the leak of the migration allocation # self._delete_and_check_allocations(server) ",,263,0
openstack%2Fmonasca-specs~master~I4cfc1f8af749a04c14790f4610359ec71633a86b,openstack/monasca-specs,master,I4cfc1f8af749a04c14790f4610359ec71633a86b,Add Stein Monasca spec template,MERGED,2018-09-26 14:43:19.000000000,2018-09-27 14:36:12.000000000,2018-09-27 14:36:12.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 14:43:19.000000000', 'files': ['specs/stein-template.rst'], 'web_link': 'https://opendev.org/openstack/monasca-specs/commit/1c350e95541d7815a4a1a5f2831aaf2f99da0dfd', 'message': 'Add Stein Monasca spec template\n\nTrivial-Fix\nChange-Id: I4cfc1f8af749a04c14790f4610359ec71633a86b\n'}]",0,605445,1c350e95541d7815a4a1a5f2831aaf2f99da0dfd,7,2,1,17669,,,0,"Add Stein Monasca spec template

Trivial-Fix
Change-Id: I4cfc1f8af749a04c14790f4610359ec71633a86b
",git fetch https://review.opendev.org/openstack/monasca-specs refs/changes/45/605445/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/stein-template.rst'],1,1c350e95541d7815a4a1a5f2831aaf2f99da0dfd,template,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ================================================ Example Spec - The title of your feature request ================================================ Include the URL of your story: https://storyboard.openstack.org Introduction paragraph -- why are we doing anything? A single paragraph of prose that operators can understand. The title and this first paragraph should be used as the subject line and body of the commit message respectively. Some notes about the monasca-spec and stories process: * Not all stories need a spec. For more information see https://docs.openstack.org/monasca-api/latest/contributor/index.html * The aim of this document is first to define the problem we need to solve, and second agree the overall approach to solve that problem. * This is not intended to be extensive documentation for a new feature. For example, there is no need to specify the exact configuration changes, nor the exact details of any DB model changes. But you should still define that such changes are required, and be clear on how that will affect upgrades. * You should aim to get your spec approved before writing your code. While you are free to write prototypes and code before getting your spec approved, its possible that the outcome of the spec review process leads you towards a fundamentally different solution than you first envisaged. * But, API changes are held to a much higher level of scrutiny. As soon as an API change merges, we must assume it could be in production somewhere, and as such, we then need to support that API change forever. To avoid getting that wrong, we do want lots of details about API changes upfront. Some notes about using this template: * Your spec should be in ReSTructured text, like this template. * Please wrap text at 79 columns. * Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None * For help with syntax, see http://sphinx-doc.org/rest.html * To test out your formatting, build the docs using tox and see the generated HTML file in doc/build/html/specs/<path_of_your_file> * If you would like to provide a diagram with your spec, ascii diagrams are required. http://asciiflow.com/ is a very nice tool to assist with making ascii diagrams. The reason for this is that the tool used to review specs is based purely on plain text. Plain text will allow review to proceed without having to look at additional files which can not be viewed in gerrit. It will also allow inline feedback on the diagram itself. * If your specification proposes any changes to the Monasca REST API such as changing parameters which can be returned or accepted, or even the semantics of what happens when a client calls into the API, then you should add the APIImpact flag to the commit message. Specifications with the APIImpact flag can be found with the following query: https://review.openstack.org/#/q/status:open+project:openstack/monasca-specs+message:apiimpact,n,z Problem description =================== A detailed description of the problem. What problem is this feature request addressing? Use Cases --------- What use cases does this address? What impact on actors does this change have? Ensure you are clear about the actors in each use case: Developer, End User, Deployer etc. Proposed change =============== Here is where you cover the change you propose to make in detail. How do you propose to solve this problem? If this is one part of a larger effort make it clear where this piece ends. In other words, what's the scope of this effort? At this point, if you would like to just get feedback on if the problem and proposed change fit in monasca, you can stop here and post this for review to get preliminary feedback. If so please say: Posting to get preliminary feedback on the scope of this spec. Alternatives ------------ What other ways could we do this thing? Why aren't we using those? This doesn't have to be a full literature review, but it should demonstrate that thought has been put into why the proposed solution is an appropriate one. Data model impact ----------------- Changes which require modifications to the data model often have a wider impact on the system. The community often has strong opinions on how the data model should be evolved, from both a functional and performance perspective. It is therefore important to capture and gain agreement as early as possible on any proposed changes to the data model. Questions which need to be addressed by this section include: * What new data objects and/or database schema changes is this going to require? * What database migrations will accompany this change. * How will the initial set of new data objects be generated, for example if you need to take into account existing instances, or modify other existing data describe how that will work. REST API impact --------------- Each API method which is either added or changed should have the following * Specification for the method * A description of what the method does suitable for use in user documentation * Method type (POST/PUT/GET/DELETE) * Normal http response code(s) * Expected error http response code(s) * A description for each possible error code should be included describing semantic errors which can cause it such as inconsistent parameters supplied to the method, or when an instance is not in an appropriate state for the request to succeed. Errors caused by syntactic problems covered by the JSON schema definition do not need to be included. * URL for the resource * URL should not include underscores, and use hyphens instead. * Parameters which can be passed via the url * JSON schema definition for the request body data if allowed * Field names should use snake_case style, not CamelCase or MixedCase style. * JSON schema definition for the response body data if any * Field names should use snake_case style, not CamelCase or MixedCase style. * Example use case including typical API samples for both data supplied by the caller and the response * Discuss any policy changes, and discuss what things a deployer needs to think about when defining their policy. Note that the schema should be defined as restrictively as possible. Parameters which are required should be marked as such and only under exceptional circumstances should additional parameters which are not defined in the schema be permitted. Reuse of existing predefined parameter types such as regexps for passwords and user defined names is highly encouraged. Security impact --------------- Describe any potential security impact on the system. Some of the items to consider include: * Does this change touch sensitive data such as tokens, keys, or user data? * Does this change alter the API in a way that may impact security, such as a new way to access sensitive information or a new way to login? * Does this change involve cryptography or hashing? * Does this change require the use of sudo or any elevated privileges? * Does this change involve using or parsing user-provided data? This could be directly at the API level or indirectly such as changes to a cache layer. * Can this change enable a resource exhaustion attack, such as allowing a single API interaction to consume significant server resources? Some examples of this include launching subprocesses for each connection, or entity expansion attacks in XML. For more detailed guidance, please see the OpenStack Security Guidelines as a reference (https://wiki.openstack.org/wiki/Security/Guidelines). These guidelines are a work in progress and are designed to help you identify security best practices. For further information, feel free to reach out to the OpenStack Security Group at openstack-security@lists.openstack.org. Other end user impact --------------------- Aside from the API, are there other ways a user will interact with this feature? * Does this change have an impact on python-monascaclient? What does the user interface there look like? Performance Impact ------------------ Describe any potential performance impact on the system, for example how often will new code be called, and is there a major change to the calling pattern of existing code. Examples of things to consider here include: * A periodic task might look like a small addition but if it calls conductor or another service the load is multiplied by the number of nodes in the system. * Scheduler filters get called once per host for every instance being created, so any latency they introduce is linear with the size of the system. * A small change in a utility function or a commonly used decorator can have a large impacts on performance. * Calls which result in a database queries (whether direct or via conductor) can have a profound impact on performance when called in critical sections of the code. * Will the change include any locking, and if so what considerations are there on holding the lock? Other deployer impact --------------------- Discuss things that will affect how you deploy and configure Monasca that have not already been mentioned, such as: * What config options are being added? Should they be more generic than proposed (for example a flag that other hypervisor drivers might want to implement as well)? Are the default values ones which will work well in real deployments? * Is this a change that takes immediate effect after its merged, or is it something that has to be explicitly enabled? * If this change is a new binary, how would it be deployed? * Please state anything that those doing continuous deployment, or those upgrading from the previous release, need to be aware of. Also describe any plans to deprecate configuration values or features. For example, if we change the directory name that instances are stored in, how do we handle instance directories created before the change landed? Do we move them? Do we have a special case in the code? Do we assume that the operator will recreate all the instances in their cloud? Developer impact ---------------- Discuss things that will affect other developers working on Monasca. Implementation ============== Assignee(s) ----------- Who is leading the writing of the code? Or is this a feature where you're throwing it out there to see who picks it up? If more than one person is working on the implementation, please designate the primary author and contact. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- Work items or tasks -- break the feature up into the things that need to be done to implement it. Those parts might end up being done by different people, but we're mostly trying to understand the timeline for implementation. Dependencies ============ * Include specific references to specs and/or blueprints in monasca, or in other projects, that this one either depends on or is related to. * If this requires functionality of another project that is not currently used by Monasca (such as the glance v2 API when we previously only required v1), document that fact. * Does this feature require any new library dependencies or code otherwise not included in OpenStack? Or does it depend on a specific version of library? Testing ======= Please discuss the important scenarios needed to test here, as well as specific edge cases we should be ensuring work correctly. For each scenario please specify if this requires specialized hardware, a full openstack environment, or can be simulated inside the Monasca tree. Please discuss how the change will be tested. We especially want to know what tempest tests will be added. It is assumed that unit test coverage will be added so that doesn't need to be mentioned explicitly, but discussion of why you think unit tests are sufficient and we don't need to add more tempest tests would need to be included. Is this untestable in gate given current limitations (specific hardware / software configurations available)? If so, are there mitigation plans (3rd party testing, gate enhancements, etc). Documentation Impact ==================== Which audiences are affected most by this change, and which documentation titles on docs.openstack.org should be updated because of this change? Don't repeat details discussed above, but reference them here in the context of documentation for multiple audiences. For example, the Operations Guide targets cloud operators, and the End User Guide would need to be updated if the change offers a new feature available through the CLI or dashboard. If a config option changes or is deprecated, note here that the documentation needs to be updated to reflect this specification's change. References ========== Please add any useful references here. You are not required to have any reference. Moreover, this specification should still make sense when your references are unavailable. Examples of what you could include are: * Links to mailing list or IRC discussions * Links to notes from a summit session * Links to relevant research, if appropriate * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) * Anything else you feel it is worthwhile to refer to History ======= Optional section intended to be used each time the spec is updated to describe new design, API or any database schema updated. Useful to let reader understand what's happened along the time. .. list-table:: Revisions :header-rows: 1 * - Release Name - Description * - Stein - Introduced ",,378,0
openstack%2Fproject-config~master~Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02,openstack/project-config,master,Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02,Add zone-opendev.org project,MERGED,2018-09-25 15:02:42.000000000,2018-09-27 14:30:56.000000000,2018-09-27 14:30:56.000000000,"[{'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 15:02:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0634247c1b5bc8a7095f11651e55b0e7d3994514', 'message': 'Add zone-opendev.org project\n\nChange-Id: Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02\nNote: This creates the opendev/ git repo hierarchy.\n'}, {'number': 2, 'created': '2018-09-25 15:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/5d58ca78d60838bc6ce19c185b97b1c973d665e0', 'message': 'Add zone-opendev.org project\n\nChange-Id: Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02\n'}, {'number': 3, 'created': '2018-09-26 16:38:57.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml', 'gerrit/acls/openstack-infra/zone-opendev.org.config'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ec39c14f13766d4eff4fa3c6f552b7d18a9d67fd', 'message': 'Add zone-opendev.org project\n\nChange-Id: Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02\n'}]",0,605095,ec39c14f13766d4eff4fa3c6f552b7d18a9d67fd,11,3,3,1,,,0,"Add zone-opendev.org project

Change-Id: Ife0e61cdfe3bde5825ac3942f5d9281b1c707e02
",git fetch https://review.opendev.org/openstack/project-config refs/changes/95/605095/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/acls/opendev/zone-opendev.org.config', 'gerrit/projects.yaml']",2,0634247c1b5bc8a7095f11651e55b0e7d3994514,,- project: opendev/zone-opendev.org use-storyboard: true groups: - openstack-ci description: Zone file for opendev.org,,18,0
openstack%2Fplacement~master~Ic532bc231e89eaec4cb5ad01d27bbe840b01a5f7,openstack/placement,master,Ic532bc231e89eaec4cb5ad01d27bbe840b01a5f7,Add alloc cands test with nested and aggregates,MERGED,2018-09-14 15:08:03.000000000,2018-09-27 14:09:52.000000000,2018-09-27 14:09:51.000000000,"[{'_account_id': 7}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-14 15:08:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/beaf5472f8a0b4e1905eebb9148f62c47bba7a9c', 'message': 'Add alloc cands test with nested and aggregates\n\nWhen placement picks up allocation candidates, the aggregates of\nnested providers are assumed as the same as root providers. This\nmeans it ignores the aggregates of the nested provider itself.\nThis could result in the lack of allocation candidates when an\naggregate on a nested provider but not on the root has been\nspecified in the `member_of` query parameter.\n\nThis patch adds test cases for the bug. The fix is done in a\nfollow up.\n\nRelated-Bug: #1792503\n\nChange-Id: Ic532bc231e89eaec4cb5ad01d27bbe840b01a5f7\n'}, {'number': 2, 'created': '2018-09-21 01:27:12.000000000', 'files': ['placement/tests/functional/fixtures/gabbits.py', 'placement/tests/functional/gabbits/allocation-candidates-bug-1792503.yaml'], 'web_link': 'https://opendev.org/openstack/placement/commit/dc472e144a8e9edba90c4dc05a2e7e2220854387', 'message': 'Add alloc cands test with nested and aggregates\n\nWhen placement picks up allocation candidates, the aggregates of\nnested providers are assumed as the same as root providers. This\nmeans it ignores the aggregates of the nested provider itself.\nThis could result in the lack of allocation candidates when an\naggregate on a nested provider but not on the root has been\nspecified in the `member_of` query parameter.\n\nThis patch adds test cases for the bug. The fix is done in a\nfollow up.\n\nRelated-Bug: #1792503\n\nChange-Id: Ic532bc231e89eaec4cb5ad01d27bbe840b01a5f7\n'}]",8,602638,dc472e144a8e9edba90c4dc05a2e7e2220854387,10,4,2,25625,,,0,"Add alloc cands test with nested and aggregates

When placement picks up allocation candidates, the aggregates of
nested providers are assumed as the same as root providers. This
means it ignores the aggregates of the nested provider itself.
This could result in the lack of allocation candidates when an
aggregate on a nested provider but not on the root has been
specified in the `member_of` query parameter.

This patch adds test cases for the bug. The fix is done in a
follow up.

Related-Bug: #1792503

Change-Id: Ic532bc231e89eaec4cb5ad01d27bbe840b01a5f7
",git fetch https://review.opendev.org/openstack/placement refs/changes/38/602638/2 && git format-patch -1 --stdout FETCH_HEAD,"['placement/tests/functional/fixtures/gabbits.py', 'placement/tests/functional/gabbits/allocation-candidates-bug-1792503.yaml']",2,beaf5472f8a0b4e1905eebb9148f62c47bba7a9c,bug/1792503,"# Tests of allocation candidates API fixtures: - NUMAAggregateFixture defaults: request_headers: x-auth-token: admin accept: application/json openstack-api-version: placement 1.29 tests: - name: get allocation candidates without aggregate GET: /allocation_candidates?resources=VCPU:1 response_json_paths: $.allocation_requests.`len`: 4 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate A GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGA_UUID'] response_json_paths: # Aggregate A is on the root rps (both cn1 and cn2) so it spans on the # whole tree. We have full allocations here. $.allocation_requests.`len`: 4 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate B GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGB_UUID'] response_json_paths: # Aggregate B is on the root of cn2 so it spans on the # whole tree including rps of NUMA2_1 and NUMA2_2. $.allocation_requests.`len`: 2 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 - name: get allocation candidates with aggregate C GET: /allocation_candidates?resources=VCPU:1&member_of=$ENVIRON['AGGC_UUID'] response_json_paths: # Aggregate C is *NOT* on the root, so we should get only NUMA1_1 # here that is only the rp in aggregate C. # --------------------- # Bug#1792503: It lacks allocation candidates when an aggregate on the # nested rp but not on the root rp has been specified in # the `member_of` query parameter. # --------------------- # $.allocation_requests.`len`: 1 # $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests.`len`: 0 - name: get allocation candidates with shared storage GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000 response_json_paths: # Since `members_of` query parameter is not specified, sharing rp 1 is # being shared with the *whole* trees of CN1 and CN2. Sharing rp 2 is # being shared with the *whole* tree of CN1. # As a result, there should be 6 allocation candidates: # [ # (numa1-1, ss1), (numa1-2, ss1), (numa2-1, ss1), (numa2-2, ss1), # (numa1-1, ss2), # ] $.allocation_requests.`len`: 6 $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: [1, 1] $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS1_UUID']""].resources.DISK_GB: [1000, 1000, 1000, 1000] $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: [1000, 1000] - name: get allocation candidates with shared storage with aggregate A GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGA_UUID'] response_json_paths: $.allocation_requests.`len`: 4 # Since aggregate A is specified, which is on the root CN1, sharing # rp 1 can be allocation candidates with the *whole* trees in CN1. # Sharing rp 2 can't in the allocation candidates since it is not # under aggregate A but under aggregate C. # As a result, there should be 4 allocation candidates: # [ # (numa1-1, ss1), (numa1-2, ss1), (numa2-1, ss1), (numa2-2, ss1) # ] $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA1_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_1_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['NUMA2_2_UUID']""].resources.VCPU: 1 $.allocation_requests..allocations[""$ENVIRON['SS1_UUID']""].resources.DISK_GB: [1000, 1000, 1000, 1000] - name: get allocation candidates with shared storage with aggregate B GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGB_UUID'] response_json_paths: # We don't have shared disk in aggregate B. $.allocation_requests.`len`: 0 - name: get allocation candidates with shared storage with aggregate C GET: /allocation_candidates?resources=VCPU:1,DISK_GB:1000&member_of=$ENVIRON['AGGC_UUID'] response_json_paths: # Since aggregate C is specified, which is on *non-root*, NUMA1_1, # sharing provider 2 is not shared with the whole tree. It is shared # with rps only with aggregate C for their own (opposite to not on root). # As a result, there should be 1 allocation candidate: # [ # (numa1-1, ss2), # ] # --------------------- # Bug#1792503: It lacks allocation candidates when an aggregate on the # nested rp but not on the root rp has been specified in # the `member_of` query parameter. # --------------------- # $.allocation_requests.`len`: 1 # $.allocation_requests..allocations[""$ENVIRON['NUMA1_1_UUID']""].resources.VCPU: 1 # $.allocation_requests..allocations[""$ENVIRON['SS2_UUID']""].resources.DISK_GB: 1000 $.allocation_requests.`len`: 0 ",,197,0
openstack%2Fopenstack-ansible~stable%2Frocky~I33f7994a50ba5fcea7fca171dfca6b4d32011900,openstack/openstack-ansible,stable/rocky,I33f7994a50ba5fcea7fca171dfca6b4d32011900,Remove broken uptime tests during upgrade,MERGED,2018-09-25 17:07:51.000000000,2018-09-27 13:37:17.000000000,2018-09-27 13:37:17.000000000,"[{'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-25 17:07:51.000000000', 'files': ['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/dc943b99c8f87c58a3bee6801eabe9aa5f0473f9', 'message': 'Remove broken uptime tests during upgrade\n\nThe uptime tests during upgrades have not been\nworking for some time, and we really need a better\nway to implement them anyway.\n\nTo at least allow upgrade tests to work without\ntheir interference, we remove the scripts and\nimplementation.\n\nChange-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900\n(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)\n'}]",0,605151,dc943b99c8f87c58a3bee6801eabe9aa5f0473f9,13,4,1,6816,,,0,"Remove broken uptime tests during upgrade

The uptime tests during upgrades have not been
working for some time, and we really need a better
way to implement them anyway.

To at least allow upgrade tests to work without
their interference, we remove the scripts and
implementation.

Change-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900
(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/51/605151/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh']",4,dc943b99c8f87c58a3bee6801eabe9aa5f0473f9,cleanup-role-tests-stable/rocky,,"#!/bin/bash # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## Shell Opts ---------------------------------------------------------------- set -e ## Vars ---------------------------------------------------------------------- # Test script socket file location TEST_SOCKET_FILE=""/var/run/disk-access-test.socket"" # The location to write to TEST_DATA_FILE=""/mnt/test"" # Setup counters PASS=0 FAIL=0 ## Functions ----------------------------------------------------------------- # Tests to execute tests() { # We want the output format to be: # YYYY-MM-DD HH:MM:SS <result> echo -n ""$(date -u '+%Y-%m-%d %H:%M:%S') "" # A simple disk write test to validate whether # we are able to write to disk. CMD_WRITE=""timeout 1s dd bs=1M count=50 if=/dev/zero of=${TEST_DATA_FILE} conv=fdatasync"" if ${CMD_WRITE}; then echo ""PASS"" PASS=$((PASS+1)) else echo ""FAIL"" FAIL=$((FAIL+1)) fi } # Steps to execute when finishing finish() { rm -f ${TEST_SOCKET_FILE} > /dev/null echo ""PASS: ${PASS}"" echo ""FAIL: ${FAIL}"" } # Setup the trap for the interrupt trap finish SIGHUP SIGINT SIGTERM ## Main ---------------------------------------------------------------------- # Partition the volume echo ';' | sfdisk --quiet /dev/vdb > /dev/null # Format the volume mkfs /dev/vdb1 > /dev/null # Mount the volume mount /dev/vdb1 /mnt # Setup the socket file to allow termination later echo $$ > ${TEST_SOCKET_FILE} # Execute the test loop while [ -f ""${TEST_SOCKET_FILE}"" ]; do tests sleep 1 done # This point will only be reached if the # socket file is removed finish ",0,329
openstack%2Freleases~master~I748090888362613822b8b58c8ff7494e4507058d,openstack/releases,master,I748090888362613822b8b58c8ff7494e4507058d,training-labs stable/rocky,MERGED,2018-09-25 13:33:07.000000000,2018-09-27 13:37:03.000000000,2018-09-27 13:37:03.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 20156}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 13:33:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/80fc03ef41e149060a3e215f8a2ded7a835b6a25', 'message': 'training-labs stable/rocky\n\nChange-Id: I748090888362613822b8b58c8ff7494e4507058d\n'}, {'number': 2, 'created': '2018-09-26 07:17:11.000000000', 'files': ['deliverables/_independent/training-labs.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/efc9d417c27bccb89533195cd6277b8cb46cfce9', 'message': 'training-labs stable/rocky\n\nChange-Id: I748090888362613822b8b58c8ff7494e4507058d\n'}]",0,605073,efc9d417c27bccb89533195cd6277b8cb46cfce9,11,4,2,11109,,,0,"training-labs stable/rocky

Change-Id: I748090888362613822b8b58c8ff7494e4507058d
",git fetch https://review.opendev.org/openstack/releases refs/changes/73/605073/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/training-labs.yaml'],1,80fc03ef41e149060a3e215f8a2ded7a835b6a25,release_training-labs, - name: stable/rocky location: openstack/training-labs: 29e18ecf65d106c22a8613664f99051417b96662, - name: stable/queens location: openstack/training-labs: b5a44c367b99a13af577248b354572e241734d7a,2,2
openstack%2Fglance~master~I1eaf87eedb86679d9ca9323aac05f0770c33efea,openstack/glance,master,I1eaf87eedb86679d9ca9323aac05f0770c33efea,Rename async package to async_,MERGED,2018-07-13 14:58:56.000000000,2018-09-27 13:33:33.000000000,2018-09-20 15:18:31.000000000,"[{'_account_id': 2537}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 9008}, {'_account_id': 9303}, {'_account_id': 9373}, {'_account_id': 11805}, {'_account_id': 11904}, {'_account_id': 18791}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 27882}]","[{'number': 1, 'created': '2018-07-13 14:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/f582c17e77124f2da92c3e00dd1130fbce5b55b2', 'message': 'Rename async package to async_\n\nIn Python 3.7, ""async"" is a keyword. To prevent it from\nconflicting, rename the async package to async_.\n\nChange-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea\nCloses-Bug: #1781617\n'}, {'number': 2, 'created': '2018-07-13 17:03:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/011816e4a7a46b3250c66d80b361ffde6fe13ebc', 'message': 'Rename async package to async_\n\nIn Python 3.7, ""async"" is a keyword. To prevent it from\nconflicting, rename the async package to async_.\n\nChange-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea\nCloses-Bug: #1781617\n'}, {'number': 3, 'created': '2018-07-14 01:44:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3544674720a160da752b22d9aee6bffff54b29a0', 'message': 'Rename async package to async_\n\nIn Python 3.7, ""async"" is a keyword. To prevent it from\nconflicting, rename the async package to async_.\n\nChange-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea\nCloses-Bug: #1781617\n'}, {'number': 4, 'created': '2018-07-14 11:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9267bdc752d18f7e264f933688b922e6f8b3164e', 'message': 'Rename async package to async_\n\nIn Python 3.7, ""async"" is a keyword. To prevent it from\nconflicting, rename the async package to async_.\n\nChange-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea\nCloses-Bug: #1781617\n'}, {'number': 5, 'created': '2018-08-07 18:42:16.000000000', 'files': ['glance/async_/flows/plugins/inject_image_metadata.py', 'glance/tests/unit/async_/flows/__init__.py', 'doc/source/admin/interoperable-image-import.rst', 'glance/domain/__init__.py', 'glance/async_/flows/plugins/__init__.py', 'glance/async_/flows/_internal_plugins/__init__.py', 'glance/async_/flows/plugins/plugin_opts.py', 'glance/tests/unit/test_notifier.py', 'glance/tests/unit/async_/flows/test_import.py', 'glance/async_/flows/base_import.py', 'glance/async_/flows/introspect.py', 'glance/tests/unit/async_/test_taskflow_executor.py', 'glance/async_/utils.py', 'glance/tests/unit/async_/flows/test_api_image_import.py', 'glance/async_/taskflow_executor.py', 'glance/async_/__init__.py', 'glance/tests/unit/async_/flows/test_convert.py', 'glance/async_/flows/ovf_process.py', 'glance/tests/unit/async_/flows/test_web_download.py', 'glance/opts.py', 'glance/tests/unit/async_/test_async.py', 'glance/async_/flows/convert.py', 'glance/tests/unit/async_/flows/test_ovf_process.py', 'glance/tests/unit/test_domain.py', 'glance/common/utils.py', 'glance/async_/flows/__init__.py', 'glance/async_/flows/plugins/image_conversion.py', 'glance/tests/unit/async_/flows/test_introspect.py', 'glance/async_/flows/_internal_plugins/web_download.py', 'glance/async_/flows/api_image_import.py', 'glance/async_/flows/plugins/no_op.py', 'glance/tests/unit/async_/flows/plugins/test_inject_image_metadata.py', 'setup.cfg', 'glance/tests/unit/async_/__init__.py', 'glance/tests/unit/async_/flows/plugins/__init__.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/c58e5e02af76cad3967d22d14c63794c6d60456f', 'message': 'Rename async package to async_\n\nIn Python 3.7, ""async"" is a keyword. To prevent it from\nconflicting, rename the async package to async_.\n\nChange-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea\nCloses-Bug: #1781617\n'}]",0,582613,c58e5e02af76cad3967d22d14c63794c6d60456f,27,12,5,11805,,,0,"Rename async package to async_

In Python 3.7, ""async"" is a keyword. To prevent it from
conflicting, rename the async package to async_.

Change-Id: I1eaf87eedb86679d9ca9323aac05f0770c33efea
Closes-Bug: #1781617
",git fetch https://review.opendev.org/openstack/glance refs/changes/13/582613/4 && git format-patch -1 --stdout FETCH_HEAD,"['glance/tests/unit/async/flows/test_introspect.py', 'glance/async_/flows/plugins/inject_image_metadata.py', 'glance/domain/__init__.py', 'glance/async_/flows/plugins/__init__.py', 'glance/async_/flows/_internal_plugins/__init__.py', 'glance/tests/unit/async/flows/test_convert.py', 'glance/async_/flows/plugins/plugin_opts.py', 'glance/tests/unit/test_notifier.py', 'glance/tests/unit/async/flows/test_import.py', 'glance/async_/flows/base_import.py', 'glance/tests/unit/async/flows/plugins/test_inject_image_metadata.py', 'glance/tests/unit/async/flows/test_api_image_import.py', 'glance/async_/flows/introspect.py', 'glance/async_/utils.py', 'glance/async_/taskflow_executor.py', 'glance/tests/unit/async/test_taskflow_executor.py', 'glance/async_/__init__.py', 'glance/tests/unit/async/flows/test_ovf_process.py', 'glance/async_/flows/ovf_process.py', 'glance/opts.py', 'glance/async_/flows/convert.py', 'glance/tests/unit/test_domain.py', 'glance/common/utils.py', 'glance/async_/flows/__init__.py', 'glance/async_/flows/plugins/image_conversion.py', 'glance/async_/flows/_internal_plugins/web_download.py', 'glance/async_/flows/api_image_import.py', 'glance/async_/flows/plugins/no_op.py', 'glance/tests/unit/async/test_async.py', 'glance/tests/unit/async/flows/test_web_download.py']",30,f582c17e77124f2da92c3e00dd1130fbce5b55b2,bug/1781617,from glance.async_.flows._internal_plugins import web_download,from glance.async.flows._internal_plugins import web_download,45,45
openstack%2Ftripleo-heat-templates~master~I8b908970a5eee89640a1c5ebb459fa4d61d8e69d,openstack/tripleo-heat-templates,master,I8b908970a5eee89640a1c5ebb459fa4d61d8e69d,Restart os-collect-config if journald was restarted.,ABANDONED,2018-09-27 13:19:18.000000000,2018-09-27 13:28:55.000000000,,"[{'_account_id': 6926}, {'_account_id': 8297}]","[{'number': 1, 'created': '2018-09-27 13:19:18.000000000', 'files': ['environments/lifecycle/upgrade-prepare.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a26b380f8dae26d0cf61d37e5c621a739ff4e8b8', 'message': 'Restart os-collect-config if journald was restarted.\n\nCurrently there is an issue with in os-collect-config\nas it gets hung when journald has restarted [0], this\nis a known issue in systemd [1]. To workaround this\nsituation, in which an upgrade or update will fail\nas os-collect-config does not reply, we check the\nuptime for systemd-journald and os-collect-config and\nrestart os-collect-config if journald has been running\nfor less time.\n\n[0] - https://bugzilla.redhat.com/show_bug.cgi?id=1623921\n[1] - https://bugs.freedesktop.org/show_bug.cgi?id=84923\n\nChange-Id: I8b908970a5eee89640a1c5ebb459fa4d61d8e69d\n'}]",1,605698,a26b380f8dae26d0cf61d37e5c621a739ff4e8b8,3,2,1,26343,,,0,"Restart os-collect-config if journald was restarted.

Currently there is an issue with in os-collect-config
as it gets hung when journald has restarted [0], this
is a known issue in systemd [1]. To workaround this
situation, in which an upgrade or update will fail
as os-collect-config does not reply, we check the
uptime for systemd-journald and os-collect-config and
restart os-collect-config if journald has been running
for less time.

[0] - https://bugzilla.redhat.com/show_bug.cgi?id=1623921
[1] - https://bugs.freedesktop.org/show_bug.cgi?id=84923

Change-Id: I8b908970a5eee89640a1c5ebb459fa4d61d8e69d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/98/605698/1 && git format-patch -1 --stdout FETCH_HEAD,['environments/lifecycle/upgrade-prepare.yaml'],1,a26b380f8dae26d0cf61d37e5c621a739ff4e8b8,," # Restart os-collect-config if journald has beeing restarted # after os-collect-config start https://bugzilla.redhat.com/show_bug.cgi?id=1623921 if [ ""`systemctl is-active os-collect-config`"" == ""active"" ] then journald_time=`sudo systemctl show systemd-journald --property=ActiveEnterTimestampMonotonic | awk -F""="" '{print $2}'` occ_time=`sudo systemctl show os-collect-config --property=ActiveEnterTimestampMonotonic | awk -F""="" '{print $2}'` if [ ""$journald_time"" -gt ""$occ_time"" ] then systemctl restart os-collect-config if [ $? -ne 0 ] then echo ""ERROR: os-collect-config can't start, rc=$?"" exit $? fi fi else systemctl start os-collect-config if [ $? -ne 0 ] then echo ""ERROR: os-collect-config can't start, rc=$?"" exit $? fi fi",,23,0
openstack%2Fcastellan-ui~master~I62aab6a33715a09e462c72a99a963b7076ab8c13,openstack/castellan-ui,master,I62aab6a33715a09e462c72a99a963b7076ab8c13,fix tox python3 overrides,ABANDONED,2018-09-27 13:25:31.000000000,2018-09-27 13:26:30.000000000,,[],"[{'number': 1, 'created': '2018-09-27 13:25:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/castellan-ui/commit/82d8cbc72531c1291a93dce1cf24209ba82b65d7', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I62aab6a33715a09e462c72a99a963b7076ab8c13\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605704,82d8cbc72531c1291a93dce1cf24209ba82b65d7,2,0,1,2472,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I62aab6a33715a09e462c72a99a963b7076ab8c13
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/castellan-ui refs/changes/04/605704/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,82d8cbc72531c1291a93dce1cf24209ba82b65d7,python3-first,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,,5,0
openstack%2Fopenstack-ansible-repo_build~stable%2Fpike~I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7,openstack/openstack-ansible-repo_build,stable/pike,I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7,Remove galera_client meta-dependency,ABANDONED,2018-09-19 13:25:13.000000000,2018-09-27 13:11:25.000000000,,"[{'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-19 13:25:13.000000000', 'files': ['meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/5f26a45115f0fd24c687ae0ebd7cbb341fc6690b', 'message': 'Remove galera_client meta-dependency\n\nGiven that pymysql is pure python and has no C binding\ndependencies, we no longer need the role to install the\nMariaDB client libraries.\n\nChange-Id: I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7\n(cherry picked from commit d3bcd1c9515ac7876fe263f2808e761e402a269a)\n'}]",0,603774,5f26a45115f0fd24c687ae0ebd7cbb341fc6690b,10,4,1,6816,,,0,"Remove galera_client meta-dependency

Given that pymysql is pure python and has no C binding
dependencies, we no longer need the role to install the
MariaDB client libraries.

Change-Id: I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7
(cherry picked from commit d3bcd1c9515ac7876fe263f2808e761e402a269a)
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/74/603774/1 && git format-patch -1 --stdout FETCH_HEAD,['meta/main.yml'],1,5f26a45115f0fd24c687ae0ebd7cbb341fc6690b,remove-mysql-python-stable/pike,, - role: galera_client vars: galera_client_drop_config_file: false,0,3
openstack%2Fopenstack-ansible-repo_build~stable%2Fqueens~I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7,openstack/openstack-ansible-repo_build,stable/queens,I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7,Remove galera_client meta-dependency,ABANDONED,2018-09-19 13:23:08.000000000,2018-09-27 13:11:18.000000000,,"[{'_account_id': 6816}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-19 13:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/4a7256b9f399c6adc5690f8021678f55086e541a', 'message': 'Remove galera_client meta-dependency\n\nGiven that pymysql is pure python and has no C binding\ndependencies, we no longer need the role to install the\nMariaDB client libraries.\n\nChange-Id: I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7\n(cherry picked from commit d3bcd1c9515ac7876fe263f2808e761e402a269a)\n'}, {'number': 2, 'created': '2018-09-27 13:10:18.000000000', 'files': ['meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/b6be4f3318c62914df9d0105db9212c14c60e1b5', 'message': 'Remove galera_client meta-dependency\n\nGiven that pymysql is pure python and has no C binding\ndependencies, we no longer need the role to install the\nMariaDB client libraries.\n\nChange-Id: I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7\n(cherry picked from commit d3bcd1c9515ac7876fe263f2808e761e402a269a)\n'}]",0,603772,b6be4f3318c62914df9d0105db9212c14c60e1b5,10,3,2,6816,,,0,"Remove galera_client meta-dependency

Given that pymysql is pure python and has no C binding
dependencies, we no longer need the role to install the
MariaDB client libraries.

Change-Id: I3d752bdde0dc38fd0cf4a5941b9d4496189dddb7
(cherry picked from commit d3bcd1c9515ac7876fe263f2808e761e402a269a)
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/72/603772/1 && git format-patch -1 --stdout FETCH_HEAD,['meta/main.yml'],1,4a7256b9f399c6adc5690f8021678f55086e541a,remove-mysql-python-stable/queens,, - role: galera_client vars: galera_client_drop_config_file: false,0,3
openstack%2Fmonasca-notification~master~Ia672120ccce01ec17832733971977ff471a6893a,openstack/monasca-notification,master,Ia672120ccce01ec17832733971977ff471a6893a,Includes alarm value meta in slack notification,NEW,2018-09-17 13:36:28.000000000,2018-09-27 12:59:58.000000000,,"[{'_account_id': 16222}, {'_account_id': 17669}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-17 13:36:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/dc3438104e9e03edc6d10e4feaf8bc1c1064e570', 'message': 'Includes alarm value meta in slack notification\n\nChange-Id: Ia672120ccce01ec17832733971977ff471a6893a\nstory: #2001282\ntask: #26498\n'}, {'number': 2, 'created': '2018-09-18 08:42:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/654ef5598fc5de889b58b9cbfe4044f8ae9abd08', 'message': 'Includes alarm value meta in slack notification\n\nChange-Id: Ia672120ccce01ec17832733971977ff471a6893a\nstory: #2001282\ntask: #26498\n'}, {'number': 3, 'created': '2018-09-18 12:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/e7d42754c5793393824265ec660eb1e0a8a68ce9', 'message': 'Includes alarm value meta in slack notification\n\nChange-Id: Ia672120ccce01ec17832733971977ff471a6893a\nstory: #2001282\ntask: #26498\n'}, {'number': 4, 'created': '2018-09-18 15:20:36.000000000', 'files': ['tests/test_email_notification.py', 'tests/test_alarm_processor.py', 'tests/test_notifiers.py', 'monasca_notification/plugins/slack_notifier.py', 'tests/test_slack_notification.py', 'tests/test_webhook_notification.py', 'tests/test_jira_notification.py', 'tests/test_pagerduty_notification.py', 'tests/test_notification_processor.py', 'tests/test_hipchat_notification.py', 'monasca_notification/processors/alarm_processor.py', 'monasca_notification/notification.py'], 'web_link': 'https://opendev.org/openstack/monasca-notification/commit/df5b3921d3a888e35dcd710df8889699785db537', 'message': 'Includes alarm value meta in slack notification\n\nChange-Id: Ia672120ccce01ec17832733971977ff471a6893a\nstory: #2001282\ntask: #26498\n'}]",9,603127,df5b3921d3a888e35dcd710df8889699785db537,11,3,4,28529,,,0,"Includes alarm value meta in slack notification

Change-Id: Ia672120ccce01ec17832733971977ff471a6893a
story: #2001282
task: #26498
",git fetch https://review.opendev.org/openstack/monasca-notification refs/changes/27/603127/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/test_email_notification.py', 'tests/test_alarm_processor.py', 'tests/test_notifiers.py', 'monasca_notification/plugins/slack_notifier.py', 'tests/test_slack_notification.py', 'tests/test_webhook_notification.py', 'tests/test_jira_notification.py', 'tests/test_pagerduty_notification.py', 'tests/test_notification_processor.py', 'tests/test_hipchat_notification.py', 'monasca_notification/processors/alarm_processor.py', 'monasca_notification/notification.py']",12,dc3438104e9e03edc6d10e4feaf8bc1c1064e570,slack-patch," 'periodic_topic', 'value_meta' self.value_meta = alarm['valueMeta'] 'periodic_topic', 'value_meta'", 'periodic_topic' 'periodic_topic',39,17
openstack%2Fopenstack-ansible-ceph_client~master~Ib95e96130a06d3dd92aa237080a04f762995a729,openstack/openstack-ansible-ceph_client,master,Ib95e96130a06d3dd92aa237080a04f762995a729,Fix apt pinning for ceph,MERGED,2018-09-26 13:55:10.000000000,2018-09-27 12:36:18.000000000,2018-09-27 02:59:10.000000000,"[{'_account_id': 7353}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 13:55:10.000000000', 'files': ['defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/cdee58123df3eb83134bea9ce5161d741b090900', 'message': 'Fix apt pinning for ceph\n\nCeph apt pinning need to pin to ceph.com instead of RedHat.\napt policy :\n\n1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages\n     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64\n     origin download.ceph.com\n\nChange-Id: Ib95e96130a06d3dd92aa237080a04f762995a729\n'}]",0,605429,cdee58123df3eb83134bea9ce5161d741b090900,10,3,1,13095,,,0,"Fix apt pinning for ceph

Ceph apt pinning need to pin to ceph.com instead of RedHat.
apt policy :

1001 http://download.ceph.com/debian-luminous xenial/main amd64 Packages
     release o=ceph.com,a=stable,n=xenial,c=main,b=amd64
     origin download.ceph.com

Change-Id: Ib95e96130a06d3dd92aa237080a04f762995a729
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/29/605429/1 && git format-patch -1 --stdout FETCH_HEAD,['defaults/main.yml'],1,cdee58123df3eb83134bea9ce5161d741b090900,fix-apt-pinning,"ceph_apt_pinned_packages: [{ package: ""*"", release: ""ceph.com"", priority: 1001 }]","ceph_apt_pinned_packages: [{ package: ""*"", release: ""RedHat"", priority: 1001 }]",1,1
openstack%2Ftripleo-quickstart~master~I44fab1096bb17dbd9720041265a512efd0867525,openstack/tripleo-quickstart,master,I44fab1096bb17dbd9720041265a512efd0867525,Document the KVM accelerated mode for building VMs,MERGED,2018-09-26 16:40:58.000000000,2018-09-27 12:34:48.000000000,2018-09-27 12:34:48.000000000,"[{'_account_id': 4328}, {'_account_id': 6926}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-26 16:40:58.000000000', 'files': ['doc/source/getting-started.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/297df78c889e2be1c333aaa6a8d407bdff118944', 'message': 'Document the KVM accelerated mode for building VMs\n\nDepends-On: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\n\nChange-Id: I44fab1096bb17dbd9720041265a512efd0867525\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",3,605483,297df78c889e2be1c333aaa6a8d407bdff118944,11,7,1,6926,,,0,"Document the KVM accelerated mode for building VMs

Depends-On: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4

Change-Id: I44fab1096bb17dbd9720041265a512efd0867525
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/83/605483/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/getting-started.rst'],1,297df78c889e2be1c333aaa6a8d407bdff118944,bug/1743749,".. note:: By default, Quickstart builds the guests' images using qemu emulation (``LIBGUESTFS_BACKEND_SETTINGS=force_tcg``), which is slow but just works. In order to enable KVM acceleration, use ``export LIBGUESTFS_BACKEND_SETTINGS=network_bridge=virbr0``. It may be like a 4 times faster to build VM images in that mode, except that you may be hit by bug1743749_. .. _bug1743749: https://bugs.launchpad.net/tripleo/+bug/1743749 export LIBGUESTFS_BACKEND_SETTINGS=network_bridge=virbr0",,10,0
openstack%2Fos-net-config~master~I8f879072799cef29c09ddc74bd71069dd168ec88,openstack/os-net-config,master,I8f879072799cef29c09ddc74bd71069dd168ec88,Restart ivs/nvfswitch after config file is updated,MERGED,2018-09-24 20:38:34.000000000,2018-09-27 12:33:44.000000000,2018-09-27 12:24:53.000000000,"[{'_account_id': 3153}, {'_account_id': 12398}, {'_account_id': 18575}, {'_account_id': 21909}, {'_account_id': 21977}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 20:38:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/15b04fe11d7a77cb3857dd16523ab8f7e983a362', 'message': 'Restart ivs/nvfswitch after config file is updated\n\nThis change - https://review.openstack.org/#/c/561609/, removed the\nrestart of ivs/nvfswitch to avoid network interruptions. However,\nwhen a change is made to the config file then ivs/nvfswitch must be\nrestarted in order to pick up the change.\n\nChange-Id: I8f879072799cef29c09ddc74bd71069dd168ec88\n'}, {'number': 2, 'created': '2018-09-24 20:39:58.000000000', 'files': ['os_net_config/impl_ifcfg.py', 'releasenotes/notes/restart-ivs-nvfswitch-after-change-0825ea78aae8f138.yaml'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/2495c9ddaa0e7bde9b93e62b02ac146791ff1f21', 'message': 'Restart ivs/nvfswitch after config file is updated\n\nThis change - https://review.openstack.org/#/c/561609/, removed the\nrestart of ivs/nvfswitch to avoid network interruptions. However,\nwhen a change is made to the config file then ivs/nvfswitch must be\nrestarted in order to pick up the change.\n\nCloses-Bug: #1794182\nChange-Id: I8f879072799cef29c09ddc74bd71069dd168ec88\n'}]",0,604901,2495c9ddaa0e7bde9b93e62b02ac146791ff1f21,17,7,2,21909,,,0,"Restart ivs/nvfswitch after config file is updated

This change - https://review.openstack.org/#/c/561609/, removed the
restart of ivs/nvfswitch to avoid network interruptions. However,
when a change is made to the config file then ivs/nvfswitch must be
restarted in order to pick up the change.

Closes-Bug: #1794182
Change-Id: I8f879072799cef29c09ddc74bd71069dd168ec88
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/01/604901/2 && git format-patch -1 --stdout FETCH_HEAD,"['os_net_config/impl_ifcfg.py', 'releasenotes/notes/restart-ivs-nvfswitch-after-change-0825ea78aae8f138.yaml']",2,15b04fe11d7a77cb3857dd16523ab8f7e983a362,bug/1794182,"--- fixes: - When the ivs interface (or nfvswitch) configuration changes, ivs (or nvfswitch) needs to be restarted in order to pick up the new configuration. ",,15,2
openstack%2Ftripleo-heat-templates~master~Ie787693c0f5360529a81f6e03bdcae9e19488a2c,openstack/tripleo-heat-templates,master,Ie787693c0f5360529a81f6e03bdcae9e19488a2c,Cleanup ControllerStorageNfs role,MERGED,2018-09-09 22:41:31.000000000,2018-09-27 12:30:30.000000000,2018-09-27 12:24:50.000000000,"[{'_account_id': 6796}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-09 22:41:31.000000000', 'files': ['roles/ControllerStorageNfs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5d015ceb53515f15cb47e7cfea09265fb375aa3a', 'message': 'Cleanup ControllerStorageNfs role\n\n1) Complete the role description to include the main\npoint.\n\n2) Set reasonable CountDefault given that ganesha\nservice should be deployed in HA configuration.\n\nChange-Id: Ie787693c0f5360529a81f6e03bdcae9e19488a2c\n'}]",3,601137,5d015ceb53515f15cb47e7cfea09265fb375aa3a,27,7,1,9003,,,0,"Cleanup ControllerStorageNfs role

1) Complete the role description to include the main
point.

2) Set reasonable CountDefault given that ganesha
service should be deployed in HA configuration.

Change-Id: Ie787693c0f5360529a81f6e03bdcae9e19488a2c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/37/601137/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ControllerStorageNfs.yaml'],1,5d015ceb53515f15cb47e7cfea09265fb375aa3a,," Controller role that has all the controller services loaded, handles Database, Messaging and Network functions, and additionally runs a ganesha service as a CephFS to NFS gateway. The gateway serves NFS exports via a VIP on a new isolated StorageNFS network. # ganesha service should always be deployed in HA configuration. CountDefault: 3"," Controller role that has all the controler services loaded and handles Database, Messaging and Network functions. CountDefault: 1",6,3
openstack%2Ftripleo-common~stable%2Frocky~I08781fe2aa6472d3fae5c5f5d0babd1f7a3b9b2d,openstack/tripleo-common,stable/rocky,I08781fe2aa6472d3fae5c5f5d0babd1f7a3b9b2d,Set SSH server keep alive options,MERGED,2018-09-21 19:32:05.000000000,2018-09-27 12:28:16.000000000,2018-09-27 12:24:52.000000000,"[{'_account_id': 7144}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-21 19:32:05.000000000', 'files': ['releasenotes/notes/set-ssh-server-keep-alive-options-071e1b3b570e78a7.yaml', 'tripleo_common/actions/ansible.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b17791ae2ce2bd6dd5e888bdbb5318e53af4cea6', 'message': ""Set SSH server keep alive options\n\nWhen os-net-config configures the network configuration on the overcloud nodes\nssh connections can be dropped.\n\nSince we have ssh retries set to 8 in ansible.cfg, ansible would retry the task\nsince it was failed by a ssh connection error.\n\nHowever, the first task was actually still running and it eventually succeeds.\n\nThe second task that was kicked off by ansible as a retry, sees that the\ndeployment is already applied, but the notification file (*.notify.json) does\nnot yet exist since the first task is still in progress. This causes the second\ntask to fail with the error reported in the bug and the whole ansible-playbook\nrun to then fail.\n\nSetting ServerAliveInterval and ServerAliveCountMax ssh options seems to fix\nthe issue as ssh doesn't drop the first connection when these are configured.\n\nChange-Id: I08781fe2aa6472d3fae5c5f5d0babd1f7a3b9b2d\nCloses-Bug: #1792343\n(cherry picked from commit c0f41cae9f672c21f05fa7b0cfbfeb66d1cfe296)\n""}]",0,604455,b17791ae2ce2bd6dd5e888bdbb5318e53af4cea6,20,5,1,7144,,,0,"Set SSH server keep alive options

When os-net-config configures the network configuration on the overcloud nodes
ssh connections can be dropped.

Since we have ssh retries set to 8 in ansible.cfg, ansible would retry the task
since it was failed by a ssh connection error.

However, the first task was actually still running and it eventually succeeds.

The second task that was kicked off by ansible as a retry, sees that the
deployment is already applied, but the notification file (*.notify.json) does
not yet exist since the first task is still in progress. This causes the second
task to fail with the error reported in the bug and the whole ansible-playbook
run to then fail.

Setting ServerAliveInterval and ServerAliveCountMax ssh options seems to fix
the issue as ssh doesn't drop the first connection when these are configured.

Change-Id: I08781fe2aa6472d3fae5c5f5d0babd1f7a3b9b2d
Closes-Bug: #1792343
(cherry picked from commit c0f41cae9f672c21f05fa7b0cfbfeb66d1cfe296)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/55/604455/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/set-ssh-server-keep-alive-options-071e1b3b570e78a7.yaml', 'tripleo_common/actions/ansible.py']",2,b17791ae2ce2bd6dd5e888bdbb5318e53af4cea6,bug/1792343-stable/rocky, '-o ControlPersist=30m ' '-o ServerAliveInterval=5 ' '-o ServerAliveCountMax=5'), '-o ControlPersist=30m'),8,1
openstack%2Frally~master~I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228,openstack/rally,master,I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228,"Ensure that we support py34,py36,py37 envs",ABANDONED,2018-07-20 10:04:16.000000000,2018-09-27 12:27:15.000000000,,"[{'_account_id': 9545}, {'_account_id': 21528}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-20 10:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0b056c54b60cb70de2e2ed57a958c6e072dc3e95', 'message': ""Add more python jobs\n\n* Since configuration of zuul become bigger, let's move it to the\n  separate directory\n* Run unittests against python 3.6 and python 3.7 environemnts.\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n""}, {'number': 2, 'created': '2018-07-20 11:10:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/11a86c3c1908561f6f401aa881d60f38f738d844', 'message': ""Add more python jobs\n\n* Since configuration of zuul become bigger, let's move it to the\n  separate directory\n* Run unittests against python 3.6 and python 3.7 environemnts.\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n""}, {'number': 3, 'created': '2018-07-20 12:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6f4d2ce89279f49cef6fd52865b8f01922dba1e2', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Removed unised tests/ci/playbooks/base/post.yaml playbook\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 4, 'created': '2018-07-24 10:03:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/415910a289e1350ad257d4b27af9391dc513d6b7', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Removed unised tests/ci/playbooks/base/post.yaml playbook\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 5, 'created': '2018-07-24 10:37:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/0888278a2c0cfacc3ab75dd32ca8a381a12cb44c', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Removed unised tests/ci/playbooks/base/post.yaml playbook\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 6, 'created': '2018-07-24 10:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/6c868f01344ecbf0fc144a72409991bcc1d28297', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Removed unised tests/ci/playbooks/base/post.yaml playbook\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 7, 'created': '2018-07-24 11:44:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/d2eab60e90f2f79e681827a320e06cfc5b442462', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Remove unused tests/ci/playbooks/base/post.yaml playbook\n* Update requirements and u-c to support py37 env\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 8, 'created': '2018-07-26 11:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/7e09459d2ba0a3a1656876465a68c8c0bb90aad1', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Remove unused tests/ci/playbooks/base/post.yaml playbook\n* Update requirements and u-c to support py37 env\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 9, 'created': '2018-08-06 11:53:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/940369dfef9029bccb70406a6d3de9c4e685331c', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Remove unused tests/ci/playbooks/base/post.yaml playbook\n* Update requirements and u-c to support py37 env\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 10, 'created': '2018-08-06 13:07:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/425f53c87b58db84df1977e727841e4dcf19735e', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Remove unused tests/ci/playbooks/base/post.yaml playbook\n* Update requirements and u-c to support py37 env\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}, {'number': 11, 'created': '2018-08-06 13:42:33.000000000', 'files': ['test-requirements.txt', 'tests/unit/cli/commands/test_task.py', 'tests/unit/test_api.py', 'tests/unit/test_hacking.py', '.zuul.d/python-jobs.yaml', 'tests/ci/playbooks/pre-run-tox.yaml', 'upper-constraints.txt', 'rally/task/utils.py', 'rally/cli/commands/task.py', 'requirements.txt', 'rally/api.py', '.zuul.d/zuul.yaml', 'tests/unit/cli/commands/test_env.py', 'tests/ci/playbooks/base/post.yaml', 'setup.cfg', 'tox.ini', 'rally/cli/commands/env.py', 'CHANGELOG.rst'], 'web_link': 'https://opendev.org/openstack/rally/commit/a8624cace0b80e4cc2a8b968afa9726004bfbb32', 'message': 'Ensure that we support py34,py36,py37 envs\n\n* Add CI jobs for py34,py36,py37 envs\n  - Since configuration of zuul become bigger, it is moved to the\n    separate directory\n* Add proper trove classifiers\n* Sort table by ""Platform"" at `rally env check` command. It is needed to\n  make the result of unittests equal at python 2 and python 3 envs.\n  Also, the resulting table become more readable and user-friendly.\n* Remove unused tests/ci/playbooks/base/post.yaml playbook\n* Update requirements and u-c to support py37 env\n\nChange-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228\n'}]",0,584301,a8624cace0b80e4cc2a8b968afa9726004bfbb32,29,3,11,9545,,,0,"Ensure that we support py34,py36,py37 envs

* Add CI jobs for py34,py36,py37 envs
  - Since configuration of zuul become bigger, it is moved to the
    separate directory
* Add proper trove classifiers
* Sort table by ""Platform"" at `rally env check` command. It is needed to
  make the result of unittests equal at python 2 and python 3 envs.
  Also, the resulting table become more readable and user-friendly.
* Remove unused tests/ci/playbooks/base/post.yaml playbook
* Update requirements and u-c to support py37 env

Change-Id: I3cdbebb0a9c026b3d54f2bf9a75886f14c21b228
",git fetch https://review.opendev.org/openstack/rally refs/changes/01/584301/11 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.d/zuul.yaml', 'zuul.yaml']",2,0b056c54b60cb70de2e2ed57a958c6e072dc3e95,python,,- job: name: rally-install-ubuntu-xenial parent: base nodeset: ubuntu-xenial run: tests/ci/playbooks/rally-install/run.yaml timeout: 1800 - job: name: rally-install-centos-7 parent: base nodeset: centos-7 run: tests/ci/playbooks/rally-install/run.yaml timeout: 1800 - job: name: rally-database-migration parent: base nodeset: ubuntu-xenial run: tests/ci/playbooks/rally-database-migration/run.yaml timeout: 1800 - job: name: rally-tox-self parent: tox description: | Run test for rally project. Uses tox with the ``self`` environment. vars: tox_envlist: self - project: check: jobs: - rally-database-migration - rally-install-ubuntu-xenial - rally-install-centos-7 - openstack-tox-functional - rally-tox-self gate: jobs: - rally-database-migration - rally-install-ubuntu-xenial - rally-install-centos-7 - openstack-tox-functional - rally-tox-self ,79,47
openstack%2Ftripleo-heat-templates~master~If70da9804d8a26fff594f7282f64318fd6b79e2c,openstack/tripleo-heat-templates,master,If70da9804d8a26fff594f7282f64318fd6b79e2c,Allow to run bootstrap containers in privileged mode.,MERGED,2018-09-06 19:40:42.000000000,2018-09-27 12:24:58.000000000,2018-09-27 12:24:58.000000000,"[{'_account_id': 3153}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-09-06 19:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7d67a62cab890d27bb706921098119a921c35926', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 2, 'created': '2018-09-10 06:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7fad25e36cc7048a7b1376d4c5b72cb208a52101', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 3, 'created': '2018-09-14 08:32:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8be70b307d1c7b8bf9a1f3d69926e95d187b3342', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 4, 'created': '2018-09-19 01:19:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/77760d8bfced95090c13cb849ee15fd69fbdce0e', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 5, 'created': '2018-09-21 22:11:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/a80b65a3f3fc878f4159673d3901be9f25ef6cc4', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 6, 'created': '2018-09-23 15:50:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/076232be2828970bdc27c6fe1293ca28a12d8ba7', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 7, 'created': '2018-09-24 23:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c9504fab688ea771b7cdf397b40d3b55bb0ed9f3', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}, {'number': 8, 'created': '2018-09-26 23:35:30.000000000', 'files': ['docker/docker-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/99f9e599d344c69d5e88560186b9d97fd63bc65a', 'message': 'Allow to run bootstrap containers in privileged mode.\n\nThis will allow some containers to call out specific hosts commands,\nsuch as ""iptables"".\n\nChange-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c\n'}]",2,600533,99f9e599d344c69d5e88560186b9d97fd63bc65a,68,6,8,28223,,,0,"Allow to run bootstrap containers in privileged mode.

This will allow some containers to call out specific hosts commands,
such as ""iptables"".

Change-Id: If70da9804d8a26fff594f7282f64318fd6b79e2c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/33/600533/6 && git format-patch -1 --stdout FETCH_HEAD,['docker/docker-puppet.py'],1,7d67a62cab890d27bb706921098119a921c35926,podman/tag," cli_dcmd = ['--security-opt', 'label=disable', '--volume', '/usr/share/openstack-puppet/modules/:/usr/share/openstack-puppet/modules/:ro', service.get('prigileged', False), privileged = service[5] if len(service) > 5 else False log.debug('privileged %s' % privileged) cp -dR /tmp/puppet-etc/* /etc/puppet (config_volume,puppet_tags,manifest,config_image,volumes,privileged) = args[0] log.debug('privileged %s' % privileged) '--volume', '/etc/pki/tls/cert.pem:/etc/pki/tls/cert.pem:ro', # script injection '--volume', '%s:%s:z' % (sh_script, sh_script) ] if privileged: common_dcmd.push('--privileged') privileged = service[5] if len(service) > 5 else False process_map.append([config_volume, puppet_tags, manifest, config_image, volumes, privileged])"," cli_dcmd = ['--volume', '/usr/share/openstack-puppet/modules/:/usr/share/openstack-puppet/modules/:ro', cp -a /tmp/puppet-etc/* /etc/puppet (config_volume,puppet_tags,manifest,config_image,volumes) = args[0] '--volume', '/etc/pki/tls/cert.pem:/etc/pki/tls/cert.pem:ro'] process_map.append([config_volume, puppet_tags, manifest, config_image, volumes])",15,5
openstack%2Ftripleo-upgrade~stable%2Frocky~I626366470673001e5d86cb9756e994e001751e17,openstack/tripleo-upgrade,stable/rocky,I626366470673001e5d86cb9756e994e001751e17,Set container_images_file for containerized undercloud.,MERGED,2018-09-12 14:29:42.000000000,2018-09-27 12:24:57.000000000,2018-09-27 12:24:57.000000000,"[{'_account_id': 8297}, {'_account_id': 18851}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-12 14:29:42.000000000', 'files': ['tasks/upgrade/main.yml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/1366184c585dccece07293f933324a6943c5c50f', 'message': ""Set container_images_file for containerized undercloud.\n\nWhile performing upgrade to containerized undercloud it's needed\nto specify file with docker images to be used.\nGenerating this file is out of scope for tripleo-upgrade.\n\nChange-Id: I626366470673001e5d86cb9756e994e001751e17\n(cherry picked from commit ee96eea0f990533317519b9c0a404e0b3f03c6f9)\n""}]",0,602045,1366184c585dccece07293f933324a6943c5c50f,14,5,1,21537,,,0,"Set container_images_file for containerized undercloud.

While performing upgrade to containerized undercloud it's needed
to specify file with docker images to be used.
Generating this file is out of scope for tripleo-upgrade.

Change-Id: I626366470673001e5d86cb9756e994e001751e17
(cherry picked from commit ee96eea0f990533317519b9c0a404e0b3f03c6f9)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/45/602045/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/upgrade/main.yml', 'defaults/main.yml']",2,1366184c585dccece07293f933324a6943c5c50f,uc-containers-file-stable/rocky,"# undercloud.conf undercloud_conf: ""{{ working_dir }}/undercloud.conf"" # container registry file for overcloud# container prepare params env file uc_containers_prepare_file: ""containers-prepare-parameter.yaml"" ",# container registry file,21,1
openstack%2Ftripleo-heat-templates~master~I1fd78fd1eeb071788fc23ba343915ce7d6d14f02,openstack/tripleo-heat-templates,master,I1fd78fd1eeb071788fc23ba343915ce7d6d14f02,Pass NeutronMechanismDrivers parameter to prepare,MERGED,2018-09-25 01:55:18.000000000,2018-09-27 12:24:56.000000000,2018-09-27 12:24:55.000000000,"[{'_account_id': 4571}, {'_account_id': 8042}, {'_account_id': 14985}, {'_account_id': 16690}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-25 01:55:18.000000000', 'files': ['puppet/services/container-image-prepare.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6450d206c67d44ea866f2d2d44064e6f4d4eb6d2', 'message': 'Pass NeutronMechanismDrivers parameter to prepare\n\nThis change is part of the proposal to use the value of\nNeutronMechanismDrivers to determine what neutron images to prepare\n(specifically whether the Opendaylight or OVN images should be\nprepared).\n\nChange-Id: I1fd78fd1eeb071788fc23ba343915ce7d6d14f02\nPartial-Bug: #1794103\n'}]",2,604952,6450d206c67d44ea866f2d2d44064e6f4d4eb6d2,12,6,1,4571,,,0,"Pass NeutronMechanismDrivers parameter to prepare

This change is part of the proposal to use the value of
NeutronMechanismDrivers to determine what neutron images to prepare
(specifically whether the Opendaylight or OVN images should be
prepared).

Change-Id: I1fd78fd1eeb071788fc23ba343915ce7d6d14f02
Partial-Bug: #1794103
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/52/604952/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/container-image-prepare.j2.yaml'],1,6450d206c67d44ea866f2d2d44064e6f4d4eb6d2,bug/1794103, NeutronMechanismDrivers: default: 'openvswitch' description: | The mechanism drivers for the Neutron tenant network. type: comma_delimited_list NeutronMechanismDrivers: {get_param: NeutronMechanismDrivers},,7,0
openstack%2Ftripleo-common~stable%2Frocky~Ie7660894050e5eca251aaf8c10f0cc7e7d837dfc,openstack/tripleo-common,stable/rocky,Ie7660894050e5eca251aaf8c10f0cc7e7d837dfc,config: ignore missing server_id from the stack,MERGED,2018-09-26 12:56:40.000000000,2018-09-27 12:24:54.000000000,2018-09-27 12:24:54.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-26 12:56:40.000000000', 'files': ['tripleo_common/utils/config.py', 'releasenotes/notes/blacklisted_serverid_config-e079e64e8a04cdb4.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f86b2b4c55b2aa10612388e75f604faae969971a', 'message': ""config: ignore missing server_id from the stack\n\nWhen blacklisting nodes on the overcloud, we don't want to generated\na configuration with these servers.\nThis patch ignore the server when server_id can't be found in the stack\nwhen generating the configuration of the overcloud.\nA warning is shown so the operator knows this server isn't part of the\nconfiguration, probably due to blacklisting.\nIf getting the server name fails for another reason than a KeyError,\nwe fail the configuration generation and raise an exception with the\nerror message.\n\nChange-Id: Ie7660894050e5eca251aaf8c10f0cc7e7d837dfc\nCloses-Bug: #1793605\n(cherry picked from commit 272bd17c304d7d047ed75679568a09e9ebf7865b)\n""}]",0,605412,f86b2b4c55b2aa10612388e75f604faae969971a,8,4,1,3153,,,0,"config: ignore missing server_id from the stack

When blacklisting nodes on the overcloud, we don't want to generated
a configuration with these servers.
This patch ignore the server when server_id can't be found in the stack
when generating the configuration of the overcloud.
A warning is shown so the operator knows this server isn't part of the
configuration, probably due to blacklisting.
If getting the server name fails for another reason than a KeyError,
we fail the configuration generation and raise an exception with the
error message.

Change-Id: Ie7660894050e5eca251aaf8c10f0cc7e7d837dfc
Closes-Bug: #1793605
(cherry picked from commit 272bd17c304d7d047ed75679568a09e9ebf7865b)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/12/605412/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/utils/config.py', 'releasenotes/notes/blacklisted_serverid_config-e079e64e8a04cdb4.yaml']",2,f86b2b4c55b2aa10612388e75f604faae969971a,bug/1793605-stable/rocky,"--- fixes: - | Fixes `bug 1793605 <https://bugs.launchpad.net/tripleo/+bug/1793605>`__ so when nodes are blacklisted, they are not included in the Overcloud config. A warning will show that the server_id that was ignored if the it can't be found in the stack. ",,24,3
openstack%2Ftripleo-common~master~Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3,openstack/tripleo-common,master,Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3,Remove non-voting jobs from the gate,MERGED,2018-09-18 15:27:48.000000000,2018-09-27 12:24:51.000000000,2018-09-27 12:24:51.000000000,"[{'_account_id': 3153}, {'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-18 15:27:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fcb6f41a51bc7b6eac5f9ba8a58c6d1abc10db4c', 'message': 'Remove non-voting jobs from the gate\n\nThe scenario000 and scenario007 jobs are currently non-voting and should\nnot be in the gate.\n\nChange-Id: Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3\n'}, {'number': 2, 'created': '2018-09-25 13:10:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/07085f2ec08d41e91fd3f716593a134d41511427', 'message': 'Remove non-voting jobs from the gate\n\nThe scenario000 and scenario007 jobs are currently non-voting and should\nnot be in the gate.\n\nChange-Id: Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3\n'}, {'number': 3, 'created': '2018-09-26 12:13:56.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fb978f900f569b7b7bce39b3da10e5915f71a35a', 'message': 'Remove non-voting jobs from the gate\n\nThe scenario000 and scenario007 jobs are currently non-voting and should\nnot be in the gate.\n\nChange-Id: Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3\n'}]",0,603419,fb978f900f569b7b7bce39b3da10e5915f71a35a,49,10,3,14985,,,0,"Remove non-voting jobs from the gate

The scenario000 and scenario007 jobs are currently non-voting and should
not be in the gate.

Change-Id: Ie5a41dd837bc6c89a6015aaf7be6a1fd85b901c3
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/19/603419/3 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,fcb6f41a51bc7b6eac5f9ba8a58c6d1abc10db4c,fix-ci,, - tripleo-ci-centos-7-scenario000-multinode-oooq-container-updates: files: - workbooks/package_update.yaml - workbooks/baremetal.yaml - ^container-images/.*$ - tripleo_common/actions/deployment.py - tripleo_common/actions/container_images.py - tripleo_common/image/kolla_builder.py - tripleo-ci-centos-7-scenario007-multinode-oooq-container: files: - ^container-images/.*$ - tripleo_common/image/kolla_builder.py,0,12
openstack%2Fpython-tripleoclient~stable%2Frocky~I7543c8e61711f036140db20416a57447da6c4c18,openstack/python-tripleoclient,stable/rocky,I7543c8e61711f036140db20416a57447da6c4c18,Add a guard to break if no connection,MERGED,2018-09-19 13:48:46.000000000,2018-09-27 12:24:49.000000000,2018-09-27 12:24:48.000000000,"[{'_account_id': 3153}, {'_account_id': 6796}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-09-19 13:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bf4199783bd0ff00850e3d40f711d789ed2cbc20', 'message': ""Add a guard to break if no connection\n\nIf the WebSocket connection is already disconnected we don't have to\nwait for messages\n\nChange-Id: I7543c8e61711f036140db20416a57447da6c4c18\nCloses-Bug: #1793264\n""}, {'number': 2, 'created': '2018-09-19 13:50:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4376f8379acd62ada80e4ecfa39ffa08bc34a472', 'message': ""Add a guard to break if no connection\n\nIf the WebSocket connection is already disconnected we don't have to\nwait for messages\n\nChange-Id: I7543c8e61711f036140db20416a57447da6c4c18\nCloses-Bug: #1793264\n(cherry picked from commit 99b7a3d1d15813fd8d07aa36636feb44516dc523)\n""}, {'number': 3, 'created': '2018-09-26 11:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2ff71b2ec82d5ad56ef9e0d483ed3ff75c6887b0', 'message': ""Add a guard to break if no connection\n\nIf the WebSocket connection is already disconnected we don't have to\nwait for messages\n\nChange-Id: I7543c8e61711f036140db20416a57447da6c4c18\nCloses-Bug: #1793264\n(cherry picked from commit 99b7a3d1d15813fd8d07aa36636feb44516dc523)\n""}, {'number': 4, 'created': '2018-09-26 12:01:02.000000000', 'files': ['tripleoclient/plugin.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d476a6ca714fca39b75a187500ab5eb393f17083', 'message': ""Add a guard to break if no connection\n\nIf the WebSocket connection is already disconnected we don't have to\nwait for messages\n\nChange-Id: I7543c8e61711f036140db20416a57447da6c4c18\nCloses-Bug: #1793264\n(cherry picked from commit 99b7a3d1d15813fd8d07aa36636feb44516dc523)\n""}]",0,603804,d476a6ca714fca39b75a187500ab5eb393f17083,22,16,4,27898,,,0,"Add a guard to break if no connection

If the WebSocket connection is already disconnected we don't have to
wait for messages

Change-Id: I7543c8e61711f036140db20416a57447da6c4c18
Closes-Bug: #1793264
(cherry picked from commit 99b7a3d1d15813fd8d07aa36636feb44516dc523)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/04/603804/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/plugin.py'],1,bf4199783bd0ff00850e3d40f711d789ed2cbc20,bug/1793264, if not self._ws.connected: return ,,3,0
openstack%2Fnova~stable%2Focata~Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a,openstack/nova,stable/ocata,Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a,[placement] Retry allocation writes server side,ABANDONED,2018-08-10 18:36:53.000000000,2018-09-27 12:01:17.000000000,,"[{'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-10 18:36:53.000000000', 'files': ['nova/exception.py', 'nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/efdec3bf3ae7f4d5724c3f99a482a1c46e7db0d9', 'message': '[placement] Retry allocation writes server side\n\nThis change adds a fast retry loop around\nAllocationList._set_allocations if a resource provider generation\nconflict happens. It turns out that under high concurrency of allocation\nclaims being made on the same resource provider conflicts can be quite\ncommon and client side retries are insufficient.\n\nBecause both consumer generation and resource provider generations had\nraised the same exception there was no way to distinguish between the\ntwo so a child of ConcurrentUpdateDetected has been created as\nResourceProviderConcurrentUpdateDetected. In the future this will allow\nus to send different error codes to the client as well, but that change\nis not done here.\n\nWhen the conflict is detected, all the resource providers in the\nAllocationList are reloaded and the list objects refreshed.\n\nLogging is provided to indicate:\n\n* at debug that a retry is going to happen\n* at warning that all the retries failed and the client is going to\n  see the conflict\n\nThe tests for this are a bit funky: Some mocks are used to cause the\nconflicts, then the real actions after a couple of iterations.\n\nThis was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with\nconflicts because exceptions, tests and object files were moved to\nnew locations with Rocky and the AllocationList.create_all method was\nrenamed to the more accurate replace_all. Prior to Rocky there were\nno Consumer objects and fewer helper methods in functional tests,\nso the test is adjusted accordingly.\n\nThe backport from queens to pike conflicted on a different docstring on\nthe set_allocations method. The docstring from queens was maintained as\nthe info it contains remains true and useful.\n\nThe backport from pike to ocata confliced on the name of a context\nvariable in the test. The modern version was ctx. The older tests\nexpect context. Also, the method _set_allocations is a static method\nin ocata, so the mock in the include test did not need to be a\nfunctools.partial.\n\nChange-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a\nCloses-Bug: #1719933\n(cherry picked from commit 72e4c4c8d7fb146862b899337626485dad10f15b)\n'}]",0,591042,efdec3bf3ae7f4d5724c3f99a482a1c46e7db0d9,7,5,1,11564,,,0,"[placement] Retry allocation writes server side

This change adds a fast retry loop around
AllocationList._set_allocations if a resource provider generation
conflict happens. It turns out that under high concurrency of allocation
claims being made on the same resource provider conflicts can be quite
common and client side retries are insufficient.

Because both consumer generation and resource provider generations had
raised the same exception there was no way to distinguish between the
two so a child of ConcurrentUpdateDetected has been created as
ResourceProviderConcurrentUpdateDetected. In the future this will allow
us to send different error codes to the client as well, but that change
is not done here.

When the conflict is detected, all the resource providers in the
AllocationList are reloaded and the list objects refreshed.

Logging is provided to indicate:

* at debug that a retry is going to happen
* at warning that all the retries failed and the client is going to
  see the conflict

The tests for this are a bit funky: Some mocks are used to cause the
conflicts, then the real actions after a couple of iterations.

This was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with
conflicts because exceptions, tests and object files were moved to
new locations with Rocky and the AllocationList.create_all method was
renamed to the more accurate replace_all. Prior to Rocky there were
no Consumer objects and fewer helper methods in functional tests,
so the test is adjusted accordingly.

The backport from queens to pike conflicted on a different docstring on
the set_allocations method. The docstring from queens was maintained as
the info it contains remains true and useful.

The backport from pike to ocata confliced on the name of a context
variable in the test. The modern version was ctx. The older tests
expect context. Also, the method _set_allocations is a static method
in ocata, so the mock in the include test did not need to be a
functools.partial.

Change-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a
Closes-Bug: #1719933
(cherry picked from commit 72e4c4c8d7fb146862b899337626485dad10f15b)
",git fetch https://review.opendev.org/openstack/nova refs/changes/42/591042/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py']",3,efdec3bf3ae7f4d5724c3f99a482a1c46e7db0d9,bug/1719933,"def add_inventory(rp, rc, total, **kwargs): kwargs.setdefault('max_unit', total) inv = rp_obj.Inventory(rp._context, resource_provider=rp, resource_class=rc, total=total, **kwargs) inv.obj_set_defaults() rp.add_inventory(inv) return inv @mock.patch('nova.objects.resource_provider.LOG') def test_set_allocations_retry(self, mock_log): """"""Test server side allocation write retry handling."""""" # Create a single resource provider and give it some inventory. rp1 = rp_obj.ResourceProvider( self.context, name='rp1', uuid=uuidsentinel.rp1) rp1.create() add_inventory(rp1, fields.ResourceClass.VCPU, 24, allocation_ratio=16.0) add_inventory(rp1, fields.ResourceClass.MEMORY_MB, 1024, min_unit=64, max_unit=1024, step_size=64) original_generation = rp1.generation # Verify the generation is what we expect (we'll be checking again # later). self.assertEqual(2, original_generation) inst_consumer = uuidsentinel.instance alloc_list = rp_obj.AllocationList(context=self.context, objects=[ rp_obj.Allocation( context=self.context, consumer_id=inst_consumer, resource_provider=rp1, resource_class=fields.ResourceClass.VCPU, used=12), rp_obj.Allocation( context=self.context, consumer_id=inst_consumer, resource_provider=rp1, resource_class=fields.ResourceClass.MEMORY_MB, used=1024) ]) # Make sure the right exception happens when the retry loop expires. with mock.patch.object(rp_obj.AllocationList, 'RP_CONFLICT_RETRY_COUNT', 0): self.assertRaises( exception.ResourceProviderConcurrentUpdateDetected, alloc_list.create_all) mock_log.warning.assert_called_with( 'Exceeded retry limit of %d on allocations write', 0) # Make sure the right thing happens after a small number of failures. # There's a bit of mock magic going on here to enusre that we can # both do some side effects on _set_allocations as well as have the # real behavior. Two generation conflicts and then a success. mock_log.reset_mock() with mock.patch.object(rp_obj.AllocationList, 'RP_CONFLICT_RETRY_COUNT', 3): unmocked_set = rp_obj.AllocationList._set_allocations with mock.patch( 'nova.objects.resource_provider.' 'AllocationList._set_allocations') as mock_set: exceptions = iter([ exception.ResourceProviderConcurrentUpdateDetected(), exception.ResourceProviderConcurrentUpdateDetected(), ]) def side_effect(*args, **kwargs): try: raise next(exceptions) except StopIteration: return unmocked_set(*args, **kwargs) mock_set.side_effect = side_effect alloc_list.create_all() self.assertEqual(2, mock_log.debug.call_count) mock_log.debug.called_with( 'Retrying allocations write on resource provider ' 'generation conflict') self.assertEqual(3, mock_set.call_count) # Confirm we're using a different rp object after the change # and that it has a higher generation. new_rp = alloc_list[0].resource_provider self.assertEqual(original_generation, rp1.generation) self.assertEqual(original_generation + 1, new_rp.generation) ",,142,5
openstack%2Fnova~stable%2Fpike~Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a,openstack/nova,stable/pike,Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a,[placement] Retry allocation writes server side,ABANDONED,2018-08-10 10:57:27.000000000,2018-09-27 12:00:57.000000000,,"[{'_account_id': 6873}, {'_account_id': 9373}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11564}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 19944}, {'_account_id': 22348}, {'_account_id': 27336}]","[{'number': 1, 'created': '2018-08-10 10:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5c74eb6d3f95fe8e8a23c6bfe3136a7807de9803', 'message': '[placement] Retry allocation writes server side\n\nThis change adds a fast retry loop around\nAllocationList._set_allocations if a resource provider generation\nconflict happens. It turns out that under high concurrency of allocation\nclaims being made on the same resource provider conflicts can be quite\ncommon and client side retries are insufficient.\n\nBecause both consumer generation and resource provider generations had\nraised the same exception there was no way to distinguish between the\ntwo so a child of ConcurrentUpdateDetected has been created as\nResourceProviderConcurrentUpdateDetected. In the future this will allow\nus to send different error codes to the client as well, but that change\nis not done here.\n\nWhen the conflict is detected, all the resource providers in the\nAllocationList are reloaded and the list objects refreshed.\n\nLogging is provided to indicate:\n\n* at debug that a retry is going to happen\n* at warning that all the retries failed and the client is going to\n  see the conflict\n\nThe tests for this are a bit funky: Some mocks are used to cause the\nconflicts, then the real actions after a couple of iterations.\n\nThis was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with\nconflicts because exceptions, tests and object files were moved to\nnew locations with Rocky and the AllocationList.create_all method was\nrenamed to the more accurate replace_all. Prior to Rocky there were\nno Consumer objects and fewer helper methods in functional tests,\nso the test is adjusted accordingly.\n\nThe backport from queens to pike conflicted on a different docstring on\nthe set_allocations method. The docstring from queens was maintained as\nthe info it contains remains true and useful.\n\nChange-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a\nCloses-Bug: #1719933\n(cherry picked from commit 72e4c4c8d7fb146862b899337626485dad10f15b)\n'}, {'number': 2, 'created': '2018-08-14 09:28:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3071a13824ff452426aedfc42a13d6ab6e7153b2', 'message': '[placement] Retry allocation writes server side\n\nThis change adds a fast retry loop around\nAllocationList._set_allocations if a resource provider generation\nconflict happens. It turns out that under high concurrency of allocation\nclaims being made on the same resource provider conflicts can be quite\ncommon and client side retries are insufficient.\n\nBecause both consumer generation and resource provider generations had\nraised the same exception there was no way to distinguish between the\ntwo so a child of ConcurrentUpdateDetected has been created as\nResourceProviderConcurrentUpdateDetected. In the future this will allow\nus to send different error codes to the client as well, but that change\nis not done here.\n\nWhen the conflict is detected, all the resource providers in the\nAllocationList are reloaded and the list objects refreshed.\n\nLogging is provided to indicate:\n\n* at debug that a retry is going to happen\n* at warning that all the retries failed and the client is going to\n  see the conflict\n\nThe tests for this are a bit funky: Some mocks are used to cause the\nconflicts, then the real actions after a couple of iterations.\n\nThis was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with\nconflicts because exceptions, tests and object files were moved to\nnew locations with Rocky and the AllocationList.create_all method was\nrenamed to the more accurate replace_all. Prior to Rocky there were\nno Consumer objects and fewer helper methods in functional tests,\nso the test is adjusted accordingly.\n\nThe backport from queens to pike conflicted on a different docstring on\nthe set_allocations method. The docstring from queens was maintained as\nthe info it contains remains true and useful.\n\nChange-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a\nCloses-Bug: #1719933\n(cherry picked from commit 66a47b7623035cff38a12fdace9a325bbfdd9a14)\n'}, {'number': 3, 'created': '2018-09-17 14:26:56.000000000', 'files': ['nova/exception.py', 'nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/854b6af7ede65626f2dbfa33603f882b32da36f9', 'message': '[placement] Retry allocation writes server side\n\nThis change adds a fast retry loop around\nAllocationList._set_allocations if a resource provider generation\nconflict happens. It turns out that under high concurrency of allocation\nclaims being made on the same resource provider conflicts can be quite\ncommon and client side retries are insufficient.\n\nBecause both consumer generation and resource provider generations had\nraised the same exception there was no way to distinguish between the\ntwo so a child of ConcurrentUpdateDetected has been created as\nResourceProviderConcurrentUpdateDetected. In the future this will allow\nus to send different error codes to the client as well, but that change\nis not done here.\n\nWhen the conflict is detected, all the resource providers in the\nAllocationList are reloaded and the list objects refreshed.\n\nLogging is provided to indicate:\n\n* at debug that a retry is going to happen\n* at warning that all the retries failed and the client is going to\n  see the conflict\n\nThe tests for this are a bit funky: Some mocks are used to cause the\nconflicts, then the real actions after a couple of iterations.\n\nThis was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with\nconflicts because exceptions, tests and object files were moved to\nnew locations with Rocky and the AllocationList.create_all method was\nrenamed to the more accurate replace_all. Prior to Rocky there were\nno Consumer objects and fewer helper methods in functional tests,\nso the test is adjusted accordingly.\n\nThe backport from queens to pike conflicted on a different docstring on\nthe set_allocations method. The docstring from queens was maintained as\nthe info it contains remains true and useful.\n\nChange-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a\nCloses-Bug: #1719933\n(cherry picked from commit 66a47b7623035cff38a12fdace9a325bbfdd9a14)\n'}]",2,590745,854b6af7ede65626f2dbfa33603f882b32da36f9,27,10,3,11564,,,0,"[placement] Retry allocation writes server side

This change adds a fast retry loop around
AllocationList._set_allocations if a resource provider generation
conflict happens. It turns out that under high concurrency of allocation
claims being made on the same resource provider conflicts can be quite
common and client side retries are insufficient.

Because both consumer generation and resource provider generations had
raised the same exception there was no way to distinguish between the
two so a child of ConcurrentUpdateDetected has been created as
ResourceProviderConcurrentUpdateDetected. In the future this will allow
us to send different error codes to the client as well, but that change
is not done here.

When the conflict is detected, all the resource providers in the
AllocationList are reloaded and the list objects refreshed.

Logging is provided to indicate:

* at debug that a retry is going to happen
* at warning that all the retries failed and the client is going to
  see the conflict

The tests for this are a bit funky: Some mocks are used to cause the
conflicts, then the real actions after a couple of iterations.

This was backported from 72e4c4c8d7fb146862b899337626485dad10f15b with
conflicts because exceptions, tests and object files were moved to
new locations with Rocky and the AllocationList.create_all method was
renamed to the more accurate replace_all. Prior to Rocky there were
no Consumer objects and fewer helper methods in functional tests,
so the test is adjusted accordingly.

The backport from queens to pike conflicted on a different docstring on
the set_allocations method. The docstring from queens was maintained as
the info it contains remains true and useful.

Change-Id: Id614d609fc8f3ed2d2ff29a2b52143f53b3b1b9a
Closes-Bug: #1719933
(cherry picked from commit 66a47b7623035cff38a12fdace9a325bbfdd9a14)
",git fetch https://review.opendev.org/openstack/nova refs/changes/45/590745/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/objects/resource_provider.py', 'nova/tests/functional/db/test_resource_provider.py']",3,5c74eb6d3f95fe8e8a23c6bfe3136a7807de9803,bug/1719933,"import functoolsdef add_inventory(rp, rc, total, **kwargs): kwargs.setdefault('max_unit', total) inv = rp_obj.Inventory(rp._context, resource_provider=rp, resource_class=rc, total=total, **kwargs) inv.obj_set_defaults() rp.add_inventory(inv) return inv @mock.patch('nova.objects.resource_provider.LOG') def test_set_allocations_retry(self, mock_log): """"""Test server side allocation write retry handling."""""" # Create a single resource provider and give it some inventory. rp1 = rp_obj.ResourceProvider( self.ctx, name='rp1', uuid=uuidsentinel.rp1) rp1.create() add_inventory(rp1, fields.ResourceClass.VCPU, 24, allocation_ratio=16.0) add_inventory(rp1, fields.ResourceClass.MEMORY_MB, 1024, min_unit=64, max_unit=1024, step_size=64) original_generation = rp1.generation # Verify the generation is what we expect (we'll be checking again # later). self.assertEqual(2, original_generation) inst_consumer = uuidsentinel.instance alloc_list = rp_obj.AllocationList(context=self.ctx, objects=[ rp_obj.Allocation( context=self.ctx, consumer_id=inst_consumer, resource_provider=rp1, resource_class=fields.ResourceClass.VCPU, used=12), rp_obj.Allocation( context=self.ctx, consumer_id=inst_consumer, resource_provider=rp1, resource_class=fields.ResourceClass.MEMORY_MB, used=1024) ]) # Make sure the right exception happens when the retry loop expires. with mock.patch.object(rp_obj.AllocationList, 'RP_CONFLICT_RETRY_COUNT', 0): self.assertRaises( exception.ResourceProviderConcurrentUpdateDetected, alloc_list.create_all) mock_log.warning.assert_called_with( 'Exceeded retry limit of %d on allocations write', 0) # Make sure the right thing happens after a small number of failures. # There's a bit of mock magic going on here to enusre that we can # both do some side effects on _set_allocations as well as have the # real behavior. Two generation conflicts and then a success. mock_log.reset_mock() with mock.patch.object(rp_obj.AllocationList, 'RP_CONFLICT_RETRY_COUNT', 3): unmocked_set = functools.partial( rp_obj.AllocationList._set_allocations, alloc_list) with mock.patch( 'nova.objects.resource_provider.' 'AllocationList._set_allocations') as mock_set: exceptions = iter([ exception.ResourceProviderConcurrentUpdateDetected(), exception.ResourceProviderConcurrentUpdateDetected(), ]) def side_effect(*args, **kwargs): try: raise next(exceptions) except StopIteration: return unmocked_set(*args, **kwargs) mock_set.side_effect = side_effect alloc_list.create_all() self.assertEqual(2, mock_log.debug.call_count) mock_log.debug.called_with( 'Retrying allocations write on resource provider ' 'generation conflict') self.assertEqual(3, mock_set.call_count) # Confirm we're using a different rp object after the change # and that it has a higher generation. new_rp = alloc_list[0].resource_provider self.assertEqual(original_generation, rp1.generation) self.assertEqual(original_generation + 1, new_rp.generation) ",,144,5
openstack%2Fpython-tripleoclient~stable%2Frocky~I65b45c00df65ec910b4fd620c475d4ee1d691e30,openstack/python-tripleoclient,stable/rocky,I65b45c00df65ec910b4fd620c475d4ee1d691e30,Use workflow config_download_export,MERGED,2018-09-24 19:22:19.000000000,2018-09-27 11:58:24.000000000,2018-09-27 11:58:23.000000000,"[{'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 19:22:19.000000000', 'files': ['tripleoclient/workflows/deployment.py', 'tripleoclient/tests/v1/overcloud_config/test_overcloud_config.py', 'tripleoclient/v1/overcloud_config.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/607d4835af54cba13f320003966d37709d1bb372', 'message': 'Use workflow config_download_export\n\nUpdate openstack overcloud config download to go through the API and use\nthe workflow added in the depends-on patch.\n\nChange-Id: I65b45c00df65ec910b4fd620c475d4ee1d691e30\nCloses-Bug: #1783646\nDepends-On: Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3\n(cherry picked from commit 611cf819a95735c77d13f9077abe8430a91597dd)\n'}]",0,604885,607d4835af54cba13f320003966d37709d1bb372,7,3,1,7144,,,0,"Use workflow config_download_export

Update openstack overcloud config download to go through the API and use
the workflow added in the depends-on patch.

Change-Id: I65b45c00df65ec910b4fd620c475d4ee1d691e30
Closes-Bug: #1783646
Depends-On: Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3
(cherry picked from commit 611cf819a95735c77d13f9077abe8430a91597dd)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/85/604885/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/workflows/deployment.py', 'tripleoclient/tests/v1/overcloud_config/test_overcloud_config.py', 'tripleoclient/v1/overcloud_config.py']",3,607d4835af54cba13f320003966d37709d1bb372,bug/1783646-stable/rocky,"import shutil from six.moves.urllib import requestfrom oslo_concurrency import processutilsfrom tripleoclient.workflows import deployment def create_config_dir(self, config_dir, preserve_config_dir=True): # Create config directory if os.path.exists(config_dir) and preserve_config_dir is False: try: self.log.info(""Directory %s already exists, removing"" % config_dir) shutil.rmtree(config_dir) except OSError as e: message = 'Failed to remove: %s, error: %s' % (config_dir, str(e)) raise OSError(message) if not os.path.exists(config_dir): os.makedirs(config_dir) self.create_config_dir(config_dir, preserve_config_dir) print(""Starting config-download export..."") tempurl = deployment.config_download_export( self.app.client_manager, plan=name, config_type=config_type ) print(""Finished config-download export."") self.log.debug(""config-download tempurl: %s"" % tempurl) f = request.urlopen(tempurl) tarball_contents = f.read() tarball_name = ""%s-config.tar.gz"" % name tarball_path = os.path.join(config_dir, tarball_name) with open(tarball_path, 'w') as f: f.write(tarball_contents) print(""Extracting config-download..."") cmd = ['/usr/bin/tar', '-C', config_dir, '-xf', tarball_path] processutils.execute(*cmd) ""into: {0}"".format(config_dir))","from tripleo_common.utils import config as ooo_config # Get clients clients = self.app.client_manager config = ooo_config.Config(clients.orchestration) config_path = config.download_config(name, config_dir, config_type, preserve_config_dir) ""into: {0}"".format(config_path))",92,13
openstack%2Ftripleo-common~stable%2Frocky~Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3,openstack/tripleo-common,stable/rocky,Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3,Add workflow for config-download export,MERGED,2018-09-24 19:22:11.000000000,2018-09-27 11:58:22.000000000,2018-09-27 11:58:22.000000000,"[{'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 19:22:11.000000000', 'files': ['workbooks/deployment.yaml', 'releasenotes/notes/workflow-config-download-export-d22f3eb958b8c97a.yaml', 'tripleo_common/actions/config.py', 'tripleo_common/utils/config.py', 'tripleo_common/tests/actions/test_config.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/792bc26fb8446ede0475d99ec6e3e51a074eaee5', 'message': 'Add workflow for config-download export\n\nAdd a new workflow, config_download_export, to export the\nconfig_download files by providing a swift tempurl of the generated\ntarball.\n\nThe CLI will be migrated to using this workflow.\n\nPartial-Bug: #1783646\nChange-Id: Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3\n(cherry picked from commit e1556486c57f839c39171f92de2279c41f6577a2)\n'}]",0,604884,792bc26fb8446ede0475d99ec6e3e51a074eaee5,11,4,1,7144,,,0,"Add workflow for config-download export

Add a new workflow, config_download_export, to export the
config_download files by providing a swift tempurl of the generated
tarball.

The CLI will be migrated to using this workflow.

Partial-Bug: #1783646
Change-Id: Ic3d3667a7e2d0b445a4ace4d9aa8643062eb9cf3
(cherry picked from commit e1556486c57f839c39171f92de2279c41f6577a2)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/84/604884/1 && git format-patch -1 --stdout FETCH_HEAD,"['workbooks/deployment.yaml', 'releasenotes/notes/workflow-config-download-export-d22f3eb958b8c97a.yaml', 'tripleo_common/actions/config.py', 'tripleo_common/utils/config.py', 'tripleo_common/tests/actions/test_config.py']",5,792bc26fb8446ede0475d99ec6e3e51a074eaee5,bug/1783646-stable/rocky," self.assertEqual(2, self.swift.put_object.call_count) self.assertEqual(mock.call('config-overcloud', 'config-overcloud.tar.gz', ''), self.swift.put_object.call_args_list[1])", self.swift.put_object.assert_called_once(),86,2
openstack%2Ftripleo-heat-templates~master~Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c,openstack/tripleo-heat-templates,master,Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c,Pacemaker-cinder-volume & pacemaker-cinder-backup log path fix,MERGED,2018-08-29 12:16:24.000000000,2018-09-27 11:58:20.000000000,2018-09-27 11:58:20.000000000,"[{'_account_id': 5241}, {'_account_id': 6926}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 22954}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-29 12:16:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8501abd7e883e18a5a616ffe1afa08e2a91c4bd9', 'message': 'Pacemaker-cinder-volume log path fix\n\nAdded the inheritance service_config_settings for\npuppet/services/pacemaker/cinder-volume.yaml\n\nOverwrite the log path on the\ndocker/services/pacemaker/cinder-volume.yaml\n\nChange-Id: Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c\n'}, {'number': 2, 'created': '2018-09-13 06:43:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/465ac0f9682489ed2e84e4f28281882625dae1e2', 'message': 'Pacemaker-cinder-volume & pacemaker-cinder-backup log path fix\n\nAs can be seen in the gate [1][2], the path for the\nservices are not set correctly.\n\nAdded the inheritance service_config_settings for\npuppet/services/pacemaker/cinder-volume.yaml &\npuppet/services/pacemaker/cinder-backup.yaml\n\nOverwrite the log path on the\ndocker/services/pacemaker/cinder-volume.yaml &\ndocker/services/pacemaker/cinder-backup.yaml\n\n[1]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_backup.conf.txt.gz\n[2]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_volume.conf.txt.gz\n\nDepends-On: If253da4f0f89221dc6ddacc280c984079c6a3c7f\nChange-Id: Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c\n'}, {'number': 3, 'created': '2018-09-19 08:52:06.000000000', 'files': ['docker/services/pacemaker/cinder-volume.yaml', 'puppet/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'puppet/services/pacemaker/cinder-backup.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/fd172137157dfdc7d7c6ab3089f005086d629e05', 'message': 'Pacemaker-cinder-volume & pacemaker-cinder-backup log path fix\n\nAs can be seen in the gate [1][2], the path for the\nservices are not set correctly.\n\nAdded the inheritance service_config_settings for\npuppet/services/pacemaker/cinder-volume.yaml &\npuppet/services/pacemaker/cinder-backup.yaml\n\nOverwrite the log path on the\ndocker/services/pacemaker/cinder-volume.yaml &\ndocker/services/pacemaker/cinder-backup.yaml\n\n[1]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_backup.conf.txt.gz\n[2]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_volume.conf.txt.gz\n\nDepends-On: If253da4f0f89221dc6ddacc280c984079c6a3c7f\nChange-Id: Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c\n'}]",0,597462,fd172137157dfdc7d7c6ab3089f005086d629e05,41,8,3,22954,,,0,"Pacemaker-cinder-volume & pacemaker-cinder-backup log path fix

As can be seen in the gate [1][2], the path for the
services are not set correctly.

Added the inheritance service_config_settings for
puppet/services/pacemaker/cinder-volume.yaml &
puppet/services/pacemaker/cinder-backup.yaml

Overwrite the log path on the
docker/services/pacemaker/cinder-volume.yaml &
docker/services/pacemaker/cinder-backup.yaml

[1]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_backup.conf.txt.gz
[2]http://logs.openstack.org/36/594836/1/check/tripleo-ci-centos-7-scenario002-multinode-oooq-container/427de6c/logs/subnode-2/var/log/config-data/fluentd/etc/fluentd/config.d/100-openstack-cinder_volume.conf.txt.gz

Depends-On: If253da4f0f89221dc6ddacc280c984079c6a3c7f
Change-Id: Iaf2ab01a501e8f5ef15ac3618eac5df67fabcf5c
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/597462/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/cinder-volume.yaml', 'puppet/services/pacemaker/cinder-volume.yaml']",2,8501abd7e883e18a5a616ffe1afa08e2a91c4bd9,log_path_fix," service_config_settings: {get_attr: [CinderVolumeBase, role_data, service_config_settings]}",,14,1
openstack%2Ftripleo-common~master~I2ed9dcac8f7bc212f55571eedee7572d8f0becf7,openstack/tripleo-common,master,I2ed9dcac8f7bc212f55571eedee7572d8f0becf7,Optimize Heat stack check when processing roles,MERGED,2018-09-25 10:11:11.000000000,2018-09-27 11:58:18.000000000,2018-09-27 11:58:18.000000000,"[{'_account_id': 4328}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-25 10:11:11.000000000', 'files': ['tripleo_common/actions/templates.py', 'tripleo_common/tests/actions/test_templates.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e29cb1dbfdce3d9a2d035daed46781b85b095a96', 'message': 'Optimize Heat stack check when processing roles\n\nWhen checking for compatibility when upgrading networks, we check if the\nstack exists for every single network. Including on initial deployment.\nThis makes the check once, and pass on the result.\n\nChange-Id: I2ed9dcac8f7bc212f55571eedee7572d8f0becf7\n'}]",0,605029,e29cb1dbfdce3d9a2d035daed46781b85b095a96,10,5,1,7385,,,0,"Optimize Heat stack check when processing roles

When checking for compatibility when upgrading networks, we check if the
stack exists for every single network. Including on initial deployment.
This makes the check once, and pass on the result.

Change-Id: I2ed9dcac8f7bc212f55571eedee7572d8f0becf7
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/29/605029/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/actions/templates.py', 'tripleo_common/tests/actions/test_templates.py']",2,e29cb1dbfdce3d9a2d035daed46781b85b095a96,heat-stack-presence," @mock.patch('tripleo_common.actions.base.TripleOAction.' 'get_orchestration_client') def test_run(self, mock_get_heat_client, mock_get_object_client, @mock.patch('tripleo_common.actions.base.TripleOAction.' 'get_orchestration_client') def test_process_custom_roles(self, get_heat_client_mock, get_obj_client_mock, resource_exists_mock): @mock.patch('tripleo_common.actions.base.TripleOAction.' 'get_orchestration_client') self, snippet, get_heat_client_mock, get_obj_client_mock, resource_exists_mock): @mock.patch('tripleo_common.actions.base.TripleOAction' '.get_orchestration_client') def test_custom_roles_networks(self, get_heat_client_mock, get_obj_client_mock, resource_exists_mock): stack = mock.MagicMock(stack_name='overcloud') heat_client, stack, 'Networks', 'InternalNetwork', mock_ctx)) stack = mock.MagicMock(stack_name='overcloud') heat_client, stack, 'Networks', 'InternalNetwork', mock_ctx)) @mock.patch('tripleo_common.actions.base.TripleOAction.' 'get_orchestration_client') def test_legacy_api_network_exists(self, get_heat_client_mock, get_obj_client_mock, j2_mock, @mock.patch('tripleo_common.actions.base.TripleOAction.' 'get_orchestration_client') def test_no_legacy_api_network_exists(self, get_heat_client_mock, get_obj_client_mock, j2_mock,"," def test_run(self, mock_get_object_client, def test_process_custom_roles(self, get_obj_client_mock, resource_exists_mock): self, snippet, get_obj_client_mock, resource_exists_mock): def test_custom_roles_networks(self, get_obj_client_mock, resource_exists_mock): heat_client.stacks.get.return_value = mock.MagicMock( stack_name='overcloud') 'Networks', 'InternalNetwork', mock_ctx)) heat_client.stacks.get.return_value = mock.MagicMock( stack_name='overcloud') 'Networks', 'InternalNetwork', mock_ctx)) def test_legacy_api_network_exists(self, get_obj_client_mock, j2_mock, def test_no_legacy_api_network_exists(self, get_obj_client_mock, j2_mock,",40,20
openstack%2Ftripleo-ci~master~I742695bfcd071c4930c4170553af7d9a59f6a432,openstack/tripleo-ci,master,I742695bfcd071c4930c4170553af7d9a59f6a432,Use python3 for tox linting,MERGED,2018-08-03 14:43:56.000000000,2018-09-27 11:58:17.000000000,2018-09-27 11:58:16.000000000,"[{'_account_id': 2472}, {'_account_id': 6159}, {'_account_id': 6547}, {'_account_id': 6926}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-08-03 14:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d7e2ef816b9e7b014f9771953c809a94cee10cf0', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I742695bfcd071c4930c4170553af7d9a59f6a432\n'}, {'number': 2, 'created': '2018-09-06 13:46:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b531518403afe915b046fb329e40725f6f30bbf0', 'message': 'Use python3 for tox linting\n\nfix tox python3 overrides We want to default to running all tox\nenvironments under python 3, so set the basepython value in each\nenvironment. We do not want to specify a minor version number, because\nwe do not want to have to update the file every time we upgrade python.\nWe do not want to set the override once in testenv, because that breaks\nthe more specific versions used in default environments like py35 and\npy36.\n\nChange-Id: I742695bfcd071c4930c4170553af7d9a59f6a432\n'}, {'number': 3, 'created': '2018-09-19 08:50:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5222eba51ef5a5a0c6e350dc8e38b6432553b236', 'message': 'Use python3 for tox linting\n\nfix tox python3 overrides We want to default to running all tox\nenvironments under python 3, so set the basepython value in each\nenvironment. We do not want to specify a minor version number, because\nwe do not want to have to update the file every time we upgrade python.\nWe do not want to set the override once in testenv, because that breaks\nthe more specific versions used in default environments like py35 and\npy36.\n\nChange-Id: I742695bfcd071c4930c4170553af7d9a59f6a432\n'}, {'number': 4, 'created': '2018-09-24 06:13:53.000000000', 'files': ['zuul.d/layout.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/db10400e88d2d684606b43395b940748f6c07612', 'message': ""Use python3 for tox linting\n\nfix tox python3 overrides We want to default to running all tox\nenvironments under python 3, so set the basepython value in each\nenvironment. We do not want to specify a minor version number, because\nwe do not want to have to update the file every time we upgrade python.\nWe do not want to set the override once in testenv, because that breaks\nthe more specific versions used in default environments like py35 and\npy36.\n\nAlso, add tox-linters job to gate so that changes like this can merge.\nThe files section limit what runs - and if *nothing* run, there's no +2\nfrom CI. Another reason to add this job is that we run voting jobs in\nboth check and gate, and this one was only in check.\n\nChange-Id: I742695bfcd071c4930c4170553af7d9a59f6a432\n""}]",2,588587,db10400e88d2d684606b43395b940748f6c07612,39,16,4,24162,,,0,"Use python3 for tox linting

fix tox python3 overrides We want to default to running all tox
environments under python 3, so set the basepython value in each
environment. We do not want to specify a minor version number, because
we do not want to have to update the file every time we upgrade python.
We do not want to set the override once in testenv, because that breaks
the more specific versions used in default environments like py35 and
py36.

Also, add tox-linters job to gate so that changes like this can merge.
The files section limit what runs - and if *nothing* run, there's no +2
from CI. Another reason to add this job is that we run voting jobs in
both check and gate, and this one was only in check.

Change-Id: I742695bfcd071c4930c4170553af7d9a59f6a432
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/87/588587/4 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d7e2ef816b9e7b014f9771953c809a94cee10cf0,python3-first,basepython = python3basepython = python3,,2,0
openstack%2Ftripleo-heat-templates~master~I2d8f04c0dd806b2e39a38f8b9e96f50c1e0f75e0,openstack/tripleo-heat-templates,master,I2d8f04c0dd806b2e39a38f8b9e96f50c1e0f75e0,Enable fluentd health check,MERGED,2018-04-24 10:40:18.000000000,2018-09-27 11:58:15.000000000,2018-09-27 11:58:14.000000000,"[{'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-04-24 10:40:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ee4fd8f5075a00ffb1cefb712f75cffc1815e709', 'message': 'Enable fluentd health check\n\nThis patch enables container health check for fluentd container.\n\nChange-Id: I2d8f04c0dd806b2e39a38f8b9e96f50c1e0f75e0\nDepends-On: Ie724b155fa071da9f1baee193cf79e2ecdc2ff30\n'}, {'number': 2, 'created': '2018-09-12 08:30:10.000000000', 'files': ['docker/services/fluentd.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f9bb8b6ca54a269f50d9f3b699d8b254c3e5237c', 'message': 'Enable fluentd health check\n\nThis patch enables container health check for fluentd container.\n\nChange-Id: I2d8f04c0dd806b2e39a38f8b9e96f50c1e0f75e0\nDepends-On: Ie724b155fa071da9f1baee193cf79e2ecdc2ff30\n'}]",0,563881,f9bb8b6ca54a269f50d9f3b699d8b254c3e5237c,24,6,2,5241,,,0,"Enable fluentd health check

This patch enables container health check for fluentd container.

Change-Id: I2d8f04c0dd806b2e39a38f8b9e96f50c1e0f75e0
Depends-On: Ie724b155fa071da9f1baee193cf79e2ecdc2ff30
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/563881/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/fluentd.yaml'],1,ee4fd8f5075a00ffb1cefb712f75cffc1815e709,healthcheck/fluentd, healthcheck: test: /openstack/healthcheck,,2,0
openstack%2Ftripleo-quickstart-extras~master~I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4,openstack/tripleo-quickstart-extras,master,I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4,Do not enforce libguestfs emulation mode,MERGED,2018-08-23 09:51:47.000000000,2018-09-27 11:58:13.000000000,2018-09-27 11:58:13.000000000,"[{'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-08-23 09:51:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8f3bfeff9b8b7605004e59646fcc8474f4bded84', 'message': 'Do not enforce libguestfs emulation mode\n\nAllow users to override the setting on their own risk\nof being hit by bug 1743749\n\nRelated-Bug: #1743749\n\nChange-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2018-08-23 12:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/6b98f35e627366e5105bbcaeab6f543ed2cf8f0a', 'message': 'Do not enforce libguestfs emulation mode\n\nAllow users to override the setting on their own risk\nof being hit by bug 1743749\n\nRelated-Bug: #1743749\n\nChange-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2018-09-10 10:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8fb81df7b592b01dd719e234b7be6908ade1d5e7', 'message': 'Do not enforce libguestfs emulation mode\n\nAllow users to override the setting on their own risk\nof being hit by bug 1743749\n\nRelated-Bug: #1743749\n\nChange-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2018-09-17 16:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e578bf5fb120e14abd6315abc1ece15cec86a77e', 'message': 'Do not enforce libguestfs emulation mode\n\nAllow users to override the setting on their own risk\nof being hit by bug 1743749\n\nRelated-Doc: http://libguestfs.org/guestfs.3.html#force_tcg\n\nRelated-Bug: #1743749\n\nChange-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2018-09-18 07:51:18.000000000', 'files': ['roles/modify-image/tasks/libguestfs.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/850595c42a21d85fc56de73d9abc8cad3c14be0f', 'message': 'Do not enforce libguestfs emulation mode\n\nAllow users to override the setting on their own risk\nof being hit by bug 1743749\n\nRelated-Doc: http://libguestfs.org/guestfs.3.html#force_tcg\n\nRelated-Bug: #1743749\n\nChange-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",2,595566,850595c42a21d85fc56de73d9abc8cad3c14be0f,59,11,5,6926,,,0,"Do not enforce libguestfs emulation mode

Allow users to override the setting on their own risk
of being hit by bug 1743749

Related-Doc: http://libguestfs.org/guestfs.3.html#force_tcg

Related-Bug: #1743749

Change-Id: I5aa3f665d9e449eaa8e91441a3f46d322d5d43a4
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/66/595566/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/modify-image/tasks/libguestfs.yml'],1,8f3bfeff9b8b7605004e59646fcc8474f4bded84,bug/1743749," LIBGUESTFS_BACKEND_SETTINGS: ""{{ lookup( 'env', 'LIBGUESTFS_BACKEND_SETTINGS')|default('force_tcg') }}""", LIBGUESTFS_BACKEND_SETTINGS: force_tcg,1,1
openstack%2Fopenstack-ansible-os_swift~master~I99aad1c3c4ec342c2997b2e59289d60304f1c81a,openstack/openstack-ansible-os_swift,master,I99aad1c3c4ec342c2997b2e59289d60304f1c81a,Remove role used for upgrade tests,MERGED,2018-09-19 20:14:56.000000000,2018-09-27 11:55:05.000000000,2018-09-27 11:55:05.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-19 20:14:56.000000000', 'files': ['tests/ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/9e8da77d8423921b4bd9c10d584750edcadf8d21', 'message': ""Remove role used for upgrade tests\n\nIn https://review.openstack.org/601060 we removed everything\nrelated to the upgrade tests, except the 'previous' role.\n\nChange-Id: I99aad1c3c4ec342c2997b2e59289d60304f1c81a\n""}]",0,603903,9e8da77d8423921b4bd9c10d584750edcadf8d21,15,4,1,6816,,,0,"Remove role used for upgrade tests

In https://review.openstack.org/601060 we removed everything
related to the upgrade tests, except the 'previous' role.

Change-Id: I99aad1c3c4ec342c2997b2e59289d60304f1c81a
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/03/603903/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/ansible-role-requirements.yml'],1,9e8da77d8423921b4bd9c10d584750edcadf8d21,cleanup-role-tests,,- name: os_previous_swift src: https://git.openstack.org/openstack/openstack-ansible-os_swift scm: git version: stable/queens,0,4
openstack%2Ftripleo-heat-templates~master~I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25,openstack/tripleo-heat-templates,master,I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25,Enable ceilometer-agent-compute health check,MERGED,2018-03-13 12:22:49.000000000,2018-09-27 11:45:55.000000000,2018-09-27 11:45:55.000000000,"[{'_account_id': 5241}, {'_account_id': 6924}, {'_account_id': 11491}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-03-13 12:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2728d890ba62c562d7d530304b00f458724b1067', 'message': 'Enable ceilometer-agent-compute health check\n\nThis patch enables health check execution for ceilometer-agent-compute\ndocker container.\n\nChange-Id: I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25\nDepends-On: I4a193d7ce1c455da2865498470ed3b98160df112\nDepends-On: Id5dc7d169301e45cb0abab7cecae67457db9fd96\n'}, {'number': 2, 'created': '2018-08-29 11:37:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/71a9738b4428832f8d7a7ee00e734efb44abbcf1', 'message': 'Enable ceilometer-agent-compute health check\n\nThis patch enables health check execution for ceilometer-agent-compute\ndocker container.\n\nChange-Id: I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25\nDepends-On: I4a193d7ce1c455da2865498470ed3b98160df112\nDepends-On: Id5dc7d169301e45cb0abab7cecae67457db9fd96\n'}, {'number': 3, 'created': '2018-09-12 08:30:05.000000000', 'files': ['docker/services/ceilometer-agent-compute.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ebf0db0d738c74e9fd4bfb0982b700132161ee02', 'message': 'Enable ceilometer-agent-compute health check\n\nThis patch enables health check execution for ceilometer-agent-compute\ndocker container.\n\nChange-Id: I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25\nDepends-On: I4a193d7ce1c455da2865498470ed3b98160df112\nDepends-On: Id5dc7d169301e45cb0abab7cecae67457db9fd96\n'}]",0,552501,ebf0db0d738c74e9fd4bfb0982b700132161ee02,33,7,3,5241,,,0,"Enable ceilometer-agent-compute health check

This patch enables health check execution for ceilometer-agent-compute
docker container.

Change-Id: I9041c817c18ce68bf1fa9bb72c6bc7429d50cb25
Depends-On: I4a193d7ce1c455da2865498470ed3b98160df112
Depends-On: Id5dc7d169301e45cb0abab7cecae67457db9fd96
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/01/552501/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceilometer-agent-compute.yaml'],1,2728d890ba62c562d7d530304b00f458724b1067,healthcheck/ceilometer-agents, healthcheck: test: /openstack/healthcheck,,2,0
openstack%2Fironic~master~Iec93aaf85751895efed5dac4ccb4383ee919305c,openstack/ironic,master,Iec93aaf85751895efed5dac4ccb4383ee919305c,Add documentation for changing node's hardware type,MERGED,2018-07-24 16:21:48.000000000,2018-09-27 11:39:11.000000000,2018-07-28 14:41:18.000000000,"[{'_account_id': 11655}, {'_account_id': 13689}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 24828}, {'_account_id': 26340}]","[{'number': 1, 'created': '2018-07-24 16:21:48.000000000', 'files': ['doc/source/admin/drivers.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/600081daa95afbafee30ceef72e4b3287dff8460', 'message': ""Add documentation for changing node's hardware type\n\nChange-Id: Iec93aaf85751895efed5dac4ccb4383ee919305c\nStory: #2002868\n""}]",8,585463,600081daa95afbafee30ceef72e4b3287dff8460,12,7,1,10239,,,0,"Add documentation for changing node's hardware type

Change-Id: Iec93aaf85751895efed5dac4ccb4383ee919305c
Story: #2002868
",git fetch https://review.opendev.org/openstack/ironic refs/changes/63/585463/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/drivers.rst'],1,600081daa95afbafee30ceef72e4b3287dff8460,story/2002868,"Changing Hardware Types and Interfaces -------------------------------------- Hardware types and interfaces are enabled in the configuration as described in :doc:`/install/enabling-drivers`. Usually, a hardware type is configured on enrolling as described in :doc:`/install/enrollment`:: openstack baremetal node create --driver <hardware type> Any hardware interfaces can be specified on enrollment as well:: openstack baremetal node create --driver <hardware type> \ --deploy-interface direct --<other>-interface <other implementation> For the remaining interfaces the default value is assigned as described in :ref:`hardware_interfaces_defaults`. Both the hardware type and the hardware interfaces can be changed later. Changing hardware interfaces ~~~~~~~~~~~~~~~~~~~~~~~~~~~~ A hardware interfaces can be changed by the following command:: openstack baremetal node set <NODE> \ --deploy-interface direct \ --<other>-interface <other implementation> The modified interfaces must be enabled and compatible with the current node's hardware type. Changing hardware type ~~~~~~~~~~~~~~~~~~~~~~ Changing the node's hardware type can pose a problem. When the ``driver`` field is updated, the final result must be consistent, that is, the resulting hardware interfaces must be compatible with the new hardware type. This will not work:: openstack baremetal node create --name test --driver fake-hardware openstack baremetal node set test --driver ipmi This is because the ``fake-hardware`` hardware type defaults to ``fake`` implementations for some or all interfaces, but the ``ipmi`` hardware type is not compatible with them. There are three ways to deal with this situation: #. Provide new values for all incompatible interfaces, for example:: openstack baremetal node set test --driver ipmi \ --boot-interface pxe \ --deploy-interface iscsi \ --management-interface ipmitool \ --power-interface ipmitool #. Request resetting some of the interfaces to their new defaults by using the ``--reset-<IFACE>-interface`` family of arguments, for example:: openstack baremetal node set test --driver ipmi \ --reset-boot-interface \ --reset-deploy-interface \ --reset-management-interface \ --reset-power-interface .. note:: This feature is available starting with the Rocky release. #. Request resetting all interfaces to their new defaults:: openstack baremetal node set test --driver ipmi --reset-interfaces You can still specify explicit values for some interfaces:: openstack baremetal node set test --driver ipmi --reset-interfaces \ --deploy-interface direct .. note:: This feature is available starting with the Rocky release.",,74,0
openstack%2Fnova~master~Iba230201803ef3d33bccaaf83eb10453eea43f20,openstack/nova,master,Iba230201803ef3d33bccaaf83eb10453eea43f20,Consumer gen support for put allocations,MERGED,2018-08-14 12:33:35.000000000,2018-09-27 11:27:57.000000000,2018-09-26 05:25:31.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-08-14 12:33:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bdbec5a474b62b9cc0c4074b41c4566c2eb2c8c5', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the put_allocations raises\nthen allocation healing will be retried in _allocate_for_instance\nand if retries fail then _allocate_for_instance will re-raise the\nAllocationUpdateFailed exception.\n\nTODO:\n* Decide to either handle the exception in Ironic or drop allocation\n  healing from Ironic.\n* Make the unit test pass\n\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 2, 'created': '2018-08-14 12:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/18e45792b2ce2bcc12d027fa7bd3138b8e54374d', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the put_allocations raises\nthen allocation healing will be retried in _allocate_for_instance\nand if retries fail then _allocate_for_instance will re-raise the\nAllocationUpdateFailed exception.\n\nTODO:\n* Decide to either handle the exception in Ironic or drop allocation\n  healing from Ironic.\n* Make the unit test pass\n\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 3, 'created': '2018-08-14 18:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f84dea389e84ecdbb3e2522dc1106b064035cbe3', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the put_allocations raises\nthen allocation healing will be retried in _allocate_for_instance\nand if retries fail then _allocate_for_instance will re-raise the\nAllocationUpdateFailed exception.\n\nTODO:\n* Decide to either handle the exception in Ironic or drop allocation\n  healing from Ironic.\n* Make the unit test pass\n\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 4, 'created': '2018-08-31 13:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bcb78fb24cc6efd7244e0503f6e5356c0c96d390', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the periodic allocation healing\nfails it due to conflict then it will be retried in the next periodic\nrun.\n\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 5, 'created': '2018-09-12 22:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3b973eea4721eeec01cc5b076f9b2d11b2954920', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the periodic allocation healing\nfails it due to conflict then it will be retried in the next periodic\nrun.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 6, 'created': '2018-09-17 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a9823fda0f3b2d81a6feef05f75a02968c3a0c5f', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the periodic allocation healing\nfails it due to conflict then it will be retried in the next periodic\nrun.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 7, 'created': '2018-09-21 13:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a446a9da2f4dbbfefcde7ba49501961a6fbead3', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nThere is another indirect user of the modfied put_allocations function\nwhich is allocation healing in the resource tracker. Today it is only\ntriggered by Ironic virt driver. If the periodic allocation healing\nfails it due to conflict then it will be retried in the next periodic\nrun.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}, {'number': 8, 'created': '2018-09-25 11:09:15.000000000', 'files': ['nova/exception.py', 'nova/tests/functional/test_report_client.py', 'nova/tests/unit/test_nova_manage.py', 'nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py', 'nova/cmd/manage.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/dfa2e6f221fbd4dd909da052805b0118da72f9a9', 'message': 'Consumer gen support for put allocations\n\nThe placement API version 1.28 introduced consumer generation as a way\nto make updating allocation safe even if it is done from multiple\nplaces.\n\nThis patch changes the scheduler report client put_allocations\nfunction to raise AllocationUpdateFailed in case of generation conflict.\nThe only direct user of this call is the nova-manage heal_allocations\nCLI which will simply fail to heal the allocation for this instance.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20\n'}]",36,591647,dfa2e6f221fbd4dd909da052805b0118da72f9a9,106,19,8,9708,,,0,"Consumer gen support for put allocations

The placement API version 1.28 introduced consumer generation as a way
to make updating allocation safe even if it is done from multiple
places.

This patch changes the scheduler report client put_allocations
function to raise AllocationUpdateFailed in case of generation conflict.
The only direct user of this call is the nova-manage heal_allocations
CLI which will simply fail to heal the allocation for this instance.

Blueprint: use-nested-allocation-candidates
Change-Id: Iba230201803ef3d33bccaaf83eb10453eea43f20
",git fetch https://review.opendev.org/openstack/nova refs/changes/47/591647/8 && git format-patch -1 --stdout FETCH_HEAD,"['nova/exception.py', 'nova/scheduler/client/report.py', 'nova/cmd/manage.py', 'nova/tests/functional/test_servers.py']",4,bdbec5a474b62b9cc0c4074b41c4566c2eb2c8c5,bp/use-nested-allocation-candidates, def test_ironic_periodic_allocation_heal_retry_success(self): # Based on nova/virt/ironic/driver.py#L145-L149 # # requires_allocation_refresh = True # # the Ironic virt driver still uses allocation healing in the resource # tracker. This eventually calls _allocate_for_instance in the report # client that does local retry for consumer generation conflict and it # might fail with a AllocationUpdateFailed exception if runs out of # retries. # TODO(gibi): Can we drop this from Ironic now in Stein? pass def test_ironic_periodic_allocation_heal_retry_fails(self): pass,,64,21
openstack%2Fopenstack-ansible-os_designate~master~If64f825fcac107f3820b710324624cf3117a9de3,openstack/openstack-ansible-os_designate,master,If64f825fcac107f3820b710324624cf3117a9de3,SUSE: Add support for openSUSE Leap 15,MERGED,2018-09-26 10:52:01.000000000,2018-09-27 11:06:07.000000000,2018-09-27 11:06:07.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-26 10:52:01.000000000', 'files': ['zuul.d/project.yaml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_designate/commit/8e829211a0c3954bb9cc92a1ccbca15cafd443de', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: If64f825fcac107f3820b710324624cf3117a9de3\n'}]",0,605391,8e829211a0c3954bb9cc92a1ccbca15cafd443de,11,4,1,23163,,,0,"SUSE: Add support for openSUSE Leap 15

Change-Id: If64f825fcac107f3820b710324624cf3117a9de3
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_designate refs/changes/91/605391/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'meta/main.yml']",2,8e829211a0c3954bb9cc92a1ccbca15cafd443de,osa-add-leap-150, - all, - 42.1 - 42.2 - 42.3,3,3
openstack%2Fopenstack-ansible-os_heat~master~Ia47b3be327bd66818163b034b72938e4868dc824,openstack/openstack-ansible-os_heat,master,Ia47b3be327bd66818163b034b72938e4868dc824,SUSE: Add support for openSUSE Leap 15,MERGED,2018-09-26 10:46:56.000000000,2018-09-27 10:56:26.000000000,2018-09-27 10:56:25.000000000,"[{'_account_id': 7353}, {'_account_id': 19298}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-26 10:46:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/c2f7092fce12d614efe5b2c47bcbe5d802692450', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: Ia47b3be327bd66818163b034b72938e4868dc824\nDepends-On: https://review.openstack.org/604080\nDepends-On: https://review.openstack.org/604286\n'}, {'number': 2, 'created': '2018-09-26 12:58:38.000000000', 'files': ['zuul.d/project.yaml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/f3e30f96f60e7759222313f40a2456672ff37dc2', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: Ia47b3be327bd66818163b034b72938e4868dc824\n'}]",2,605389,f3e30f96f60e7759222313f40a2456672ff37dc2,15,5,2,23163,,,0,"SUSE: Add support for openSUSE Leap 15

Change-Id: Ia47b3be327bd66818163b034b72938e4868dc824
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/89/605389/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'meta/main.yml']",2,c2f7092fce12d614efe5b2c47bcbe5d802692450,osa-add-leap-150, - all, - 42.1 - 42.2 - 42.3,3,3
openstack%2Ftripleo-quickstart~master~I8c39ea710034a6dbe5ab910afa8230c2fd1ecc37,openstack/tripleo-quickstart,master,I8c39ea710034a6dbe5ab910afa8230c2fd1ecc37,Retry id command for stack user,MERGED,2018-09-12 12:22:34.000000000,2018-09-27 10:52:50.000000000,2018-09-27 10:52:50.000000000,"[{'_account_id': 6926}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 11090}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-09-12 12:22:34.000000000', 'files': ['roles/provision/remote/tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/ff5112cdecea1de56f2ca9dfe7ea4cb98b617508', 'message': 'Retry id command for stack user\n\nSometimes the stack user is not yet present, we add a retry to overcome\nit.\n\nChange-Id: I8c39ea710034a6dbe5ab910afa8230c2fd1ecc37\nCloses-Bug: 1791053\n'}]",2,602015,ff5112cdecea1de56f2ca9dfe7ea4cb98b617508,17,14,1,27898,,,0,"Retry id command for stack user

Sometimes the stack user is not yet present, we add a retry to overcome
it.

Change-Id: I8c39ea710034a6dbe5ab910afa8230c2fd1ecc37
Closes-Bug: 1791053
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/15/602015/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/provision/remote/tasks/main.yml'],1,ff5112cdecea1de56f2ca9dfe7ea4cb98b617508,bug/1791053, retry: 3 delay: 5 until: non_root_user_uid_output is not failed,,3,0
openstack%2Ftripleo-upgrade~master~Ib54320e4994b67560c9d83cbbc831a57532ffc8c,openstack/tripleo-upgrade,master,Ib54320e4994b67560c9d83cbbc831a57532ffc8c,Configure undercloud for containerized upgrade.,MERGED,2018-09-17 14:30:31.000000000,2018-09-27 10:52:41.000000000,2018-09-27 10:52:41.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-17 14:30:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/88c0bf7e71720cd92447cdf12ee4f77c931f1a51', 'message': ""Configure undercloud for containerized upgrade.\n\nTo upgrade undercloud from non-containerized to containerized\nit's required to set file with ContainerImagePrepare parameter\ndefined.\nWhen it's set add registries specified within ContainerImagePrepare\nto docker_insecure_registries parameter of uunercloud.conf\n\nChange-Id: Ib54320e4994b67560c9d83cbbc831a57532ffc8c\n""}, {'number': 2, 'created': '2018-09-18 10:07:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/7a5d71b012a2a71d256094331e037c44902e9c05', 'message': ""Configure undercloud for containerized upgrade.\n\nTo upgrade undercloud from non-containerized to containerized\nit's required to set file with ContainerImagePrepare parameter\ndefined.\nWhen it's set add registries specified within ContainerImagePrepare\nto docker_insecure_registries parameter of uunercloud.conf\n\nChange-Id: Ib54320e4994b67560c9d83cbbc831a57532ffc8c\n""}, {'number': 3, 'created': '2018-09-19 08:42:04.000000000', 'files': ['tasks/upgrade/main.yml', 'tasks/upgrade/configure_uc_containers.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/d2d32c9ab8da42c8fbd523baceedd66329460c5c', 'message': ""Configure undercloud for containerized upgrade.\n\nTo upgrade undercloud from non-containerized to containerized\nit's required to set file with ContainerImagePrepare parameter\ndefined.\nWhen it's set add registries specified within ContainerImagePrepare\nto docker_insecure_registries parameter of uunercloud.conf\n\nChange-Id: Ib54320e4994b67560c9d83cbbc831a57532ffc8c\n""}]",6,603151,d2d32c9ab8da42c8fbd523baceedd66329460c5c,17,7,3,21537,,,0,"Configure undercloud for containerized upgrade.

To upgrade undercloud from non-containerized to containerized
it's required to set file with ContainerImagePrepare parameter
defined.
When it's set add registries specified within ContainerImagePrepare
to docker_insecure_registries parameter of uunercloud.conf

Change-Id: Ib54320e4994b67560c9d83cbbc831a57532ffc8c
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/51/603151/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/upgrade/main.yml', 'tasks/upgrade/configure_uc_containers.yml']",2,88c0bf7e71720cd92447cdf12ee4f77c931f1a51,uc-insecure-registry,"--- - name: check customized {{ uc_containers_prepare_file }} exists stat: path: ""{{ working_dir }}/{{ uc_containers_prepare_file }}"" register: custom_uc_containers - name: set containers file for undercloud lineinfile: path: ""{{ undercloud_conf }}"" regexp: '^(container_images_file)(.*)' line: ""container_images_file = {{ working_dir }}/{{ uc_containers_prepare_file }}"" insertafter: ^\[DEFAULT\] when: custom_uc_containers.stat.exists - name: get namespaces from {{ uc_containers_prepare_file }} shell: | awk '/namespace:/ {split($2,a,""/""); print a[1]}' {{ uc_containers_prepare_file }} | uniq register: insecure_registries when: custom_uc_containers.stat.exists - name: check docker_insecure_registries already defined in {{ undercloud_conf }} shell: | grep ^docker_insecure_registries {{ undercloud_conf }} failed_when: false register: defined_insecure_registry - name: set docker_insecure_registries for undercloud upgrade lineinfile: path: ""{{ undercloud_conf }}"" regexp: '^(docker_insecure_registries)(.*)' line: docker_insecure_registries = {{ insecure_registries.stdout_lines|join(',') }} insertafter: ^\[DEFAULT\] when: - defined_insecure_registry.rc == 1 - insecure_registries.stdout_lines|default([])|length > 0 - name: adjust existing docker_insecure_registries for undercloud upgrade replace: path: ""{{ undercloud_conf }}"" regexp: '^(docker_insecure_registries)(\s*=\s*)(.*)' replace: '\1\2\3,{{ insecure_registries.stdout_lines|join("","") }}' when: - defined_insecure_registry.rc == 0 - insecure_registries.stdout_lines|default([])|length > 0 ",,47,13
openstack%2Fopenstacksdk~master~I207519a625434ce205218c2b6be242a8b3d49ba8,openstack/openstacksdk,master,I207519a625434ce205218c2b6be242a8b3d49ba8,Change the method of role update,MERGED,2018-09-07 08:10:48.000000000,2018-09-27 10:38:31.000000000,2018-09-27 10:38:31.000000000,"[{'_account_id': 10239}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-07 08:10:48.000000000', 'files': ['openstack/identity/v3/role.py', 'openstack/tests/unit/identity/v3/test_role.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/782919e50766a14b787ce474038fc83b5932b38d', 'message': 'Change the method of role update\n\nchange the method of role update from PUT to PATCH\n\nChange-Id: I207519a625434ce205218c2b6be242a8b3d49ba8\nSigned-off-by: liuzhuangzhuang <vpbvmw651078@gmail.com>\n'}]",0,600671,782919e50766a14b787ce474038fc83b5932b38d,11,3,1,26580,,,0,"Change the method of role update

change the method of role update from PUT to PATCH

Change-Id: I207519a625434ce205218c2b6be242a8b3d49ba8
Signed-off-by: liuzhuangzhuang <vpbvmw651078@gmail.com>
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/71/600671/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/identity/v3/role.py', 'openstack/tests/unit/identity/v3/test_role.py']",2,782919e50766a14b787ce474038fc83b5932b38d,," self.assertEqual('PATCH', sot.commit_method)",,2,0
openstack%2Frally-openstack~master~I584f9501af52f5e0f7c5f9e9fb238a68756c2832,openstack/rally-openstack,master,I584f9501af52f5e0f7c5f9e9fb238a68756c2832,Rename nova.create_image action,MERGED,2018-09-26 12:00:32.000000000,2018-09-27 10:24:15.000000000,2018-09-27 10:24:15.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 12:00:32.000000000', 'files': ['tests/unit/scenarios/nova/test_utils.py', 'rally_openstack/scenarios/nova/utils.py', 'CHANGELOG.rst'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/69c7427223a826fb91a73d017e3cc5661c368e16', 'message': 'Rename nova.create_image action\n\nChange-Id: I584f9501af52f5e0f7c5f9e9fb238a68756c2832\n'}]",0,605405,69c7427223a826fb91a73d017e3cc5661c368e16,10,2,1,9545,,,0,"Rename nova.create_image action

Change-Id: I584f9501af52f5e0f7c5f9e9fb238a68756c2832
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/05/605405/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/scenarios/nova/test_utils.py', 'rally_openstack/scenarios/nova/utils.py', 'CHANGELOG.rst']",3,69c7427223a826fb91a73d017e3cc5661c368e16,nova.create_image,* Rename an action ``nova.create_image`` to ``nova.snapshot_server`` for better understanding for what is actually done.,,4,2
openstack%2Fkeystone~master~Iabf40c723f2611c7eeb0a289b7ff594766a3452e,openstack/keystone,master,Iabf40c723f2611c7eeb0a289b7ff594766a3452e,Convert legacy functional jobs to Zuul-v3-native,MERGED,2018-09-13 20:48:20.000000000,2018-09-27 10:15:40.000000000,2018-09-27 10:15:40.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 15054}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-13 20:48:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/69be716a708839975cb9579526936332e2b502b5', 'message': '[WIP] Convert legacy jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 2, 'created': '2018-09-13 21:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/059f34e4cac98fb5121522bce755f3ce76a49237', 'message': '[WIP] Convert legacy jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 3, 'created': '2018-09-18 13:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2a3c4a3f57d6daa2b1b86cac7955b0070f90089e', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 4, 'created': '2018-09-18 16:39:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/fce329a9896cd6218dc52207947d6ca9a41d9f82', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 5, 'created': '2018-09-19 07:01:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2049c4f04f5e599f6f9375ebc6a42a52a8a51b32', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 6, 'created': '2018-09-19 13:03:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/e5dc25a03acf585c4a95f7e825510ea6b1b37d5b', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 7, 'created': '2018-09-19 13:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/7a59f975b2363dc17254f5875123e293bf2d0460', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 8, 'created': '2018-09-24 20:57:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/ef5d2c8673426952aca614d84d379c0ed2c44fc5', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 9, 'created': '2018-09-25 09:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/9cb6fd5fe9fb6d929ed5ea94312fcd5147faf593', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 10, 'created': '2018-09-25 18:59:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/2069ae9200bb0d8c4dbac9d21a51d666c9b2c39c', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}, {'number': 11, 'created': '2018-09-26 18:10:40.000000000', 'files': ['playbooks/legacy/keystone-dsvm-functional-federation/run.yaml', 'playbooks/legacy/keystone-dsvm-functional-federation/post.yaml', 'playbooks/legacy/keystone-dsvm-py35-functional-federation/post.yaml', 'playbooks/legacy/keystone-dsvm-py35-functional-federation/run.yaml', 'playbooks/legacy/keystone-dsvm-functional/post.yaml', '.zuul.yaml', 'playbooks/legacy/keystone-dsvm-functional/run.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/1a5bbb5677da45a962870a7dbdf9384b38be238c', 'message': 'Convert legacy functional jobs to Zuul-v3-native\n\nFollow the guidelines from the Infra[1] and QA[2] teams to properly set\nup our functional tests. This patch leaves the experimental grenade jobs\nalone for now since there does not yet seem to be an existing\nZuul-v3-native grenade job to use as a parent.\n\n[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native\n[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html\n\nChange-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e\n'}]",4,602452,1a5bbb5677da45a962870a7dbdf9384b38be238c,40,5,11,8482,,,0,"Convert legacy functional jobs to Zuul-v3-native

Follow the guidelines from the Infra[1] and QA[2] teams to properly set
up our functional tests. This patch leaves the experimental grenade jobs
alone for now since there does not yet seem to be an existing
Zuul-v3-native grenade job to use as a parent.

[1] https://docs.openstack.org/infra/manual/zuulv3.html#reworking-legacy-jobs-to-be-v3-native
[2] https://docs.openstack.org/devstack/latest/zuul_ci_jobs_migration.html

Change-Id: Iabf40c723f2611c7eeb0a289b7ff594766a3452e
",git fetch https://review.opendev.org/openstack/keystone refs/changes/52/602452/7 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/keystone-dsvm-functional/post.yaml', '.zuul.yaml', 'playbooks/legacy/keystone-dsvm-functional/run.yaml']",3,69be716a708839975cb9579526936332e2b502b5,python3-first,,"- hosts: all name: Autoconverted job legacy-keystone-dsvm-functional from old job gate-keystone-dsvm-functional-ubuntu-xenial tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x cat > clonemap.yaml << EOF clonemap: - name: openstack-infra/devstack-gate dest: devstack-gate EOF /usr/zuul-env/bin/zuul-cloner -m clonemap.yaml --cache-dir /opt/git \ git://git.openstack.org \ openstack-infra/devstack-gate executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x cat << 'EOF' >>""/tmp/dg-local.conf"" [[local|localrc]] TEMPEST_PLUGINS='/opt/stack/new/keystone-tempest-plugin' EOF executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x export PYTHONUNBUFFERED=true export PROJECTS=""openstack/keystone-tempest-plugin $PROJECTS"" export DEVSTACK_GATE_TEMPEST=1 export BRANCH_OVERRIDE=default if [ ""$BRANCH_OVERRIDE"" != ""default"" ] ; then export OVERRIDE_ZUUL_BRANCH=$BRANCH_OVERRIDE fi export DEVSTACK_GATE_TEMPEST_REGEX='keystone_tempest_plugin' cp devstack-gate/devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh ./safe-devstack-vm-gate-wrap.sh executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",5,73
openstack%2Fplacement~master~I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be,openstack/placement,master,I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be,wsgi: Always reset conf.CONF when starting the application,MERGED,2018-09-20 17:11:40.000000000,2018-09-27 09:53:50.000000000,2018-09-25 13:19:09.000000000,"[{'_account_id': 7166}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-20 17:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/44bab3f292bd0dfdd62f6c65c0d7529fc2db8915', 'message': 'wsgi: Always reset conf.CONF when starting the application\n\nThis ensures that options loaded during any prior run of the application\nare dropped before being added again during init_application.\n\nChange-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be\nCloses-bug: #1784155\n'}, {'number': 2, 'created': '2018-09-20 17:14:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/016c3e1d0094f036a7dab6869da0418352498550', 'message': 'wsgi: Always reset conf.CONF when starting the application\n\nThis ensures that options loaded during any prior run of the application\nare dropped before being added again during init_application.\n\nChange-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be\nCloses-bug: #1784155\n'}, {'number': 3, 'created': '2018-09-20 17:18:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/placement/commit/ac88b596c60f6c48c0e4c8e878a3ee70c4c2b756', 'message': 'wsgi: Always reset conf.CONF when starting the application\n\nThis ensures that options loaded during any prior run of the application\nare dropped before being added again during init_application.\n\nChange-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be\nCloses-bug: #1784155\n'}, {'number': 4, 'created': '2018-09-24 07:59:43.000000000', 'files': ['placement/wsgi.py'], 'web_link': 'https://opendev.org/openstack/placement/commit/d83b1056b45f129dcbeda8daa2e49210e6321aa2', 'message': 'wsgi: Always reset conf.CONF when starting the application\n\nThis ensures that options loaded during any prior run of the application\nare dropped before being added again during init_application.\n\nChange-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be\nCloses-bug: #1784155\n'}]",0,604167,d83b1056b45f129dcbeda8daa2e49210e6321aa2,13,4,4,10135,,,0,"wsgi: Always reset conf.CONF when starting the application

This ensures that options loaded during any prior run of the application
are dropped before being added again during init_application.

Change-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be
Closes-bug: #1784155
",git fetch https://review.opendev.org/openstack/placement refs/changes/67/604167/1 && git format-patch -1 --stdout FETCH_HEAD,['placement/wsgi.py'],1,44bab3f292bd0dfdd62f6c65c0d7529fc2db8915,bug/1784155, # NOTE(lyarwood): Call reset to ensure the ConfigOpts object doesn't # already contain registered options when the app is reloaded by httpd conf.CONF.reset() ,,5,0
openstack%2Fmurano-dashboard~master~I421d9cc3a8639d727c59350f8e1c0418071d3770,openstack/murano-dashboard,master,I421d9cc3a8639d727c59350f8e1c0418071d3770,Imported Translations from Zanata,MERGED,2018-09-18 07:13:10.000000000,2018-09-27 09:53:05.000000000,2018-09-27 09:53:05.000000000,"[{'_account_id': 1736}, {'_account_id': 14107}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-18 07:13:10.000000000', 'files': ['releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po'], 'web_link': 'https://opendev.org/openstack/murano-dashboard/commit/92a304eccaed9538fa16944eb52e38d16fc6b52a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I421d9cc3a8639d727c59350f8e1c0418071d3770\n'}]",0,603302,92a304eccaed9538fa16944eb52e38d16fc6b52a,13,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I421d9cc3a8639d727c59350f8e1c0418071d3770
",git fetch https://review.opendev.org/openstack/murano-dashboard refs/changes/02/603302/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/source/locale/de/LC_MESSAGES/releasenotes.po'],1,92a304eccaed9538fa16944eb52e38d16fc6b52a,zanata/translations,"""Project-Id-Version: murano-dashboard\n""""POT-Creation-Date: 2018-09-10 02:39+0000\n""""PO-Revision-Date: 2018-09-17 01:14+0000\n""msgid ""Rocky Series Release Notes"" msgstr ""Rocky Serie Releasenotes"" ","""Project-Id-Version: Murano Dashboard Release Notes\n""""POT-Creation-Date: 2018-03-20 03:52+0000\n""""PO-Revision-Date: 2018-03-20 02:31+0000\n""",6,3
openstack%2Fneutron-vpnaas~master~I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7,openstack/neutron-vpnaas,master,I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7,Move to new PTI for document build,ABANDONED,2018-07-06 07:42:09.000000000,2018-09-27 09:43:55.000000000,,"[{'_account_id': 15905}, {'_account_id': 18320}, {'_account_id': 22348}, {'_account_id': 25254}]","[{'number': 1, 'created': '2018-07-06 07:42:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/4faf0ca521ecf693c9e2c5a8367339c7dfe52421', 'message': 'Move to new PTI for document build\n\nFor compliance with the Project Testing Interface as described in:\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nFor more detials information, please refer to:\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html\n\nDepends-on: https://review.openstack.org/#/c/579742/\nChange-Id: I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7\n'}, {'number': 2, 'created': '2018-07-25 06:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/debc91b5746c3a4fbb792c69951a7d1665ec0ec0', 'message': 'Move to new PTI for document build\n\nFor compliance with the Project Testing Interface as described in:\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nFor more detials information, please refer to:\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html\n\nDepends-on: https://review.openstack.org/#/c/579742/\nChange-Id: I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7\n'}, {'number': 3, 'created': '2018-07-25 06:29:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/b0934a8d40d26f600d2284c54e76cb729f15fcad', 'message': 'Move to new PTI for document build\n\nFor compliance with the Project Testing Interface as described in:\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nFor more detials information, please refer to:\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html\n\nChange-Id: I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7\n'}, {'number': 4, 'created': '2018-07-30 08:33:09.000000000', 'files': ['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/neutron-vpnaas/commit/73c457175fca88c90b6cc8a656dcece7b30ae94f', 'message': 'Move to new PTI for document build\n\nFor compliance with the Project Testing Interface as described in:\nhttps://governance.openstack.org/tc/reference/project-testing-interface.html\n\nFor more detials information, please refer to:\nhttp://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html\n\nChange-Id: I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7\n'}]",0,580571,73c457175fca88c90b6cc8a656dcece7b30ae94f,17,4,4,25254,,,0,"Move to new PTI for document build

For compliance with the Project Testing Interface as described in:
https://governance.openstack.org/tc/reference/project-testing-interface.html

For more detials information, please refer to:
http://lists.openstack.org/pipermail/openstack-dev/2017-December/125710.html

Change-Id: I97b9ffe45e3b3e84e026ce4d87bc40a2fd6541b7
",git fetch https://review.opendev.org/openstack/neutron-vpnaas refs/changes/71/580571/4 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/requirements.txt', 'setup.cfg', 'tox.ini']",4,4faf0ca521ecf693c9e2c5a8367339c7dfe52421,improve_sphinx,deps = -r{toxinidir}/doc/requirements.txt,,4,11
openstack%2Frequirements~stable%2Frocky~I7a1b3388afe37940412a18f742324d9d0472a0f3,openstack/requirements,stable/rocky,I7a1b3388afe37940412a18f742324d9d0472a0f3,update constraint for ovsdbapp to new release 0.13.0 Related-bug: 1793499 Related-bug: 1735154,ABANDONED,2018-09-26 09:14:39.000000000,2018-09-27 09:43:31.000000000,,"[{'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 11131}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 09:14:39.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e25949df57c8de37c212de2fe5af916235392015', 'message': 'update constraint for ovsdbapp to new release 0.13.0\nRelated-bug: 1793499\nRelated-bug: 1735154\n\nChange-Id: I7a1b3388afe37940412a18f742324d9d0472a0f3\nmeta:version: 0.13.0\nmeta:diff-start: -\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: yes\nmeta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>\nmeta:release:Change-Id: I7c411ad58e10285d026d87a4e4f7b584d923695b\nmeta:release:Code-Review+1: Jakub Libosvar <libosvar@redhat.com>\nmeta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>\nmeta:release:Code-Review+1: Terry Wilson <twilson@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605374,e25949df57c8de37c212de2fe5af916235392015,10,6,1,23804,,,0,"update constraint for ovsdbapp to new release 0.13.0
Related-bug: 1793499
Related-bug: 1735154

Change-Id: I7a1b3388afe37940412a18f742324d9d0472a0f3
meta:version: 0.13.0
meta:diff-start: -
meta:series: stein
meta:release-type: release
meta:pypi: no
meta:first: yes
meta:release:Author: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Commit: Lucas Alvares Gomes <lucasagomes@gmail.com>
meta:release:Change-Id: I7c411ad58e10285d026d87a4e4f7b584d923695b
meta:release:Code-Review+1: Jakub Libosvar <libosvar@redhat.com>
meta:release:Code-Review+1: Daniel Alvarez <dalvarez@redhat.com>
meta:release:Code-Review+1: Terry Wilson <twilson@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/74/605374/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e25949df57c8de37c212de2fe5af916235392015,new-release-stable/rocky,ovsdbapp===0.13.0,ovsdbapp===0.12.1,1,1
openstack%2Ftripleo-upgrade~master~Ifa2b21bca4c3523cb76f8aad869b45e6aeca2e91,openstack/tripleo-upgrade,master,Ifa2b21bca4c3523cb76f8aad869b45e6aeca2e91,Assert services/containers are started after reboot.,MERGED,2018-09-25 14:12:01.000000000,2018-09-27 09:39:51.000000000,2018-09-27 07:37:09.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-25 14:12:01.000000000', 'files': ['tasks/common/undercloud_validate_upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/6e72e7dfe2f934cf053126cec04e21f39738ff04', 'message': 'Assert services/containers are started after reboot.\n\nAfter undercloud\'s reboot services ain\'t available immediately.\nTo assert services\' readines list stacks and compare overcloud\nstack is present in output.\nTask is retried for ""service_readiness_count"" times, that\ndefaults to 100, with a 3 seconds delay in between, resulting\nin ~300 seconds.\n\nChange-Id: Ifa2b21bca4c3523cb76f8aad869b45e6aeca2e91\n'}]",0,605084,6e72e7dfe2f934cf053126cec04e21f39738ff04,8,7,1,21537,,,0,"Assert services/containers are started after reboot.

After undercloud's reboot services ain't available immediately.
To assert services' readines list stacks and compare overcloud
stack is present in output.
Task is retried for ""service_readiness_count"" times, that
defaults to 100, with a 3 seconds delay in between, resulting
in ~300 seconds.

Change-Id: Ifa2b21bca4c3523cb76f8aad869b45e6aeca2e91
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/84/605084/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/undercloud_validate_upgrade.yaml'],1,6e72e7dfe2f934cf053126cec04e21f39738ff04,uc-post-reboot," - name: assert UC services started shell: | source {{ undercloud_rc }} ; openstack stack list -f json | jq -c -r '.[]|.""Stack Name""' ignore_errors: true register: oc_name until: oc_name.stdout.find('{{ overcloud_stack_name }}') != -1 retries: ""{{ service_readiness_count|default(100)|int }}"" delay: 3",,10,0
openstack%2Fastara~master~I044fb581cb156ac1364330056814d09597e9b9a8,openstack/astara,master,I044fb581cb156ac1364330056814d09597e9b9a8,import zuul job settings from project-config,ABANDONED,2018-08-09 07:09:28.000000000,2018-09-27 09:38:24.000000000,,"[{'_account_id': 6547}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-08-09 07:09:28.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/astara/commit/393f5525ff5f123a024652b181e195c1c609a727', 'message': 'import zuul job settings from project-config\n\nChange-Id: I044fb581cb156ac1364330056814d09597e9b9a8\n'}]",0,590137,393f5525ff5f123a024652b181e195c1c609a727,6,4,1,26297,,,0,"import zuul job settings from project-config

Change-Id: I044fb581cb156ac1364330056814d09597e9b9a8
",git fetch https://review.opendev.org/openstack/astara refs/changes/37/590137/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,393f5525ff5f123a024652b181e195c1c609a727,,- project: templates: - openstack-python-jobs - openstack-python35-jobs - publish-openstack-docs-pti - check-requirements - lib-forward-testing - release-notes-jobs-python3 - periodic-stable-jobs ,,10,0
openstack%2Fpuppet-tripleo~master~I9f53e68732e1d32c78c82e64c04ff6efd28aebca,openstack/puppet-tripleo,master,I9f53e68732e1d32c78c82e64c04ff6efd28aebca,Added Containerization support for Liquidio service,ABANDONED,2018-08-09 09:25:08.000000000,2018-09-27 09:38:01.000000000,,"[{'_account_id': 14538}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-09 09:25:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/1c33b86b19903de71d3a8c9b2481d0bec7ab7bc9', 'message': 'Added Containerization support for Liquidio service\n\nLiquidio service runs on Liquidio compute nodes. This service\nneeds to be containerized for deployments. This patch addresses\nthe relevant puppet module changes to it.\n\nChange-Id: I9f53e68732e1d32c78c82e64c04ff6efd28aebca\nImplements: liquidio-containerization\n'}, {'number': 2, 'created': '2018-08-10 07:51:04.000000000', 'files': ['spec/unit/provider/liquidio_config/ini_setting.rb', 'lib/puppet/type/liquidio_config.rb', 'manifests/host/liquidio/compute.pp', 'lib/puppet/provider/liquidio_config/ini_setting.rb', 'spec/classes/tripleo_host_liquidio_config_spec.rb', 'spec/unit/type/liquidio_config_sepc.rb', 'spec/classes/tripleo_host_liquidio_compute_spec.rb', 'manifests/host/liquidio/config.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/ca85b326eed5501e86e926c31a18bcb2735c2841', 'message': 'Added Containerization support for Liquidio service\n\nLiquidio service runs on Liquidio compute nodes. This service\nneeds to be containerized for deployments. This patch addresses\nthe relevant puppet module changes to it.\n\nChange-Id: I9f53e68732e1d32c78c82e64c04ff6efd28aebca\nImplements: liquidio-containerization\n'}]",0,590202,ca85b326eed5501e86e926c31a18bcb2735c2841,10,3,2,14538,,,0,"Added Containerization support for Liquidio service

Liquidio service runs on Liquidio compute nodes. This service
needs to be containerized for deployments. This patch addresses
the relevant puppet module changes to it.

Change-Id: I9f53e68732e1d32c78c82e64c04ff6efd28aebca
Implements: liquidio-containerization
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/02/590202/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/tripleo_host_liquidio_init_spec.rb', 'spec/unit/provider/liquidio_config/ini_setting.rb', 'lib/puppet/type/liquidio_config.rb', 'lib/puppet/provider/liquidio_config/ini_setting.rb', 'manifests/host/liquidio/init.pp', 'spec/classes/tripleo_host_liquidio_config_spec.rb', 'spec/unit/type/liquidio_config_sepc.rb', 'manifests/host/liquidio/config.pp']",8,1c33b86b19903de71d3a8c9b2481d0bec7ab7bc9,liquidio-containerization,"# == Class: tripleo::host::liquidio::config # # This class is used to manage Liquidio configurations. # # === Parameters # # [*xxx_config*] # (optional) Allow configuration of arbitrary Neutron xxx specific configurations. # The value is a hash of neutron_config resources. Example: # server_config => # { 'DEFAULT/foo' => { value => 'fooValue'}, # 'DEFAULT/bar' => { value => 'barValue'} # } # # NOTE: { 'DEFAULT/foo': value => 'fooValue'; 'DEFAULT/bar': value => 'barValue'} is invalid. # # In yaml format, Example: # server_config: # DEFAULT/foo: # value: fooValue # DEFAULT/bar: # value: barValue # # [*liquidio_config*] # (optional) Allow configuration of liquidio.conf configurations. # class tripleo::host::liquidio::config ( $liquidio_config = {} ) { validate_hash($liquidio_config) create_resources('liquidio_config', $liquidio_config) } ",,259,30
openstack%2Fbifrost~master~Ic09d5b22e58d50180e915dee3c9ed80471a3069a,openstack/bifrost,master,Ic09d5b22e58d50180e915dee3c9ed80471a3069a,"[DNM] Revert ""Add possibility to use proper public URLs for endpoints""",ABANDONED,2018-09-26 06:21:33.000000000,2018-09-27 09:34:02.000000000,,"[{'_account_id': 19578}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 06:21:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/01445456b08ecb25d3312616fa106febc6be19ef', 'message': '[DNM] Revert ""Add possibility to use proper public URLs for endpoints""\n\nTesting impact on CI\n\nChange-Id: Ic09d5b22e58d50180e915dee3c9ed80471a3069a\n'}, {'number': 2, 'created': '2018-09-26 07:56:03.000000000', 'files': ['playbooks/roles/bifrost-ironic-install/tasks/keystone_setup.yml', 'releasenotes/notes/use_public_urls_endpoints-1220a7f4164696c3.yaml', 'playbooks/roles/bifrost-keystone-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-ironic-install/tasks/keystone_setup_inspector.yml'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/47fbde3092416e33430d667f93648e5d56a2a31f', 'message': '[DNM] Revert ""Add possibility to use proper public URLs for endpoints""\n\nTesting impact on CI\n\nChange-Id: Ic09d5b22e58d50180e915dee3c9ed80471a3069a\n'}]",0,605338,47fbde3092416e33430d667f93648e5d56a2a31f,6,2,2,19578,,,0,"[DNM] Revert ""Add possibility to use proper public URLs for endpoints""

Testing impact on CI

Change-Id: Ic09d5b22e58d50180e915dee3c9ed80471a3069a
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/38/605338/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-ironic-install/tasks/keystone_setup.yml', 'playbooks/test-bifrost.yaml', 'releasenotes/notes/use_public_urls_endpoints-1220a7f4164696c3.yaml', 'playbooks/roles/bifrost-keystone-install/tasks/bootstrap.yml', 'playbooks/roles/bifrost-ironic-install/tasks/keystone_setup_inspector.yml']",5,01445456b08ecb25d3312616fa106febc6be19ef,dnm-test-revert-impact-on-ci," baremetal-introspection public ""{{ ironic_inspector.keystone.public_url | default('http://127.0.0.1:5050/') }}""","- name: ""Setting external ironic-inspector public URL"" set_fact: ironic_inspector_public_url: ""{{ ironic_inspector.keystone.public_url | default('http://127.0.0.1:5050/') | replace('127.0.0.1', hostvars[inventory_hostname]['ansible_' + ans_network_interface]['ipv4']['address']) }}"" when: use_public_urls | default(false) | bool baremetal-introspection public ""{{ ironic_inspector_public_url | default(ironic_inspector.keystone.public_url) | default('http://127.0.0.1:5050/') }}""",7,31
openstack%2Ftripleo-upgrade~master~Ie39f2eb1b5dab5b6a43485f655a05bed5454dc76,openstack/tripleo-upgrade,master,Ie39f2eb1b5dab5b6a43485f655a05bed5454dc76,Don't change user during ping check.,MERGED,2018-09-25 07:31:47.000000000,2018-09-27 09:30:34.000000000,2018-09-27 01:12:11.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 11090}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-25 07:31:47.000000000', 'files': ['tasks/common/undercloud_validate_upgrade.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/1e04ab81a57ade978dca4f0d7693e8aafc41c91a', 'message': ""Don't change user during ping check.\n\nWhen bm undercloud is rebooted task is delegated to 'localhost',\nwhere user 'stack' may not exist:\n Failed to set permissions on the temporary files\n Ansible needs to create when becoming an unprivileged user\n (rc: 1, err: chown: invalid user: stack\n\nChange-Id: Ie39f2eb1b5dab5b6a43485f655a05bed5454dc76\n""}]",0,604990,1e04ab81a57ade978dca4f0d7693e8aafc41c91a,10,7,1,21537,,,0,"Don't change user during ping check.

When bm undercloud is rebooted task is delegated to 'localhost',
where user 'stack' may not exist:
 Failed to set permissions on the temporary files
 Ansible needs to create when becoming an unprivileged user
 (rc: 1, err: chown: invalid user: stack

Change-Id: Ie39f2eb1b5dab5b6a43485f655a05bed5454dc76
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/90/604990/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/common/undercloud_validate_upgrade.yaml'],1,1e04ab81a57ade978dca4f0d7693e8aafc41c91a,bm-ping, become: no,,1,0
openstack%2Fopenstack-zuul-jobs~master~I45622ac18685b809a091edba2df96fc8040138a8,openstack/openstack-zuul-jobs,master,I45622ac18685b809a091edba2df96fc8040138a8,add Gentoo jobs and vars and also fix install test,MERGED,2018-09-13 20:21:22.000000000,2018-09-27 09:20:23.000000000,2018-09-27 09:20:23.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-13 20:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/47f5fbb89670798117224cc2056a83fa3b0bcbee', 'message': 'add Gentoo jobs\n\nBased them on fedora-latest jobs\n\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 2, 'created': '2018-09-14 22:10:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/683755689184dbe773a8b0022e15011e658ddc22', 'message': 'add Gentoo jobs and fix unbound\n\nBased them on fedora-latest jobs\n\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 3, 'created': '2018-09-14 22:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/68210e87430898c444b2bb867411d73c48f8aa91', 'message': 'add Gentoo jobs and fix unbound\n\nBased them on fedora-latest jobs\n\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 4, 'created': '2018-09-18 18:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/22a8cf300f5ede70fa6e3bdfa6670b0427861234', 'message': 'add Gentoo jobs and fix unbound\n\nBased them on fedora-latest jobs\n\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 5, 'created': '2018-09-20 07:32:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/215050bef9d8e158f2afc60addc8835d99415c46', 'message': 'add Gentoo jobs and fix install test\n\nBased them on fedora-latest jobs\n\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 6, 'created': '2018-09-24 04:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/076340458607a6f8ce2b4f2ca2c8fe2c9c4b59ed', 'message': 'add Gentoo jobs and fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604671/\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 7, 'created': '2018-09-24 05:23:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/2e8834d4e43d684fdbe9b80b633f9a918eb4d390', 'message': 'add Gentoo jobs and fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604671/\nDepends-On: https://review.openstack.org/604677/\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 8, 'created': '2018-09-24 06:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/6eba620da5e44759194007c8d9440e5ee8f0f17a', 'message': 'add Gentoo jobs and fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604671\nDepends-On: https://review.openstack.org/604677\nDepends-On: https://review.openstack.org/604688\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 9, 'created': '2018-09-24 13:54:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/c375977fa5e27e48b242e92e20689118f2e75d56', 'message': 'add Gentoo jobs and vars and also fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604671\nDepends-On: https://review.openstack.org/604677\nDepends-On: https://review.openstack.org/604688\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 10, 'created': '2018-09-24 13:58:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/656b2078bbe12d21e34521997acad1759c622eaf', 'message': 'add Gentoo jobs and vars and also fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604677\nDepends-On: https://review.openstack.org/604688\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}, {'number': 11, 'created': '2018-09-26 01:58:04.000000000', 'files': ['tests/configure-mirrors.yaml', 'tests/multinode_firewall_persistence_vars/Gentoo.yaml', 'zuul.d/project.yaml', 'zuul.d/nodesets.yaml', 'tests/multi-node-firewall-persistence.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/3b03acabf422570ab8b068b1310a113099ec299f', 'message': 'add Gentoo jobs and vars and also fix install test\n\nBased them on fedora-latest jobs\n\nDepends-On: https://review.openstack.org/604677\nDepends-On: https://review.openstack.org/604688\nChange-Id: I45622ac18685b809a091edba2df96fc8040138a8\n'}]",4,602439,3b03acabf422570ab8b068b1310a113099ec299f,52,5,11,14288,,,0,"add Gentoo jobs and vars and also fix install test

Based them on fedora-latest jobs

Depends-On: https://review.openstack.org/604677
Depends-On: https://review.openstack.org/604688
Change-Id: I45622ac18685b809a091edba2df96fc8040138a8
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/39/602439/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/nodesets.yaml', 'zuul.d/jobs.yaml']",3,47f5fbb89670798117224cc2056a83fa3b0bcbee,add-gentoo-jobs, name: openstack-infra-base-integration-gentoo-17-0-systemd parent: openstack-infra-base-integration nodeset: gentoo-17-0-systemd - job: name: openstack-infra-multinode-integration-gentoo-17-0-systemd parent: openstack-infra-multinode-integration nodeset: nodes: - name: primary label: gentoo-17-0-systemd - name: secondary label: gentoo-17-0-systemd groups: - name: switch nodes: - primary - name: peers nodes: - secondary - job:,,32,0
openstack%2Fpython-novaclient~master~I2a0af23e358cea50bf1ec5735556fa05f607db28,openstack/python-novaclient,master,I2a0af23e358cea50bf1ec5735556fa05f607db28,Update the URL in doc,ABANDONED,2018-09-23 15:01:18.000000000,2018-09-27 09:09:32.000000000,,"[{'_account_id': 679}, {'_account_id': 2472}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-23 15:01:18.000000000', 'files': ['releasenotes/notes/add-user-agent-string-db77210dfd3ec671.yaml'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/40a8a2675ec36229897a41a7f750ee8a9cd624d5', 'message': 'Update the URL in doc\n\nChange-Id: I2a0af23e358cea50bf1ec5735556fa05f607db28\n'}]",0,604629,40a8a2675ec36229897a41a7f750ee8a9cd624d5,6,4,1,17130,,,0,"Update the URL in doc

Change-Id: I2a0af23e358cea50bf1ec5735556fa05f607db28
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/29/604629/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/add-user-agent-string-db77210dfd3ec671.yaml'],1,40a8a2675ec36229897a41a7f750ee8a9cd624d5,fix-url, https://docs.openstack.org/python-novaclient/latest/reference/api/index.html, https://docs.openstack.org/developer/python-novaclient/api.html,1,1
openstack%2Ftripleo-docs~master~Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9,openstack/tripleo-docs,master,Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9,Document standalone/UC update Heat stack specifics,MERGED,2018-06-28 13:32:04.000000000,2018-09-27 08:55:11.000000000,2018-09-27 08:55:11.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 4328}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-28 13:32:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/70f415d612b50ca6b039407b43155ef373f34a12', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2018-08-24 13:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/009c40474177af3ff2a5e3532d0f6d24ce280cc8', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2018-09-13 12:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/bde69ca27beef845a6e8f10eae83f40ea9ff81bb', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2018-09-24 14:24:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/7cbaeb9a022945535692ed1b6a1930bf180197dc', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2018-09-25 10:21:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/b8423f815db9b953bcbed24c376b2bbdf097f493', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 6, 'created': '2018-09-25 10:23:49.000000000', 'files': ['doc/source/install/containers_deployment/standalone.rst', 'doc/source/install/post_deployment/updating-stacks-notes.rst', 'doc/source/install/post_deployment/post_deployment.rst', 'doc/source/install/installation/updating.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-docs/commit/e7c8bf345f9670f6e638d23e38c7048119f909a7', 'message': 'Document standalone/UC update Heat stack specifics\n\nExplain the overcloud vs undercloud/standalone heat stack updates\nDocument use cases for the --force-stack-update option and how\nit can be used with --dry-run and --output-only.\nBriefly mention --dry-run and --output-only as well.\n\nDepends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08\nRelated-bug: #1778505\n\nChange-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",38,578799,e7c8bf345f9670f6e638d23e38c7048119f909a7,32,9,6,6926,,,0,"Document standalone/UC update Heat stack specifics

Explain the overcloud vs undercloud/standalone heat stack updates
Document use cases for the --force-stack-update option and how
it can be used with --dry-run and --output-only.
Briefly mention --dry-run and --output-only as well.

Depends-on: I7c7b2bd6d202268fdf4bc08f951ec4c9c4065c08
Related-bug: #1778505

Change-Id: Ie24eaec6871990e38df4e66abe2cc1ea866d9bd9
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-docs refs/changes/99/578799/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/containers_deployment/standalone.rst', 'doc/source/install/post_deployment/updating-stacks-notes.rst', 'doc/source/install/post_deployment/post_deployment.rst', 'doc/source/install/installation/updating.rst']",4,70f415d612b50ca6b039407b43155ef373f34a12,bug/1778505,".. note:: When updating the existing containerized undercloud installation, keep in mind the special cases described in :ref:`notes-for-stack-updates`. ",,50,0
openstack%2Ftelemetry-tempest-plugin~master~Ifbd35398a038febfb5e5818a85e07d3a96abe1b6,openstack/telemetry-tempest-plugin,master,Ifbd35398a038febfb5e5818a85e07d3a96abe1b6,change default python 3 env in tox to 3.5,ABANDONED,2018-06-15 07:12:01.000000000,2018-09-27 08:51:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-06-15 07:12:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/telemetry-tempest-plugin/commit/f9830b0124fe4c474a925b95c8d3e4c24e1245e6', 'message': 'change default python 3 env in tox to 3.5\n\nChange-Id: Ifbd35398a038febfb5e5818a85e07d3a96abe1b6\n'}]",0,575660,f9830b0124fe4c474a925b95c8d3e4c24e1245e6,3,1,1,17499,,,0,"change default python 3 env in tox to 3.5

Change-Id: Ifbd35398a038febfb5e5818a85e07d3a96abe1b6
",git fetch https://review.opendev.org/openstack/telemetry-tempest-plugin refs/changes/60/575660/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f9830b0124fe4c474a925b95c8d3e4c24e1245e6,,"envlist = py35,py27,pypy,pep8","envlist = py34,py27,pypy,pep8",1,1
openstack%2Fopenstack-ansible-os_neutron~master~Ifbc274a96299e53eee8ae3652c69e5f6c3538f7f,openstack/openstack-ansible-os_neutron,master,Ifbc274a96299e53eee8ae3652c69e5f6c3538f7f,Trivial: Fix the pep8 warning,MERGED,2018-08-06 07:45:05.000000000,2018-09-27 08:49:52.000000000,2018-09-27 08:49:51.000000000,"[{'_account_id': 7353}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 26285}, {'_account_id': 26297}]","[{'number': 1, 'created': '2018-08-06 07:45:05.000000000', 'files': ['tasks/providers/nuage_config.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/4ed4125a52c9bed8686936f6eb118b8e77f20e7d', 'message': 'Trivial: Fix the pep8 warning\n\nThe yaml should start with ""---""\n\nChange-Id: Ifbc274a96299e53eee8ae3652c69e5f6c3538f7f\n'}]",0,589051,4ed4125a52c9bed8686936f6eb118b8e77f20e7d,19,6,1,21486,,,0,"Trivial: Fix the pep8 warning

The yaml should start with ""---""

Change-Id: Ifbc274a96299e53eee8ae3652c69e5f6c3538f7f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/51/589051/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/providers/nuage_config.yml'],1,4ed4125a52c9bed8686936f6eb118b8e77f20e7d,,---,,1,0
openstack%2Fpuppet-pacemaker~master~Iba2371f07710a5fb64478ad9eb07d3a4c845c34b,openstack/puppet-pacemaker,master,Iba2371f07710a5fb64478ad9eb07d3a4c845c34b,Add release note link in README,ABANDONED,2018-06-27 14:29:32.000000000,2018-09-27 08:49:35.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-06-27 14:29:32.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/puppet-pacemaker/commit/5c0be602450e27bb7018c36d243ab27db7176948', 'message': 'Add release note link in README\n\nChange-Id: Iba2371f07710a5fb64478ad9eb07d3a4c845c34b\n'}]",0,578415,5c0be602450e27bb7018c36d243ab27db7176948,3,1,1,17499,,,0,"Add release note link in README

Change-Id: Iba2371f07710a5fb64478ad9eb07d3a4c845c34b
",git fetch https://review.opendev.org/openstack/puppet-pacemaker refs/changes/15/578415/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,5c0be602450e27bb7018c36d243ab27db7176948,,Release notes for the project can be found at: https://docs.openstack.org/releasenotes/puppet-pacemaker,,2,0
openstack%2Ftempest-stress~master~Id201261cea97050f12ca08fa35a55a2fb2096be0,openstack/tempest-stress,master,Id201261cea97050f12ca08fa35a55a2fb2096be0,fix tox python3 overrides,ABANDONED,2018-06-12 05:57:01.000000000,2018-09-27 08:49:03.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-06-12 05:57:01.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tempest-stress/commit/b8f8553651da312016de512c5f9e5d669026a16c', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: Id201261cea97050f12ca08fa35a55a2fb2096be0\n'}]",0,574563,b8f8553651da312016de512c5f9e5d669026a16c,3,1,1,17499,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: Id201261cea97050f12ca08fa35a55a2fb2096be0
",git fetch https://review.opendev.org/openstack/tempest-stress refs/changes/63/574563/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b8f8553651da312016de512c5f9e5d669026a16c,,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,,6,0
openstack%2Fkeystone~master~I591179cc0e88ccde372e5df5695402b0b7aa1617,openstack/keystone,master,I591179cc0e88ccde372e5df5695402b0b7aa1617,Removes unnecessary utf-8 encoding,ABANDONED,2018-09-27 04:24:12.000000000,2018-09-27 08:47:28.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-27 04:24:12.000000000', 'files': ['keystone/tests/unit/identity/backends/test_ldap_common.py', 'keystone/tests/unit/test_validation.py', 'keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/test_backend_id_mapping_sql.py', 'keystone/tests/unit/test_backend_ldap.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/5e6d73407d597cbbae076291ffe1cefb826639b8', 'message': 'Removes unnecessary utf-8 encoding\n\nIn encoding declaration section of [1]\nutf-8 is the default encoding.So\nexplicit declaration not required.\n\n[1] https://docs.python.org/3/reference/lexical_analysis.html\n\nChange-Id: I591179cc0e88ccde372e5df5695402b0b7aa1617\n'}]",0,605582,5e6d73407d597cbbae076291ffe1cefb826639b8,3,1,1,27621,,,0,"Removes unnecessary utf-8 encoding

In encoding declaration section of [1]
utf-8 is the default encoding.So
explicit declaration not required.

[1] https://docs.python.org/3/reference/lexical_analysis.html

Change-Id: I591179cc0e88ccde372e5df5695402b0b7aa1617
",git fetch https://review.opendev.org/openstack/keystone refs/changes/82/605582/1 && git format-patch -1 --stdout FETCH_HEAD,"['keystone/tests/unit/identity/backends/test_ldap_common.py', 'keystone/tests/unit/test_validation.py', 'keystone/tests/unit/mapping_fixtures.py', 'keystone/tests/unit/test_backend_id_mapping_sql.py', 'keystone/tests/unit/test_backend_ldap.py']",5,5e6d73407d597cbbae076291ffe1cefb826639b8,encoding,,# -*- coding: utf-8 -*-,0,6
openstack%2Fswift~master~I53e3ed77c8279ac48f738e396672794300de440d,openstack/swift,master,I53e3ed77c8279ac48f738e396672794300de440d,Replacing six.iter/dict.iter usages,MERGED,2017-08-04 03:25:39.000000000,2018-09-27 08:43:30.000000000,2018-09-27 08:43:30.000000000,"[{'_account_id': 3}, {'_account_id': 597}, {'_account_id': 13052}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-08-04 03:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/933c0a12142db80dd8251f487f7b5ad01ce523c0', 'message': 'Replacing six.iter usages substituting .items(), .keys()\nand .values() in place of six.iteritems/dict.iteritems,\nsix.iterkeys/dict.iterkeys and six.itervalues/itervalues\nrespectively.\n\n1.As mentioned in [1], we should avoid using six.iteritems\nto achieve iterators. We can use dict.items instead, as it\nwill return iterators in PY3 as well. And dict.items/keys\nwill more readable. 2.In py2, the performance about list should be negligible,\nsee the link [2].\n[1] https://wiki.openstack.org/wiki/Python3\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I53e3ed77c8279ac48f738e396672794300de440d\n'}, {'number': 2, 'created': '2017-08-04 06:24:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/19e5829e9d5126ab0095da534c15930c4c38b42f', 'message': 'Replacing six.iter usages substituting .items(), .keys()\nand .values() in place of six.iteritems/dict.iteritems,\nsix.iterkeys/dict.iterkeys and six.itervalues/itervalues\nrespectively.\n\n1.As mentioned in [1], we should avoid using six.iteritems\nto achieve iterators. We can use dict.items instead, as it\nwill return iterators in PY3 as well. And dict.items/keys\nwill more readable. 2.In py2, the performance about list\nshould be negligible,see the link [2].\n\n[1] https://wiki.openstack.org/wiki/Python3#Common patterns\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I53e3ed77c8279ac48f738e396672794300de440d\n'}, {'number': 3, 'created': '2017-08-04 06:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/75cd1ebdf43fae11dc4bb63cb33abbfbf659996a', 'message': 'Replacing six.iter/dict.iter usages\n\nReplacing six.iter usages substituting .items(), and\n.values() in place of six.iteritems/dict.iteritems,\nand six.itervalues/itervalues respectively.\n\n1.As mentioned in [1], we should avoid using six.iteritems\nto achieve iterators. We can use dict.items instead, as it\nwill return iterators in PY3 as well. And dict.items/keys\nwill more readable.\n2.In py2, the performance about listshould be negligible,\nsee the link [2].\n\n[1] https://wiki.openstack.org/wiki/Python3#Common patterns\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I53e3ed77c8279ac48f738e396672794300de440d\n'}, {'number': 4, 'created': '2017-08-07 08:42:59.000000000', 'files': ['doc/source/ring_background.rst', 'test/functional/test_access_control.py', 'swift/proxy/controllers/base.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/e9d0a7acab63876b78c75d4e2c363c4b4fb1a01a', 'message': 'Replacing six.iter/dict.iter usages\n\nReplacing six.iter usages substituting .items(), and\n.values() in place of six.iteritems/dict.iteritems,\nand six.itervalues/itervalues respectively.\n\n1.As mentioned in [1], we should avoid using six.iteritems\nto achieve iterators. We can use dict.items instead, as it\nwill return iterators in PY3 as well. And dict.items/keys\nwill more readable.\n2.In py2, the performance about listshould be negligible,\nsee the link [2].\n\n[1] https://wiki.openstack.org/wiki/Python3#Common patterns\n[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html\n\nChange-Id: I53e3ed77c8279ac48f738e396672794300de440d\n'}]",3,490730,e9d0a7acab63876b78c75d4e2c363c4b4fb1a01a,21,5,4,25432,,,0,"Replacing six.iter/dict.iter usages

Replacing six.iter usages substituting .items(), and
.values() in place of six.iteritems/dict.iteritems,
and six.itervalues/itervalues respectively.

1.As mentioned in [1], we should avoid using six.iteritems
to achieve iterators. We can use dict.items instead, as it
will return iterators in PY3 as well. And dict.items/keys
will more readable.
2.In py2, the performance about listshould be negligible,
see the link [2].

[1] https://wiki.openstack.org/wiki/Python3#Common patterns
[2] http://lists.openstack.org/pipermail/openstack-dev/2015-June/066391.html

Change-Id: I53e3ed77c8279ac48f738e396672794300de440d
",git fetch https://review.opendev.org/openstack/swift refs/changes/30/490730/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/ring_background.rst', 'test/functional/test_access_control.py', 'swift/proxy/controllers/base.py']",3,933c0a12142db80dd8251f487f7b5ad01ce523c0,," for key, val in headers.items():"," for key, val in six.iteritems(headers):",16,16
openstack%2Fmonasca-ceilometer~master~Ifeeadc16eb70b6f5abb0ed3627f0f4bf18f1234b,openstack/monasca-ceilometer,master,Ifeeadc16eb70b6f5abb0ed3627f0f4bf18f1234b,fix tox python3 overrides,ABANDONED,2018-06-12 02:47:41.000000000,2018-09-27 08:42:34.000000000,,"[{'_account_id': 10311}, {'_account_id': 11580}, {'_account_id': 17499}, {'_account_id': 19554}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-12 02:47:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/6c781d221f7d354a0c5ec5de81edbdfd022f5d71', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: Ifeeadc16eb70b6f5abb0ed3627f0f4bf18f1234b\n'}, {'number': 2, 'created': '2018-07-24 05:31:49.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ceilometer/commit/39362e5963bc09ee02890a75b3233258ed7430a8', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: Ifeeadc16eb70b6f5abb0ed3627f0f4bf18f1234b\n'}]",1,574515,39362e5963bc09ee02890a75b3233258ed7430a8,11,5,2,17499,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: Ifeeadc16eb70b6f5abb0ed3627f0f4bf18f1234b
",git fetch https://review.opendev.org/openstack/monasca-ceilometer refs/changes/15/574515/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6c781d221f7d354a0c5ec5de81edbdfd022f5d71,,basepython = python3basepython = python3,,2,0
openstack%2Fswift~master~I0b9983a182daedd9dbec483b805d263238fcfac7,openstack/swift,master,I0b9983a182daedd9dbec483b805d263238fcfac7,py3: port direct_client,MERGED,2018-09-15 07:45:06.000000000,2018-09-27 08:38:48.000000000,2018-09-27 08:38:47.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-15 07:45:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1bbb8c214421cecfd70cbebe4c3cefb46fa7c96c', 'message': 'py3: port direct_client\n\nI wanna see how far I can get *without* mucking around in swob and\nrequest_helpers. Maybe eventually we can get some helpers out there to\nmake working with UTF-8-pretending-to-be-Latin-1 strings better, but for\nthe time being, I feel more at ease *embracing* the crazy.\n\nChange-Id: I0b9983a182daedd9dbec483b805d263238fcfac7\nCo-Authored-By: Pete Zaitcev <zaitcev@kotori.zaitcev.us>\n'}, {'number': 2, 'created': '2018-09-15 16:13:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bd9da1c4edefff6901380b6db3f534a43d6059b2', 'message': 'py3: port direct_client\n\nI wanna see how far I can get *without* mucking around in swob and\nrequest_helpers. Maybe eventually we can get some helpers out there to\nmake working with UTF-8-pretending-to-be-Latin-1 strings better, but for\nthe time being, I feel more at ease *embracing* the crazy.\n\nChange-Id: I0b9983a182daedd9dbec483b805d263238fcfac7\nCo-Authored-By: Pete Zaitcev <zaitcev@kotori.zaitcev.us>\n'}, {'number': 3, 'created': '2018-09-25 20:47:10.000000000', 'files': ['swift/common/utils.py', 'test/unit/common/test_direct_client.py', 'swift/common/direct_client.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/ddd5cc1592c7c761162382b0543c653142fe38cf', 'message': 'py3: port direct_client\n\nI wanna see how far I can get *without* mucking around in swob and\nrequest_helpers. Maybe eventually we can get some helpers out there to\nmake working with UTF-8-pretending-to-be-Latin-1 strings better, but for\nthe time being, I feel more at ease *embracing* the crazy.\n\nChange-Id: I0b9983a182daedd9dbec483b805d263238fcfac7\nCo-Authored-By: Pete Zaitcev <zaitcev@kotori.zaitcev.us>\n'}]",0,602822,ddd5cc1592c7c761162382b0543c653142fe38cf,18,3,3,15343,,,0,"py3: port direct_client

I wanna see how far I can get *without* mucking around in swob and
request_helpers. Maybe eventually we can get some helpers out there to
make working with UTF-8-pretending-to-be-Latin-1 strings better, but for
the time being, I feel more at ease *embracing* the crazy.

Change-Id: I0b9983a182daedd9dbec483b805d263238fcfac7
Co-Authored-By: Pete Zaitcev <zaitcev@kotori.zaitcev.us>
",git fetch https://review.opendev.org/openstack/swift refs/changes/22/602822/3 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/utils.py', 'test/unit/common/test_direct_client.py', 'swift/common/direct_client.py', 'tox.ini']",4,1bbb8c214421cecfd70cbebe4c3cefb46fa7c96c,py3-common-clients, test/unit/common/test_direct_client.py \ test/unit/common/test_memcached.py \, test/unit/common/test_memcached.py \,113,165
openstack%2Fopenstack-ansible-os_ironic~stable%2Fqueens~Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2,openstack/openstack-ansible-os_ironic,stable/queens,Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2,Adding [service_catalog] in ironic.conf,MERGED,2018-09-26 02:57:52.000000000,2018-09-27 08:33:27.000000000,2018-09-27 08:33:27.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8125}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 26181}]","[{'number': 1, 'created': '2018-09-26 02:57:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/02107e0eddd7d49a7dfd3e0d2c498ba65226ddfe', 'message': 'Adding [service_catalog] in ironic.conf  (50 character)\n\nIn absence of this section ironic conductor\nfails to identify authentication mechanism\nand fails to deploy node.\n\nChange-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2\nCloses-Bug: #1793959\n(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)\n'}, {'number': 2, 'created': '2018-09-26 15:59:50.000000000', 'files': ['templates/ironic.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/cebfc095ce6ebdb6e7d19ee5a21786f933276421', 'message': 'Adding [service_catalog] in ironic.conf\n\nIn absence of this section ironic conductor\nfails to identify authentication mechanism\nand fails to deploy node.\n\nChange-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2\nCloses-Bug: #1793959\n(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)\n'}]",0,605313,cebfc095ce6ebdb6e7d19ee5a21786f933276421,11,7,2,26181,,,0,"Adding [service_catalog] in ironic.conf

In absence of this section ironic conductor
fails to identify authentication mechanism
and fails to deploy node.

Change-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2
Closes-Bug: #1793959
(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/13/605313/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/ironic.conf.j2'],1,02107e0eddd7d49a7dfd3e0d2c498ba65226ddfe,bug/1793959-stable/queens,[service_catalog] insecure = {{ keystone_service_internaluri_insecure | bool }} auth_type = {{ ironic_keystone_auth_plugin }} auth_url = {{ keystone_service_adminuri }} www_authenticate_uri = {{ keystone_service_internaluri }} project_domain_id = {{ ironic_service_project_domain_id }} user_domain_id = {{ ironic_service_user_domain_id }} project_name = {{ ironic_service_project_name }} username = {{ ironic_service_user_name }} password = {{ ironic_service_password }} region_name = {{ keystone_service_region }} ,,13,0
openstack%2Fopenstack-ansible-os_ironic~stable%2Frocky~Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2,openstack/openstack-ansible-os_ironic,stable/rocky,Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2,Adding [service_catalog] in ironic.conf,MERGED,2018-09-26 02:57:24.000000000,2018-09-27 08:33:27.000000000,2018-09-27 08:33:27.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 8125}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 26181}]","[{'number': 1, 'created': '2018-09-26 02:57:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/b05658078defcde28357171e9261df280a8d2c07', 'message': 'Adding [service_catalog] in ironic.conf  (50 character)\n\nIn absence of this section ironic conductor\nfails to identify authentication mechanism\nand fails to deploy node.\n\nChange-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2\nCloses-Bug: #1793959\n(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)\n'}, {'number': 2, 'created': '2018-09-26 15:57:40.000000000', 'files': ['templates/ironic.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ironic/commit/d92a6b64d2b62bf869a797bc204810626dd31208', 'message': 'Adding [service_catalog] in ironic.conf\n\nIn absence of this section ironic conductor\nfails to identify authentication mechanism\nand fails to deploy node.\n\nChange-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2\nCloses-Bug: #1793959\n(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)\n'}]",0,605311,d92a6b64d2b62bf869a797bc204810626dd31208,12,7,2,26181,,,0,"Adding [service_catalog] in ironic.conf

In absence of this section ironic conductor
fails to identify authentication mechanism
and fails to deploy node.

Change-Id: Ic0d58c694ebced64c0eb2f118980eade7ba7d1e2
Closes-Bug: #1793959
(cherry picked from commit 6e0904ddf6d57ef22683060e1b2f2c8b35f84bc4)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ironic refs/changes/11/605311/1 && git format-patch -1 --stdout FETCH_HEAD,['templates/ironic.conf.j2'],1,b05658078defcde28357171e9261df280a8d2c07,bug/1793959-stable/rocky,[service_catalog] insecure = {{ keystone_service_internaluri_insecure | bool }} auth_type = {{ ironic_keystone_auth_plugin }} auth_url = {{ keystone_service_adminuri }} www_authenticate_uri = {{ keystone_service_internaluri }} project_domain_id = {{ ironic_service_project_domain_id }} user_domain_id = {{ ironic_service_user_domain_id }} project_name = {{ ironic_service_project_name }} username = {{ ironic_service_user_name }} password = {{ ironic_service_password }} region_name = {{ keystone_service_region }} ,,13,0
openstack%2Fcharm-swift-proxy~master~Ic9df7c12ee0bb402245ad2e64da0d905fe68890c,openstack/charm-swift-proxy,master,Ic9df7c12ee0bb402245ad2e64da0d905fe68890c,Update pipeline for refstack compatibility,MERGED,2018-09-25 09:29:04.000000000,2018-09-27 08:32:48.000000000,2018-09-27 08:32:48.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 09:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/69fa12d31157b57fb52061f669536e90ed72bc81', 'message': 'Update pipeline for refstack compatibility\n\nRe-align pipeline with default example pipeline; this includes\nadding the following new middleware:\n\n    - copy\n    - ratelimit\n    - symlink\n\nRe-work SLO middleware configuration to avoid duplicated section.\n\nRe-order middleware inline with documentation avoiding authentication\nissues when using DLO/SLO features.\n\nChange-Id: Ic9df7c12ee0bb402245ad2e64da0d905fe68890c\nCloses-Bug: 1794255\n'}, {'number': 2, 'created': '2018-09-25 10:48:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/76e7d01f2f4e16287db0a6f71591cd090eb24fbd', 'message': 'Update pipeline for refstack compatibility\n\nRe-align pipeline with default example pipeline; this includes\nadding the following new middleware:\n\n    - copy\n    - ratelimit\n    - symlink\n\nRe-work SLO middleware configuration to avoid duplicated section.\n\nRe-order middleware inline with documentation avoiding authentication\nissues when using DLO/SLO features.\n\nDrop proxy-server.conf validation; its brittle and function should be\nvalidated by other tests anyway.\n\nChange-Id: Ic9df7c12ee0bb402245ad2e64da0d905fe68890c\nCloses-Bug: 1794255\n'}, {'number': 3, 'created': '2018-09-26 07:14:44.000000000', 'files': ['tests/basic_deployment.py', 'templates/queens/proxy-server.conf'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/e92e8a75e054d63db12bbbcddee41e0d5c29255e', 'message': 'Update pipeline for refstack compatibility\n\nRe-align pipeline with default example pipeline; this includes\nadding the following new middleware:\n\n    - copy\n    - ratelimit\n    - symlink\n\nRe-work SLO middleware configuration to avoid duplicated section.\n\nRe-order middleware inline with documentation avoiding authentication\nissues when using DLO/SLO features.\n\nDrop proxy-server.conf validation; its brittle and function should be\nvalidated by other tests anyway.\n\nChange-Id: Ic9df7c12ee0bb402245ad2e64da0d905fe68890c\nCloses-Bug: 1794255\n'}]",0,605018,e92e8a75e054d63db12bbbcddee41e0d5c29255e,16,4,3,935,,,0,"Update pipeline for refstack compatibility

Re-align pipeline with default example pipeline; this includes
adding the following new middleware:

    - copy
    - ratelimit
    - symlink

Re-work SLO middleware configuration to avoid duplicated section.

Re-order middleware inline with documentation avoiding authentication
issues when using DLO/SLO features.

Drop proxy-server.conf validation; its brittle and function should be
validated by other tests anyway.

Change-Id: Ic9df7c12ee0bb402245ad2e64da0d905fe68890c
Closes-Bug: 1794255
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/18/605018/3 && git format-patch -1 --stdout FETCH_HEAD,['templates/queens/proxy-server.conf'],1,69fa12d31157b57fb52061f669536e90ed72bc81,bug/1794255,pipeline = ceilometer catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk tempurl ratelimit formpost authtoken keystoneauth swift3 s3token staticweb copy container-quotas account-quotas slo dlo versioned_writes symlink proxy-logging proxy-serverpipeline = catch_errors gatekeeper healthcheck proxy-logging cache container_sync bulk tempurl ratelimit formpost authtoken keystoneauth swift3 s3token staticweb copy container-quotas account-quotas slo dlo versioned_writes symlink proxy-logging proxy-server{% if static_large_object_segments and static_large_object_segments > 0 %} max_manifest_size = 536870912 max_manifest_segments = {{ static_large_object_segments }} {% endif %}[filter:ratelimit] use = egg:swift#ratelimit [filter:copy] use = egg:swift#copy [filter:symlink] use = egg:swift#symlink ,pipeline = ceilometer catch_errors gatekeeper healthcheck proxy-logging cache swift3 s3token container_sync bulk tempurl slo dlo formpost authtoken keystoneauth staticweb versioned_writes container-quotas account-quotas proxy-logging proxy-serverpipeline = catch_errors gatekeeper healthcheck proxy-logging cache authtoken swift3 s3token container_sync bulk tempurl slo dlo formpost keystoneauth staticweb versioned_writes container-quotas account-quotas proxy-logging proxy-server {% if static_large_object_segments and static_large_object_segments > 0 %} [filter:slo] use = egg:swift#slo max_manifest_size = 536870912 max_manifest_segments = {{ static_large_object_segments }} {% endif %},15,9
openstack%2Foctavia~master~I1b53076953eaf1a6c6934a10439d00977c875fec,openstack/octavia,master,I1b53076953eaf1a6c6934a10439d00977c875fec,Split up extra init steps and start processes,MERGED,2018-03-08 22:02:22.000000000,2018-09-27 08:30:30.000000000,2018-03-16 10:27:04.000000000,"[{'_account_id': 10273}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-03-08 22:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/a951daa9676f5d6230a37dd4bb4a3e61764e209e', 'message': 'Prevent awk matching itself when stopping Octavia\n\nawk is awking itself. This keeps awk from showing itself in the output,\ngrabbing only relevant PIDs. Otherwise awk PID is added to PID list\nresulting in kill command exiting with error as awk is no longer\nrunning.\n\nChange-Id: I1b53076953eaf1a6c6934a10439d00977c875fec\n'}, {'number': 2, 'created': '2018-03-09 00:39:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6640d1160c471cd732957cbf10944c35a48057a5', 'message': 'Prevent awk matching itself when stopping Octavia\n\nawk is awking itself. This keeps awk from showing itself in the output,\ngrabbing only relevant PIDs. Otherwise awk PID is added to PID list\nresulting in kill command exiting with error as awk is no longer\nrunning.\n\nChange-Id: I1b53076953eaf1a6c6934a10439d00977c875fec\n'}, {'number': 3, 'created': '2018-03-11 18:26:53.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/octavia/commit/303b339836dddc4f9a89826f9786701ace8bafb7', 'message': 'Split up extra init steps and start processes\n\nBy spliting them up, we can now start Octavia without going through the\nextra initialization steps, which are not idempotent (or meant to be\nanyway), exiting with error code and preventing from continuing the\nso desired start process of Octavia. The split-up will allow Grenade to\ncall out octavia_start solely for the purpose of starting Octavia\nservices.\n\nThis patch also fixes awk from matching itself when stopping Octavia.\nThis keeps awk from showing itself in the output, grabbing only relevant\nPIDs. Otherwise awk PID is added to PID list resulting in kill command\nexiting with error as awk is no longer running. This is equially\nimportant and required grenading Octavia, else an exit error would be\nthrown.\n\nChange-Id: I1b53076953eaf1a6c6934a10439d00977c875fec\n'}]",1,551021,303b339836dddc4f9a89826f9786701ace8bafb7,12,3,3,6469,,,0,"Split up extra init steps and start processes

By spliting them up, we can now start Octavia without going through the
extra initialization steps, which are not idempotent (or meant to be
anyway), exiting with error code and preventing from continuing the
so desired start process of Octavia. The split-up will allow Grenade to
call out octavia_start solely for the purpose of starting Octavia
services.

This patch also fixes awk from matching itself when stopping Octavia.
This keeps awk from showing itself in the output, grabbing only relevant
PIDs. Otherwise awk PID is added to PID list resulting in kill command
exiting with error as awk is no longer running. This is equially
important and required grenading Octavia, else an exit error would be
thrown.

Change-Id: I1b53076953eaf1a6c6934a10439d00977c875fec
",git fetch https://review.opendev.org/openstack/octavia refs/changes/21/551021/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,a951daa9676f5d6230a37dd4bb4a3e61764e209e,octavia_grenade," pids=$(ps aux | grep ""[o]-hm0"" | awk '{print $2}')", pids=$(ps aux | awk '/o-hm0/ { print $2 }'),1,1
openstack%2Frequirements~master~I923adf93f1cd90d479767d548c30379dd18ba88a,openstack/requirements,master,I923adf93f1cd90d479767d548c30379dd18ba88a,update constraint for oslo.i18n to new release 3.22.1,MERGED,2018-09-25 20:02:41.000000000,2018-09-27 08:29:16.000000000,2018-09-27 08:29:16.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 23825}]","[{'number': 1, 'created': '2018-09-25 20:02:41.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/118916c05421e14f4320ca83430e8f21cddffc5a', 'message': 'update constraint for oslo.i18n to new release 3.22.1\n\nChange-Id: I923adf93f1cd90d479767d548c30379dd18ba88a\nmeta:version: 3.22.1\nmeta:diff-start: 3.21.0\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605222,118916c05421e14f4320ca83430e8f21cddffc5a,13,3,1,11131,,,0,"update constraint for oslo.i18n to new release 3.22.1

Change-Id: I923adf93f1cd90d479767d548c30379dd18ba88a
meta:version: 3.22.1
meta:diff-start: 3.21.0
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/605222/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,118916c05421e14f4320ca83430e8f21cddffc5a,new-release,oslo.i18n===3.22.1,oslo.i18n===3.21.0,1,1
openstack%2Ftripleo-ci~master~I8bb0383e86ece0124fd62a07b96620efbeb46823,openstack/tripleo-ci,master,I8bb0383e86ece0124fd62a07b96620efbeb46823,fix tox python3 overrides,ABANDONED,2018-06-11 17:22:44.000000000,2018-09-27 08:27:28.000000000,,[],"[{'number': 1, 'created': '2018-06-11 17:22:44.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f5f023ce53079fea0dffa6772cfe47a01b0920c6', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I8bb0383e86ece0124fd62a07b96620efbeb46823\n'}]",0,574355,f5f023ce53079fea0dffa6772cfe47a01b0920c6,2,0,1,17499,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I8bb0383e86ece0124fd62a07b96620efbeb46823
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/55/574355/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f5f023ce53079fea0dffa6772cfe47a01b0920c6,,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,,6,0
openstack%2Fopenstack-planet~master~I74de31efcca9050737980757fcf9a9a1cf39ee6b,openstack/openstack-planet,master,I74de31efcca9050737980757fcf9a9a1cf39ee6b,Update feed for scas,MERGED,2018-09-27 01:27:22.000000000,2018-09-27 08:20:15.000000000,2018-09-27 08:20:15.000000000,"[{'_account_id': 308}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-27 01:27:22.000000000', 'files': ['planet.ini'], 'web_link': 'https://opendev.org/openstack/openstack-planet/commit/e065b39d554fe1c112d293cae637af7cc303419f', 'message': 'Update feed for scas\n\nChange-Id: I74de31efcca9050737980757fcf9a9a1cf39ee6b\n'}]",0,605564,e065b39d554fe1c112d293cae637af7cc303419f,6,2,1,14790,,,0,"Update feed for scas

Change-Id: I74de31efcca9050737980757fcf9a9a1cf39ee6b
",git fetch https://review.opendev.org/openstack/openstack-planet refs/changes/64/605564/1 && git format-patch -1 --stdout FETCH_HEAD,['planet.ini'],1,e065b39d554fe1c112d293cae637af7cc303419f,,[https://samuel.cassi.ba/feed.openstack.xml],[https://s.cassiba.com/feed.openstack.xml],1,1
openstack%2Faodh~stable%2Fpike~I67af1c7dc5d0d28d8d45a4b3c47b008e391d4071,openstack/aodh,stable/pike,I67af1c7dc5d0d28d8d45a4b3c47b008e391d4071,import zuul job settings from project-config,MERGED,2018-08-31 12:12:09.000000000,2018-09-27 08:12:51.000000000,2018-09-27 08:12:51.000000000,"[{'_account_id': 1669}, {'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-31 12:12:09.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/aodh/commit/d69b8813034f6bf818c0efd61b930b2818279b76', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I67af1c7dc5d0d28d8d45a4b3c47b008e391d4071\nStory: #2002586\nTask: #24339\n'}]",0,598653,d69b8813034f6bf818c0efd61b930b2818279b76,21,4,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I67af1c7dc5d0d28d8d45a4b3c47b008e391d4071
Story: #2002586
Task: #24339
",git fetch https://review.opendev.org/openstack/aodh refs/changes/53/598653/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d69b8813034f6bf818c0efd61b930b2818279b76,python3-first, templates: - openstack-python-jobs - openstack-python35-jobs - publish-openstack-sphinx-docs - release-notes-jobs,,5,0
openstack%2Ftripleo-heat-templates~master~I504b52a2bb3c89e75ac3402f259c317889c054e6,openstack/tripleo-heat-templates,master,I504b52a2bb3c89e75ac3402f259c317889c054e6,"Dropped ""recurse"" for idempotency",MERGED,2018-09-25 11:21:11.000000000,2018-09-27 08:01:10.000000000,2018-09-27 08:01:10.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 10873}, {'_account_id': 11090}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-09-25 11:21:11.000000000', 'files': ['common/deploy-steps-tasks.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/57154fd084309cacf57fbc1d1e1f2d154ad5b49a', 'message': 'Dropped ""recurse"" for idempotency\n\nWe should not need that recurse anyway.\n\nChange-Id: I504b52a2bb3c89e75ac3402f259c317889c054e6\nCloses-Bug: #1794251\n'}]",0,605039,57154fd084309cacf57fbc1d1e1f2d154ad5b49a,19,9,1,28223,,,0,"Dropped ""recurse"" for idempotency

We should not need that recurse anyway.

Change-Id: I504b52a2bb3c89e75ac3402f259c317889c054e6
Closes-Bug: #1794251
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/39/605039/1 && git format-patch -1 --stdout FETCH_HEAD,['common/deploy-steps-tasks.yaml'],1,57154fd084309cacf57fbc1d1e1f2d154ad5b49a,podman/selinux,, recurse: true,0,1
openstack%2Ftripleo-quickstart-extras~master~Ic5834dbf66471802eb5a9319718d3ba02548236c,openstack/tripleo-quickstart-extras,master,Ic5834dbf66471802eb5a9319718d3ba02548236c,Fix used paths to match custom working dir,MERGED,2018-08-21 07:48:43.000000000,2018-09-27 08:01:09.000000000,2018-09-27 08:01:08.000000000,"[{'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12715}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-08-21 07:48:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9a83d36f1953029622cf339b9bd0c7938156f43e', 'message': 'Fix stackrc path to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME hardcode, which only mathches the default\nworking dir of /home/stack.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2018-08-21 07:54:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3696e56ab6d3b39905915af3e7cf5c09c9263090', 'message': 'Fix stackrc path to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2018-08-21 08:26:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c08a5c321f52a67809fa751c0c4c578b9fa759ea', 'message': 'Fix stackrc path to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2018-08-21 09:39:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/2ad20887de4d6153bd8c407269b0b6bad75d70d2', 'message': 'Fix used paths to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nFix openssl commands to refer server-req.pem et al from the\nworking_dir instead of the current dir.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2018-08-21 12:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5a9fc5f2ac766d70bf813a79d47346bc96305328', 'message': 'Fix used paths to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nFix openssl commands to refer server-req.pem et al from the\nworking_dir instead of the current dir.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 6, 'created': '2018-08-24 16:05:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9075a7660780d0fb45127217876d5aa0fef0cd4c', 'message': 'Fix used paths to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nFix openssl commands to refer server-req.pem et al from the\nworking_dir instead of the current dir.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 7, 'created': '2018-09-10 10:33:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a81b96e20c85dc5b12af9ebad1290f37bb3f2c9f', 'message': 'Fix used paths to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nFix openssl commands to refer server-req.pem et al from the\nworking_dir instead of the current dir.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 8, 'created': '2018-09-20 07:50:33.000000000', 'files': ['roles/overcloud-deploy/templates/deployed_server_prepare.sh.j2', 'roles/undercloud-deploy/tasks/post-install.yml', 'roles/overcloud-prep-images/templates/overcloud-prep-images.sh.j2', 'roles/collect-logs/templates/get_host_info.sh.j2', 'roles/overcloud-ssl/templates/overcloud-create-ssl-cert.sh.j2', 'roles/overcloud-deploy/templates/overcloud-status.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e4621e8471c6fa9491f43d5b594c16983f430097', 'message': 'Fix used paths to match custom working dir\n\nStackrc is used to be referred via the working_dir path.\nFix the $HOME or /home/{{ undercloud_user }} paths, which only mathche\nthe default working dir of /home/stack.\n\nFix openssl commands to refer server-req.pem et al from the\nworking_dir instead of the current dir.\n\nAdditionally, when containerized undercloud, copy stackrc\ncreated by the tripleoclient at the UC user $HOME to the working dir,\nwhere it is expected by quickstart, if given a custom working dir.\n\nChange-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",3,594055,e4621e8471c6fa9491f43d5b594c16983f430097,79,12,8,6926,,,0,"Fix used paths to match custom working dir

Stackrc is used to be referred via the working_dir path.
Fix the $HOME or /home/{{ undercloud_user }} paths, which only mathche
the default working dir of /home/stack.

Fix openssl commands to refer server-req.pem et al from the
working_dir instead of the current dir.

Additionally, when containerized undercloud, copy stackrc
created by the tripleoclient at the UC user $HOME to the working dir,
where it is expected by quickstart, if given a custom working dir.

Change-Id: Ic5834dbf66471802eb5a9319718d3ba02548236c
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/55/594055/8 && git format-patch -1 --stdout FETCH_HEAD,['roles/overcloud-prep-images/templates/overcloud-prep-images.sh.j2'],1,9a83d36f1953029622cf339b9bd0c7938156f43e,localcon, timeout $1 bash -c -- 'source {{ working_dir }}/stackrc; \, timeout $1 bash -c -- 'source $HOME/stackrc; \,1,1
openstack%2Fopenstack-zuul-jobs~master~I8fb8a3720a92bd83e1b63a62cab398ee743dc917,openstack/openstack-zuul-jobs,master,I8fb8a3720a92bd83e1b63a62cab398ee743dc917,Remove tricircle dsvm jobs,MERGED,2018-09-26 07:19:50.000000000,2018-09-27 07:49:10.000000000,2018-09-27 07:49:10.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 07:19:50.000000000', 'files': ['playbooks/legacy/tricircle-dsvm-functional/post.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/tricircle-dsvm-multiregion/run.yaml', 'playbooks/legacy/tricircle-dsvm-functional/run.yaml', 'playbooks/legacy/tricircle-dsvm-multiregion/post.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/13ba243236106ab7f58da3d8b778044f53e45dea', 'message': 'Remove tricircle dsvm jobs\n\nThese jobs are now in-tree, remove them here.\n\nChange-Id: I8fb8a3720a92bd83e1b63a62cab398ee743dc917\n'}]",0,605344,13ba243236106ab7f58da3d8b778044f53e45dea,7,3,1,6547,,,0,"Remove tricircle dsvm jobs

These jobs are now in-tree, remove them here.

Change-Id: I8fb8a3720a92bd83e1b63a62cab398ee743dc917
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/44/605344/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/tricircle-dsvm-functional/post.yaml', 'zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/tricircle-dsvm-multiregion/run.yaml', 'playbooks/legacy/tricircle-dsvm-functional/run.yaml', 'playbooks/legacy/tricircle-dsvm-multiregion/post.yaml']",5,13ba243236106ab7f58da3d8b778044f53e45dea,tricircle,,- hosts: primary tasks: - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*nose_results.html - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testr_results.html.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.testrepository/tmp* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=**/*testrepository.subunit.gz - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}/tox' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/.tox/*/log/* - --include=*/ - --exclude=* - --prune-empty-dirs - name: Copy files from {{ ansible_user_dir }}/workspace/ on node synchronize: src: '{{ ansible_user_dir }}/workspace/' dest: '{{ zuul.executor.log_root }}' mode: pull copy_links: true verify_host: true rsync_opts: - --include=/logs/** - --include=*/ - --exclude=* - --prune-empty-dirs ,0,318
openstack%2Ftripleo-heat-templates~master~I17c12124790f2fe1b3edf3312a741eff5366a850,openstack/tripleo-heat-templates,master,I17c12124790f2fe1b3edf3312a741eff5366a850,Fix typo in upgrade package ansible resource name.,ABANDONED,2018-09-13 17:13:26.000000000,2018-09-27 07:43:58.000000000,,"[{'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 8297}, {'_account_id': 8449}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-13 17:13:26.000000000', 'files': ['puppet/services/tripleo-packages.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/15fc57e665f9b53daf2fbde7962a9851f1e701d8', 'message': 'Fix typo in upgrade package ansible resource name.\n\nAll is in $title.\n\nChange-Id: I17c12124790f2fe1b3edf3312a741eff5366a850\n'}]",0,602399,15fc57e665f9b53daf2fbde7962a9851f1e701d8,13,7,1,8297,,,0,"Fix typo in upgrade package ansible resource name.

All is in $title.

Change-Id: I17c12124790f2fe1b3edf3312a741eff5366a850
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/99/602399/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/tripleo-packages.yaml'],1,15fc57e665f9b53daf2fbde7962a9851f1e701d8,, package: name=* state=latest, pacakge: name=* state=latest,1,1
openstack%2Fcinder~master~I507d7a552c713b097cbcee1598757f53d70f0b4d,openstack/cinder,master,I507d7a552c713b097cbcee1598757f53d70f0b4d,Add an instance-uuid check on attachment_reserve,MERGED,2017-05-30 21:11:46.000000000,2018-09-27 07:43:53.000000000,2017-05-31 14:50:10.000000000,"[{'_account_id': 3}, {'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9562}, {'_account_id': 15831}, {'_account_id': 16595}, {'_account_id': 21976}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24815}]","[{'number': 1, 'created': '2017-05-30 21:11:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d4806d4329e15c03574b0a7e4e838b685e5d9dc0', 'message': ""Add an instance-uuid check on attachment_reserve\n\nCurrently the new cinder attachment_create method only allows creating\nattachments for volumes that are in available or downloading state. We\nintend to allow multiple attachments when multi-attach is ready to\nland and then manage everything off of attachment-id's, but for now\nwe're not enabling that.\n\nIn order to allow Nova to continue to do things like live-migration\nwhich is really a special case of multi-attach we'll add an instance\nuuid check that allows this flow to continue until we fully turn on\nmulti-attach.\n\nJust check on the _attachment_reserve, if there's a n instance_uuid\nspecified, and it matches the existing attachments ignore the status\ncheck failure.\n\nChange-Id: I507d7a552c713b097cbcee1598757f53d70f0b4d\nCloses-Bug: #1694530\n""}, {'number': 2, 'created': '2017-05-30 21:30:09.000000000', 'files': ['cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/220dafc65cdffaefa867380a476aa7fcd55268c4', 'message': ""Add an instance-uuid check on attachment_reserve\n\nCurrently the new cinder attachment_create method only allows creating\nattachments for volumes that are in available or downloading state. We\nintend to allow multiple attachments when multi-attach is ready to\nland and then manage everything off of attachment-id's, but for now\nwe're not enabling that.\n\nIn order to allow Nova to continue to do things like live-migration\nwhich is really a special case of multi-attach we'll add an instance\nuuid check that allows this flow to continue until we fully turn on\nmulti-attach.\n\nJust check on the _attachment_reserve, if there's an instance_uuid\nspecified, and it matches the existing attachments ignore the status\ncheck failure.\n\nChange-Id: I507d7a552c713b097cbcee1598757f53d70f0b4d\nCloses-Bug: #1694530\n""}]",4,469252,220dafc65cdffaefa867380a476aa7fcd55268c4,36,10,2,2243,,,0,"Add an instance-uuid check on attachment_reserve

Currently the new cinder attachment_create method only allows creating
attachments for volumes that are in available or downloading state. We
intend to allow multiple attachments when multi-attach is ready to
land and then manage everything off of attachment-id's, but for now
we're not enabling that.

In order to allow Nova to continue to do things like live-migration
which is really a special case of multi-attach we'll add an instance
uuid check that allows this flow to continue until we fully turn on
multi-attach.

Just check on the _attachment_reserve, if there's an instance_uuid
specified, and it matches the existing attachments ignore the status
check failure.

Change-Id: I507d7a552c713b097cbcee1598757f53d70f0b4d
Closes-Bug: #1694530
",git fetch https://review.opendev.org/openstack/cinder refs/changes/52/469252/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/attachments/test_attachments_api.py', 'cinder/volume/api.py']",2,d4806d4329e15c03574b0a7e4e838b685e5d9dc0,bug/1694530," if not result: # Make sure we're not going to the same instance, in which case # it could be a live-migrate or similar scenario (LP BUG: 1694530) override = False if instance_uuid: override = True for attachment in vref.volume_attachment: if attachment.instance_uuid != instance_uuid: override = False break if not override: msg = (_('Volume %(vol_id)s status must be %(statuses)s') % {'vol_id': vref.id, 'statuses': utils.build_or_str(expected['status'])}) raise exception.InvalidVolume(reason=msg)"," if not result: msg = (_('Volume %(vol_id)s status must be %(statuses)s') % {'vol_id': vref.id, 'statuses': utils.build_or_str(expected['status'])}) raise exception.InvalidVolume(reason=msg)",45,4
openstack%2Ftripleo-common~stable%2Fqueens~I14f0f778d21b0d2a27d6e02468dac2cc1c8f25f7,openstack/tripleo-common,stable/queens,I14f0f778d21b0d2a27d6e02468dac2cc1c8f25f7,Disable external plugins in rabbitmq container,MERGED,2018-09-09 13:47:28.000000000,2018-09-27 07:37:09.000000000,2018-09-27 07:37:09.000000000,"[{'_account_id': 13039}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-09 13:47:28.000000000', 'files': ['container-images/tripleo_kolla_template_overrides.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/573b22b81f449d414dcfcef50245c67d1853c877', 'message': 'Disable external plugins in rabbitmq container\n\nWe are doing this in the rabbit kolla container in tripleo:\n{% block rabbitmq_install_plugins %}\n\nRUN rm -rf /var/lib/rabbitmq/* \\\n    && ln -s /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.* /usr/lib/rabbitmq/lib/rabbitmq_server-3.6 \\\n    && curl -o /usr/lib/rabbitmq/lib/rabbitmq_server-3.6/plugins/rabbitmq_clusterer-3.6.x-667f92b0.ez http://www.rabbitmq.com/community-plugins/v3.6.x/rabbitmq_clusterer-3.6.x-667f92b0.ez \\\n    && /usr/lib/rabbitmq/bin/rabbitmq-plugins enable --offline \\\n       rabbitmq_management \\\n       rabbitmq_clusterer\n\n{% endblock %}\n\nWe should disable this as:\na) this is unwanted\nb) we want to use only plugins shipped with rpm\nc) we do not use those two plugins anyway\n\nWe do this by simply overriding the ""rabbitmq_install_plugins"" to a\ncomment.\n\nChange-Id: I14f0f778d21b0d2a27d6e02468dac2cc1c8f25f7\nCloses-Bug: #1791077\n(cherry picked from commit 699d5002ccf43f8f20594116b9e5e0ea3b2d6d18)\n'}]",0,601075,573b22b81f449d414dcfcef50245c67d1853c877,31,4,1,20172,,,0,"Disable external plugins in rabbitmq container

We are doing this in the rabbit kolla container in tripleo:
{% block rabbitmq_install_plugins %}

RUN rm -rf /var/lib/rabbitmq/* \
    && ln -s /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.* /usr/lib/rabbitmq/lib/rabbitmq_server-3.6 \
    && curl -o /usr/lib/rabbitmq/lib/rabbitmq_server-3.6/plugins/rabbitmq_clusterer-3.6.x-667f92b0.ez http://www.rabbitmq.com/community-plugins/v3.6.x/rabbitmq_clusterer-3.6.x-667f92b0.ez \
    && /usr/lib/rabbitmq/bin/rabbitmq-plugins enable --offline \
       rabbitmq_management \
       rabbitmq_clusterer

{% endblock %}

We should disable this as:
a) this is unwanted
b) we want to use only plugins shipped with rpm
c) we do not use those two plugins anyway

We do this by simply overriding the ""rabbitmq_install_plugins"" to a
comment.

Change-Id: I14f0f778d21b0d2a27d6e02468dac2cc1c8f25f7
Closes-Bug: #1791077
(cherry picked from commit 699d5002ccf43f8f20594116b9e5e0ea3b2d6d18)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/75/601075/1 && git format-patch -1 --stdout FETCH_HEAD,['container-images/tripleo_kolla_template_overrides.j2'],1,573b22b81f449d414dcfcef50245c67d1853c877,bug/1791077,{% block rabbitmq_install_plugins %} # External rabbitmq plugins installation is disabled {% endblock %} ,,4,0
openstack%2Ftripleo-heat-templates~master~I8cada7be57cd50c54ca5f2f38ec010062512ae06,openstack/tripleo-heat-templates,master,I8cada7be57cd50c54ca5f2f38ec010062512ae06,Undercloud - Restart keepalived on update,MERGED,2018-09-19 08:06:58.000000000,2018-09-27 07:34:44.000000000,2018-09-27 04:07:03.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 17823}, {'_account_id': 20172}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2018-09-19 08:06:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ea73b3e697cdc16b9827bd05739175ca4a309f00', 'message': ""Undercloud - Restart keepalived on update\n\ninstack-undercloud had a workaround (30-reload-keepalived)\nin place to always restart keepalived on install/upgrade.\nThis is required to ensure VIP's are present in case the\nnetwork config was changed and os-net-config restarts\nthe network interface. When containerizing the undercloud\nthis workaround was missed.\n\nThis change adds a similar workaround. A pre_deploy\nNodeExtraconfig script will restart the keepalived\ncontainer when the undercloud installer is (re-)run.\n\nNOTE: We can remove this workaround once keepalived\n      v2.0.6 or later is available.\n\nCloses-Bug: #1791238\nChange-Id: I8cada7be57cd50c54ca5f2f38ec010062512ae06\n""}, {'number': 2, 'created': '2018-09-24 15:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/68772ffcbda4b620133ed84d8848b34e4cf1895c', 'message': ""Undercloud - Restart keepalived on update\n\ninstack-undercloud had a workaround (30-reload-keepalived)\nin place to always restart keepalived on install/upgrade.\nThis is required to ensure VIP's are present in case the\nnetwork config was changed and os-net-config restarts\nthe network interface. When containerizing the undercloud\nthis workaround was missed.\n\nThis change adds a similar workaround. A pre_deploy\nNodeExtraconfig script will restart the keepalived\ncontainer when the undercloud installer is (re-)run.\n\nNOTE: We can remove this workaround once keepalived\n      v2.0.6 or later is available.\n\nCloses-Bug: #1791238\nChange-Id: I8cada7be57cd50c54ca5f2f38ec010062512ae06\n""}, {'number': 3, 'created': '2018-09-24 21:02:47.000000000', 'files': ['environments/undercloud.yaml', 'extraconfig/pre_deploy/undercloud_pre.yaml', 'extraconfig/pre_deploy/undercloud_pre.sh', 'releasenotes/notes/fix-contiainer-underloud-keepalived-needs-restart-6d7efbb9788e0f95.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b766e253f4df4bb61247640850c3490b988c36d0', 'message': ""Undercloud - Restart keepalived on update\n\ninstack-undercloud had a workaround (30-reload-keepalived)\nin place to always restart keepalived on install/upgrade.\nThis is required to ensure VIP's are present in case the\nnetwork config was changed and os-net-config restarts\nthe network interface. When containerizing the undercloud\nthis workaround was missed.\n\nThis change adds a similar workaround. A pre_deploy\nNodeExtraconfig script will restart the keepalived\ncontainer when the undercloud installer is (re-)run.\n\nNOTE: We can remove this workaround once keepalived\n      v2.0.6 or later is available.\n\nCloses-Bug: #1791238\nChange-Id: I8cada7be57cd50c54ca5f2f38ec010062512ae06\n""}]",2,603587,b766e253f4df4bb61247640850c3490b988c36d0,28,8,3,24245,,,0,"Undercloud - Restart keepalived on update

instack-undercloud had a workaround (30-reload-keepalived)
in place to always restart keepalived on install/upgrade.
This is required to ensure VIP's are present in case the
network config was changed and os-net-config restarts
the network interface. When containerizing the undercloud
this workaround was missed.

This change adds a similar workaround. A pre_deploy
NodeExtraconfig script will restart the keepalived
container when the undercloud installer is (re-)run.

NOTE: We can remove this workaround once keepalived
      v2.0.6 or later is available.

Closes-Bug: #1791238
Change-Id: I8cada7be57cd50c54ca5f2f38ec010062512ae06
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/87/603587/3 && git format-patch -1 --stdout FETCH_HEAD,"['environments/undercloud.yaml', 'extraconfig/pre_deploy/undercloud_pre.yaml', 'extraconfig/pre_deploy/undercloud_pre.sh', 'releasenotes/notes/fix-contiainer-underloud-keepalived-needs-restart-6d7efbb9788e0f95.yaml']",4,ea73b3e697cdc16b9827bd05739175ca4a309f00,bug/1791238,--- fixes: - | An issue causing undercloud installer re-run (or update) to fail because VIP's where lost in case the networking configuration was changed has been fixed. See `Bug: 1791238 <https://bugs.launchpad.net/tripleo/+bug/1791238>`_. ,,39,0
openstack%2Fneutron-lbaas-dashboard~master~Ic57c4da8eae59e7025dade3d5619a05938e72f9e,openstack/neutron-lbaas-dashboard,master,Ic57c4da8eae59e7025dade3d5619a05938e72f9e,Imported Translations from Zanata,MERGED,2018-09-23 07:56:28.000000000,2018-09-27 07:16:40.000000000,2018-09-27 07:16:40.000000000,"[{'_account_id': 2245}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-23 07:56:28.000000000', 'files': ['neutron_lbaas_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas-dashboard/commit/b0102599a14e5dfe30087a574d73ee488102320e', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Ic57c4da8eae59e7025dade3d5619a05938e72f9e\n'}]",0,604579,b0102599a14e5dfe30087a574d73ee488102320e,8,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Ic57c4da8eae59e7025dade3d5619a05938e72f9e
",git fetch https://review.opendev.org/openstack/neutron-lbaas-dashboard refs/changes/79/604579/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron_lbaas_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po'],1,b0102599a14e5dfe30087a574d73ee488102320e,zanata/translations,"# Soonyeul Park <ardentpark@gmail.com>, 2018. #zanata""POT-Creation-Date: 2018-09-21 03:22+0000\n""""PO-Revision-Date: 2018-09-22 08:01+0000\n"" ""Last-Translator: Soonyeul Park <ardentpark@gmail.com>\n""msgid ""Floating IP address or pool"" msgstr "" IP  "" ","""POT-Creation-Date: 2018-08-25 00:47+0000\n""""PO-Revision-Date: 2018-08-31 10:41+0000\n"" ""Last-Translator: ByungYeol Woo <wby1089@gmail.com>\n""",7,3
openstack%2Fnetworking-bgpvpn~master~I27fd4d41fa66924507d58a980813d150b5299e1b,openstack/networking-bgpvpn,master,I27fd4d41fa66924507d58a980813d150b5299e1b,add local tox targets for pep8 and py3,MERGED,2018-09-20 20:11:15.000000000,2018-09-27 07:15:17.000000000,2018-09-27 07:15:16.000000000,"[{'_account_id': 55}, {'_account_id': 2888}, {'_account_id': 5367}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-20 20:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/6b2499494b34091dc429f434c783f06bb1c64915', 'message': 'add local tox targets for pep8 and py3\n\nThis patch adds local tox targets for pep8 and python 3 as per [1]\nthat will install dependencies in editable mode.\nTo run them use the pep8-dev and py3-dev targets respectively.\n\n[1] https://etherpad.openstack.org/p/neutron-sibling-setup\n\nChange-Id: I27fd4d41fa66924507d58a980813d150b5299e1b\n'}, {'number': 2, 'created': '2018-09-24 16:04:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/60bc3092161f7deaf7f7e77637d73a68a774cddd', 'message': 'add local tox targets for pep8 and py3\n\nThis patch adds local tox targets for pep8 and python 3 as per [1]\nthat will install dependencies in editable mode.\nTo run them use the pep8-dev and py3-dev targets respectively.\n\n[1] https://etherpad.openstack.org/p/neutron-sibling-setup\n\nChange-Id: I27fd4d41fa66924507d58a980813d150b5299e1b\n'}, {'number': 3, 'created': '2018-09-26 13:44:59.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/networking-bgpvpn/commit/c33002f62defeed8384614787bb3e266cf9b5624', 'message': 'add local tox targets for pep8 and py3\n\nThis patch adds local tox targets for pep8 and python 3 as per [1]\nthat will install dependencies in editable mode.\nTo run them use the pep8-dev and py3-dev targets respectively.\n\n[1] https://etherpad.openstack.org/p/neutron-sibling-setup\n\nChange-Id: I27fd4d41fa66924507d58a980813d150b5299e1b\n'}]",5,604206,c33002f62defeed8384614787bb3e266cf9b5624,15,5,3,5367,,,0,"add local tox targets for pep8 and py3

This patch adds local tox targets for pep8 and python 3 as per [1]
that will install dependencies in editable mode.
To run them use the pep8-dev and py3-dev targets respectively.

[1] https://etherpad.openstack.org/p/neutron-sibling-setup

Change-Id: I27fd4d41fa66924507d58a980813d150b5299e1b
",git fetch https://review.opendev.org/openstack/networking-bgpvpn refs/changes/06/604206/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,6b2499494b34091dc429f434c783f06bb1c64915,neutronlib-zuulv3," [testenv:dev] # run locally (not in the gate) using editable mode # https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs # note that order is important to ensure dependencies don't override commands = pip install -q -e ""git+https://git.openstack.org/openstack/networking-bagpipe#egg=networking_bagpipe"" pip install -q -e ""git+https://git.openstack.org/openstack/neutron#egg=neutron"" [testenv:py3-dev] basepython = python3 commands = {[testenv:dev]commands} pip freeze stestr run {posargs} whitelist_externals = stestr [testenv:pep8-dev] deps = {[testenv]deps} commands = {[testenv:dev]commands} flake8 flake8 doc/source/samples pylint --version pylint --rcfile=.pylintrc --output-format=colorized {posargs:networking_bgpvpn} pylint --rcfile=.pylintrc --output-format=colorized doc/source/samples neutron-db-manage --subproject networking-bgpvpn --database-connection sqlite:// check_migration {[testenv:genconfig]commands}",,30,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I4040c7cc004e8ee81355bbae6ccc1a0a4dfd0822,openstack/tripleo-heat-templates,stable/queens,I4040c7cc004e8ee81355bbae6ccc1a0a4dfd0822,Fix syntax for set_fact ansible task.,MERGED,2018-09-24 12:02:50.000000000,2018-09-27 07:10:40.000000000,2018-09-27 07:10:40.000000000,"[{'_account_id': 8042}, {'_account_id': 20172}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 12:02:50.000000000', 'files': ['docker/services/pacemaker/haproxy.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9c337f00519bf9a0b28313843a87007bdabcdda2', 'message': 'Fix syntax for set_fact ansible task.\n\nError in ansible task causes upgrade job to fail:\ntripleo-ci-centos-7-scenario000-multinode-oooq-container-upgrades\n\nCloses-Bug: 1778455\n\nChange-Id: I4040c7cc004e8ee81355bbae6ccc1a0a4dfd0822\n(cherry picked from commit ed26bd71655a9c63073e45d876c3d194c6ca9e8a)\n'}]",0,604752,9c337f00519bf9a0b28313843a87007bdabcdda2,13,5,1,8042,,,0,"Fix syntax for set_fact ansible task.

Error in ansible task causes upgrade job to fail:
tripleo-ci-centos-7-scenario000-multinode-oooq-container-upgrades

Closes-Bug: 1778455

Change-Id: I4040c7cc004e8ee81355bbae6ccc1a0a4dfd0822
(cherry picked from commit ed26bd71655a9c63073e45d876c3d194c6ca9e8a)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/52/604752/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/pacemaker/haproxy.yaml'],1,9c337f00519bf9a0b28313843a87007bdabcdda2,bug/1778455-stable/queens," set_fact: haproxy_pcs_res: ""{{haproxy_pcs_res_result|succeeded}}"""," set_fact: ""{{haproxy_pcs_res_result|succeeded}}""",2,1
openstack%2Ftripleo-heat-templates~master~I0ce91ed9132afe305c60036837c702c2611fa7c2,openstack/tripleo-heat-templates,master,I0ce91ed9132afe305c60036837c702c2611fa7c2,Add ERL args parameter for rabbit and set the busy wait threshold to none,MERGED,2018-09-12 16:21:35.000000000,2018-09-27 07:10:38.000000000,2018-09-27 07:10:38.000000000,"[{'_account_id': 8042}, {'_account_id': 8871}, {'_account_id': 9257}, {'_account_id': 10873}, {'_account_id': 15206}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-12 16:21:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6c858030644f92455b28f4fa7b9e83180f3553d4', 'message': 'WIP Additional ERL args for rabbit parameter\n\nAdditional argument to be able to customize the ERL command line\narguments\n\nChange-Id: I0ce91ed9132afe305c60036837c702c2611fa7c2\n'}, {'number': 2, 'created': '2018-09-12 18:04:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6d6319d45edb16f1529093821024f0fea76c60cf', 'message': 'WIP Additional ERL args for rabbit parameter\n\nAdditional argument to be able to customize the ERL command line\narguments\n\nChange-Id: I0ce91ed9132afe305c60036837c702c2611fa7c2\n'}, {'number': 3, 'created': '2018-09-12 20:10:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/394dce0a08e2d80b7e24d152457a1785f84dead2', 'message': 'Additional ERL args for rabbit parameters\n\nAdditional argument to be able to customize the ERL command line\narguments. This allows the operator to specify some arguments to the\nErlang VM. For example, it would be possible to pass:\nparameter_defaults:\n    RabbitAdditionalErlArgs: ""\'+sbwt none\'""\n\nWhich would then set the scheduler busy wait threshold to none:\nroot         346  0.0  0.0  11680  1468 ?        S    18:29   0:00  \\_ /bin/sh /usr/sbin/rabbitmq-server\nroot         367  0.0  0.0  81940  2060 ?        S    18:29   0:00      \\_ su rabbitmq -s /bin/sh -c /usr/lib/rabbitmq/bin/rabbitmq-server\nrabbitmq     372  0.0  0.0   9672  1520 ?        Ss   18:29   0:00          \\_ /bin/sh /usr/lib/rabbitmq/bin/rabbitmq-server\nrabbitmq     561  2.6  0.5 2365936 122036 ?      Sl   18:29   1:04              \\_ /usr/lib64/erlang/erts-7.3.1.4/bin/beam.smp -W w -A 64 -K true -P 1048576 -K true -sbwt none -B i -- -root /usr/lib64/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/ebin -noshell -noinput -s rabbit boot -sname rabbit@controller-0 -boot start_sasl -config /etc/rabbitmq/rabbitmq -kernel inet_default_connect_options [{nodelay,true}] -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,""/var/log/rabbitmq/rabbit@controller-0.log""} -rabbit sasl_error_logger {file,""/var/log/rabbitmq/rabbit@controller-0-sasl.log""} -rabbit enabled_plugins_file ""/etc/rabbitmq/enabled_plugins"" -rabbit plugins_dir ""/usr/lib/rabbitmq/plugins:/usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/plugins"" -rabbit plugins_expand_dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0-plugins-expand"" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0""\nrabbitmq     703  0.0  0.0  11588   448 ?        Ss   18:29   0:00                  \\_ inet_gethost 4\nrabbitmq     704  0.0  0.0  13712   708 ?        S    18:29   0:00                      \\_ inet_gethost 4\n\nChange-Id: I0ce91ed9132afe305c60036837c702c2611fa7c2\n'}, {'number': 4, 'created': '2018-09-17 16:05:23.000000000', 'files': ['puppet/services/rabbitmq.yaml', 'releasenotes/notes/rabbitmq-erl-args-9029cf4605d63dd9.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06b66a8094b2ab0be844d4bd1996d760a27e0b2b', 'message': 'Add ERL args parameter for rabbit and set the busy wait threshold to none\n\nAdditional argument to be able to customize the ERL command line\narguments. This allows the operator to specify some arguments to the\nErlang VM. By default we are now passing \'+sbwt none\' to set the\nthe erlang scheduler busy wait threshold. This threshold determines how\nlong schedulers are to busy wait when running out of work before going\nto sleep. On most of our deployments where rabbitmq shares a node with\na lot of other services it makes little sense to busy wait when out of\nwork in order to improve latency as other processes are more likely to\nfail to do work due to CPUs being overused by rabbit,\n\nWe have measured a three-fold reduction of CPU usage with this option\nwith no other observable impact.\n\nWe can observe the change in the beam.smp params:\nroot         346  0.0  0.0  11680  1468 ?        S    18:29   0:00  \\_ /bin/sh /usr/sbin/rabbitmq-server\nroot         367  0.0  0.0  81940  2060 ?        S    18:29   0:00      \\_ su rabbitmq -s /bin/sh -c /usr/lib/rabbitmq/bin/rabbitmq-server\nrabbitmq     372  0.0  0.0   9672  1520 ?        Ss   18:29   0:00          \\_ /bin/sh /usr/lib/rabbitmq/bin/rabbitmq-server\nrabbitmq     561  2.6  0.5 2365936 122036 ?      Sl   18:29   1:04              \\_ /usr/lib64/erlang/erts-7.3.1.4/bin/beam.smp -W w -A 64 -K true -P 1048576 -K true -sbwt none -B i -- -root /usr/lib64/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/ebin -noshell -noinput -s rabbit boot -sname rabbit@controller-0 -boot start_sasl -config /etc/rabbitmq/rabbitmq -kernel inet_default_connect_options [{nodelay,true}] -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,""/var/log/rabbitmq/rabbit@controller-0.log""} -rabbit sasl_error_logger {file,""/var/log/rabbitmq/rabbit@controller-0-sasl.log""} -rabbit enabled_plugins_file ""/etc/rabbitmq/enabled_plugins"" -rabbit plugins_dir ""/usr/lib/rabbitmq/plugins:/usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/plugins"" -rabbit plugins_expand_dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0-plugins-expand"" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0""\nrabbitmq     703  0.0  0.0  11588   448 ?        Ss   18:29   0:00                  \\_ inet_gethost 4\nrabbitmq     704  0.0  0.0  13712   708 ?        S    18:29   0:00                      \\_ inet_gethost 4\n\nChange-Id: I0ce91ed9132afe305c60036837c702c2611fa7c2\n'}]",0,602082,06b66a8094b2ab0be844d4bd1996d760a27e0b2b,39,8,4,20172,,,0,"Add ERL args parameter for rabbit and set the busy wait threshold to none

Additional argument to be able to customize the ERL command line
arguments. This allows the operator to specify some arguments to the
Erlang VM. By default we are now passing '+sbwt none' to set the
the erlang scheduler busy wait threshold. This threshold determines how
long schedulers are to busy wait when running out of work before going
to sleep. On most of our deployments where rabbitmq shares a node with
a lot of other services it makes little sense to busy wait when out of
work in order to improve latency as other processes are more likely to
fail to do work due to CPUs being overused by rabbit,

We have measured a three-fold reduction of CPU usage with this option
with no other observable impact.

We can observe the change in the beam.smp params:
root         346  0.0  0.0  11680  1468 ?        S    18:29   0:00  \_ /bin/sh /usr/sbin/rabbitmq-server
root         367  0.0  0.0  81940  2060 ?        S    18:29   0:00      \_ su rabbitmq -s /bin/sh -c /usr/lib/rabbitmq/bin/rabbitmq-server
rabbitmq     372  0.0  0.0   9672  1520 ?        Ss   18:29   0:00          \_ /bin/sh /usr/lib/rabbitmq/bin/rabbitmq-server
rabbitmq     561  2.6  0.5 2365936 122036 ?      Sl   18:29   1:04              \_ /usr/lib64/erlang/erts-7.3.1.4/bin/beam.smp -W w -A 64 -K true -P 1048576 -K true -sbwt none -B i -- -root /usr/lib64/erlang -progname erl -- -home /var/lib/rabbitmq -- -pa /usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/ebin -noshell -noinput -s rabbit boot -sname rabbit@controller-0 -boot start_sasl -config /etc/rabbitmq/rabbitmq -kernel inet_default_connect_options [{nodelay,true}] -kernel inet_default_connect_options [{nodelay,true}] -sasl errlog_type error -sasl sasl_error_logger false -rabbit error_logger {file,""/var/log/rabbitmq/rabbit@controller-0.log""} -rabbit sasl_error_logger {file,""/var/log/rabbitmq/rabbit@controller-0-sasl.log""} -rabbit enabled_plugins_file ""/etc/rabbitmq/enabled_plugins"" -rabbit plugins_dir ""/usr/lib/rabbitmq/plugins:/usr/lib/rabbitmq/lib/rabbitmq_server-3.6.15/plugins"" -rabbit plugins_expand_dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0-plugins-expand"" -os_mon start_cpu_sup false -os_mon start_disksup false -os_mon start_memsup false -mnesia dir ""/var/lib/rabbitmq/mnesia/rabbit@controller-0""
rabbitmq     703  0.0  0.0  11588   448 ?        Ss   18:29   0:00                  \_ inet_gethost 4
rabbitmq     704  0.0  0.0  13712   708 ?        S    18:29   0:00                      \_ inet_gethost 4

Change-Id: I0ce91ed9132afe305c60036837c702c2611fa7c2
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/82/602082/3 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/rabbitmq.yaml'],1,6c858030644f92455b28f4fa7b9e83180f3553d4,rabbitmq-sbwt, RabbitAdditionalErlArgs: description: Additional parameters passed to the Erlang subsystem. defaut: '' type: string RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: {get_param: RabbitAdditionalErlArgs},,6,0
openstack%2Fswift~master~I852d83e477243f70ae7c1896102510455a7cb124,openstack/swift,master,I852d83e477243f70ae7c1896102510455a7cb124,Enable FakeConn to handle multiple requests/responses,NEW,2018-06-29 17:02:32.000000000,2018-09-27 06:54:14.000000000,,"[{'_account_id': 597}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-06-29 17:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/67c0fc210b1816f3327114c9cbcc0feb866e6e68', 'message': 'Enable FakeConn to capture multiple requests\n\n... which is needed to test the object server PUT+POST protocol\nwhere more than one request is sent on same connection.\n\nChange-Id: I852d83e477243f70ae7c1896102510455a7cb124\n'}, {'number': 2, 'created': '2018-07-02 18:23:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/3b2ca055647b4f7b3ee60439ecd90a0a8584f9ea', 'message': 'Enable FakeConn to handle multiple requests/responses\n\n... which is needed to test the object server PUT+POST protocol\nwhere more than one request is sent on same connection.\n\nChange-Id: I852d83e477243f70ae7c1896102510455a7cb124\n'}, {'number': 3, 'created': '2018-07-02 18:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e88b262ca5b5f3cfb14933a42a21240dbbe764fe', 'message': 'Enable FakeConn to handle multiple requests/responses\n\n... which is needed to test the object server PUT+POST protocol\nwhere more than one request is sent on same connection.\n\nChange-Id: I852d83e477243f70ae7c1896102510455a7cb124\n'}, {'number': 4, 'created': '2018-07-05 17:10:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/eefd06ab6cd542555723d1b41805e2ba34626e43', 'message': 'Enable FakeConn to handle multiple requests/responses\n\n... which is needed to test the object server PUT+POST protocol\nwhere more than one request is sent on same connection.\n\nChange-Id: I852d83e477243f70ae7c1896102510455a7cb124\n'}, {'number': 5, 'created': '2018-09-27 02:34:07.000000000', 'files': ['test/unit/__init__.py', 'test/unit/proxy/controllers/test_obj.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/1abd981f3e9f6af5865b60a15e40aaba089267e9', 'message': 'Enable FakeConn to handle multiple requests/responses\n\n... which is needed to test the object server PUT+POST protocol\nwhere more than one request is sent on same connection.\n\nChange-Id: I852d83e477243f70ae7c1896102510455a7cb124\n'}]",1,579228,1abd981f3e9f6af5865b60a15e40aaba089267e9,11,2,5,7847,,,0,"Enable FakeConn to handle multiple requests/responses

... which is needed to test the object server PUT+POST protocol
where more than one request is sent on same connection.

Change-Id: I852d83e477243f70ae7c1896102510455a7cb124
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/579228/4 && git format-patch -1 --stdout FETCH_HEAD,['test/unit/__init__.py'],1,67c0fc210b1816f3327114c9cbcc0feb866e6e68,p-put-post/better_test_2," self.requests = [] def putrequest(self, method, url, skip_host=0, skip_accept_encoding=0): # collect requests so they are available for inspection self.requests.append({'method': method, 'url': url, 'headers': {}}) def putheader(self, header, value): self.requests[-1]['headers'][header] = value def endheaders(self, message_body=None): pass resp_headers = next(headers_iter) # connect() is used to mock both http_connect and http_connect_raw (!) # so alter arg mapping accordingly if kwargs.get('mocked_function') == 'http_connect_raw': method_arg_position = 2 else: method_arg_position = 4 method, path = args[method_arg_position:method_arg_position + 2] if len(args) > method_arg_position + 2: req_headers = args[method_arg_position + 2] else: req_headers = ckwargs.get('headers') fake_conn = None try: fake_conn = FakeConn(status, etag, path=path, body=body, timestamp=timestamp, headers=resp_headers, expect_headers=expect_headers, connection_id=i, give_send=kwargs.get('give_send'), give_expect=kwargs.get('give_expect')) # set initial request in the fake connection, similar to what # http_connect_raw would do fake_conn.putrequest(method, path) if req_headers: for k, v in req_headers.items(): fake_conn.putheader(k, v) fake_conn.endheaders() finally: # A FakeStatus may raise an exception during the FakeConn.__init__ # but we always want to call give_connect... if 'give_connect' in kwargs: give_conn_fn = kwargs['give_connect'] argspec = inspect.getargspec(give_conn_fn) if argspec.keywords or 'connection_id' in argspec.args: ckwargs['connection_id'] = i if argspec.keywords or 'connection' in argspec.args: ckwargs['connection'] = fake_conn give_conn_fn(*args, **ckwargs) return fake_conn def capture_requests(ip, port, method, path, headers, qs, ssl, connection_id=None, connection=None): 'connection': connection, 'connection_id': connection_id, # pass hint to fake_http_connect to modify connect() arg parsing kwargs['mocked_function'] = 'http_connect_raw'"," if 'give_connect' in kwargs: give_conn_fn = kwargs['give_connect'] argspec = inspect.getargspec(give_conn_fn) if argspec.keywords or 'connection_id' in argspec.args: ckwargs['connection_id'] = i give_conn_fn(*args, **ckwargs) headers = next(headers_iter) return FakeConn(status, etag, path=args[5], body=body, timestamp=timestamp, headers=headers, expect_headers=expect_headers, connection_id=i, give_send=kwargs.get('give_send'), give_expect=kwargs.get('give_expect')) def capture_requests(ip, port, method, path, headers, qs, ssl):",60,13
openstack%2Ftempest~master~I433c78821185600a230803cddec54a5d264c2ca5,openstack/tempest,master,I433c78821185600a230803cddec54a5d264c2ca5,Add response schema validation for volume qos-specs,MERGED,2018-09-20 08:54:12.000000000,2018-09-27 06:45:59.000000000,2018-09-27 06:45:59.000000000,"[{'_account_id': 5803}, {'_account_id': 8871}, {'_account_id': 10385}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-09-20 08:54:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/91912a230876e41174f80f359a43483634c5c566', 'message': 'Add response schema validation for volume qos-specs\n\nThis is to add response schema validation for volume\nqos-specs.\nBesides, there are some inconsistencies in volume qos-specs api ref,\nIb5c9b3a15ee2ca40c19e7a530d1ff5351d3dcaf8 will fix them.\n\nChange-Id: I433c78821185600a230803cddec54a5d264c2ca5\npartially-implements: blueprint volume-response-schema-validation\n'}, {'number': 2, 'created': '2018-09-25 02:17:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/e733d2399e485c9f500c24405c32444f3c4e5b70', 'message': 'Add response schema validation for volume qos-specs\n\nThis is to add response schema validation for volume\nqos-specs.\nBesides, there are some inconsistencies in volume qos-specs api ref,\nIb5c9b3a15ee2ca40c19e7a530d1ff5351d3dcaf8 will fix them.\n\nChange-Id: I433c78821185600a230803cddec54a5d264c2ca5\npartially-implements: blueprint volume-response-schema-validation\n'}, {'number': 3, 'created': '2018-09-26 00:56:05.000000000', 'files': ['tempest/lib/api_schema/response/volume/qos.py', 'tempest/lib/services/volume/v3/qos_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/53d94a82b7b2d6045e9e63c62bcceab7d50bac0b', 'message': 'Add response schema validation for volume qos-specs\n\nThis is to add response schema validation for volume\nqos-specs.\nBesides, there are some inconsistencies in volume qos-specs api ref,\nIb5c9b3a15ee2ca40c19e7a530d1ff5351d3dcaf8 will fix them.\n\nChange-Id: I433c78821185600a230803cddec54a5d264c2ca5\npartially-implements: blueprint volume-response-schema-validation\n'}]",6,604019,53d94a82b7b2d6045e9e63c62bcceab7d50bac0b,22,6,3,20190,,,0,"Add response schema validation for volume qos-specs

This is to add response schema validation for volume
qos-specs.
Besides, there are some inconsistencies in volume qos-specs api ref,
Ib5c9b3a15ee2ca40c19e7a530d1ff5351d3dcaf8 will fix them.

Change-Id: I433c78821185600a230803cddec54a5d264c2ca5
partially-implements: blueprint volume-response-schema-validation
",git fetch https://review.opendev.org/openstack/tempest refs/changes/19/604019/3 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/lib/api_schema/response/volume/qos.py', 'tempest/lib/services/volume/v3/qos_client.py']",2,91912a230876e41174f80f359a43483634c5c566,bp/volume-response-schema-validation,"from tempest.lib.api_schema.response.volume import qos as schema self.validate_response(schema.show_qos, resp, body) self.validate_response(schema.delete_qos, resp, body) self.validate_response(schema.list_qos, resp, body) self.validate_response(schema.show_qos, resp, body) self.validate_response(schema.set_qos_key, resp, body) self.validate_response(schema.unset_qos_key, resp, body) self.validate_response(schema.associate_qos, resp, body) self.validate_response(schema.show_association_qos, resp, body) self.validate_response(schema.disassociate_qos, resp, body) self.validate_response(schema.disassociate_all_qos, resp, body)"," self.expected_success(200, resp.status) self.expected_success(202, resp.status) self.expected_success(200, resp.status) self.expected_success(200, resp.status) self.expected_success(200, resp.status) self.expected_success(202, resp.status) self.expected_success(202, resp.status) self.expected_success(200, resp.status) self.expected_success(202, resp.status) self.expected_success(202, resp.status)",134,10
openstack%2Fneutron~stable%2Frocky~I4336197f7e086ef474c81a708861e788f28be025,openstack/neutron,stable/rocky,I4336197f7e086ef474c81a708861e788f28be025,fix spell error,ABANDONED,2018-09-27 02:44:43.000000000,2018-09-27 06:31:45.000000000,,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 27003}]","[{'number': 1, 'created': '2018-09-27 02:44:43.000000000', 'files': ['neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6aa35851977b3b65f7c605bd1786f0f399fc4e34', 'message': 'fix spell error\n\nChange-Id: I4336197f7e086ef474c81a708861e788f28be025\n(cherry picked from commit 979de972f5e23489279ded10a442ad6ca96809d0)\n'}]",0,605572,6aa35851977b3b65f7c605bd1786f0f399fc4e34,5,3,1,22016,,,0,"fix spell error

Change-Id: I4336197f7e086ef474c81a708861e788f28be025
(cherry picked from commit 979de972f5e23489279ded10a442ad6ca96809d0)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/72/605572/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/iptables_manager.py'],1,6aa35851977b3b65f7c605bd1786f0f399fc4e34,, # want to add them if they aren't already there, # want to add them if they arent' already there,1,1
openstack%2Fnetworking-onos~master~I5a56f186af321869b2d52fb06115c12386d11b0c,openstack/networking-onos,master,I5a56f186af321869b2d52fb06115c12386d11b0c,Reflect network config changes in all-in-one script,MERGED,2018-09-19 09:28:58.000000000,2018-09-27 06:24:01.000000000,2018-09-27 06:24:01.000000000,"[{'_account_id': 22348}, {'_account_id': 25575}, {'_account_id': 26288}]","[{'number': 1, 'created': '2018-09-19 09:28:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/67ed17a5d90070defe4dc300ad50c8d31367bcff', 'message': 'Reflect network config changes in all-in-one script\n\nChange-Id: I5a56f186af321869b2d52fb06115c12386d11b0c\n'}, {'number': 2, 'created': '2018-09-27 00:53:20.000000000', 'files': ['devstack/entry_points'], 'web_link': 'https://opendev.org/openstack/networking-onos/commit/67b24755bf2ccf11f944d1dba0c3fb4ad663a6b1', 'message': 'Reflect network config changes in all-in-one script\n\nChange-Id: I5a56f186af321869b2d52fb06115c12386d11b0c\n'}]",0,603620,67b24755bf2ccf11f944d1dba0c3fb4ad663a6b1,8,3,2,25575,,,0,"Reflect network config changes in all-in-one script

Change-Id: I5a56f186af321869b2d52fb06115c12386d11b0c
",git fetch https://review.opendev.org/openstack/networking-onos refs/changes/20/603620/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/entry_points'],1,67ed17a5d90070defe4dc300ad50c8d31367bcff,network_cfg_change," echo "" \""keystoneConfig\"" : {"" >> /tmp/sona_config echo "" \""endpoint\"" : \""$HOST_IP/identity/v3\"","" >> /tmp/sona_config echo "" \""authentication\"" : {"" >> /tmp/sona_config echo "" \""version\"" : \""v3\"","" >> /tmp/sona_config echo "" \""protocol\"" : \""HTTP\"","" >> /tmp/sona_config echo "" \""project\"" : \""admin\"","" >> /tmp/sona_config echo "" \""username\"" : \""admin\"","" >> /tmp/sona_config echo "" \""password\"" : \""nova\"","" >> /tmp/sona_config echo "" \""perspective\"" : \""PUBLIC\"""" >> /tmp/sona_config echo "" } }"" >> /tmp/sona_config"," echo "" \""endpoint\"" : \""$HOST_IP\"","" >> /tmp/sona_config echo "" \""authentication\"" : {"" >> /tmp/sona_config echo "" \""version\"" : \""v3\"","" >> /tmp/sona_config echo "" \""port\"" : 80,"" >> /tmp/sona_config echo "" \""protocol\"" : \""HTTP\"","" >> /tmp/sona_config echo "" \""project\"" : \""admin\"","" >> /tmp/sona_config echo "" \""username\"" : \""admin\"","" >> /tmp/sona_config echo "" \""password\"" : \""nova\"","" >> /tmp/sona_config echo "" \""perspective\"" : \""PUBLIC\"""" >> /tmp/sona_config echo "" }"" >> /tmp/sona_config",10,10
openstack%2Fkolla~master~Ibea3498589b6c3c1512e558919c6ea00c95686cb,openstack/kolla,master,Ibea3498589b6c3c1512e558919c6ea00c95686cb,Fix ceph version in ubuntu,MERGED,2018-09-21 07:37:32.000000000,2018-09-27 06:10:53.000000000,2018-09-21 14:05:36.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 24250}]","[{'number': 1, 'created': '2018-09-21 07:37:32.000000000', 'files': ['docker/ceph/ceph-base/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/78001f06a79d3bdd52fb7e2702fa4f124b453343', 'message': ""Fix ceph version in ubuntu\n\nThe ceph version supported by kolla is now luminous, but the latest\nceph version of ubuntu's apt source is mimic, so there will be\nproblems with ceph deployment.\nThis patch solves this problem by specifying the version of the ceph\npackage installed.\n\nChange-Id: Ibea3498589b6c3c1512e558919c6ea00c95686cb\nCloses-bug: #1793667\n""}]",4,604288,78001f06a79d3bdd52fb7e2702fa4f124b453343,18,4,1,24250,,,0,"Fix ceph version in ubuntu

The ceph version supported by kolla is now luminous, but the latest
ceph version of ubuntu's apt source is mimic, so there will be
problems with ceph deployment.
This patch solves this problem by specifying the version of the ceph
package installed.

Change-Id: Ibea3498589b6c3c1512e558919c6ea00c95686cb
Closes-bug: #1793667
",git fetch https://review.opendev.org/openstack/kolla refs/changes/88/604288/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/ceph/ceph-base/Dockerfile.j2'],1,78001f06a79d3bdd52fb7e2702fa4f124b453343,bug/1793667," 'ceph=12.2.4-0ubuntu1', 'ceph-mgr=12.2.4-0ubuntu1', 'ceph-mon=12.2.4-0ubuntu1', 'ceph-osd=12.2.4-0ubuntu1', 'ceph-mds=12.2.4-0ubuntu1', 'ceph-base=12.2.4-0ubuntu1', 'ceph-common=12.2.4-0ubuntu1', 'librbd1=12.2.4-0ubuntu1', 'python-cephfs=12.2.4-0ubuntu1', 'python-rados=12.2.4-0ubuntu1', 'python-rbd=12.2.4-0ubuntu1', 'libcephfs2=12.2.4-0ubuntu1', 'librados2=12.2.4-0ubuntu1', 'libradosstriper1=12.2.4-0ubuntu1', 'radosgw=12.2.4-0ubuntu1', 'librgw2=12.2.4-0ubuntu1',"," 'ceph', 'radosgw',",16,2
openstack%2Fcinder~master~I8b4843c2e9392139b42d6e2ebd2c5e1cd09d4c7a,openstack/cinder,master,I8b4843c2e9392139b42d6e2ebd2c5e1cd09d4c7a,Fix image volume cache max size and max count limits,MERGED,2018-09-17 14:15:08.000000000,2018-09-27 06:01:10.000000000,2018-09-27 04:52:45.000000000,"[{'_account_id': 24}, {'_account_id': 5997}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12924}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21129}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-17 14:15:08.000000000', 'files': ['cinder/image/cache.py', 'cinder/tests/unit/image/test_cache.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/74249de6398dbec8592591667b83a5612bf4a969', 'message': 'Fix image volume cache max size and max count limits\n\nFix the code that enforces the image volume cache max size and max count\nlimits so that each limit functions independently from the other.\n\nThis fixes a bug where the code would function correctly when both were\nset to zero (unlimited) or when both limits were set (non-zero), but would\nmisbehave when only one limit was set and the other unlimited.\n\nCloses-Bug: #1792944\nChange-Id: I8b4843c2e9392139b42d6e2ebd2c5e1cd09d4c7a\n'}]",0,603145,74249de6398dbec8592591667b83a5612bf4a969,57,39,1,21129,,,0,"Fix image volume cache max size and max count limits

Fix the code that enforces the image volume cache max size and max count
limits so that each limit functions independently from the other.

This fixes a bug where the code would function correctly when both were
set to zero (unlimited) or when both limits were set (non-zero), but would
misbehave when only one limit was set and the other unlimited.

Closes-Bug: #1792944
Change-Id: I8b4843c2e9392139b42d6e2ebd2c5e1cd09d4c7a
",git fetch https://review.opendev.org/openstack/cinder refs/changes/45/603145/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/image/cache.py', 'cinder/tests/unit/image/test_cache.py']",2,74249de6398dbec8592591667b83a5612bf4a969,bug/1792944," cache = self._build_cache(max_gb=30, max_count=0) cache = self._build_cache(max_gb=0, max_count=2)"," cache = self._build_cache(max_gb=30, max_count=10) cache = self._build_cache(max_gb=30, max_count=2)",6,4
openstack%2Fopenstack-ansible-os_swift~master~I946b225cc43f9195f63b064a33392476270f7d32,openstack/openstack-ansible-os_swift,master,I946b225cc43f9195f63b064a33392476270f7d32,zuul.d: Update jobs for package installations,MERGED,2018-09-25 07:18:50.000000000,2018-09-27 05:59:15.000000000,2018-09-27 05:59:15.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-25 07:18:50.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/e0fde62f4e118114784fbb5983db60eefd76350d', 'message': 'zuul.d: Update jobs for package installations\n\nAdd Leap 15 distro_install job and replace Xenial with Bionic since the\nformer does not provide packages for recent OpenStack releases.\n\nChange-Id: I946b225cc43f9195f63b064a33392476270f7d32\n'}]",0,604988,e0fde62f4e118114784fbb5983db60eefd76350d,16,5,1,23163,,,0,"zuul.d: Update jobs for package installations

Add Leap 15 distro_install job and replace Xenial with Bionic since the
former does not provide packages for recent OpenStack releases.

Change-Id: I946b225cc43f9195f63b064a33392476270f7d32
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/88/604988/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,e0fde62f4e118114784fbb5983db60eefd76350d,osa-add-leap-150, - openstack-ansible-functional-distro_install-ubuntu-bionic - openstack-ansible-functional-distro_install-opensuse-150 - openstack-ansible-functional-distro_install-ubuntu-bionic - openstack-ansible-functional-distro_install-opensuse-150, - openstack-ansible-functional-distro_install-ubuntu-xenial - openstack-ansible-functional-distro_install-ubuntu-xenial,4,2
openstack%2Fopenstack-ansible~stable%2Fqueens~I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,openstack/openstack-ansible,stable/queens,I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,Use loop_control for haproxy keystone back-end enablement,MERGED,2018-09-26 20:03:50.000000000,2018-09-27 05:53:06.000000000,2018-09-27 05:53:06.000000000,"[{'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 20:03:50.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/d350df49f30f38d180422af7b7b4559ac6b31b30', 'message': 'Use loop_control for haproxy keystone back-end enablement\n\nIn I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop\ncontrol specification from in the common tasks to the parent task,\nbut forgot to implement the loop control for the task which enables\nthe back-end again later. This patch corrects that.\n\nChange-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b\n(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)\n'}]",0,605517,d350df49f30f38d180422af7b7b4559ac6b31b30,7,3,1,6816,,,0,"Use loop_control for haproxy keystone back-end enablement

In I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop
control specification from in the common tasks to the parent task,
but forgot to implement the loop control for the task which enables
the back-end again later. This patch corrects that.

Change-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b
(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/17/605517/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,d350df49f30f38d180422af7b7b4559ac6b31b30,keystone_admin_port-stable/queens," haproxy_backend: ""{{ backend_name }}"" loop_control: loop_var: backend_name"," haproxy_backend: ""{{ item }}""",3,1
openstack%2Fopenstack-ansible~stable%2Focata~I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,openstack/openstack-ansible,stable/ocata,I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,Use loop_control for haproxy keystone back-end enablement,MERGED,2018-09-26 20:06:57.000000000,2018-09-27 05:53:05.000000000,2018-09-27 05:53:05.000000000,"[{'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 20:06:57.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/63728f40c97e87c83459822636b11a2b025f5f9f', 'message': 'Use loop_control for haproxy keystone back-end enablement\n\nIn I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop\ncontrol specification from in the common tasks to the parent task,\nbut forgot to implement the loop control for the task which enables\nthe back-end again later. This patch corrects that.\n\nChange-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b\n(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)\n'}]",0,605519,63728f40c97e87c83459822636b11a2b025f5f9f,7,3,1,6816,,,0,"Use loop_control for haproxy keystone back-end enablement

In I17dafb283e41ce05083ae4adb3a325aaca0253dd we switched the loop
control specification from in the common tasks to the parent task,
but forgot to implement the loop control for the task which enables
the back-end again later. This patch corrects that.

Change-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b
(cherry picked from commit 8d8755be86b6cde10f656de6ef19637a91b94954)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/19/605519/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,63728f40c97e87c83459822636b11a2b025f5f9f,keystone_admin_port-stable/ocata," haproxy_backend: ""{{ backend_name }}"" loop_control: loop_var: backend_name"," haproxy_backend: ""{{ item }}""",3,1
openstack%2Fopenstack-ansible~master~I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,openstack/openstack-ansible,master,I0d7e4804bdc92ffe7a679060a686e684c01fcd1b,Remove keystone_admin-back load balancer manipulation,MERGED,2018-09-26 17:33:42.000000000,2018-09-27 05:53:03.000000000,2018-09-27 05:53:03.000000000,"[{'_account_id': 7414}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 17:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/98e1aa66ee7560a48569b1575447c5cd806ebfe2', 'message': 'Remove keystone_admin-back load balancer manipulation\n\nFor multi-node builds, we previously shut down the keystone_admin-back\nfor the node being worked on when making changes to the keystone node.\n\nThis back-end no longer exists, and manipulating it now causes the\nkeystone_service-back not to come up again when it should - resulting\nin keystone never being available.\n\nThis patch removes the back-end from the list, and also removes the\nport reservation which is no longer applicable.\n\nChange-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b\n'}, {'number': 2, 'created': '2018-09-26 18:34:20.000000000', 'files': ['playbooks/os-keystone-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/a45467abeee0646720e8b04ce5613cf4a855e318', 'message': ""Remove keystone_admin-back load balancer manipulation\n\nFor multi-node builds, we previously shut down the keystone_admin-back\nfor the node being worked on when making changes to the keystone node.\n\nThis back-end no longer exists, and the second loop does not use loop\ncontrol to ensure that the common tasks 'item' and the playbook 'item'\ndo not clash, causing the task to enable the back-end to have no effect\nand keystone remains in maintenance mode.\n\nThis patch removes the back-end from the list, and also removes the\nport reservation which is no longer applicable.\n\nChange-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b\n""}]",0,605494,a45467abeee0646720e8b04ce5613cf4a855e318,9,3,2,6816,,,0,"Remove keystone_admin-back load balancer manipulation

For multi-node builds, we previously shut down the keystone_admin-back
for the node being worked on when making changes to the keystone node.

This back-end no longer exists, and the second loop does not use loop
control to ensure that the common tasks 'item' and the playbook 'item'
do not clash, causing the task to enable the back-end to have no effect
and keystone remains in maintenance mode.

This patch removes the back-end from the list, and also removes the
port reservation which is no longer applicable.

Change-Id: I0d7e4804bdc92ffe7a679060a686e684c01fcd1b
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/94/605494/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/os-keystone-install.yml'],1,98e1aa66ee7560a48569b1575447c5cd806ebfe2,keystone_admin_port," haproxy_backend: ""keystone_service-back"" haproxy_backend: ""keystone_service-back"""," haproxy_backend: ""{{ backend_name }}"" with_items: - ""keystone_service-back"" - ""keystone_admin-back"" # todo(cloudnull): this task is being run only if/when keystone is installed on a physical host. # This is not being run within a container because it is an unsupported action due to this # issue: (https://bugs.launchpad.net/ubuntu/+source/lxc/+bug/1279041) # This issue was resolved however we'll need to eval it in the next LTS release. # Related OSA Bug: https://launchpad.net/bugs/1426371 - name: Add keystone reserved port to physical host sysctl: name: ""{{ item.key }}"" value: ""{{ item.value }}"" sysctl_set: ""{{ item.set|default('yes') }}"" state: ""{{ item.state|default('present') }}"" reload: ""{{ item.reload|default('yes') }}"" with_items: - { key: ""net.ipv4.ip_local_reserved_ports"", value: ""{{ keystone_admin_port }}""} when: is_metal | bool haproxy_backend: ""{{ item }}"" with_items: - ""keystone_service-back"" - ""keystone_admin-back""",2,24
openstack%2Fpython-qinlingclient~master~Ib553db027106dff6cceade5812a4f4b1b79cf450,openstack/python-qinlingclient,master,Ib553db027106dff6cceade5812a4f4b1b79cf450,Update the outdated URL in docstring,MERGED,2018-09-23 10:02:43.000000000,2018-09-27 05:47:16.000000000,2018-09-27 05:47:16.000000000,"[{'_account_id': 6732}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-09-23 10:02:43.000000000', 'files': ['qinlingclient/i18n.py'], 'web_link': 'https://opendev.org/openstack/python-qinlingclient/commit/02a0fcd578471e35e79b39a6f864e47256747a0f', 'message': 'Update the outdated URL in docstring\n\nChange-Id: Ib553db027106dff6cceade5812a4f4b1b79cf450\n'}]",0,604605,02a0fcd578471e35e79b39a6f864e47256747a0f,8,3,1,17130,,,0,"Update the outdated URL in docstring

Change-Id: Ib553db027106dff6cceade5812a4f4b1b79cf450
",git fetch https://review.opendev.org/openstack/python-qinlingclient refs/changes/05/604605/1 && git format-patch -1 --stdout FETCH_HEAD,['qinlingclient/i18n.py'],1,02a0fcd578471e35e79b39a6f864e47256747a0f,fix-url,See https://docs.openstack.org/oslo.i18n/latest/user/index.html,See http://docs.openstack.org/developer/oslo.i18n/usage.html,1,1
openstack%2Fgovernance~master~I2616aeaeb4c55b7e71b0a655f9716048d0ce01cb,openstack/governance,master,I2616aeaeb4c55b7e71b0a655f9716048d0ce01cb,Add ansible-role-chrony to TripleO,MERGED,2018-09-18 22:08:20.000000000,2018-09-27 05:00:23.000000000,2018-09-27 05:00:23.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-18 22:08:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/governance/commit/29cd57b5c91f2edd654ca2272bcbbeeffb7d4328', 'message': 'Add ansible-role-chrony to TripleO\n\nChange-Id: I2616aeaeb4c55b7e71b0a655f9716048d0ce01cb\nDepends-On: https://review.openstack.org/#/c/603489/\n'}, {'number': 2, 'created': '2018-09-18 22:11:45.000000000', 'files': ['reference/projects.yaml'], 'web_link': 'https://opendev.org/openstack/governance/commit/8ca73376500697aeca63478dba1847fd59824e8c', 'message': 'Add ansible-role-chrony to TripleO\n\nChange-Id: I2616aeaeb4c55b7e71b0a655f9716048d0ce01cb\nDepends-On: https://review.openstack.org/#/c/603489/\nRelated-Blueprint: tripleo-chrony\n'}]",0,603516,8ca73376500697aeca63478dba1847fd59824e8c,17,7,2,14985,,,0,"Add ansible-role-chrony to TripleO

Change-Id: I2616aeaeb4c55b7e71b0a655f9716048d0ce01cb
Depends-On: https://review.openstack.org/#/c/603489/
Related-Blueprint: tripleo-chrony
",git fetch https://review.opendev.org/openstack/governance refs/changes/16/603516/2 && git format-patch -1 --stdout FETCH_HEAD,['reference/projects.yaml'],1,29cd57b5c91f2edd654ca2272bcbbeeffb7d4328,project-update, ansible-role-chrony: repos: - openstack/ansible-role-chrony,,3,0
openstack%2Fkeystone~master~I0760746dc62b65607ac0e88ee6d03395c9226fe7,openstack/keystone,master,I0760746dc62b65607ac0e88ee6d03395c9226fe7,Comment out un-runnable tests,MERGED,2018-09-18 17:54:06.000000000,2018-09-27 04:52:47.000000000,2018-09-27 04:52:46.000000000,"[{'_account_id': 2218}, {'_account_id': 5046}, {'_account_id': 7725}, {'_account_id': 8482}, {'_account_id': 11022}, {'_account_id': 13063}, {'_account_id': 15054}, {'_account_id': 16465}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2018-09-18 17:54:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/daee283320ab7df4cfcca6d5654d03200e8a4f34', 'message': 'Comment out un-runnable tests\n\nThese tests have not been run in > 2 years. They are commented out\nwith an updated FIXME to rework once the flask port is done (auth).\nIt is out of scope of Flask to re-enable long disabled tests.\nWe do not want to lose the context of the coverage the tests provide\nthus we are commenting them out instead of outright deletion.\n\nChange-Id: I0760746dc62b65607ac0e88ee6d03395c9226fe7\n'}, {'number': 2, 'created': '2018-09-21 13:35:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/d5cd2596cd078e929ec92e9ee8131920fc4969fe', 'message': 'Comment out un-runnable tests\n\nThese tests have not been run in > 2 years. They are commented out\nwith an updated FIXME to rework once the flask port is done (auth).\nIt is out of scope of Flask to re-enable long disabled tests.\nWe do not want to lose the context of the coverage the tests provide\nthus we are commenting them out instead of outright deletion.\n\nChange-Id: I0760746dc62b65607ac0e88ee6d03395c9226fe7\n'}, {'number': 3, 'created': '2018-09-21 19:06:58.000000000', 'files': ['keystone/tests/unit/test_v3_auth.py'], 'web_link': 'https://opendev.org/openstack/keystone/commit/d6d3bf911043a772cf4312e6da2f526fddb45acf', 'message': 'Comment out un-runnable tests\n\nThese tests have not been run in > 2 years. They are commented out\nwith an updated FIXME to rework once the flask port is done (auth).\nIt is out of scope of Flask to re-enable long disabled tests.\nWe do not want to lose the context of the coverage the tests provide\nthus we are commenting them out instead of outright deletion.\n\nChange-Id: I0760746dc62b65607ac0e88ee6d03395c9226fe7\n'}]",3,603459,d6d3bf911043a772cf4312e6da2f526fddb45acf,15,11,3,2903,,,0,"Comment out un-runnable tests

These tests have not been run in > 2 years. They are commented out
with an updated FIXME to rework once the flask port is done (auth).
It is out of scope of Flask to re-enable long disabled tests.
We do not want to lose the context of the coverage the tests provide
thus we are commenting them out instead of outright deletion.

Change-Id: I0760746dc62b65607ac0e88ee6d03395c9226fe7
",git fetch https://review.opendev.org/openstack/keystone refs/changes/59/603459/1 && git format-patch -1 --stdout FETCH_HEAD,['keystone/tests/unit/test_v3_auth.py'],1,daee283320ab7df4cfcca6d5654d03200e8a4f34,,"# FIXME(morgan): This test case must be re-worked to function under flask. It # has been commented out until it is re-worked ensuring no issues when webob # classes are removed. # class AuthExternalDomainBehavior(object): # content_type = 'json' # # def test_remote_user_with_realm(self): # api = auth.controllers.Auth() # remote_user = self.user['name'] # remote_domain = self.domain['name'] # request, auth_info, auth_context = self.build_external_auth_request( # remote_user, remote_domain=remote_domain, kerberos=self.kerberos) # # api.authenticate(request, auth_info, auth_context) # self.assertEqual(self.user['id'], auth_context['user_id']) # # # Now test to make sure the user name can, itself, contain the # # '@' character. # user = {'name': 'myname@mydivision'} # PROVIDERS.identity_api.update_user(self.user['id'], user) # remote_user = user['name'] # request, auth_info, auth_context = self.build_external_auth_request( # remote_user, remote_domain=remote_domain, kerberos=self.kerberos) # # api.authenticate(request, auth_info, auth_context) # self.assertEqual(self.user['id'], auth_context['user_id']) # # # FIXME(morgan): This test case must be re-worked to function under flask. It # has been commented out until it is re-worked ensuring no issues when webob # classes are removed. # class TestAuthExternalDefaultDomain(object): # content_type = 'json' # # def config_overrides(self): # super(TestAuthExternalDefaultDomain, self).config_overrides() # self.kerberos = False # self.auth_plugin_config_override(external='DefaultDomain') # # def test_remote_user_with_default_domain(self): # api = auth.controllers.Auth() # remote_user = self.default_domain_user['name'] # request, auth_info, auth_context = self.build_external_auth_request( # remote_user, kerberos=self.kerberos) # # api.authenticate(request, auth_info, auth_context) # self.assertEqual(self.default_domain_user['id'], # auth_context['user_id']) # # # Now test to make sure the user name can, itself, contain the # # '@' character. # user = {'name': 'myname@mydivision'} # PROVIDERS.identity_api.update_user( # self.default_domain_user['id'], user # ) # remote_user = user['name'] # request, auth_info, auth_context = self.build_external_auth_request( # remote_user, kerberos=self.kerberos) # # api.authenticate(request, auth_info, auth_context) # self.assertEqual(self.default_domain_user['id'], # auth_context['user_id']) #","# TODO(morgan): Determine if these test cases should be run. If so, retro-fit # them to run. class AuthExternalDomainBehavior(object): content_type = 'json' def test_remote_user_with_realm(self): api = auth.controllers.Auth() remote_user = self.user['name'] remote_domain = self.domain['name'] request, auth_info, auth_context = self.build_external_auth_request( remote_user, remote_domain=remote_domain, kerberos=self.kerberos) api.authenticate(request, auth_info, auth_context) self.assertEqual(self.user['id'], auth_context['user_id']) # Now test to make sure the user name can, itself, contain the # '@' character. user = {'name': 'myname@mydivision'} PROVIDERS.identity_api.update_user(self.user['id'], user) remote_user = user['name'] request, auth_info, auth_context = self.build_external_auth_request( remote_user, remote_domain=remote_domain, kerberos=self.kerberos) api.authenticate(request, auth_info, auth_context) self.assertEqual(self.user['id'], auth_context['user_id']) # TODO(morgan): Determine if these test cases should be run. If so, retro-fit # them to run. class TestAuthExternalDefaultDomain(object): content_type = 'json' def config_overrides(self): super(TestAuthExternalDefaultDomain, self).config_overrides() self.kerberos = False self.auth_plugin_config_override(external='DefaultDomain') def test_remote_user_with_default_domain(self): api = auth.controllers.Auth() remote_user = self.default_domain_user['name'] request, auth_info, auth_context = self.build_external_auth_request( remote_user, kerberos=self.kerberos) api.authenticate(request, auth_info, auth_context) self.assertEqual(self.default_domain_user['id'], auth_context['user_id']) # Now test to make sure the user name can, itself, contain the # '@' character. user = {'name': 'myname@mydivision'} PROVIDERS.identity_api.update_user( self.default_domain_user['id'], user ) remote_user = user['name'] request, auth_info, auth_context = self.build_external_auth_request( remote_user, kerberos=self.kerberos) api.authenticate(request, auth_info, auth_context) self.assertEqual(self.default_domain_user['id'], auth_context['user_id'])",63,60
openstack%2Fopenstack-ansible-os_swift~master~Ic7a24089fe71b072adaa09cd79fe0286ea93913f,openstack/openstack-ansible-os_swift,master,Ic7a24089fe71b072adaa09cd79fe0286ea93913f,add the project source code repository,MERGED,2018-09-07 02:30:54.000000000,2018-09-27 04:40:53.000000000,2018-09-27 04:40:53.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27372}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:30:54.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/bb31dd88be828b5d1e08e2a8f7f894513bfffc33', 'message': 'add the project source code repository\n\nChange-Id: Ic7a24089fe71b072adaa09cd79fe0286ea93913f\n'}]",0,600617,bb31dd88be828b5d1e08e2a8f7f894513bfffc33,7,4,1,27385,,,0,"add the project source code repository

Change-Id: Ic7a24089fe71b072adaa09cd79fe0286ea93913f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/17/600617/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,bb31dd88be828b5d1e08e2a8f7f894513bfffc33,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_swift/ ,,3,0
openstack%2Fopenstack-ansible-os_swift~master~Ibf58f0fd6c7c5128b7e124ad4e66c34fec9b89f7,openstack/openstack-ansible-os_swift,master,Ibf58f0fd6c7c5128b7e124ad4e66c34fec9b89f7,Add source code repository notes link to README,MERGED,2018-07-17 02:20:45.000000000,2018-09-27 04:40:53.000000000,2018-09-27 04:40:53.000000000,"[{'_account_id': 1004}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25695}, {'_account_id': 26431}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-07-17 02:20:45.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/26c87006b55f64a0b67144b832898ff3e79b935f', 'message': 'Add source code repository notes link to README\n\nChange-Id: Ibf58f0fd6c7c5128b7e124ad4e66c34fec9b89f7\n'}]",0,583082,26c87006b55f64a0b67144b832898ff3e79b935f,13,6,1,27190,,,0,"Add source code repository notes link to README

Change-Id: Ibf58f0fd6c7c5128b7e124ad4e66c34fec9b89f7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/82/583082/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,26c87006b55f64a0b67144b832898ff3e79b935f,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_swift/ ,,3,0
openstack%2Fopenstack-ansible-ops~master~Ie640f609ef345e9b4908eb17a03be5390b72b186,openstack/openstack-ansible-ops,master,Ie640f609ef345e9b4908eb17a03be5390b72b186,Add additional API tests to confirm functionality,MERGED,2018-09-25 19:42:31.000000000,2018-09-27 04:38:10.000000000,2018-09-27 04:38:10.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-25 19:42:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/bfbc6cc32f32d0ac0d9647f81964d2ebcb904612', 'message': 'Add additional tests and update setupKibanaDashboard\n\nThe changes here add additional tests to the system to ensure all of\nthe required APIs are up, available, and are returning data as expected.\nTo ensure the tests run the `q_mem` override value has been set a little\nhigher, which will allow logstash to start (before it would result in a\nheap size of 115M which is not enough to start logstash). These tests\nwere added in support of ensuring the setupKibanaDashboard playbook\nexecutes correctly.\n\nAdditional dependencies were added to the setupKibanaDashboard playbook\nwhich are required for the playbook to run successfully without any\nassumption that the other playbooks (installKibana) were executed in\nseries. To ensure the playbook functions it has been added to the\n""site.yml"" file.\n\nChange-Id: Ie640f609ef345e9b4908eb17a03be5390b72b186\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}, {'number': 2, 'created': '2018-09-26 16:16:16.000000000', 'files': ['elk_metrics_6x/tests/test-vars.yml', 'elk_metrics_6x/tests/testAPI.yml', 'elk_metrics_6x/tests/test.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/f1423bdfee9af1a612662be0fb3cdf751b234077', 'message': 'Add additional API tests to confirm functionality\n\nThe changes here add additional tests to the system to ensure all of\nthe required APIs are up, available, and are returning data as expected.\nTo ensure the tests run the `q_mem` override value has been set a little\nhigher, which will allow logstash to start (before it would result in a\nheap size of 115M which is not enough to start logstash).\n\nChange-Id: Ie640f609ef345e9b4908eb17a03be5390b72b186\nSigned-off-by: Kevin Carter <kevin.carter@rackspace.com>\n'}]",1,605194,f1423bdfee9af1a612662be0fb3cdf751b234077,10,3,2,7353,,,0,"Add additional API tests to confirm functionality

The changes here add additional tests to the system to ensure all of
the required APIs are up, available, and are returning data as expected.
To ensure the tests run the `q_mem` override value has been set a little
higher, which will allow logstash to start (before it would result in a
heap size of 115M which is not enough to start logstash).

Change-Id: Ie640f609ef345e9b4908eb17a03be5390b72b186
Signed-off-by: Kevin Carter <kevin.carter@rackspace.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/94/605194/1 && git format-patch -1 --stdout FETCH_HEAD,"['elk_metrics_6x/roles/elastic_kibana/defaults/main.yml', 'elk_metrics_6x/tests/test-vars.yml', 'elk_metrics_6x/setupKibanaDashboard.yml', 'elk_metrics_6x/site.yml', 'elk_metrics_6x/tests/testAPI.yml', 'elk_metrics_6x/vars/variables.yml', 'elk_metrics_6x/tests/test.yml']",7,bfbc6cc32f32d0ac0d9647f81964d2ebcb904612,,- import_playbook: testAPI.yml,,156,32
openstack%2Fpython-tripleoclient~master~I3f1055ece3c267540bd4a94d42811b9146a09a86,openstack/python-tripleoclient,master,I3f1055ece3c267540bd4a94d42811b9146a09a86,Remove instack-undercloud and --use-heat,MERGED,2018-08-03 15:40:33.000000000,2018-09-27 04:34:06.000000000,2018-09-27 04:34:06.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 22865}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-03 15:40:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f9c3b830e128847a8306df048ce1a03b33573327', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}, {'number': 2, 'created': '2018-08-04 17:33:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/59c4a4487ab7fc821d4281f287bf48b019e72c8a', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}, {'number': 3, 'created': '2018-08-14 22:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/94d0e4ff0052eea1a7cfcb7a2f8063a593a0b63c', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nDepends-On: https://review.openstack.org/#/c/591858/\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}, {'number': 4, 'created': '2018-08-27 16:22:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e518176f5e8689265e7036dfa5dbfee5a9847179', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nDepends-On: https://review.openstack.org/#/c/591858/\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}, {'number': 5, 'created': '2018-08-29 17:57:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5875d1082e921eed7a7b5b988948516f2af73b01', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nDepends-On: https://review.openstack.org/#/c/591858/\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}, {'number': 6, 'created': '2018-09-24 19:36:38.000000000', 'files': ['tripleoclient/tests/v1/undercloud/test_undercloud.py', 'releasenotes/notes/retire-instack-undercloud-1cd802a8cc437f7c.yaml', 'tripleoclient/v1/undercloud.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ea904d09643fecf221b8c47289eb1b5252c97864', 'message': 'Remove instack-undercloud and --use-heat\n\nThe instack-undercloud method of installing the undercloud was\ndeprecated in Rocky. We would like to remove the tie in via the\ntripleoclient to reduce the overall package requirements when install\ntripleoclient.\n\nDepends-On: https://review.openstack.org/#/c/591858/\nChange-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86\nBlueprint: remove-instack-undercloud\n'}]",0,588606,ea904d09643fecf221b8c47289eb1b5252c97864,71,8,6,14985,,,0,"Remove instack-undercloud and --use-heat

The instack-undercloud method of installing the undercloud was
deprecated in Rocky. We would like to remove the tie in via the
tripleoclient to reduce the overall package requirements when install
tripleoclient.

Depends-On: https://review.openstack.org/#/c/591858/
Change-Id: I3f1055ece3c267540bd4a94d42811b9146a09a86
Blueprint: remove-instack-undercloud
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/06/588606/3 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/undercloud/test_undercloud.py', 'releasenotes/notes/retire-instack-undercloud-1cd802a8cc437f7c.yaml', 'tripleoclient/v1/undercloud.py']",3,f9c3b830e128847a8306df048ce1a03b33573327,bp/remove-instack-undercloud," no_validations = parsed_args.dry_run or parsed_args.no_validations cmd = undercloud_config.prepare_undercloud_deploy( no_validations=no_validations, verbose_level=self.app_args.verbose_level, force_stack_update=parsed_args.force_stack_update, dry_run=parsed_args.dry_run) cmd = undercloud_config.\ prepare_undercloud_deploy( upgrade=True, yes=parsed_args.yes, no_validations=parsed_args. no_validations, verbose_level=self.app_args.verbose_level, force_stack_update=parsed_args.force_stack_update) self.log.warning(""Running: %s"" % ' '.join(cmd)) try: subprocess.check_call(cmd) self.log.warning(UNDERCLOUD_UPGRADE_COMPLETION_MESSAGE.format( '~/undercloud-passwords.conf', '~/stackrc' )) except Exception as e: self.log.error(UNDERCLOUD_FAILURE_MESSAGE) self.log.error(e) raise exceptions.DeploymentError(e)"," parser.add_argument( '--use-heat', dest='use_heat', nargs='?', default=None, const=""true"", help=_('This option is deprecated in Rocky. It makes sure that we ' 'perform undercloud deploy using ephemeral ' '(one-time create and forget) heat stack and ansible.'), ) if parsed_args.use_heat is not None: self.log.warning('--use-heat is deprecated in Rocky') if parsed_args.use_heat is not None and \ parsed_args.use_heat.lower() == ""false"": self.log.warning(_('Non-containerized undercloud deployment is ' 'deprecated in Rocky cycle.')) cmd = [""instack-install-undercloud""] else: no_validations = parsed_args.dry_run or parsed_args.no_validations cmd = undercloud_config.\ prepare_undercloud_deploy( no_validations=no_validations, verbose_level=self.app_args.verbose_level, force_stack_update=parsed_args.force_stack_update, dry_run=parsed_args.dry_run) if parsed_args.use_heat is not None: self.log.warning('--use-heat is deprecated in Rocky') if parsed_args.use_heat is not None and \ parsed_args.use_heat.lower() == ""false"": self.log.warning(_('Non-containerized undercloud deployment is ' 'deprecated in Rocky cycle.')) subprocess.check_call(['sudo', 'yum', 'update', '-y', 'instack-undercloud']) subprocess.check_call(""instack-pre-upgrade-undercloud"") subprocess.check_call(""instack-upgrade-undercloud"") # restart nova-api # https://bugzilla.redhat.com/show_bug.cgi?id=1315467 subprocess.check_call(['sudo', 'systemctl', 'restart', 'openstack-nova-api']) else: cmd = undercloud_config.\ prepare_undercloud_deploy( upgrade=True, yes=parsed_args.yes, no_validations=parsed_args. no_validations, verbose_level=self.app_args.verbose_level, force_stack_update=parsed_args.force_stack_update) self.log.warning(""Running: %s"" % ' '.join(cmd)) try: subprocess.check_call(cmd) self.log.warning(UNDERCLOUD_UPGRADE_COMPLETION_MESSAGE.format( '~/undercloud-passwords.conf', '~/stackrc' )) except Exception as e: self.log.error(UNDERCLOUD_FAILURE_MESSAGE) self.log.error(e) raise exceptions.DeploymentError(e)",41,102
openstack%2Ftripleo-quickstart-extras~master~I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2,openstack/tripleo-quickstart-extras,master,I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2,Add tempest to standalone,MERGED,2018-06-15 03:00:37.000000000,2018-09-27 04:34:03.000000000,2018-09-27 04:34:03.000000000,"[{'_account_id': 3153}, {'_account_id': 8367}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}]","[{'number': 1, 'created': '2018-06-15 03:00:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f446bf934415f522952e6a1f250ad9b69bdb62d4', 'message': 'WIP: add tempest to standalone\n\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 2, 'created': '2018-06-16 15:54:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f86a92b19b370a43f077a64856717da98ae4ef49', 'message': 'WIP: add tempest to standalone\n\nDepends-On: I2289159d501f9c6793afa5f4a548cabea5062c00\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 3, 'created': '2018-06-16 15:54:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d1ac748b1bbe8ec98aa25e5b4e4cfc4e41c4d2de', 'message': 'WIP: add tempest to standalone\n\nDepends-On: I2289159d501f9c6793afa5f4a548cabea5062c00\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 4, 'created': '2018-07-03 21:43:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d3d166d8da0d9de563fe1a3f83381f10b4167568', 'message': 'WIP: add tempest to standalone\n\nDepends-On: I2289159d501f9c6793afa5f4a548cabea5062c00\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 5, 'created': '2018-07-06 20:54:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d2221f7ed41e42b5e7c55b6989f7c6aa0c96d44a', 'message': 'WIP: add tempest to standalone\n\nDepends-On: I2289159d501f9c6793afa5f4a548cabea5062c00\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 6, 'created': '2018-07-12 22:34:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ad5c916366ae323751bb92b3e805a15378fc54dc', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 7, 'created': '2018-07-13 19:05:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f05e1399a06cc2072c7e7c9ac0db3b25c97a5ea2', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 8, 'created': '2018-08-20 16:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/29094c8d3e12e482b4c1a3f02ed7821d40f6b2a6', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 9, 'created': '2018-09-06 21:57:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/f70fc04881e5d1702bf41e206b70b05e2bac9e9c', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 10, 'created': '2018-09-06 22:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c95ec986e6f14b4732d4c971a4b64ed1bed6ed93', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 11, 'created': '2018-09-07 00:05:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5fa203f7fd41e90958dd3f6176b817ef5864019d', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 12, 'created': '2018-09-07 02:47:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/0eb89d24372925e057df8c0fe4a5b332515238bf', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}, {'number': 13, 'created': '2018-09-14 16:40:27.000000000', 'files': ['playbooks/multinode-standalone.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9cb388dc93f1675b24a384ea275e50861e343155', 'message': 'Add tempest to standalone\n\nDepends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7\nChange-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2\n'}]",0,575588,9cb388dc93f1675b24a384ea275e50861e343155,75,10,13,9592,,,0,"Add tempest to standalone

Depends-On: Iaac8be4822059d2a9e1947e05ecac371714c34c7
Change-Id: I4421fd4d948aa3eeec48057fe7d6cc2b44e006c2
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/88/575588/12 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/multinode-standalone.yml'],1,f446bf934415f522952e6a1f250ad9b69bdb62d4,bp/all-in-one,- name: Validate the undercloud hosts: undercloud roles: - validate-undercloud ,,5,0
openstack%2Fopenstackdocstheme~master~Ib6fb3bd1a6a776be06bc09e2e4183ca909ea7b60,openstack/openstackdocstheme,master,Ib6fb3bd1a6a776be06bc09e2e4183ca909ea7b60,Add an option to disable global TOC section,MERGED,2018-09-25 12:54:05.000000000,2018-09-27 04:32:14.000000000,2018-09-27 04:32:14.000000000,"[{'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 6547}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 12:54:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/69a54e2b70ed3856dc19b2a40c498375a32c9aec', 'message': 'Add an option to disable global TOC section\n\nOn some sites (like the governance site) the navigation between\npages is included in the page content itself, making the global\nsection of the TOC unnecessary. This adds a new theme option\n(display_global_toc_section) to allow to disable it.\n\nChange-Id: Ib6fb3bd1a6a776be06bc09e2e4183ca909ea7b60\n'}, {'number': 2, 'created': '2018-09-26 13:27:11.000000000', 'files': ['openstackdocstheme/theme/openstackdocs/sidebartoc.html', 'doc/source/index.rst', 'openstackdocstheme/theme/openstackdocs/theme.conf', 'openstackdocstheme/theme/openstackdocs/localtoc.html'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/c3bf0d1f626670c4d991468621aff9fea7e66f54', 'message': 'Add an option to disable global TOC section\n\nOn some sites (like the governance site) the navigation between\npages is included in the page content itself, making the global\nsection of the TOC unnecessary. This adds a new theme option\n(display_global_toc_section) to allow to disable it.\n\nChange-Id: Ib6fb3bd1a6a776be06bc09e2e4183ca909ea7b60\n'}]",0,605063,c3bf0d1f626670c4d991468621aff9fea7e66f54,11,5,2,308,,,0,"Add an option to disable global TOC section

On some sites (like the governance site) the navigation between
pages is included in the page content itself, making the global
section of the TOC unnecessary. This adds a new theme option
(display_global_toc_section) to allow to disable it.

Change-Id: Ib6fb3bd1a6a776be06bc09e2e4183ca909ea7b60
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/63/605063/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstackdocstheme/theme/openstackdocs/sidebartoc.html', 'doc/source/index.rst', 'openstackdocstheme/theme/openstackdocs/theme.conf', 'openstackdocstheme/theme/openstackdocs/localtoc.html']",4,69a54e2b70ed3856dc19b2a40c498375a32c9aec,support-governance," <h4 class=""docs-sidebar-section-title"">{%- if theme_display_global_toc_section %}Page {%- endif %}Contents</h4>"," <h4 class=""docs-sidebar-section-title"">Page Contents</h4>",14,1
openstack%2Fproject-config~master~I05bceff2feafc24e93e295312cdff4bcabf00501,openstack/project-config,master,I05bceff2feafc24e93e295312cdff4bcabf00501,Added twine check functionality to python-tarball playbook,MERGED,2018-09-25 15:11:54.000000000,2018-09-27 04:32:06.000000000,2018-09-27 04:32:06.000000000,"[{'_account_id': 2}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 12393}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 15:11:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/d674a4f0d2648cbc7a549c3c2936133377333c69', 'message': 'Added twine check functionality to python-tarball playbook\n\n* twine has introduced a new feature to check the README.rst so that\n  the content should render fine on pypi\n\nChange-Id: I05bceff2feafc24e93e295312cdff4bcabf00501\n'}, {'number': 2, 'created': '2018-09-25 15:13:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/94c5e1728e6515c8099a6c2b72ce602d792ad9fb', 'message': 'Added twine check functionality to python-tarball playbook\n\n* twine has introduced a new feature to check the README.rst so that\n  the content should render fine on pypi\n\nChange-Id: I05bceff2feafc24e93e295312cdff4bcabf00501\n'}, {'number': 3, 'created': '2018-09-26 08:11:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/b764c6d1f6c0018e320bf962b9bb96f643115cf6', 'message': 'Added twine check functionality to python-tarball playbook\n\n* twine has introduced a new feature to check the README.rst so that\n  the content should render fine on pypi\n\nChange-Id: I05bceff2feafc24e93e295312cdff4bcabf00501\n'}, {'number': 4, 'created': '2018-09-26 19:49:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/e0502769abca10a12f0c6df82790bcbbc0c14484', 'message': 'Added twine check functionality to python-tarball playbook\n\n* twine has introduced a new feature to check the README.rst so that\n  the content should render fine on pypi\n\nChange-Id: I05bceff2feafc24e93e295312cdff4bcabf00501\n'}, {'number': 5, 'created': '2018-09-26 19:57:00.000000000', 'files': ['playbooks/pti-python-tarball/check.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/38e40c5de76752948ac770373145191cf09fe48b', 'message': 'Added twine check functionality to python-tarball playbook\n\n* twine has introduced a new feature to check the README.rst so that\n  the content should render fine on pypi\n\nChange-Id: I05bceff2feafc24e93e295312cdff4bcabf00501\n'}]",2,605096,38e40c5de76752948ac770373145191cf09fe48b,21,5,5,12393,,,0,"Added twine check functionality to python-tarball playbook

* twine has introduced a new feature to check the README.rst so that
  the content should render fine on pypi

Change-Id: I05bceff2feafc24e93e295312cdff4bcabf00501
",git fetch https://review.opendev.org/openstack/project-config refs/changes/96/605096/3 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/python-tarball/run.yaml'],1,d674a4f0d2648cbc7a549c3c2936133377333c69,twine_check," - role: ensure_twine - tasks: - name: Run twine check on python dist tarball command: ""{{ pypi_twine_executable }} check dist/*",,4,0
openstack%2Fgoal-tools~master~I08d155926e9f4cfea4a6d51debe44fdc9c18a434,openstack/goal-tools,master,I08d155926e9f4cfea4a6d51debe44fdc9c18a434,try to remove python2.7 settings before adding python3,MERGED,2018-09-26 22:50:25.000000000,2018-09-27 04:30:31.000000000,2018-09-27 04:30:31.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 22:50:25.000000000', 'files': ['goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/049d7b384c377fe7a0d6d4f4669b716a73a6bb31', 'message': 'try to remove python2.7 settings before adding python3\n\nChange-Id: I08d155926e9f4cfea4a6d51debe44fdc9c18a434\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605549,049d7b384c377fe7a0d6d4f4669b716a73a6bb31,6,2,1,2472,,,0,"try to remove python2.7 settings before adding python3

Change-Id: I08d155926e9f4cfea4a6d51debe44fdc9c18a434
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/49/605549/1 && git format-patch -1 --stdout FETCH_HEAD,['goal_tools/python3_first/toxsettings.py'],1,049d7b384c377fe7a0d6d4f4669b716a73a6bb31,python3-first," # First try to remove a python2 setting, if it is there. This # won't catch everything, but it does seem to be the most # common pattern. tox_contents = tox_contents.replace( env_header + 'basepython = python2.7\n', env_header, ) # Now try to add the python3 setting.",,8,0
openstack%2Ftripleo-heat-templates~master~Ie7a42822be89cced480302d40180b9972d191004,openstack/tripleo-heat-templates,master,Ie7a42822be89cced480302d40180b9972d191004,Stop cap granting to empty pool when telemetry disabled,MERGED,2018-07-25 23:20:36.000000000,2018-09-27 04:26:30.000000000,2018-09-27 04:26:30.000000000,"[{'_account_id': 6796}, {'_account_id': 6924}, {'_account_id': 11444}, {'_account_id': 14270}, {'_account_id': 18002}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-07-25 23:20:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/692dd4b734e31feccbe5e3aa84b3fd065da31d4e', 'message': ""WIP/DNM: Stop cap granting to empty pool when telemetry disabled\n\nAttempt to not create GnocchiRbdPool pool when it is set to empty\nstring [1] resulted in related bug which was not resolved by\noriginally proposed fix [2]. Reverting original attempt [1] would\ncause bug #1772743 to return.\n\nEither handle the empty string correctly or don't pass empty\nstring and simply create an unused pool.\n\n[1] https://review.openstack.org/#/c/575571\n[2] https://review.openstack.org/#/c/570043\n\nChange-Id: Ie7a42822be89cced480302d40180b9972d191004\nRelated-Bug: 1776987\n""}, {'number': 2, 'created': '2018-09-05 13:42:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/94a58d22b189f18f8c988c92e625cf9be74d32b8', 'message': ""Stop cap granting to empty pool when telemetry disabled\n\nAttempt to not create GnocchiRbdPool pool when it is set to empty\nstring [1] resulted in related bug which was not resolved by\noriginally proposed fix [2]. Reverting original attempt [1] would\ncause bug #1772743 to return.\n\nEither handle the empty string correctly or don't pass empty\nstring and simply create an unused pool.\n\n[1] https://review.openstack.org/#/c/575571\n[2] https://review.openstack.org/#/c/570043\n\nChange-Id: Ie7a42822be89cced480302d40180b9972d191004\nRelated-Bug: 1776987\n""}, {'number': 3, 'created': '2018-09-20 12:36:07.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e0b52904c05b8c2df0471f97ebc374af7f51324b', 'message': 'Stop cap granting to empty pool when telemetry disabled\n\nAttempt to not create GnocchiRbdPool pool when it is set to empty\nstring [1] resulted in related bug which was not resolved by\noriginally proposed fix [2].\n\n1. https://review.openstack.org/#/c/575571\n2. https://review.openstack.org/#/c/570043\n\nChange-Id: Ie7a42822be89cced480302d40180b9972d191004\nCloses-Bug: 1776987\n'}]",3,585911,e0b52904c05b8c2df0471f97ebc374af7f51324b,42,8,3,18002,,,0,"Stop cap granting to empty pool when telemetry disabled

Attempt to not create GnocchiRbdPool pool when it is set to empty
string [1] resulted in related bug which was not resolved by
originally proposed fix [2].

1. https://review.openstack.org/#/c/575571
2. https://review.openstack.org/#/c/570043

Change-Id: Ie7a42822be89cced480302d40180b9972d191004
Closes-Bug: 1776987
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/11/585911/2 && git format-patch -1 --stdout FETCH_HEAD,['environments/disable-telemetry.yaml'],1,692dd4b734e31feccbe5e3aa84b3fd065da31d4e,bug/1776987,, GnocchiRbdPoolName: '',0,1
openstack%2Ftripleo-ci~master~Ib3c05f327e3d6773990e4e39b1892a61e41cb044,openstack/tripleo-ci,master,Ib3c05f327e3d6773990e4e39b1892a61e41cb044,Add a script to compare reviews CI artifacts,MERGED,2018-08-03 08:50:21.000000000,2018-09-27 04:21:10.000000000,2018-09-27 04:21:10.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9196}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2018-08-03 08:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/90334b3e360d6587e6110cdd392b768e575c20c9', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween revies\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 2, 'created': '2018-08-03 08:55:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/79f7bd7930e779238ba16e584d7aaf46a4f4f105', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween revies\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 3, 'created': '2018-08-03 09:17:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/5b8da5a4e1f3edb0111122cca0566cd751731a4e', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween revies\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 4, 'created': '2018-08-03 09:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/55d6e983a47b2c5f297ee5b7e9c4e609849dd247', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 5, 'created': '2018-08-03 09:33:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8b0da3c9a3d19ee1f189d3768a35e8192006c83d', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 6, 'created': '2018-08-03 09:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4217b24ac8e73794e18340bc9e9741503c35e5ce', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 7, 'created': '2018-08-03 09:50:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/515770e5ed82136c1c33aa7bebf1c7ffb7a5abba', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 8, 'created': '2018-08-03 09:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b5c33105d236f3d63be18d1a61eab32a755a740a', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 9, 'created': '2018-08-03 10:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6b589f7e4eedcd0e0a1fda17a45db4fe2e1a2d99', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 10, 'created': '2018-08-03 12:02:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ca003b83ebe1c80934605d877b729dcf96a7d95e', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 11, 'created': '2018-08-03 12:18:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d2f7f035a40a4174268cf302efc2f3786fc392ea', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 12, 'created': '2018-08-03 12:39:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9f91bfc6fb313bc9f58d8df4bae26429e83131c6', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 13, 'created': '2018-08-03 12:51:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8981d777b380491f5f2248ebe150229329d0554c', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 14, 'created': '2018-08-03 12:58:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6f4323e4978ac5235f6e2adf8ec3c0f35dbba6e7', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 15, 'created': '2018-08-09 13:47:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e0b19d0dc161964da6f7729f252d8f3e6eb27a03', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 16, 'created': '2018-08-10 09:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2540757d05b6b95142c8eaceae1906698c367756', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 17, 'created': '2018-08-10 09:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bb09eae58c6a02b1204f698cc43684f58209ea61', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 18, 'created': '2018-08-10 11:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a19509ac53f40befd0d558d10ebe5d18c3a4a5b0', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 19, 'created': '2018-08-23 13:38:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/37099c33cd0a20bda025db1d5d47f140ffb9f637', 'message': 'Add a script to compare playbook executions\n\nTo check that playbooks get executed the same way\nbetween reviews.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 20, 'created': '2018-09-04 07:33:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3da6dfd2671eee7a24085fe94752d2fa1742117', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 21, 'created': '2018-09-04 09:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1a3bba6795835cfc3b916a87480e6c8cced48f9', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 22, 'created': '2018-09-04 09:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bfe463bcc7a4dd0b2ac4ff13a88c9167361de1fe', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 23, 'created': '2018-09-04 09:32:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1d796116ba641055eaa0d4b2b44f7159335b4964', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 24, 'created': '2018-09-05 10:03:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/53ba783bf2e2c0d8a6c81a8227aa18d3af569141', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}, {'number': 25, 'created': '2018-09-19 14:29:33.000000000', 'files': ['requirements.txt', 'scripts/compare-reviews.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/86915c638d7f705bf60389c69791d93eefd7f579', 'message': 'Add a script to compare reviews CI artifacts\n\nThe ""compare-reviews.py"" is a manual execution script that needs a left\nhand and right hand review numbers and optionally you can override the\nlist of files that it\'s going to compare.\n\nBy default the list of files that compare is:\n- playbook_executions.log\n- reproducer-quickstart.sh\n- collect_logs.sh\n\nAn example of execution would be ""./compare-reviews.py 584508  589068""\nIt will compare the CI artifacts stated before between the two reviews.\n\nThe output is a diff with the differences, for each file at each job.\n\nChange-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044\n'}]",11,588475,86915c638d7f705bf60389c69791d93eefd7f579,66,11,25,27898,,,0,"Add a script to compare reviews CI artifacts

The ""compare-reviews.py"" is a manual execution script that needs a left
hand and right hand review numbers and optionally you can override the
list of files that it's going to compare.

By default the list of files that compare is:
- playbook_executions.log
- reproducer-quickstart.sh
- collect_logs.sh

An example of execution would be ""./compare-reviews.py 584508  589068""
It will compare the CI artifacts stated before between the two reviews.

The output is a diff with the differences, for each file at each job.

Change-Id: Ib3c05f327e3d6773990e4e39b1892a61e41cb044
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/75/588475/3 && git format-patch -1 --stdout FETCH_HEAD,['scripts/compare-reviews.py'],1,90334b3e360d6587e6110cdd392b768e575c20c9,588475,"#!/usr/bin/env python import json import requests import sys gerrit_detail_api = ""https://review.openstack.org/changes/{}/detail"" def parse_ci_message(message): jobs = {} for line in message.split(""\n""): if line[:1] == '-': splitted_line = line.split() jobs[splitted_line[1]] = splitted_line[2] return jobs def get_file(logs_url, file): response = requests.get(logs_url + '/logs/' + file) if response.ok: return response.content def get_playbook_logs(change): playbook_logs = {} detail_url = gerrit_detail_api.format(change) response = requests.get(detail_url) if response.ok: sanitized_content = ""\n"".join(response.content.split(""\n"")[1:]) detail = json.loads(sanitized_content) messages = detail['messages'] zuul_messages = [ message for message in detail['messages'] if message['author']['username'] == 'zuul' ] jobs = parse_ci_message((zuul_messages[-1]['message'])) for job, logs in jobs.iteritems(): playbook_log = get_file(logs, 'playbook_executions.log') if playbook_log: playbook_logs[job] = playbook_log return playbook_logs if __name__ == '__main__': lho = sys.argv[1] rho = sys.argv[2] lho_logs = get_playbook_logs(lho) rho_logs = get_playbook_logs(rho) if lho_logs != rho_logs: print(""Playbooks executions are different"") else: print(""Playbooks executions are the same"") ",,53,0
openstack%2Fopenstack-ansible-os_nova~master~Ibe64eccb3388dedf3ba7e849609aa36ceaa316ea,openstack/openstack-ansible-os_nova,master,Ibe64eccb3388dedf3ba7e849609aa36ceaa316ea,add the project source code repository,MERGED,2018-09-07 01:40:06.000000000,2018-09-27 04:19:12.000000000,2018-09-27 04:19:11.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27372}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/66895403372abebac2ae41610530720c6979d10e', 'message': 'add the project source code repository\n\nChange-Id: Ibe64eccb3388dedf3ba7e849609aa36ceaa316ea\n'}, {'number': 2, 'created': '2018-09-07 01:49:47.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/5385df9ad9186d5a66f1f31134d7a3862164b665', 'message': 'add the project source code repository\n\nChange-Id: Ibe64eccb3388dedf3ba7e849609aa36ceaa316ea\n'}]",0,600602,5385df9ad9186d5a66f1f31134d7a3862164b665,9,4,2,27385,,,0,"add the project source code repository

Change-Id: Ibe64eccb3388dedf3ba7e849609aa36ceaa316ea
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/02/600602/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,66895403372abebac2ae41610530720c6979d10e,update_doc,The project source code repository is located at: `<https://git.openstack.org/cgit/openstack/openstack-ansible-rabbitmq_server/>`_ ,,3,0
openstack%2Fopenstack-ansible-os_nova~master~I3046953f3e27157914dbe1fefd78c7eb2ddddcf6,openstack/openstack-ansible-os_nova,master,I3046953f3e27157914dbe1fefd78c7eb2ddddcf6,Bring gather vars in line with other OSA roles,MERGED,2018-07-28 15:09:32.000000000,2018-09-27 04:19:10.000000000,2018-09-27 04:19:10.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-07-28 15:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/c4d8f620e7e5656d298a5c879bfe7b5161327a57', 'message': 'Bring gather vars in line with other OSA roles\n\nChange-Id: I3046953f3e27157914dbe1fefd78c7eb2ddddcf6\n'}, {'number': 2, 'created': '2018-08-21 15:34:08.000000000', 'files': ['tasks/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/afcbbc57435cb88f4f3ccc1dee6fd5a48d218dc8', 'message': 'Bring gather vars in line with other OSA roles\n\nChange-Id: I3046953f3e27157914dbe1fefd78c7eb2ddddcf6\n'}]",0,586818,afcbbc57435cb88f4f3ccc1dee6fd5a48d218dc8,12,4,2,25023,,,0,"Bring gather vars in line with other OSA roles

Change-Id: I3046953f3e27157914dbe1fefd78c7eb2ddddcf6
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/18/586818/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/main.yml'],1,c4d8f620e7e5656d298a5c879bfe7b5161327a57,fix-gather-vars," - ""{{ ansible_os_family | lower }}-{{ ansible_distribution_version.split('.')[0] }}.yml""",,1,0
openstack%2Fgoal-tools~master~I1b999f3f20c69ae4a004e3e70b9cb63187f5b702,openstack/goal-tools,master,I1b999f3f20c69ae4a004e3e70b9cb63187f5b702,handle errors in fix_one(),MERGED,2018-09-26 22:50:25.000000000,2018-09-27 04:18:48.000000000,2018-09-27 04:18:48.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 22:50:25.000000000', 'files': ['goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/b43191241e1e74887ce59b377ff1059743a58b6f', 'message': 'handle errors in fix_one()\n\nChange-Id: I1b999f3f20c69ae4a004e3e70b9cb63187f5b702\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605548,b43191241e1e74887ce59b377ff1059743a58b6f,6,2,1,2472,,,0,"handle errors in fix_one()

Change-Id: I1b999f3f20c69ae4a004e3e70b9cb63187f5b702
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/48/605548/1 && git format-patch -1 --stdout FETCH_HEAD,['goal_tools/python3_first/toxsettings.py'],1,b43191241e1e74887ce59b377ff1059743a58b6f,python3-first," try: fix_one(team_dir, r, bad_envs) except Exception: LOG.exception('failed to update {}'.format(r)) continue"," fix_one(team_dir, r, bad_envs)",5,1
openstack%2Fgoal-tools~master~I37c101f8d3f7b17e3b69b8e1981b41f53a0d08e6,openstack/goal-tools,master,I37c101f8d3f7b17e3b69b8e1981b41f53a0d08e6,tool to fix the tox settings,MERGED,2018-09-26 22:50:25.000000000,2018-09-27 04:18:47.000000000,2018-09-27 04:18:47.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 22:50:25.000000000', 'files': ['setup.cfg', 'goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/305b39fbc7b81e0113c98b5d276e9def821a2bf2', 'message': ""tool to fix the tox settings\n\nThis is a bit hacky because there isn't a configparser that preserves\ncomments, so we have to edit the contents of the files as text instead\nof using logical operations like configparser.set().\n\nChange-Id: I37c101f8d3f7b17e3b69b8e1981b41f53a0d08e6\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,605547,305b39fbc7b81e0113c98b5d276e9def821a2bf2,6,2,1,2472,,,0,"tool to fix the tox settings

This is a bit hacky because there isn't a configparser that preserves
comments, so we have to edit the contents of the files as text instead
of using logical operations like configparser.set().

Change-Id: I37c101f8d3f7b17e3b69b8e1981b41f53a0d08e6
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/47/605547/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'goal_tools/python3_first/toxsettings.py']",2,305b39fbc7b81e0113c98b5d276e9def821a2bf2,python3-first,"import osimport shutilfrom cliff import commandfrom goal_tools import governance start_dir = os.getcwd() tools_dir = os.path.join(start_dir, 'tools') def clone_repo(workdir, repo): LOG.info('cloning %s', repo) repo_dir = os.path.join(workdir, repo) if os.path.exists(repo_dir): raise RuntimeError('Found another copy of {} at {}'.format( repo, repo_dir)) subprocess.run( [os.path.join(tools_dir, 'clone_repo.sh'), '--workspace', workdir, repo], check=True, ) def git(repo_dir, *args): subprocess.run( ['git'] + list(args), check=True, cwd=repo_dir, ) COMMIT_MESSAGE = '''\ fix tox python3 overrides We want to default to running all tox environments under python 3, so set the basepython value in each environment. We do not want to specify a minor version number, because we do not want to have to update the file every time we upgrade python. We do not want to set the override once in testenv, because that breaks the more specific versions used in default environments like py35 and py36. Signed-off-by: Doug Hellmann <doug@doughellmann.com> ''' def fix_one(workdir, repo, bad_envs): LOG.info('processing %s', repo) repo_dir = os.path.join(workdir, repo) git(repo_dir, 'checkout', 'master') git(repo_dir, 'checkout', '-b', 'python3-first-tox') tox_file = os.path.join(repo_dir, 'tox.ini') with open(tox_file, 'r', encoding='utf-8') as f: tox_contents = f.read() for env in bad_envs: env_header = '[{}]\n'.format(env) LOG.info('updating %r', env_header.rstrip()) tox_contents = tox_contents.replace( env_header, env_header + 'basepython = python3\n', ) with open(tox_file, 'w', encoding='utf-8') as f: f.write(tox_contents) git(repo_dir, 'diff') git(repo_dir, 'add', 'tox.ini') git(repo_dir, 'review', '-s') git(repo_dir, 'commit', '-m', COMMIT_MESSAGE) git(repo_dir, 'show') class ToxFixMissingPy3(command.Command): ""fix the tox environments missing python3 settings"" def get_parser(self, prog_name): parser = super().get_parser(prog_name) parser.add_argument( '--project-list', default=governance.PROJECTS_LIST, help='URL for governance projects.yaml', ) parser.add_argument( 'workdir', help='working directory for output repositories', ) return parser def take_action(self, parsed_args): gov_dat = governance.Governance(url=parsed_args.project_list) repos = gov_dat.get_repos() teams_and_repos = sorted( (gov_dat.get_repo_owner(r), r) for r in repos ) workdir = os.path.realpath(parsed_args.workdir) for team, r in teams_and_repos: if team == 'Infrastructure': LOG.info('skipping %s', r) continue team_dir = os.path.join(workdir, team).replace(' ', '-') if not os.path.exists(team_dir): LOG.info('creating %s', team_dir) os.mkdir(team_dir) tracking_file = os.path.join(team_dir, 'master') clone_repo(team_dir, r) bad_envs = [ env for env, status in check_one(team_dir, r) if status != 'OK' ] if not bad_envs: LOG.info('nothing to change for %s', r) shutil.rmtree(os.path.join(team_dir, r)) continue fix_one(team_dir, r, bad_envs) LOG.info('adding %s to %s', r, tracking_file) with open(tracking_file, 'a', encoding='utf-8') as f: f.write('{}\n'.format(r))",from goal_tools import governance ,132,2
openstack%2Fgoal-tools~master~I2e502c12e1ca80a96bf7a2c4cf9ec0f085342284,openstack/goal-tools,master,I2e502c12e1ca80a96bf7a2c4cf9ec0f085342284,include bindep and cover in the output,MERGED,2018-09-26 22:50:25.000000000,2018-09-27 04:18:06.000000000,2018-09-27 04:18:06.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 22:50:25.000000000', 'files': ['goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/63d0ab45ea2e92725bcf61799183e4367c50c331', 'message': 'include bindep and cover in the output\n\nChange-Id: I2e502c12e1ca80a96bf7a2c4cf9ec0f085342284\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605546,63d0ab45ea2e92725bcf61799183e4367c50c331,6,2,1,2472,,,0,"include bindep and cover in the output

Change-Id: I2e502c12e1ca80a96bf7a2c4cf9ec0f085342284
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/46/605546/1 && git format-patch -1 --stdout FETCH_HEAD,['goal_tools/python3_first/toxsettings.py'],1,63d0ab45ea2e92725bcf61799183e4367c50c331,python3-first," 'bindep', 'cover',",,2,0
openstack%2Fgoal-tools~master~I82408dd6acb580b3038a0d26b5e0d7a49571a9f3,openstack/goal-tools,master,I82408dd6acb580b3038a0d26b5e0d7a49571a9f3,ignore the infra team for now,MERGED,2018-09-26 22:50:25.000000000,2018-09-27 04:18:06.000000000,2018-09-27 04:18:06.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 22:50:25.000000000', 'files': ['goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/4ba53c0b515d57e93e2c1cc4590b86f8c92fc060', 'message': 'ignore the infra team for now\n\nChange-Id: I82408dd6acb580b3038a0d26b5e0d7a49571a9f3\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605545,4ba53c0b515d57e93e2c1cc4590b86f8c92fc060,6,2,1,2472,,,0,"ignore the infra team for now

Change-Id: I82408dd6acb580b3038a0d26b5e0d7a49571a9f3
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/45/605545/1 && git format-patch -1 --stdout FETCH_HEAD,['goal_tools/python3_first/toxsettings.py'],1,4ba53c0b515d57e93e2c1cc4590b86f8c92fc060,python3-first, if team != 'Infrastructure',,1,0
openstack%2Fnova~master~Ibd44ba9de5680958f55f0ae6325cfc33dabadc4c,openstack/nova,master,Ibd44ba9de5680958f55f0ae6325cfc33dabadc4c,"Revert ""Make host_aggregate_map dictionary case-insensitive""",MERGED,2018-09-24 20:30:47.000000000,2018-09-27 04:11:31.000000000,2018-09-27 04:11:30.000000000,"[{'_account_id': 7}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-24 20:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd5bdf33e0012573d8e3de3d1c9c5162a5084d15', 'message': 'Revert ""Make host_aggregate_map dictionary case-insensitive""\n\nThis reverts commit 2caf8f65e414732fb1ef1ac32a5884a48af6655d.\n\nThe original change caused our host state processing to be inconsistent\nwith our own hypervisors API. Automation tooling that used our API\nto add hosts to aggregates would fail silently. We are reverting\nthis and will propose a check on the aggregate host add action\nwhich will confirm the case-sensitive mapping of the host being\nadded, which is what we should have done in the first place.\n\nChange-Id: Ibd44ba9de5680958f55f0ae6325cfc33dabadc4c\nCloses-Bug: #1793747\n'}, {'number': 2, 'created': '2018-09-25 23:05:39.000000000', 'files': ['nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/c9448cbdbf96e7436b13ac5c3a92addfc0f2f5a2', 'message': 'Revert ""Make host_aggregate_map dictionary case-insensitive""\n\nThis reverts commit 0dc0db932e3ad5ad911f2072015cb9854f6e4e23.\n\nThe original change caused our host state processing to be inconsistent\nwith our own hypervisors API. Automation tooling that used our API\nto add hosts to aggregates would fail silently. We are reverting\nthis and will propose a check on the aggregate host add action\nwhich will confirm the case-sensitive mapping of the host being\nadded, which is what we should have done in the first place.\n\nChange-Id: Ibd44ba9de5680958f55f0ae6325cfc33dabadc4c\nCloses-Bug: #1793747\n'}]",3,604898,c9448cbdbf96e7436b13ac5c3a92addfc0f2f5a2,38,15,2,4393,,,0,"Revert ""Make host_aggregate_map dictionary case-insensitive""

This reverts commit 0dc0db932e3ad5ad911f2072015cb9854f6e4e23.

The original change caused our host state processing to be inconsistent
with our own hypervisors API. Automation tooling that used our API
to add hosts to aggregates would fail silently. We are reverting
this and will propose a check on the aggregate host add action
which will confirm the case-sensitive mapping of the host being
added, which is what we should have done in the first place.

Change-Id: Ibd44ba9de5680958f55f0ae6325cfc33dabadc4c
Closes-Bug: #1793747
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/604898/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/scheduler/test_host_manager.py', 'nova/scheduler/host_manager.py']",2,cd5bdf33e0012573d8e3de3d1c9c5162a5084d15,bug/1709260, self.host_aggregates_map[host].add(agg.id) self.host_aggregates_map[host].remove(aggregate.id) self.host_aggregates_map[host]], self.host_aggregates_map[host.lower()].add(agg.id) self.host_aggregates_map[host.lower()].remove(aggregate.id) self.host_aggregates_map[host.lower()]],3,14
openstack%2Ftripleo-common~stable%2Fqueens~Ieb0e4fc7f05ba9bcae870fa9a5030977cd71a92d,openstack/tripleo-common,stable/queens,Ieb0e4fc7f05ba9bcae870fa9a5030977cd71a92d,Remove container_registry parameter from update workflows,MERGED,2018-09-11 16:23:54.000000000,2018-09-27 04:11:27.000000000,2018-09-27 04:11:27.000000000,"[{'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-11 16:23:54.000000000', 'files': ['workbooks/package_update.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/62711e0c4fed1ba3f232988ffd9435ecad7827c3', 'message': 'Remove container_registry parameter from update workflows\n\nAfter Id2811dbef59d1be2a35cea062eb7116648f52145 removed the parameter\nfrom client, it can be fully removed from the workflow too.\n\nCloses-Bug: #1785825\nChange-Id: Ieb0e4fc7f05ba9bcae870fa9a5030977cd71a92d\nDepends-On: Id2811dbef59d1be2a35cea062eb7116648f52145\n(cherry picked from commit 68b53034e0b0dd9b1881475ede26fac8e474e13f)\n'}]",0,601630,62711e0c4fed1ba3f232988ffd9435ecad7827c3,13,4,1,8297,,,0,"Remove container_registry parameter from update workflows

After Id2811dbef59d1be2a35cea062eb7116648f52145 removed the parameter
from client, it can be fully removed from the workflow too.

Closes-Bug: #1785825
Change-Id: Ieb0e4fc7f05ba9bcae870fa9a5030977cd71a92d
Depends-On: Id2811dbef59d1be2a35cea062eb7116648f52145
(cherry picked from commit 68b53034e0b0dd9b1881475ede26fac8e474e13f)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/30/601630/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/package_update.yaml'],1,62711e0c4fed1ba3f232988ffd9435ecad7827c3,bug/1785825,, - container_registry: '',0,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~I44133b0b0c4367214649777680c94dcfa7bddc76,openstack/tripleo-heat-templates,stable/queens,I44133b0b0c4367214649777680c94dcfa7bddc76,Fix bind-mount to manila's bootstrap container,MERGED,2018-08-22 14:07:14.000000000,2018-09-27 04:11:26.000000000,2018-09-27 04:11:26.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9003}, {'_account_id': 10459}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 16643}, {'_account_id': 20778}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-22 14:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9db743bdc48f73cf4f0540c94076f9f897f8877a', 'message': ""Fix bind-mount to manila's bootstrap container\n\nWhen deploying with tls-everywhere, there are\nmore connection options necessary for the Overcloud\nmanila database bootstrap container to connect\nto mysql. These connection options are present in\nthe configuration folder\n/var/lib/config-data/manila/etc/my.cnf.d/tripleo.cnf.\n\nFix the bind-mounts on the manila_api_db_sync\ncontainer so it doesn't fail to find this\nconfiguration.\n\nCloses-Bug: #1788337\nChange-Id: I44133b0b0c4367214649777680c94dcfa7bddc76\n(cherry picked from commit a4bb5ab1a6e1b981a93c31140d347473ab3483bf)\n""}, {'number': 2, 'created': '2018-08-28 13:05:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c5ab1eb91af35a8f55f741b568faead0d325ab9b', 'message': ""Fix bind-mount to manila's bootstrap container\n\nWhen deploying with tls-everywhere, there are\nmore connection options necessary for the Overcloud\nmanila database bootstrap container to connect\nto mysql. These connection options are present in\nthe configuration folder\n/var/lib/config-data/manila/etc/my.cnf.d/tripleo.cnf.\n\nFix the bind-mounts on the manila_api_db_sync\ncontainer so it doesn't fail to find this\nconfiguration.\n\nCloses-Bug: #1788337\nChange-Id: I44133b0b0c4367214649777680c94dcfa7bddc76\n(cherry picked from commit a4bb5ab1a6e1b981a93c31140d347473ab3483bf)\n""}, {'number': 3, 'created': '2018-09-13 15:46:28.000000000', 'files': ['releasenotes/notes/bug-1788337-fix-manila-db-sync-overcloud-deploy-f323d85509ca81ec.yaml', 'docker/services/manila-api.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3b1c2f135d95798eafbc81fc5699a2fa7c2ae728', 'message': ""Fix bind-mount to manila's bootstrap container\n\nWhen deploying with tls-everywhere, there are\nmore connection options necessary for the Overcloud\nmanila database bootstrap container to connect\nto mysql. These connection options are present in\nthe configuration folder\n/var/lib/config-data/manila/etc/my.cnf.d/tripleo.cnf.\n\nFix the bind-mounts on the manila_api_db_sync\ncontainer so it doesn't fail to find this\nconfiguration.\n\nCloses-Bug: #1788337\nChange-Id: I44133b0b0c4367214649777680c94dcfa7bddc76\n(cherry picked from commit a4bb5ab1a6e1b981a93c31140d347473ab3483bf)\n""}]",0,595014,3b1c2f135d95798eafbc81fc5699a2fa7c2ae728,51,11,3,9003,,,0,"Fix bind-mount to manila's bootstrap container

When deploying with tls-everywhere, there are
more connection options necessary for the Overcloud
manila database bootstrap container to connect
to mysql. These connection options are present in
the configuration folder
/var/lib/config-data/manila/etc/my.cnf.d/tripleo.cnf.

Fix the bind-mounts on the manila_api_db_sync
container so it doesn't fail to find this
configuration.

Closes-Bug: #1788337
Change-Id: I44133b0b0c4367214649777680c94dcfa7bddc76
(cherry picked from commit a4bb5ab1a6e1b981a93c31140d347473ab3483bf)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/14/595014/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/bug-1788337-fix-manila-db-sync-overcloud-deploy-f323d85509ca81ec.yaml', 'docker/services/manila-api.yaml']",2,9db743bdc48f73cf4f0540c94076f9f897f8877a,bug/1788337-stable/queens, - /var/lib/config-data/manila/etc/my.cnf.d/tripleo.cnf:/etc/my.cnf.d/tripleo.cnf:ro,,8,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Ie7a42822be89cced480302d40180b9972d191004,openstack/tripleo-heat-templates,stable/queens,Ie7a42822be89cced480302d40180b9972d191004,Stop cap granting to empty pool when telemetry disabled,MERGED,2018-09-24 10:43:56.000000000,2018-09-27 04:11:24.000000000,2018-09-27 04:11:24.000000000,"[{'_account_id': 6796}, {'_account_id': 21129}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 10:43:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/54639fa46247b46742e06f17fdbe69f3153624f8', 'message': 'Stop cap granting to empty pool when telemetry disabled\n\nAttempt to not create GnocchiRbdPool pool when it is set to empty\nstring [1] resulted in related bug which was not resolved by\noriginally proposed fix [2].\n\n1. https://review.openstack.org/#/c/575571\n2. https://review.openstack.org/#/c/570043\n\nChange-Id: Ie7a42822be89cced480302d40180b9972d191004\nCloses-Bug: 1776987\n'}, {'number': 2, 'created': '2018-09-24 21:20:29.000000000', 'files': ['docker/services/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/17dec684dc0bc64709700ba663fab48e9a50e153', 'message': 'Stop cap granting to empty pool when telemetry disabled\n\nAttempt to not create GnocchiRbdPool pool when it is set to empty\nstring [1] resulted in related bug which was not resolved by\noriginally proposed fix [2].\n\n1. https://review.openstack.org/#/c/575571\n2. https://review.openstack.org/#/c/570043\n\nChange-Id: Ie7a42822be89cced480302d40180b9972d191004\nCloses-Bug: 1776987\n(cherry picked from commit e0b52904c05b8c2df0471f97ebc374af7f51324b)\n'}]",0,604735,17dec684dc0bc64709700ba663fab48e9a50e153,22,4,2,6796,,,0,"Stop cap granting to empty pool when telemetry disabled

Attempt to not create GnocchiRbdPool pool when it is set to empty
string [1] resulted in related bug which was not resolved by
originally proposed fix [2].

1. https://review.openstack.org/#/c/575571
2. https://review.openstack.org/#/c/570043

Change-Id: Ie7a42822be89cced480302d40180b9972d191004
Closes-Bug: 1776987
(cherry picked from commit e0b52904c05b8c2df0471f97ebc374af7f51324b)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/35/604735/2 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/ceph-ansible/ceph-base.yaml'],1,54639fa46247b46742e06f17fdbe69f3153624f8,bug/1776987-stable/queens," - if: - equals: [{get_param: GnocchiRbdPoolName}, ''] - [] - [{get_param: GnocchiRbdPoolName}]", - {get_param: GnocchiRbdPoolName},4,1
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Icf5cf2f7878206329260cc897e2820521a41209e,openstack/tripleo-heat-templates,stable/queens,Icf5cf2f7878206329260cc897e2820521a41209e,Update sample-env-generator files to make it use ceph-ansible,MERGED,2018-09-05 12:14:22.000000000,2018-09-27 04:11:23.000000000,2018-09-27 04:11:23.000000000,"[{'_account_id': 6796}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-05 12:14:22.000000000', 'files': ['sample-env-generator/storage.yaml', 'environments/storage/enable-ceph.yaml', 'environments/storage/external-ceph.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e93748665286695ae172a88fe4e5dd2693a95f1b', 'message': ""Update sample-env-generator files to make it use ceph-ansible\n\nPreviously the old sample-env-generator files where pointing to\nthe puppet-ceph implementation of the Ceph services, which isn't\nsupported in Queens.\n\nChange-Id: Icf5cf2f7878206329260cc897e2820521a41209e\nCloses-Bug: 1790862\n""}]",0,600017,e93748665286695ae172a88fe4e5dd2693a95f1b,29,5,1,6796,,,0,"Update sample-env-generator files to make it use ceph-ansible

Previously the old sample-env-generator files where pointing to
the puppet-ceph implementation of the Ceph services, which isn't
supported in Queens.

Change-Id: Icf5cf2f7878206329260cc897e2820521a41209e
Closes-Bug: 1790862
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/17/600017/1 && git format-patch -1 --stdout FETCH_HEAD,"['sample-env-generator/storage.yaml', 'environments/storage/enable-ceph.yaml', 'environments/storage/external-ceph.yaml']",3,e93748665286695ae172a88fe4e5dd2693a95f1b,bug/1790862,resource_registry: OS::TripleO::Services::CephExternal: ../../docker/services/ceph-ansible/ceph-external.yaml, # The Ceph admin client key. Can be created with ceph-authtool --gen-print-key. # Type: string CephAdminKey: '' # The default features enabled when creating a block device image. Only applies to format 2 images. Set to '1' for Jewel clients using older Ceph servers. # Type: string RbdDefaultFeatures: '' resource_registry: OS::TripleO::Services::CephClient: OS::Heat::None OS::TripleO::Services::CephExternal: ../../puppet/services/ceph-external.yaml OS::TripleO::Services::CephMon: OS::Heat::None OS::TripleO::Services::CephOSD: OS::Heat::None,14,29
openstack%2Ftripleo-heat-templates~stable%2Frocky~I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd,openstack/tripleo-heat-templates,stable/rocky,I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd,Fix syntax for set_fact module.,MERGED,2018-09-24 06:13:00.000000000,2018-09-27 04:07:14.000000000,2018-09-27 04:07:14.000000000,"[{'_account_id': 8042}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2018-09-24 06:13:00.000000000', 'files': ['docker/services/pacemaker/database/redis.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ab9c7b95b1bdf3037d88be9d9d4e90e46d8de0ba', 'message': ""Fix syntax for set_fact module.\n\nFix issue that arise during upgrade:\n error while evaluating conditional (redis_pcs_res|bool):\n  'redis_pcs_res' is undefined\n\nChange-Id: I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd\n(cherry picked from commit 33e49507a53c825554bd9f03c71b02754f5951fc)\n""}]",0,604681,ab9c7b95b1bdf3037d88be9d9d4e90e46d8de0ba,15,5,1,21537,,,0,"Fix syntax for set_fact module.

Fix issue that arise during upgrade:
 error while evaluating conditional (redis_pcs_res|bool):
  'redis_pcs_res' is undefined

Change-Id: I4298eb1ec2fc0e0c44aa63189cff3962fb06c6bd
(cherry picked from commit 33e49507a53c825554bd9f03c71b02754f5951fc)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/81/604681/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/services/pacemaker/database/redis.yaml'],1,ab9c7b95b1bdf3037d88be9d9d4e90e46d8de0ba,redis-typo-fix-stable/rocky," set_fact: redis_pcs_res: ""{{redis_pcs_res_result|succeeded}}"""," set_fact: ""{{redis_pcs_res_result|succeeded}}""",2,1
openstack%2Fpython-tripleoclient~stable%2Focata~Ic86c02c89050510fefd95fafd08db6d77db6e83e,openstack/python-tripleoclient,stable/ocata,Ic86c02c89050510fefd95fafd08db6d77db6e83e,import zuul job settings from project-config,MERGED,2018-08-29 23:57:59.000000000,2018-09-27 04:07:11.000000000,2018-09-27 04:07:11.000000000,"[{'_account_id': 4328}, {'_account_id': 6547}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27427}]","[{'number': 1, 'created': '2018-08-29 23:57:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fd29156c061c0f1ee9f53e73ce51737aac542970', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: Ic86c02c89050510fefd95fafd08db6d77db6e83e\nStory: #2002586\nTask: #24341\n'}, {'number': 2, 'created': '2018-09-14 13:50:28.000000000', 'files': ['tools/tox_install.sh', 'zuul.d/layout.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/90c58aee50a7bbe674a63a3332043d5829e359ad', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: Ic86c02c89050510fefd95fafd08db6d77db6e83e\nStory: #2002586\nTask: #24341\n'}]",0,597801,90c58aee50a7bbe674a63a3332043d5829e359ad,26,6,2,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: Ic86c02c89050510fefd95fafd08db6d77db6e83e
Story: #2002586
Task: #24341
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/01/597801/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,fd29156c061c0f1ee9f53e73ce51737aac542970,python3-first, - openstack-python-jobs - openstack-python35-jobs - check-requirements - openstackclient-plugin-jobs - release-notes-jobs - publish-openstack-sphinx-docs,,6,1
openstack%2Fpaunch~stable%2Fpike~I4e09e021759e9d396ca42fcfca14e38ba239f8e1,openstack/paunch,stable/pike,I4e09e021759e9d396ca42fcfca14e38ba239f8e1,import zuul job settings from project-config,MERGED,2018-08-29 23:58:46.000000000,2018-09-27 04:07:09.000000000,2018-09-27 04:07:09.000000000,"[{'_account_id': 6547}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-29 23:58:46.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/paunch/commit/8034b44480c245f5c324134f92601decebe0c314', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I4e09e021759e9d396ca42fcfca14e38ba239f8e1\nStory: #2002586\nTask: #24341\n'}]",0,597814,8034b44480c245f5c324134f92601decebe0c314,23,4,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I4e09e021759e9d396ca42fcfca14e38ba239f8e1
Story: #2002586
Task: #24341
",git fetch https://review.opendev.org/openstack/paunch refs/changes/14/597814/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,8034b44480c245f5c324134f92601decebe0c314,python3-first, - check-requirements - publish-openstack-sphinx-docs - openstack-python-jobs - release-notes-jobs,,4,1
openstack%2Fos-net-config~stable%2Focata~I3dbc5debe5459cb4f2e19f608d6e1777b6b4504d,openstack/os-net-config,stable/ocata,I3dbc5debe5459cb4f2e19f608d6e1777b6b4504d,import zuul job settings from project-config,MERGED,2018-08-29 23:57:48.000000000,2018-09-27 04:07:07.000000000,2018-09-27 04:07:07.000000000,"[{'_account_id': 4328}, {'_account_id': 6547}, {'_account_id': 10873}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-29 23:57:48.000000000', 'files': ['zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/os-net-config/commit/6429384f23244a6ebe11c4e48dfa50b963b1aa87', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I3dbc5debe5459cb4f2e19f608d6e1777b6b4504d\nStory: #2002586\nTask: #24341\n'}]",0,597798,6429384f23244a6ebe11c4e48dfa50b963b1aa87,17,5,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I3dbc5debe5459cb4f2e19f608d6e1777b6b4504d
Story: #2002586
Task: #24341
",git fetch https://review.opendev.org/openstack/os-net-config refs/changes/98/597798/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/layout.yaml'],1,6429384f23244a6ebe11c4e48dfa50b963b1aa87,python3-first, - check-requirements - openstack-python-jobs - release-notes-jobs check: jobs: - openstack-tox-py35 - openstack-tox-cover: voting: false gate: queue: tripleo jobs: - openstack-tox-py35,,12,1
openstack%2Fpython-tripleoclient~stable%2Frocky~Ica28227b011255c23e677539c5e3df33f556e1b7,openstack/python-tripleoclient,stable/rocky,Ica28227b011255c23e677539c5e3df33f556e1b7,Properly mock unlink,MERGED,2018-09-25 10:58:39.000000000,2018-09-27 04:07:06.000000000,2018-09-27 04:07:05.000000000,"[{'_account_id': 6926}, {'_account_id': 10873}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-25 10:58:39.000000000', 'files': ['tripleoclient/tests/test_utils.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2565aef537cd32c32d08163c8c4fe52c945fae44', 'message': ""Properly mock unlink\n\nI5de4d68cc2669d37e7a667209423b9ac842136ff added these tests but did not\nproperly mock the unlink that can be triggered. This change mocks the\nos.unlink so it doesn't try to remove our mocked file when the tests\nrun.\n\nCo-authored-by: Sergii Golovatiuk <sgolovat@redhat.com>\n\nChange-Id: Ica28227b011255c23e677539c5e3df33f556e1b7\nCloses-Bug: #1789506\n(cherry picked from commit 6e6ad0a8cea3eebe7c4ebfba01b3d7d12384f2d4)\n""}]",0,605038,2565aef537cd32c32d08163c8c4fe52c945fae44,9,5,1,12393,,,0,"Properly mock unlink

I5de4d68cc2669d37e7a667209423b9ac842136ff added these tests but did not
properly mock the unlink that can be triggered. This change mocks the
os.unlink so it doesn't try to remove our mocked file when the tests
run.

Co-authored-by: Sergii Golovatiuk <sgolovat@redhat.com>

Change-Id: Ica28227b011255c23e677539c5e3df33f556e1b7
Closes-Bug: #1789506
(cherry picked from commit 6e6ad0a8cea3eebe7c4ebfba01b3d7d12384f2d4)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/38/605038/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/test_utils.py'],1,2565aef537cd32c32d08163c8c4fe52c945fae44,bug/1789506-stable/rocky, self.unlink_patch = mock.patch('os.unlink') self.addCleanup(self.unlink_patch.stop) self.unlink_patch.start(),,3,0
openstack%2Finstack-undercloud~master~Ic6175d8ecb63184b6597a9cdcdd6604f13e1b32d,openstack/instack-undercloud,master,Ic6175d8ecb63184b6597a9cdcdd6604f13e1b32d,Use templates for cover and lower-constraints,MERGED,2018-09-22 15:44:32.000000000,2018-09-27 04:07:05.000000000,2018-09-27 04:07:04.000000000,"[{'_account_id': 6547}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-22 15:44:32.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/instack-undercloud/commit/65fa3f9f1bae7081e7f64098ee68fee81fdec518', 'message': 'Use templates for cover and lower-constraints\n\nSmall cleanups:\n\n* Use openstack-tox-cover template, this runs the cover job\n  in the check queue only. Remove individual cover jobs.\n* Use openstack-lower-constraints-jobs template, remove individual\n  jobs.\n* Sort list of templates\n\nChange-Id: Ic6175d8ecb63184b6597a9cdcdd6604f13e1b32d\n'}]",0,604536,65fa3f9f1bae7081e7f64098ee68fee81fdec518,15,5,1,6547,,,0,"Use templates for cover and lower-constraints

Small cleanups:

* Use openstack-tox-cover template, this runs the cover job
  in the check queue only. Remove individual cover jobs.
* Use openstack-lower-constraints-jobs template, remove individual
  jobs.
* Sort list of templates

Change-Id: Ic6175d8ecb63184b6597a9cdcdd6604f13e1b32d
",git fetch https://review.opendev.org/openstack/instack-undercloud refs/changes/36/604536/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,65fa3f9f1bae7081e7f64098ee68fee81fdec518,update-zuul, - check-requirements - openstack-cover-jobs - openstack-lower-constraints-jobs, - check-requirements check: jobs: - openstack-tox-lower-constraints - openstack-tox-cover: voting: false gate: jobs: - openstack-tox-lower-constraints,3,10
openstack%2Fopenstack-ansible-rsyslog_server~master~I7fd9a47ba0c0bde2743636e27b2af2e6cb063395,openstack/openstack-ansible-rsyslog_server,master,I7fd9a47ba0c0bde2743636e27b2af2e6cb063395,add the project source code repository,MERGED,2018-09-07 01:30:07.000000000,2018-09-27 03:54:30.000000000,2018-09-27 03:54:30.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:30:07.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/2802e6db70eb50966ae1b04af70db1a30ec0a151', 'message': 'add the project source code repository\n\nChange-Id: I7fd9a47ba0c0bde2743636e27b2af2e6cb063395\n'}]",0,600598,2802e6db70eb50966ae1b04af70db1a30ec0a151,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I7fd9a47ba0c0bde2743636e27b2af2e6cb063395
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/98/600598/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,2802e6db70eb50966ae1b04af70db1a30ec0a151,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-rsyslog_server/ The project home is at: https://launchpad.net/openstack-ansible/,The project home is at: https://launchpad.net/openstack-ansible,4,1
openstack%2Fopenstack-ansible-rsyslog_server~master~I042256b23e4b3ba4bdd7f55cfbcd2e0515e7fe31,openstack/openstack-ansible-rsyslog_server,master,I042256b23e4b3ba4bdd7f55cfbcd2e0515e7fe31,Add the project source code repository in README,MERGED,2018-07-20 04:48:12.000000000,2018-09-27 03:54:29.000000000,2018-09-27 03:54:29.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-07-20 04:48:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/1892126c1de9b09b7c57c018bba93d1cb2e7fa0c', 'message': 'Add the project source code repository in README\n\nChange-Id: I042256b23e4b3ba4bdd7f55cfbcd2e0515e7fe31\n'}, {'number': 2, 'created': '2018-07-20 04:50:40.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_server/commit/f243aab11e96a3fae99c03ff8f8cc43e72aad3c1', 'message': 'Add the project source code repository in README\n\nChange-Id: I042256b23e4b3ba4bdd7f55cfbcd2e0515e7fe31\n'}]",1,584221,f243aab11e96a3fae99c03ff8f8cc43e72aad3c1,12,5,2,14151,,,0,"Add the project source code repository in README

Change-Id: I042256b23e4b3ba4bdd7f55cfbcd2e0515e7fe31
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_server refs/changes/21/584221/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1892126c1de9b09b7c57c018bba93d1cb2e7fa0c,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-rsyslog_server/ ,,3,0
openstack%2Fkolla-ansible~master~Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4,openstack/kolla-ansible,master,Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4,Add support for Cells v2 rabbitmq servers,NEW,2018-05-17 18:44:10.000000000,2018-09-27 03:54:23.000000000,,"[{'_account_id': 6488}, {'_account_id': 7488}, {'_account_id': 10273}, {'_account_id': 14119}, {'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 19316}, {'_account_id': 21691}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28250}]","[{'number': 1, 'created': '2018-05-17 18:44:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e79530bce276105dc66dc92883fc835e788b590f', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq clusters grouped in the\ninventory. This gives users the ability to configure those by making use\nof include_role per cell. Eventually the cells variable will also be\nuseful for initializing all of the cells with their configuration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 2, 'created': '2018-05-17 21:04:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4ba3a5a3f012035db1b4592ffabd0fd51299a556', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq clusters grouped in the\ninventory. This gives users the ability to configure those by making use\nof include_role per cell. Eventually the cells variable will also be\nuseful for initializing all of the cells with their configuration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 3, 'created': '2018-05-31 07:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5a627ba331dbf4c307699d2761847df23b2f5075', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 4, 'created': '2018-07-02 22:11:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2a12955b10c7d687720c6b4a2d92d0ebf8bba2dc', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 5, 'created': '2018-07-02 22:17:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1018be3a35123aec61c4e5f25681965632810702', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 6, 'created': '2018-07-16 17:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bd069d53e359bd913d95a6cb6e1434fd0d36ff58', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 7, 'created': '2018-07-16 17:57:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c91ad3c11ee38b89a523eb734e14875265fda3cc', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 8, 'created': '2018-07-16 21:02:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5c944ccd4bc04d9895f150564aa83eaf697ab746', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 9, 'created': '2018-07-16 21:09:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/69384f105fc6c9e698e99904f7dee3ff3d123ee0', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 10, 'created': '2018-07-17 23:03:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/80882bca893add68690c8326374c299a95b35026', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 11, 'created': '2018-07-20 08:56:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/67ec955506fa5dc60650ddfa1e956b1a7d5ef78b', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 12, 'created': '2018-07-23 09:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d0e6b5483efbfd7a278ef29c3b33cf4e40a90b62', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 13, 'created': '2018-07-30 17:28:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0aad8babd945e809494e9b7872af3acb6ce5495c', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 14, 'created': '2018-08-03 20:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d0ab4dfb19d011e8aa36c0c02e7394189e71e054', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 15, 'created': '2018-08-21 12:59:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/21ec5b9d2118dfe7f531095e3f98651a214791b8', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 16, 'created': '2018-08-28 06:45:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4df100ef4e25828530e9b7e6f81acdb02c7402af', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 17, 'created': '2018-09-17 22:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e73dc671e73cae1d9ca200c990a9b9d89d8e5037', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 18, 'created': '2018-09-20 23:07:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9ea4c793322222c603ca0c0a551b29ad2af69d1c', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}, {'number': 19, 'created': '2018-09-26 19:43:43.000000000', 'files': ['ansible/inventory/multinode', 'ansible/roles/cell-rabbitmq/tasks/main.yml', 'ansible/group_vars/all.yml', 'ansible/site.yml', 'ansible/inventory/all-in-one'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1642e6424e11db6562a05f13eb71d270db7bf9cc', 'message': 'Add support for Cells v2 rabbitmq servers\n\nIn cells v2, there will be n number of rabbitmq configurations grouped\nin the inventory. This gives users the ability to configure those by\nmaking use of include_role per cell. Eventually the cells variable will\nalso be useful for initializing all of the cells with their\nconfiguration.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nImplements: blueprint cellsv2-rabbitmq-support\n\nChange-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4\n'}]",13,569219,1642e6424e11db6562a05f13eb71d270db7bf9cc,55,11,19,6488,,,0,"Add support for Cells v2 rabbitmq servers

In cells v2, there will be n number of rabbitmq configurations grouped
in the inventory. This gives users the ability to configure those by
making use of include_role per cell. Eventually the cells variable will
also be useful for initializing all of the cells with their
configuration.

Co-Authored-By: Adam Harwell <flux.adam@gmail.com>
Implements: blueprint cellsv2-rabbitmq-support

Change-Id: Ib5fe2aeeb2a6997cef327ad5ae4af6d1f07131b4
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/19/569219/19 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/inventory/multinode', 'ansible/roles/cell-rabbitmq/tasks/main.yml', 'ansible/group_vars/all.yml', 'ansible/site.yml', 'ansible/inventory/all-in-one']",5,e79530bce276105dc66dc92883fc835e788b590f,cell-rabbitmq,[cells-rabbitmq] ,,38,0
openstack%2Frally~master~I7a35debd44da6844b8e8626b34aaad23e3092dfb,openstack/rally,master,I7a35debd44da6844b8e8626b34aaad23e3092dfb,build universal wheels,MERGED,2018-09-26 21:27:29.000000000,2018-09-27 03:52:43.000000000,2018-09-27 03:52:43.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 21:27:29.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/rally/commit/f606f72fb53dc146e1546642a13ebabe489c66f6', 'message': 'build universal wheels\n\nBuild wheels that can be installed under python 2 and 3.\n\nChange-Id: I7a35debd44da6844b8e8626b34aaad23e3092dfb\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605537,f606f72fb53dc146e1546642a13ebabe489c66f6,6,2,1,2472,,,0,"build universal wheels

Build wheels that can be installed under python 2 and 3.

Change-Id: I7a35debd44da6844b8e8626b34aaad23e3092dfb
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/rally refs/changes/37/605537/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,f606f72fb53dc146e1546642a13ebabe489c66f6,universal-wheels, [wheel] universal = 1,,3,0
openstack%2Fopenstack-ansible-os_barbican~master~I48d15756c8259297ce04c9a5656bc461b7221350,openstack/openstack-ansible-os_barbican,master,I48d15756c8259297ce04c9a5656bc461b7221350,SUSE: Add support for openSUSE Leap 15,MERGED,2018-09-26 10:54:36.000000000,2018-09-27 03:49:36.000000000,2018-09-27 03:49:35.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-26 10:54:36.000000000', 'files': ['zuul.d/project.yaml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/c9c4bb78fec014ef6c41f7d876050ca2df46b7a7', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: I48d15756c8259297ce04c9a5656bc461b7221350\n'}]",0,605393,c9c4bb78fec014ef6c41f7d876050ca2df46b7a7,7,3,1,23163,,,0,"SUSE: Add support for openSUSE Leap 15

Change-Id: I48d15756c8259297ce04c9a5656bc461b7221350
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/93/605393/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'meta/main.yml']",2,c9c4bb78fec014ef6c41f7d876050ca2df46b7a7,osa-add-leap-150, - all, - 42.3,3,1
openstack%2Fopenstack-ansible-os_barbican~master~Ia79f8eb2f80fac7554d97cd9319c03d19f6f3564,openstack/openstack-ansible-os_barbican,master,Ia79f8eb2f80fac7554d97cd9319c03d19f6f3564,Add the project source code repository in README,MERGED,2018-07-20 05:05:26.000000000,2018-09-27 03:49:36.000000000,2018-09-27 03:49:36.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-07-20 05:05:26.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_barbican/commit/62867c7f023561bde28ef1ff776b1f5f333df6d4', 'message': 'Add the project source code repository in README\n\nChange-Id: Ia79f8eb2f80fac7554d97cd9319c03d19f6f3564\n'}]",0,584225,62867c7f023561bde28ef1ff776b1f5f333df6d4,10,5,1,14151,,,0,"Add the project source code repository in README

Change-Id: Ia79f8eb2f80fac7554d97cd9319c03d19f6f3564
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_barbican refs/changes/25/584225/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,62867c7f023561bde28ef1ff776b1f5f333df6d4,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_barbican/ ,,3,0
openstack%2Fopenstack-ansible-os_masakari~master~I5c1323875b132c72a67619bed9a18f9d6c44e3a4,openstack/openstack-ansible-os_masakari,master,I5c1323875b132c72a67619bed9a18f9d6c44e3a4,add the project source code repository,MERGED,2018-09-07 02:11:44.000000000,2018-09-27 03:45:05.000000000,2018-09-27 03:45:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:11:44.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/775158afb6f516c9eeb051706a8a58786ea5a734', 'message': 'add the project source code repository\n\nChange-Id: I5c1323875b132c72a67619bed9a18f9d6c44e3a4\n'}]",0,600611,775158afb6f516c9eeb051706a8a58786ea5a734,8,4,1,27385,,,0,"add the project source code repository

Change-Id: I5c1323875b132c72a67619bed9a18f9d6c44e3a4
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/11/600611/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,775158afb6f516c9eeb051706a8a58786ea5a734,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_masakari/ ,,3,0
openstack%2Fopenstack-ansible-os_masakari~master~I1c6fed57368620213de85dc5948e63b72c5114df,openstack/openstack-ansible-os_masakari,master,I1c6fed57368620213de85dc5948e63b72c5114df,Add source code information to readme,MERGED,2018-09-05 06:45:41.000000000,2018-09-27 03:45:04.000000000,2018-09-27 03:45:04.000000000,"[{'_account_id': 7353}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-09-05 06:45:41.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/ddadb0879deef6a486da099c0212e23c3816acc5', 'message': 'Add source code information to readme\n\nChange-Id: I1c6fed57368620213de85dc5948e63b72c5114df\n'}]",0,599934,ddadb0879deef6a486da099c0212e23c3816acc5,8,4,1,26490,,,0,"Add source code information to readme

Change-Id: I1c6fed57368620213de85dc5948e63b72c5114df
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/34/599934/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ddadb0879deef6a486da099c0212e23c3816acc5,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_masakari/ ,,3,0
openstack%2Fopenstack-ansible-os_masakari~master~I69300e4349d2baabdd2687dcbab6119978b7ad19,openstack/openstack-ansible-os_masakari,master,I69300e4349d2baabdd2687dcbab6119978b7ad19,Add the project source code repository in README,MERGED,2018-07-28 12:40:02.000000000,2018-09-27 03:45:04.000000000,2018-09-27 03:45:04.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 12:40:02.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/ece0a6a211589494d6cb9708615554949b0e99c6', 'message': 'Add the project source code repository in README\n\nChange-Id: I69300e4349d2baabdd2687dcbab6119978b7ad19\n'}]",0,586790,ece0a6a211589494d6cb9708615554949b0e99c6,10,6,1,14320,,,0,"Add the project source code repository in README

Change-Id: I69300e4349d2baabdd2687dcbab6119978b7ad19
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/90/586790/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ece0a6a211589494d6cb9708615554949b0e99c6,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_masakari/ ,,3,0
openstack%2Fopenstack-ansible-os_masakari~master~I76a08c5637d427a79d2b7390c1ee0154f44115d6,openstack/openstack-ansible-os_masakari,master,I76a08c5637d427a79d2b7390c1ee0154f44115d6,Drop un-used packages from role,MERGED,2018-09-07 07:56:18.000000000,2018-09-27 03:45:03.000000000,2018-09-27 03:45:03.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-07 07:56:18.000000000', 'files': ['vars/ubuntu.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_masakari/commit/11f71099292ecb4b58a7acf152531eb2f87c0ebf', 'message': 'Drop un-used packages from role\n\nChange-Id: I76a08c5637d427a79d2b7390c1ee0154f44115d6\n'}]",0,600670,11f71099292ecb4b58a7acf152531eb2f87c0ebf,8,3,1,21486,,,0,"Drop un-used packages from role

Change-Id: I76a08c5637d427a79d2b7390c1ee0154f44115d6
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_masakari refs/changes/70/600670/1 && git format-patch -1 --stdout FETCH_HEAD,['vars/ubuntu.yml'],1,11f71099292ecb4b58a7acf152531eb2f87c0ebf,,, - rpcbind - rsync ,0,2
openstack%2Fopenstack-ansible-tests~master~Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b,openstack/openstack-ansible-tests,master,Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b,"tests-ansible-env-prep: Fix plugin, tests and ops testing on Vagrant",MERGED,2018-08-16 14:58:41.000000000,2018-09-27 03:42:21.000000000,2018-09-27 03:42:21.000000000,"[{'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-08-16 14:58:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/fdcc03426699e114b90268e21b3cbe54c5538437', 'message': ""tests-ansible-env-prep: Fix plugin and ops testing on Vagrant\n\nOur Vagrantfile is rsync'ing the role to /vagrant. This breaks the\nrole test since the $WORKING_DIR no longer matches the name of the\nOSA project. As such, when we are using vagrant to test the plugins\nand ops repositories we end up using the HEAD of plugins and ops\nrepositories instead of our local copy. We fix this by introducing a\nnew OSA_PROJECT_NAME and then we test against this to determine the\nactual OSA project we are testing\n\nChange-Id: Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b\n""}, {'number': 2, 'created': '2018-08-16 15:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/a4fdd1aaee6674df66a0c28a4b3b49000889a090', 'message': ""tests-ansible-env-prep: Fix plugin, tests and ops testing on Vagrant\n\nOur Vagrantfile is rsync'ing the role to /vagrant. This breaks the\nrole test since the $WORKING_DIR no longer matches the name of the\nOSA project. As such, when we are using vagrant to test the plugins\ntests and ops repositories we end up using the HEAD of the repositories\ninstead of our local copy. We fix this by introducing a new\nOSA_PROJECT_NAME and then we test against this to determine the actual\nOSA project we are testing\n\nChange-Id: Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b\n""}, {'number': 3, 'created': '2018-08-17 12:36:57.000000000', 'files': ['run_tests.sh', 'test-ansible-env-prep.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-tests/commit/0aeb045fb0a06d13e2280786bb881c069afeed6f', 'message': ""tests-ansible-env-prep: Fix plugin, tests and ops testing on Vagrant\n\nOur Vagrantfile is rsync'ing the role to /vagrant. This breaks the\nrole test since the $WORKING_DIR no longer matches the name of the\nOSA project. As such, when we are using vagrant to test the plugins\ntests and ops repositories we end up using the HEAD of the repositories\ninstead of our local copy. We fix this by introducing a new\nOSA_PROJECT_NAME and then we test against this to determine the actual\nOSA project we are testing\n\nChange-Id: Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b\n""}]",1,592527,0aeb045fb0a06d13e2280786bb881c069afeed6f,15,4,3,23163,,,0,"tests-ansible-env-prep: Fix plugin, tests and ops testing on Vagrant

Our Vagrantfile is rsync'ing the role to /vagrant. This breaks the
role test since the $WORKING_DIR no longer matches the name of the
OSA project. As such, when we are using vagrant to test the plugins
tests and ops repositories we end up using the HEAD of the repositories
instead of our local copy. We fix this by introducing a new
OSA_PROJECT_NAME and then we test against this to determine the actual
OSA project we are testing

Change-Id: Ic8b99b4f2d241144e1200ddf7c33742e9bc91c5b
",git fetch https://review.opendev.org/openstack/openstack-ansible-tests refs/changes/27/592527/2 && git format-patch -1 --stdout FETCH_HEAD,['test-ansible-env-prep.sh'],1,fdcc03426699e114b90268e21b3cbe54c5538437,fix-plugin-vagrant-test,"export OSA_PROJECT_NAME=""$(grep project= $(pwd)/.gitreview | cut -d '/' -f 2 | sed 's/.git//')"" if [[ ""${OSA_PROJECT_NAME}"" == ""openstack-ansible-plugins"" ]]; then if [[ ""${OSA_PROJECT_DIR}"" == ""openstack-ansible-ops"" ]]; then"," if [[ ""$(basename ${WORKING_DIR})"" == ""openstack-ansible-plugins"" ]]; then if [[ ""$(basename ${WORKING_DIR})"" == ""openstack-ansible-ops"" ]]; then",3,2
openstack%2Fgoal-tools~master~Ia53fef73d67604d86b9a9d1d41364ed2f80cb260,openstack/goal-tools,master,Ia53fef73d67604d86b9a9d1d41364ed2f80cb260,add tool to show incorrect tox settings,MERGED,2018-09-26 21:22:04.000000000,2018-09-27 03:42:20.000000000,2018-09-27 03:42:20.000000000,"[{'_account_id': 2472}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 21:22:04.000000000', 'files': ['setup.cfg', 'goal_tools/python3_first/toxsettings.py'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/b6fd3ce42d9ac394c3e1570b715c8a760f8c85d0', 'message': ""add tool to show incorrect tox settings\n\nLook at the tox settings for the repos and report any that ought to be\nusing python3 that aren't.\n\nChange-Id: Ia53fef73d67604d86b9a9d1d41364ed2f80cb260\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,605536,b6fd3ce42d9ac394c3e1570b715c8a760f8c85d0,6,2,1,2472,,,0,"add tool to show incorrect tox settings

Look at the tox settings for the repos and report any that ought to be
using python3 that aren't.

Change-Id: Ia53fef73d67604d86b9a9d1d41364ed2f80cb260
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/36/605536/1 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'goal_tools/python3_first/toxsettings.py']",2,b6fd3ce42d9ac394c3e1570b715c8a760f8c85d0,python3-first,"#!/usr/bin/env python3 import configparser import logging import os.path import subprocess from goal_tools import governance from cliff import lister LOG = logging.getLogger(__name__) ENVS = [ 'docs', 'linters', 'lower-constraints', 'pep8', 'releasenotes', 'venv' ] def get_tox_config(repo_dir): LOG.debug('getting tox settings in %s', repo_dir) try: result = subprocess.run( ['tox', '--showconfig'], check=True, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL, cwd=repo_dir, ) except subprocess.CalledProcessError: LOG.info('unable to fetch tox settings for %s', repo_dir) return None text = result.stdout.decode('utf-8') # The preamble of the output is not INI format, # so we skip over it by looking for a double blank line. return text.partition('\n\n')[-1] def check_one(repo_base_dir, repo): repo_dir = os.path.join(os.path.expanduser(repo_base_dir), repo) if not os.path.exists(os.path.join(repo_dir, 'tox.ini')): LOG.info('skipping %s', repo) return LOG.info('scanning %s', repo) config = get_tox_config(repo_dir) LOG.debug(config) if config is None: return parser = configparser.ConfigParser() parser.read_string(config, repo) for env in ENVS: section = 'testenv:{}'.format(env) if not parser.has_section(section): LOG.debug('%s has no section %s', repo, section) continue if not parser.has_option(section, 'basepython'): yield (section, 'not set') continue value = parser.get(section, 'basepython') if 'python3' not in value: yield (section, 'set to {!r}'.format(value)) continue yield (section, 'OK') class ToxMissingPy3(lister.Lister): ""list the tox environments missing python3 settings"" def get_parser(self, prog_name): parser = super().get_parser(prog_name) parser.add_argument( '--repo-base-dir', default='~/repos', help='base directory where repositories are cloned (%(default)s)', ) parser.add_argument( '--project-list', default=governance.PROJECTS_LIST, help='URL for governance projects.yaml', ) parser.add_argument( '--team', help='limit search to one team', ) parser.add_argument( '--errors-only', '-e', default=False, action='store_true', help='only show mistakes', ) return parser def take_action(self, parsed_args): columns = ('Team', 'Repo', 'Env', 'Status') gov_dat = governance.Governance(url=parsed_args.project_list) if parsed_args.team: repos = gov_dat.get_repos_for_team(parsed_args.team) else: repos = gov_dat.get_repos() teams_and_repos = sorted( (gov_dat.get_repo_owner(r), r) for r in repos ) data = [ (team, r, env, status) for team, r in teams_and_repos for env, status in check_one(parsed_args.repo_base_dir, r) ] if parsed_args.errors_only: data = [ r for r in data if r[-1] != 'OK' ] return (columns, data) ",,125,0
openstack%2Fopenstack-ansible-os_ceilometer~master~Ieabebf214753733d4762756f1c51c1e2c71ab658,openstack/openstack-ansible-os_ceilometer,master,Ieabebf214753733d4762756f1c51c1e2c71ab658,[Trivial Fix] Replace Chinese punctuation with English punctuation,MERGED,2018-09-10 02:46:16.000000000,2018-09-27 03:40:06.000000000,2018-09-27 03:40:06.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-09-10 02:46:16.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/1beca3d1e327af3ec98329527a850369d30c1242', 'message': '[Trivial Fix] Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input method.\nWhen read from english context, it makes some confusion.\n\nChange-Id: Ieabebf214753733d4762756f1c51c1e2c71ab658\n'}]",0,601146,1beca3d1e327af3ec98329527a850369d30c1242,7,3,1,28842,,,0,"[Trivial Fix] Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input method.
When read from english context, it makes some confusion.

Change-Id: Ieabebf214753733d4762756f1c51c1e2c71ab658
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/46/601146/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,1beca3d1e327af3ec98329527a850369d30c1242,," * If the issue is a bug that needs fixing in a branch other than Master, add the 'backport potential' tag TO THE ISSUE (not the PR)."," * If the issue is a bug that needs fixing in a branch other than Master, add the backport potential tag TO THE ISSUE (not the PR).",1,1
openstack%2Fopenstack-ansible-os_ceilometer~master~Ie7349d6f76d8ff6f1fa713bfeb5bfc3385a78513,openstack/openstack-ansible-os_ceilometer,master,Ie7349d6f76d8ff6f1fa713bfeb5bfc3385a78513,SUSE: Add support for openSUSE Leap 15,MERGED,2018-09-26 10:57:32.000000000,2018-09-27 03:40:05.000000000,2018-09-27 03:40:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-26 10:57:32.000000000', 'files': ['zuul.d/project.yaml', 'meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_ceilometer/commit/152bf823c7ba2815b06e48178ad0ca1ac18906a0', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: Ie7349d6f76d8ff6f1fa713bfeb5bfc3385a78513\n'}]",0,605395,152bf823c7ba2815b06e48178ad0ca1ac18906a0,7,3,1,23163,,,0,"SUSE: Add support for openSUSE Leap 15

Change-Id: Ie7349d6f76d8ff6f1fa713bfeb5bfc3385a78513
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_ceilometer refs/changes/95/605395/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'meta/main.yml']",2,152bf823c7ba2815b06e48178ad0ca1ac18906a0,osa-add-leap-150, - all, - 42.1 - 42.2 - 42.3,3,3
openstack%2Fopenstack-ansible-os_zaqar~master~I9969b267a35525623d4a6e534c3241d5351fba32,openstack/openstack-ansible-os_zaqar,master,I9969b267a35525623d4a6e534c3241d5351fba32,add the project source code repository,MERGED,2018-09-07 01:13:19.000000000,2018-09-27 03:39:23.000000000,2018-09-27 03:39:22.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 26775}]","[{'number': 1, 'created': '2018-09-07 01:13:19.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zaqar/commit/7728411368690deac740066802724ad6b9f30f57', 'message': 'add the project source code repository\n\nChange-Id: I9969b267a35525623d4a6e534c3241d5351fba32\n'}]",0,600595,7728411368690deac740066802724ad6b9f30f57,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I9969b267a35525623d4a6e534c3241d5351fba32
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zaqar refs/changes/95/600595/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,7728411368690deac740066802724ad6b9f30f57,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_zaqar/ ,,3,0
openstack%2Fopenstack-ansible-os_zaqar~master~Id60027322c305b74be161e0174a5b9ece0890e22,openstack/openstack-ansible-os_zaqar,master,Id60027322c305b74be161e0174a5b9ece0890e22,Trivial: Fix the pep8 warning,MERGED,2018-08-06 07:59:20.000000000,2018-09-27 03:39:22.000000000,2018-09-27 03:39:22.000000000,"[{'_account_id': 7353}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 26285}]","[{'number': 1, 'created': '2018-08-06 07:59:20.000000000', 'files': ['os-zaqar-install.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_zaqar/commit/3f65bb632d14947aab6d702aaf9eda691430a134', 'message': 'Trivial: Fix the pep8 warning\n\nThe yaml should start with ""---""\n\nChange-Id: Id60027322c305b74be161e0174a5b9ece0890e22\n'}]",0,589062,3f65bb632d14947aab6d702aaf9eda691430a134,11,4,1,21486,,,0,"Trivial: Fix the pep8 warning

The yaml should start with ""---""

Change-Id: Id60027322c305b74be161e0174a5b9ece0890e22
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_zaqar refs/changes/62/589062/1 && git format-patch -1 --stdout FETCH_HEAD,['os-zaqar-install.yml'],1,3f65bb632d14947aab6d702aaf9eda691430a134,,---,,1,0
openstack%2Fopenstack-ansible-rabbitmq_server~master~I4fd442fe422e937f7414def763f24468ad56f2df,openstack/openstack-ansible-rabbitmq_server,master,I4fd442fe422e937f7414def763f24468ad56f2df,add the project source code repository,MERGED,2018-09-07 01:36:26.000000000,2018-09-27 03:27:30.000000000,2018-09-27 03:27:30.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 26775}]","[{'number': 1, 'created': '2018-09-07 01:36:26.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/db591149ce8b838693c423cf49287a2715e43cc5', 'message': 'add the project source code repository\n\nChange-Id: I4fd442fe422e937f7414def763f24468ad56f2df\n'}]",0,600601,db591149ce8b838693c423cf49287a2715e43cc5,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I4fd442fe422e937f7414def763f24468ad56f2df
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/01/600601/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,db591149ce8b838693c423cf49287a2715e43cc5,update_doc, https://docs.openstack.org/openstack-ansible-rabbitmq_server/latest/ https://docs.openstack.org/releasenotes/openstack-ansible-rabbitmq_server/ The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-rabbitmq_server/ https://launchpad.net/openstack-ansible/, https://docs.openstack.org/openstack-ansible-rabbitmq_server/latest https://docs.openstack.org/releasenotes/openstack-ansible-rabbitmq_server https://launchpad.net/openstack-ansible,6,3
openstack%2Fopenstack-ansible-rabbitmq_server~master~Ia953788e26527c0eb2f256cca405120f69a90918,openstack/openstack-ansible-rabbitmq_server,master,Ia953788e26527c0eb2f256cca405120f69a90918,Add the project source code repository in README,MERGED,2018-07-28 14:29:31.000000000,2018-09-27 03:27:29.000000000,2018-09-27 03:27:29.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 14:29:31.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/d31a5865efb3ddb3544b00aa33b5bb4f293976da', 'message': 'Add the project source code repository in README\n\nChange-Id: Ia953788e26527c0eb2f256cca405120f69a90918\n'}]",0,586805,d31a5865efb3ddb3544b00aa33b5bb4f293976da,10,6,1,14320,,,0,"Add the project source code repository in README

Change-Id: Ia953788e26527c0eb2f256cca405120f69a90918
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/05/586805/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d31a5865efb3ddb3544b00aa33b5bb4f293976da,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-rabbitmq_server/ ,,3,0
openstack%2Fopenstack-ansible-lxc_hosts~master~I843367fa42f55f4ddf61062c931900fb818dd16a,openstack/openstack-ansible-lxc_hosts,master,I843367fa42f55f4ddf61062c931900fb818dd16a,add the project source code repository,MERGED,2018-09-07 02:42:31.000000000,2018-09-27 03:27:05.000000000,2018-09-27 03:27:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:42:31.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/ad632302aba472c25d68808c76ec3aa8ea438c2b', 'message': 'add the project source code repository\n\nChange-Id: I843367fa42f55f4ddf61062c931900fb818dd16a\n'}]",0,600620,ad632302aba472c25d68808c76ec3aa8ea438c2b,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I843367fa42f55f4ddf61062c931900fb818dd16a
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/20/600620/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,ad632302aba472c25d68808c76ec3aa8ea438c2b,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-lxc_hosts/ ,,3,0
openstack%2Fopenstack-ansible-repo_server~master~I765783bc322266bc20e85873482231e64a19480c,openstack/openstack-ansible-repo_server,master,I765783bc322266bc20e85873482231e64a19480c,add the project source code repository,MERGED,2018-09-07 01:56:13.000000000,2018-09-27 03:27:01.000000000,2018-09-27 03:27:01.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:56:13.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_server/commit/279a95d3fb948f447c550ea194b12c76906ad3f7', 'message': 'add the project source code repository\n\nChange-Id: I765783bc322266bc20e85873482231e64a19480c\n'}]",0,600605,279a95d3fb948f447c550ea194b12c76906ad3f7,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I765783bc322266bc20e85873482231e64a19480c
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_server refs/changes/05/600605/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,279a95d3fb948f447c550ea194b12c76906ad3f7,update_doc,The project source code repository is located at: `<https://git.openstack.org/cgit/openstack/openstack-ansible-repo_server/>`_ The project home is at: `<https://launchpad.net/openstack-ansible/>`_,The project home is at: https://launchpad.net/openstack-ansible,4,1
openstack%2Fopenstack-ansible-repo_build~master~If65347d1b4a98431c3f975adc76d47266f1ced86,openstack/openstack-ansible-repo_build,master,If65347d1b4a98431c3f975adc76d47266f1ced86,add the project source code repository,MERGED,2018-09-07 02:00:39.000000000,2018-09-27 03:26:57.000000000,2018-09-27 03:26:57.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:00:39.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/1f28162dc3f4889eb6003fa918dff960b4874157', 'message': 'add the project source code repository\n\nChange-Id: If65347d1b4a98431c3f975adc76d47266f1ced86\n'}]",0,600607,1f28162dc3f4889eb6003fa918dff960b4874157,7,3,1,27385,,,0,"add the project source code repository

Change-Id: If65347d1b4a98431c3f975adc76d47266f1ced86
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/07/600607/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1f28162dc3f4889eb6003fa918dff960b4874157,update_doc, https://docs.openstack.org/openstack-ansible-repo_build/latest/The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-repo_build/ The project home is at: https://launchpad.net/openstack-ansible/, https://docs.openstack.org/openstack-ansible-repo_build/latestThe project home is at: https://launchpad.net/openstack-ansible,5,2
openstack%2Fopenstack-ansible-repo_build~master~I91694dd1618ece5168e740524b8a039a55725421,openstack/openstack-ansible-repo_build,master,I91694dd1618ece5168e740524b8a039a55725421,Add the project source code repository in README,MERGED,2018-07-28 14:32:11.000000000,2018-09-27 03:26:57.000000000,2018-09-27 03:26:57.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 14:32:11.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-repo_build/commit/4ad66e74df7f73fccf396f3bc6a6c10ad76cdc0d', 'message': 'Add the project source code repository in README\n\nChange-Id: I91694dd1618ece5168e740524b8a039a55725421\n'}]",0,586806,4ad66e74df7f73fccf396f3bc6a6c10ad76cdc0d,10,6,1,14320,,,0,"Add the project source code repository in README

Change-Id: I91694dd1618ece5168e740524b8a039a55725421
",git fetch https://review.opendev.org/openstack/openstack-ansible-repo_build refs/changes/06/586806/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4ad66e74df7f73fccf396f3bc6a6c10ad76cdc0d,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-repo_build/ ,,3,0
openstack%2Fopenstack-ansible-os_blazar~master~I47fa76ba83f0ab8b0ede6191cc138f1e8e5e6b9f,openstack/openstack-ansible-os_blazar,master,I47fa76ba83f0ab8b0ede6191cc138f1e8e5e6b9f,modify the format of release notes link,MERGED,2018-09-06 07:47:56.000000000,2018-09-27 03:26:31.000000000,2018-09-27 03:26:31.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-06 07:47:56.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_blazar/commit/4952cc6f22a85be1227505074c2643ff1be93492', 'message': 'modify the format of release notes link\n\nChange-Id: I47fa76ba83f0ab8b0ede6191cc138f1e8e5e6b9f\n'}]",0,600361,4952cc6f22a85be1227505074c2643ff1be93492,7,3,1,27385,,,0,"modify the format of release notes link

Change-Id: I47fa76ba83f0ab8b0ede6191cc138f1e8e5e6b9f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_blazar refs/changes/61/600361/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,4952cc6f22a85be1227505074c2643ff1be93492,modify_format,The documentation for the role can also be found at:`<https://git.openstack.org/cgit/openstack/openstack-ansible-os_blazar/>`_`<https://launchpad.net/openstack-ansible/>`_,The documentation for the role can also be found at`<https://git.openstack.org/cgit/openstack/openstack-ansible-os_blazar/>_ https://launchpad.net/openstack-ansible,3,3
openstack%2Fopenstacksdk~master~I85a51e16c4f714c15b1920c0085d98a095832904,openstack/openstacksdk,master,I85a51e16c4f714c15b1920c0085d98a095832904,Allow JMESPath on searching networking resources,MERGED,2018-08-31 21:14:22.000000000,2018-09-27 03:26:17.000000000,2018-09-27 03:26:17.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 17860}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-31 21:14:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e32de177a5c7dcb68d1ec1d46db7bb5b350ba59f', 'message': 'Allow JMESPath on searching networking resources\n\nAs most of search methods in SDK, allowing a JMESPath expression for\nnetwork, subnet, port and router resources is powerful to end users.\n\nStory: #2003611\nTask: #24945\n\nChange-Id: I85a51e16c4f714c15b1920c0085d98a095832904\n'}, {'number': 2, 'created': '2018-09-08 01:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/67e342b82ffcd08f3797b149aa2ff5d0c45ea233', 'message': 'Allow JMESPath on searching networking resources\n\nAs most of search methods in SDK, allowing a JMESPath expression for\nnetwork, subnet, port and router resources is powerful to end users.\n\nStory: #2003611\nTask: #24945\n\nChange-Id: I85a51e16c4f714c15b1920c0085d98a095832904\n'}, {'number': 3, 'created': '2018-09-08 01:50:18.000000000', 'files': ['openstack/cloud/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/e40ccf742f00c318d77037d7d6dcdcb27b34506d', 'message': 'Allow JMESPath on searching networking resources\n\nAs most of search methods in SDK, allowing a JMESPath expression for\nnetwork, subnet, port and router resources is powerful to end users.\n\nStory: #2003611\nTask: #24945\n\nChange-Id: I85a51e16c4f714c15b1920c0085d98a095832904\n'}]",0,599078,e40ccf742f00c318d77037d7d6dcdcb27b34506d,18,4,3,17860,,,0,"Allow JMESPath on searching networking resources

As most of search methods in SDK, allowing a JMESPath expression for
network, subnet, port and router resources is powerful to end users.

Story: #2003611
Task: #24945

Change-Id: I85a51e16c4f714c15b1920c0085d98a095832904
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/78/599078/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/cloud/openstackcloud.py'],1,e32de177a5c7dcb68d1ec1d46db7bb5b350ba59f,2003611," networks = self.list_networks( filters if isinstance(filters, dict) else None) routers = self.list_routers( filters if isinstance(filters, dict) else None) subnets = self.list_subnets( filters if isinstance(filters, dict) else None) if self._PORT_AGE or isinstance(filters, str):", networks = self.list_networks(filters) routers = self.list_routers(filters) subnets = self.list_subnets(filters) if self._PORT_AGE:,7,4
openstack%2Fopenstack-ansible-os_gnocchi~master~I1747ad420309bc5781a0f93f978250973734f257,openstack/openstack-ansible-os_gnocchi,master,I1747ad420309bc5781a0f93f978250973734f257,SUSE: Add support for openSUSE Leap 15,MERGED,2018-09-26 10:56:30.000000000,2018-09-27 03:26:16.000000000,2018-09-27 03:26:16.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-26 10:56:30.000000000', 'files': ['meta/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_gnocchi/commit/7bac113dc085ead757c1077204a27e94cfc7fb2e', 'message': 'SUSE: Add support for openSUSE Leap 15\n\nChange-Id: I1747ad420309bc5781a0f93f978250973734f257\n'}]",0,605394,7bac113dc085ead757c1077204a27e94cfc7fb2e,7,3,1,23163,,,0,"SUSE: Add support for openSUSE Leap 15

Change-Id: I1747ad420309bc5781a0f93f978250973734f257
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_gnocchi refs/changes/94/605394/1 && git format-patch -1 --stdout FETCH_HEAD,['meta/main.yml'],1,7bac113dc085ead757c1077204a27e94cfc7fb2e,osa-add-leap-150, - all, - 42.1 - 42.2 - 42.3,1,3
openstack%2Fopenstack-ansible-pip_install~master~Ibabcafc6ca8e07f3975431891a54f2c23fd84f3d,openstack/openstack-ansible-pip_install,master,Ibabcafc6ca8e07f3975431891a54f2c23fd84f3d,add the project source code repository,MERGED,2018-09-07 02:36:23.000000000,2018-09-27 03:25:20.000000000,2018-09-27 03:25:20.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:36:23.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/3b51f84bc6f11c495a9a40f7c6298a26da705e58', 'message': 'add the project source code repository\n\nChange-Id: Ibabcafc6ca8e07f3975431891a54f2c23fd84f3d\n'}]",0,600618,3b51f84bc6f11c495a9a40f7c6298a26da705e58,7,3,1,27385,,,0,"add the project source code repository

Change-Id: Ibabcafc6ca8e07f3975431891a54f2c23fd84f3d
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/18/600618/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3b51f84bc6f11c495a9a40f7c6298a26da705e58,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-pip_install/ ,,3,0
openstack%2Fopenstack-ansible-openstack_hosts~master~Ibd9052d9d75b2a9d0e02ff627753a2104046df0f,openstack/openstack-ansible-openstack_hosts,master,Ibd9052d9d75b2a9d0e02ff627753a2104046df0f,add the project source code repository,MERGED,2018-09-07 01:22:22.000000000,2018-09-27 03:25:19.000000000,2018-09-27 03:25:18.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:22:22.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/06257da767deb5d57ddf06b04ef609fdd2382956', 'message': 'add the project source code repository\n\nChange-Id: Ibd9052d9d75b2a9d0e02ff627753a2104046df0f\n'}]",0,600596,06257da767deb5d57ddf06b04ef609fdd2382956,8,4,1,27385,,,0,"add the project source code repository

Change-Id: Ibd9052d9d75b2a9d0e02ff627753a2104046df0f
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/96/600596/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,06257da767deb5d57ddf06b04ef609fdd2382956,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-openstack_hosts/ ,,3,0
openstack%2Fopenstack-ansible-os_molteniron~master~I9edbb7bb656b79aa0cb759241a316ce6bdb89fbd,openstack/openstack-ansible-os_molteniron,master,I9edbb7bb656b79aa0cb759241a316ce6bdb89fbd,add the project source code repository,MERGED,2018-09-07 02:38:42.000000000,2018-09-27 03:25:14.000000000,2018-09-27 03:25:14.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 26775}]","[{'number': 1, 'created': '2018-09-07 02:38:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_molteniron/commit/8b2974eda1b3359e0c3a658c6511424309a1283d', 'message': 'add the project source code repository\n\nChange-Id: I9edbb7bb656b79aa0cb759241a316ce6bdb89fbd\n'}]",0,600619,8b2974eda1b3359e0c3a658c6511424309a1283d,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I9edbb7bb656b79aa0cb759241a316ce6bdb89fbd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_molteniron refs/changes/19/600619/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,8b2974eda1b3359e0c3a658c6511424309a1283d,update_doc, https://docs.openstack.org/releasenotes/openstack-ansible-os_molteniron/ The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_molteniron/ https://launchpad.net/openstack-ansible/, https://docs.openstack.org/releasenotes/openstack-ansible-os_molteniron https://launchpad.net/openstack-ansible,5,2
openstack%2Fopenstack-ansible-os_monasca-agent~master~I16799638f696d9b887fd9eccc8f3d7c514cf9418,openstack/openstack-ansible-os_monasca-agent,master,I16799638f696d9b887fd9eccc8f3d7c514cf9418,add the project source code repository,MERGED,2018-09-07 01:48:20.000000000,2018-09-27 03:25:05.000000000,2018-09-27 03:25:05.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:48:20.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca-agent/commit/5a5b7906af3bd2daf379848e0915b0cab70379fb', 'message': 'add the project source code repository\n\nChange-Id: I16799638f696d9b887fd9eccc8f3d7c514cf9418\n'}]",0,600604,5a5b7906af3bd2daf379848e0915b0cab70379fb,7,3,1,27385,,,0,"add the project source code repository

Change-Id: I16799638f696d9b887fd9eccc8f3d7c514cf9418
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_monasca-agent refs/changes/04/600604/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5a5b7906af3bd2daf379848e0915b0cab70379fb,update_doc, https://docs.openstack.org/releasenotes/openstack-ansible-os_monasca-agent/ The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_monasca-agent/ https://launchpad.net/openstack-ansible/, https://docs.openstack.org/releasenotes/openstack-ansible-os_monasca-agent https://launchpad.net/openstack-ansible,5,2
openstack%2Fopenstack-ansible-os_sahara~master~Ibbedce3ae72079eb3d8da32447aaae6d2a225fbd,openstack/openstack-ansible-os_sahara,master,Ibbedce3ae72079eb3d8da32447aaae6d2a225fbd,add the project source code repository,MERGED,2018-09-07 02:28:28.000000000,2018-09-27 03:24:59.000000000,2018-09-27 03:24:59.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:28:28.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/deb29eaa4519916af88380608b8f1cd35d52ba61', 'message': 'add the project source code repository\n\nChange-Id: Ibbedce3ae72079eb3d8da32447aaae6d2a225fbd\n'}]",0,600615,deb29eaa4519916af88380608b8f1cd35d52ba61,7,3,1,27385,,,0,"add the project source code repository

Change-Id: Ibbedce3ae72079eb3d8da32447aaae6d2a225fbd
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/15/600615/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,deb29eaa4519916af88380608b8f1cd35d52ba61,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_sahara/ ,,3,0
openstack%2Fopenstack-ansible-rsyslog_client~master~If0ae7d85c057f53f5deaf4587fa4076b2684807c,openstack/openstack-ansible-rsyslog_client,master,If0ae7d85c057f53f5deaf4587fa4076b2684807c,add the project source code repository,MERGED,2018-09-07 02:08:33.000000000,2018-09-27 03:24:34.000000000,2018-09-27 03:24:34.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 02:08:33.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rsyslog_client/commit/c968cc32b01a4a5f999c0ea9809eea4858197554', 'message': 'add the project source code repository\n\nChange-Id: If0ae7d85c057f53f5deaf4587fa4076b2684807c\n'}]",0,600609,c968cc32b01a4a5f999c0ea9809eea4858197554,7,3,1,27385,,,0,"add the project source code repository

Change-Id: If0ae7d85c057f53f5deaf4587fa4076b2684807c
",git fetch https://review.opendev.org/openstack/openstack-ansible-rsyslog_client refs/changes/09/600609/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,c968cc32b01a4a5f999c0ea9809eea4858197554,update_doc,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-rsyslog_client/ ,,3,0
openstack%2Fopenstack-ansible-os_monasca-agent~master~I458b70de189aad5b84e20bf9800f93f0e5ac3c39,openstack/openstack-ansible-os_monasca-agent,master,I458b70de189aad5b84e20bf9800f93f0e5ac3c39,Add the project source code repository in README,MERGED,2018-07-28 13:45:21.000000000,2018-09-27 03:23:38.000000000,2018-09-27 03:23:38.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 13:45:21.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca-agent/commit/7fc6b777a190fa9232f8c12069f2ec555b0e111f', 'message': 'Add the project source code repository in README\n\nChange-Id: I458b70de189aad5b84e20bf9800f93f0e5ac3c39\n'}]",0,586793,7fc6b777a190fa9232f8c12069f2ec555b0e111f,11,7,1,14320,,,0,"Add the project source code repository in README

Change-Id: I458b70de189aad5b84e20bf9800f93f0e5ac3c39
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_monasca-agent refs/changes/93/586793/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,7fc6b777a190fa9232f8c12069f2ec555b0e111f,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_monasca-agent/ ,,3,0
openstack%2Fopenstack-ansible-os_cinder~master~I6e73dd0c5ef26576f2aacbb1840f0a1e585075a0,openstack/openstack-ansible-os_cinder,master,I6e73dd0c5ef26576f2aacbb1840f0a1e585075a0,[Trivial Fix] Replace Chinese punctuation with English punctuation,MERGED,2018-09-10 02:50:18.000000000,2018-09-27 03:23:23.000000000,2018-09-27 03:23:23.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-09-10 02:50:18.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cinder/commit/b93b945faf4d2a564381d4797aa6bca841cdf08e', 'message': '[Trivial Fix] Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input method.\nWhen read from english context, it makes some confusion.\n\nChange-Id: I6e73dd0c5ef26576f2aacbb1840f0a1e585075a0\n'}]",0,601147,b93b945faf4d2a564381d4797aa6bca841cdf08e,7,3,1,28842,,,0,"[Trivial Fix] Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input method.
When read from english context, it makes some confusion.

Change-Id: I6e73dd0c5ef26576f2aacbb1840f0a1e585075a0
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cinder refs/changes/47/601147/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,b93b945faf4d2a564381d4797aa6bca841cdf08e,," * If the issue is a bug that needs fixing in a branch other than Master, add the 'backport potential' tag TO THE ISSUE (not the PR)."," * If the issue is a bug that needs fixing in a branch other than Master, add the backport potential tag TO THE ISSUE (not the PR).",1,1
openstack%2Fopenstack-ansible-os_tempest~master~I86e28d8765762156ecca15ca0a0018daac40743f,openstack/openstack-ansible-os_tempest,master,I86e28d8765762156ecca15ca0a0018daac40743f,Add the project source code repository in README,MERGED,2018-07-28 14:13:12.000000000,2018-09-27 03:22:35.000000000,2018-09-27 03:22:34.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 14:13:12.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/81c8cbca955632db45cd5f04e22e00dee424b36f', 'message': 'Add the project source code repository in README\n\nChange-Id: I86e28d8765762156ecca15ca0a0018daac40743f\n'}]",0,586801,81c8cbca955632db45cd5f04e22e00dee424b36f,10,6,1,14320,,,0,"Add the project source code repository in README

Change-Id: I86e28d8765762156ecca15ca0a0018daac40743f
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/01/586801/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,81c8cbca955632db45cd5f04e22e00dee424b36f,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_tempest ,,3,0
openstack%2Fopenstack-ansible-os_aodh~master~Ic6e5f00b4d9ed9e667dcb41930720dbb43fb732c,openstack/openstack-ansible-os_aodh,master,Ic6e5f00b4d9ed9e667dcb41930720dbb43fb732c,[Trivial Fix] Replace Chinese punctuation with English punctuation,MERGED,2018-09-10 02:14:46.000000000,2018-09-27 03:22:29.000000000,2018-09-27 03:22:29.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27190}]","[{'number': 1, 'created': '2018-09-10 02:14:46.000000000', 'files': ['CONTRIBUTING.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_aodh/commit/039b528591f81035fd567ddb3c09bfea0cda3b56', 'message': '[Trivial Fix] Replace Chinese punctuation with English punctuation\n\nCurly quotes(Chinese punctuation) usually input from Chinese input method.\nWhen read from english context, it makes some confusion.\n\nChange-Id: Ic6e5f00b4d9ed9e667dcb41930720dbb43fb732c\n'}]",0,601140,039b528591f81035fd567ddb3c09bfea0cda3b56,7,3,1,28842,,,0,"[Trivial Fix] Replace Chinese punctuation with English punctuation

Curly quotes(Chinese punctuation) usually input from Chinese input method.
When read from english context, it makes some confusion.

Change-Id: Ic6e5f00b4d9ed9e667dcb41930720dbb43fb732c
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_aodh refs/changes/40/601140/1 && git format-patch -1 --stdout FETCH_HEAD,['CONTRIBUTING.rst'],1,039b528591f81035fd567ddb3c09bfea0cda3b56,," * If the issue is a bug that needs fixing in a branch other than Master, add the 'backport potential' tag TO THE ISSUE (not the PR)."," * If the issue is a bug that needs fixing in a branch other than Master, add the backport potential tag TO THE ISSUE (not the PR).",1,1
openstack%2Fopenstack-ansible-pip_install~master~I563eafd9b288f88448c2b94ae8fdb91286464209,openstack/openstack-ansible-pip_install,master,I563eafd9b288f88448c2b94ae8fdb91286464209,Add the project source code repository in README,MERGED,2018-07-28 14:22:17.000000000,2018-09-27 03:21:56.000000000,2018-09-27 03:21:56.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 21314}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 14:22:17.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-pip_install/commit/773386740b6f9c9c58137d4f9b2a474dd4973131', 'message': 'Add the project source code repository in README\n\nChange-Id: I563eafd9b288f88448c2b94ae8fdb91286464209\n'}]",0,586804,773386740b6f9c9c58137d4f9b2a474dd4973131,12,7,1,14320,,,0,"Add the project source code repository in README

Change-Id: I563eafd9b288f88448c2b94ae8fdb91286464209
",git fetch https://review.opendev.org/openstack/openstack-ansible-pip_install refs/changes/04/586804/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,773386740b6f9c9c58137d4f9b2a474dd4973131,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-pip_install/ ,,3,0
openstack%2Fopenstack-ansible-os_monasca-ui~master~I64e8e71900cac9899b0c5f8b2013e4a5b95366b7,openstack/openstack-ansible-os_monasca-ui,master,I64e8e71900cac9899b0c5f8b2013e4a5b95366b7,add the project source code repository,MERGED,2018-09-07 01:26:58.000000000,2018-09-27 03:21:51.000000000,2018-09-27 03:21:51.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}, {'_account_id': 27372}, {'_account_id': 27565}]","[{'number': 1, 'created': '2018-09-07 01:26:58.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_monasca-ui/commit/82a68c326eee76691d9344059a8fddf8d35360c4', 'message': 'add the project source code repository\n\nChange-Id: I64e8e71900cac9899b0c5f8b2013e4a5b95366b7\n'}]",0,600597,82a68c326eee76691d9344059a8fddf8d35360c4,7,4,1,27385,,,0,"add the project source code repository

Change-Id: I64e8e71900cac9899b0c5f8b2013e4a5b95366b7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_monasca-ui refs/changes/97/600597/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,82a68c326eee76691d9344059a8fddf8d35360c4,update_doc, https://docs.openstack.org/releasenotes/openstack-ansible-os_monasca-ui/ The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_monasca-ui/ https://launchpad.net/openstack-ansible/, https://docs.openstack.org/releasenotes/openstack-ansible-os_monasca-ui https://launchpad.net/openstack-ansible,5,2
openstack%2Fopenstack-ansible-os_watcher~master~If3e88b34f0df05a269149e02e53596ac8ddae8b9,openstack/openstack-ansible-os_watcher,master,If3e88b34f0df05a269149e02e53596ac8ddae8b9,Add the project source code repository in README,MERGED,2018-07-28 14:18:33.000000000,2018-09-27 03:21:12.000000000,2018-09-27 03:21:11.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 14:18:33.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_watcher/commit/2f5c023f4544f0960fc0a0a1e3ae7f6aedfdd630', 'message': 'Add the project source code repository in README\n\nChange-Id: If3e88b34f0df05a269149e02e53596ac8ddae8b9\n'}]",0,586802,2f5c023f4544f0960fc0a0a1e3ae7f6aedfdd630,10,6,1,14320,,,0,"Add the project source code repository in README

Change-Id: If3e88b34f0df05a269149e02e53596ac8ddae8b9
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_watcher refs/changes/02/586802/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,2f5c023f4544f0960fc0a0a1e3ae7f6aedfdd630,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_watcher/ ,,3,0
openstack%2Fopenstack-ansible-os_molteniron~master~I6d92e933b0dce96458e27c5b1bda8a0ee464c430,openstack/openstack-ansible-os_molteniron,master,I6d92e933b0dce96458e27c5b1bda8a0ee464c430,Add the project source code repository in READM,MERGED,2018-07-28 13:42:57.000000000,2018-09-27 03:20:49.000000000,2018-09-27 03:20:49.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 13:42:57.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_molteniron/commit/12744450797081956d3b45a29598dc50cef7b608', 'message': 'Add the project source code repository in READM\n\nChange-Id: I6d92e933b0dce96458e27c5b1bda8a0ee464c430\n'}]",0,586792,12744450797081956d3b45a29598dc50cef7b608,10,6,1,14320,,,0,"Add the project source code repository in READM

Change-Id: I6d92e933b0dce96458e27c5b1bda8a0ee464c430
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_molteniron refs/changes/92/586792/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,12744450797081956d3b45a29598dc50cef7b608,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_molteniron/ ,,3,0
openstack%2Fopenstack-ansible-os_neutron~master~Icf40663dc859b4eb044881949fac007830bdc51b,openstack/openstack-ansible-os_neutron,master,Icf40663dc859b4eb044881949fac007830bdc51b,Add the project source code repository in README,MERGED,2018-07-28 13:55:10.000000000,2018-09-27 03:19:38.000000000,2018-09-27 03:19:38.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 21486}, {'_account_id': 22348}, {'_account_id': 26285}, {'_account_id': 26431}]","[{'number': 1, 'created': '2018-07-28 13:55:10.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_neutron/commit/3acfde6ff867b94df8bafe1b349c3ecc37dad1bb', 'message': 'Add the project source code repository in README\n\nChange-Id: Icf40663dc859b4eb044881949fac007830bdc51b\n'}]",0,586796,3acfde6ff867b94df8bafe1b349c3ecc37dad1bb,11,7,1,14320,,,0,"Add the project source code repository in README

Change-Id: Icf40663dc859b4eb044881949fac007830bdc51b
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_neutron refs/changes/96/586796/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,3acfde6ff867b94df8bafe1b349c3ecc37dad1bb,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_neutron/ ,,3,0
openstack%2Fopenstack-ansible-os_sahara~master~I05f6422a5a9772b6850511955da5d856556cb8ef,openstack/openstack-ansible-os_sahara,master,I05f6422a5a9772b6850511955da5d856556cb8ef,Add the project source code repository in README,MERGED,2018-07-20 04:47:27.000000000,2018-09-27 03:17:13.000000000,2018-09-27 03:17:13.000000000,"[{'_account_id': 7353}, {'_account_id': 14151}, {'_account_id': 14320}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2018-07-20 04:47:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/d0aefa139d95bb4356992d7d3628b3c99c56147f', 'message': 'Add the project source code repository in README\n\nChange-Id: I05f6422a5a9772b6850511955da5d856556cb8ef\n'}, {'number': 2, 'created': '2018-07-20 04:51:36.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_sahara/commit/d9b8e179cbe61e1cbef9ef32ed1ed43f96447800', 'message': 'Add the project source code repository in README\n\nChange-Id: I05f6422a5a9772b6850511955da5d856556cb8ef\n'}]",1,584220,d9b8e179cbe61e1cbef9ef32ed1ed43f96447800,12,5,2,14151,,,0,"Add the project source code repository in README

Change-Id: I05f6422a5a9772b6850511955da5d856556cb8ef
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_sahara refs/changes/20/584220/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,d0aefa139d95bb4356992d7d3628b3c99c56147f,,The project source code repository is located at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_sahara/ ,,3,0
openstack%2Fopenstack-ansible-os_tempest~master~I6f2739dab7146b2228046c9f5b8ea3f002924932,openstack/openstack-ansible-os_tempest,master,I6f2739dab7146b2228046c9f5b8ea3f002924932,Remove duplicate link in README,MERGED,2018-08-31 08:07:10.000000000,2018-09-27 03:13:16.000000000,2018-09-27 03:13:16.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-31 08:07:10.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/940829bace1de8a117d7cc7d5f4be0c0913b2f54', 'message': 'Remove duplicate link in README\n\nRemove the project source code link which\nis duplicate in README.rst.\n\nChange-Id: I6f2739dab7146b2228046c9f5b8ea3f002924932\n'}]",0,598485,940829bace1de8a117d7cc7d5f4be0c0913b2f54,6,2,1,23317,,,0,"Remove duplicate link in README

Remove the project source code link which
is duplicate in README.rst.

Change-Id: I6f2739dab7146b2228046c9f5b8ea3f002924932
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/85/598485/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,940829bace1de8a117d7cc7d5f4be0c0913b2f54,fix,, The project source code is at: https://git.openstack.org/cgit/openstack/openstack-ansible-os_tempest/,0,3
openstack%2Fopenstack-ansible-os_nova~master~Ia3dd28129b328a0e33fe53d8af9a305ef42913d7,openstack/openstack-ansible-os_nova,master,Ia3dd28129b328a0e33fe53d8af9a305ef42913d7,Add an address of project source code repository.,MERGED,2018-08-23 07:08:28.000000000,2018-09-27 03:08:31.000000000,2018-09-27 03:08:31.000000000,"[{'_account_id': 7353}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-23 07:08:28.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_nova/commit/5c6a5691ac8e8adfc0ae8a07fef4f1f50b8704ee', 'message': 'Add an address of project source code repository.\n\nChange-Id: Ia3dd28129b328a0e33fe53d8af9a305ef42913d7\n'}]",0,595507,5c6a5691ac8e8adfc0ae8a07fef4f1f50b8704ee,6,2,1,28842,,,0,"Add an address of project source code repository.

Change-Id: Ia3dd28129b328a0e33fe53d8af9a305ef42913d7
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_nova refs/changes/07/595507/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,5c6a5691ac8e8adfc0ae8a07fef4f1f50b8704ee,,The project source code repository is located at: `<https://git.openstack.org/cgit/openstack/openstack-ansible-os_nova/>`_ ,,3,0
openstack%2Fopenstacksdk~master~I6b132c9aac119d94b1085741f557fa405836a703,openstack/openstacksdk,master,I6b132c9aac119d94b1085741f557fa405836a703,Normalize security groups when using Neutron,MERGED,2018-09-12 20:02:24.000000000,2018-09-27 03:07:49.000000000,2018-09-27 03:07:49.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 17860}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-12 20:02:24.000000000', 'files': ['openstack/cloud/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/d7470b5e952a85718734c837a958660e94f699ff', 'message': ""Normalize security groups when using Neutron\n\nWhen Neutron was used, the listed security groups were not being\nnormalized, which doesn't help end users on having a consistent\nrepresentation of them regardless the cloud configuration choices.\n\nStory: #2003741\nTask: #26423\n\nChange-Id: I6b132c9aac119d94b1085741f557fa405836a703\n""}]",0,602147,d7470b5e952a85718734c837a958660e94f699ff,19,4,1,17860,,,0,"Normalize security groups when using Neutron

When Neutron was used, the listed security groups were not being
normalized, which doesn't help end users on having a consistent
representation of them regardless the cloud configuration choices.

Story: #2003741
Task: #26423

Change-Id: I6b132c9aac119d94b1085741f557fa405836a703
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/47/602147/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/cloud/openstackcloud.py'],1,d7470b5e952a85718734c837a958660e94f699ff,2003741," return self._normalize_secgroups( self._get_and_munchify('security_groups', data))"," return self._get_and_munchify('security_groups', data)",2,1
openstack%2Fopenstack-ansible-os_cloudkitty~master~Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed,openstack/openstack-ansible-os_cloudkitty,master,Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed,Completed required variables for README.rst,MERGED,2018-07-19 15:02:07.000000000,2018-09-27 03:05:27.000000000,2018-09-27 03:05:27.000000000,"[{'_account_id': 7353}, {'_account_id': 21691}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 25695}, {'_account_id': 27781}, {'_account_id': 28614}]","[{'number': 1, 'created': '2018-07-19 15:02:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cloudkitty/commit/39bfcf4b927d6d1fb1bfdaddef0fd95a19aebeb5', 'message': 'Completed required variables for README.rst\n\nChange-Id: Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed\n'}, {'number': 2, 'created': '2018-07-21 12:26:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cloudkitty/commit/e6039cc35a0a13a7e417ebe0ac4f0995908ea0e5', 'message': 'Completed required variables for README.rst\n\nRequired variable section should include external_lb_vip_address and\ninternal_lb_vip_address[0], and add the value to keep consistence with\nthe others[1]\n\n[0]: https://github.com/openstack/openstack-ansible-os_cloudkitty/blob/master/README.rst\n[1]: https://github.com/openstack/openstack-ansible-os_trove/blob/master/README.rst\n\nChange-Id: Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed\n'}, {'number': 3, 'created': '2018-08-17 07:46:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_cloudkitty/commit/708f78015068bfb7724f344f6fab3ba40768b775', 'message': 'Completed required variables for README.rst\n\nRequired variable section should include external_lb_vip_address and\ninternal_lb_vip_address[0], and add the value to keep consistence with\nthe others[1]\n\n[0]: https://github.com/openstack/openstack-ansible-os_cloudkitty/blob/master/README.rst\n[1]: https://github.com/openstack/openstack-ansible-os_trove/blob/master/README.rst\n\nChange-Id: Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed\n'}]",0,583981,708f78015068bfb7724f344f6fab3ba40768b775,15,7,3,21691,,,0,"Completed required variables for README.rst

Required variable section should include external_lb_vip_address and
internal_lb_vip_address[0], and add the value to keep consistence with
the others[1]

[0]: https://github.com/openstack/openstack-ansible-os_cloudkitty/blob/master/README.rst
[1]: https://github.com/openstack/openstack-ansible-os_trove/blob/master/README.rst

Change-Id: Ib11d7ea2bbf5e6450201a2c6bdc15fc96cd91eed
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_cloudkitty refs/changes/81/583981/2 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,39bfcf4b927d6d1fb1bfdaddef0fd95a19aebeb5,," external_lb_vip_address: 172.16.24.1 internal_lb_vip_address: 192.168.0.1 cloudkitty_galera_address: ""{{ internal_lb_vip_address }}"" cloudkitty_container_mysql_password: ""SuperSecretePassword1"" cloudkitty_service_password: ""SuperSecretePassword2"" cloudkitty_rabbitmq_password: ""SuperSecretePassword3""", cloudkitty_service_password cloudkitty_rabbitmq_password cloudkitty_container_mysql_password cloudkitty_galera_address,6,4
openstack%2Fneutron~master~I4336197f7e086ef474c81a708861e788f28be025,openstack/neutron,master,I4336197f7e086ef474c81a708861e788f28be025,fix spell error,MERGED,2018-08-29 01:24:31.000000000,2018-09-27 02:44:43.000000000,2018-09-27 02:00:00.000000000,"[{'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 17120}, {'_account_id': 22348}, {'_account_id': 23312}, {'_account_id': 26622}]","[{'number': 1, 'created': '2018-08-29 01:24:31.000000000', 'files': ['neutron/agent/linux/iptables_manager.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/979de972f5e23489279ded10a442ad6ca96809d0', 'message': 'fix spell error\n\nChange-Id: I4336197f7e086ef474c81a708861e788f28be025\n'}]",0,597348,979de972f5e23489279ded10a442ad6ca96809d0,16,11,1,22016,,,0,"fix spell error

Change-Id: I4336197f7e086ef474c81a708861e788f28be025
",git fetch https://review.opendev.org/openstack/neutron refs/changes/48/597348/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/agent/linux/iptables_manager.py'],1,979de972f5e23489279ded10a442ad6ca96809d0,, # want to add them if they aren't already there, # want to add them if they arent' already there,1,1
openstack%2Foctavia~master~Ic110e0e73938743c1aba01aa28f393bae7141cbd,openstack/octavia,master,Ic110e0e73938743c1aba01aa28f393bae7141cbd,Fix the API list performance regression,MERGED,2018-09-17 22:29:37.000000000,2018-09-27 02:28:49.000000000,2018-09-26 08:32:38.000000000,"[{'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 8873}, {'_account_id': 10273}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27488}, {'_account_id': 28329}]","[{'number': 1, 'created': '2018-09-17 22:29:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/e5747bf71dbbea7398a1a9bc68f724d8b4a856b0', 'message': 'Fix the API list performance regression\n\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}, {'number': 2, 'created': '2018-09-18 02:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f63e839773473d6f26ff4141df4bb9342e6fa4f6', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}, {'number': 3, 'created': '2018-09-18 21:34:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/fd29b064d33e97793bb21dc7a31b72607428fd76', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}, {'number': 4, 'created': '2018-09-18 23:50:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/02b92c16417078b43f1528f8733163321e83c6a4', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}, {'number': 5, 'created': '2018-09-19 01:26:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/9ae331af91f77369d461a5fe98fcdd22b252f212', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}, {'number': 6, 'created': '2018-09-19 21:02:44.000000000', 'files': ['octavia/api/v2/controllers/load_balancer.py', 'octavia/db/models.py', 'octavia/api/v2/controllers/pool.py', 'octavia/db/repositories.py', 'octavia/api/v2/controllers/l7policy.py', 'octavia/api/v2/controllers/l7rule.py', 'octavia/api/v2/controllers/member.py', 'octavia/api/v2/controllers/amphora.py', 'octavia/api/v2/controllers/health_monitor.py', 'releasenotes/notes/fix-API-list-performance-3b121deffbc3ce4a.yaml', 'octavia/api/v2/controllers/listener.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/f15b43ddf432d9c320db73325abe042b65df3970', 'message': 'Fix the API list performance regression\n\nThis patch fixes the Octavia v2 API ""list"" performance regression.\n\nIt also corrects some database model forward reference issues.\n\nCo-Authored-By: Adam Harwell <flux.adam@gmail.com>\nChange-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd\nStory: 2002933\nTask: 22920\n'}]",1,603242,f15b43ddf432d9c320db73325abe042b65df3970,29,10,6,11628,,,0,"Fix the API list performance regression

This patch fixes the Octavia v2 API ""list"" performance regression.

It also corrects some database model forward reference issues.

Co-Authored-By: Adam Harwell <flux.adam@gmail.com>
Change-Id: Ic110e0e73938743c1aba01aa28f393bae7141cbd
Story: 2002933
Task: 22920
",git fetch https://review.opendev.org/openstack/octavia refs/changes/42/603242/4 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/db/base_models.py', 'octavia/db/repositories.py']",2,e5747bf71dbbea7398a1a9bc68f724d8b4a856b0,, data_model_list = [model.to_data_model( max_depth=2) for model in model_list], # Only make one trip to the database query = query.options(joinedload('*')) data_model_list = [model.to_data_model() for model in model_list],11,8
openstack%2Fkeystone~master~I7c34d67f1dd326fb7bb9772c7a56ef9934587608,openstack/keystone,master,I7c34d67f1dd326fb7bb9772c7a56ef9934587608,Fix command to verify role removal in docs,MERGED,2018-09-26 19:03:26.000000000,2018-09-27 02:00:14.000000000,2018-09-27 02:00:14.000000000,"[{'_account_id': 5046}, {'_account_id': 10343}, {'_account_id': 11589}, {'_account_id': 15054}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 19:03:26.000000000', 'files': ['doc/source/admin/cli-manage-projects-users-and-roles.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/a8e26936a9cf3f48ac70d65efc70ca8649ce58b3', 'message': ""Fix command to verify role removal in docs\n\nThe command here doesn't work; update it to a command that does.\n\nChange-Id: I7c34d67f1dd326fb7bb9772c7a56ef9934587608\n""}]",2,605509,a8e26936a9cf3f48ac70d65efc70ca8649ce58b3,9,5,1,10343,,,0,"Fix command to verify role removal in docs

The command here doesn't work; update it to a command that does.

Change-Id: I7c34d67f1dd326fb7bb9772c7a56ef9934587608
",git fetch https://review.opendev.org/openstack/keystone refs/changes/09/605509/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/cli-manage-projects-users-and-roles.rst'],1,a8e26936a9cf3f48ac70d65efc70ca8649ce58b3,docs-fix, $ openstack role assignment list --user USER_NAME --project TENANT_ID --names, $ openstack role list --user USER_NAME --project TENANT_ID,1,1
openstack%2Fpython-swiftclient~master~I86d24104033b490a35178fc504d88c1e4a566628,openstack/python-swiftclient,master,I86d24104033b490a35178fc504d88c1e4a566628,fix tox python3 overrides,MERGED,2018-06-07 16:46:38.000000000,2018-09-27 02:00:05.000000000,2018-09-27 02:00:05.000000000,"[{'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 7847}, {'_account_id': 14151}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 27153}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-06-07 16:46:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/ff67c5b829795779fdd9687df01e54f621f8d2e2', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I86d24104033b490a35178fc504d88c1e4a566628\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}, {'number': 2, 'created': '2018-09-05 05:46:52.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/37ee6459cd2bb0197637f6d38e454bfe59192637', 'message': 'fix tox python3 overrides\n\nWe want to default to running all tox environments under python 3, so\nset the basepython value in each environment.\n\nWe do not want to specify a minor version number, because we do not\nwant to have to update the file every time we upgrade python.\n\nWe do not want to set the override once in testenv, because that\nbreaks the more specific versions used in default environments like\npy35 and py36.\n\nChange-Id: I86d24104033b490a35178fc504d88c1e4a566628\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n'}]",0,573355,37ee6459cd2bb0197637f6d38e454bfe59192637,22,8,2,2472,,,0,"fix tox python3 overrides

We want to default to running all tox environments under python 3, so
set the basepython value in each environment.

We do not want to specify a minor version number, because we do not
want to have to update the file every time we upgrade python.

We do not want to set the override once in testenv, because that
breaks the more specific versions used in default environments like
py35 and py36.

Change-Id: I86d24104033b490a35178fc504d88c1e4a566628
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/55/573355/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,ff67c5b829795779fdd9687df01e54f621f8d2e2,python3-first,basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3basepython = python3,,7,0
openstack%2Fdevstack~stable%2Focata~Iccb045a6695deb10da4d68a5694e1fa45ccbb810,openstack/devstack,stable/ocata,Iccb045a6695deb10da4d68a5694e1fa45ccbb810,CentOS: Fix EPEL mirroring and RDO install on CI nodes,MERGED,2018-09-25 21:02:58.000000000,2018-09-27 02:00:04.000000000,2018-09-27 02:00:04.000000000,"[{'_account_id': 7118}, {'_account_id': 9003}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 21:02:58.000000000', 'files': ['stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/363e8cd6b847e818c3a59383fd681d183aadb109', 'message': 'CentOS: Fix EPEL mirroring and RDO install on CI nodes\n\nCentOS tests have reverted to using upstream for EPEL rather than\nlocal mirrors, introducing some unnecessary instability.  The root of\nthe problem is that /etc/nodepool/provider disappeared with zuulv3, so\nwe now always re-install the EPEL repo and overwrite the local EPEL\n.repos files that were made during test setup and point to local\nmirrors.\n\nThe other change is that we stopped installing the RDO repositories on\nthe testing nodes too.  That we were incorrectly taking this path and\nreinstalling EPEL has hidden the removal of these packages from the\nbase image in the test, since it ends up installing them too.\n\nSplit the install into two parts -- epel and RDO.  Check for\n/etc/ci/mirror_info.sh (the sourcable mirror script provided by base\ntest setup) and if so, just enable EPEL so we get the CI-mirror\nversion correctly.  Install the RDO repositories (if not already\ninstalled) unconditionally.\n\n(Cherry-Picked from dc04b5aa24411b4081f0ad08021e0dc694c982e8)\nChange-Id: Iccb045a6695deb10da4d68a5694e1fa45ccbb810\n'}]",0,605231,363e8cd6b847e818c3a59383fd681d183aadb109,11,6,1,7118,,,0,"CentOS: Fix EPEL mirroring and RDO install on CI nodes

CentOS tests have reverted to using upstream for EPEL rather than
local mirrors, introducing some unnecessary instability.  The root of
the problem is that /etc/nodepool/provider disappeared with zuulv3, so
we now always re-install the EPEL repo and overwrite the local EPEL
.repos files that were made during test setup and point to local
mirrors.

The other change is that we stopped installing the RDO repositories on
the testing nodes too.  That we were incorrectly taking this path and
reinstalling EPEL has hidden the removal of these packages from the
base image in the test, since it ends up installing them too.

Split the install into two parts -- epel and RDO.  Check for
/etc/ci/mirror_info.sh (the sourcable mirror script provided by base
test setup) and if so, just enable EPEL so we get the CI-mirror
version correctly.  Install the RDO repositories (if not already
installed) unconditionally.

(Cherry-Picked from dc04b5aa24411b4081f0ad08021e0dc694c982e8)
Change-Id: Iccb045a6695deb10da4d68a5694e1fa45ccbb810
",git fetch https://review.opendev.org/openstack/devstack refs/changes/31/605231/1 && git format-patch -1 --stdout FETCH_HEAD,['stack.sh'],1,363e8cd6b847e818c3a59383fd681d183aadb109,,"function _install_epel {} function _install_rdo { # There are multiple options for this, including using CloudSIG # repositories (centos-release-*), trunk versions, etc. Since # we're not interested in the actual openstack distributions # (since we're using git to run!) but only peripherial packages # like kvm or ovs, this has been reliable. # TODO(ianw): figure out how to best mirror -- probably use infra # mirror RDO reverse proxy. We could either have test # infrastructure set it up disabled like EPEL, or fiddle it here. # Per the point above, it's a bunch of repos so starts getting a # little messy... if ! is_package_installed rdo-release ; then yum_install https://rdoproject.org/repos/rdo-release.rpm fi # Also enable optional for RHEL7 proper. Note this is a silent # no-op on other platforms.if [[ $DISTRO == ""rhel7"" ]]; then # If we have /etc/ci/mirror_info.sh assume we're on a OpenStack CI # node, where EPEL is installed (but disabled) and already # pointing at our internal mirror if [[ -f /etc/ci/mirror_info.sh ]]; then SKIP_EPEL_INSTALL=True if [[ ${SKIP_EPEL_INSTALL} != True ]]; then _install_epel fi # Along with EPEL, CentOS (and a-likes) require some packages only # available in RDO repositories (e.g. OVS, or later versions of # kvm) to run. _install_rdo","function _install_epel_and_rdo { # ... and also optional to be enabled # install the lastest RDO is_package_installed rdo-release || yum_install https://rdoproject.org/repos/rdo-release.rpm # If we have /etc/nodepool/provider assume we're on a OpenStack CI # node, where EPEL is already pointing at our internal mirror and RDO # is pre-installed. if [[ -f /etc/nodepool/provider ]]; then SKIP_EPEL_INSTALL=True if is_fedora; then # However, EPEL is not enabled by default.fi if is_fedora && [[ $DISTRO == ""rhel7"" ]] && \ [[ ${SKIP_EPEL_INSTALL} != True ]]; then _install_epel_and_rdo",33,16
openstack%2Fswift~master~Idcb1e9cacba5b959387a2bfd7a4ef5e9d502996a,openstack/swift,master,Idcb1e9cacba5b959387a2bfd7a4ef5e9d502996a,update 1space url in associated projects,MERGED,2018-09-26 15:55:57.000000000,2018-09-27 02:00:02.000000000,2018-09-27 02:00:02.000000000,"[{'_account_id': 597}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 15:55:57.000000000', 'files': ['doc/source/associated_projects.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/36a3fee80521c07b9bfef25ad48a13b3db8c32dd', 'message': 'update 1space url in associated projects\n\nChange-Id: Idcb1e9cacba5b959387a2bfd7a4ef5e9d502996a\n'}]",0,605467,36a3fee80521c07b9bfef25ad48a13b3db8c32dd,6,2,1,9625,,,0,"update 1space url in associated projects

Change-Id: Idcb1e9cacba5b959387a2bfd7a4ef5e9d502996a
",git fetch https://review.opendev.org/openstack/swift refs/changes/67/605467/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/associated_projects.rst'],1,36a3fee80521c07b9bfef25ad48a13b3db8c32dd,,* `1space <https://github.com/swiftstack/1space>`_ - Multi-cloud synchronization tool - supports Swift and S3 APIs,* `swift-s3-sync <https://github.com/swiftstack/swift-s3-sync>`_ - Swift-S3 synchronization tool,2,2
openstack%2Fkeystone~master~Ia6ee29e5f2c0bb5c89029a7bbe3b35bfdf7a1187,openstack/keystone,master,Ia6ee29e5f2c0bb5c89029a7bbe3b35bfdf7a1187,Fixing wrong url of keystone-specs,ABANDONED,2018-09-27 01:05:16.000000000,2018-09-27 01:42:11.000000000,,[{'_account_id': 15054}],"[{'number': 1, 'created': '2018-09-27 01:05:16.000000000', 'files': ['doc/source/contributor/api_change_tutorial.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/3b6174d771a554d4fa601ccbe60b592488ae1e77', 'message': 'Fixing wrong url of keystone-specs\n\napi-change-tutorial.rst is having wrong\nurl of keystone-specs.This patch fixes\nthis.\n\nChange-Id: Ia6ee29e5f2c0bb5c89029a7bbe3b35bfdf7a1187\n'}]",1,605561,3b6174d771a554d4fa601ccbe60b592488ae1e77,3,1,1,27621,,,0,"Fixing wrong url of keystone-specs

api-change-tutorial.rst is having wrong
url of keystone-specs.This patch fixes
this.

Change-Id: Ia6ee29e5f2c0bb5c89029a7bbe3b35bfdf7a1187
",git fetch https://review.opendev.org/openstack/keystone refs/changes/61/605561/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/api_change_tutorial.rst'],1,3b6174d771a554d4fa601ccbe60b592488ae1e77,,#. git clone https://specs.openstack.org/openstack/keystone-specs;,#. git clone https://git.openstack.org/openstack/keystone-specs;,1,1
openstack%2Fneutron~master~Ifad26642d730456136dfa9177d1c9515fe5ec421,openstack/neutron,master,Ifad26642d730456136dfa9177d1c9515fe5ec421,Add PortForwarding to neutron.objects entrypoint.,MERGED,2018-09-26 02:35:01.000000000,2018-09-27 01:32:37.000000000,2018-09-27 01:32:37.000000000,"[{'_account_id': 333}, {'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-09-26 02:35:01.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/neutron/commit/66991f1c8be86560ef2d774ed7a7b07ff2834ab1', 'message': 'Add PortForwarding to neutron.objects entrypoint.\n\nCloses-bug: #1794406\nChange-Id: Ifad26642d730456136dfa9177d1c9515fe5ec421\n'}]",0,605302,66991f1c8be86560ef2d774ed7a7b07ff2834ab1,11,9,1,27602,,,0,"Add PortForwarding to neutron.objects entrypoint.

Closes-bug: #1794406
Change-Id: Ifad26642d730456136dfa9177d1c9515fe5ec421
",git fetch https://review.opendev.org/openstack/neutron refs/changes/02/605302/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,66991f1c8be86560ef2d774ed7a7b07ff2834ab1,bug/1794406, PortForwarding = neutron.objects.port_forwarding:PortForwarding,,1,0
openstack%2Fkuryr-kubernetes~master~I92fbf002c2bd8c7a3fc7f7aee7d1197dc6a7dc87,openstack/kuryr-kubernetes,master,I92fbf002c2bd8c7a3fc7f7aee7d1197dc6a7dc87,Drop unnecessary import,MERGED,2018-09-26 13:20:38.000000000,2018-09-27 01:31:43.000000000,2018-09-27 01:31:43.000000000,"[{'_account_id': 6598}, {'_account_id': 11600}, {'_account_id': 14885}, {'_account_id': 22348}, {'_account_id': 23567}]","[{'number': 1, 'created': '2018-09-26 13:20:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/d0fd503d5b63663ed5284188307f34714696bf34', 'message': 'Drop unnecessary import\n\ngenerate_uuid is only ever useful if you have code that needs to process\nuuids also numerically. In our case it only adds indirection and another\nsource of dependency on oslo utils.\n\nChange-Id: I92fbf002c2bd8c7a3fc7f7aee7d1197dc6a7dc87\nSigned-off-by: Antoni Segura Puimedon <celebdor@gmail.com>\n'}, {'number': 2, 'created': '2018-09-26 15:14:48.000000000', 'files': ['kuryr_kubernetes/tests/unit/test_os_vif_util.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_ingress_lbaas.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_sriov.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_lbaas.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_vif_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ef00f3480b8a1cc394f2c65f04ebcf85c337f398', 'message': 'Drop unnecessary import\n\ngenerate_uuid is only ever useful if you have code that needs to process\nuuids also numerically. In our case it only adds indirection and another\nsource of dependency on oslo utils.\n\nChange-Id: I92fbf002c2bd8c7a3fc7f7aee7d1197dc6a7dc87\nSigned-off-by: Antoni Segura Puimedon <celebdor@gmail.com>\n'}]",0,605418,ef00f3480b8a1cc394f2c65f04ebcf85c337f398,10,5,2,14352,,,0,"Drop unnecessary import

generate_uuid is only ever useful if you have code that needs to process
uuids also numerically. In our case it only adds indirection and another
source of dependency on oslo utils.

Change-Id: I92fbf002c2bd8c7a3fc7f7aee7d1197dc6a7dc87
Signed-off-by: Antoni Segura Puimedon <celebdor@gmail.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/18/605418/2 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/tests/unit/test_os_vif_util.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_ingress_lbaas.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_sriov.py', 'kuryr_kubernetes/tests/unit/controller/handlers/test_lbaas.py', 'kuryr_kubernetes/tests/unit/controller/drivers/test_vif_pool.py']",5,d0fd503d5b63663ed5284188307f34714696bf34,ansible, project_id = str(uuid.uuid4()) subnet_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) project_id = str(uuid.uuid4()) subnet_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) project_id = str(uuid.uuid4()) project_id = str(uuid.uuid4()) project_id = str(uuid.uuid4()) project_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) subport_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) port_id1 = str(uuid.uuid4()) trunk_id1 = str(uuid.uuid4()) port_id2 = str(uuid.uuid4()) trunk_id2 = str(uuid.uuid4()) trunk_id=str(uuid.uuid4())) net_id = str(uuid.uuid4()) port_id1 = str(uuid.uuid4()) port_id2 = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) net_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()) port_id = str(uuid.uuid4()) trunk_id = str(uuid.uuid4()),from oslo_utils import uuidutils project_id = uuidutils.generate_uuid() subnet_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() project_id = uuidutils.generate_uuid() subnet_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() project_id = uuidutils.generate_uuid() project_id = uuidutils.generate_uuid() project_id = uuidutils.generate_uuid() project_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() subport_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() port_id1 = uuidutils.generate_uuid() trunk_id1 = uuidutils.generate_uuid() port_id2 = uuidutils.generate_uuid() trunk_id2 = uuidutils.generate_uuid() trunk_id=uuidutils.generate_uuid()) net_id = uuidutils.generate_uuid() port_id1 = uuidutils.generate_uuid() port_id2 = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() net_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid() port_id = uuidutils.generate_uuid() trunk_id = uuidutils.generate_uuid(),92,97
openstack%2Fneutron~master~I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc,openstack/neutron,master,I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc,dhcp: serializing port delete and network rpc calls,MERGED,2017-12-01 19:37:19.000000000,2018-09-27 01:22:35.000000000,2018-05-11 01:51:23.000000000,"[{'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 4694}, {'_account_id': 9732}, {'_account_id': 10385}, {'_account_id': 11975}, {'_account_id': 12860}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 25437}, {'_account_id': 26477}]","[{'number': 1, 'created': '2017-12-01 19:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/224ed76b33ad32f1c0a5fb2333d37c8a3db57b01', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}, {'number': 2, 'created': '2017-12-04 17:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/99b73ec3b721fdf5a36bf4182aa640a13f671722', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}, {'number': 3, 'created': '2017-12-11 13:52:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/23af1bf7074b6d29d3bcefc7aff05ff4b6c41513', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}, {'number': 4, 'created': '2018-03-15 12:24:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/a73eb0f8a855e074c1e2055562ae1e18ddff18ce', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}, {'number': 5, 'created': '2018-03-15 20:11:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/6bdf9c8c96476413b8e40c339e0fec8b7fe47bf0', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}, {'number': 6, 'created': '2018-05-09 19:04:20.000000000', 'files': ['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/agent/dhcp/test_agent.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/fa78b580105111b1238e5b18d415b08e8fb35d97', 'message': 'dhcp: serializing port delete and network rpc calls\n\nThe port delete events are not synchronized with network rpc events.  This\ncreates a condition which makes it possible for a port delete event to be\nprocessed just before a previously started network query completes.\n\nThe problematic order of operations is as follows:\n\n  1) a network is scheduled to an agent; a network rpc is sent to the\n     agent\n\n  2) the agent queries the network data from the server\n\n  3) while that query is in progress a port on that network is deleted; a\n     port rpc is sent to the agent\n\n  4) that port delete rpc is received before the network query rpc\n     completes\n\n  5) the port delete results in no action because the port was not present\n     on the agent\n\n  6) the network query finishes and adds the port to the cache (even\n     though the port has already been deleted)\n\n  7) some time passes and a new port is configured with the same IP\n     address as the port that was deleted in (3)\n\n  8) the dhcp host file is corrupted with 2 entries for the same IP\n     address.\n\n  9) dhcp queries for the newest port is rejected because of the duplicate\n     entry in the dhcp host file.\n\nThe solution is to add the network_id to the port_delete_end rpc event\nso that the _net_lock(network_id) synchronization point can be acquired\nso that it is processed serially with other network related events.\n\nTo ensure backwards compatibility with newer agents running against older\nservers the determination of which network_id value to use in the lock is\nhandled using a utility that will fallback to the previous mode of operation\nwhenever the network_id attribute is not present in the *_delete_end RPC\nevents.  That utility can be removed in the future when it is guaranteed\nthat the network_id attribute will be present in RPC messages from the\nserver.\n\nCloses-Bug: #1732456\n\nChange-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc\nSigned-off-by: Allain Legacy <allain.legacy@windriver.com>\n'}]",9,524711,fa78b580105111b1238e5b18d415b08e8fb35d97,48,12,6,25437,,,0,"dhcp: serializing port delete and network rpc calls

The port delete events are not synchronized with network rpc events.  This
creates a condition which makes it possible for a port delete event to be
processed just before a previously started network query completes.

The problematic order of operations is as follows:

  1) a network is scheduled to an agent; a network rpc is sent to the
     agent

  2) the agent queries the network data from the server

  3) while that query is in progress a port on that network is deleted; a
     port rpc is sent to the agent

  4) that port delete rpc is received before the network query rpc
     completes

  5) the port delete results in no action because the port was not present
     on the agent

  6) the network query finishes and adds the port to the cache (even
     though the port has already been deleted)

  7) some time passes and a new port is configured with the same IP
     address as the port that was deleted in (3)

  8) the dhcp host file is corrupted with 2 entries for the same IP
     address.

  9) dhcp queries for the newest port is rejected because of the duplicate
     entry in the dhcp host file.

The solution is to add the network_id to the port_delete_end rpc event
so that the _net_lock(network_id) synchronization point can be acquired
so that it is processed serially with other network related events.

To ensure backwards compatibility with newer agents running against older
servers the determination of which network_id value to use in the lock is
handled using a utility that will fallback to the previous mode of operation
whenever the network_id attribute is not present in the *_delete_end RPC
events.  That utility can be removed in the future when it is guaranteed
that the network_id attribute will be present in RPC messages from the
server.

Closes-Bug: #1732456

Change-Id: I735f8b1c9248b12e5feb6cbe970cf67f321e6ebc
Signed-off-by: Allain Legacy <allain.legacy@windriver.com>
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/524711/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/agent/dhcp/agent.py', 'neutron/api/rpc/agentnotifiers/dhcp_rpc_agent_api.py', 'neutron/tests/unit/agent/dhcp/test_agent.py']",3,224ed76b33ad32f1c0a5fb2333d37c8a3db57b01,bug/1732456," def test_subnet_delete_end_no_network_id(self): mock.call.get_network_by_subnet_id( 'bbbbbbbb-bbbb-bbbb-bbbbbbbbbbbb'), mock.call.get_network_by_id('12345678-1234-5678-1234567890ab'), mock.call.put(fake_network)]) self.call_driver.assert_called_once_with('restart', fake_network) def test_subnet_update_end_delete_payload(self): prev_state = dhcp.NetModel(dict(id=fake_network.id, tenant_id=fake_network.tenant_id, admin_state_up=True, subnets=[fake_subnet1, fake_subnet3], ports=[fake_port1])) payload = dict(subnet_id=fake_subnet1.id, network_id=fake_network.id) self.cache.get_network_by_subnet_id.return_value = prev_state self.cache.get_network_by_id.return_value = prev_state self.plugin.get_network_info.return_value = fake_network self.dhcp.subnet_delete_end(None, payload) self.cache.assert_has_calls([ mock.call.get_network_by_subnet_id( 'bbbbbbbb-bbbb-bbbb-bbbbbbbbbbbb'), def test_port_delete_end_no_network_id(self): mock.call.deleted_ports.add(fake_port2.id), mock.call.get_network_by_id(fake_network.id), mock.call.remove_port(fake_port2)]) self.call_driver.assert_has_calls( [mock.call.call_driver('reload_allocations', fake_network)]) def test_port_delete_end(self): payload = dict(port_id=fake_port2.id, network_id=fake_network.id) self.cache.get_network_by_id.return_value = fake_network self.cache.get_port_by_id.return_value = fake_port2 self.dhcp.port_delete_end(None, payload) self.cache.assert_has_calls( [mock.call.get_port_by_id(fake_port2.id), mock.call.deleted_ports.add(fake_port2.id), payload = dict(port_id='unknown', network_id='unknown') self.dhcp.port_delete_end(None, {'port_id': port.id, 'network_id': fake_network.id})"," def test_subnet_update_end_delete_payload(self): def test_port_delete_end(self): mock.call.deleted_ports.add(fake_port2.id), payload = dict(port_id='unknown') self.dhcp.port_delete_end(None, {'port_id': port.id})",70,16
openstack%2Ftripleo-heat-templates~master~Iee477ea736aff4290b703cd70258966819228c4a,openstack/tripleo-heat-templates,master,Iee477ea736aff4290b703cd70258966819228c4a,Add simple validation that OpenShift is deployed,MERGED,2018-09-05 14:10:02.000000000,2018-09-27 01:12:07.000000000,2018-09-27 01:12:07.000000000,"[{'_account_id': 4330}, {'_account_id': 6159}, {'_account_id': 6926}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-05 14:10:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc129774361634fbf4301e6456cfb6b7941fd2cd', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 2, 'created': '2018-09-05 18:29:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1bb167dcefe72d246fc2fc56e3be486312475c59', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 3, 'created': '2018-09-06 12:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/49fb21fddf1ed3907216b4044de4d63b5822dc23', 'message': 'Add simple validation that OpenShift is deployed\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 4, 'created': '2018-09-06 12:24:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/296184bb7fec9c9df83a8eeaf64608e43582c782', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 5, 'created': '2018-09-06 12:46:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/609350f16e2ebc4ef3b3bfb618a4441167fdcd80', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 6, 'created': '2018-09-07 16:15:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d87beefdd518f1ac4850e9d7101eb9d8619ace87', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 7, 'created': '2018-09-10 13:32:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/74c6ba9e52a4729586b8d71a9199c027a01655bb', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 8, 'created': '2018-09-12 16:08:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3daa2f3ecea71b88d564b8e38af13ea85d910673', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 9, 'created': '2018-09-12 20:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/235124f7d47ee1ce44b2c0d9d135b2ea6ba833c3', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 10, 'created': '2018-09-13 13:15:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/465150bafefa2f5a0b6ecb88fd84d1fba3a7de07', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 11, 'created': '2018-09-14 13:40:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/157c6da601af88e4ba5c732c0c4937dfeacfe611', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 12, 'created': '2018-09-14 18:18:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/956ef61ee80eb96bd0079ee7374df20953ec44f2', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 13, 'created': '2018-09-14 21:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1751c9e948316b001ccd8050abdbcc49e3f433fe', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: I05457605a1265e7c44f92a883d17cca3e7b0ccf6\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\nDepends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 14, 'created': '2018-09-15 03:12:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0e7bd451a1fda9fedf8e321e2632af04bd6c814e', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\nDepends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 15, 'created': '2018-09-17 13:26:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81b66f022fcb5f49c9c4596b9ec6ee3e2a2c1f9d', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\nDepends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 16, 'created': '2018-09-17 13:29:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ed18b6415bc9fc4a96061a2e8c83bca9bb3b547', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\nDepends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}, {'number': 17, 'created': '2018-09-25 16:47:08.000000000', 'files': ['extraconfig/services/openshift-master.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/df04ed93154c30dd54885dde92aad896bb4dcbda', 'message': 'Add simple validation that OpenShift is deployed\n\nCurrently, we have no test to check if we actually deploy OpenShift\nat the end of the scenario009 job. This can easily lead to false\npositives from this job if some deploy step fails silently.\n\nThis patch adds two very basic commands to check if the OpenShift\ncluster is actually operational.\n\nDepends-On: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\nDepends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\nDepends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221\n\nChange-Id: Iee477ea736aff4290b703cd70258966819228c4a\n'}]",3,600067,df04ed93154c30dd54885dde92aad896bb4dcbda,56,8,17,12715,,,0,"Add simple validation that OpenShift is deployed

Currently, we have no test to check if we actually deploy OpenShift
at the end of the scenario009 job. This can easily lead to false
positives from this job if some deploy step fails silently.

This patch adds two very basic commands to check if the OpenShift
cluster is actually operational.

Depends-On: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293
Depends-On: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a
Depends-On: Ie21cc0dfed28353a13d419ff38cea82e65166221

Change-Id: Iee477ea736aff4290b703cd70258966819228c4a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/600067/10 && git format-patch -1 --stdout FETCH_HEAD,['extraconfig/services/openshift-master.yaml'],1,dc129774361634fbf4301e6456cfb6b7941fd2cd,tripleo-openshift," - name: Simple validation OpenShift is actually deployed hosts: masters tasks: - name: Check oc status command: oc status --suggest register: oc_status become: true - name: Register failure if oc status fails command: echo true register: oc_status_failed when: '""svc/kubernetes"" not in oc_status.stdout' - debug: var: oc_status.stdout_lines - name: Check oc get nodes command: oc get nodes --all-namespaces register: oc_get_nodes become: true - name: Register failure if oc get nodes fails command: echo true register: oc_get_nodes_failed when: '""Ready"" not in oc_get_nodes.stdout' - debug: var: oc_get_nodes.stdout_lines - name: Fail the playbook if any validations failed fail: when: oc_status_failed.changed or oc_get_nodes_failed.changed ",,34,0
openstack%2Fheat~stable%2Focata~I5a1eff6b704dff7c17edcbbe58cdbc380ae6abc9,openstack/heat,stable/ocata,I5a1eff6b704dff7c17edcbbe58cdbc380ae6abc9,Unit tests: Fix mock errors with too few side effects,MERGED,2018-08-10 21:49:51.000000000,2018-09-27 01:04:55.000000000,2018-09-27 01:04:55.000000000,"[{'_account_id': 4257}, {'_account_id': 4328}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-10 21:49:51.000000000', 'files': ['heat/tests/openstack/heat/test_swiftsignal.py', 'heat/tests/openstack/nova/test_server.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ab7b0c30dbf3b4063b0d2dd90bd38313b29591f2', 'message': ""Unit tests: Fix mock errors with too few side effects\n\nWhen a mock hasn't been provided with a long-enough list of side-effects\nfor the number of times it is called, it raises StopIteration (instead\nof something sensible like AssertionError). Prior to Python 3.7, this\nexception could bubble up until it just stopped a task. (In Python 3.7\nit will eventually be caught and turned into a RuntimeError.)\n\nTo ensure that any errors of this sort are not handled silently, and to\nenable us to test for them prior to using Python 3.7, catch any\nStopIteration errors coming from plugin-provided non-generator functions\nand convert them to RuntimeError exceptions.\n\nThis reveals many errors in the unit tests, which are also fixed by this\npatch. This backport contains fewer fixes than master, because many of\nthe errors were introduced in the process of moving from mox to mock in\nthe Rocky release cycle.\n\nChange-Id: I5a1eff6b704dff7c17edcbbe58cdbc380ae6abc9\nStory: #2003412\nTask: 24553\n(cherry picked from commit 38fad07c0a01072ee4e17815f6ad0e5c2ce1f64a)\n""}]",0,591100,ab7b0c30dbf3b4063b0d2dd90bd38313b29591f2,7,3,1,4257,,,0,"Unit tests: Fix mock errors with too few side effects

When a mock hasn't been provided with a long-enough list of side-effects
for the number of times it is called, it raises StopIteration (instead
of something sensible like AssertionError). Prior to Python 3.7, this
exception could bubble up until it just stopped a task. (In Python 3.7
it will eventually be caught and turned into a RuntimeError.)

To ensure that any errors of this sort are not handled silently, and to
enable us to test for them prior to using Python 3.7, catch any
StopIteration errors coming from plugin-provided non-generator functions
and convert them to RuntimeError exceptions.

This reveals many errors in the unit tests, which are also fixed by this
patch. This backport contains fewer fixes than master, because many of
the errors were introduced in the process of moving from mox to mock in
the Rocky release cycle.

Change-Id: I5a1eff6b704dff7c17edcbbe58cdbc380ae6abc9
Story: #2003412
Task: 24553
(cherry picked from commit 38fad07c0a01072ee4e17815f6ad0e5c2ce1f64a)
",git fetch https://review.opendev.org/openstack/heat refs/changes/00/591100/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/tests/openstack/heat/test_swiftsignal.py', 'heat/tests/openstack/nova/test_server.py', 'heat/engine/resource.py', 'heat/tests/test_resource.py']",4,ab7b0c30dbf3b4063b0d2dd90bd38313b29591f2,," create_excs = [ self.patchobject(generic_rsrc.ResourceWithProps, 'handle_create', side_effect=create_excs) self.patchobject(generic_rsrc.ResourceWithProps, 'handle_delete', return_value=None)", generic_rsrc.ResourceWithProps.handle_create = mock.Mock() generic_rsrc.ResourceWithProps.handle_delete = mock.Mock() generic_rsrc.ResourceWithProps.handle_create.side_effect = [ generic_rsrc.ResourceWithProps.handle_delete.return_value = None,76,76
openstack%2Fmanila~stable%2Fpike~Ie506f237010c415ee9f0d64abbefd5854f776a5f,openstack/manila,stable/pike,Ie506f237010c415ee9f0d64abbefd5854f776a5f,[ZFSOnLinux] Retry unmounting old datasets during manage,MERGED,2018-09-25 11:55:47.000000000,2018-09-27 00:19:56.000000000,2018-09-27 00:19:56.000000000,"[{'_account_id': 8871}, {'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 24236}, {'_account_id': 25243}]","[{'number': 1, 'created': '2018-09-25 11:55:47.000000000', 'files': ['manila/tests/share/drivers/zfsonlinux/test_driver.py', 'releasenotes/notes/bug-1785180-zfsonlinux-retry-unmounting-during-manage-872cf46313c5a4ff.yaml', 'manila/share/drivers/zfsonlinux/driver.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/efbc62d9b29e94dd45339fa78da93a6a85532271', 'message': '[ZFSOnLinux] Retry unmounting old datasets during manage\n\nAdd a retry loop to ensure the dataset being renamed\nis cleanly unmounted before the rename operation.\n\nChange-Id: Ie506f237010c415ee9f0d64abbefd5854f776a5f\nCloses-Bug: #1785180\n(cherry picked from commit d7c01efb444b7bf02c1729be3554abebaee473a3)\n(cherry picked from commit 6d8f47d3c367aa0247dca713146825cfa66b6848)\n(cherry picked from commit 820638ccef471eb00f2a233e64b05a9c377e170c)\n'}]",0,605050,efbc62d9b29e94dd45339fa78da93a6a85532271,14,7,1,9003,,,0,"[ZFSOnLinux] Retry unmounting old datasets during manage

Add a retry loop to ensure the dataset being renamed
is cleanly unmounted before the rename operation.

Change-Id: Ie506f237010c415ee9f0d64abbefd5854f776a5f
Closes-Bug: #1785180
(cherry picked from commit d7c01efb444b7bf02c1729be3554abebaee473a3)
(cherry picked from commit 6d8f47d3c367aa0247dca713146825cfa66b6848)
(cherry picked from commit 820638ccef471eb00f2a233e64b05a9c377e170c)
",git fetch https://review.opendev.org/openstack/manila refs/changes/50/605050/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/share/drivers/zfsonlinux/test_driver.py', 'releasenotes/notes/bug-1785180-zfsonlinux-retry-unmounting-during-manage-872cf46313c5a4ff.yaml', 'manila/share/drivers/zfsonlinux/driver.py']",3,efbc62d9b29e94dd45339fa78da93a6a85532271,bug/1785180-stable/rocky-stable/queens-stable/pike," # Unmount the dataset before attempting to rename and mount try: self._unmount_share_with_retry(old_dataset_name) except exception.ZFSonLinuxException: msg = _(""Unable to unmount share before renaming and re-mounting."") raise exception.ZFSonLinuxException(message=msg) # Rename the dataset and mount with new name try: self.zfs(""mount"", new_dataset_name) except exception.ProcessExecutionError: # Workaround for bug/1785180 out, err = self.zfs(""mount"") mounted = any([new_dataset_name in mountedfs for mountedfs in out.splitlines()]) if not mounted: raise self.private_storage.update( share[""id""], { ""entity_type"": ""share"", ""dataset_name"": new_dataset_name, ""ssh_cmd"": ssh_cmd, # used in replication ""pool_name"": actual_pool_name, # used in replication ""used_options"": "" "".join(options), } ) @utils.retry(exception.ZFSonLinuxException) def _unmount_share_with_retry(self, share_name): out, err = self.execute(""sudo"", ""mount"") if ""%s "" % share_name not in out: return self.zfs_with_retry(""umount"", ""-f"", share_name) out, err = self.execute(""sudo"", ""mount"") if ""%s "" % share_name in out: raise exception.ZFSonLinuxException( _(""Unable to unmount dataset %s""), share_name) "," self.private_storage.update( share[""id""], { ""entity_type"": ""share"", ""dataset_name"": new_dataset_name, ""ssh_cmd"": ssh_cmd, # used in replication ""pool_name"": actual_pool_name, # used in replication ""used_options"": "" "".join(options), } ) # Rename dataset out, err = self.execute(""sudo"", ""mount"") if ""%s "" % old_dataset_name in out: self.zfs_with_retry(""umount"", ""-f"", old_dataset_name) time.sleep(1) self.zfs(""mount"", new_dataset_name)",116,22
openstack%2Fswift~master~I070c21bc1eaf1c71ac0652cec9e813cadcc14851,openstack/swift,master,I070c21bc1eaf1c71ac0652cec9e813cadcc14851,Configure diskfile per storage policy,MERGED,2017-03-17 20:38:22.000000000,2018-09-27 00:19:32.000000000,2018-09-27 00:19:32.000000000,"[{'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 4608}, {'_account_id': 7233}, {'_account_id': 7847}, {'_account_id': 9625}, {'_account_id': 13052}, {'_account_id': 13852}, {'_account_id': 14766}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 25251}]","[{'number': 1, 'created': '2017-03-17 20:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/915db8631e7d8e1fa5f698aad055dfacfb76f27f', 'message': 'WIP: Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Configuration of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n\n    diskfile = replication.fs\n    diskfile.devices = /srv/1/node\n    diskfile.mount_check = false\n    diskfile.disable_fallocate = true\n\nIt even allows for different storage policy to use different\nconfiguration for the same diskfile (eg: keep_cache_size, reclaim_age,\n...)\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.diskfile_manager.get_diskfile(...)\n\nFIXME: it breaks SAIO as configuration parameter ""devices""\n(eg: /srv/1/node) is now in swift.conf, but there can\'t be one swift.conf\nper object-server instance\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 2, 'created': '2017-03-20 17:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ab0f7b7c645e920b4adc45f41a178a63c47a4dd0', 'message': 'WIP: Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = replication.fs\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 3, 'created': '2017-09-13 21:04:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ffc9797c83a18b2db2a34cf65b14f3ee8dfbf8f0', 'message': 'WIP: Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 4, 'created': '2017-09-21 15:43:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f69239b8bb66ef4dd4ec5b2e196fe57b28829946', 'message': 'WIP: Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 5, 'created': '2018-02-28 11:17:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d41b92e067484044049ee9914eacf9709cf1d2b0', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 6, 'created': '2018-02-28 13:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/bf70425028ebee5e8e7ae551dba60995ca7aeae3', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 7, 'created': '2018-02-28 16:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/e1432f88628ea5085ff9a092ee6d161350451f6c', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 8, 'created': '2018-05-30 10:08:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4661bf48fa6eecbe57cd43f5e54093015a759a22', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 9, 'created': '2018-06-01 15:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/c5b6202f36c364f4d700aa19f8c312a41ca53783', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 10, 'created': '2018-06-06 12:29:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/fd290c33fa3328a62400bc8f2b736330440ca8be', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed through\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 11, 'created': '2018-06-29 15:28:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1888d91428e59cab55845804ffa21b3406ae881f', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed\nthrough\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 12, 'created': '2018-06-29 15:30:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/dfe74caca1352d1bee4a05055359acb71f1f9692', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed\nthrough\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 13, 'created': '2018-07-02 13:19:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/058c5ee562da3f75ba12140f5afd991ead4f5542', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed\nthrough\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 14, 'created': '2018-07-02 16:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/29065746b5957026010654ac99cb6c422ff95ae9', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nThe DiskFileRouter is removed. The DiskFileManager is now accessed\nthrough\nthe policy instance:\n    df_router[policy].get_diskfile(...)\nbecome:\n    policy.load_diskfile_manager(conf, logger)\n    policy.diskfile_manager\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 15, 'created': '2018-07-03 15:04:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/909e50983e91192ba665c1f258142265eded5ea0', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 16, 'created': '2018-07-03 18:01:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/30db6a95721e18c40027d199e5c6b1f1a5c84929', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 17, 'created': '2018-07-25 08:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/6b6f4181e73c9e6ecee769d7f5b1c36fb9b579c7', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 18, 'created': '2018-07-25 10:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/4b850da4c9f600aaead6ccfc987c3481c21244fe', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alexandre Lcuyer <alexandre.lecuyer@corp.ovh.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 19, 'created': '2018-08-23 05:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/71124752e4b3977e826f6bc6b636f7f2a1be91ed', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alexandre Lcuyer <alexandre.lecuyer@corp.ovh.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}, {'number': 20, 'created': '2018-08-24 02:29:13.000000000', 'files': ['doc/source/overview_policies.rst', 'test/unit/common/test_storage_policy.py', 'swift/common/utils.py', 'test/unit/cli/test_relinker.py', 'swift/common/storage_policy.py', 'etc/swift.conf-sample', 'test/unit/obj/test_diskfile.py', 'setup.cfg', 'test/unit/common/test_utils.py', 'swift/obj/diskfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/673fda76203be7c70afe6236d3fadc88deb75117', 'message': 'Configure diskfile per storage policy\n\nWith this commit, each storage policy can define the diskfile to use to\naccess objects. Selection of the diskfile is done in swift.conf.\n\nExample:\n    [storage-policy:0]\n    name = gold\n    policy_type = replication\n    default = yes\n    diskfile = egg:swift#replication.fs\n\nThe diskfile configuration item accepts the same format than middlewares\ndeclaration: [[scheme:]egg_name#]entry_point\nThe egg_name is optional and default to ""swift"". The scheme is optional\nand default to the only valid value ""egg"". The upstream entry points are\n""replication.fs"" and ""erasure_coding.fs"".\n\nCo-Authored-By: Alexandre Lcuyer <alexandre.lecuyer@corp.ovh.com>\nCo-Authored-By: Alistair Coles <alistairncoles@gmail.com>\nChange-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851\n'}]",83,447129,673fda76203be7c70afe6236d3fadc88deb75117,75,12,20,13852,,,0,"Configure diskfile per storage policy

With this commit, each storage policy can define the diskfile to use to
access objects. Selection of the diskfile is done in swift.conf.

Example:
    [storage-policy:0]
    name = gold
    policy_type = replication
    default = yes
    diskfile = egg:swift#replication.fs

The diskfile configuration item accepts the same format than middlewares
declaration: [[scheme:]egg_name#]entry_point
The egg_name is optional and default to ""swift"". The scheme is optional
and default to the only valid value ""egg"". The upstream entry points are
""replication.fs"" and ""erasure_coding.fs"".

Co-Authored-By: Alexandre Lcuyer <alexandre.lecuyer@corp.ovh.com>
Co-Authored-By: Alistair Coles <alistairncoles@gmail.com>
Change-Id: I070c21bc1eaf1c71ac0652cec9e813cadcc14851
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/447129/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/obj/replicator.py', 'swift/obj/server.py', 'swift/obj/reconstructor.py', 'swift/obj/auditor.py', 'swift/common/storage_policy.py', 'setup.cfg', 'swift/obj/diskfile.py']",7,915db8631e7d8e1fa5f698aad055dfacfb76f27f,feature/load_diskfile,,"class DiskFileRouter(object): policy_type_to_manager_cls = {} @classmethod def register(cls, policy_type): """""" Decorator for Storage Policy implementations to register their DiskFile implementation. """""" def register_wrapper(diskfile_cls): if policy_type in cls.policy_type_to_manager_cls: raise PolicyError( '%r is already registered for the policy_type %r' % ( cls.policy_type_to_manager_cls[policy_type], policy_type)) cls.policy_type_to_manager_cls[policy_type] = diskfile_cls return diskfile_cls return register_wrapper def __init__(self, *args, **kwargs): self.policy_to_manager = {} for policy in POLICIES: manager_cls = self.policy_type_to_manager_cls[policy.policy_type] self.policy_to_manager[policy] = manager_cls(*args, **kwargs) def __getitem__(self, policy): return self.policy_to_manager[policy] @DiskFileRouter.register(REPL_POLICY)@DiskFileRouter.register(EC_POLICY)",48,53
openstack%2Fopenstack-ansible-ops~master~Idb20e298d4f0f7f4ab175a2810492b9842f30f8b,openstack/openstack-ansible-ops,master,Idb20e298d4f0f7f4ab175a2810492b9842f30f8b,MNAIO: Only adjust user_variables.yml if pre_config_osa is true,MERGED,2018-09-26 16:41:40.000000000,2018-09-27 00:12:54.000000000,2018-09-27 00:12:54.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 16:41:40.000000000', 'files': ['multi-node-aio/playbooks/deploy-osa.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/404b9a77db8a8496ec113ede0c845a32ffd79e42', 'message': ""MNAIO: Only adjust user_variables.yml if pre_config_osa is true\n\nIf pre_config_osa is not true, then the folder won't exist and\nthe task will fail.\n\nChange-Id: Idb20e298d4f0f7f4ab175a2810492b9842f30f8b\n""}]",0,605484,404b9a77db8a8496ec113ede0c845a32ffd79e42,6,2,1,6816,,,0,"MNAIO: Only adjust user_variables.yml if pre_config_osa is true

If pre_config_osa is not true, then the folder won't exist and
the task will fail.

Change-Id: Idb20e298d4f0f7f4ab175a2810492b9842f30f8b
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/84/605484/1 && git format-patch -1 --stdout FETCH_HEAD,['multi-node-aio/playbooks/deploy-osa.yml'],1,404b9a77db8a8496ec113ede0c845a32ffd79e42,, when: - pre_config_osa | default(true) | bool,,2,0
openstack%2Fnetworking-sfc~stable%2Fqueens~I8f0a99a07d9f7361c5729db456eb26acad90a741,openstack/networking-sfc,stable/queens,I8f0a99a07d9f7361c5729db456eb26acad90a741,import zuul job settings from project-config,MERGED,2018-08-30 00:08:55.000000000,2018-09-27 00:01:48.000000000,2018-09-27 00:01:48.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 17130}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-30 00:08:55.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/31265a7a5f1e23ba50e4e9cf58d35685c6bbf27d', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I8f0a99a07d9f7361c5729db456eb26acad90a741\nStory: #2002586\nTask: #24314\n'}]",0,597940,31265a7a5f1e23ba50e4e9cf58d35685c6bbf27d,10,6,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I8f0a99a07d9f7361c5729db456eb26acad90a741
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/40/597940/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,31265a7a5f1e23ba50e4e9cf58d35685c6bbf27d,python3-first, templates: - openstack-python-jobs-neutron - publish-openstack-sphinx-docs - check-requirements - openstack-python35-jobs-neutron - release-notes-jobs, name: openstack/networking-sfc,6,1
openstack%2Fnetworking-sfc~stable%2Frocky~Id25bbd8a8813239b9f0c3b013eff963618864ea1,openstack/networking-sfc,stable/rocky,Id25bbd8a8813239b9f0c3b013eff963618864ea1,import zuul job settings from project-config,MERGED,2018-08-30 00:09:52.000000000,2018-09-27 00:01:46.000000000,2018-09-27 00:01:46.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 17130}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-30 00:09:52.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/networking-sfc/commit/07e16141437f9b35a3cca313e2ed1ea422f2a834', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: Id25bbd8a8813239b9f0c3b013eff963618864ea1\nStory: #2002586\nTask: #24314\n'}]",0,597955,07e16141437f9b35a3cca313e2ed1ea422f2a834,10,6,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: Id25bbd8a8813239b9f0c3b013eff963618864ea1
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/networking-sfc refs/changes/55/597955/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,07e16141437f9b35a3cca313e2ed1ea422f2a834,python3-first, templates: - openstack-python-jobs-neutron - publish-openstack-sphinx-docs - check-requirements - openstack-python35-jobs-neutron - release-notes-jobs,,6,0
openstack%2Fproject-config~master~I5cbf6ef41d9d4e1d22f3b9f35214c47b46d6e05b,openstack/project-config,master,I5cbf6ef41d9d4e1d22f3b9f35214c47b46d6e05b,Add ansible-role-chrony project,MERGED,2018-09-18 20:23:42.000000000,2018-09-26 23:44:38.000000000,2018-09-26 23:44:38.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 10873}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-18 20:23:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/0e164521d5fb49a62e862b6ebd2e32c18650ce40', 'message': 'Add ansible-role-chrony project\n\nChange-Id: I5cbf6ef41d9d4e1d22f3b9f35214c47b46d6e05b\nRelated-Blueprint: tripleo-chrony\n'}, {'number': 2, 'created': '2018-09-18 22:09:16.000000000', 'files': ['gerritbot/channels.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/a5a08f24c1d9ae543599e7e93a79a9237fca9420', 'message': 'Add ansible-role-chrony project\n\nNeeded-By: https://review.openstack.org/#/c/603516/\nChange-Id: I5cbf6ef41d9d4e1d22f3b9f35214c47b46d6e05b\nRelated-Blueprint: tripleo-chrony\n'}]",0,603489,a5a08f24c1d9ae543599e7e93a79a9237fca9420,13,5,2,14985,,,0,"Add ansible-role-chrony project

Needed-By: https://review.openstack.org/#/c/603516/
Change-Id: I5cbf6ef41d9d4e1d22f3b9f35214c47b46d6e05b
Related-Blueprint: tripleo-chrony
",git fetch https://review.opendev.org/openstack/project-config refs/changes/89/603489/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/projects.yaml', 'zuul/main.yaml']",3,0e164521d5fb49a62e862b6ebd2e32c18650ce40,bp/tripleo-chrony, - openstack/ansible-role-chrony,,8,0
openstack%2Fopenstack-helm~master~Ibf4499ac1f95b9ea7cced62cff7add6a36dd1b18,openstack/openstack-helm,master,Ibf4499ac1f95b9ea7cced62cff7add6a36dd1b18,testing,ABANDONED,2018-09-26 23:12:14.000000000,2018-09-26 23:12:55.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2018-09-26 23:12:14.000000000', 'files': ['doc/source/testing.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/f96ff526e68e45f1a940bcd1d10d7a5337202302', 'message': 'testing\n\nChange-Id: Ibf4499ac1f95b9ea7cced62cff7add6a36dd1b18\n'}]",0,605555,f96ff526e68e45f1a940bcd1d10d7a5337202302,3,1,1,29203,,,0,"testing

Change-Id: Ibf4499ac1f95b9ea7cced62cff7add6a36dd1b18
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/55/605555/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/testing.rst'],1,f96ff526e68e45f1a940bcd1d10d7a5337202302,,testing ,,1,0
openstack%2Fopenstack-helm~master~Id60fe27077123a1919ce4df4b385dee9fdfe921b,openstack/openstack-helm,master,Id60fe27077123a1919ce4df4b385dee9fdfe921b,[US403568]: Test update,ABANDONED,2018-09-26 23:09:58.000000000,2018-09-26 23:10:39.000000000,,"[{'_account_id': 10068}, {'_account_id': 22214}]","[{'number': 1, 'created': '2018-09-26 23:09:58.000000000', 'files': ['doc/source/testing.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8fc55f6b489d06c124aeb3a9782b8f624c888085', 'message': '[US403568]: Test update\n\nChange-Id: Id60fe27077123a1919ce4df4b385dee9fdfe921b\n'}]",0,605554,8fc55f6b489d06c124aeb3a9782b8f624c888085,4,2,1,22214,,,0,"[US403568]: Test update

Change-Id: Id60fe27077123a1919ce4df4b385dee9fdfe921b
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/54/605554/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/testing.rst'],1,8fc55f6b489d06c124aeb3a9782b8f624c888085,,,,0,0
openstack%2Fopenstack-helm~master~Id6cd3403ce14d9ad7f6ade572f21523dd764224d,openstack/openstack-helm,master,Id6cd3403ce14d9ad7f6ade572f21523dd764224d,Testing first commit,ABANDONED,2018-09-26 23:08:29.000000000,2018-09-26 23:09:46.000000000,,"[{'_account_id': 10068}, {'_account_id': 29202}]","[{'number': 1, 'created': '2018-09-26 23:08:29.000000000', 'files': ['doc/source/testing1.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b10099606ed50b4cece5e76dcf33ffe90cc4ca18', 'message': 'Testing first commit\n\nChange-Id: Id6cd3403ce14d9ad7f6ade572f21523dd764224d\n'}]",0,605553,b10099606ed50b4cece5e76dcf33ffe90cc4ca18,4,2,1,29202,,,0,"Testing first commit

Change-Id: Id6cd3403ce14d9ad7f6ade572f21523dd764224d
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/53/605553/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/testing1.rst'],1,b10099606ed50b4cece5e76dcf33ffe90cc4ca18,,,,0,0
openstack%2Frally-openstack~master~I3afb4a4e78a6145ea95b37dfa7d5015ed4ae1a18,openstack/rally-openstack,master,I3afb4a4e78a6145ea95b37dfa7d5015ed4ae1a18,Remove deprecated NovaImages.list_images scenario,MERGED,2018-09-26 11:43:50.000000000,2018-09-26 22:50:18.000000000,2018-09-26 22:50:17.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 11:43:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/c95d35da35e53d77143ed6d7a7c331df93510c97', 'message': 'Remove deprecated NovaImages.list_images scenario\n\nThis scenario was deprecated in Rally 0.10\n\nChange-Id: I3afb4a4e78a6145ea95b37dfa7d5015ed4ae1a18\n'}, {'number': 2, 'created': '2018-09-26 11:54:14.000000000', 'files': ['tests/unit/scenarios/nova/test_utils.py', 'rally_openstack/scenarios/nova/utils.py', 'tests/unit/scenarios/nova/test_images.py', 'rally_openstack/scenarios/nova/images.py', 'samples/tasks/scenarios/nova/list-images.yaml', 'rally-jobs/nova.yaml', 'samples/tasks/scenarios/nova/list-images.json', 'CHANGELOG.rst'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/781736cf52285dab06becf8c2ac7e181da59f2e2', 'message': 'Remove deprecated NovaImages.list_images scenario\n\nThis scenario was deprecated in Rally 0.10\n\nChange-Id: I3afb4a4e78a6145ea95b37dfa7d5015ed4ae1a18\n'}]",0,605404,781736cf52285dab06becf8c2ac7e181da59f2e2,7,2,2,9545,,,0,"Remove deprecated NovaImages.list_images scenario

This scenario was deprecated in Rally 0.10

Change-Id: I3afb4a4e78a6145ea95b37dfa7d5015ed4ae1a18
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/04/605404/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/scenarios/nova/test_images.py', 'rally_openstack/scenarios/nova/images.py', 'CHANGELOG.rst']",3,c95d35da35e53d77143ed6d7a7c331df93510c97,nova.create_image,* Remove deprecated in Rally 0.10.0 ``NovaImages.list_images`` scenario.,,1,72
openstack%2Fneutron-dynamic-routing~stable%2Frocky~I53566dc319d042c28fa1eccb68392e6fe67a231e,openstack/neutron-dynamic-routing,stable/rocky,I53566dc319d042c28fa1eccb68392e6fe67a231e,import zuul job settings from project-config,MERGED,2018-08-30 00:10:01.000000000,2018-09-26 22:35:57.000000000,2018-09-26 22:35:57.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 22348}, {'_account_id': 27153}]","[{'number': 1, 'created': '2018-08-30 00:10:01.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-dynamic-routing/commit/d10a8dcfc3519b597b2751661ea173fc444a8c17', 'message': 'import zuul job settings from project-config\n\nThis is a mechanically generated patch to complete step 1 of moving\nthe zuul job settings out of project-config and into each project\nrepository.\n\nBecause there will be a separate patch on each branch, the branch\nspecifiers for branch-specific jobs have been removed.\n\nBecause this patch is generated by a script, there may be some\ncosmetic changes to the layout of the YAML file(s) as the contents are\nnormalized.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: I53566dc319d042c28fa1eccb68392e6fe67a231e\nStory: #2002586\nTask: #24314\n'}]",0,597957,d10a8dcfc3519b597b2751661ea173fc444a8c17,8,4,1,2472,,,0,"import zuul job settings from project-config

This is a mechanically generated patch to complete step 1 of moving
the zuul job settings out of project-config and into each project
repository.

Because there will be a separate patch on each branch, the branch
specifiers for branch-specific jobs have been removed.

Because this patch is generated by a script, there may be some
cosmetic changes to the layout of the YAML file(s) as the contents are
normalized.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: I53566dc319d042c28fa1eccb68392e6fe67a231e
Story: #2002586
Task: #24314
",git fetch https://review.opendev.org/openstack/neutron-dynamic-routing refs/changes/57/597957/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,d10a8dcfc3519b597b2751661ea173fc444a8c17,python3-first, templates: - check-requirements - openstack-python-jobs-neutron - openstack-python35-jobs-neutron - publish-openstack-sphinx-docs - release-notes-jobs - legacy-periodic-neutron-dynamic-routing-dsvm-tempest-with-ryu-master-scenario-ipv4 post: jobs: - openstack-tox-cover: required-projects: - openstack/neutron,,12,0
openstack%2Ftripleo-common~master~Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a,openstack/tripleo-common,master,Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a,Add container-registry image to openshift master role,MERGED,2018-09-12 17:44:13.000000000,2018-09-26 22:33:27.000000000,2018-09-26 22:33:27.000000000,"[{'_account_id': 4328}, {'_account_id': 6159}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-12 17:44:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ebf2334b81edee2ab2edd90758fa2b8bda5467a8', 'message': 'WIP: Add master service for container-registry image\n\nThis image is not getting created in the scenario009 job. Testing\nif this resolves the issue.\n\nChange-Id: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n'}, {'number': 2, 'created': '2018-09-12 20:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e596cdeea36d72a4edc66c7318d003704fbb10d7', 'message': 'Add container-registry image to openshift master role\n\nWe need this image in scenario009 where we only deploy the master role.\n\nChange-Id: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n'}, {'number': 3, 'created': '2018-09-19 13:10:17.000000000', 'files': ['container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/19388f526710e22eaec7aa0f82af4e5eec9a9f2d', 'message': 'Add container-registry image to openshift master role\n\nWe need this image in scenario009 where we only deploy the master role.\n\nChange-Id: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a\n'}]",1,602112,19388f526710e22eaec7aa0f82af4e5eec9a9f2d,20,6,3,12715,,,0,"Add container-registry image to openshift master role

We need this image in scenario009 where we only deploy the master role.

Change-Id: Id24a7a0d9d34df4fd52ee1f99da61b873e5b870a
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/12/602112/3 && git format-patch -1 --stdout FETCH_HEAD,['container-images/overcloud_containers.yaml.j2'],1,ebf2334b81edee2ab2edd90758fa2b8bda5467a8,openshift, - OS::TripelO::Services::OpenShift::Master,,1,0
openstack%2Fopenstack-ansible~stable%2Fpike~Ia5fde1fb0cec6ef0a8937d4696b2e928be51e9aa,openstack/openstack-ansible,stable/pike,Ia5fde1fb0cec6ef0a8937d4696b2e928be51e9aa,Update all SHAs for 16.0.20,MERGED,2018-09-23 14:26:57.000000000,2018-09-26 22:29:11.000000000,2018-09-26 22:29:11.000000000,"[{'_account_id': 1004}, {'_account_id': 6816}, {'_account_id': 7414}, {'_account_id': 19298}, {'_account_id': 21486}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-23 14:26:57.000000000', 'files': ['playbooks/defaults/repo_packages/openstack_services.yml', 'group_vars/all/all.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2650ba13417356cef8fae69f4d4842da34acb78b', 'message': 'Update all SHAs for 16.0.20\n\nThis patch:\n- updates all the roles to the latest available stable SHAs\n- copies the release notes from the updated roles into the integrated repo\n- updates all the OpenStack Service SHAs\nDepends-On: https://review.openstack.org/604623\n\nChange-Id: Ia5fde1fb0cec6ef0a8937d4696b2e928be51e9aa\n'}]",0,604624,2650ba13417356cef8fae69f4d4842da34acb78b,21,6,1,17068,,,0,"Update all SHAs for 16.0.20

This patch:
- updates all the roles to the latest available stable SHAs
- copies the release notes from the updated roles into the integrated repo
- updates all the OpenStack Service SHAs
Depends-On: https://review.openstack.org/604623

Change-Id: Ia5fde1fb0cec6ef0a8937d4696b2e928be51e9aa
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/24/604624/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/defaults/repo_packages/openstack_services.yml', 'group_vars/all/all.yml', 'playbooks/defaults/repo_packages/gnocchi.yml', 'ansible-role-requirements.yml']",4,2650ba13417356cef8fae69f4d4842da34acb78b,release_osa, version: 2397da31a14218ac831d53c22b01aa1e4fd648fb version: a7cc4ff03d40ed98ba9f29faf2b552ffb8d404b2 version: 7187fc8be6e54629c625645b83ac48e2064130d5 version: eefbc89ea59a54a033dfd8b8c4c3e3dcd1b67803 version: c5a7ac9341b4258f4d4913d4510a32b47aa608aa version: 7f1d84cb023992bca0c6cb7174e5a45bb5e4c4d3 version: 2cbecda29b5be57b1cbb781e8e7f414e0486e3fd version: 0512aac790686af779bba92ba826f8d615bad032 version: 5e7a5a6f22e4725acb0ecf152ce7757a2afaa55d version: d9cb7e0f10fb1359f4c0645a370c0a7d5f682ad7 version: ad2cdac9e3ab6b9b0130328b38afd1955b489eae version: 5f999ad20efd29f32b77a65278d25eefc1dc72c0 version: 0020b42bbe9fd65710ad73eed59a02a57a3d959b version: ea7c9b56467963dbaacf9ca7b43480b3fb2478ae version: f6d8ceee47ea0aaa709462fb906c39deda49a8e5 version: 1e1f7f3dfe22e28e611575d4bbf7c846e6afcde7 version: b7a2f36f2230f041957685a28b28371f5d14e05e version: c46b2744896fc26fd900c2c882d6e5bb2427db55 version: f9f5535ae8dd772318592402e5b0338e66a3c0e9 version: 2a060fbdfc165f087be1ccf096332f950629de1b version: 16c77a5eb468eb9bb30a9e1f24d70118fe4caee3 version: 22aa6261fc16efdfd1c5bfbdfb5c878e077026aa version: 3dce72d0dba6365ce86851181b4bebbc44c40e04 version: 74330358621b7264a26087716acc066cd8350586 version: 1af6528e1d06f809914ff8134d88ebd4d6746f74 version: a8e6a674d38862883b41e28fb5da33ff9e244ceb version: 5e2b4d928da5975b7904a5379c48a2feea3ad74c version: f5f16b8ca88b38b18cad7ba68bafee1ef1e90607 version: 171fb64352b5005544f53e5b2162b656337ff5f7 version: 93aa82d7481e775b77d215c4c43a69d3cf63c93a version: e1ed1fda3aa8c885a922b05162f8d69caaa8beaa version: e7bc8e253b169e8d5ea2136fef15d0e0ad6139d6 version: 6140c545dfbc2e2fb10ddec4f5852e5aa6be2b54 version: 183ca1367a614e5c509b6f3a66174a530de9f794 version: 25b50e9465b2a0633175ec9620c32ea34411ef10 version: 532add072620ca9b3c96ea65b117b97caa730fc9 version: 2fc0ffac46395a14df0854dd5dc10c7d974bf52f, version: 71e18e1ef7c37979239f8e65bc9c200e0105b5b4 version: 956e06cf66bd878b132c58bdd97304749c0da189 version: fc50adf1d949b6826c1b814759230d4d732f7557 version: ca1ee798b74b6e1c7667e608334f1ac5a14087bb version: eb2a11bfb7817d17d0c31618ea737439dd4650fb version: 6dd85991b2d052b58305a0ebb6984d9b29c263d9 version: 11cda0a3ffabc00a150a08c5c6f1511a1677f4ca version: 7650d0836bdefbd4903e52c61338b317c3b5aec2 version: 373fc792ca2b34f09b9089c8a0b0a581cbb536b6 version: 3ebe2aa049fd685db76edb70762371cf15536923 version: a94d802963c78d16e1cca3c86b9d2df7131262c8 version: 422240620d0e662357fa145128c64396f9cc7c08 version: bab88ea31150dd68465ef623fb49d21f078315c7 version: f2f12158038e105f3f15f72b33639c00f359ba84 version: bde64ba84bb0bf805bbb1e43045a2612dcc8db6f version: 712573dfbb098b2dc71ac2ac52ed64f0ebe99f4f version: 75fcd073e03b1d85698fb9c558fb5c5290e5368e version: 68613dc63e5f9c388e6467132107bc4f1b0ff914 version: 3ee0fd2606e67ed358a084fab6fff8b0ad585e05 version: 40378453b77ee3dbd5a73e61f4e4b5d86472f200 version: e28dd67860037003e08ec3e5c6bbc54b73db230c version: 0571b414fb217665457ac3fd250674758275ec7a version: 90cadb5b30868f57607c9e21a4d5ed416cbf686b version: c62c194ab7fec957f84eaab8ce101ee897512afb version: 4e5051433c4142bdcafa23b911e77b8a3961ad91 version: 7e0d6b5477d6218467dc2692c74e4df8ea07fca6 version: f489cc3c0e1a991d72298b81afedda0b7eac6e68 version: 37f48c1e029b82dabd86e72ce4497e41d186a679 version: c7fb95950d0e109c9b0f50b7f40e8c7f8885eb88 version: 2719ce077ec8c4fb5a3400a238c3c6cbe1063254 version: 977901fa36de2cfba071eb07df68f66511c4f007 version: 1756d7c11fc1036cc013b4c5163673dc13aa18ef version: efc324a2c3ed55c041a4e4dbb40d9ec8e84790f2 version: b1da71fc2470cb280126b0c314cb2d0a0ed8d9d0 version: 63c6537fcb7fa688e1e82074ea958b9349f58cc7 version: 693255ee40a2908707fcc962d620d68008647a57 version: fa201bbadeb959f363ecba7046f052b2ee16e474,71,71
openstack%2Ftripleo-common~master~I46def282e9bd2fd84322c8b9213ac280782f09dd,openstack/tripleo-common,master,I46def282e9bd2fd84322c8b9213ac280782f09dd,Switch to origin-docker-build,MERGED,2018-09-03 07:51:49.000000000,2018-09-26 22:17:45.000000000,2018-09-26 22:17:45.000000000,"[{'_account_id': 4328}, {'_account_id': 6159}, {'_account_id': 6926}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-03 07:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4f7f4133d3ee18c984fe4ffe3269dae453f46262', 'message': 'Switch to origin-docker-build\n\nSince OpenShift 3.10, origin-sti-build is deprecated in favor of\norigin-docker-builder:\n\nhttps://github.com/openshift/origin/commit/57e7c6c0d45fb7f7b2e4bb6dfc13ad5b4b46d0b9\n\nChange-Id: I46def282e9bd2fd84322c8b9213ac280782f09dd\n'}, {'number': 2, 'created': '2018-09-13 06:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a1b88175da21180a102994cbcffe64da0c29c562', 'message': 'Switch to origin-docker-build\n\nSince OpenShift 3.10, origin-sti-build is deprecated in favor of\norigin-docker-builder:\n\nhttps://github.com/openshift/origin/commit/57e7c6c0d45fb7f7b2e4bb6dfc13ad5b4b46d0b9\n\nThe new heat parameter for the image is now\nDockerOpenShiftDockerBuilderImage.\n\nChange-Id: I46def282e9bd2fd84322c8b9213ac280782f09dd\n'}, {'number': 3, 'created': '2018-09-19 13:10:17.000000000', 'files': ['container-images/overcloud_containers.yaml', 'container-images/overcloud_containers.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8bb72cadfe81b0ef16822a5ef5ed2ee1e82559ea', 'message': 'Switch to origin-docker-build\n\nSince OpenShift 3.10, origin-sti-build is deprecated in favor of\norigin-docker-builder:\n\nhttps://github.com/openshift/origin/commit/57e7c6c0d45fb7f7b2e4bb6dfc13ad5b4b46d0b9\n\nThe new heat parameter for the image is now\nDockerOpenShiftDockerBuilderImage.\n\nChange-Id: I46def282e9bd2fd84322c8b9213ac280782f09dd\n'}]",1,599307,8bb72cadfe81b0ef16822a5ef5ed2ee1e82559ea,27,7,3,13039,,,0,"Switch to origin-docker-build

Since OpenShift 3.10, origin-sti-build is deprecated in favor of
origin-docker-builder:

https://github.com/openshift/origin/commit/57e7c6c0d45fb7f7b2e4bb6dfc13ad5b4b46d0b9

The new heat parameter for the image is now
DockerOpenShiftDockerBuilderImage.

Change-Id: I46def282e9bd2fd84322c8b9213ac280782f09dd
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/07/599307/3 && git format-patch -1 --stdout FETCH_HEAD,"['container-images/overcloud_containers.yaml', 'container-images/overcloud_containers.yaml.j2']",2,4f7f4133d3ee18c984fe4ffe3269dae453f46262,3.10,"- imagename: ""{{openshift_namespace}}/{{openshift_base_image}}-docker-builder:{{openshift_tag}}"" params: - DockerOpenShiftDockerBuilderImage services: - OS::TripleO::Services::OpenShift::Worker ","- imagename: ""{{openshift_namespace}}/{{openshift_base_image}}-sti-builder:{{openshift_tag}}"" params: - DockerOpenShiftStiBuilderImage services: - OS::TripleO::Services::OpenShift::Worker ",7,7
openstack%2Ftripleo-common~master~Ied55e1713bf2803b17041c35e51d4e2d914dd302,openstack/tripleo-common,master,Ied55e1713bf2803b17041c35e51d4e2d914dd302,Switch to openshift 3.10,MERGED,2018-08-27 15:41:23.000000000,2018-09-26 22:17:44.000000000,2018-09-26 22:17:44.000000000,"[{'_account_id': 4328}, {'_account_id': 10873}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-08-27 15:41:23.000000000', 'files': ['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/d9e27e7826034893038b059d95fcb07edc130ccb', 'message': 'Switch to openshift 3.10\n\nThis updates the default tags for OpenShift images to v3.10.0.\n\nChange-Id: Ied55e1713bf2803b17041c35e51d4e2d914dd302\nDepends-On: I4f8127a9e2d822057f3db8f0974ab1db0698985a\n'}]",0,596820,d9e27e7826034893038b059d95fcb07edc130ccb,18,6,1,13039,,,0,"Switch to openshift 3.10

This updates the default tags for OpenShift images to v3.10.0.

Change-Id: Ied55e1713bf2803b17041c35e51d4e2d914dd302
Depends-On: I4f8127a9e2d822057f3db8f0974ab1db0698985a
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/20/596820/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/kolla_builder.py', 'container-images/overcloud_containers.yaml', 'tripleo_common/tests/image/test_kolla_builder.py']",3,d9e27e7826034893038b059d95fcb07edc130ccb,3.10," 'openshift_tag': 'v3.10.0',"," 'openshift_tag': 'v3.9.0',",10,10
openstack%2Ftripleo-quickstart~master~Ibe94a58e0083b75e2f4cc904be6c17b0633d0293,openstack/tripleo-quickstart,master,Ibe94a58e0083b75e2f4cc904be6c17b0633d0293,Set containerized_undercloud for OpenShift featureset,MERGED,2018-09-15 03:02:43.000000000,2018-09-26 22:14:39.000000000,2018-09-26 22:14:39.000000000,"[{'_account_id': 6159}, {'_account_id': 6926}, {'_account_id': 12715}, {'_account_id': 13039}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-15 03:02:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/25a72b2c5b8fee3d37299bfcc236558f0d208707', 'message': 'Set containerized_undercloud for OpenShift featureset\n\nWe are getting most of the behaviors of containerized_undercloud\nwhen using containerized_undercloud=false (default). Namely, the\nundercloud is deployed via containers.\n\nHowever, without this explicity set, we do not include the\ncontainers-prepare-parameter.yaml in the undercloud.conf template[1].\n\nThis causes the undercloud containers to never be updated since the\nupdate params are templated to that file.\n\nChange-Id: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\n'}, {'number': 2, 'created': '2018-09-15 03:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/65027aa97657629a7230407fdb6312baf8a1a986', 'message': 'Set containerized_undercloud for OpenShift featureset\n\nWe are getting most of the behaviors of containerized_undercloud\nwhen using containerized_undercloud=false (default). Namely, the\nundercloud is deployed via containers.\n\nHowever, without this explicity set, we do not include the\ncontainers-prepare-parameter.yaml in the undercloud.conf template[1].\n\nThis causes the undercloud containers to never be updated since the\nupdate params are templated to that file.\n\n[1] https://github.com/openstack/tripleo-quickstart-extras/blob/b3794ff03ab841bbbc15a339e35a7ec02b193111/roles/undercloud-deploy/templates/undercloud.conf.j2#L260-L266\nChange-Id: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\n'}, {'number': 3, 'created': '2018-09-15 13:18:58.000000000', 'files': ['config/general_config/featureset033.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/7d5cd2fc8cc29e6b9d1cc6171b591ec21d49700b', 'message': 'Set containerized_undercloud for OpenShift featureset\n\nWe are getting most of the behaviors of containerized_undercloud\nwhen using containerized_undercloud=false (default). Namely, the\nundercloud is deployed via containers.\n\nHowever, without this explicity set, we do not include the\ncontainers-prepare-parameter.yaml in the undercloud.conf template[1].\n\nThis causes the undercloud containers to never be updated since the\nupdate params are templated to that file.\n\n[1] https://github.com/openstack/tripleo-quickstart-extras/blob/b3794ff03ab841bbbc15a339e35a7ec02b193111/roles/undercloud-deploy/templates/undercloud.conf.j2#L260-L266\nChange-Id: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293\n'}]",0,602802,7d5cd2fc8cc29e6b9d1cc6171b591ec21d49700b,39,7,3,12715,,,0,"Set containerized_undercloud for OpenShift featureset

We are getting most of the behaviors of containerized_undercloud
when using containerized_undercloud=false (default). Namely, the
undercloud is deployed via containers.

However, without this explicity set, we do not include the
containers-prepare-parameter.yaml in the undercloud.conf template[1].

This causes the undercloud containers to never be updated since the
update params are templated to that file.

[1] https://github.com/openstack/tripleo-quickstart-extras/blob/b3794ff03ab841bbbc15a339e35a7ec02b193111/roles/undercloud-deploy/templates/undercloud.conf.j2#L260-L266
Change-Id: Ibe94a58e0083b75e2f4cc904be6c17b0633d0293
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/02/602802/2 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset033.yml'],1,25a72b2c5b8fee3d37299bfcc236558f0d208707,openshift-validation,containerized_undercloud: true,,1,0
openstack%2Ftripleo-quickstart-extras~master~Icd0bf18baa4da0953cc3c9ba68896a6073649941,openstack/tripleo-quickstart-extras,master,Icd0bf18baa4da0953cc3c9ba68896a6073649941,Calculate ARA metrics for overcloud,MERGED,2018-09-24 20:35:54.000000000,2018-09-26 22:14:38.000000000,2018-09-26 22:14:38.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-24 20:35:54.000000000', 'files': ['roles/collect-logs/tasks/ara_influxdb.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e0d14153aa5f0bfc3310016fb92beffc1d1320cf', 'message': 'Calculate ARA metrics for overcloud\n\nCalculate ARA metrics for overcloud and post them into influxdb\nfile in logs directory.\n\nChange-Id: Icd0bf18baa4da0953cc3c9ba68896a6073649941\n'}]",0,604900,e0d14153aa5f0bfc3310016fb92beffc1d1320cf,16,6,1,10969,,,0,"Calculate ARA metrics for overcloud

Calculate ARA metrics for overcloud and post them into influxdb
file in logs directory.

Change-Id: Icd0bf18baa4da0953cc3c9ba68896a6073649941
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/00/604900/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/collect-logs/tasks/ara_influxdb.yml'],1,e0d14153aa5f0bfc3310016fb92beffc1d1320cf,ansibleara,"- name: Get ARA json data for undercloud - name: Get ARA json data for overcloud become: yes shell: ""{{ local_working_dir }}/bin/ara result list --all -f json"" register: ara_oc_data environment: ARA_DATABASE: 'sqlite:///{{ ara_overcloud_db_path }}' - name: Collect and send data to InfluxDB ara_influxdb: influxdb_url: ""{{ influxdb_url|default('') }}"" influxdb_port: ""{{ influxdb_port }}"" influxdb_user: ""{{ influxdb_user }}"" influxdb_password: ""{{ influxdb_password }}"" influxdb_db: ""{{ influxdb_dbname}}"" ara_data: ""{{ ara_oc_data.stdout }}"" measurement: ""overcloud"" data_file: ""{{ influxdb_data_file_path }}"" only_successful_tasks: ""{{ influxdb_only_successful_tasks }}"" mapped_fields: false standard_fields: false longest_tasks: 15 when: ara_oc_data.stdout != ""[]""",- name: Get ARA json data,24,1
openstack%2Ftripleo-quickstart-extras~master~I329c69a2ccd8bfa969a285e0ee8c67d6057509d7,openstack/tripleo-quickstart-extras,master,I329c69a2ccd8bfa969a285e0ee8c67d6057509d7,Support ARA statistics in InfluxDB for longest tasks,MERGED,2018-07-04 23:59:12.000000000,2018-09-26 21:54:37.000000000,2018-09-26 21:54:37.000000000,"[{'_account_id': 3153}, {'_account_id': 8871}, {'_account_id': 9592}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 14985}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24752}, {'_account_id': 27898}]","[{'number': 1, 'created': '2018-07-04 23:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/5144d7e146930f82872f9faacc3e5f13c0738cea', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 2, 'created': '2018-07-05 15:32:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/123df7237e052017983d6e4f8579ee80c76ea7e7', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 3, 'created': '2018-08-16 15:17:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/173dddccd327562ad0d49f071145f76a7a150f4d', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 4, 'created': '2018-08-27 16:02:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c7c1431d05cb6935565c0c3b6c7831f8fb965439', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 5, 'created': '2018-09-01 22:29:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c3c796f31f8a6e9c82c104b8116055804e8ac3ba', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 6, 'created': '2018-09-14 18:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/3425d24f4ccc42469410777a57100b33b3c0c54a', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 7, 'created': '2018-09-14 21:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/4e2407d08a0889dc2710f3e13d461bf97aae1bf5', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}, {'number': 8, 'created': '2018-09-20 03:18:55.000000000', 'files': ['roles/collect-logs/tasks/ara_influxdb.yml', 'roles/collect-logs/library/ara_influxdb.py'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9da455dcca4b1028b6d73149a8ffe0cbe43fe63d', 'message': 'Support ARA statistics in InfluxDB for longest tasks\n\nCalculate longest tasks and send them to influxDB\n\nChange-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7\n'}]",14,580238,9da455dcca4b1028b6d73149a8ffe0cbe43fe63d,71,12,8,10969,,,0,"Support ARA statistics in InfluxDB for longest tasks

Calculate longest tasks and send them to influxDB

Change-Id: I329c69a2ccd8bfa969a285e0ee8c67d6057509d7
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/38/580238/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/collect-logs/tasks/ara_influxdb.yml', 'roles/collect-logs/library/ara_influxdb.py']",2,5144d7e146930f82872f9faacc3e5f13c0738cea,ansibleara,"import json import reSCHEME = '{measure},{tags} {fields} {timestamp}' CUSTOM_MAP = {} class InfluxStandartTags: def __init__(self): pass def branch(self): return os.environ.get('STABLE_RELEASE') or 'master' def cloud(self): return os.environ.get('NODEPOOL_PROVIDER', 'null') def pipeline(self): if os.environ.get('ZUUL_PIPELINE'): if 'check' in os.environ['ZUUL_PIPELINE']: return 'check' elif 'gate' in os.environ['ZUUL_PIPELINE']: return 'gate' elif 'periodic' in os.environ['ZUUL_PIPELINE']: return 'periodic' return 'null' def toci_jobtype(self): return os.environ.get('TOCI_JOBTYPE', 'null') def render(self): return ('branch=%s,' 'cloud=%s,' 'pipeline=%s,' 'toci_jobtype=%s') % ( self.branch(), self.cloud(), self.pipeline(), self.toci_jobtype(), ) class InfluxStandardFields: def __init__(self): pass def job_duration(self): if os.environ.get('START_JOB_TIME'): return int( datetime.datetime.utcnow().strftime(""%s"")) - int( os.environ.get('START_JOB_TIME')) return 0 def logs_size(self): # not implemented return 0 def timestamp(self): return datetime.datetime.utcnow().strftime(""%s"") def testenv_prepare(self): return os.environ.get('STATS_TESTENV', 0) def quickstart_prepare(self): return os.environ.get('STATS_OOOQ', 0) def zuul_host_prepare(self): if (os.environ.get('DEVSTACK_GATE_TIMEOUT') and os.environ.get('REMAINING_TIME')): return (int( os.environ['DEVSTACK_GATE_TIMEOUT']) - int( os.environ['REMAINING_TIME'])) * 60 return 0 def render(self): return ('job_duration=%d,' 'logs_size=%d,' 'testenv_prepare=%s,' 'quickstart_prepare=%s,' 'zuul_host_prepare=%d,' ) % ( self.job_duration(), self.logs_size(), self.testenv_prepare(), self.quickstart_prepare(), self.zuul_host_prepare() ) class InfluxConfiguredFields: def __init__(self, match_map, json_data, only_ok=True): self.map = match_map self.only_ok = only_ok self.data = json_data def task_maps(self): times_dict = tasks_times_dict(self.data, self.only_ok) tasks = {} for i in self.map: tasks[i] = sum([int(times_dict.get(k, 0)) for k in self.map[i]]) return tasks def render(self): tasks = self.task_maps() result = '' for task, time in tasks.items(): result += ""%s=%d,"" % (task, time) return result class InfluxLongestFields: def __init__(self, json_data, only_ok=True, top=15): self.top = top self.only_ok = only_ok self.data = json_data def collect_tasks(self): tasks_dict = tasks_times_dict(self.data, self.only_ok) return sorted( [[k, v] for k, v in tasks_dict.items()], key=lambda x: x[1], reverse=True )[:self.top] def translate_names(self, names): for i in names: i[0] = re.sub( r'[^0-9A-z\-_]+', '', i[0].replace("":"", ""__"").replace("" "", ""_"")) i[1] = int(i[1]) return names def render(self): result = '' for i in self.translate_names(self.collect_tasks()): result += ""{0}={1},"".format(*i) return result def tasks_times_dict(tasks, only_ok=True): times_dict = {} for task in tasks: if not only_ok or task['Status'] in ['changed', 'ok']: name = task['Name'] if name in times_dict: times_dict[name].append(task['Duration']) else: times_dict[name] = [task['Duration']] # because of some tasks are executed multiple times we need to count # all of them and make summary of all durations for i in times_dict: times_dict[i] = sum([task_length(t) for t in times_dict[i]]) return times_dict def translate(measure, json_data, only_ok, mapped_fields=True, standard_fields=True, longest_tasks=0): tags = InfluxStandartTags() std_fields = InfluxStandardFields() map_fields = InfluxConfiguredFields( match_map=CUSTOM_MAP, json_data=data, only_ok=only_ok) longest_fields = InfluxLongestFields(json_data=data, top=longest_tasks, only_ok=only_ok) fields = '' if standard_fields: fields += std_fields.render() if mapped_fields: fields += map_fields.render() if longest_tasks: fields += longest_fields.render() fields = fields.rstrip("","") result = SCHEME.format( measure=measure, tags=tags.render(), fields=fields, timestamp=std_fields.timestamp() ) return result with open(path, ""a"") as f: measure, data_file, only_ok, mapped_fields=True, standard_fields=True, longest_tasks=0): :param: mapped_fields: if to use configured map of fields and tasks :param: standard_fields: if to send standard fields of each job, i.e. times :param: longest_tasks: if to print only longest tasks and how many data2send = translate(measure, json_data, only_ok, mapped_fields, standard_fields, longest_tasks) mapped_fields=dict(default=True, type='bool'), standard_fields=dict(default=True, type='bool'), longest_tasks=dict(default=0, type='int'), module.params['mapped_fields'], module.params['standard_fields'], module.params['longest_tasks'],","SCHEME = ( # measurement '{measure},' # tags 'branch={branch},' 'cloud={cloud},' 'pipeline={pipeline},' 'toci_jobtype={toci_jobtype} ' # fields 'job_duration={job_duration},' 'logs_size={logs_size},' 'testenv_prepare={testenv_prepare},' 'zuul_host_prepare={zuul_host_prepare},' 'quickstart_prepare={quickstart_prepare},' 'undercloud_install={undercloud_install},' 'prepare_images={prepare_images},' 'images_update={images_update},' 'images_build={images_build},' 'containers_prepare={containers_prepare},' 'overcloud_deploy={overcloud_deploy},' 'pingtest={pingtest},' 'tempest_run={tempest_run},' 'undercloud_reinstall={undercloud_reinstall},' 'overcloud_delete={overcloud_delete},' 'undercloud_upgrade={undercloud_upgrade},' 'overcloud_upgrade={overcloud_upgrade} ' '{timestamp}' ) DATA = { 'measure': '', # tags 'branch': os.environ.get('STABLE_RELEASE') or 'master', 'cloud': os.environ.get('NODEPOOL_PROVIDER', 'N/A'), 'pipeline': 'N/A', # implemented in function 'toci_jobtype': os.environ.get('TOCI_JOBTYPE', 'N/A'), # fields 'job_duration': 0, # implemented in function 'logs_size': 0, # not implemented 'testenv_prepare': os.environ.get('STATS_TESTENV', 0), 'zuul_host_prepare': 0, # implemented in function 'quickstart_prepare': os.environ.get('STATS_OOOQ', 0), 'timestamp': int(datetime.datetime.utcnow().strftime(""%s"")), } def translate(measure, json_data, only_ok): DATA['measure'] = measure if os.environ.get('START_JOB_TIME'): DATA['job_duration'] = int( datetime.datetime.utcnow().strftime(""%s"")) - int( os.environ.get('START_JOB_TIME')) if os.environ.get('ZUUL_PIPELINE'): if 'check' in os.environ['ZUUL_PIPELINE']: DATA['pipeline'] = 'check' elif 'gate' in os.environ['ZUUL_PIPELINE']: DATA['pipeline'] = 'gate' elif 'periodic' in os.environ['ZUUL_PIPELINE']: DATA['pipeline'] = 'periodic' if (os.environ.get('DEVSTACK_GATE_TIMEOUT') and os.environ.get('REMAINING_TIME')): DATA['zuul_host_prepare'] = (int( os.environ['DEVSTACK_GATE_TIMEOUT']) - int( os.environ['REMAINING_TIME'])) * 60 # create a dictionary with durations for each task # every task could run multiple times times_dict = {} for task in data: if not only_ok or task['Status'] in ['changed', 'ok']: name = task['Name'] if name in times_dict: times_dict[name].append(task['Duration']) else: times_dict[name] = [task['Duration']] # because of some tasks are executed multiple times we need to count # all of them and make summary of all durations for i in times_dict: times_dict[i] = sum([task_length(t) for t in times_dict[i]]) # replace tasks lists in DATA with tasks durations for i in DATA: if isinstance(DATA[i], list): DATA[i] = sum([int(times_dict.get(k, 0)) for k in DATA[i]]) return SCHEME.format(**DATA) with open(path, ""w"") as f: measure, data_file, only_ok): data2send = translate(measure, json_data, only_ok)",216,84
openstack%2Fos-ken~master~I807a8785e525cc02825d15a1a01eec3d5d20cce4,openstack/os-ken,master,I807a8785e525cc02825d15a1a01eec3d5d20cce4,Move files from ryu/* to os_ken/*,MERGED,2018-09-03 22:34:05.000000000,2018-09-26 21:45:31.000000000,2018-09-26 20:34:08.000000000,"[{'_account_id': 4187}, {'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15471}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-09-03 22:34:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-ken/commit/419becace51d797111b8f23d3592d932be15d100', 'message': 'Move files from ryu/* to os_ken/*\n\nAfter forking from Ryu, the namespace needs to be adjusted.\n\nChange-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4\n'}, {'number': 2, 'created': '2018-09-03 22:43:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-ken/commit/82171d93ce37e987983ec26de9d053991d236726', 'message': ""Move files from ryu/* to os_ken/*\n\nAfter forking from Ryu, the namespace needs to change from 'ryu'\nto 'os_ken'.\n\nChange-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4\n""}, {'number': 3, 'created': '2018-09-04 17:01:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-ken/commit/6a421daf6117db47e94a7f5dfd6874baeabef41c', 'message': ""Move files from ryu/* to os_ken/*\n\nAfter forking from Ryu, the namespace needs to change from 'ryu'\nto 'os_ken'.\n\nChange-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4\n""}, {'number': 4, 'created': '2018-09-25 20:53:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-ken/commit/cfaf25e32faa5ef1aa1306cac01a99b37be47885', 'message': ""Move files from ryu/* to os_ken/*\n\nAfter forking from Ryu, the namespace needs to change from 'ryu'\nto 'os_ken'.\n\nChange-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4\n""}, {'number': 5, 'created': '2018-09-25 20:57:22.000000000', 'files': ['os_ken/lib/type_desc.py', 'os_ken/lib/packet/ethernet.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-packet_out.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_stats_reply.packet.json', 'os_ken/services/protocols/bgp/operator/views/__init__.py', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv4_UDP.json', 'os_ken/tests/switch/of10/match/06_NW_TOS_IPv4.json', 'os_ken/lib/of_config/__init__.py', 'ryu/tests/unit/lib/__init__.py', 'os_ken/tests/packet_data/of14/5-54-ofp_table_features_reply.packet', 'os_ken/lib/of_config/constants.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/18_SCTP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/packet/test_slow.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/16_UDP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-47-ofp_meter_config_request.packet.json', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv4_UDP.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-aggregate_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-17-ofp_barrier_request.packet.json', 'os_ken/services/protocols/bgp/info_base/vpn.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_stats_reply.packet', 'os_ken/tests/switch/of14/match/28_IPV6_FLABEL_Mask.json', 'ryu/tests/mininet/l2/vlan/test_vlan.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-aggregate_stats_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_meter_config_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/17_SCTP_SRC_IPv6.json', 'ryu/services/protocols/vrrp/event.py', 'os_ken/lib/packet/icmpv6.py', 'os_ken/tests/unit/ofproto/json/of12/3-9-ofp_get_config_reply.packet.json', 'os_ken/tests/unit/packet/test_igmp.py', 'os_ken/tests/unit/ofproto/json/of12/3-37-ofp_queue_stats_request.packet.json', 'os_ken/tests/switch/of13/match/08_IP_DSCP_IPv6.json', 'os_ken/tests/unit/ofproto/json/of12/3-18-ofp_barrier_reply.packet.json', 'os_ken/tests/unit/packet/test_cfm.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_desc_request.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-62-ofp_group_stats_reply.packet.json', 'os_ken/tests/packet_data/bgp4/bgp4-update.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-4-ofp_packet_in.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-50-ofp_meter_stats_reply.packet.json', 'ryu/tests/unit/lib/test_ofp_pktinfilter.py', 'os_ken/tests/mininet/l2/vlan/PopVLAN_vlan.mn', 'os_ken/tests/switch/of14/action/25_SET_FIELD/21_ARP_OP.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/33_IPV6_ND_TLL.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-set_async.packet.json', 'ryu/tests/unit/packet/test_llc.py', 'os_ken/tests/integrated/common/quagga.py', 'os_ken/tests/packet_data/of14/5-42-ofp_set_async.packet', 'os_ken/lib/packet/packet.py', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/packet_data/pcap/openflow_flowmod.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-70-ofp_bundle_add_msg.packet.json', 'os_ken/ofproto/ofproto_protocol.py', 'os_ken/tests/unit/ofproto/json/of14/5-23-ofp_table_mod.packet.json', 'os_ken/app/gui_topology/gui_topology.py', 'os_ken/tests/packet_data_generator/Makefile', 'os_ken/tests/switch/of13/match/00_IN_PORT.json', 'os_ken/services/__init__.py', 'os_ken/tests/switch/of14/action/24_DEC_NW_TTL_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_desc_request.packet.json', 'ryu/ofproto/nx_actions.py', 'os_ken/tests/unit/ofproto/json/of12/3-38-ofp_queue_stats_reply.packet.json', 'ryu/services/protocols/bgp/info_base/ipv6.py', 'ryu/services/protocols/bgp/rtconf/base.py', 'ryu/services/protocols/bgp/info_base/rtc.py', 'os_ken/tests/switch/of13/match/11_IPV4_SRC_Mask.json', 'ryu/tests/unit/packet/test_geneve.py', 'os_ken/tests/unit/ofproto/json/of12/3-13-ofp_echo_request.packet.json', 'ryu/utils.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/12_IPV4_DST.json', 'ryu/tests/unit/lib/test_mod/ddd/mod.py', 'os_ken/tests/packet_data/of13/4-50-ofp_meter_stats_reply.packet', 'os_ken/tests/switch/of13/match/12_IPV4_DST_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/packet_data/of12/3-27-ofp_table_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-0-ofp_desc_stats_reply.packet.json', 'os_ken/controller/__init__.py', 'os_ken/utils.py', 'os_ken/tests/packet_data_generator2/README', 'os_ken/lib/packet/sctp.py', 'os_ken/app/simple_switch_igmp_13.py', 'os_ken/tests/packet_data/of14/5-64-ofp_queue_desc_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-35-ofp_queue_stats_request.packet.json', 'os_ken/services/protocols/bgp/operator/views/conf.py', 'ryu/log.py', 'os_ken/tests/packet_data/pcap/geneve_unknown.pcap', 'ryu/hooks.py', 'os_ken/tests/unit/ofproto/json/of13/4-17-ofp_barrier_request.packet.json', 'os_ken/tests/packet_data/of14/5-58-ofp_flow_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-hello.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-34-ofp_group_desc_reply.packet.json', 'os_ken/lib/of_config/of-config-1.1.1.xsd', 'os_ken/tests/packet_data/of12/3-29-ofp_port_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of13/4-42-ofp_get_async_request.packet.json', 'os_ken/tests/packet_data/of14/5-5-ofp_features_request.packet', 'os_ken/cmd/__init__.py', 'os_ken/tests/packet_data/of12/3-39-ofp_port_status.packet', 'os_ken/tests/switch/of14/match/02_METADATA.json', 'ryu/services/protocols/bgp/signals/__init__.py', 'os_ken/tests/packet_data/of14/5-37-ofp_port_status.packet', 'ryu/tests/unit/lib/ofctl_json/of14/5-21-ofp_group_mod.packet.json', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_action.pcap', 'os_ken/services/protocols/bgp/processor.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_request.packet', 'ryu/app/wsgi.py', 'os_ken/tests/switch/of13/group/01_SELECT_Weight_Ether.json', 'os_ken/app/simple_switch_12.py', 'os_ken/tests/packet_data/of14/5-57-ofp_packet_in.packet', 'os_ken/services/protocols/vrrp/api.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_desc_reply.packet', 'os_ken/tests/switch/of13/match/37_PBB_ISID_Mask.json', 'os_ken/tests/switch/of14/action/23_SET_NW_TTL_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-30-ofp_port_stats_reply.packet.json', 'os_ken/tests/packet_data/of14/5-18-ofp_barrier_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter_request.packet', 'os_ken/tests/packet_data/of14/5-28-ofp_table_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_status.packet.json', 'ryu/services/protocols/zebra/client/event.py', 'os_ken/tests/packet_data/of12/3-26-ofp_aggregate_stats_reply.packet', 'os_ken/tests/unit/cmd/dummy_openflow_app.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/15_UDP_SRC_IPv4.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/31_IPV6_ND_TARGET.json', 'os_ken/tests/unit/ofproto/json/of12/3-39-ofp_port_status.packet.json', 'os_ken/lib/ofp_pktinfilter.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/37_PBB_ISID.json', 'os_ken/lib/netdevice.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data_generator2/gen.c', 'ryu/controller/ofp_event.py', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv4_UDP.json', 'os_ken/tests/unit/packet/test_llc.py', 'os_ken/lib/lacplib.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_stats_request.packet', 'os_ken/tests/switch/of13/match/11_IPV4_SRC.json', 'os_ken/ofproto/ether.py', 'os_ken/lib/packet/__init__.py', 'os_ken/tests/switch/of14/action/23_SET_NW_TTL_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-30-ofp_port_stats_reply.packet.json', 'os_ken/lib/bfdlib.py', 'os_ken/tests/packet_data/of13/4-49-ofp_meter_stats_request.packet', 'ryu/tests/unit/packet/test_bpdu.py', 'ryu/tests/unit/packet/test_bgp.py', 'ryu/services/protocols/bgp/info_base/l2vpnfs.py', 'ryu/tests/integrated/bgp/test_basic.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_as_based.pcap', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_ctrl.packet.json', 'os_ken/tests/switch/of14/match/28_IPV6_FLABEL.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_fintimeout.packet.json', 'os_ken/tests/packet_data/of12/3-20-ofp_role_reply.packet', 'ryu/tests/unit/sample/test_sample2.py', 'ryu/tests/unit/lib/test_ofctl_string.py', 'os_ken/services/protocols/bgp/operator/views/bgp.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod_match_conj.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/28_IPV6_FLABEL.json', 'os_ken/tests/unit/ofproto/json/of13/4-6-ofp_features_reply.packet.json', 'ryu/controller/dpset.py', 'ryu/lib/lacplib.py', 'os_ken/tests/unit/ofproto/json/of13/4-27-ofp_table_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv6fs.py', 'os_ken/tests/unit/ofproto/json/of13/4-12-ofp_flow_stats_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_stats_reply.packet.json', 'os_ken/tests/mininet/l2/mpls/PushMPLS_mpls.mn', 'os_ken/tests/unit/ofproto/json/of10/1-5-features_request.packet.json', 'os_ken/lib/ofctl_v1_5.py', 'os_ken/tests/packet_data/of13/4-31-ofp_group_features_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-port_mod.packet.json', 'os_ken/lib/port_no.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_request.packet.json', 'os_ken/lib/packet/in_proto.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_meter_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-29-ofp_port_stats_request.packet.json', 'ryu/tests/unit/packet/test_vrrp.py', 'os_ken/tests/unit/ofproto/json/of13/4-41-ofp_error_msg_experimenter.packet.json', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv6_TCP.json', 'os_ken/base/app_manager.py', 'os_ken/tests/unit/ofproto/test_parser_v10.py', 'os_ken/lib/netconf/xml.xsd', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_removed.packet.json', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_00_1M.json', 'os_ken/tests/switch/of13/match/30_ICMPV6_CODE.json', 'os_ken/tests/unit/ofproto/json/of12/3-1-ofp_packet_out.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-error_msg.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_dec_nw_ttl.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-46-ofp_flow_mod.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_esi_arbitrary.pcap', 'os_ken/tests/unit/ofproto/json/of13/4-8-ofp_get_config_request.packet.json', 'os_ken/tests/switch/of13/match/07_VLAN_PCP.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_pkt_mark.packet', 'os_ken/tests/unit/ofproto/json/of13/4-2-ofp_flow_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of10/1-2-ofp_flow_mod.packet.json', 'os_ken/services/protocols/bgp/rtconf/neighbors.py', 'os_ken/services/protocols/bgp/api/jsonrpc.py', 'os_ken/tests/switch/of13/match/35_MPLS_TC.json', 'os_ken/tests/switch/of14/action/17_PUSH_VLAN_multiple.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/switch/of14/match/22_ARP_SPA_Mask.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-24-ofp_desc_stats_request.packet.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_gratuitous.mn', 'os_ken/tests/packet_data/pcap/little_endian.pcap', 'os_ken/tests/switch/of13/action/18_POP_VLAN.json', 'os_ken/tests/packet_data_generator/src/x.erl', 'os_ken/lib/netconf/__init__.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-12-ofp_flow_stats_reply.packet.json', 'os_ken/ofproto/oxx_fields.py', 'os_ken/tests/unit/ofproto/json/of12/3-2-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-66-ofp_flow_monitor_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-0-ofp_desc_reply.packet.json', 'os_ken/tests/switch/of14/match/14_TCP_DST_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-45-ofp_meter_mod.packet.json', 'os_ken/tests/unit/packet/test_bfd.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-echo_request.packet', 'ryu/services/protocols/bgp/speaker.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/28_IPV6_FLABEL.json', 'os_ken/tests/switch/of13/match/21_ARP_OP.json', 'os_ken/services/protocols/ovsdb/client.py', 'os_ken/tests/unit/ofproto/json/of13/4-9-ofp_get_config_reply.packet.json', 'os_ken/tests/switch/of14/action/27_POP_PBB.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_desc_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-error_msg_experimenter.packet', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_02_100M.json', 'os_ken/tests/unit/ofproto/test_parser.py', 'ryu/cfg.py', 'os_ken/tests/unit/ofproto/json/of13/4-31-ofp_group_features_request.packet.json', 'os_ken/tests/packet_data/of12/3-13-ofp_echo_request.packet', 'os_ken/app/rest_conf_switch.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-32-ofp_group_features_reply.packet.json', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_01_1000.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/04_ETH_SRC.json', 'os_ken/tests/unit/packet/test_gre.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_desc_request.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/17_SCTP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_note.packet.json', 'os_ken/tests/packet_data/of14/5-34-ofp_group_desc_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/04_ETH_SRC.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_dec_ttl_cnt_ids.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_conj.packet.json', 'os_ken/tests/switch/of14/group/01_SELECT_IP.json', 'os_ken/tests/unit/ofproto/json/of13/4-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-packet_in.packet.json', 'ryu/tests/integrated/test_add_flow_v10.py', 'os_ken/app/ws_topology.py', 'os_ken/tests/unit/ofproto/json/of12/3-41-ofp_error_msg_experimenter.packet.json', 'os_ken/tests/unit/ofproto/test_oxm.py', 'os_ken/tests/unit/ofproto/json/of12/3-33-ofp_group_desc_stats_request.packet.json', 'os_ken/services/protocols/bgp/rtconf/vrfs.py', 'os_ken/tests/packet_data/pcap/zebra_v3.pcap', 'os_ken/tests/switch/of13/action/19_PUSH_MPLS_multiple.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_features_request.packet', 'os_ken/services/protocols/bgp/constants.py', 'os_ken/tests/unit/app/test_ws_topology.py', 'os_ken/ofproto/ofproto_v1_3.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_ttl.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_stack_push.packet.json', 'os_ken/lib/packet/gre.py', 'os_ken/tests/switch/of13/action/15_SET_MPLS_TTL.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/36_MPLS_BOS.json', 'ryu/tests/integrated/bgp/base.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_removed.packet', 'os_ken/tests/unit/ofproto/json/of13/4-50-ofp_meter_stats_reply.packet.json', 'os_ken/controller/mac_to_port.py', 'os_ken/lib/ofctl_v1_2.py', 'os_ken/lib/of_config/capable_switch.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_desc_reply.packet', 'ryu/app/simple_monitor_13.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of13/match/06_VLAN_VID_Mask.json', 'ryu/services/protocols/bgp/operator/commands/show/vrf.py', 'os_ken/tests/switch/of14/match/27_IPV6_DST_Mask.json', 'os_ken/tests/switch/of14/match/23_ARP_TPA_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/4-57-ofp_group_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/rtc.py', 'os_ken/services/protocols/ovsdb/manager.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-52-ofp_meter_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-42-ofp_get_async_request.packet', 'os_ken/tests/switch/__init__.py', 'os_ken/lib/dpid.py', 'os_ken/tests/switch/of13/match/10_IP_PROTO_IPv4.json', 'ryu/tests/unit/ofproto/test_parser_v10.py', 'ryu/app/simple_switch_14.py', 'os_ken/tests/switch/of14/match/06_VLAN_VID.json', 'os_ken/tests/unit/sample/__init__.py', 'os_ken/tests/switch/of13/action/00_OUTPUT.json', 'os_ken/tests/unit/ofproto/json/of14/5-51-ofp_port_desc_request.packet.json', 'ryu/tests/unit/lib/test_import_module.py', 'os_ken/tests/switch/of13/match/03_ETH_DST.json', 'os_ken/lib/packet/openflow.py', 'os_ken/tests/switch/of14/match/31_IPV6_ND_TARGET.json', 'os_ken/tests/packet_data/of14/5-35-ofp_queue_stats_request.packet', 'os_ken/tests/switch/of10/match/08_NW_SRC.json', 'os_ken/tests/switch/of14/match/07_VLAN_PCP.json', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_ipv4.pcap', 'os_ken/tests/packet_data/of14/5-59-ofp_experimenter_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-3-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_01_10M.json', 'os_ken/ofproto/ofproto_common.py', 'ryu/services/protocols/bgp/rtconf/vrfs.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_push_mpls.packet', 'os_ken/tests/integrated/test_vrrp_linux_multi.py', 'ryu/tests/unit/cmd/test_manager.py', 'os_ken/tests/switch/of10/match/04_DL_VLAN_PCP.json', 'os_ken/tests/switch/of14/match/14_TCP_DST_IPv6.json', 'os_ken/services/protocols/vrrp/utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-30-ofp_port_stats_reply.packet.json', 'ryu/ofproto/oxm_fields.py', 'os_ken/tests/integrated/test_add_flow_v10.py', 'os_ken/tests/packet_data/of12/3-31-ofp_group_features_stats_request.packet', 'os_ken/tests/unit/packet/test_vxlan.py', 'os_ken/tests/packet_data/of14/5-25-ofp_aggregate_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet3.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-38-ofp_queue_stats_reply.packet.json', 'os_ken/services/protocols/bgp/peer.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-meter_mod.packet', 'os_ken/tests/packet_data/of12/3-10-ofp_hello.packet', 'os_ken/tests/packet_data/mrt/rib.20161101.0000_pick.bz2', 'ryu/tests/unit/packet/test_vlan.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter_request.packet.json', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_00_100.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/16_UDP_DST_IPv6.json', 'os_ken/tests/switch/of14/match/35_MPLS_TC.json', 'os_ken/tests/switch/of13/match/34_MPLS_LABEL.json', '.gitignore', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_00_100.json', 'os_ken/tests/unit/ofproto/json/of12/3-62-ofp_group_stats_reply.packet.json', 'ryu/services/protocols/bgp/api/rtconf.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-hello.packet.json', 'ryu/tests/unit/lib/test_ofctl_utils.py', 'os_ken/app/ofctl/api.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/14_TCP_DST_IPv6.json', 'os_ken/tests/packet_data/of14/libofproto-OFP14-ofp_packet_out_packet_library.packet', 'os_ken/tests/switch/of13/match/09_IP_ECN_IPv4.json', 'ryu/tests/unit/ofproto/test_oxs.py', 'os_ken/tests/switch/of14/match/04_ETH_SRC_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/26_IPV6_SRC.json', 'ryu/services/protocols/ovsdb/client.py', 'os_ken/tests/packet_data/of13/4-25-ofp_aggregate_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-69-ofp_bundle_ctrl_msg.packet.json', 'os_ken/tests/unit/services/protocols/bgp/core_managers/__init__.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/16_UDP_DST_IPv4.json', 'os_ken/tests/switch/of14/match/33_IPV6_ND_TLL.json', 'os_ken/tests/unit/ofproto/json/of10/1-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/32_IPV6_ND_SLL.json', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_01_1000.json', 'os_ken/tests/unit/ofproto/json/of14/5-45-ofp_meter_config_request.packet.json', 'ryu/tests/unit/ofproto/test_parser_ofpmatch.py', 'os_ken/tests/switch/of14/match/16_UDP_DST_IPv4.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status_request.packet', 'ryu/tests/mininet/l2/mpls/test_mpls.py', 'ryu/tests/unit/packet/test_vxlan.py', 'os_ken/tests/unit/ofproto/json/of14/5-52-ofp_port_desc_reply.packet.json', 'os_ken/lib/packet/bfd.py', 'os_ken/services/protocols/bgp/info_base/evpn.py', 'ryu/tests/unit/test_utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-12-ofp_flow_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-50-ofp_meter_features_reply.packet.json', 'ryu/tests/integrated/test_add_flow_v12_actions.py', 'os_ken/tests/unit/ofproto/json/of14/5-57-ofp_packet_in.packet.json', 'os_ken/tests/packet_data/of13/4-57-ofp_group_stats_request.packet', 'os_ken/tests/packet_data/of12/3-62-ofp_group_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_desc_reply.packet.json', 'os_ken/services/protocols/vrrp/event.py', 'os_ken/services/protocols/bgp/info_base/vrf4fs.py', 'os_ken/services/protocols/bgp/core_managers/import_map_manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod.packet.json', 'ryu/services/protocols/bgp/info_base/vrf4.py', 'os_ken/tests/packet_data/pcap/big_endian.pcap', 'os_ken/tests/unit/ofproto/test_parser_ofpstats.py', 'os_ken/cmd/rpc_cli.py', 'ryu/services/protocols/bgp/core_managers/import_map_manager.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-50-ofp_meter_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-set_config.packet.json', 'ryu/services/protocols/bgp/core_manager.py', 'ryu/services/protocols/bgp/api/operator.py', 'os_ken/tests/integrated/test_vrrp_linux_multi.sh', 'os_ken/tests/unit/ofproto/json/of13/4-16-ofp_experimenter.packet.json', 'ryu/ofproto/ofproto_v1_5.py', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_01_10M.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-51-ofp_port_desc_request.packet', 'os_ken/tests/packet_data/pcap/gre_nvgre_option.pcap', 'os_ken/tests/switch/of13/match/26_IPV6_SRC_Mask.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_request.mn', 'ryu/services/protocols/zebra/db/route.py', 'os_ken/tests/packet_data/of13/4-34-ofp_group_desc_reply.packet', 'os_ken/app/cbench.py', 'ryu/app/example_switch_13.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/14_TCP_DST_IPv4.json', 'os_ken/tests/packet_data/of14/5-40-ofp_get_async_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-17-ofp_barrier_request.packet.json', 'ryu/tests/mininet/l3/icmp/test_icmp.py', 'os_ken/lib/ovs/bridge.py', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/tests/switch/of13/match/22_ARP_SPA.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_nat_v6.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_inc_multi_eth_tag.pcap', 'os_ken/tests/unit/packet/test_lldp.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_controller.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_ctrl.packet', 'os_ken/tests/switch/of14/match/19_ICMPV4_TYPE.json', 'ryu/services/protocols/bgp/utils/validation.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_features_request.packet', 'os_ken/tests/unit/controller/test_controller.py', 'os_ken/tests/integrated/common/install_docker_test_pkg_for_travis.sh', 'ryu/controller/tunnels.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/32_IPV6_ND_SLL.json', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_dec_nw_ttl.packet', 'os_ken/tests/packet_data/pcap/openflow_flowstats_req.pcap', 'os_ken/tests/switch/of14/action/20_POP_MPLS.json', 'os_ken/services/protocols/bgp/__init__.py', 'os_ken/tests/run_tests.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-61-ofp_group_stats_request.packet.json', 'os_ken/tests/switch/of14/match/09_IP_ECN_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_clear.packet.json', 'ryu/services/protocols/vrrp/router.py', 'os_ken/tests/switch/of14/match/00_IN_PORT.json', 'ryu/tests/unit/packet/test_ipv6.py', 'os_ken/tests/switch/of13/match/20_ICMPV4_CODE.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_no_nx.packet.json', 'ryu/__init__.py', 'os_ken/lib/packet/geneve.py', 'ryu/tests/unit/cmd/dummy_openflow_app.py', 'os_ken/tests/switch/of14/group/01_SELECT_Weight_IP.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/services/protocols/vrrp/__init__.py', 'os_ken/tests/packet_data/of14/5-20-ofp_role_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_exec.packet.json', 'ryu/app/simple_switch_igmp_13.py', 'os_ken/tests/switch/of14/action/17_PUSH_VLAN.json', 'os_ken/tests/packet_data_generator2/Makefile.BSD', 'os_ken/tests/packet_data/of13/libofproto-OFP13-echo_reply.packet', 'ryu/lib/ip.py', 'os_ken/tests/unit/ofproto/json/of12/3-8-ofp_get_config_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-packet_in.packet.json', 'os_ken/services/protocols/bgp/utils/bgp.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_features_request.packet', 'os_ken/tests/unit/ofproto/json/of13/4-10-ofp_hello.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-15-ofp_error_msg.packet.json', 'os_ken/tests/packet_data/of12/3-4-ofp_packet_in.packet', 'os_ken/services/protocols/bgp/info_base/vrf6.py', 'os_ken/tests/switch/of14/match/04_ETH_SRC.json', 'os_ken/tests/unit/ofproto/test_ofproto.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-meter_mod.packet.json', 'os_ken/tests/packet_data/of12/3-35-ofp_queue_get_config_request.packet', 'ryu/ofproto/ofproto_v1_5_parser.py', 'ryu/cmd/manager.py', 'os_ken/tests/switch/of13/match/15_UDP_SRC_IPv6.json', 'os_ken/tests/packet_data/of14/5-69-ofp_bundle_ctrl_msg.packet', 'os_ken/tests/unit/ofproto/json/of14/5-31-ofp_group_features_request.packet.json', 'os_ken/tests/packet_data/of14/5-39-ofp_error_msg_experimenter.packet', 'ryu/services/protocols/bgp/core_managers/peer_manager.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_sample2.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-59-ofp_packet_in.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_mod.packet.json', 'os_ken/lib/packet/packet_utils.py', 'os_ken/tests/packet_data/of13/4-14-ofp_echo_reply.packet', 'os_ken/services/protocols/ovsdb/api.py', 'os_ken/ofproto/oxs_fields.py', 'os_ken/services/protocols/bgp/info_base/vrf.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_vpn6.pcap', 'os_ken/services/protocols/bgp/api/rpc_log_handler.py', 'os_ken/tests/packet_data/of12/3-3-ofp_flow_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/lib/test_rpc.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/21_ARP_OP.json', 'os_ken/tests/switch/of14/match/38_TUNNEL_ID.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/05_ETH_TYPE.json', 'os_ken/tests/packet_data/of12/3-18-ofp_barrier_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-40-ofp_get_async_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_config_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_match_conj.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_desc_request.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-65-ofp_role_status.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_stats_reply.packet.json', 'ryu/ofproto/ofproto_v1_2.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/unit/__init__.py', 'os_ken/tests/unit/packet/test_ospf.py', 'os_ken/tests/switch/of14/match/15_UDP_SRC_IPv4.json', 'os_ken/services/protocols/bgp/utils/__init__.py', 'os_ken/tests/unit/packet/test_ipv6.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/06_VLAN_VID.json', 'os_ken/tests/unit/ofproto/json/of13/4-32-ofp_group_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_stats_reply.packet.json', 'os_ken/tests/mininet/l3/icmp/test_icmp.py', 'ryu/tests/unit/packet/test_udp.py', 'os_ken/tests/switch/of14/match/37_PBB_ISID_Mask.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/35_MPLS_TC.json', 'os_ken/lib/packet/cfm.py', 'os_ken/services/protocols/bgp/base.py', 'os_ken/tests/unit/ofproto/json/of12/3-6-ofp_features_reply.packet.json', 'ryu/tests/unit/lib/test_ofctl_action_match.py', 'ryu/services/protocols/bgp/processor.py', 'os_ken/app/gui_topology/html/router.svg', 'os_ken/tests/packet_data/of12/3-1-ofp_packet_out.packet', 'os_ken/tests/unit/ofproto/json/of13/4-52-ofp_meter_features_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-aggregate_stats_request.packet', 'ryu/services/protocols/bgp/info_base/vrf6fs.py', 'os_ken/tests/unit/ofproto/json/of14/5-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of12/3-6-ofp_features_reply.packet', 'os_ken/lib/of_config/of-config-1.1.xsd', 'ryu/tests/unit/cmd/dummy_app.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-22-ofp_port_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-0-ofp_desc_reply.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_eth_seg.pcap', 'os_ken/tests/packet_data/of15/libofproto-OFP15-echo_reply.packet', 'ryu/tests/unit/lib/test_addrconv.py', 'os_ken/tests/switch/of10/action/03_STRIP_VLAN.json', 'ryu/app/simple_switch_websocket_13.py', 'os_ken/app/simple_switch_lacp_13.py', 'os_ken/ofproto/ofproto_v1_3_parser.py', 'os_ken/tests/unit/packet/test_tcp.py', 'os_ken/lib/ofctl_nicira_ext.py', 'os_ken/tests/switch/of13/action/26_PUSH_PBB_multiple.json', 'os_ken/tests/switch/of13/match/04_ETH_SRC.json', 'os_ken/lib/ofctl_string.py', 'ryu/services/protocols/bgp/operator/commands/show/importmap.py', 'os_ken/tests/packet_data/of13/4-0-ofp_desc_reply.packet', 'os_ken/tests/packet_data/of14/5-38-ofp_flow_removed.packet', 'os_ken/tests/packet_data_generator/src/x3.erl', 'os_ken/tests/unit/packet/test_pbb.py', 'os_ken/tests/packet_data/of14/5-23-ofp_table_mod.packet', 'os_ken/cmd/ofa_neutron_agent.py', 'os_ken/tests/packet_data/of13/4-24-ofp_desc_request.packet', 'ryu/tests/integrated/test_add_flow_v12_matches.py', 'os_ken/tests/unit/app/__init__.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-39-ofp_port_status.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_conj.packet', 'os_ken/exception.py', 'os_ken/tests/unit/ofproto/json/of12/3-32-ofp_group_features_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/4-13-ofp_echo_request.packet', 'os_ken/tests/switch/of14/match/17_SCTP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-44-ofp_set_async.packet.json', 'os_ken/tests/packet_data/of13/4-52-ofp_meter_features_reply.packet', 'os_ken/tests/packet_data/of14/5-32-ofp_group_features_reply.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/16_UDP_DST_IPv4.json', 'ryu/services/protocols/zebra/event.py', 'os_ken/tests/switch/of14/match/18_SCTP_DST_IPv6.json', 'os_ken/services/protocols/ovsdb/event.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/10_IP_PROTO_IPv4.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-port_status.packet', 'os_ken/lib/packet/mpls.py', 'os_ken/tests/packet_data/of13/4-23-ofp_table_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_mod.packet.json', 'os_ken/controller/ofp_handler.py', 'os_ken/services/protocols/vrrp/router.py', 'os_ken/tests/switch/of14/match/03_ETH_DST.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-port_status.packet.json', 'os_ken/tests/integrated/common/ryubgp.py', 'os_ken/tests/packet_data/of12/3-5-ofp_features_request.packet', 'os_ken/tests/switch/of14/match/09_IP_ECN_IPv4.json', 'os_ken/tests/packet_data/of14/5-14-ofp_echo_reply.packet', 'os_ken/tests/unit/ofproto/json/of10/1-6-ofp_switch_features.packet.json', 'os_ken/tests/switch/of13/match/10_IP_PROTO_IPv6.json', 'os_ken/tests/switch/tester.py', 'os_ken/tests/mininet/l2/mpls/PopMPLS_mpls.mn', 'os_ken/topology/api.py', 'os_ken/app/simple_switch.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_stats_request.packet', 'ryu/services/protocols/bgp/utils/bgp.py', 'os_ken/services/protocols/bgp/info_base/l2vpnfs.py', 'os_ken/tests/switch/of14/match/21_ARP_OP.json', 'os_ken/tests/packet_data/of14/5-70-ofp_bundle_add_msg.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_stats_reply.packet.json', 'os_ken/controller/mac_to_network.py', 'os_ken/services/protocols/bgp/bmp.py', 'os_ken/app/rest_router.py', 'os_ken/tests/packet_data/pcap/zebra_v4_frr_v2.pcap', 'os_ken/tests/unit/test_utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-71-ofp_requestforward.packet.json', 'ryu/tests/unit/lib/test_mod/fff.py', 'ryu/tests/unit/ofproto/test_parser_ofpstats.py', 'os_ken/lib/packet/ipv6.py', 'os_ken/tests/unit/ofproto/json/of12/3-7-ofp_set_config.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_esi_mac_base.pcap', 'os_ken/tests/unit/app/test_ofctl_rest.py', 'ryu/tests/unit/lib/test_of_config_classes.py', 'os_ken/tests/packet_data/of13/4-56-ofp_table_features_reply.packet', 'os_ken/ofproto/inet.py', 'os_ken/tests/integrated/test_add_flow_v12_actions.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/tests/mininet/l2/vlan/PushVLAN_icmp.mn', 'os_ken/tests/switch/of14/action/19_PUSH_MPLS.json', 'ryu/services/protocols/bgp/operator/ssh.py', 'os_ken/services/protocols/bgp/api/operator.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/22_ARP_SPA.json', 'os_ken/lib/packet/linux.py', 'os_ken/app/simple_switch_stp.py', 'ryu/services/protocols/bgp/utils/evtlet.py', 'os_ken/tests/packet_data/of13/4-2-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of14/5-43-ofp_meter_mod.packet', 'ryu/services/protocols/bgp/operator/commands/root.py', 'os_ken/tests/switch/of14/match/39_IPV6_EXTHDR_Mask.json', 'ryu/tests/unit/ofproto/test_ofproto_parser.py', 'os_ken/tests/packet_data/of13/4-41-ofp_error_msg_experimenter.packet', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-table_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/lib/ovs/__init__.py', 'os_ken/services/protocols/bgp/utils/evtlet.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_stats_request.packet', 'ryu/tests/unit/services/protocols/bgp/utils/test_bgp.py', 'os_ken/tests/packet_data/of12/3-2-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod_match_conj.packet', 'os_ken/tests/unit/ofproto/json/of14/5-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv6_UDP.json', 'os_ken/tests/packet_data/of13/4-9-ofp_get_config_reply.packet', 'os_ken/services/protocols/bgp/rtconf/base.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-18-ofp_barrier_reply.packet.json', 'os_ken/tests/packet_data_generator/src/x_of_protocol.erl', 'ryu/ofproto/oxs_fields.py', 'os_ken/tests/packet_data/bgp4/bgp4-open.pcap', 'os_ken/tests/packet_data/of14/5-26-ofp_aggregate_stats_reply.packet', 'os_ken/services/protocols/bgp/core_managers/__init__.py', 'os_ken/tests/packet_data/of14/5-53-ofp_table_features_request.packet', 'os_ken/tests/packet_data/of13/4-6-ofp_features_reply.packet', 'ryu/lib/mrtlib.py', 'os_ken/tests/mininet/l2/mpls/PushMPLS_ip.mn', 'ryu/tests/unit/lib/ofctl_json/of14/5-46-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/03_ETH_DST.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/12_IPV4_DST.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-desc_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv4.py', 'os_ken/tests/switch/of13/match/19_ICMPV4_TYPE.json', 'os_ken/tests/unit/ofproto/json/of10/1-1-ofp_packet_out.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/neighbor.py', 'os_ken/tests/unit/ofproto/json/of12/3-23-ofp_table_mod.packet.json', 'os_ken/services/protocols/zebra/client/sample_dumper.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_get_config_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/27_IPV6_DST.json', 'os_ken/lib/packet/safi.py', 'os_ken/tests/unit/ofproto/json/of12/3-25-ofp_aggregate_stats_request.packet.json', 'os_ken/lib/rpc.py', 'os_ken/tests/unit/controller/__init__.py', 'os_ken/tests/unit/ofproto/test_parser_compat.py', 'os_ken/tests/unit/services/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-22-ofp_port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-1-ofp_packet_out.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_controller2.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-get_config_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_monitor_reply.packet.json', 'os_ken/tests/switch/of14/match/24_ARP_SHA.json', 'os_ken/tests/unit/packet/test_vlan.py', 'os_ken/lib/mac.py', 'os_ken/services/protocols/bgp/api/rtconf.py', 'ryu/app/simple_switch_snort.py', 'os_ken/tests/packet_data/of13/4-19-ofp_role_request.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/15_UDP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-29-ofp_port_stats_request.packet.json', 'os_ken/services/protocols/bgp/signals/__init__.py', 'ryu/base/app_manager.py', 'os_ken/tests/packet_data/of14/5-63-ofp_queue_desc_request.packet', 'ryu/ofproto/nx_match.py', 'ryu/services/protocols/bgp/rtconf/common.py', 'os_ken/tests/packet_data/of12/3-16-ofp_experimenter.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data_generator/src/x1.erl', 'ryu/tests/unit/packet/test_tcp.py', 'os_ken/tests/packet_data/of13/4-18-ofp_barrier_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-32-ofp_group_features_stats_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/vpnv4.py', 'os_ken/tests/packet_data/of13/4-21-ofp_group_mod.packet', 'os_ken/tests/unit/ofproto/json/of14/5-53-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of13/4-10-ofp_hello.packet', 'os_ken/services/protocols/bgp/core_managers/configuration_manager.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_meter_config_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod_conjunction.packet', 'os_ken/tests/unit/ofproto/json/of14/libofproto-OFP14-ofp_packet_out_packet_library.packet.json', 'ryu/tests/unit/__init__.py', 'os_ken/tests/switch/of14/match/12_IPV4_DST.json', 'os_ken/services/protocols/bgp/speaker.py', 'ryu/tests/unit/lib/ovs/__init__.py', 'os_ken/tests/unit/app/ofctl_rest_json/of15.json', 'os_ken/tests/packet_data/of14/5-11-ofp_flow_stats_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-24-ofp_desc_request.packet', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv4_TCP.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/08_IP_DSCP_IPv4.json', 'os_ken/app/simple_switch_15.py', 'os_ken/tests/unit/ofproto/json/of13/4-20-ofp_role_reply.packet.json', 'ryu/app/gui_topology/gui_topology.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-echo_request.packet', 'os_ken/tests/switch/of14/action/26_PUSH_PBB_multiple.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-set_async.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/15_UDP_SRC_IPv6.json', 'os_ken/services/protocols/bgp/utils/circlist.py', 'ryu/services/protocols/bgp/info_base/ipv6fs.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_stats_request.packet.json', 'os_ken/tests/packet_data/of13/4-32-ofp_group_features_reply.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod.truncated64', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_02_10000.json', 'os_ken/controller/dpset.py', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_02_100M.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_ip_prefix.pcap', 'os_ken/tests/packet_data/bgp4/evpn_esi_router_id.pcap', 'os_ken/tests/packet_data/of13/4-17-ofp_barrier_request.packet', 'os_ken/tests/packet_data/of12/3-24-ofp_desc_stats_request.packet', 'ryu/tests/unit/lib/test_mod/bbb/__init__.py', 'os_ken/tests/integrated/bgp/base.py', 'os_ken/ofproto/nx_match.py', 'os_ken/tests/switch/of14/group/01_SELECT_Ether.json', 'os_ken/app/bmpstation.py', 'os_ken/tests/unit/packet/test_icmp.py', 'ryu/controller/conf_switch.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-table_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_sample.packet.json', 'os_ken/tests/switch/of14/match/26_IPV6_SRC_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-12-ofp_flow_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_desc_reply.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_controller2.packet', 'os_ken/tests/switch/of10/action/06_SET_NW_SRC.json', 'ryu/services/protocols/bgp/info_base/vrf4fs.py', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_get_config_request.packet.json', 'os_ken/tests/packet_data/of13/4-28-ofp_table_stats_reply.packet', 'os_ken/services/protocols/bgp/operator/views/base.py', 'os_ken/tests/switch/of13/action/24_DEC_NW_TTL_IPv4.json', 'os_ken/tests/unit/ofproto/json/of14/5-18-ofp_barrier_reply.packet.json', 'ryu/app/simple_switch_igmp.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_config_request.packet.json', 'ryu/services/protocols/bgp/api/jsonrpc.py', 'ryu/services/protocols/vrrp/monitor_linux.py', 'os_ken/tests/test_lib.py', 'ryu/services/protocols/vrrp/api.py', 'os_ken/tests/packet_data/of14/5-27-ofp_table_stats_request.packet', 'os_ken/tests/integrated/common/install_docker_test_pkg_common.sh', 'os_ken/tests/packet_data/of10/libofproto-OFP10-ofp_packet_out_packet_library.packet', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_desc_request.packet.json', 'ryu/tests/__init__.py', 'os_ken/lib/ofctl_v1_3.py', 'os_ken/tests/packet_data_generator/rebar.config', 'os_ken/tests/unit/ofproto/json/of13/4-7-ofp_set_config.packet.json', 'os_ken/tests/switch/of10/action/05_SET_DL_DST.json', 'os_ken/tests/switch/of13/match/25_ARP_THA_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-12-ofp_flow_stats_reply.packet.json', 'os_ken/lib/snortlib.py', 'os_ken/tests/unit/ofproto/json/of14/5-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/unit/sample/test_sample2.py', 'os_ken/tests/switch/of10/match/06_NW_TOS_IPv6.json', 'os_ken/tests/unit/ofproto/json/of10/1-4-ofp_packet_in.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-24-ofp_desc_request.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_eth_a-d.pcap', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_monitor_request.packet.json', 'ryu/controller/mac_to_network.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/23_ARP_TPA.json', 'os_ken/tests/unit/ofproto/json/of13/4-39-ofp_port_status.packet.json', 'ryu/services/protocols/vrrp/dumper.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/25_ARP_THA.json', 'os_ken/tests/packet_data/of14/5-31-ofp_group_features_request.packet', 'os_ken/ofproto/ofproto_v1_2.py', 'os_ken/tests/packet_data/of13/4-51-ofp_meter_features_request.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-table_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_features_reply.packet', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv6_TCP.json', 'os_ken/tests/unit/ofproto/json/of14/5-41-ofp_get_async_reply.packet.json', 'os_ken/tests/unit/packet/test_packet.py', 'os_ken/tests/unit/ofproto/json/of13/4-4-ofp_packet_in.packet.json', 'os_ken/services/protocols/zebra/client/zclient.py', 'os_ken/tests/mininet/l2/vlan/test_vlan.py', 'os_ken/services/protocols/vrrp/sample_manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-experimenter.packet.json', 'os_ken/tests/unit/packet/test_mpls.py', 'ryu/services/protocols/bgp/operator/commands/show/rib.py', 'ryu/tests/unit/lib/test_mod/aaa/mod.py', 'os_ken/tests/switch/of13/action/12_COPY_TTL_IN.json', 'os_ken/tests/unit/ofproto/json/of14/5-6-ofp_features_reply.packet.json', 'os_ken/tests/switch/of10/match/05_DL_TYPE.json', 'ryu/services/protocols/bgp/info_base/vpnv6.py', 'os_ken/tests/packet_data/of14/5-49-ofp_meter_features_request.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/services/protocols/zebra/event.py', 'ryu/controller/mac_to_port.py', 'ryu/services/protocols/vrrp/monitor_openflow.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_desc_request.packet.json', 'ryu/app/simple_switch_lacp_13.py', 'ryu/services/protocols/bgp/operator/views/bgp.py', 'os_ken/tests/packet_data/of12/3-15-ofp_error_msg.packet', 'os_ken/tests/integrated/vrrp_common.py', 'ryu/tests/integrated/common/docker_base.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_desc_request.packet', 'os_ken/tests/packet_data/of12/3-33-ofp_group_desc_stats_request.packet', 'os_ken/tests/integrated/bgp/test_basic.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/20_ICMPV4_CODE.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_async_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_desc_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_desc_reply.packet.json', 'os_ken/tests/switch/of13/match/13_TCP_SRC_IPv6.json', 'os_ken/tests/switch/of14/match/11_IPV4_SRC_Mask.json', 'os_ken/lib/packet/ether_types.py', 'os_ken/lib/netconf/netconf.xsd', 'os_ken/tests/switch/of13/action/17_PUSH_VLAN.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of14/5-10-ofp_hello.packet.json', 'ryu/lib/bfdlib.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_features_reply.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/route_formatter_mixin.py', 'os_ken/tests/packet_data_generator3/gen.py', 'ryu/ofproto/ofproto_utils.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/33_IPV6_ND_TLL.json', 'os_ken/tests/switch/of13/match/33_IPV6_ND_TLL.json', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_port_stats_request.packet.json', 'ryu/app/simple_switch_15.py', 'ryu/tests/integrated/test_vrrp_multi.py', 'os_ken/tests/packet_data/of13/4-58-ofp_group_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-34-ofp_group_desc_stats_reply.packet.json', 'os_ken/tests/packet_data/of12/3-30-ofp_port_stats_reply.packet', 'os_ken/tests/switch/of13/match/17_SCTP_SRC_IPv6.json', 'os_ken/services/protocols/bgp/operator/commands/clear.py', 'os_ken/lib/xflow/netflow.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_tc.packet.json', 'ryu/tests/unit/lib/test_mrtlib.py', 'os_ken/app/ofctl_rest.py', 'os_ken/tests/unit/services/protocols/bgp/utils/test_validation.py', 'os_ken/tests/packet_data/of14/5-71-ofp_requestforward.packet', 'os_ken/lib/alert.py', 'ryu/services/protocols/bgp/info_base/vrffs.py', 'os_ken/tests/switch/of13/action/23_SET_NW_TTL_IPv4.json', 'os_ken/tests/switch/of13/match/18_SCTP_DST_IPv6.json', 'ryu/tests/unit/ofproto/test_inet.py', 'ryu/tests/unit/packet/test_openflow.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_add.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_features_reply.packet.json', 'os_ken/tests/switch/of13/match/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_features_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_mod.packet.json', 'ryu/tests/integrated/run_tests_with_ovs12.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-35-ofp_queue_get_config_request.packet.json', 'os_ken/services/protocols/bgp/core_manager.py', 'os_ken/tests/packet_data/of13/4-47-ofp_meter_config_request.packet', 'ryu/tests/unit/ofproto/test_parser.py', 'os_ken/lib/packet/dhcp6.py', 'os_ken/hooks.py', 'ryu/services/protocols/zebra/server/event.py', 'os_ken/tests/switch/of13/match/03_ETH_DST_Mask.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_pkt_mark_masked.packet', 'os_ken/tests/switch/of13/match/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data/bgp4/bgp4-keepalive.pcap', 'os_ken/tests/unit/cmd/test_manager.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-get_config_reply.packet', 'os_ken/tests/packet_data/of14/5-67-ofp_flow_monitor_reply.packet', 'os_ken/services/protocols/bgp/protocol.py', 'os_ken/services/protocols/bgp/rtconf/__init__.py', 'os_ken/tests/packet_data/of12/3-28-ofp_table_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-16-ofp_experimenter.packet.json', 'ryu/controller/ofp_api.py', 'os_ken/services/protocols/vrrp/sample_router.py', 'os_ken/app/ofctl/event.py', 'os_ken/tests/unit/ofproto/json/of13/4-3-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/test_ether.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_01_10M.json', 'os_ken/tests/switch/of13/match/38_TUNNEL_ID.json', 'ryu/ofproto/ofproto_protocol.py', 'ryu/tests/unit/packet/test_icmp.py', 'os_ken/tests/switch/of14/match/05_ETH_TYPE.json', 'os_ken/services/protocols/bgp/api/base.py', 'os_ken/services/protocols/zebra/db/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-26-ofp_aggregate_stats_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-16-ofp_experimenter.packet.json', 'os_ken/services/protocols/bgp/operator/command.py', 'os_ken/tests/switch/of13/match/06_VLAN_VID.json', 'os_ken/tests/packet_data_generator/src/x5.erl', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_features_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/13_TCP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-60-ofp_flow_mod.packet.json', 'os_ken/app/rest_qos.py', 'os_ken/tests/switch/of10/match/01_DL_SRC.json', 'os_ken/tests/switch/of13/match/16_UDP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_status.packet.json', 'os_ken/services/protocols/vrrp/rpc_manager.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_async_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-9-ofp_get_config_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_desc_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-packet_in.packet', 'os_ken/tests/unit/ofproto/test_parser_ofpmatch.py', 'os_ken/lib/packet/slow.py', 'os_ken/tests/switch/of14/match/32_IPV6_ND_SLL.json', 'os_ken/tests/unit/services/protocols/bgp/test_peer.py', 'os_ken/tests/switch/of14/match/27_IPV6_DST.json', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_mod.packet.json', 'os_ken/lib/of_config/classes.py', 'os_ken/controller/controller.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/09_IP_ECN_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/switch/of10/action/08_SET_NW_TOS_IPv6.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-aggregate_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-desc_reply.packet.json', 'ryu/tests/unit/ofproto/test_ofproto_common.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/19_ICMPV4_TYPE.json', 'os_ken/controller/conf_switch.py', 'os_ken/services/protocols/vrrp/monitor_openflow.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/tests/packet_data/of14/5-65-ofp_role_status.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/14_TCP_DST_IPv4.json', 'os_ken/tests/packet_data/of14/5-36-ofp_queue_stats_reply.packet', 'os_ken/tests/packet_data/of14/5-52-ofp_port_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_group_stats_request.packet.json', 'ryu/tests/unit/packet/test_bmp.py', 'ryu/tests/unit/app/test_ws_topology.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/unit/ofproto/json/of12/3-59-ofp_packet_in.packet.json', 'os_ken/tests/mininet/l2/vlan/PopVLAN_vlanvlan.mn', 'os_ken/tests/unit/ofproto/json/of14/5-22-ofp_port_mod.packet.json', 'os_ken/lib/packet/arp.py', 'os_ken/tests/switch/of14/match/08_IP_DSCP_IPv4.json', 'ryu/tests/unit/packet/test_ospf.py', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_00_100.json', 'ryu/tests/unit/lib/test_ip.py', 'os_ken/tests/switch/of10/match/09_NW_DST_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-set_config.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-35-ofp_queue_get_config_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-error_msg.packet', 'os_ken/tests/unit/ofproto/json/of12/3-5-ofp_features_request.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_exec.packet', 'os_ken/tests/unit/ofproto/json/of14/5-38-ofp_flow_removed.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter.packet.json', 'os_ken/tests/integrated/common/__init__.py', 'os_ken/lib/packet/vlan.py', 'os_ken/tests/unit/ofproto/json/of14/lib-ofctl-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of13/4-46-ofp_flow_mod.packet', 'os_ken/services/protocols/bgp/application.py', 'ryu/tests/unit/packet/test_pbb.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_monitor_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_conjunction.packet.json', 'ryu/services/protocols/bgp/application.py', 'ryu/services/protocols/bgp/bgp_sample_conf.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_features_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-24-ofp_desc_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/30_ICMPV6_CODE.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_dec_ttl_cnt_ids.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-16-ofp_experimenter.packet.json', 'os_ken/services/protocols/bgp/core_managers/peer_manager.py', 'os_ken/tests/packet_data/pcap/openflow_invalid_version.pcap', 'os_ken/tests/switch/of13/action/25_SET_FIELD/34_MPLS_LABEL.json', 'os_ken/topology/dumper.py', 'os_ken/tests/packet_data/of12/3-12-ofp_flow_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/4-51-ofp_meter_features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-48-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of13/match/39_IPV6_EXTHDR.json', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-ofp_queue_stats_request.packet.json', 'os_ken/tests/mininet/l2/mpls/test_mpls.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-desc_reply.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/07_VLAN_PCP.json', 'ryu/services/protocols/bgp/operator/commands/responses.py', 'os_ken/lib/of_config/generated_classes.py', 'os_ken/app/gui_topology/html/ryu.topology.css', 'os_ken/tests/switch/of14/match/34_MPLS_LABEL.json', 'os_ken/services/protocols/bgp/info_base/vrf6fs.py', 'ryu/services/protocols/bgp/core_managers/configuration_manager.py', 'os_ken/app/ofctl/exception.py', 'os_ken/tests/switch/of14/match/20_ICMPV4_CODE.json', 'ryu/services/protocols/bgp/info_base/vpnv4fs.py', 'os_ken/tests/packet_data/of13/4-30-ofp_port_stats_reply.packet', 'os_ken/services/protocols/bgp/api/import_map.py', 'os_ken/tests/packet_data/of13/4-7-ofp_set_config.packet', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_02_100M.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-features_reply.packet.json', 'ryu/tests/unit/packet/test_mpls.py', 'os_ken/lib/of_config/xmldsig-core-schema.xsd', 'os_ken/lib/packet/pbb.py', 'os_ken/tests/switch/of14/match/13_TCP_SRC_IPv6.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_clear.packet', 'os_ken/tests/switch/of13/match/28_IPV6_FLABEL_Mask.json', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_00_100.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_controller.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-58-ofp_flow_mod.packet.json', 'os_ken/app/simple_switch_14.py', 'os_ken/services/protocols/bgp/operator/commands/__init__.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-echo_request.packet.json', 'os_ken/app/simple_monitor_13.py', 'os_ken/tests/switch/of13/group/01_SELECT_Weight_IP.json', 'os_ken/tests/unit/ofproto/test_inet.py', 'ryu/app/bmpstation.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/20_ICMPV4_CODE.json', 'os_ken/tests/unit/ofproto/json/of12/3-16-ofp_experimenter.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_pop_mpls.packet.json', 'os_ken/tests/packet_data/of14/5-47-ofp_meter_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_get_config_request.packet.json', 'os_ken/lib/packet/tcp.py', 'ryu/tests/unit/ofproto/test_ofproto_v12.py', 'ryu/services/protocols/bgp/api/rpc_log_handler.py', 'os_ken/tests/unit/packet/test_sctp.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-35-ofp_queue_get_config_request.packet.json', 'ryu/tests/unit/lib/test_hub.py', 'ryu/services/protocols/bgp/info_base/ipv4.py', 'os_ken/tests/packet_data/of13/4-35-ofp_queue_get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-60-ofp_flow_mod.packet.json', 'os_ken/lib/ovs/vsctl.py', 'os_ken/tests/switch/of13/match/32_IPV6_ND_SLL.json', 'os_ken/services/protocols/bgp/api/all.py', 'os_ken/services/protocols/bgp/info_base/vpnv6fs.py', 'os_ken/tests/packet_data/of13/4-44-ofp_set_async.packet', 'os_ken/lib/packet/stream_parser.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_desc_request.packet', 'os_ken/tests/switch/of13/action/17_PUSH_VLAN_multiple.json', 'os_ken/tests/switch/of14/match/30_ICMPV6_CODE.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-6-ofp_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-56-ofp_group_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/test_oxs.py', 'ryu/app/cbench.py', 'os_ken/tests/packet_data/of14/5-7-ofp_set_config.packet', 'os_ken/tests/unit/ofproto/json/of12/3-28-ofp_table_stats_reply.packet.json', 'ryu/ofproto/ofproto_v1_3.py', 'os_ken/services/protocols/bgp/info_base/__init__.py', 'ryu/topology/event.py', 'os_ken/tests/packet_data/of13/4-61-ofp_experimenter_request.packet', 'ryu/ofproto/ofproto_parser.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-48-ofp_meter_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/30_ICMPV6_CODE.json', 'os_ken/tests/packet_data/of12/3-34-ofp_group_desc_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_stats_request.packet.json', 'os_ken/services/protocols/bgp/bgp_sample_conf.py', 'os_ken/tests/unit/packet/test_arp.py', 'os_ken/tests/packet_data/of14/5-16-ofp_experimenter.packet', 'os_ken/tests/packet_data/of14/5-17-ofp_barrier_request.packet', 'ryu/tests/unit/ofproto/test_oxm.py', 'os_ken/tests/switch/of10/match/09_NW_DST.json', 'os_ken/controller/event.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_02_100M.json', 'os_ken/ofproto/ofproto_v1_5_parser.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/17_SCTP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of14/5-49-ofp_meter_features_request.packet.json', 'ryu/app/rest_conf_switch.py', 'os_ken/tests/integrated/bgp/base_ip6.py', 'ryu/app/ofctl_rest.py', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/packet_data/of10/1-6-ofp_switch_features.packet', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv6_TCP.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_learn.packet.json', 'os_ken/app/simple_switch_snort.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_resubmit.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/vrf.py', 'os_ken/tests/packet_data/of12/3-59-ofp_packet_in.packet', 'os_ken/tests/unit/ofproto/json/of13/4-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/app/ofctl_rest_json/of12.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-port_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet2.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_pkt_mark.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_mac_ip_ad.pcap', 'os_ken/tests/switch/of14/action/25_SET_FIELD/06_VLAN_VID.json', 'os_ken/tests/unit/ofproto/json/of13/4-36-ofp_queue_get_config_reply.packet.json', 'ryu/tests/unit/app/test_wsgi.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_mod.packet.json', 'ryu/services/protocols/bgp/net_ctrl.py', 'ryu/topology/dumper.py', 'os_ken/tests/unit/ofproto/json/of12/3-31-ofp_group_features_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-13-ofp_echo_request.packet.json', 'os_ken/lib/packet/vxlan.py', 'os_ken/tests/switch/of13/match/04_ETH_SRC_Mask.json', 'os_ken/services/protocols/bgp/model.py', 'os_ken/services/protocols/bgp/utils/stats.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_stats_reply.packet', 'os_ken/services/protocols/bgp/rtconf/common.py', 'ryu/ofproto/ofproto_v1_2_parser.py', 'os_ken/tests/unit/ofproto/test_parser_v12.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_push_mpls.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-42-ofp_set_async.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-33-ofp_group_desc_request.packet.json', 'os_ken/tests/unit/ofproto/test_nx_flow_spec.py', 'ryu/services/protocols/bgp/operator/commands/set.py', 'os_ken/tests/unit/ofproto/json/of12/3-20-ofp_role_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod.packet', 'os_ken/tests/switch/of14/match/25_ARP_THA_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/4-37-ofp_queue_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-27-ofp_table_stats_request.packet.json', 'ryu/topology/switches.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-0-ofp_desc_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod_conjunction.packet.json', 'os_ken/tests/packet_data_generator/src/er.app.src', 'ryu/app/simple_switch_rest_13.py', 'os_ken/app/simple_switch_stp_13.py', 'os_ken/services/protocols/bgp/info_base/base.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-features_request.packet', 'os_ken/tests/switch/of14/match/10_IP_PROTO_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-56-ofp_table_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-36-ofp_queue_get_config_reply.packet', 'os_ken/tests/switch/of13/action/24_DEC_NW_TTL_IPv6.json', 'os_ken/tests/packet_data/of14/5-56-ofp_group_stats_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/08_IP_DSCP_IPv6.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_sample2.packet', 'ryu/services/protocols/bgp/signals/emit.py', 'os_ken/tests/switch/of14/match/06_VLAN_VID_Mask.json', 'os_ken/ofproto/ofproto_utils.py', 'os_ken/tests/packet_data/of13/4-62-ofp_experimenter_reply.packet', 'os_ken/services/protocols/bgp/api/core.py', 'os_ken/tests/packet_data/of13/4-16-ofp_experimenter.packet', 'ryu/app/simple_switch.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-64-ofp_queue_desc_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-10-ofp_hello.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_reply.packet', 'os_ken/tests/switch/of14/action/19_PUSH_MPLS_multiple.json', 'os_ken/tests/switch/of13/match/26_IPV6_SRC.json', 'ryu/tests/unit/lib/test_mod/ggg.py', 'os_ken/tests/switch/of13/action/23_SET_NW_TTL_IPv6.json', 'ryu/services/protocols/zebra/db/interface.py', 'ryu/tests/mininet/l3/ip_ttl/test_ip_ttl.py', 'os_ken/services/protocols/bgp/operator/ssh.py', 'os_ken/tests/packet_data/of13/4-12-ofp_flow_stats_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-features_reply.packet', 'os_ken/tests/switch/of13/match/14_TCP_DST_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_meter_stats_request.packet.json', 'ryu/services/protocols/bgp/info_base/vpnv4.py', 'os_ken/ofproto/oxm_fields.py', 'os_ken/services/protocols/bgp/signals/emit.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/38_TUNNEL_ID.json', 'os_ken/services/protocols/bgp/info_base/vrfevpn.py', 'os_ken/app/rest_topology.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-set_config.packet', 'os_ken/tests/switch/of13/match/37_PBB_ISID.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_stats_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/13_TCP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod.packet.truncated64.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-requestforward.packet.json', 'os_ken/lib/packet/igmp.py', 'os_ken/tests/switch/of13/match/23_ARP_TPA_Mask.json', 'os_ken/topology/__init__.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_desc_reply.packet', 'os_ken/services/protocols/bgp/operator/commands/show/rib.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_features_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-set_config.packet', 'os_ken/app/simple_switch_websocket_13.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/10_IP_PROTO_IPv6.json', 'ryu/app/ofctl/service.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_label.packet', 'os_ken/tests/unit/ofproto/json/of14/5-7-ofp_set_config.packet.json', 'os_ken/tests/packet_data/of14/5-6-ofp_features_reply.packet', 'os_ken/tests/packet_data/of13/4-27-ofp_table_stats_request.packet', 'os_ken/tests/packet_data/of13/4-20-ofp_role_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-aggregate_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/18_SCTP_DST_IPv4.json', 'ryu/controller/controller.py', 'os_ken/tests/switch/of13/match/14_TCP_DST_IPv6.json', 'os_ken/tests/packet_data/of13/4-54-ofp_port_desc_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status_reply.packet', 'ryu/app/simple_switch_stp_13.py', 'ryu/app/ofctl/api.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status_request.packet.json', 'os_ken/app/example_switch_13.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-43-ofp_meter_mod.packet.json', 'ryu/tests/unit/packet/test_dhcp.py', 'os_ken/app/__init__.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/41_PBB_UCA.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/38_TUNNEL_ID.json', 'os_ken/services/protocols/ovsdb/__init__.py', 'os_ken/tests/mininet/l3/ip_ttl/test_ip_ttl.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-requestforward.packet', 'os_ken/tests/packet_data/of14/5-68-ofp_table_status.packet', 'os_ken/controller/tunnels.py', 'os_ken/tests/unit/ofproto/json/of14/5-14-ofp_echo_reply.packet.json', 'ryu/app/rest_router.py', 'os_ken/tests/packet_data/of13/4-60-ofp_flow_mod.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/08_IP_DSCP_IPv4.json', 'os_ken/tests/switch/of13/match/31_IPV6_ND_TARGET.json', 'ryu/services/protocols/zebra/client/sample_dumper.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/24_ARP_SHA.json', 'ryu/services/protocols/bgp/operator/views/other.py', 'os_ken/tests/unit/ofproto/json/of14/5-68-ofp_table_status.packet.json', 'os_ken/tests/unit/services/protocols/__init__.py', 'os_ken/tests/packet_data/of14/5-30-ofp_port_stats_reply.packet', 'ryu/app/ofctl/exception.py', 'os_ken/tests/packet_data/of13/4-63-onf_flow_monitor_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-62-ofp_table_desc_reply.packet.json', 'os_ken/tests/switch/of13/match/25_ARP_THA.json', 'os_ken/tests/mininet/l3/icmp/ICMP_reply.mn', 'os_ken/tests/switch/of10/match/08_NW_SRC_Mask.json', 'ryu/tests/integrated/run_test.py', 'os_ken/lib/mrtlib.py', 'os_ken/lib/stplib.py', 'os_ken/app/wsgi.py', 'os_ken/tests/switch/of14/match/25_ARP_THA.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_stats_reply.packet.json', 'os_ken/app/gui_topology/html/ryu.topology.js', 'os_ken/tests/packet_data/of13/4-43-ofp_get_async_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/11_IPV4_SRC.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/07_VLAN_PCP.json', 'os_ken/tests/unit/ofproto/json/of12/3-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of10/match/02_DL_DST.json', 'os_ken/services/protocols/zebra/db/base.py', 'ryu/tests/packet_data_generator3/gen.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_features_reply.packet', 'os_ken/tests/integrated/test_vrrp_multi.py', 'ryu/app/rest_qos.py', 'os_ken/ofproto/nx_actions.py', 'os_ken/tests/switch/of14/match/18_SCTP_DST_IPv4.json', 'os_ken/tests/unit/services/protocols/bgp/utils/__init__.py', 'ryu/services/protocols/zebra/server/sample_dumper.py', 'os_ken/tests/unit/app/ofctl_rest_json/of10.json', 'os_ken/app/rest_vtep.py', 'os_ken/controller/ofp_api.py', 'os_ken/ofproto/ofproto_parser.py', 'os_ken/lib/pack_utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-27-ofp_table_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-50-ofp_meter_features_reply.packet', 'os_ken/tests/switch/of10/action/02_SET_VLAN_PCP.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_mod.packet', 'os_ken/tests/unit/ofproto/json/of14/5-37-ofp_port_status.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-67-ofp_flow_monitor_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-61-ofp_table_desc_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-36-ofp_queue_stats_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/vrf4.py', 'os_ken/tests/unit/ofproto/json/of14/5-48-ofp_meter_stats_reply.packet.json', 'os_ken/tests/switch/of10/match/07_NW_PROTO_IPv6.json', 'os_ken/tests/unit/services/protocols/bgp/test_bgpspeaker.py', 'os_ken/tests/switch/of13/match/24_ARP_SHA_Mask.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status_reply.packet.json', 'ryu/ofproto/ofproto_v1_3_parser.py', 'ryu/services/protocols/bgp/info_base/ipv4fs.py', 'ryu/tests/unit/controller/test_controller.py', 'os_ken/tests/unit/ofproto/json/of13/4-5-ofp_features_request.packet.json', 'os_ken/lib/packet/lldp.py', 'ryu/tests/switch/tester.py', 'ryu/tests/unit/lib/test_mod/ddd/__init__.py', 'os_ken/tests/integrated/bgp/test_ip6_basic.py', 'ryu/services/protocols/bgp/info_base/vpnv6fs.py', 'os_ken/tests/unit/packet/test_bmp.py', 'os_ken/lib/packet/packet_base.py', 'os_ken/tests/switch/of14/match/13_TCP_SRC_IPv4.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_removed.packet', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_00_1M.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-56-ofp_group_stats_reply.packet.json', 'os_ken/services/protocols/bgp/core_managers/table_manager.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/17_SCTP_SRC_IPv6.json', 'ryu/ofproto/ether.py', 'ryu/services/protocols/vrrp/__init__.py', 'os_ken/lib/packet/bmp.py', 'os_ken/tests/packet_data/of14/5-12-ofp_flow_stats_reply.packet', 'os_ken/tests/switch/of14/match/15_UDP_SRC_IPv6.json', 'ryu/tests/unit/packet/test_slow.py', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv6_UDP.json', 'os_ken/tests/unit/packet/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_desc_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_config_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of14/5-2-ofp_flow_mod.packet.json', 'os_ken/services/protocols/vrrp/monitor.py', 'os_ken/lib/ip.py', 'os_ken/tests/unit/ofproto/json/of14/5-16-ofp_experimenter.packet.json', 'os_ken/tests/unit/ofproto/test_ofproto_v12.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-28-ofp_table_stats_reply.packet.json', 'ryu/tests/unit/lib/test_mac.py', 'os_ken/tests/unit/ofproto/json/of14/5-29-ofp_port_stats_request.packet.json', 'ryu/services/protocols/bgp/utils/rtfilter.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_lacp.pcap', 'ryu/services/protocols/bgp/api/core.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-55-ofp_table_features_request.packet.json', 'ryu/services/protocols/zebra/db/__init__.py', 'ryu/lib/hub.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/08_IP_DSCP_IPv6.json', 'ryu/tests/integrated/common/ryubgp.py', 'ryu/lib/igmplib.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_features_reply.packet.json', 'ryu/tests/unit/packet/test_zebra.py', 'os_ken/tests/unit/ofproto/json/of14/5-5-ofp_features_request.packet.json', 'os_ken/lib/stringify.py', 'ryu/services/protocols/bgp/base.py', 'os_ken/tests/unit/app/ofctl_rest_json/of14.json', 'ryu/services/protocols/bgp/bmp.py', 'ryu/tests/unit/lib/test_mod/aaa/__init__.py', 'os_ken/lib/ofctl_v1_4.py', 'os_ken/tests/unit/packet/test_zebra.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-features_reply.packet', 'ryu/tests/mininet/packet_lib/arp/test_arp.py', 'os_ken/tests/unit/ofproto/json/of13/4-0-ofp_desc_reply.packet.json', 'os_ken/tests/switch/of14/match/08_IP_DSCP_IPv6.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-barrier_reply.packet', 'ryu/tests/unit/app/test_ofctl_rest.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-52-ofp_port_desc_reply.packet.json', 'os_ken/app/ofctl/service.py', 'ryu/services/protocols/bgp/info_base/vrf.py', 'os_ken/tests/packet_data/of14/5-41-ofp_get_async_reply.packet', 'os_ken/tests/switch/of13/action/20_POP_MPLS.json', 'os_ken/tests/unit/ofproto/json/of14/5-59-ofp_experimenter_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_desc_reply.packet.json', 'os_ken/services/protocols/bgp/operator/commands/root.py', 'ryu/services/protocols/vrrp/rpc_manager.py', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv4_TCP.json', 'os_ken/tests/integrated/run_test.py', 'ryu/tests/unit/packet/test_ipv4.py', 'os_ken/base/__init__.py', 'os_ken/services/protocols/zebra/server/__init__.py', 'os_ken/controller/ofp_event.py', 'os_ken/ofproto/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-38-ofp_queue_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-1-ofp_packet_out.packet.json', 'ryu/services/protocols/bgp/info_base/vrf6.py', 'os_ken/tests/unit/ofproto/json/of12/libofproto-OFP12-ofp_packet_out_packet_library.packet.json', 'os_ken/app/simple_switch_igmp.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_pop_mpls.packet', 'os_ken/tests/unit/ofproto/json/of13/4-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of12/3-21-ofp_group_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-49-ofp_meter_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-packet_out.packet.json', 'os_ken/tests/unit/cmd/__init__.py', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv4_UDP.json', 'ryu/tests/unit/packet/test_arp.py', 'os_ken/tests/switch/of10/match/03_DL_VLAN.json', 'os_ken/lib/of_config/ietf-yang-types.xsd', 'os_ken/tests/switch/of14/match/12_IPV4_DST_Mask.json', 'os_ken/cmd/of_config_cli.py', 'os_ken/tests/unit/ofproto/json/of13/4-48-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of14/action/18_POP_VLAN.json', 'os_ken/tests/packet_data/of12/3-25-ofp_aggregate_stats_request.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_output_trunc.packet', 'ryu/tests/unit/lib/ofctl_json/of14/5-63-ofp_queue_desc_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_add.packet', 'os_ken/tests/packet_data/of12/3-19-ofp_role_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-15-ofp_error_msg.packet.json', 'os_ken/lib/ofctl_v1_0.py', 'os_ken/tests/unit/ofproto/json/of13/4-14-ofp_echo_reply.packet.json', 'os_ken/topology/switches.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/13_TCP_SRC_IPv4.json', 'os_ken/services/protocols/ovsdb/model.py', 'os_ken/tests/packet_data/of13/4-45-ofp_meter_mod.packet', 'ryu/services/protocols/bgp/info_base/vrfl2vpnfs.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/10_IP_PROTO_IPv4.json', 'ryu/flags.py', 'os_ken/tests/switch/of13/match/38_TUNNEL_ID_Mask.json', 'os_ken/lib/hub.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_desc_request.packet.json', 'ryu/tests/unit/ofproto/test_parser_v12.py', 'ryu/services/protocols/bgp/model.py', 'os_ken/lib/packet/llc.py', 'os_ken/tests/packet_data/of12/3-8-ofp_get_config_request.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_stats_reply.packet', 'os_ken/tests/packet_data/of14/5-62-ofp_table_desc_reply.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/09_IP_ECN_IPv4.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_stats_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-features_reply.packet.json', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv6_UDP.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-58-ofp_group_stats_reply.packet.json', 'os_ken/lib/sockopt.py', 'os_ken/tests/packet_data/of14/5-61-ofp_table_desc_request.packet', 'os_ken/services/protocols/bgp/net_ctrl.py', 'os_ken/tests/unit/ofproto/json/of14/5-46-ofp_meter_config_reply.packet.json', 'ryu/services/protocols/bgp/api/base.py', 'os_ken/tests/unit/app/test_tester.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_load_nx_register.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_features_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/05_ETH_TYPE.json', 'os_ken/services/protocols/bgp/info_base/vrfl2vpnfs.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_conjunction.packet.json', 'ryu/topology/api.py', 'os_ken/lib/packet/udp.py', 'ryu/cmd/of_config_cli.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_mod.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/27_IPV6_DST.json', 'os_ken/tests/packet_data/of13/4-48-ofp_meter_config_reply.packet', 'os_ken/lib/of_config/base.py', 'ryu/services/protocols/ovsdb/event.py', 'ryu/tests/switch/run_mininet.py', 'os_ken/tests/packet_data/of14/5-44-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of10/1-4-ofp_packet_in.packet', 'os_ken/services/protocols/bgp/utils/rtfilter.py', 'os_ken/tests/unit/packet/test_udp.py', 'os_ken/ofproto/ofproto_v1_5.py', 'ryu/tests/unit/lib/test_mod/bbb/mod.py', 'os_ken/tests/packet_data/of14/5-4-ofp_packet_in.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_move_nx_register.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-barrier_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-14-ofp_echo_reply.packet.json', 'os_ken/tests/switch/of14/group/01_SELECT_Weight_Ether.json', 'os_ken/tests/unit/ofproto/json/of14/5-55-ofp_group_stats_request.packet.json', 'ryu/services/protocols/bgp/info_base/vrfevpn.py', 'os_ken/services/protocols/bgp/operator/internal_api.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/37_PBB_ISID.json', 'ryu/services/protocols/zebra/client/zclient.py', 'os_ken/tests/mininet/packet_lib/arp/test_arp.py', 'os_ken/tests/packet_data/pcap/gre_full_options.pcap', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_00_1M.json', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_00_1M.json', 'ryu/topology/__init__.py', 'os_ken/tests/switch/of14/match/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of12/3-30-ofp_port_stats_reply.packet.json', 'ryu/tests/unit/packet/test_icmpv6.py', 'os_ken/tests/switch/of13/match/18_SCTP_DST_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-58-ofp_group_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_nat.packet', 'ryu/app/rest_topology.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_desc_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-barrier_request.packet', 'ryu/services/protocols/bgp/operator/commands/show/memory.py', 'ryu/tests/integrated/test_vrrp_linux_multi.py', 'os_ken/tests/unit/ofproto/json/of14/5-3-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-30-ofp_port_stats_reply.packet.json', 'ryu/app/simple_switch_12.py', 'os_ken/lib/packet/icmp.py', 'os_ken/tests/unit/ofproto/test_ofproto_parser.py', 'ryu/tests/unit/ofproto/test_ether.py', 'os_ken/tests/switch/of13/group/01_SELECT_IP.json', 'os_ken/tests/packet_data/of12/3-7-ofp_set_config.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_stats_request.packet.json', 'os_ken/tests/integrated/test_add_flow_v12_matches.py', 'os_ken/tests/mininet/l3/ip_ttl/DecNwTtl.mn', 'os_ken/tests/switch/of10/action/08_SET_NW_TOS_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/lib/test_ofctl.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_vpn4.pcap', 'os_ken/tests/packet_data/of13/4-4-ofp_packet_in.packet', 'os_ken/tests/packet_data/of13/4-11-ofp_flow_stats_request.packet', 'ryu/services/protocols/bgp/info_base/evpn.py', 'os_ken/app/simple_switch_lacp.py', 'os_ken/tests/unit/ofproto/json/of14/5-36-ofp_queue_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_stack_push.packet', 'os_ken/tests/switch/of10/action/01_SET_VLAN_VID.json', 'os_ken/tests/unit/cmd/dummy_app.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_desc_request.packet', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_02_10000.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-desc_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_desc_request.packet.json', 'ryu/tests/unit/ofproto/test_nx_flow_spec.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod_conjunction.packet', 'ryu/tests/integrated/test_request_reply_v12.py', 'os_ken/tests/packet_data/of13/4-59-ofp_packet_in.packet', 'ryu/tests/integrated/tester.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_fintimeout.packet', 'os_ken/tests/switch/of14/match/26_IPV6_SRC.json', 'ryu/tests/integrated/bgp/test_ip6_basic.py', 'os_ken/tests/packet_data/of13/4-53-ofp_port_desc_request.packet', 'os_ken/lib/ovs/db_client.py', 'os_ken/tests/integrated/test_request_reply_v12.py', 'os_ken/tests/unit/packet/test_ethernet.py', 'os_ken/services/protocols/bgp/signals/base.py', 'ryu/tests/unit/lib/test_pack_utils.py', 'os_ken/tests/mininet/l3/icmp/ICMP_ping.mn', 'os_ken/tests/switch/of14/match/11_IPV4_SRC.json', 'os_ken/services/protocols/zebra/client/event.py', 'os_ken/tests/switch/of13/match/05_ETH_TYPE.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_desc_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-32-ofp_group_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-22-ofp_port_mod.packet.json', 'os_ken/tests/switch/of13/match/23_ARP_TPA.json', 'os_ken/tests/integrated/common/install_docker_test_pkg.sh', 'os_ken/tests/switch/of13/action/25_SET_FIELD/35_MPLS_TC.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-packet_in.packet', 'os_ken/tests/integrated/tester.py', 'os_ken/lib/packet/bpdu.py', 'os_ken/tests/packet_data/of14/5-0-ofp_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-12-ofp_flow_stats_reply.packet.json', 'os_ken/services/protocols/__init__.py', 'os_ken/tests/packet_data/of13/4-8-ofp_get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/__init__.py', 'os_ken/tests/unit/packet/test_vrrp.py', 'ryu/tests/integrated/test_of_config.py', 'os_ken/services/protocols/bgp/bgpspeaker.py', 'os_ken/tests/mininet/run_mnet-test.sh', 'os_ken/tests/switch/of14/action/12_COPY_TTL_IN.json', 'os_ken/controller/network.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_nat.packet.json', 'os_ken/services/protocols/zebra/server/sample_dumper.py', 'os_ken/tests/switch/of13/match/02_METADATA_Mask.json', 'os_ken/services/protocols/bgp/info_base/vpnv6.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_conjunction.packet', 'os_ken/tests/packet_data/of14/5-3-ofp_flow_mod.packet', 'ryu/app/rest_vtep.py', 'os_ken/tests/unit/ofproto/test_parser_v13.py', 'os_ken/services/protocols/bgp/core.py', 'os_ken/tests/switch/of14/match/03_ETH_DST_Mask.json', 'ryu/app/ofctl/event.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_features_reply.packet.json', 'ryu/services/protocols/vrrp/sample_manager.py', 'os_ken/services/protocols/bgp/operator/commands/show/memory.py', 'os_ken/lib/packet/dhcp.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_learn.packet', 'os_ken/services/protocols/vrrp/manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_mod_no_nx.packet.json', 'os_ken/tests/switch/of14/match/37_PBB_ISID.json', 'ryu/ofproto/ofproto_v1_4_parser.py', 'os_ken/tests/integrated/common/docker_base.py', 'os_ken/tests/packet_data/of13/4-1-ofp_packet_out.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct.packet', 'os_ken/tests/switch/of14/match/24_ARP_SHA_Mask.json', 'os_ken/tests/switch/of13/match/13_TCP_SRC_IPv4.json', 'ryu/services/protocols/bgp/operator/views/conf.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-table_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-34-ofp_group_desc_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-hello.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_mod.packet', 'os_ken/app/simple_switch_13.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-echo_reply.packet.json', 'os_ken/tests/switch/of10/action/04_SET_DL_SRC.json', 'os_ken/tests/packet_data/bgp4/bgp4-update_ipv6.pcap', 'os_ken/tests/packet_data/of12/3-37-ofp_queue_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-44-ofp_flow_mod.packet.json', 'ryu/lib/mac.py', 'os_ken/tests/unit/ofproto/json/of13/4-38-ofp_queue_stats_reply.packet.json', 'os_ken/tests/packet_data/pcap/gre_no_option.pcap', 'ryu/services/protocols/bgp/operator/commands/show/__init__.py', 'os_ken/services/protocols/bgp/operator/commands/set.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-25-ofp_aggregate_stats_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_desc_request.packet.json', 'ryu/tests/unit/packet/test_packet.py', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_02_10000.json', 'ryu/controller/network.py', 'os_ken/tests/packet_data/of13/4-29-ofp_port_stats_request.packet', 'os_ken/lib/packet/zebra.py', 'ryu/services/protocols/bgp/operator/commands/show/neighbor.py', 'os_ken/tests/packet_data/of12/3-9-ofp_get_config_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv4_TCP.json', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_rate.pcap', 'ryu/tests/unit/lib/ofctl_json/of14/5-28-ofp_table_stats_reply.packet.json', 'ryu/app/rest_firewall.py', 'ryu/tests/unit/ofproto/test_ofproto.py', 'os_ken/tests/packet_data/of10/1-1-ofp_packet_out.packet', 'os_ken/tests/switch/of10/match/07_NW_PROTO_IPv4.json', 'os_ken/lib/packet/vrrp.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_move_nx_register.packet.json', 'ryu/services/protocols/bgp/utils/stats.py', 'ryu/tests/unit/packet/test_gre.py', 'os_ken/lib/of_config/of-config-1.0.xsd', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-barrier_request.packet.json', 'ryu/ofproto/ofproto_v1_4.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-2-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-20-ofp_role_reply.packet.json', 'os_ken/tests/packet_data/of12/3-36-ofp_queue_get_config_reply.packet', 'os_ken/tests/packet_data_generator/src/x4.erl', 'os_ken/cfg.py', 'os_ken/services/protocols/vrrp/dumper.py', 'os_ken/cmd/ryu_base.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/09_IP_ECN_IPv4.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_resubmit.packet', 'os_ken/tests/unit/ofproto/json/of12/3-19-ofp_role_request.packet.json', 'os_ken/tests/packet_data/of13/4-37-ofp_queue_stats_request.packet', 'os_ken/tests/packet_data/of10/1-2-ofp_flow_mod.packet', 'ryu/services/protocols/zebra/server/zserver.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/13_TCP_SRC_IPv6.json', 'os_ken/tests/unit/packet/test_bpdu.py', 'ryu/tests/unit/lib/ovs/test_vsctl.py', 'os_ken/tests/switch/of10/action/07_SET_NW_DST.json', 'os_ken/tests/packet_data/of12/3-17-ofp_barrier_request.packet', 'os_ken/tests/packet_data/of13/4-3-ofp_flow_mod.packet', 'os_ken/tests/unit/ofproto/json/of12/3-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv4fs.py', 'ryu/tests/unit/packet/test_bfd.py', 'ryu/app/simple_switch_lacp.py', 'os_ken/tests/packet_data/of14/5-13-ofp_echo_request.packet', 'os_ken/contrib/__init__.py', 'os_ken/tests/switch/of13/match/27_IPV6_DST_Mask.json', 'os_ken/ofproto/ofproto_v1_0.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_note.packet', 'os_ken/tests/switch/run_mininet.py', 'ryu/tests/unit/lib/test_mod/ccc/mod.py', 'os_ken/services/protocols/bgp/info_base/vrffs.py', 'ryu/services/protocols/bgp/operator/commands/clear.py', 'os_ken/tests/packet_data/of10/1-5-features_request.packet', 'os_ken/tests/packet_data/of14/5-8-ofp_get_config_request.packet', 'os_ken/lib/packet/ospf.py', 'ryu/services/protocols/ovsdb/api.py', 'os_ken/tests/unit/ofproto/json/of12/3-40-ofp_flow_removed.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_desc_reply.packet.json', 'os_ken/lib/xflow/__init__.py', 'os_ken/tests/switch/of13/match/09_IP_ECN_IPv6.json', 'os_ken/tests/packet_data/of13/4-26-ofp_aggregate_stats_reply.packet', 'os_ken/tests/switch/of13/match/16_UDP_DST_IPv4.json', 'os_ken/tests/switch/of14/action/11_COPY_TTL_OUT.json', 'os_ken/tests/packet_data/of12/3-14-ofp_echo_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_status.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_features_reply.packet', 'ryu/services/protocols/bgp/operator/commands/show/count.py', 'os_ken/tests/packet_data/of14/5-15-ofp_error_msg.packet', 'os_ken/tests/unit/packet/test_dhcp.py', 'os_ken/tests/unit/ofproto/json/of14/5-33-ofp_group_desc_request.packet.json', 'os_ken/services/protocols/bgp/api/prefix.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_desc_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/packet_data/of14/5-1-ofp_packet_out.packet', 'os_ken/tests/packet_data/of13/4-15-ofp_error_msg.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-45-ofp_meter_mod.packet.json', 'os_ken/tests/switch/of13/match/39_IPV6_EXTHDR_Mask.json', 'os_ken/tests/switch/of10/match/00_IN_PORT.json', 'os_ken/services/protocols/bgp/operator/views/other.py', 'os_ken/tests/unit/ofproto/json/of12/3-4-ofp_packet_in.packet.json', 'os_ken/tests/unit/packet/test_geneve.py', 'os_ken/tests/packet_data/bgp4/flowspec_action_redirect.pcap', 'ryu/ofproto/ofproto_v1_0.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/10_IP_PROTO_IPv6.json', 'os_ken/tests/switch/of14/action/16_DEC_MPLS_TTL.json', 'ryu/tests/unit/lib/test_ofctl_v1_3.py', 'ryu/cmd/ryu_base.py', 'os_ken/tests/integrated/test_of_config.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_stats_request.packet', 'os_ken/tests/packet_data/of13/4-40-ofp_flow_removed.packet', 'os_ken/lib/packet/afi.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_features_request.packet', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_01_1000.json', 'ryu/tests/integrated/bgp/base_ip6.py', 'os_ken/tests/switch/of13/match/17_SCTP_SRC_IPv4.json', 'ryu/app/ws_topology.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_output_trunc.packet.json', 'ryu/tests/unit/services/protocols/bgp/core_managers/test_table_manager.py', 'os_ken/lib/addrconv.py', 'os_ken/tests/unit/ofproto/json/of14/5-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/services/protocols/bgp/core_managers/test_table_manager.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_tc.packet', 'ryu/services/protocols/bgp/api/import_map.py', 'os_ken/tests/unit/ofproto/json/of13/4-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/switch/of13/match/27_IPV6_DST.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-error_msg.packet', 'os_ken/tests/unit/packet/test_openflow.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_features_request.packet.json', 'os_ken/tests/unit/packet/test_bgp.py', 'ryu/ofproto/ofproto_v1_0_parser.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/31_IPV6_ND_TARGET.json', 'os_ken/tests/switch/of13/group/01_SELECT_Ether.json', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-ofp_packet_out_packet_library.packet', 'os_ken/lib/ofctl_utils.py', 'os_ken/services/protocols/bgp/info_base/ipv6.py', 'os_ken/tests/switch/of14/match/39_IPV6_EXTHDR.json', 'ryu/services/protocols/bgp/core_managers/table_manager.py', 'os_ken/tests/packet_data/of12/3-32-ofp_group_features_stats_reply.packet', 'os_ken/tests/packet_data/of12/3-60-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of14/5-33-ofp_group_desc_request.packet', 'os_ken/tests/packet_data/of14/5-66-ofp_flow_monitor_request.packet', 'os_ken/tests/unit/sample/test_sample1.py', 'os_ken/tests/unit/ofproto/json/of14/5-43-ofp_meter_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_dec_mpls_ttl.packet.json', 'os_ken/services/protocols/bgp/operator/__init__.py', 'os_ken/tests/switch/of14/match/29_ICMPV6_TYPE.json', 'ryu/tests/unit/packet/test_sctp.py', 'os_ken/tests/unit/ofproto/json/of12/3-22-ofp_port_mod.packet.json', 'os_ken/tests/packet_data/of14/5-55-ofp_group_stats_request.packet', 'os_ken/lib/xflow/sflow.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_load_nx_register.packet', 'os_ken/tests/unit/test_requirements.py', 'os_ken/tests/unit/ofproto/json/of13/4-53-ofp_port_desc_request.packet.json', 'os_ken/app/gui_topology/html/index.html', 'ryu/controller/ofp_handler.py', 'os_ken/tests/packet_data/of12/3-11-ofp_flow_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_desc_reply.packet.json', 'os_ken/lib/of_config/ietf-inet-types.xsd', 'os_ken/tests/switch/of14/action/00_OUTPUT.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/03_ETH_DST.json', 'ryu/services/protocols/bgp/rtconf/neighbors.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-54-ofp_port_desc_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/15_UDP_SRC_IPv4.json', 'os_ken/tests/packet_data/of12/libofproto-OFP12-ofp_packet_out_packet_library.packet', 'ryu/services/protocols/vrrp/utils.py', 'os_ken/tests/unit/packet/test_ipv4.py', 'os_ken/tests/unit/ofproto/json/of13/4-40-ofp_flow_removed.packet.json', 'os_ken/tests/packet_data/of12/3-40-ofp_flow_removed.packet', 'os_ken/tests/switch/of13/match/24_ARP_SHA.json', 'ryu/services/protocols/bgp/info_base/base.py', 'os_ken/tests/switch/of14/match/41_PBB_UCA.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_async_reply.packet.json', 'ryu/tests/unit/sample/test_sample1.py', 'os_ken/tests/packet_data/of12/3-23-ofp_table_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-54-ofp_port_desc_reply.packet.json', 'os_ken/services/protocols/bgp/api/__init__.py', 'os_ken/tests/packet_data_generator2/Makefile.GNU', 'os_ken/tests/switch/of13/match/22_ARP_SPA_Mask.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-error_msg_experimenter.packet.json', 'os_ken/tests/packet_data/of14/5-19-ofp_role_request.packet', 'os_ken/ofproto/nicira_ext.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_stack_pop.packet.json', 'os_ken/tests/switch/of13/match/08_IP_DSCP_IPv4.json', 'os_ken/services/protocols/bgp/operator/commands/show/importmap.py', 'os_ken/tests/switch/of14/group/00_ALL.json', 'os_ken/tests/integrated/test_vrrp_multi.sh', 'ryu/ofproto/oxx_fields.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/11_IPV4_SRC.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod_match_conj.packet', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-echo_reply.packet.json', 'os_ken/tests/integrated/bgp/__init__.py', 'os_ken/services/protocols/zebra/client/__init__.py', 'ryu/app/simple_switch_13.py', 'os_ken/services/protocols/zebra/server/event.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/26_IPV6_SRC.json', 'os_ken/tests/unit/ofproto/json/of14/5-60-ofp_experimenter_reply.packet.json', 'ryu/services/protocols/vrrp/sample_router.py', 'os_ken/tests/packet_data_generator/src/x_flower_packet.erl', 'os_ken/ofproto/ofproto_v1_0_parser.py', 'ryu/tests/unit/lib/test_stringify.py', 'os_ken/tests/packet_data/bgp4/bgp4-update_vpnv6.pcap', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_01_1000.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_desc_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/integrated/run_tests_with_ovs12.py', 'os_ken/tests/packet_data/of13/4-55-ofp_table_features_request.packet', 'os_ken/controller/handler.py', 'os_ken/tests/unit/ofproto/json/of13/4-23-ofp_table_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-56-ofp_table_features_reply.packet.json', 'ryu/services/protocols/bgp/core.py', 'ryu/tests/unit/lib/test_pcaplib.py', 'ryu/services/protocols/bgp/operator/views/base.py', 'os_ken/tests/packet_data/mrt/updates.20161101.0000.bz2', 'ryu/tests/unit/lib/test_mod/ccc/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-21-ofp_group_mod.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_status.packet', 'os_ken/tests/switch/of13/action/26_PUSH_PBB.json', 'os_ken/tests/unit/services/protocols/bgp/__init__.py', 'os_ken/tests/packet_data/of14/5-21-ofp_group_mod.packet', 'os_ken/app/gui_topology/__init__.py', 'os_ken/services/protocols/zebra/db/interface.py', 'os_ken/tests/packet_data/of14/5-45-ofp_meter_config_request.packet', 'os_ken/tests/switch/of14/action/24_DEC_NW_TTL_IPv4.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/23_ARP_TPA.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of12/3-61-ofp_group_stats_request.packet', 'ryu/cmd/ofa_neutron_agent.py', 'ryu/services/protocols/bgp/info_base/vpn.py', 'os_ken/tests/packet_data/of13/4-38-ofp_queue_stats_reply.packet', 'ryu/services/protocols/vrrp/manager.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-32-ofp_group_features_reply.packet.json', 'os_ken/services/protocols/zebra/server/zserver.py', 'os_ken/lib/pcaplib.py', 'os_ken/tests/unit/services/protocols/bgp/utils/test_bgp.py', 'os_ken/lib/netconf/constants.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/18_SCTP_DST_IPv4.json', 'os_ken/tests/switch/of14/match/38_TUNNEL_ID_Mask.json', 'os_ken/topology/event.py', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_get_config_request.packet.json', 'ryu/tests/integrated/vrrp_common.py', 'ryu/services/protocols/bgp/bgpspeaker.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/25_ARP_THA.json', 'os_ken/services/protocols/bgp/operator/commands/show/count.py', 'ryu/ofproto/inet.py', 'os_ken/tests/unit/ofproto/json/of13/4-19-ofp_role_request.packet.json', 'os_ken/tests/packet_data/of14/5-29-ofp_port_stats_request.packet', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_01_10M.json', 'os_ken/app/ofctl/__init__.py', 'os_ken/tests/unit/app/ofctl_rest_json/of13.json', 'ryu/tests/unit/lib/test_mod/eee.py', 'os_ken/tests/packet_data/of14/5-60-ofp_experimenter_reply.packet', 'os_ken/tests/switch/of13/match/12_IPV4_DST.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/18_SCTP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of14/5-47-ofp_meter_stats_request.packet.json', 'ryu/services/protocols/ovsdb/manager.py', 'ryu/services/protocols/bgp/api/prefix.py', 'os_ken/tests/unit/ofproto/json/of14/5-64-ofp_queue_desc_reply.packet.json', 'os_ken/lib/igmplib.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_desc_request.packet.json', 'os_ken/services/protocols/zebra/__init__.py', 'os_ken/ofproto/ofproto_v1_4_parser.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_monitor_request.packet', 'os_ken/tests/packet_data/of14/5-46-ofp_meter_config_reply.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_nat_v6.packet', 'os_ken/tests/packet_data/of12/3-0-ofp_desc_stats_reply.packet', 'os_ken/tests/switch/of13/action/19_PUSH_MPLS.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/24_ARP_SHA.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_sample.packet', 'os_ken/tests/packet_data/of14/5-9-ofp_get_config_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/4-35-ofp_queue_get_config_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-30-ofp_port_stats_reply.packet.json', 'os_ken/app/rest_firewall.py', 'os_ken/services/protocols/bgp/operator/commands/responses.py', 'ryu/tests/run_tests.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_dec_mpls_ttl.packet', 'os_ken/tests/switch/of13/action/27_POP_PBB.json', 'os_ken/services/protocols/bgp/operator/views/fields.py', 'ryu/ofproto/nicira_ext.py', 'os_ken/tests/unit/ofproto/json/of14/5-0-ofp_desc_reply.packet.json', 'os_ken/lib/packet/bgp.py', 'os_ken/tests/packet_data/of14/5-48-ofp_meter_stats_reply.packet', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv6_UDP.json', 'ryu/tests/unit/packet/test_ethernet.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-error_msg.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-63-onf_flow_monitor_request.packet.json', 'os_ken/tests/switch/of13/match/02_METADATA.json', 'os_ken/tests/switch/of14/match/23_ARP_TPA.json', 'ryu/tests/unit/services/protocols/bgp/test_bgpspeaker.py', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-ofp_table_features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_desc_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_desc_request.packet.json', 'os_ken/tests/unit/packet/test_icmpv6.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-desc_request.packet.json', 'os_ken/services/protocols/vrrp/monitor_linux.py', 'os_ken/tests/unit/ofproto/json/of10/libofproto-OFP10-ofp_packet_out_packet_library.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/19_ICMPV4_TYPE.json', 'os_ken/tests/switch/of10/action/00_OUTPUT.json', 'os_ken/tests/unit/ofproto/json/of12/3-26-ofp_aggregate_stats_reply.packet.json', 'ryu/cmd/rpc_cli.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_l2vpn.pcap', 'os_ken/tests/packet_data/of13/4-22-ofp_port_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_removed.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_stats_reply.packet', 'ryu/tests/unit/lib/test_mod/__init__.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_l2_bridge.pcap', 'ryu/tests/unit/services/protocols/bgp/test_peer.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/22_ARP_SPA.json', 'os_ken/tests/unit/app/test_wsgi.py', 'ryu/ofproto/__init__.py', 'os_ken/lib/ovs/vswitch_idl.py', 'os_ken/services/protocols/zebra/db/route.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-54-ofp_table_features_reply.packet.json', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv4_TCP.json', 'os_ken/tests/packet_data/of12/3-22-ofp_port_mod.packet', 'os_ken/app/conf_switch_key.py', 'os_ken/tests/packet_data/of14/5-22-ofp_port_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-43-ofp_get_async_reply.packet.json', 'ryu/app/simple_switch_stp.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_status.packet', 'os_ken/tests/switch/of14/match/16_UDP_DST_IPv6.json', 'ryu/controller/handler.py', 'ryu/tests/unit/ofproto/test_parser_v13.py', 'os_ken/tests/unit/ofproto/test_ofproto_common.py', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/packet/test_lldp.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_stats_request.packet.json', 'ryu/tests/unit/packet/test_igmp.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_pkt_mark_masked.packet.json', 'os_ken/tests/switch/of14/match/02_METADATA_Mask.json', 'ryu/services/protocols/vrrp/monitor.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-22-ofp_port_mod.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_stack_pop.packet', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_marking.pcap', 'os_ken/tests/packet_data/of14/5-2-ofp_flow_mod.packet', 'os_ken/app/simple_switch_rest_13.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_ttl.packet', 'os_ken/tests/switch/of13/match/15_UDP_SRC_IPv4.json', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_ipv6.pcap', 'os_ken/tests/packet_data/pcap/zebra_v2.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-54-ofp_table_features_reply.packet.json', 'ryu/tests/unit/services/protocols/bgp/utils/test_validation.py', 'os_ken/tests/unit/ofproto/json/of14/5-19-ofp_role_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-echo_request.packet.json', 'os_ken/tests/packet_data/of13/4-33-ofp_group_desc_request.packet', 'os_ken/log.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-ofp_packet_out_packet_library.packet.json', 'os_ken/tests/switch/of14/action/26_PUSH_PBB.json', 'os_ken/tests/unit/ofproto/json/of13/4-62-ofp_experimenter_reply.packet.json', 'os_ken/tests/switch/of13/action/16_DEC_MPLS_TTL.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_async_request.packet.json', 'os_ken/tests/unit/ofproto/__init__.py', 'os_ken/tests/unit/ofproto/json/of14/5-13-ofp_echo_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-61-ofp_experimenter_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter_reply.packet.json', 'os_ken/lib/__init__.py', 'os_ken/tests/switch/of14/action/15_SET_MPLS_TTL.json', 'ryu/tests/unit/ofproto/test_parser_compat.py', 'os_ken/tests/packet_data/of14/5-10-ofp_hello.packet', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv6_TCP.json', 'os_ken/flags.py', 'os_ken/lib/sockaddr.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/34_MPLS_LABEL.json', 'os_ken/tests/switch/of14/match/10_IP_PROTO_IPv4.json', 'os_ken/ofproto/ofproto_v1_4.py', 'ryu/tests/unit/app/test_tester.py', 'os_ken/tests/unit/ofproto/json/of13/4-15-ofp_error_msg.packet.json', 'os_ken/tests/switch/of14/match/17_SCTP_SRC_IPv4.json', 'os_ken/lib/packet/ipv4.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/14_TCP_DST_IPv6.json', 'os_ken/tests/switch/of13/match/28_IPV6_FLABEL.json', 'os_ken/tests/unit/ofproto/json/of14/5-39-ofp_error_msg_experimenter.packet.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_reply.mn', 'os_ken/tests/unit/ofproto/json/of14/5-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_status.packet.json', 'os_ken/tests/packet_data/of13/4-5-ofp_features_request.packet', 'os_ken/tests/switch/of14/match/22_ARP_SPA.json', 'os_ken/tests/integrated/__init__.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_02_10000.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/09_IP_ECN_IPv6.json', 'ryu/tests/unit/packet/test_cfm.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-hello.packet', 'os_ken/tests/switch/of13/action/11_COPY_TTL_OUT.json', 'os_ken/tests/unit/ofproto/json/of14/5-8-ofp_get_config_request.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_label.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-63-ofp_queue_desc_request.packet.json', 'ryu/services/protocols/bgp/operator/internal_api.py', 'os_ken/ofproto/ofproto_v1_2_parser.py', 'os_ken/tests/switch/of13/group/00_ALL.json', 'os_ken/cmd/manager.py', 'os_ken/services/protocols/bgp/utils/validation.py', 'ryu/services/protocols/bgp/peer.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_desc_request.packet.json', 'os_ken/tests/packet_data/of12/3-41-ofp_error_msg_experimenter.packet', 'os_ken/tests/packet_data/of12/3-38-ofp_queue_stats_reply.packet', 'os_ken/services/protocols/bgp/info_base/vpnv4fs.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-aggregate_stats_request.packet.json'], 'web_link': 'https://opendev.org/openstack/os-ken/commit/9f1f1726d0b86a43df61bc22f6a8dec0f5c5b918', 'message': ""Move files from ryu/* to os_ken/*\n\nAfter forking from Ryu, the namespace needs to change from 'ryu'\nto 'os_ken' so that it won't collide with the namespace of the\nold library.\n\nChange-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4\n""}]",2,599463,9f1f1726d0b86a43df61bc22f6a8dec0f5c5b918,29,9,5,27654,,,0,"Move files from ryu/* to os_ken/*

After forking from Ryu, the namespace needs to change from 'ryu'
to 'os_ken' so that it won't collide with the namespace of the
old library.

Change-Id: I807a8785e525cc02825d15a1a01eec3d5d20cce4
",git fetch https://review.opendev.org/openstack/os-ken refs/changes/63/599463/5 && git format-patch -1 --stdout FETCH_HEAD,"['os_ken/tests/packet_data/of15/libofproto-OFP15-packet_out.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_stats_reply.packet.json', 'os_ken/services/protocols/bgp/operator/views/__init__.py', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv4_UDP.json', 'os_ken/tests/switch/of10/match/06_NW_TOS_IPv4.json', 'ryu/tests/unit/lib/__init__.py', 'os_ken/tests/packet_data/of14/5-54-ofp_table_features_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/18_SCTP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/packet/test_slow.py', 'ryu/lib/packet/openflow.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/16_UDP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-47-ofp_meter_config_request.packet.json', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv4_UDP.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-aggregate_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-17-ofp_barrier_request.packet.json', 'ryu/lib/of_config/__init__.py', 'os_ken/services/protocols/bgp/info_base/vpn.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_stats_reply.packet', 'os_ken/tests/switch/of14/match/28_IPV6_FLABEL_Mask.json', 'ryu/tests/mininet/l2/vlan/test_vlan.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-aggregate_stats_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_meter_config_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/17_SCTP_SRC_IPv6.json', 'ryu/services/protocols/vrrp/event.py', 'os_ken/tests/unit/ofproto/json/of12/3-9-ofp_get_config_reply.packet.json', 'os_ken/tests/unit/packet/test_igmp.py', 'os_ken/tests/unit/ofproto/json/of12/3-37-ofp_queue_stats_request.packet.json', 'os_ken/tests/switch/of13/match/08_IP_DSCP_IPv6.json', 'ryu/lib/netconf/constants.py', 'os_ken/tests/unit/ofproto/json/of12/3-18-ofp_barrier_reply.packet.json', 'os_ken/tests/unit/packet/test_cfm.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_desc_request.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-62-ofp_group_stats_reply.packet.json', 'os_ken/tests/packet_data/bgp4/bgp4-update.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-4-ofp_packet_in.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-50-ofp_meter_stats_reply.packet.json', 'ryu/tests/unit/lib/test_ofp_pktinfilter.py', 'os_ken/tests/mininet/l2/vlan/PopVLAN_vlan.mn', 'os_ken/tests/switch/of14/action/25_SET_FIELD/21_ARP_OP.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/33_IPV6_ND_TLL.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-set_async.packet.json', 'ryu/tests/unit/packet/test_llc.py', 'os_ken/tests/integrated/common/quagga.py', 'os_ken/tests/packet_data/of14/5-42-ofp_set_async.packet', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/packet_data/pcap/openflow_flowmod.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-70-ofp_bundle_add_msg.packet.json', 'os_ken/ofproto/ofproto_protocol.py', 'os_ken/tests/unit/ofproto/json/of14/5-23-ofp_table_mod.packet.json', 'os_ken/app/gui_topology/gui_topology.py', 'os_ken/tests/packet_data_generator/Makefile', 'ryu/lib/ofctl_v1_3.py', 'os_ken/tests/switch/of13/match/00_IN_PORT.json', 'os_ken/services/__init__.py', 'os_ken/tests/switch/of14/action/24_DEC_NW_TTL_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_desc_request.packet.json', 'ryu/ofproto/nx_actions.py', 'os_ken/tests/unit/ofproto/json/of12/3-38-ofp_queue_stats_reply.packet.json', 'ryu/services/protocols/bgp/info_base/ipv6.py', 'ryu/services/protocols/bgp/rtconf/base.py', 'ryu/services/protocols/bgp/info_base/rtc.py', 'os_ken/tests/switch/of13/match/11_IPV4_SRC_Mask.json', 'ryu/tests/unit/packet/test_geneve.py', 'os_ken/tests/unit/ofproto/json/of12/3-13-ofp_echo_request.packet.json', 'ryu/utils.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/12_IPV4_DST.json', 'ryu/tests/unit/lib/test_mod/ddd/mod.py', 'os_ken/tests/packet_data/of13/4-50-ofp_meter_stats_reply.packet', 'os_ken/tests/switch/of13/match/12_IPV4_DST_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/packet_data/of12/3-27-ofp_table_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-0-ofp_desc_stats_reply.packet.json', 'os_ken/controller/__init__.py', 'os_ken/utils.py', 'os_ken/tests/packet_data_generator2/README', 'os_ken/app/simple_switch_igmp_13.py', 'ryu/lib/ovs/db_client.py', 'os_ken/tests/packet_data/of14/5-64-ofp_queue_desc_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-35-ofp_queue_stats_request.packet.json', 'os_ken/services/protocols/bgp/operator/views/conf.py', 'ryu/log.py', 'os_ken/tests/packet_data/pcap/geneve_unknown.pcap', 'ryu/hooks.py', 'os_ken/tests/unit/ofproto/json/of13/4-17-ofp_barrier_request.packet.json', 'os_ken/tests/packet_data/of14/5-58-ofp_flow_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-hello.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of12/3-29-ofp_port_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of13/4-42-ofp_get_async_request.packet.json', 'os_ken/tests/packet_data/of14/5-5-ofp_features_request.packet', 'ryu/lib/of_config/capable_switch.py', 'os_ken/cmd/__init__.py', 'os_ken/tests/packet_data/of12/3-39-ofp_port_status.packet', 'os_ken/tests/switch/of14/match/02_METADATA.json', 'ryu/services/protocols/bgp/signals/__init__.py', 'os_ken/tests/packet_data/of14/5-37-ofp_port_status.packet', 'ryu/lib/packet/in_proto.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-21-ofp_group_mod.packet.json', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_action.pcap', 'os_ken/services/protocols/bgp/processor.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_request.packet', 'ryu/app/wsgi.py', 'os_ken/tests/switch/of13/group/01_SELECT_Weight_Ether.json', 'os_ken/app/simple_switch_12.py', 'os_ken/tests/packet_data/of14/5-57-ofp_packet_in.packet', 'os_ken/services/protocols/vrrp/api.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_desc_reply.packet', 'os_ken/tests/switch/of13/match/37_PBB_ISID_Mask.json', 'os_ken/tests/switch/of14/action/23_SET_NW_TTL_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-30-ofp_port_stats_reply.packet.json', 'os_ken/tests/packet_data/of14/5-18-ofp_barrier_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter_request.packet', 'os_ken/tests/packet_data/of14/5-28-ofp_table_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_status.packet.json', 'ryu/services/protocols/zebra/client/event.py', 'os_ken/tests/packet_data/of12/3-26-ofp_aggregate_stats_reply.packet', 'os_ken/tests/unit/cmd/dummy_openflow_app.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/15_UDP_SRC_IPv4.json', 'ryu/lib/packet/udp.py', 'ryu/lib/__init__.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/31_IPV6_ND_TARGET.json', 'os_ken/tests/unit/ofproto/json/of12/3-39-ofp_port_status.packet.json', 'ryu/lib/packet/arp.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/37_PBB_ISID.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data_generator2/gen.c', 'ryu/controller/ofp_event.py', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv4_UDP.json', 'os_ken/tests/unit/packet/test_llc.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_stats_request.packet', 'os_ken/tests/switch/of13/match/11_IPV4_SRC.json', 'os_ken/ofproto/ether.py', 'os_ken/tests/switch/of14/action/23_SET_NW_TTL_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-30-ofp_port_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/4-49-ofp_meter_stats_request.packet', 'ryu/tests/unit/packet/test_bpdu.py', 'ryu/tests/unit/packet/test_bgp.py', 'ryu/services/protocols/bgp/info_base/l2vpnfs.py', 'ryu/tests/integrated/bgp/test_basic.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_as_based.pcap', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_ctrl.packet.json', 'os_ken/tests/switch/of14/match/28_IPV6_FLABEL.json', 'ryu/lib/port_no.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_fintimeout.packet.json', 'os_ken/tests/packet_data/of12/3-20-ofp_role_reply.packet', 'ryu/tests/unit/sample/test_sample2.py', 'ryu/tests/unit/lib/test_ofctl_string.py', 'os_ken/services/protocols/bgp/operator/views/bgp.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod_match_conj.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/28_IPV6_FLABEL.json', 'ryu/lib/packet/bmp.py', 'os_ken/tests/unit/ofproto/json/of13/4-6-ofp_features_reply.packet.json', 'ryu/controller/dpset.py', 'ryu/lib/lacplib.py', 'os_ken/tests/unit/ofproto/json/of13/4-27-ofp_table_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv6fs.py', 'os_ken/tests/unit/ofproto/json/of13/4-12-ofp_flow_stats_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_stats_reply.packet.json', 'os_ken/tests/mininet/l2/mpls/PushMPLS_mpls.mn', 'os_ken/tests/unit/ofproto/json/of10/1-5-features_request.packet.json', 'os_ken/tests/packet_data/of13/4-31-ofp_group_features_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_mod.packet', 'ryu/lib/packet/icmp.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-port_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_meter_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-29-ofp_port_stats_request.packet.json', 'ryu/tests/unit/packet/test_vrrp.py', 'os_ken/tests/unit/ofproto/json/of13/4-41-ofp_error_msg_experimenter.packet.json', 'ryu/lib/packet/ipv6.py', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv6_TCP.json', 'os_ken/base/app_manager.py', 'os_ken/tests/unit/ofproto/test_parser_v10.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_removed.packet.json', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_00_1M.json', 'os_ken/tests/switch/of13/match/30_ICMPV6_CODE.json', 'os_ken/tests/unit/ofproto/json/of12/3-1-ofp_packet_out.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-error_msg.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_dec_nw_ttl.packet.json', 'ryu/lib/packet/ethernet.py', 'os_ken/tests/unit/ofproto/json/of13/4-46-ofp_flow_mod.packet.json', 'ryu/lib/ofp_pktinfilter.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_arbitrary.pcap', 'os_ken/tests/unit/ofproto/json/of13/4-8-ofp_get_config_request.packet.json', 'os_ken/tests/switch/of13/match/07_VLAN_PCP.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_pkt_mark.packet', 'os_ken/tests/unit/ofproto/json/of13/4-2-ofp_flow_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of10/1-2-ofp_flow_mod.packet.json', 'os_ken/services/protocols/bgp/rtconf/neighbors.py', 'os_ken/services/protocols/bgp/api/jsonrpc.py', 'os_ken/tests/switch/of13/match/35_MPLS_TC.json', 'os_ken/tests/switch/of14/action/17_PUSH_VLAN_multiple.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/switch/of14/match/22_ARP_SPA_Mask.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-24-ofp_desc_stats_request.packet.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_gratuitous.mn', 'os_ken/tests/packet_data/pcap/little_endian.pcap', 'os_ken/tests/switch/of13/action/18_POP_VLAN.json', 'os_ken/tests/packet_data_generator/src/x.erl', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-12-ofp_flow_stats_reply.packet.json', 'os_ken/ofproto/oxx_fields.py', 'os_ken/tests/unit/ofproto/json/of12/3-2-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-66-ofp_flow_monitor_request.packet.json', 'ryu/lib/snortlib.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-0-ofp_desc_reply.packet.json', 'os_ken/tests/switch/of14/match/14_TCP_DST_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-45-ofp_meter_mod.packet.json', 'os_ken/tests/unit/packet/test_bfd.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-echo_request.packet', 'ryu/services/protocols/bgp/speaker.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/28_IPV6_FLABEL.json', 'os_ken/tests/switch/of13/match/21_ARP_OP.json', 'os_ken/services/protocols/ovsdb/client.py', 'os_ken/tests/unit/ofproto/json/of13/4-9-ofp_get_config_reply.packet.json', 'os_ken/tests/switch/of14/action/27_POP_PBB.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_desc_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-error_msg_experimenter.packet', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_02_100M.json', 'os_ken/tests/unit/ofproto/test_parser.py', 'ryu/cfg.py', 'os_ken/tests/unit/ofproto/json/of13/4-31-ofp_group_features_request.packet.json', 'os_ken/tests/packet_data/of12/3-13-ofp_echo_request.packet', 'os_ken/app/rest_conf_switch.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-32-ofp_group_features_reply.packet.json', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_01_1000.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/04_ETH_SRC.json', 'os_ken/tests/unit/packet/test_gre.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_desc_request.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/17_SCTP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_note.packet.json', 'ryu/lib/packet/safi.py', 'os_ken/tests/packet_data/of14/5-34-ofp_group_desc_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/04_ETH_SRC.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_dec_ttl_cnt_ids.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_conj.packet.json', 'os_ken/tests/switch/of14/group/01_SELECT_IP.json', 'os_ken/tests/unit/ofproto/json/of13/4-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-packet_in.packet.json', 'ryu/tests/integrated/test_add_flow_v10.py', 'os_ken/app/ws_topology.py', 'os_ken/tests/unit/ofproto/json/of12/3-41-ofp_error_msg_experimenter.packet.json', 'os_ken/tests/unit/ofproto/test_oxm.py', 'os_ken/tests/unit/ofproto/json/of12/3-33-ofp_group_desc_stats_request.packet.json', 'os_ken/services/protocols/bgp/rtconf/vrfs.py', 'os_ken/tests/packet_data/pcap/zebra_v3.pcap', 'os_ken/tests/switch/of13/action/19_PUSH_MPLS_multiple.json', 'ryu/lib/stplib.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_features_request.packet', 'os_ken/services/protocols/bgp/constants.py', 'os_ken/tests/unit/app/test_ws_topology.py', 'os_ken/ofproto/ofproto_v1_3.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_ttl.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_stack_push.packet.json', 'os_ken/tests/switch/of13/action/15_SET_MPLS_TTL.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/36_MPLS_BOS.json', 'ryu/tests/integrated/bgp/base.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_removed.packet', 'os_ken/tests/unit/ofproto/json/of13/4-50-ofp_meter_stats_reply.packet.json', 'ryu/lib/of_config/base.py', 'os_ken/controller/mac_to_port.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_desc_reply.packet', 'ryu/app/simple_monitor_13.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of13/match/06_VLAN_VID_Mask.json', 'ryu/services/protocols/bgp/operator/commands/show/vrf.py', 'os_ken/tests/switch/of14/match/27_IPV6_DST_Mask.json', 'ryu/lib/packet/vxlan.py', 'os_ken/tests/switch/of14/match/23_ARP_TPA_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/4-57-ofp_group_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/rtc.py', 'os_ken/services/protocols/ovsdb/manager.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-52-ofp_meter_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-42-ofp_get_async_request.packet', 'os_ken/tests/switch/__init__.py', 'os_ken/tests/switch/of13/match/10_IP_PROTO_IPv4.json', 'ryu/tests/unit/ofproto/test_parser_v10.py', 'ryu/app/simple_switch_14.py', 'os_ken/tests/switch/of14/match/06_VLAN_VID.json', 'os_ken/tests/unit/sample/__init__.py', 'os_ken/tests/switch/of13/action/00_OUTPUT.json', 'os_ken/tests/unit/ofproto/json/of14/5-51-ofp_port_desc_request.packet.json', 'ryu/tests/unit/lib/test_import_module.py', 'os_ken/tests/switch/of13/match/03_ETH_DST.json', 'os_ken/tests/switch/of14/match/31_IPV6_ND_TARGET.json', 'os_ken/tests/packet_data/of14/5-35-ofp_queue_stats_request.packet', 'os_ken/tests/switch/of10/match/08_NW_SRC.json', 'os_ken/tests/switch/of14/match/07_VLAN_PCP.json', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_ipv4.pcap', 'os_ken/tests/packet_data/of14/5-59-ofp_experimenter_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-3-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_01_10M.json', 'os_ken/ofproto/ofproto_common.py', 'ryu/services/protocols/bgp/rtconf/vrfs.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_push_mpls.packet', 'os_ken/tests/integrated/test_vrrp_linux_multi.py', 'ryu/tests/unit/cmd/test_manager.py', 'os_ken/tests/switch/of10/match/04_DL_VLAN_PCP.json', 'os_ken/tests/switch/of14/match/14_TCP_DST_IPv6.json', 'os_ken/services/protocols/vrrp/utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-30-ofp_port_stats_reply.packet.json', 'ryu/lib/packet/ospf.py', 'ryu/ofproto/oxm_fields.py', 'os_ken/tests/integrated/test_add_flow_v10.py', 'os_ken/tests/packet_data/of12/3-31-ofp_group_features_stats_request.packet', 'os_ken/tests/unit/packet/test_vxlan.py', 'os_ken/tests/packet_data/of14/5-25-ofp_aggregate_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet3.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-38-ofp_queue_stats_reply.packet.json', 'os_ken/services/protocols/bgp/peer.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-meter_mod.packet', 'os_ken/tests/packet_data/of12/3-10-ofp_hello.packet', 'os_ken/tests/packet_data/mrt/rib.20161101.0000_pick.bz2', 'ryu/tests/unit/packet/test_vlan.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter_request.packet.json', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_00_100.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/16_UDP_DST_IPv6.json', 'os_ken/tests/switch/of14/match/35_MPLS_TC.json', 'os_ken/tests/switch/of13/match/34_MPLS_LABEL.json', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_00_100.json', 'os_ken/tests/unit/ofproto/json/of12/3-62-ofp_group_stats_reply.packet.json', 'ryu/services/protocols/bgp/api/rtconf.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-hello.packet.json', 'ryu/tests/unit/lib/test_ofctl_utils.py', 'os_ken/app/ofctl/api.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/14_TCP_DST_IPv6.json', 'os_ken/tests/packet_data/of14/libofproto-OFP14-ofp_packet_out_packet_library.packet', 'os_ken/tests/switch/of13/match/09_IP_ECN_IPv4.json', 'ryu/tests/unit/ofproto/test_oxs.py', 'os_ken/tests/switch/of14/match/04_ETH_SRC_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/26_IPV6_SRC.json', 'ryu/services/protocols/ovsdb/client.py', 'os_ken/tests/packet_data/of13/4-25-ofp_aggregate_stats_request.packet', 'ryu/lib/packet/lldp.py', 'os_ken/tests/unit/ofproto/json/of14/5-69-ofp_bundle_ctrl_msg.packet.json', 'os_ken/tests/unit/services/protocols/bgp/core_managers/__init__.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/16_UDP_DST_IPv4.json', 'os_ken/tests/switch/of14/match/33_IPV6_ND_TLL.json', 'os_ken/tests/unit/ofproto/json/of10/1-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/32_IPV6_ND_SLL.json', 'ryu/lib/of_config/of-config-1.1.xsd', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_01_1000.json', 'os_ken/tests/unit/ofproto/json/of14/5-45-ofp_meter_config_request.packet.json', 'ryu/tests/unit/ofproto/test_parser_ofpmatch.py', 'os_ken/tests/switch/of14/match/16_UDP_DST_IPv4.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status_request.packet', 'ryu/tests/mininet/l2/mpls/test_mpls.py', 'ryu/tests/unit/packet/test_vxlan.py', 'os_ken/tests/unit/ofproto/json/of14/5-52-ofp_port_desc_reply.packet.json', 'ryu/lib/packet/tcp.py', 'ryu/lib/packet/vlan.py', 'os_ken/services/protocols/bgp/info_base/evpn.py', 'ryu/tests/unit/test_utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-12-ofp_flow_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-50-ofp_meter_features_reply.packet.json', 'ryu/tests/integrated/test_add_flow_v12_actions.py', 'os_ken/tests/unit/ofproto/json/of14/5-57-ofp_packet_in.packet.json', 'os_ken/tests/packet_data/of13/4-57-ofp_group_stats_request.packet', 'os_ken/tests/packet_data/of12/3-62-ofp_group_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_desc_reply.packet.json', 'os_ken/services/protocols/vrrp/event.py', 'os_ken/services/protocols/bgp/info_base/vrf4fs.py', 'os_ken/services/protocols/bgp/core_managers/import_map_manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod.packet.json', 'ryu/services/protocols/bgp/info_base/vrf4.py', 'os_ken/tests/packet_data/pcap/big_endian.pcap', 'os_ken/tests/unit/ofproto/test_parser_ofpstats.py', 'os_ken/cmd/rpc_cli.py', 'ryu/services/protocols/bgp/core_managers/import_map_manager.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-50-ofp_meter_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-set_config.packet.json', 'ryu/services/protocols/bgp/core_manager.py', 'ryu/services/protocols/bgp/api/operator.py', 'os_ken/tests/integrated/test_vrrp_linux_multi.sh', 'os_ken/tests/unit/ofproto/json/of13/4-16-ofp_experimenter.packet.json', 'ryu/ofproto/ofproto_v1_5.py', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_01_10M.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-51-ofp_port_desc_request.packet', 'os_ken/tests/packet_data/pcap/gre_nvgre_option.pcap', 'os_ken/tests/switch/of13/match/26_IPV6_SRC_Mask.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_request.mn', 'ryu/services/protocols/zebra/db/route.py', 'os_ken/tests/packet_data/of13/4-34-ofp_group_desc_reply.packet', 'os_ken/app/cbench.py', 'ryu/app/example_switch_13.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/14_TCP_DST_IPv4.json', 'os_ken/tests/packet_data/of14/5-40-ofp_get_async_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-17-ofp_barrier_request.packet.json', 'ryu/tests/mininet/l3/icmp/test_icmp.py', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/tests/switch/of13/match/22_ARP_SPA.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_nat_v6.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_inc_multi_eth_tag.pcap', 'os_ken/tests/unit/packet/test_lldp.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_controller.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_ctrl.packet', 'os_ken/tests/switch/of14/match/19_ICMPV4_TYPE.json', 'ryu/services/protocols/bgp/utils/validation.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_features_request.packet', 'os_ken/tests/unit/controller/test_controller.py', 'os_ken/tests/integrated/common/install_docker_test_pkg_for_travis.sh', 'ryu/controller/tunnels.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/32_IPV6_ND_SLL.json', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_dec_nw_ttl.packet', 'os_ken/tests/packet_data/pcap/openflow_flowstats_req.pcap', 'os_ken/tests/switch/of14/action/20_POP_MPLS.json', 'os_ken/services/protocols/bgp/__init__.py', 'ryu/lib/ovs/vsctl.py', 'os_ken/tests/run_tests.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-61-ofp_group_stats_request.packet.json', 'os_ken/tests/switch/of14/match/09_IP_ECN_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_clear.packet.json', 'ryu/services/protocols/vrrp/router.py', 'os_ken/tests/switch/of14/match/00_IN_PORT.json', 'ryu/tests/unit/packet/test_ipv6.py', 'os_ken/tests/switch/of13/match/20_ICMPV4_CODE.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_no_nx.packet.json', 'ryu/lib/packet/__init__.py', 'ryu/__init__.py', 'ryu/tests/unit/cmd/dummy_openflow_app.py', 'os_ken/tests/switch/of14/group/01_SELECT_Weight_IP.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/services/protocols/vrrp/__init__.py', 'os_ken/tests/packet_data/of14/5-20-ofp_role_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_exec.packet.json', 'ryu/app/simple_switch_igmp_13.py', 'os_ken/tests/switch/of14/action/17_PUSH_VLAN.json', 'os_ken/tests/packet_data_generator2/Makefile.BSD', 'os_ken/tests/packet_data/of13/libofproto-OFP13-echo_reply.packet', 'ryu/lib/ip.py', 'ryu/lib/packet/vrrp.py', 'ryu/lib/pcaplib.py', 'os_ken/tests/unit/ofproto/json/of12/3-8-ofp_get_config_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-packet_in.packet.json', 'os_ken/services/protocols/bgp/utils/bgp.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_features_request.packet', 'os_ken/tests/unit/ofproto/json/of13/4-10-ofp_hello.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-15-ofp_error_msg.packet.json', 'os_ken/tests/packet_data/of12/3-4-ofp_packet_in.packet', 'os_ken/services/protocols/bgp/info_base/vrf6.py', 'os_ken/tests/switch/of14/match/04_ETH_SRC.json', 'os_ken/tests/unit/ofproto/test_ofproto.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-meter_mod.packet.json', 'os_ken/tests/packet_data/of12/3-35-ofp_queue_get_config_request.packet', 'ryu/ofproto/ofproto_v1_5_parser.py', 'ryu/cmd/manager.py', 'os_ken/tests/switch/of13/match/15_UDP_SRC_IPv6.json', 'os_ken/tests/packet_data/of14/5-69-ofp_bundle_ctrl_msg.packet', 'os_ken/tests/unit/ofproto/json/of14/5-31-ofp_group_features_request.packet.json', 'os_ken/tests/packet_data/of14/5-39-ofp_error_msg_experimenter.packet', 'ryu/services/protocols/bgp/core_managers/peer_manager.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_sample2.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-59-ofp_packet_in.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_mod.packet.json', 'os_ken/tests/packet_data/of13/4-14-ofp_echo_reply.packet', 'os_ken/services/protocols/ovsdb/api.py', 'os_ken/ofproto/oxs_fields.py', 'os_ken/services/protocols/bgp/info_base/vrf.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_vpn6.pcap', 'os_ken/services/protocols/bgp/api/rpc_log_handler.py', 'os_ken/tests/packet_data/of12/3-3-ofp_flow_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/lib/test_rpc.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/21_ARP_OP.json', 'os_ken/tests/switch/of14/match/38_TUNNEL_ID.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/05_ETH_TYPE.json', 'os_ken/tests/packet_data/of12/3-18-ofp_barrier_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-40-ofp_get_async_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_config_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_match_conj.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_desc_request.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-65-ofp_role_status.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_stats_reply.packet.json', 'ryu/ofproto/ofproto_v1_2.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/unit/__init__.py', 'os_ken/tests/unit/packet/test_ospf.py', 'os_ken/tests/switch/of14/match/15_UDP_SRC_IPv4.json', 'os_ken/services/protocols/bgp/utils/__init__.py', 'os_ken/tests/unit/packet/test_ipv6.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/06_VLAN_VID.json', 'ryu/lib/ofctl_v1_2.py', 'os_ken/tests/unit/ofproto/json/of13/4-32-ofp_group_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_stats_reply.packet.json', 'os_ken/tests/mininet/l3/icmp/test_icmp.py', 'ryu/tests/unit/packet/test_udp.py', 'os_ken/tests/switch/of14/match/37_PBB_ISID_Mask.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/35_MPLS_TC.json', 'os_ken/services/protocols/bgp/base.py', 'os_ken/tests/unit/ofproto/json/of12/3-6-ofp_features_reply.packet.json', 'ryu/tests/unit/lib/test_ofctl_action_match.py', 'ryu/services/protocols/bgp/processor.py', 'os_ken/app/gui_topology/html/router.svg', 'os_ken/tests/packet_data/of12/3-1-ofp_packet_out.packet', 'os_ken/tests/unit/ofproto/json/of13/4-52-ofp_meter_features_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-aggregate_stats_request.packet', 'ryu/services/protocols/bgp/info_base/vrf6fs.py', 'os_ken/tests/unit/ofproto/json/of14/5-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of12/3-6-ofp_features_reply.packet', 'ryu/tests/unit/cmd/dummy_app.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-22-ofp_port_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-0-ofp_desc_reply.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_eth_seg.pcap', 'os_ken/tests/packet_data/of15/libofproto-OFP15-echo_reply.packet', 'ryu/tests/unit/lib/test_addrconv.py', 'os_ken/tests/switch/of10/action/03_STRIP_VLAN.json', 'ryu/app/simple_switch_websocket_13.py', 'os_ken/app/simple_switch_lacp_13.py', 'os_ken/ofproto/ofproto_v1_3_parser.py', 'os_ken/tests/unit/packet/test_tcp.py', 'os_ken/tests/switch/of13/action/26_PUSH_PBB_multiple.json', 'os_ken/tests/switch/of13/match/04_ETH_SRC.json', 'ryu/lib/of_config/ietf-yang-types.xsd', 'ryu/services/protocols/bgp/operator/commands/show/importmap.py', 'os_ken/tests/packet_data/of13/4-0-ofp_desc_reply.packet', 'os_ken/tests/packet_data/of14/5-38-ofp_flow_removed.packet', 'os_ken/tests/packet_data_generator/src/x3.erl', 'os_ken/tests/unit/packet/test_pbb.py', 'os_ken/tests/packet_data/of14/5-23-ofp_table_mod.packet', 'os_ken/cmd/ofa_neutron_agent.py', 'os_ken/tests/packet_data/of13/4-24-ofp_desc_request.packet', 'ryu/tests/integrated/test_add_flow_v12_matches.py', 'os_ken/tests/unit/app/__init__.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-39-ofp_port_status.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_conj.packet', 'os_ken/exception.py', 'os_ken/tests/unit/ofproto/json/of12/3-32-ofp_group_features_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/4-13-ofp_echo_request.packet', 'os_ken/tests/switch/of14/match/17_SCTP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-44-ofp_set_async.packet.json', 'os_ken/tests/packet_data/of13/4-52-ofp_meter_features_reply.packet', 'os_ken/tests/packet_data/of14/5-32-ofp_group_features_reply.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/16_UDP_DST_IPv4.json', 'ryu/services/protocols/zebra/event.py', 'os_ken/tests/switch/of14/match/18_SCTP_DST_IPv6.json', 'os_ken/services/protocols/ovsdb/event.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/10_IP_PROTO_IPv4.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-port_status.packet', 'os_ken/tests/packet_data/of13/4-23-ofp_table_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_mod.packet.json', 'os_ken/controller/ofp_handler.py', 'os_ken/services/protocols/vrrp/router.py', 'os_ken/tests/switch/of14/match/03_ETH_DST.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-port_status.packet.json', 'os_ken/tests/integrated/common/ryubgp.py', 'os_ken/tests/packet_data/of12/3-5-ofp_features_request.packet', 'os_ken/tests/switch/of14/match/09_IP_ECN_IPv4.json', 'os_ken/tests/packet_data/of14/5-14-ofp_echo_reply.packet', 'os_ken/tests/unit/ofproto/json/of10/1-6-ofp_switch_features.packet.json', 'os_ken/tests/switch/of13/match/10_IP_PROTO_IPv6.json', 'os_ken/tests/switch/tester.py', 'os_ken/tests/mininet/l2/mpls/PopMPLS_mpls.mn', 'os_ken/topology/api.py', 'os_ken/app/simple_switch.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_stats_request.packet', 'ryu/services/protocols/bgp/utils/bgp.py', 'os_ken/services/protocols/bgp/info_base/l2vpnfs.py', 'os_ken/tests/switch/of14/match/21_ARP_OP.json', 'os_ken/tests/packet_data/of14/5-70-ofp_bundle_add_msg.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_stats_reply.packet.json', 'os_ken/controller/mac_to_network.py', 'os_ken/services/protocols/bgp/bmp.py', 'os_ken/app/rest_router.py', 'os_ken/tests/packet_data/pcap/zebra_v4_frr_v2.pcap', 'os_ken/tests/unit/test_utils.py', 'os_ken/tests/unit/ofproto/json/of14/5-71-ofp_requestforward.packet.json', 'ryu/tests/unit/lib/test_mod/fff.py', 'ryu/lib/packet/icmpv6.py', 'ryu/tests/unit/ofproto/test_parser_ofpstats.py', 'os_ken/tests/unit/ofproto/json/of12/3-7-ofp_set_config.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_esi_mac_base.pcap', 'os_ken/tests/unit/app/test_ofctl_rest.py', 'ryu/tests/unit/lib/test_of_config_classes.py', 'os_ken/tests/packet_data/of13/4-56-ofp_table_features_reply.packet', 'os_ken/ofproto/inet.py', 'os_ken/tests/integrated/test_add_flow_v12_actions.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/tests/mininet/l2/vlan/PushVLAN_icmp.mn', 'os_ken/tests/switch/of14/action/19_PUSH_MPLS.json', 'ryu/services/protocols/bgp/operator/ssh.py', 'os_ken/services/protocols/bgp/api/operator.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/22_ARP_SPA.json', 'os_ken/app/simple_switch_stp.py', 'ryu/services/protocols/bgp/utils/evtlet.py', 'os_ken/tests/packet_data/of13/4-2-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of14/5-43-ofp_meter_mod.packet', 'ryu/services/protocols/bgp/operator/commands/root.py', 'os_ken/tests/switch/of14/match/39_IPV6_EXTHDR_Mask.json', 'ryu/tests/unit/ofproto/test_ofproto_parser.py', 'os_ken/tests/packet_data/of13/4-41-ofp_error_msg_experimenter.packet', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-table_mod.packet.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/services/protocols/bgp/utils/evtlet.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_stats_request.packet', 'ryu/tests/unit/services/protocols/bgp/utils/test_bgp.py', 'os_ken/tests/packet_data/of12/3-2-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod_match_conj.packet', 'os_ken/tests/unit/ofproto/json/of14/5-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv6_UDP.json', 'os_ken/tests/packet_data/of13/4-9-ofp_get_config_reply.packet', 'os_ken/services/protocols/bgp/rtconf/base.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_stats_request.packet.json', 'ryu/lib/stringify.py', 'os_ken/tests/unit/ofproto/json/of13/4-18-ofp_barrier_reply.packet.json', 'os_ken/tests/packet_data_generator/src/x_of_protocol.erl', 'ryu/ofproto/oxs_fields.py', 'os_ken/tests/packet_data/bgp4/bgp4-open.pcap', 'os_ken/tests/packet_data/of14/5-26-ofp_aggregate_stats_reply.packet', 'os_ken/services/protocols/bgp/core_managers/__init__.py', 'os_ken/tests/packet_data/of14/5-53-ofp_table_features_request.packet', 'os_ken/tests/packet_data/of13/4-6-ofp_features_reply.packet', 'ryu/lib/mrtlib.py', 'os_ken/tests/mininet/l2/mpls/PushMPLS_ip.mn', 'ryu/tests/unit/lib/ofctl_json/of14/5-46-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/03_ETH_DST.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-2-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/12_IPV4_DST.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-desc_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv4.py', 'os_ken/tests/switch/of13/match/19_ICMPV4_TYPE.json', 'os_ken/tests/unit/ofproto/json/of10/1-1-ofp_packet_out.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/neighbor.py', 'os_ken/tests/unit/ofproto/json/of12/3-23-ofp_table_mod.packet.json', 'os_ken/services/protocols/zebra/client/sample_dumper.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_get_config_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/27_IPV6_DST.json', 'os_ken/tests/unit/ofproto/json/of12/3-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/unit/controller/__init__.py', 'os_ken/tests/unit/ofproto/test_parser_compat.py', 'os_ken/tests/unit/services/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-22-ofp_port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-1-ofp_packet_out.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_controller2.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-get_config_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_monitor_reply.packet.json', 'os_ken/tests/switch/of14/match/24_ARP_SHA.json', 'os_ken/tests/unit/packet/test_vlan.py', 'os_ken/services/protocols/bgp/api/rtconf.py', 'ryu/app/simple_switch_snort.py', 'os_ken/tests/packet_data/of13/4-19-ofp_role_request.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/15_UDP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-29-ofp_port_stats_request.packet.json', 'os_ken/services/protocols/bgp/signals/__init__.py', 'ryu/base/app_manager.py', 'os_ken/tests/packet_data/of14/5-63-ofp_queue_desc_request.packet', 'ryu/ofproto/nx_match.py', 'ryu/services/protocols/bgp/rtconf/common.py', 'os_ken/tests/packet_data/of12/3-16-ofp_experimenter.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data_generator/src/x1.erl', 'ryu/tests/unit/packet/test_tcp.py', 'os_ken/tests/packet_data/of13/4-18-ofp_barrier_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-32-ofp_group_features_stats_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/vpnv4.py', 'os_ken/tests/packet_data/of13/4-21-ofp_group_mod.packet', 'os_ken/tests/unit/ofproto/json/of14/5-53-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of13/4-10-ofp_hello.packet', 'os_ken/services/protocols/bgp/core_managers/configuration_manager.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_meter_config_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod_conjunction.packet', 'os_ken/tests/unit/ofproto/json/of14/libofproto-OFP14-ofp_packet_out_packet_library.packet.json', 'ryu/tests/unit/__init__.py', 'os_ken/tests/switch/of14/match/12_IPV4_DST.json', 'os_ken/services/protocols/bgp/speaker.py', 'ryu/tests/unit/lib/ovs/__init__.py', 'os_ken/tests/unit/app/ofctl_rest_json/of15.json', 'os_ken/tests/packet_data/of14/5-11-ofp_flow_stats_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-24-ofp_desc_request.packet', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv4_TCP.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/08_IP_DSCP_IPv4.json', 'os_ken/app/simple_switch_15.py', 'os_ken/tests/unit/ofproto/json/of13/4-20-ofp_role_reply.packet.json', 'ryu/app/gui_topology/gui_topology.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-echo_request.packet', 'os_ken/tests/switch/of14/action/26_PUSH_PBB_multiple.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-set_async.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/15_UDP_SRC_IPv6.json', 'ryu/lib/packet/linux.py', 'os_ken/services/protocols/bgp/utils/circlist.py', 'ryu/services/protocols/bgp/info_base/ipv6fs.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_stats_request.packet.json', 'os_ken/tests/packet_data/of13/4-32-ofp_group_features_reply.packet', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod.truncated64', 'os_ken/tests/switch/of13/meter/01_DROP_01_PKTPS_02_10000.json', 'os_ken/controller/dpset.py', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_02_100M.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_ip_prefix.pcap', 'os_ken/tests/packet_data/bgp4/evpn_esi_router_id.pcap', 'os_ken/tests/packet_data/of13/4-17-ofp_barrier_request.packet', 'os_ken/tests/packet_data/of12/3-24-ofp_desc_stats_request.packet', 'ryu/tests/unit/lib/test_mod/bbb/__init__.py', 'os_ken/tests/integrated/bgp/base.py', 'os_ken/ofproto/nx_match.py', 'os_ken/tests/switch/of14/group/01_SELECT_Ether.json', 'os_ken/app/bmpstation.py', 'os_ken/tests/unit/packet/test_icmp.py', 'ryu/controller/conf_switch.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-table_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_sample.packet.json', 'os_ken/tests/switch/of14/match/26_IPV6_SRC_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-12-ofp_flow_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_desc_reply.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_controller2.packet', 'os_ken/tests/switch/of10/action/06_SET_NW_SRC.json', 'ryu/services/protocols/bgp/info_base/vrf4fs.py', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_get_config_request.packet.json', 'os_ken/tests/packet_data/of13/4-28-ofp_table_stats_reply.packet', 'os_ken/services/protocols/bgp/operator/views/base.py', 'os_ken/tests/switch/of13/action/24_DEC_NW_TTL_IPv4.json', 'os_ken/tests/unit/ofproto/json/of14/5-18-ofp_barrier_reply.packet.json', 'ryu/app/simple_switch_igmp.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_config_request.packet.json', 'ryu/lib/ofctl_nicira_ext.py', 'ryu/services/protocols/bgp/api/jsonrpc.py', 'ryu/services/protocols/vrrp/monitor_linux.py', 'os_ken/tests/test_lib.py', 'ryu/services/protocols/vrrp/api.py', 'os_ken/tests/packet_data/of14/5-27-ofp_table_stats_request.packet', 'os_ken/tests/integrated/common/install_docker_test_pkg_common.sh', 'os_ken/tests/packet_data/of10/libofproto-OFP10-ofp_packet_out_packet_library.packet', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_desc_request.packet.json', 'ryu/tests/__init__.py', 'ryu/lib/pack_utils.py', 'os_ken/tests/packet_data_generator/rebar.config', 'os_ken/tests/unit/ofproto/json/of13/4-7-ofp_set_config.packet.json', 'os_ken/tests/switch/of10/action/05_SET_DL_DST.json', 'os_ken/tests/switch/of13/match/25_ARP_THA_Mask.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-12-ofp_flow_stats_reply.packet.json', 'ryu/lib/xflow/sflow.py', 'os_ken/tests/unit/ofproto/json/of14/5-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/unit/sample/test_sample2.py', 'os_ken/tests/switch/of10/match/06_NW_TOS_IPv6.json', 'os_ken/tests/unit/ofproto/json/of10/1-4-ofp_packet_in.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-24-ofp_desc_request.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_eth_a-d.pcap', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_monitor_request.packet.json', 'ryu/controller/mac_to_network.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/23_ARP_TPA.json', 'os_ken/tests/unit/ofproto/json/of13/4-39-ofp_port_status.packet.json', 'ryu/services/protocols/vrrp/dumper.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/25_ARP_THA.json', 'ryu/lib/rpc.py', 'os_ken/tests/packet_data/of14/5-31-ofp_group_features_request.packet', 'os_ken/ofproto/ofproto_v1_2.py', 'os_ken/tests/packet_data/of13/4-51-ofp_meter_features_request.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-table_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_features_reply.packet', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv6_TCP.json', 'os_ken/tests/unit/ofproto/json/of14/5-41-ofp_get_async_reply.packet.json', 'os_ken/tests/unit/packet/test_packet.py', 'os_ken/tests/unit/ofproto/json/of13/4-4-ofp_packet_in.packet.json', 'os_ken/services/protocols/zebra/client/zclient.py', 'os_ken/tests/mininet/l2/vlan/test_vlan.py', 'os_ken/services/protocols/vrrp/sample_manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-experimenter.packet.json', 'os_ken/tests/unit/packet/test_mpls.py', 'ryu/services/protocols/bgp/operator/commands/show/rib.py', 'ryu/tests/unit/lib/test_mod/aaa/mod.py', 'os_ken/tests/switch/of13/action/12_COPY_TTL_IN.json', 'os_ken/tests/unit/ofproto/json/of14/5-6-ofp_features_reply.packet.json', 'os_ken/tests/switch/of10/match/05_DL_TYPE.json', 'ryu/services/protocols/bgp/info_base/vpnv6.py', 'os_ken/tests/packet_data/of14/5-49-ofp_meter_features_request.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/services/protocols/zebra/event.py', 'ryu/controller/mac_to_port.py', 'ryu/services/protocols/vrrp/monitor_openflow.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_desc_request.packet.json', 'ryu/app/simple_switch_lacp_13.py', 'ryu/services/protocols/bgp/operator/views/bgp.py', 'os_ken/tests/packet_data/of12/3-15-ofp_error_msg.packet', 'os_ken/tests/integrated/vrrp_common.py', 'ryu/tests/integrated/common/docker_base.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_desc_request.packet', 'ryu/lib/sockopt.py', 'os_ken/tests/packet_data/of12/3-33-ofp_group_desc_stats_request.packet', 'os_ken/tests/integrated/bgp/test_basic.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/20_ICMPV4_CODE.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_async_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_desc_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_desc_reply.packet.json', 'os_ken/tests/switch/of13/match/13_TCP_SRC_IPv6.json', 'os_ken/tests/switch/of14/match/11_IPV4_SRC_Mask.json', 'os_ken/tests/switch/of13/action/17_PUSH_VLAN.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of14/5-10-ofp_hello.packet.json', 'ryu/lib/bfdlib.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_features_reply.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/route_formatter_mixin.py', 'os_ken/tests/packet_data_generator3/gen.py', 'ryu/ofproto/ofproto_utils.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/33_IPV6_ND_TLL.json', 'os_ken/tests/switch/of13/match/33_IPV6_ND_TLL.json', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_port_stats_request.packet.json', 'ryu/app/simple_switch_15.py', 'ryu/tests/integrated/test_vrrp_multi.py', 'os_ken/tests/packet_data/of13/4-58-ofp_group_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-34-ofp_group_desc_stats_reply.packet.json', 'os_ken/__init__.py', 'os_ken/tests/packet_data/of12/3-30-ofp_port_stats_reply.packet', 'os_ken/tests/switch/of13/match/17_SCTP_SRC_IPv6.json', 'ryu/lib/ofctl_utils.py', 'os_ken/services/protocols/bgp/operator/commands/clear.py', 'ryu/lib/packet/cfm.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_tc.packet.json', 'ryu/tests/unit/lib/test_mrtlib.py', 'os_ken/app/ofctl_rest.py', 'os_ken/tests/unit/services/protocols/bgp/utils/test_validation.py', 'os_ken/tests/packet_data/of14/5-71-ofp_requestforward.packet', 'ryu/services/protocols/bgp/info_base/vrffs.py', 'os_ken/tests/switch/of13/action/23_SET_NW_TTL_IPv4.json', 'os_ken/tests/switch/of13/match/18_SCTP_DST_IPv6.json', 'ryu/tests/unit/ofproto/test_inet.py', 'ryu/tests/unit/packet/test_openflow.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_add.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_features_reply.packet.json', 'os_ken/tests/switch/of13/match/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_features_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_mod.packet.json', 'ryu/tests/integrated/run_tests_with_ovs12.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-35-ofp_queue_get_config_request.packet.json', 'os_ken/services/protocols/bgp/core_manager.py', 'os_ken/tests/packet_data/of13/4-47-ofp_meter_config_request.packet', 'ryu/tests/unit/ofproto/test_parser.py', 'os_ken/hooks.py', 'ryu/services/protocols/zebra/server/event.py', 'os_ken/tests/switch/of13/match/03_ETH_DST_Mask.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_pkt_mark_masked.packet', 'os_ken/tests/switch/of13/match/29_ICMPV6_TYPE.json', 'os_ken/tests/packet_data/bgp4/bgp4-keepalive.pcap', 'os_ken/tests/unit/cmd/test_manager.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-get_config_reply.packet', 'os_ken/tests/packet_data/of14/5-67-ofp_flow_monitor_reply.packet', 'os_ken/services/protocols/bgp/protocol.py', 'os_ken/services/protocols/bgp/rtconf/__init__.py', 'os_ken/tests/packet_data/of12/3-28-ofp_table_stats_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-16-ofp_experimenter.packet.json', 'ryu/controller/ofp_api.py', 'os_ken/services/protocols/vrrp/sample_router.py', 'os_ken/app/ofctl/event.py', 'os_ken/tests/unit/ofproto/json/of13/4-3-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/test_ether.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_01_10M.json', 'os_ken/tests/switch/of13/match/38_TUNNEL_ID.json', 'ryu/ofproto/ofproto_protocol.py', 'ryu/tests/unit/packet/test_icmp.py', 'os_ken/tests/switch/of14/match/05_ETH_TYPE.json', 'os_ken/services/protocols/bgp/api/base.py', 'os_ken/services/protocols/zebra/db/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-26-ofp_aggregate_stats_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-16-ofp_experimenter.packet.json', 'os_ken/services/protocols/bgp/operator/command.py', 'os_ken/tests/switch/of13/match/06_VLAN_VID.json', 'os_ken/tests/packet_data_generator/src/x5.erl', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-bundle_features_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/13_TCP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-60-ofp_flow_mod.packet.json', 'os_ken/app/rest_qos.py', 'os_ken/tests/switch/of10/match/01_DL_SRC.json', 'os_ken/tests/switch/of13/match/16_UDP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_status.packet.json', 'os_ken/services/protocols/vrrp/rpc_manager.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_async_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-9-ofp_get_config_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_desc_request.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-packet_in.packet', 'os_ken/tests/unit/ofproto/test_parser_ofpmatch.py', 'os_ken/tests/switch/of14/match/32_IPV6_ND_SLL.json', 'os_ken/tests/unit/services/protocols/bgp/test_peer.py', 'os_ken/tests/switch/of14/match/27_IPV6_DST.json', 'ryu/lib/packet/bpdu.py', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_mod.packet.json', 'ryu/lib/netconf/netconf.xsd', 'os_ken/controller/controller.py', 'ryu/lib/xflow/netflow.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/09_IP_ECN_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/4-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/switch/of10/action/08_SET_NW_TOS_IPv6.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-aggregate_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-desc_reply.packet.json', 'ryu/tests/unit/ofproto/test_ofproto_common.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/19_ICMPV4_TYPE.json', 'os_ken/controller/conf_switch.py', 'os_ken/services/protocols/vrrp/monitor_openflow.py', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet1.json', 'os_ken/tests/packet_data/of14/5-65-ofp_role_status.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/14_TCP_DST_IPv4.json', 'os_ken/tests/packet_data/of14/5-36-ofp_queue_stats_reply.packet', 'os_ken/tests/packet_data/of14/5-52-ofp_port_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_group_stats_request.packet.json', 'ryu/tests/unit/packet/test_bmp.py', 'ryu/tests/unit/app/test_ws_topology.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/unit/ofproto/json/of12/3-59-ofp_packet_in.packet.json', 'os_ken/tests/mininet/l2/vlan/PopVLAN_vlanvlan.mn', 'os_ken/tests/unit/ofproto/json/of14/5-22-ofp_port_mod.packet.json', 'os_ken/tests/switch/of14/match/08_IP_DSCP_IPv4.json', 'ryu/tests/unit/packet/test_ospf.py', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_00_100.json', 'ryu/tests/unit/lib/test_ip.py', 'os_ken/tests/switch/of10/match/09_NW_DST_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-set_config.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-35-ofp_queue_get_config_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-error_msg.packet', 'os_ken/tests/unit/ofproto/json/of12/3-5-ofp_features_request.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_exec.packet', 'os_ken/tests/unit/ofproto/json/of14/5-38-ofp_flow_removed.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter.packet.json', 'os_ken/tests/integrated/common/__init__.py', 'os_ken/tests/unit/ofproto/json/of14/lib-ofctl-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of13/4-46-ofp_flow_mod.packet', 'os_ken/services/protocols/bgp/application.py', 'ryu/tests/unit/packet/test_pbb.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_monitor_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_mod_conjunction.packet.json', 'ryu/services/protocols/bgp/application.py', 'ryu/services/protocols/bgp/bgp_sample_conf.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_features_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-24-ofp_desc_request.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/30_ICMPV6_CODE.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_dec_ttl_cnt_ids.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-16-ofp_experimenter.packet.json', 'os_ken/services/protocols/bgp/core_managers/peer_manager.py', 'os_ken/tests/packet_data/pcap/openflow_invalid_version.pcap', 'os_ken/tests/switch/of13/action/25_SET_FIELD/34_MPLS_LABEL.json', 'os_ken/topology/dumper.py', 'ryu/lib/packet/sctp.py', 'os_ken/tests/packet_data/of12/3-12-ofp_flow_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/4-51-ofp_meter_features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-48-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of13/match/39_IPV6_EXTHDR.json', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-ofp_queue_stats_request.packet.json', 'os_ken/tests/mininet/l2/mpls/test_mpls.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-desc_reply.packet', 'os_ken/tests/switch/of13/action/25_SET_FIELD/07_VLAN_PCP.json', 'ryu/services/protocols/bgp/operator/commands/responses.py', 'ryu/lib/packet/gre.py', 'os_ken/app/gui_topology/html/ryu.topology.css', 'os_ken/tests/switch/of14/match/34_MPLS_LABEL.json', 'os_ken/services/protocols/bgp/info_base/vrf6fs.py', 'ryu/services/protocols/bgp/core_managers/configuration_manager.py', 'os_ken/app/ofctl/exception.py', 'os_ken/tests/switch/of14/match/20_ICMPV4_CODE.json', 'ryu/lib/netconf/xml.xsd', 'ryu/services/protocols/bgp/info_base/vpnv4fs.py', 'os_ken/tests/packet_data/of13/4-30-ofp_port_stats_reply.packet', 'os_ken/services/protocols/bgp/api/import_map.py', 'os_ken/tests/packet_data/of13/4-7-ofp_set_config.packet', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_02_100M.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-features_reply.packet.json', 'ryu/tests/unit/packet/test_mpls.py', 'os_ken/tests/switch/of14/match/13_TCP_SRC_IPv6.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_clear.packet', 'ryu/lib/packet/bfd.py', 'os_ken/tests/switch/of13/match/28_IPV6_FLABEL_Mask.json', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_00_100.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_controller.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-58-ofp_flow_mod.packet.json', 'os_ken/app/simple_switch_14.py', 'os_ken/services/protocols/bgp/operator/commands/__init__.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-echo_request.packet.json', 'os_ken/app/simple_monitor_13.py', 'os_ken/tests/switch/of13/group/01_SELECT_Weight_IP.json', 'os_ken/tests/unit/ofproto/test_inet.py', 'ryu/app/bmpstation.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/20_ICMPV4_CODE.json', 'os_ken/tests/unit/ofproto/json/of12/3-16-ofp_experimenter.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_pop_mpls.packet.json', 'os_ken/tests/packet_data/of14/5-47-ofp_meter_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_get_config_request.packet.json', 'ryu/tests/unit/ofproto/test_ofproto_v12.py', 'ryu/lib/alert.py', 'ryu/services/protocols/bgp/api/rpc_log_handler.py', 'os_ken/tests/unit/packet/test_sctp.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-35-ofp_queue_get_config_request.packet.json', 'ryu/tests/unit/lib/test_hub.py', 'ryu/services/protocols/bgp/info_base/ipv4.py', 'os_ken/tests/packet_data/of13/4-35-ofp_queue_get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-60-ofp_flow_mod.packet.json', 'os_ken/tests/switch/of13/match/32_IPV6_ND_SLL.json', 'os_ken/services/protocols/bgp/api/all.py', 'os_ken/services/protocols/bgp/info_base/vpnv6fs.py', 'os_ken/tests/packet_data/of13/4-44-ofp_set_async.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-queue_desc_request.packet', 'os_ken/tests/switch/of13/action/17_PUSH_VLAN_multiple.json', 'os_ken/tests/switch/of14/match/30_ICMPV6_CODE.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-6-ofp_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-56-ofp_group_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/test_oxs.py', 'ryu/app/cbench.py', 'os_ken/tests/packet_data/of14/5-7-ofp_set_config.packet', 'os_ken/tests/unit/ofproto/json/of12/3-28-ofp_table_stats_reply.packet.json', 'ryu/ofproto/ofproto_v1_3.py', 'os_ken/services/protocols/bgp/info_base/__init__.py', 'ryu/topology/event.py', 'os_ken/tests/packet_data/of13/4-61-ofp_experimenter_request.packet', 'ryu/ofproto/ofproto_parser.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-48-ofp_meter_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/30_ICMPV6_CODE.json', 'os_ken/tests/packet_data/of12/3-34-ofp_group_desc_stats_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_stats_request.packet.json', 'os_ken/services/protocols/bgp/bgp_sample_conf.py', 'os_ken/tests/unit/packet/test_arp.py', 'os_ken/tests/packet_data/of14/5-16-ofp_experimenter.packet', 'os_ken/tests/packet_data/of14/5-17-ofp_barrier_request.packet', 'ryu/tests/unit/ofproto/test_oxm.py', 'os_ken/tests/switch/of10/match/09_NW_DST.json', 'os_ken/controller/event.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_02_100M.json', 'os_ken/ofproto/ofproto_v1_5_parser.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/17_SCTP_SRC_IPv4.json', 'os_ken/tests/unit/ofproto/json/of14/5-49-ofp_meter_features_request.packet.json', 'ryu/app/rest_conf_switch.py', 'os_ken/tests/integrated/bgp/base_ip6.py', 'ryu/app/ofctl_rest.py', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_queue_stats_request.packet3.json', 'os_ken/tests/packet_data/of10/1-6-ofp_switch_features.packet', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv6_TCP.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_learn.packet.json', 'os_ken/app/simple_switch_snort.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_resubmit.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/vrf.py', 'os_ken/tests/packet_data/of12/3-59-ofp_packet_in.packet', 'os_ken/tests/unit/ofproto/json/of13/4-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/app/ofctl_rest_json/of12.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-port_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_stats_request.packet2.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_pkt_mark.packet.json', 'os_ken/tests/packet_data/bgp4/evpn_nlri_mac_ip_ad.pcap', 'os_ken/tests/switch/of14/action/25_SET_FIELD/06_VLAN_VID.json', 'os_ken/tests/unit/ofproto/json/of13/4-36-ofp_queue_get_config_reply.packet.json', 'ryu/tests/unit/app/test_wsgi.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_mod.packet.json', 'ryu/services/protocols/bgp/net_ctrl.py', 'ryu/topology/dumper.py', 'os_ken/tests/unit/ofproto/json/of12/3-31-ofp_group_features_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-13-ofp_echo_request.packet.json', 'os_ken/tests/switch/of13/match/04_ETH_SRC_Mask.json', 'os_ken/services/protocols/bgp/model.py', 'os_ken/services/protocols/bgp/utils/stats.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_stats_reply.packet', 'os_ken/services/protocols/bgp/rtconf/common.py', 'ryu/ofproto/ofproto_v1_2_parser.py', 'os_ken/tests/unit/ofproto/test_parser_v12.py', 'ryu/lib/packet/dhcp.py', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_push_mpls.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-42-ofp_set_async.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-33-ofp_group_desc_request.packet.json', 'os_ken/tests/unit/ofproto/test_nx_flow_spec.py', 'ryu/services/protocols/bgp/operator/commands/set.py', 'ryu/lib/netconf/__init__.py', 'os_ken/tests/unit/ofproto/json/of12/3-20-ofp_role_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod.packet', 'os_ken/tests/switch/of14/match/25_ARP_THA_Mask.json', 'os_ken/tests/unit/ofproto/json/of13/4-37-ofp_queue_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-27-ofp_table_stats_request.packet.json', 'ryu/topology/switches.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-0-ofp_desc_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod_conjunction.packet.json', 'os_ken/tests/packet_data_generator/src/er.app.src', 'ryu/app/simple_switch_rest_13.py', 'os_ken/app/simple_switch_stp_13.py', 'os_ken/services/protocols/bgp/info_base/base.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-features_request.packet', 'os_ken/tests/switch/of14/match/10_IP_PROTO_IPv6.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-56-ofp_table_features_reply.packet.json', 'os_ken/tests/packet_data/of13/4-36-ofp_queue_get_config_reply.packet', 'os_ken/tests/switch/of13/action/24_DEC_NW_TTL_IPv6.json', 'os_ken/tests/packet_data/of14/5-56-ofp_group_stats_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/08_IP_DSCP_IPv6.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_sample2.packet', 'ryu/services/protocols/bgp/signals/emit.py', 'os_ken/tests/switch/of14/match/06_VLAN_VID_Mask.json', 'os_ken/ofproto/ofproto_utils.py', 'os_ken/tests/packet_data/of13/4-62-ofp_experimenter_reply.packet', 'os_ken/services/protocols/bgp/api/core.py', 'os_ken/tests/packet_data/of13/4-16-ofp_experimenter.packet', 'ryu/app/simple_switch.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-64-ofp_queue_desc_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-10-ofp_hello.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_reply.packet', 'os_ken/tests/switch/of14/action/19_PUSH_MPLS_multiple.json', 'ryu/lib/packet/geneve.py', 'ryu/lib/sockaddr.py', 'os_ken/tests/switch/of13/match/26_IPV6_SRC.json', 'ryu/tests/unit/lib/test_mod/ggg.py', 'os_ken/tests/switch/of13/action/23_SET_NW_TTL_IPv6.json', 'ryu/lib/packet/ether_types.py', 'ryu/services/protocols/zebra/db/interface.py', 'ryu/tests/mininet/l3/ip_ttl/test_ip_ttl.py', 'os_ken/services/protocols/bgp/operator/ssh.py', 'os_ken/tests/packet_data/of13/4-12-ofp_flow_stats_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-features_reply.packet', 'os_ken/tests/switch/of13/match/14_TCP_DST_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_meter_stats_request.packet.json', 'ryu/services/protocols/bgp/info_base/vpnv4.py', 'os_ken/ofproto/oxm_fields.py', 'os_ken/services/protocols/bgp/signals/emit.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/38_TUNNEL_ID.json', 'os_ken/services/protocols/bgp/info_base/vrfevpn.py', 'os_ken/app/rest_topology.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-set_config.packet', 'os_ken/tests/switch/of13/match/37_PBB_ISID.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_stats_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/13_TCP_SRC_IPv6.json', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-flow_mod.packet.truncated64.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-requestforward.packet.json', 'os_ken/tests/switch/of13/match/23_ARP_TPA_Mask.json', 'os_ken/topology/__init__.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_desc_reply.packet', 'os_ken/services/protocols/bgp/operator/commands/show/rib.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_features_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-role_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-set_config.packet', 'os_ken/app/simple_switch_websocket_13.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/10_IP_PROTO_IPv6.json', 'ryu/app/ofctl/service.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_label.packet', 'os_ken/tests/unit/ofproto/json/of14/5-7-ofp_set_config.packet.json', 'os_ken/tests/packet_data/of14/5-6-ofp_features_reply.packet', 'ryu/lib/packet/packet_utils.py', 'os_ken/tests/packet_data/of13/4-27-ofp_table_stats_request.packet', 'os_ken/tests/packet_data/of13/4-20-ofp_role_reply.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-aggregate_stats_reply.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/18_SCTP_DST_IPv4.json', 'ryu/controller/controller.py', 'os_ken/tests/switch/of13/match/14_TCP_DST_IPv6.json', 'os_ken/tests/packet_data/of13/4-54-ofp_port_desc_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-controller_status_reply.packet', 'ryu/app/simple_switch_stp_13.py', 'ryu/app/ofctl/api.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status_request.packet.json', 'os_ken/app/example_switch_13.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-43-ofp_meter_mod.packet.json', 'ryu/tests/unit/packet/test_dhcp.py', 'os_ken/app/__init__.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/41_PBB_UCA.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/38_TUNNEL_ID.json', 'os_ken/services/protocols/ovsdb/__init__.py', 'os_ken/tests/mininet/l3/ip_ttl/test_ip_ttl.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-requestforward.packet', 'os_ken/tests/packet_data/of14/5-68-ofp_table_status.packet', 'os_ken/controller/tunnels.py', 'ryu/lib/netdevice.py', 'os_ken/tests/unit/ofproto/json/of14/5-14-ofp_echo_reply.packet.json', 'ryu/app/rest_router.py', 'os_ken/tests/packet_data/of13/4-60-ofp_flow_mod.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/08_IP_DSCP_IPv4.json', 'os_ken/tests/switch/of13/match/31_IPV6_ND_TARGET.json', 'ryu/services/protocols/zebra/client/sample_dumper.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/24_ARP_SHA.json', 'ryu/services/protocols/bgp/operator/views/other.py', 'os_ken/tests/unit/ofproto/json/of14/5-68-ofp_table_status.packet.json', 'os_ken/tests/unit/services/protocols/__init__.py', 'os_ken/tests/packet_data/of14/5-30-ofp_port_stats_reply.packet', 'ryu/app/ofctl/exception.py', 'os_ken/tests/packet_data/of13/4-63-onf_flow_monitor_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-62-ofp_table_desc_reply.packet.json', 'os_ken/tests/switch/of13/match/25_ARP_THA.json', 'os_ken/tests/mininet/l3/icmp/ICMP_reply.mn', 'os_ken/tests/switch/of10/match/08_NW_SRC_Mask.json', 'ryu/tests/integrated/run_test.py', 'os_ken/app/wsgi.py', 'os_ken/tests/switch/of14/match/25_ARP_THA.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_stats_reply.packet.json', 'os_ken/app/gui_topology/html/ryu.topology.js', 'ryu/lib/ovs/__init__.py', 'os_ken/tests/packet_data/of13/4-43-ofp_get_async_reply.packet', 'os_ken/tests/switch/of14/action/25_SET_FIELD/11_IPV4_SRC.json', 'ryu/lib/packet/stream_parser.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/07_VLAN_PCP.json', 'os_ken/tests/unit/ofproto/json/of12/3-36-ofp_queue_get_config_reply.packet.json', 'os_ken/tests/switch/of10/match/02_DL_DST.json', 'os_ken/services/protocols/zebra/db/base.py', 'ryu/tests/packet_data_generator3/gen.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_features_reply.packet', 'os_ken/tests/integrated/test_vrrp_multi.py', 'ryu/app/rest_qos.py', 'os_ken/ofproto/nx_actions.py', 'os_ken/tests/switch/of14/match/18_SCTP_DST_IPv4.json', 'os_ken/tests/unit/services/protocols/bgp/utils/__init__.py', 'ryu/services/protocols/zebra/server/sample_dumper.py', 'ryu/lib/of_config/ietf-inet-types.xsd', 'os_ken/tests/unit/app/ofctl_rest_json/of10.json', 'os_ken/app/rest_vtep.py', 'os_ken/controller/ofp_api.py', 'os_ken/ofproto/ofproto_parser.py', 'os_ken/tests/unit/ofproto/json/of14/5-27-ofp_table_stats_request.packet.json', 'os_ken/tests/packet_data/of14/5-50-ofp_meter_features_reply.packet', 'ryu/lib/packet/mpls.py', 'os_ken/tests/switch/of10/action/02_SET_VLAN_PCP.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_mod.packet', 'os_ken/tests/unit/ofproto/json/of14/5-37-ofp_port_status.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-67-ofp_flow_monitor_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-61-ofp_table_desc_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-36-ofp_queue_stats_reply.packet.json', 'os_ken/services/protocols/bgp/info_base/vrf4.py', 'os_ken/tests/unit/ofproto/json/of14/5-48-ofp_meter_stats_reply.packet.json', 'os_ken/tests/switch/of10/match/07_NW_PROTO_IPv6.json', 'os_ken/tests/unit/services/protocols/bgp/test_bgpspeaker.py', 'os_ken/tests/switch/of13/match/24_ARP_SHA_Mask.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status_reply.packet.json', 'ryu/ofproto/ofproto_v1_3_parser.py', 'ryu/services/protocols/bgp/info_base/ipv4fs.py', 'ryu/tests/unit/controller/test_controller.py', 'os_ken/tests/unit/ofproto/json/of13/4-5-ofp_features_request.packet.json', 'ryu/tests/switch/tester.py', 'ryu/tests/unit/lib/test_mod/ddd/__init__.py', 'os_ken/tests/integrated/bgp/test_ip6_basic.py', 'ryu/services/protocols/bgp/info_base/vpnv6fs.py', 'os_ken/tests/unit/packet/test_bmp.py', 'os_ken/tests/switch/of14/match/13_TCP_SRC_IPv4.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_removed.packet', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_00_KBPS_00_1M.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-56-ofp_group_stats_reply.packet.json', 'os_ken/services/protocols/bgp/core_managers/table_manager.py', 'ryu/lib/packet/slow.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/17_SCTP_SRC_IPv6.json', 'ryu/ofproto/ether.py', 'ryu/services/protocols/vrrp/__init__.py', 'os_ken/tests/packet_data/of14/5-12-ofp_flow_stats_reply.packet', 'os_ken/tests/switch/of14/match/15_UDP_SRC_IPv6.json', 'ryu/tests/unit/packet/test_slow.py', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv6_UDP.json', 'ryu/lib/packet/ipv4.py', 'os_ken/tests/unit/packet/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_desc_reply.packet.json', 'ryu/lib/of_config/of-config-1.0.xsd', 'os_ken/tests/packet_data/of15/libofproto-OFP15-get_config_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of14/5-2-ofp_flow_mod.packet.json', 'os_ken/services/protocols/vrrp/monitor.py', 'os_ken/tests/unit/ofproto/json/of14/5-16-ofp_experimenter.packet.json', 'os_ken/tests/unit/ofproto/test_ofproto_v12.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-28-ofp_table_stats_reply.packet.json', 'ryu/tests/unit/lib/test_mac.py', 'os_ken/tests/unit/ofproto/json/of14/5-29-ofp_port_stats_request.packet.json', 'ryu/services/protocols/bgp/utils/rtfilter.py', 'ryu/lib/packet/llc.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_lacp.pcap', 'ryu/services/protocols/bgp/api/core.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-55-ofp_table_features_request.packet.json', 'ryu/services/protocols/zebra/db/__init__.py', 'ryu/lib/hub.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/08_IP_DSCP_IPv6.json', 'ryu/tests/integrated/common/ryubgp.py', 'ryu/lib/igmplib.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-meter_features_reply.packet.json', 'ryu/tests/unit/packet/test_zebra.py', 'os_ken/tests/unit/ofproto/json/of14/5-5-ofp_features_request.packet.json', 'ryu/services/protocols/bgp/base.py', 'os_ken/tests/unit/app/ofctl_rest_json/of14.json', 'ryu/services/protocols/bgp/bmp.py', 'ryu/tests/unit/lib/test_mod/aaa/__init__.py', 'os_ken/tests/unit/packet/test_zebra.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-features_reply.packet', 'ryu/tests/mininet/packet_lib/arp/test_arp.py', 'os_ken/tests/unit/ofproto/json/of13/4-0-ofp_desc_reply.packet.json', 'os_ken/tests/switch/of14/match/08_IP_DSCP_IPv6.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-barrier_reply.packet', 'ryu/lib/packet/igmp.py', 'ryu/tests/unit/app/test_ofctl_rest.py', 'ryu/lib/type_desc.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-52-ofp_port_desc_reply.packet.json', 'os_ken/app/ofctl/service.py', 'ryu/services/protocols/bgp/info_base/vrf.py', 'os_ken/tests/packet_data/of14/5-41-ofp_get_async_reply.packet', 'os_ken/tests/switch/of13/action/20_POP_MPLS.json', 'os_ken/tests/unit/ofproto/json/of14/5-59-ofp_experimenter_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_desc_reply.packet.json', 'os_ken/services/protocols/bgp/operator/commands/root.py', 'ryu/services/protocols/vrrp/rpc_manager.py', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv4_TCP.json', 'os_ken/tests/integrated/run_test.py', 'ryu/lib/packet/zebra.py', 'ryu/tests/unit/packet/test_ipv4.py', 'os_ken/base/__init__.py', 'os_ken/services/protocols/zebra/server/__init__.py', 'os_ken/controller/ofp_event.py', 'os_ken/ofproto/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-38-ofp_queue_stats_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-1-ofp_packet_out.packet.json', 'ryu/services/protocols/bgp/info_base/vrf6.py', 'os_ken/tests/unit/ofproto/json/of12/libofproto-OFP12-ofp_packet_out_packet_library.packet.json', 'os_ken/app/simple_switch_igmp.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_pop_mpls.packet', 'os_ken/tests/unit/ofproto/json/of13/4-34-ofp_group_desc_reply.packet.json', 'os_ken/tests/packet_data/of12/3-21-ofp_group_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-49-ofp_meter_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-packet_out.packet.json', 'os_ken/tests/unit/cmd/__init__.py', 'os_ken/tests/switch/of10/action/09_SET_TP_SRC_IPv4_UDP.json', 'ryu/tests/unit/packet/test_arp.py', 'os_ken/tests/switch/of10/match/03_DL_VLAN.json', 'os_ken/tests/switch/of14/match/12_IPV4_DST_Mask.json', 'os_ken/cmd/of_config_cli.py', 'os_ken/tests/unit/ofproto/json/of13/4-48-ofp_meter_config_reply.packet.json', 'os_ken/tests/switch/of14/action/18_POP_VLAN.json', 'os_ken/tests/packet_data/of12/3-25-ofp_aggregate_stats_request.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_output_trunc.packet', 'ryu/tests/unit/lib/ofctl_json/of14/5-63-ofp_queue_desc_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-bundle_add.packet', 'os_ken/tests/packet_data/of12/3-19-ofp_role_request.packet', 'os_ken/tests/unit/ofproto/json/of12/3-15-ofp_error_msg.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-14-ofp_echo_reply.packet.json', 'os_ken/topology/switches.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/13_TCP_SRC_IPv4.json', 'os_ken/services/protocols/ovsdb/model.py', 'os_ken/tests/packet_data/of13/4-45-ofp_meter_mod.packet', 'ryu/services/protocols/bgp/info_base/vrfl2vpnfs.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/10_IP_PROTO_IPv4.json', 'ryu/flags.py', 'os_ken/tests/switch/of13/match/38_TUNNEL_ID_Mask.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-queue_desc_request.packet.json', 'ryu/tests/unit/ofproto/test_parser_v12.py', 'ryu/services/protocols/bgp/model.py', 'os_ken/tests/packet_data/of12/3-8-ofp_get_config_request.packet', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_stats_reply.packet', 'os_ken/tests/packet_data/of14/5-62-ofp_table_desc_reply.packet', 'ryu/lib/of_config/constants.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/09_IP_ECN_IPv4.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_stats_request.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-experimenter.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-features_reply.packet.json', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv6_UDP.json', 'ryu/tests/unit/lib/ofctl_json/of13/4-58-ofp_group_stats_reply.packet.json', 'os_ken/tests/packet_data/of14/5-61-ofp_table_desc_request.packet', 'os_ken/services/protocols/bgp/net_ctrl.py', 'os_ken/tests/unit/ofproto/json/of14/5-46-ofp_meter_config_reply.packet.json', 'ryu/services/protocols/bgp/api/base.py', 'os_ken/tests/unit/app/test_tester.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_load_nx_register.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_features_request.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/05_ETH_TYPE.json', 'os_ken/services/protocols/bgp/info_base/vrfl2vpnfs.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_conjunction.packet.json', 'ryu/topology/api.py', 'ryu/cmd/of_config_cli.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-group_mod.packet.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/27_IPV6_DST.json', 'os_ken/tests/packet_data/of13/4-48-ofp_meter_config_reply.packet', 'ryu/services/protocols/ovsdb/event.py', 'ryu/tests/switch/run_mininet.py', 'os_ken/tests/packet_data/of14/5-44-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of10/1-4-ofp_packet_in.packet', 'os_ken/services/protocols/bgp/utils/rtfilter.py', 'os_ken/tests/unit/packet/test_udp.py', 'os_ken/ofproto/ofproto_v1_5.py', 'ryu/tests/unit/lib/test_mod/bbb/mod.py', 'os_ken/tests/packet_data/of14/5-4-ofp_packet_in.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_move_nx_register.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-barrier_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of12/3-14-ofp_echo_reply.packet.json', 'os_ken/tests/switch/of14/group/01_SELECT_Weight_Ether.json', 'os_ken/tests/unit/ofproto/json/of14/5-55-ofp_group_stats_request.packet.json', 'ryu/services/protocols/bgp/info_base/vrfevpn.py', 'os_ken/services/protocols/bgp/operator/internal_api.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/37_PBB_ISID.json', 'ryu/services/protocols/zebra/client/zclient.py', 'os_ken/tests/mininet/packet_lib/arp/test_arp.py', 'os_ken/tests/packet_data/pcap/gre_full_options.pcap', 'os_ken/tests/switch/of13/meter/01_DROP_00_KBPS_00_1M.json', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_00_KBPS_00_1M.json', 'ryu/topology/__init__.py', 'os_ken/tests/switch/of14/match/36_MPLS_BOS.json', 'os_ken/tests/unit/ofproto/json/of12/3-30-ofp_port_stats_reply.packet.json', 'ryu/tests/unit/packet/test_icmpv6.py', 'os_ken/tests/switch/of13/match/18_SCTP_DST_IPv4.json', 'os_ken/tests/unit/ofproto/json/of13/4-58-ofp_group_stats_reply.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_nat.packet', 'ryu/app/rest_topology.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-meter_desc_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-barrier_request.packet', 'ryu/services/protocols/bgp/operator/commands/show/memory.py', 'ryu/tests/integrated/test_vrrp_linux_multi.py', 'os_ken/tests/unit/ofproto/json/of14/5-3-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-30-ofp_port_stats_reply.packet.json', 'ryu/app/simple_switch_12.py', 'os_ken/tests/unit/ofproto/test_ofproto_parser.py', 'ryu/tests/unit/ofproto/test_ether.py', 'ryu/lib/ofctl_v1_5.py', 'os_ken/tests/switch/of13/group/01_SELECT_IP.json', 'os_ken/tests/packet_data/of12/3-7-ofp_set_config.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_stats_request.packet.json', 'os_ken/tests/integrated/test_add_flow_v12_matches.py', 'os_ken/tests/mininet/l3/ip_ttl/DecNwTtl.mn', 'os_ken/tests/switch/of10/action/08_SET_NW_TOS_IPv4.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/lib/test_ofctl.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_vpn4.pcap', 'os_ken/tests/packet_data/of13/4-4-ofp_packet_in.packet', 'os_ken/tests/packet_data/of13/4-11-ofp_flow_stats_request.packet', 'ryu/services/protocols/bgp/info_base/evpn.py', 'os_ken/app/simple_switch_lacp.py', 'os_ken/tests/unit/ofproto/json/of14/5-36-ofp_queue_stats_reply.packet.json', 'ryu/lib/packet/dhcp6.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_stack_push.packet', 'os_ken/tests/switch/of10/action/01_SET_VLAN_VID.json', 'os_ken/tests/unit/cmd/dummy_app.py', 'ryu/lib/ofctl_string.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_desc_request.packet', 'os_ken/tests/switch/of14/meter/01_DROP_01_PKTPS_02_10000.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-desc_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_desc_request.packet.json', 'ryu/tests/unit/ofproto/test_nx_flow_spec.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-flow_mod_conjunction.packet', 'ryu/tests/integrated/test_request_reply_v12.py', 'ryu/lib/addrconv.py', 'os_ken/tests/packet_data/of13/4-59-ofp_packet_in.packet', 'ryu/tests/integrated/tester.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_fintimeout.packet', 'os_ken/tests/switch/of14/match/26_IPV6_SRC.json', 'ryu/tests/integrated/bgp/test_ip6_basic.py', 'os_ken/tests/packet_data/of13/4-53-ofp_port_desc_request.packet', 'os_ken/tests/integrated/test_request_reply_v12.py', 'os_ken/tests/unit/packet/test_ethernet.py', 'os_ken/services/protocols/bgp/signals/base.py', 'ryu/tests/unit/lib/test_pack_utils.py', 'os_ken/tests/mininet/l3/icmp/ICMP_ping.mn', 'ryu/lib/packet/bgp.py', 'os_ken/tests/switch/of14/match/11_IPV4_SRC.json', 'os_ken/services/protocols/zebra/client/event.py', 'os_ken/tests/switch/of13/match/05_ETH_TYPE.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_desc_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-32-ofp_group_features_reply.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-22-ofp_port_mod.packet.json', 'os_ken/tests/switch/of13/match/23_ARP_TPA.json', 'os_ken/tests/integrated/common/install_docker_test_pkg.sh', 'os_ken/tests/switch/of13/action/25_SET_FIELD/35_MPLS_TC.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-packet_in.packet', 'os_ken/tests/integrated/tester.py', 'os_ken/tests/packet_data/of14/5-0-ofp_desc_reply.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-12-ofp_flow_stats_reply.packet.json', 'os_ken/services/protocols/__init__.py', 'os_ken/tests/packet_data/of13/4-8-ofp_get_config_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-controller_status.packet.json', 'os_ken/services/protocols/bgp/operator/commands/show/__init__.py', 'os_ken/tests/unit/packet/test_vrrp.py', 'ryu/tests/integrated/test_of_config.py', 'os_ken/services/protocols/bgp/bgpspeaker.py', 'os_ken/tests/mininet/run_mnet-test.sh', 'os_ken/tests/switch/of14/action/12_COPY_TTL_IN.json', 'os_ken/controller/network.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_ct_nat.packet.json', 'os_ken/services/protocols/zebra/server/sample_dumper.py', 'os_ken/tests/switch/of13/match/02_METADATA_Mask.json', 'os_ken/services/protocols/bgp/info_base/vpnv6.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_conjunction.packet', 'os_ken/tests/packet_data/of14/5-3-ofp_flow_mod.packet', 'ryu/app/rest_vtep.py', 'ryu/lib/of_config/classes.py', 'os_ken/tests/unit/ofproto/test_parser_v13.py', 'os_ken/services/protocols/bgp/core.py', 'os_ken/tests/switch/of14/match/03_ETH_DST_Mask.json', 'ryu/app/ofctl/event.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_features_reply.packet.json', 'ryu/services/protocols/vrrp/sample_manager.py', 'os_ken/services/protocols/bgp/operator/commands/show/memory.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_learn.packet', 'os_ken/services/protocols/vrrp/manager.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_mod_no_nx.packet.json', 'os_ken/tests/switch/of14/match/37_PBB_ISID.json', 'ryu/ofproto/ofproto_v1_4_parser.py', 'os_ken/tests/integrated/common/docker_base.py', 'os_ken/tests/packet_data/of13/4-1-ofp_packet_out.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct.packet', 'os_ken/tests/switch/of14/match/24_ARP_SHA_Mask.json', 'os_ken/tests/switch/of13/match/13_TCP_SRC_IPv4.json', 'ryu/services/protocols/bgp/operator/views/conf.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-table_mod.packet', 'ryu/tests/unit/lib/ofctl_json/of12/3-34-ofp_group_desc_stats_reply.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-hello.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_mod.packet', 'os_ken/app/simple_switch_13.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-echo_reply.packet.json', 'ryu/lib/dpid.py', 'os_ken/tests/switch/of10/action/04_SET_DL_SRC.json', 'os_ken/tests/packet_data/bgp4/bgp4-update_ipv6.pcap', 'os_ken/tests/packet_data/of12/3-37-ofp_queue_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of14/5-44-ofp_flow_mod.packet.json', 'ryu/lib/mac.py', 'os_ken/tests/unit/ofproto/json/of13/4-38-ofp_queue_stats_reply.packet.json', 'os_ken/tests/packet_data/pcap/gre_no_option.pcap', 'ryu/services/protocols/bgp/operator/commands/show/__init__.py', 'os_ken/services/protocols/bgp/operator/commands/set.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-25-ofp_aggregate_stats_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-port_desc_request.packet.json', 'ryu/tests/unit/packet/test_packet.py', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_02_10000.json', 'ryu/controller/network.py', 'os_ken/tests/packet_data/of13/4-29-ofp_port_stats_request.packet', 'ryu/services/protocols/bgp/operator/commands/show/neighbor.py', 'os_ken/tests/packet_data/of12/3-9-ofp_get_config_reply.packet', 'os_ken/tests/unit/ofproto/json/of12/3-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/switch/of10/action/10_SET_TP_DST_IPv4_TCP.json', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_rate.pcap', 'ryu/tests/unit/lib/ofctl_json/of14/5-28-ofp_table_stats_reply.packet.json', 'ryu/app/rest_firewall.py', 'ryu/tests/unit/ofproto/test_ofproto.py', 'os_ken/tests/packet_data/of10/1-1-ofp_packet_out.packet', 'ryu/lib/of_config/generated_classes.py', 'os_ken/tests/switch/of10/match/07_NW_PROTO_IPv4.json', 'ryu/lib/of_config/of-config-1.1.1.xsd', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_move_nx_register.packet.json', 'ryu/services/protocols/bgp/utils/stats.py', 'ryu/tests/unit/packet/test_gre.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-barrier_request.packet.json', 'ryu/ofproto/ofproto_v1_4.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-2-ofp_flow_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-20-ofp_role_reply.packet.json', 'os_ken/tests/packet_data/of12/3-36-ofp_queue_get_config_reply.packet', 'os_ken/tests/packet_data_generator/src/x4.erl', 'os_ken/cfg.py', 'os_ken/services/protocols/vrrp/dumper.py', 'os_ken/cmd/ryu_base.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/09_IP_ECN_IPv4.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_resubmit.packet', 'os_ken/tests/unit/ofproto/json/of12/3-19-ofp_role_request.packet.json', 'os_ken/tests/packet_data/of13/4-37-ofp_queue_stats_request.packet', 'os_ken/tests/packet_data/of10/1-2-ofp_flow_mod.packet', 'ryu/services/protocols/zebra/server/zserver.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/13_TCP_SRC_IPv6.json', 'os_ken/tests/unit/packet/test_bpdu.py', 'ryu/tests/unit/lib/ovs/test_vsctl.py', 'os_ken/tests/switch/of10/action/07_SET_NW_DST.json', 'os_ken/tests/packet_data/of12/3-17-ofp_barrier_request.packet', 'os_ken/tests/packet_data/of13/4-3-ofp_flow_mod.packet', 'os_ken/tests/unit/ofproto/json/of12/3-21-ofp_group_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_group_stats_request.packet.json', 'os_ken/services/protocols/bgp/info_base/ipv4fs.py', 'ryu/tests/unit/packet/test_bfd.py', 'ryu/app/simple_switch_lacp.py', 'os_ken/tests/packet_data/of14/5-13-ofp_echo_request.packet', 'os_ken/contrib/__init__.py', 'os_ken/tests/switch/of13/match/27_IPV6_DST_Mask.json', 'os_ken/ofproto/ofproto_v1_0.py', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_note.packet', 'os_ken/tests/switch/run_mininet.py', 'ryu/tests/unit/lib/test_mod/ccc/mod.py', 'os_ken/services/protocols/bgp/info_base/vrffs.py', 'ryu/services/protocols/bgp/operator/commands/clear.py', 'os_ken/tests/packet_data/of10/1-5-features_request.packet', 'os_ken/tests/packet_data/of14/5-8-ofp_get_config_request.packet', 'ryu/services/protocols/ovsdb/api.py', 'os_ken/tests/unit/ofproto/json/of12/3-40-ofp_flow_removed.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-table_desc_reply.packet.json', 'os_ken/tests/switch/of13/match/09_IP_ECN_IPv6.json', 'ryu/lib/ovs/bridge.py', 'os_ken/tests/packet_data/of13/4-26-ofp_aggregate_stats_reply.packet', 'os_ken/tests/switch/of13/match/16_UDP_DST_IPv4.json', 'os_ken/tests/switch/of14/action/11_COPY_TTL_OUT.json', 'os_ken/tests/packet_data/of12/3-14-ofp_echo_reply.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-role_status.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_features_reply.packet', 'ryu/services/protocols/bgp/operator/commands/show/count.py', 'os_ken/tests/packet_data/of14/5-15-ofp_error_msg.packet', 'os_ken/tests/unit/packet/test_dhcp.py', 'os_ken/tests/unit/ofproto/json/of14/5-33-ofp_group_desc_request.packet.json', 'os_ken/services/protocols/bgp/api/prefix.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-meter_desc_reply.packet', 'os_ken/tests/unit/ofproto/json/of14/5-26-ofp_aggregate_stats_reply.packet.json', 'os_ken/tests/packet_data/of14/5-1-ofp_packet_out.packet', 'os_ken/tests/packet_data/of13/4-15-ofp_error_msg.packet', 'ryu/tests/unit/lib/ofctl_json/of13/4-45-ofp_meter_mod.packet.json', 'os_ken/tests/switch/of13/match/39_IPV6_EXTHDR_Mask.json', 'os_ken/tests/switch/of10/match/00_IN_PORT.json', 'os_ken/services/protocols/bgp/operator/views/other.py', 'os_ken/tests/unit/ofproto/json/of12/3-4-ofp_packet_in.packet.json', 'os_ken/tests/unit/packet/test_geneve.py', 'os_ken/tests/packet_data/bgp4/flowspec_action_redirect.pcap', 'ryu/ofproto/ofproto_v1_0.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/10_IP_PROTO_IPv6.json', 'os_ken/tests/switch/of14/action/16_DEC_MPLS_TTL.json', 'ryu/tests/unit/lib/test_ofctl_v1_3.py', 'ryu/cmd/ryu_base.py', 'os_ken/tests/integrated/test_of_config.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_stats_request.packet', 'os_ken/tests/packet_data/of13/4-40-ofp_flow_removed.packet', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_features_request.packet', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_01_1000.json', 'ryu/tests/integrated/bgp/base_ip6.py', 'os_ken/tests/switch/of13/match/17_SCTP_SRC_IPv4.json', 'ryu/app/ws_topology.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_output_trunc.packet.json', 'ryu/tests/unit/services/protocols/bgp/core_managers/test_table_manager.py', 'os_ken/tests/unit/ofproto/json/of14/5-11-ofp_flow_stats_request.packet.json', 'os_ken/tests/unit/services/protocols/bgp/core_managers/test_table_manager.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_tc.packet', 'ryu/services/protocols/bgp/api/import_map.py', 'os_ken/tests/unit/ofproto/json/of13/4-28-ofp_table_stats_reply.packet.json', 'os_ken/tests/switch/of13/match/27_IPV6_DST.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-error_msg.packet', 'os_ken/tests/unit/packet/test_openflow.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_features_request.packet.json', 'os_ken/tests/unit/packet/test_bgp.py', 'ryu/ofproto/ofproto_v1_0_parser.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/31_IPV6_ND_TARGET.json', 'os_ken/tests/switch/of13/group/01_SELECT_Ether.json', 'os_ken/tests/unit/ofproto/json/of12/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/packet_data/of13/libofproto-OFP13-ofp_packet_out_packet_library.packet', 'os_ken/services/protocols/bgp/info_base/ipv6.py', 'os_ken/tests/switch/of14/match/39_IPV6_EXTHDR.json', 'ryu/services/protocols/bgp/core_managers/table_manager.py', 'os_ken/tests/packet_data/of12/3-32-ofp_group_features_stats_reply.packet', 'os_ken/tests/packet_data/of12/3-60-ofp_flow_mod.packet', 'os_ken/tests/packet_data/of14/5-33-ofp_group_desc_request.packet', 'os_ken/tests/packet_data/of14/5-66-ofp_flow_monitor_request.packet', 'os_ken/tests/unit/sample/test_sample1.py', 'os_ken/tests/unit/ofproto/json/of14/5-43-ofp_meter_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_dec_mpls_ttl.packet.json', 'os_ken/services/protocols/bgp/operator/__init__.py', 'ryu/lib/xflow/__init__.py', 'os_ken/tests/switch/of14/match/29_ICMPV6_TYPE.json', 'ryu/tests/unit/packet/test_sctp.py', 'os_ken/tests/unit/ofproto/json/of12/3-22-ofp_port_mod.packet.json', 'os_ken/tests/packet_data/of14/5-55-ofp_group_stats_request.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-match_load_nx_register.packet', 'os_ken/tests/unit/test_requirements.py', 'os_ken/tests/unit/ofproto/json/of13/4-53-ofp_port_desc_request.packet.json', 'os_ken/app/gui_topology/html/index.html', 'ryu/lib/of_config/xmldsig-core-schema.xsd', 'ryu/controller/ofp_handler.py', 'os_ken/tests/packet_data/of12/3-11-ofp_flow_stats_request.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_desc_reply.packet.json', 'ryu/lib/packet/packet.py', 'os_ken/tests/switch/of14/action/00_OUTPUT.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/03_ETH_DST.json', 'ryu/services/protocols/bgp/rtconf/neighbors.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-54-ofp_port_desc_reply.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/15_UDP_SRC_IPv4.json', 'os_ken/tests/packet_data/of12/libofproto-OFP12-ofp_packet_out_packet_library.packet', 'ryu/services/protocols/vrrp/utils.py', 'os_ken/tests/unit/packet/test_ipv4.py', 'os_ken/tests/unit/ofproto/json/of13/4-40-ofp_flow_removed.packet.json', 'os_ken/tests/packet_data/of12/3-40-ofp_flow_removed.packet', 'os_ken/tests/switch/of13/match/24_ARP_SHA.json', 'ryu/services/protocols/bgp/info_base/base.py', 'ryu/lib/ofctl_v1_0.py', 'os_ken/tests/switch/of14/match/41_PBB_UCA.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_async_reply.packet.json', 'ryu/tests/unit/sample/test_sample1.py', 'os_ken/tests/packet_data/of12/3-23-ofp_table_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-54-ofp_port_desc_reply.packet.json', 'os_ken/services/protocols/bgp/api/__init__.py', 'os_ken/tests/packet_data_generator2/Makefile.GNU', 'os_ken/tests/switch/of13/match/22_ARP_SPA_Mask.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-error_msg_experimenter.packet.json', 'os_ken/tests/packet_data/of14/5-19-ofp_role_request.packet', 'os_ken/ofproto/nicira_ext.py', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_queue_stats_request.packet2.json', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-action_stack_pop.packet.json', 'os_ken/tests/switch/of13/match/08_IP_DSCP_IPv4.json', 'os_ken/services/protocols/bgp/operator/commands/show/importmap.py', 'os_ken/tests/switch/of14/group/00_ALL.json', 'os_ken/tests/integrated/test_vrrp_multi.sh', 'ryu/ofproto/oxx_fields.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/11_IPV4_SRC.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_mod_match_conj.packet', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-echo_reply.packet.json', 'os_ken/tests/integrated/bgp/__init__.py', 'os_ken/services/protocols/zebra/client/__init__.py', 'ryu/app/simple_switch_13.py', 'os_ken/services/protocols/zebra/server/event.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/26_IPV6_SRC.json', 'os_ken/tests/unit/ofproto/json/of14/5-60-ofp_experimenter_reply.packet.json', 'ryu/services/protocols/vrrp/sample_router.py', 'os_ken/tests/packet_data_generator/src/x_flower_packet.erl', 'os_ken/ofproto/ofproto_v1_0_parser.py', 'ryu/tests/unit/lib/test_stringify.py', 'ryu/lib/ovs/vswitch_idl.py', 'os_ken/tests/packet_data/bgp4/bgp4-update_vpnv6.pcap', 'os_ken/tests/switch/of14/meter/02_DSCP_REMARK_01_PKTPS_01_1000.json', 'ryu/tests/unit/lib/ofctl_json/of15/lib-ofctl-OFP15-flow_desc_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of13/lib-ofctl-ofp_port_stats_request.packet.json', 'os_ken/tests/integrated/run_tests_with_ovs12.py', 'ryu/lib/packet/packet_base.py', 'os_ken/tests/packet_data/of13/4-55-ofp_table_features_request.packet', 'os_ken/controller/handler.py', 'os_ken/tests/unit/ofproto/json/of13/4-23-ofp_table_mod.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-56-ofp_table_features_reply.packet.json', 'ryu/services/protocols/bgp/core.py', 'ryu/tests/unit/lib/test_pcaplib.py', 'ryu/services/protocols/bgp/operator/views/base.py', 'os_ken/tests/packet_data/mrt/updates.20161101.0000.bz2', 'ryu/tests/unit/lib/test_mod/ccc/__init__.py', 'ryu/tests/unit/lib/ofctl_json/of13/4-21-ofp_group_mod.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-port_status.packet', 'os_ken/tests/switch/of13/action/26_PUSH_PBB.json', 'os_ken/tests/unit/services/protocols/bgp/__init__.py', 'os_ken/tests/packet_data/of14/5-21-ofp_group_mod.packet', 'os_ken/app/gui_topology/__init__.py', 'os_ken/services/protocols/zebra/db/interface.py', 'os_ken/tests/packet_data/of14/5-45-ofp_meter_config_request.packet', 'os_ken/tests/switch/of14/action/24_DEC_NW_TTL_IPv4.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/23_ARP_TPA.json', 'os_ken/tests/unit/ofproto/json/of13/lib-ofctl-ofp_table_features_request.packet.json', 'os_ken/tests/packet_data/of12/3-61-ofp_group_stats_request.packet', 'ryu/cmd/ofa_neutron_agent.py', 'ryu/services/protocols/bgp/info_base/vpn.py', 'os_ken/tests/packet_data/of13/4-38-ofp_queue_stats_reply.packet', 'ryu/services/protocols/vrrp/manager.py', 'os_ken/__init__.py~HEAD', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of14/5-32-ofp_group_features_reply.packet.json', 'os_ken/services/protocols/zebra/server/zserver.py', 'os_ken/tests/unit/services/protocols/bgp/utils/test_bgp.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/18_SCTP_DST_IPv4.json', 'os_ken/tests/switch/of14/match/38_TUNNEL_ID_Mask.json', 'os_ken/topology/event.py', 'ryu/tests/unit/lib/ofctl_json/of12/lib-ofctl-ofp_queue_get_config_request.packet.json', 'ryu/tests/integrated/vrrp_common.py', 'ryu/services/protocols/bgp/bgpspeaker.py', 'os_ken/tests/switch/of13/action/25_SET_FIELD/25_ARP_THA.json', 'os_ken/services/protocols/bgp/operator/commands/show/count.py', 'ryu/ofproto/inet.py', 'os_ken/tests/unit/ofproto/json/of13/4-19-ofp_role_request.packet.json', 'os_ken/tests/packet_data/of14/5-29-ofp_port_stats_request.packet', 'os_ken/tests/switch/of14/meter/01_DROP_00_KBPS_01_10M.json', 'os_ken/app/ofctl/__init__.py', 'os_ken/tests/unit/app/ofctl_rest_json/of13.json', 'ryu/lib/packet/pbb.py', 'ryu/tests/unit/lib/test_mod/eee.py', 'os_ken/tests/packet_data/of14/5-60-ofp_experimenter_reply.packet', 'os_ken/tests/switch/of13/match/12_IPV4_DST.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/18_SCTP_DST_IPv6.json', 'os_ken/tests/unit/ofproto/json/of14/5-47-ofp_meter_stats_request.packet.json', 'ryu/services/protocols/ovsdb/manager.py', 'ryu/services/protocols/bgp/api/prefix.py', 'os_ken/tests/unit/ofproto/json/of14/5-64-ofp_queue_desc_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_desc_request.packet.json', 'os_ken/services/protocols/zebra/__init__.py', 'os_ken/ofproto/ofproto_v1_4_parser.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-flow_monitor_request.packet', 'os_ken/tests/packet_data/of14/5-46-ofp_meter_config_reply.packet', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_ct_nat_v6.packet', 'os_ken/tests/packet_data/of12/3-0-ofp_desc_stats_reply.packet', 'os_ken/tests/switch/of13/action/19_PUSH_MPLS.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/24_ARP_SHA.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_sample.packet', 'os_ken/tests/packet_data/of14/5-9-ofp_get_config_reply.packet', 'os_ken/tests/unit/ofproto/json/of13/4-35-ofp_queue_get_config_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of12/3-30-ofp_port_stats_reply.packet.json', 'os_ken/app/rest_firewall.py', 'os_ken/services/protocols/bgp/operator/commands/responses.py', 'ryu/tests/run_tests.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_dec_mpls_ttl.packet', 'os_ken/tests/switch/of13/action/27_POP_PBB.json', 'os_ken/services/protocols/bgp/operator/views/fields.py', 'ryu/ofproto/nicira_ext.py', 'os_ken/tests/unit/ofproto/json/of14/5-0-ofp_desc_reply.packet.json', 'os_ken/tests/packet_data/of14/5-48-ofp_meter_stats_reply.packet', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv6_UDP.json', 'ryu/tests/unit/packet/test_ethernet.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-error_msg.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-63-onf_flow_monitor_request.packet.json', 'os_ken/tests/switch/of13/match/02_METADATA.json', 'os_ken/tests/switch/of14/match/23_ARP_TPA.json', 'ryu/tests/unit/services/protocols/bgp/test_bgpspeaker.py', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-ofp_table_features_request.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_desc_reply.packet.json', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-queue_desc_request.packet.json', 'os_ken/tests/unit/packet/test_icmpv6.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-desc_request.packet.json', 'os_ken/services/protocols/vrrp/monitor_linux.py', 'os_ken/tests/unit/ofproto/json/of10/libofproto-OFP10-ofp_packet_out_packet_library.packet.json', 'os_ken/tests/switch/of14/action/25_SET_FIELD/19_ICMPV4_TYPE.json', 'os_ken/tests/switch/of10/action/00_OUTPUT.json', 'os_ken/tests/unit/ofproto/json/of12/3-26-ofp_aggregate_stats_reply.packet.json', 'ryu/cmd/rpc_cli.py', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_l2vpn.pcap', 'os_ken/tests/packet_data/of13/4-22-ofp_port_mod.packet', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-flow_removed.packet.json', 'os_ken/tests/packet_data/of15/libofproto-OFP15-group_stats_reply.packet', 'ryu/tests/unit/lib/test_mod/__init__.py', 'os_ken/tests/packet_data/bgp4/evpn_esi_l2_bridge.pcap', 'ryu/tests/unit/services/protocols/bgp/test_peer.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/22_ARP_SPA.json', 'os_ken/tests/unit/app/test_wsgi.py', 'ryu/lib/packet/afi.py', 'ryu/ofproto/__init__.py', 'os_ken/services/protocols/zebra/db/route.py', 'ryu/tests/unit/lib/ofctl_json/of14/5-54-ofp_table_features_reply.packet.json', 'os_ken/tests/switch/of10/match/11_TP_DST_IPv4_TCP.json', 'os_ken/tests/packet_data/of12/3-22-ofp_port_mod.packet', 'os_ken/app/conf_switch_key.py', 'os_ken/tests/packet_data/of14/5-22-ofp_port_mod.packet', 'os_ken/tests/unit/ofproto/json/of13/4-43-ofp_get_async_reply.packet.json', 'ryu/app/simple_switch_stp.py', 'os_ken/tests/packet_data/of15/libofproto-OFP15-table_status.packet', 'os_ken/tests/switch/of14/match/16_UDP_DST_IPv6.json', 'ryu/controller/handler.py', 'ryu/tests/unit/ofproto/test_parser_v13.py', 'os_ken/tests/unit/ofproto/test_ofproto_common.py', 'os_ken/tests/unit/ofproto/json/of15/lib-ofctl-OFP15-flow_desc_reply.packet.json', 'ryu/tests/unit/packet/test_lldp.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-flow_stats_request.packet.json', 'ryu/tests/unit/packet/test_igmp.py', 'os_ken/tests/unit/ofproto/json/of13/ovs-ofctl-of13-match_pkt_mark_masked.packet.json', 'ryu/lib/ofctl_v1_4.py', 'os_ken/tests/switch/of14/match/02_METADATA_Mask.json', 'ryu/services/protocols/vrrp/monitor.py', 'ryu/tests/unit/lib/ofctl_json/of12/3-22-ofp_port_mod.packet.json', 'os_ken/tests/packet_data/of13/ovs-ofctl-of13-action_stack_pop.packet', 'os_ken/tests/packet_data/bgp4/flowspec_action_traffic_marking.pcap', 'os_ken/tests/packet_data/of14/5-2-ofp_flow_mod.packet', 'os_ken/app/simple_switch_rest_13.py', 'os_ken/tests/packet_data/of10/ovs-ofctl-of10-action_set_mpls_ttl.packet', 'os_ken/tests/switch/of13/match/15_UDP_SRC_IPv4.json', 'os_ken/tests/packet_data/bgp4/flowspec_nlri_ipv6.pcap', 'os_ken/tests/packet_data/pcap/zebra_v2.pcap', 'os_ken/tests/unit/ofproto/json/of14/5-54-ofp_table_features_reply.packet.json', 'ryu/tests/unit/services/protocols/bgp/utils/test_validation.py', 'os_ken/tests/unit/ofproto/json/of14/5-19-ofp_role_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-echo_request.packet.json', 'os_ken/tests/packet_data/of13/4-33-ofp_group_desc_request.packet', 'os_ken/log.py', 'os_ken/tests/unit/ofproto/json/of13/libofproto-OFP13-ofp_packet_out_packet_library.packet.json', 'os_ken/tests/switch/of14/action/26_PUSH_PBB.json', 'os_ken/tests/unit/ofproto/json/of13/4-62-ofp_experimenter_reply.packet.json', 'os_ken/tests/switch/of13/action/16_DEC_MPLS_TTL.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-get_async_request.packet.json', 'os_ken/tests/unit/ofproto/__init__.py', 'os_ken/tests/unit/ofproto/json/of14/5-13-ofp_echo_request.packet.json', 'os_ken/tests/unit/ofproto/json/of13/4-61-ofp_experimenter_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-experimenter_reply.packet.json', 'os_ken/tests/switch/of14/action/15_SET_MPLS_TTL.json', 'ryu/tests/unit/ofproto/test_parser_compat.py', 'os_ken/tests/packet_data/of14/5-10-ofp_hello.packet', 'os_ken/tests/switch/of10/match/10_TP_SRC_IPv6_TCP.json', 'os_ken/flags.py', 'os_ken/tests/switch/of14/action/25_SET_FIELD/34_MPLS_LABEL.json', 'os_ken/tests/switch/of14/match/10_IP_PROTO_IPv4.json', 'os_ken/ofproto/ofproto_v1_4.py', 'ryu/tests/unit/app/test_tester.py', 'os_ken/tests/unit/ofproto/json/of13/4-15-ofp_error_msg.packet.json', 'os_ken/tests/switch/of14/match/17_SCTP_SRC_IPv4.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/14_TCP_DST_IPv6.json', 'os_ken/tests/switch/of13/match/28_IPV6_FLABEL.json', 'os_ken/tests/unit/ofproto/json/of14/5-39-ofp_error_msg_experimenter.packet.json', 'os_ken/tests/mininet/packet_lib/arp/ARP_reply.mn', 'os_ken/tests/unit/ofproto/json/of14/5-25-ofp_aggregate_stats_request.packet.json', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-port_status.packet.json', 'os_ken/tests/packet_data/of13/4-5-ofp_features_request.packet', 'os_ken/tests/switch/of14/match/22_ARP_SPA.json', 'os_ken/tests/integrated/__init__.py', 'os_ken/tests/switch/of13/meter/02_DSCP_REMARK_01_PKTPS_02_10000.json', 'os_ken/tests/switch/of13/action/25_SET_FIELD/09_IP_ECN_IPv6.json', 'ryu/tests/unit/packet/test_cfm.py', 'os_ken/tests/packet_data/of13/libofproto-OFP13-hello.packet', 'os_ken/tests/switch/of13/action/11_COPY_TTL_OUT.json', 'os_ken/tests/unit/ofproto/json/of14/5-8-ofp_get_config_request.packet.json', 'os_ken/tests/unit/ofproto/json/of10/ovs-ofctl-of10-action_set_mpls_label.packet.json', 'os_ken/tests/unit/ofproto/json/of14/5-63-ofp_queue_desc_request.packet.json', 'ryu/services/protocols/bgp/operator/internal_api.py', 'os_ken/ofproto/ofproto_v1_2_parser.py', 'os_ken/tests/switch/of13/group/00_ALL.json', 'os_ken/cmd/manager.py', 'os_ken/services/protocols/bgp/utils/validation.py', 'ryu/services/protocols/bgp/peer.py', 'os_ken/tests/unit/ofproto/json/of15/libofproto-OFP15-group_desc_request.packet.json', 'os_ken/tests/packet_data/of12/3-41-ofp_error_msg_experimenter.packet', 'os_ken/tests/packet_data/of12/3-38-ofp_queue_stats_reply.packet', 'os_ken/services/protocols/bgp/info_base/vpnv4fs.py', 'ryu/tests/unit/lib/ofctl_json/of15/libofproto-OFP15-aggregate_stats_request.packet.json']",1896,419becace51d797111b8f23d3592d932be15d100,,,"{ ""flow"": { ""cookie"": 0, ""cookie_mask"": 0, ""flags"": 0, ""match"": {}, ""out_group"": 4294967295, ""out_port"": 4294967295, ""table_id"": 255 } } ",125013,235420
openstack%2Fopenstack-ansible-ops~master~Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b,openstack/openstack-ansible-ops,master,Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b,MNAIO: Fix file-backed VM deployment,MERGED,2018-09-26 13:01:08.000000000,2018-09-26 21:43:44.000000000,2018-09-26 21:43:44.000000000,"[{'_account_id': 6816}, {'_account_id': 7414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 13:01:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/133ccf273abf51c46cf1dcdadfd55cb3efa6096a', 'message': ""MNAIO: Fix file-backed VM deployment\n\nRecent patches broke the file-backed VM deployment.\nThis patch fixes it again. It also ensures that the\ncleanup of VM's removes any VM's running, rather than\nthe active inventory.\n\nChange-Id: Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b\n""}, {'number': 2, 'created': '2018-09-26 13:38:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/fe442042e9698fc0d5ac7dca50e86ed77f4877cf', 'message': ""MNAIO: Fix file-backed VM deployment\n\nRecent patches broke the file-backed VM deployment.\nThis patch fixes it again. It also ensures that the\ncleanup of VM's removes any VM's running, rather than\nthe active inventory.\n\nChange-Id: Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b\n""}, {'number': 3, 'created': '2018-09-26 13:51:07.000000000', 'files': ['multi-node-aio/playbooks/setup-host.yml', 'multi-node-aio/playbooks/deploy-vms.yml', 'multi-node-aio/playbooks/kvm/kvm-vm.xml.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/ddcef522d4c12d0f3e94c8744b75a95d45f95be1', 'message': ""MNAIO: Fix file-backed VM deployment\n\nRecent patches broke the file-backed VM deployment.\nThis patch fixes it again. It also ensures that the\ncleanup of VM's removes any VM's running, rather than\nthe active inventory.\n\nChange-Id: Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b\n""}]",0,605413,ddcef522d4c12d0f3e94c8744b75a95d45f95be1,10,3,3,6816,,,0,"MNAIO: Fix file-backed VM deployment

Recent patches broke the file-backed VM deployment.
This patch fixes it again. It also ensures that the
cleanup of VM's removes any VM's running, rather than
the active inventory.

Change-Id: Ic1cc887bf61162a8c8d96dd53f6db9583c4c089b
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/13/605413/3 && git format-patch -1 --stdout FETCH_HEAD,['multi-node-aio/playbooks/deploy-vms.yml'],1,133ccf273abf51c46cf1dcdadfd55cb3efa6096a,," environment: ""{{ deployment_environment_variables | default({}) }}"" tags: - deploy-vms tasks: - name: Get info about existing virt storage pools - name: Get info about existing VM's virt: command: list_vms register: _virt_list - name: Stop all running VM's virt: name: ""{{ item }}"" with_items: ""{{ _virt_list.list_vms }}"" - name: Delete any LV's related to running VM's lv: ""{{ item }}"" with_items: ""{{ _virt_list.list_vms }}"" - name: Delete any disk images related to running VM's file: path: ""{{ _virt_pools.pools.default.path | default('/data/images') }}/{{ item }}.img"" with_items: ""{{ _virt_list.list_vms }}"" - name: Undefine all running VM's virt: name: ""{{ item }}"" with_items: ""{{ _virt_list.list_vms }}"" paths: ""{{ _virt_pools.pools.default.path | default('/data/images') }}"" - name: Prepare VM storage hosts: pxe_servers gather_facts: no environment: ""{{ deployment_environment_variables | default({}) }}"" tags: - deploy-vms tasks: - name: Create VM LV lvol: vg: ""{{ default_vm_disk_vg }}"" lv: ""{{ server_hostname }}"" size: ""{{ default_vm_storage }}"" when: - server_vm | default(false) | bool - default_vm_disk_mode == ""lvm"" delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Create VM Disk Image command: >- qemu-img create -f qcow2 {% if hostvars[item]['vm_use_snapshot'] | bool %} -b {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}-base.img {% endif %} {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}.img {{ default_vm_storage }}m when: - server_vm | default(false) | bool - default_vm_disk_mode == ""file"" delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Prepare file-based disk images hosts: vm_hosts gather_facts: yes environment: ""{{ deployment_environment_variables | default({}) }}"" tags: - deploy-vms tasks: --add {{ virt_pools.pools.default.path | default('/data/images') }}/{{ hostvars[item]['server_hostname'] }}.img - name: Prepare VM storage hosts: pxe_servers gather_facts: no environment: ""{{ deployment_environment_variables | default({}) }}"" tags: - deploy-vms tasks: connection: local"," tasks: - name: Get info about the virt storage pools- name: Prepare & Create VMs hosts: pxe_servers gather_facts: no environment: ""{{ deployment_environment_variables | default({}) }}"" tags: - deploy-vms tasks: - name: Stop running VMs virt: name: ""{{ server_hostname }}"" when: - server_vm | default(false) | bool delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Delete VM LV lv: ""{{ server_hostname }}"" when: - server_vm | default(false) | bool delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Delete VM Disk Image file: path: ""{{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}.img"" when: - server_vm | default(false) | bool delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Undefine the VM virt: name: ""{{ server_hostname }}"" when: - server_vm | default(false) | bool delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Create VM LV lvol: vg: ""{{ default_vm_disk_vg }}"" lv: ""{{ server_hostname }}"" size: ""{{ default_vm_storage }}"" when: - server_vm | default(false) | bool - default_vm_disk_mode == ""lvm"" delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" paths: ""{{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}"" delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" - name: Create VM Disk Image command: >- qemu-img create -f qcow2 {% if vm_use_snapshot | bool %} -b {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}-base.img {% endif %} {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ server_hostname }}.img {{ default_vm_storage }}m when: - server_vm | default(false) | bool delegate_to: ""{{ item }}"" with_items: ""{{ groups['vm_hosts'] }}"" --add {{ hostvars[item]['virt_pools'].pools.default.path | default('/data/images') }}/{{ hostvars[item]['server_hostname'] }}.img",74,64
openstack%2Fopenstackdocstheme~master~I4140f62a328debf81703cddd17dd6364b5eab479,openstack/openstackdocstheme,master,I4140f62a328debf81703cddd17dd6364b5eab479,Make root title customizable,MERGED,2018-09-25 11:55:39.000000000,2018-09-26 21:06:27.000000000,2018-09-26 21:06:27.000000000,"[{'_account_id': 308}, {'_account_id': 2472}, {'_account_id': 4257}, {'_account_id': 6547}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 11:55:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/8df4c09e163aff34328d7c0ffec854fd2682f568', 'message': 'Make root title customizable\n\nThe theme displays ""OpenStack Docs:"" in the title and ""Docs home""\nin the tooltip, which makes it hard to reuse for other websites\n(including the governance website). This patch makes the root title\n(""Docs"" by default) configurable.\n\nChange-Id: I4140f62a328debf81703cddd17dd6364b5eab479\n'}, {'number': 2, 'created': '2018-09-26 13:27:11.000000000', 'files': ['openstackdocstheme/theme/openstackdocs/sidebartoc.html', 'doc/source/index.rst', 'openstackdocstheme/theme/openstackdocs/layout.html', 'openstackdocstheme/theme/openstackdocs/theme.conf'], 'web_link': 'https://opendev.org/openstack/openstackdocstheme/commit/034683f12dea7410a69228959c8661497d918b6a', 'message': 'Make root title customizable\n\nThe theme displays ""OpenStack Docs:"" in the title and ""Docs home""\nin the tooltip, which makes it hard to reuse for other websites\n(including the governance website). This patch makes the root title\n(""OpenStack Docs"" by default) configurable.\n\nChange-Id: I4140f62a328debf81703cddd17dd6364b5eab479\n'}]",4,605048,034683f12dea7410a69228959c8661497d918b6a,17,6,2,308,,,0,"Make root title customizable

The theme displays ""OpenStack Docs:"" in the title and ""Docs home""
in the tooltip, which makes it hard to reuse for other websites
(including the governance website). This patch makes the root title
(""OpenStack Docs"" by default) configurable.

Change-Id: I4140f62a328debf81703cddd17dd6364b5eab479
",git fetch https://review.opendev.org/openstack/openstackdocstheme refs/changes/48/605048/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstackdocstheme/theme/openstackdocs/sidebartoc.html', 'doc/source/index.rst', 'openstackdocstheme/theme/openstackdocs/layout.html', 'openstackdocstheme/theme/openstackdocs/theme.conf']",4,8df4c09e163aff34328d7c0ffec854fd2682f568,support-governance,root_title = Docs,,13,2
openstack%2Frequirements~stable%2Fqueens~Iad7470618cc10394ef9bce5d557babb8c56ce95a,openstack/requirements,stable/queens,Iad7470618cc10394ef9bce5d557babb8c56ce95a,Bump ovsbdapp to 0.12.0 in Queens,ABANDONED,2018-08-29 09:12:47.000000000,2018-09-26 21:05:33.000000000,,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-29 09:12:47.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/eeb02e9e47a6104d14c2a721a595a23d4e400167', 'message': 'Bump ovsbdapp to 0.12.0 in Queens\n\nChange-Id: Iad7470618cc10394ef9bce5d557babb8c56ce95a\nRelated-bug: #1752897\n'}]",0,597431,eeb02e9e47a6104d14c2a721a595a23d4e400167,4,2,1,23804,,,0,"Bump ovsbdapp to 0.12.0 in Queens

Change-Id: Iad7470618cc10394ef9bce5d557babb8c56ce95a
Related-bug: #1752897
",git fetch https://review.opendev.org/openstack/requirements refs/changes/31/597431/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,eeb02e9e47a6104d14c2a721a595a23d4e400167,bug/1752897,ovsdbapp===0.12.0,ovsdbapp===0.10.1,1,1
openstack%2Frequirements~master~I0e3364265511aea9a0757fc8d42e05fdf9817f1e,openstack/requirements,master,I0e3364265511aea9a0757fc8d42e05fdf9817f1e,Add Octavia to global requirements,ABANDONED,2018-08-01 14:21:39.000000000,2018-09-26 21:04:47.000000000,,"[{'_account_id': 2472}, {'_account_id': 11628}, {'_account_id': 13438}, {'_account_id': 14288}, {'_account_id': 20363}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-01 14:21:39.000000000', 'files': ['global-requirements.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/0e36fe6a6873be48d49a753806c8255b2d93027c', 'message': 'Add Octavia to global requirements\n\nOctavia project is missing from global requirements while vmware-nsx\nis not dependant on it.\n\nChange-Id: I0e3364265511aea9a0757fc8d42e05fdf9817f1e\n'}]",0,587836,0e36fe6a6873be48d49a753806c8255b2d93027c,19,6,1,13438,,,0,"Add Octavia to global requirements

Octavia project is missing from global requirements while vmware-nsx
is not dependant on it.

Change-Id: I0e3364265511aea9a0757fc8d42e05fdf9817f1e
",git fetch https://review.opendev.org/openstack/requirements refs/changes/36/587836/1 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,0e36fe6a6873be48d49a753806c8255b2d93027c,,octavia # Apache-2.0,,1,0
openstack%2Fnova~master~Iaf29b9e7a92705ac8a2e7ef338b92f7f1203506d,openstack/nova,master,Iaf29b9e7a92705ac8a2e7ef338b92f7f1203506d,Ignore VirtDriverNotReady in _sync_power_states periodic task,MERGED,2018-09-21 14:49:17.000000000,2018-09-26 20:58:46.000000000,2018-09-26 20:51:52.000000000,"[{'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10343}, {'_account_id': 10385}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-21 14:49:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3f41127d2f4649bf88d2133110b79dc07c3906c3', 'message': 'Ignore VirtDriverNotReady in _sync_power_states periodic task\n\nChange Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f introduced\na new VirtDriverNotReady exception which the ironic driver raises\nwhen asked to retrieve a list of nodes and ironic-api is not\navailable, like if nova-compute is started before ironic-api.\nThis is normal and meant to be self-healing, but we can get it\nin other periodic tasks besides update_available_resource which\nleads to ugly exception traces on startup in the logs. This adds\nhandling for the exception in the _sync_power_states periodic\ntask.\n\nChange-Id: Iaf29b9e7a92705ac8a2e7ef338b92f7f1203506d\nCloses-Bug: #1793768\n'}, {'number': 2, 'created': '2018-09-22 16:30:23.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/6eb32bc40340fed631b9fce1245326e0ebc1c540', 'message': 'Ignore VirtDriverNotReady in _sync_power_states periodic task\n\nChange Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f introduced\na new VirtDriverNotReady exception which the ironic driver raises\nwhen asked to retrieve a list of nodes and ironic-api is not\navailable, like if nova-compute is started before ironic-api.\nThis is normal and meant to be self-healing, but we can get it\nin other periodic tasks besides update_available_resource which\nleads to ugly exception traces on startup in the logs. This adds\nhandling for the exception in the _sync_power_states periodic\ntask.\n\nChange-Id: Iaf29b9e7a92705ac8a2e7ef338b92f7f1203506d\nCloses-Bug: #1793768\n'}]",2,604376,6eb32bc40340fed631b9fce1245326e0ebc1c540,35,17,2,6873,,,0,"Ignore VirtDriverNotReady in _sync_power_states periodic task

Change Ib0ec1012b74e9a9e74c8879f3feed5f9332b711f introduced
a new VirtDriverNotReady exception which the ironic driver raises
when asked to retrieve a list of nodes and ironic-api is not
available, like if nova-compute is started before ironic-api.
This is normal and meant to be self-healing, but we can get it
in other periodic tasks besides update_available_resource which
leads to ugly exception traces on startup in the logs. This adds
handling for the exception in the _sync_power_states periodic
task.

Change-Id: Iaf29b9e7a92705ac8a2e7ef338b92f7f1203506d
Closes-Bug: #1793768
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/604376/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py']",2,3f41127d2f4649bf88d2133110b79dc07c3906c3,bug/1793768," try: num_vm_instances = self.driver.get_num_instances() except exception.VirtDriverNotReady as ex: # If the virt driver is not ready, like ironic-api not being up # yet in the case of ironic, just log it and exit. LOG.info('Skipping _sync_power_states periodic task due to: %s', six.text_type(ex)) return ", num_vm_instances = self.driver.get_num_instances(),23,1
openstack%2Fcharm-nova-cloud-controller~master~I20548118092a4480f37c7ab7e9d60e72e299989b,openstack/charm-nova-cloud-controller,master,I20548118092a4480f37c7ab7e9d60e72e299989b,Get glance v1 client for icehouse.,MERGED,2018-09-25 09:23:32.000000000,2018-09-26 20:53:15.000000000,2018-09-26 20:53:15.000000000,"[{'_account_id': 12549}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 09:23:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/65402060cb96f130a1b1b993d53d3277d30c0213', 'message': 'Set cirros image virt type in amulet test\n\nPreviously the image virt type was qemu and the compute node virt\ntype was kvm. This works for deployments prior to rocky but in\nrocky this causes the image type filter to return no valid hosts.\n\nChange-Id: I20548118092a4480f37c7ab7e9d60e72e299989b\n'}, {'number': 2, 'created': '2018-09-26 11:16:25.000000000', 'files': ['tests/basic_deployment.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/9cdf1baccd19ef944923e8dfb520b65c2e9eb5d3', 'message': ""Get glance v1 client for icehouse.\n\nPreviously the image virt type was qemu and the compute node virt\ntype was kvm. This works for deployments prior to rocky but in\nrocky this causes the image type filter to return no valid hosts.\nAn update to charmhelpers has removed the default behaviour of\nsetting the virt type to 'qemu' by default.\n\nDue to a bug in icehouse updating glance image properties using\nthe v2 api fails (See Bug #1371559) so for icehouse deploys\nget a v1 client.\n\nChange-Id: I20548118092a4480f37c7ab7e9d60e72e299989b\n""}]",0,605016,9cdf1baccd19ef944923e8dfb520b65c2e9eb5d3,18,5,2,12549,,,0,"Get glance v1 client for icehouse.

Previously the image virt type was qemu and the compute node virt
type was kvm. This works for deployments prior to rocky but in
rocky this causes the image type filter to return no valid hosts.
An update to charmhelpers has removed the default behaviour of
setting the virt type to 'qemu' by default.

Due to a bug in icehouse updating glance image properties using
the v2 api fails (See Bug #1371559) so for icehouse deploys
get a v1 client.

Change-Id: I20548118092a4480f37c7ab7e9d60e72e299989b
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/16/605016/2 && git format-patch -1 --stdout FETCH_HEAD,['tests/basic_deployment.py'],1,65402060cb96f130a1b1b993d53d3277d30c0213,bug/1371559," image = u.create_cirros_image(self.glance, ""cirros-image"", hypervisor_type='kvm')"," image = u.create_cirros_image(self.glance, ""cirros-image"")",2,1
openstack%2Ftempest~master~Iac6ba71496e20b6724a6a2ca4ec2beb42f2a58c8,openstack/tempest,master,Iac6ba71496e20b6724a6a2ca4ec2beb42f2a58c8,fix: Re-clarify unit test REVIEWING documentation,MERGED,2018-09-21 19:35:46.000000000,2018-09-26 20:52:00.000000000,2018-09-26 20:51:59.000000000,"[{'_account_id': 5689}, {'_account_id': 6167}, {'_account_id': 10385}, {'_account_id': 22348}, {'_account_id': 27078}, {'_account_id': 28842}]","[{'number': 1, 'created': '2018-09-21 19:35:46.000000000', 'files': ['REVIEWING.rst'], 'web_link': 'https://opendev.org/openstack/tempest/commit/a7365ae219d03bec5cc2477298fba6356b51180d', 'message': 'fix: Re-clarify unit test REVIEWING documentation\n\nThis patch set corrects some misleading documentation under ""Unit\nTests"" section in REVIEWING.rst.\n\nIt currently claims that service clients do not require unit test\ncoverage -- but this is false. This is because Tempest now places\nall of its service clients in tempest.lib. And as per\nhttps://docs.openstack.org/tempest/latest/library.html#testing it\nis required to add unit tests for all service client interfaces.\n\nThus this makes the documentation language clear that service clients\nrequire unit tests.\n\nChange-Id: Iac6ba71496e20b6724a6a2ca4ec2beb42f2a58c8\n'}]",0,604457,a7365ae219d03bec5cc2477298fba6356b51180d,10,6,1,23186,,,0,"fix: Re-clarify unit test REVIEWING documentation

This patch set corrects some misleading documentation under ""Unit
Tests"" section in REVIEWING.rst.

It currently claims that service clients do not require unit test
coverage -- but this is false. This is because Tempest now places
all of its service clients in tempest.lib. And as per
https://docs.openstack.org/tempest/latest/library.html#testing it
is required to add unit tests for all service client interfaces.

Thus this makes the documentation language clear that service clients
require unit tests.

Change-Id: Iac6ba71496e20b6724a6a2ca4ec2beb42f2a58c8
",git fetch https://review.opendev.org/openstack/tempest refs/changes/57/604457/1 && git format-patch -1 --stdout FETCH_HEAD,['REVIEWING.rst'],1,a7365ae219d03bec5cc2477298fba6356b51180d,unit-test-docs,"API and scenario tests aren't required to have unit tests since they should be self-verifying by running them in the gate. All service clients, on the other hand, `must have`_ unit tests, as they belong to ``tempest/lib``. .. _must have: https://docs.openstack.org/tempest/latest/library.html#testing","Tests, and service clients aren't required to have unit tests since they should be self verifying by running them in the gate.",5,2
openstack%2Fnova~master~I1e193237e9aec05395cd2760d96e70db7791409b,openstack/nova,master,I1e193237e9aec05395cd2760d96e70db7791409b,api-ref: add 'migrations' param to GET /os-migrations,MERGED,2018-09-25 21:07:41.000000000,2018-09-26 20:51:45.000000000,2018-09-26 20:51:45.000000000,"[{'_account_id': 5754}, {'_account_id': 6062}, {'_account_id': 6167}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14384}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26311}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-25 21:07:41.000000000', 'files': ['nova/tests/functional/api_sample_tests/api_samples/os-migrations/migrations-get.json.tpl', 'api-ref/source/os-migrations.inc', 'doc/api_samples/os-migrations/migrations-get.json', 'nova/tests/functional/api_sample_tests/test_migrations.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/183ba80ec586b8661967c3a5eeb1bb44838276bc', 'message': 'api-ref: add \'migrations\' param to GET /os-migrations\n\nThe response parameter table for the GET /os-migrations\nAPI reference was missing the top level ""migrations""\nparameter which is the list of migration objects.\n\nWhile in here, fix the fake ""Done"" status to ""done""\nin the sample. There is nothing in nova that uses a\nstatus of ""Done"". The evacuate operation uses ""done"".\n\nChange-Id: I1e193237e9aec05395cd2760d96e70db7791409b\n'}]",1,605232,183ba80ec586b8661967c3a5eeb1bb44838276bc,19,15,1,6873,,,0,"api-ref: add 'migrations' param to GET /os-migrations

The response parameter table for the GET /os-migrations
API reference was missing the top level ""migrations""
parameter which is the list of migration objects.

While in here, fix the fake ""Done"" status to ""done""
in the sample. There is nothing in nova that uses a
status of ""Done"". The evacuate operation uses ""done"".

Change-Id: I1e193237e9aec05395cd2760d96e70db7791409b
",git fetch https://review.opendev.org/openstack/nova refs/changes/32/605232/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/functional/api_sample_tests/api_samples/os-migrations/migrations-get.json.tpl', 'api-ref/source/os-migrations.inc', 'doc/api_samples/os-migrations/migrations-get.json', 'nova/tests/functional/api_sample_tests/test_migrations.py']",4,183ba80ec586b8661967c3a5eeb1bb44838276bc,api-ref-os-migrations," 'status': 'done', 'status': 'done',"," 'status': 'Done', 'status': 'Done',",7,6
openstack%2Fnova~master~I142de27f045ddb4c298ecae5a35bcb98ac863e3d,openstack/nova,master,I142de27f045ddb4c298ecae5a35bcb98ac863e3d,cells: Be explicit in docs about service restarts,MERGED,2018-09-19 08:08:52.000000000,2018-09-26 20:51:35.000000000,2018-09-26 20:51:34.000000000,"[{'_account_id': 3031}, {'_account_id': 4393}, {'_account_id': 6167}, {'_account_id': 7166}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 18551}, {'_account_id': 20676}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-19 08:08:52.000000000', 'files': ['doc/source/user/cells.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/0e0d5bf1c8969a324712bcd36407458b567e5936', 'message': 'cells: Be explicit in docs about service restarts\n\nSome operators could be confused if they start conductor workers with an\nimcomplete setup. Just adding a clear note on the dependency.\n\nChange-Id: I142de27f045ddb4c298ecae5a35bcb98ac863e3d\n'}]",1,603588,0e0d5bf1c8969a324712bcd36407458b567e5936,18,14,1,7166,,,0,"cells: Be explicit in docs about service restarts

Some operators could be confused if they start conductor workers with an
imcomplete setup. Just adding a clear note on the dependency.

Change-Id: I142de27f045ddb4c298ecae5a35bcb98ac863e3d
",git fetch https://review.opendev.org/openstack/nova refs/changes/88/603588/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/cells.rst'],1,0e0d5bf1c8969a324712bcd36407458b567e5936,doc_warning_for_cells," .. note:: Since Nova services make use of both configuration file and some databases records, starting or restarting those services with an incomplete configuration could lead to an incorrect deployment. Please only restart the services once you are done with the described steps below. ", ,9,1
openstack%2Fnova~master~If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442,openstack/nova,master,If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442,Transform missing delete notifications,MERGED,2016-12-13 16:20:45.000000000,2018-09-26 20:51:26.000000000,2018-09-26 20:51:26.000000000,"[{'_account_id': 3}, {'_account_id': 782}, {'_account_id': 6125}, {'_account_id': 7634}, {'_account_id': 8556}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9555}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 13915}, {'_account_id': 14384}, {'_account_id': 14571}, {'_account_id': 14595}, {'_account_id': 15286}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17920}, {'_account_id': 18602}, {'_account_id': 18603}, {'_account_id': 20040}, {'_account_id': 20217}, {'_account_id': 20411}, {'_account_id': 20581}, {'_account_id': 21111}, {'_account_id': 21239}, {'_account_id': 21784}, {'_account_id': 22348}, {'_account_id': 23294}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 27781}]","[{'number': 1, 'created': '2016-12-13 16:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/910fcbf433e605f66f501a099f348fb42b8d5434', 'message': 'Transform missing delete notifications\n\nThe XXX patch only considered instance delete in the happy case\nwhen the instance is scheduled to a compute successfully and the\ncompute is available when the delete action is executed.\nIf the instance is never scheduled to a compute or the compute\nis not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 2, 'created': '2016-12-15 12:43:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a0430f200683a7cc3d51749895d3057c0fafdac6', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 3, 'created': '2016-12-15 13:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0ece685047a2532694b70be818200fb025df8418', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 4, 'created': '2017-01-05 08:40:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/184e89f37b78839a435c59d2cdfb27e8ddd6504e', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 5, 'created': '2017-01-05 17:19:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/5fa73772e25861cef596ad0bf76e639c467c73a4', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 6, 'created': '2017-01-06 16:04:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce8cb2122dd2bf42cbf992b6c8ad9c05ce425b40', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-ocata\n'}, {'number': 7, 'created': '2017-02-09 16:25:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cad60baae6a0490dbb70b78177e0ab75734f10ba', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 8, 'created': '2017-02-09 16:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d7ea0916a1ac6596ecabba5564b268b19581e469', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 9, 'created': '2017-02-15 16:09:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9fc3d231cafe4dcd95c4efc2dd99b419f2c32e3c', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 10, 'created': '2017-02-23 20:42:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b81adb58f23ef86bad4bdd984c52b6b194a0d84a', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 11, 'created': '2017-03-02 14:19:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f9874b284b9267342bd0c4936009eed46bd790aa', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 12, 'created': '2017-03-02 14:34:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7ec3d782d35cd53b1519c222d19d11051b57f6e', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 13, 'created': '2017-03-09 17:23:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a55ea2ec7fa20789b4d0bcd4203a4a8a2b785e7c', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 14, 'created': '2017-06-13 16:40:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d2a63ff4d5ec49e524ab9ad02ede96243ed985d1', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 15, 'created': '2017-06-16 15:07:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c7df6cdc089ba57cdf48d8be13859ef4ec7d8a2b', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 16, 'created': '2017-06-22 10:49:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/8b1dac3348f9d80c3e2d7e2ced50f140c7b602a5', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 17, 'created': '2017-06-28 08:29:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/133950f3fe013d604aae0f023e2a875d1ed5bc5c', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 18, 'created': '2017-06-28 11:59:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/10dab237920f159be936b8eab2c79cd5af580e5b', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 19, 'created': '2017-07-10 12:44:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/f99d0dadd2a1f805f490a1ae8a8fe0c58ddfd323', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 20, 'created': '2017-07-17 10:18:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9c24ff0e019f79d598491c5e891b0b96ed188e5c', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 21, 'created': '2017-07-25 13:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd94ac18b68d536a14b6586f714ec1f6960f4106', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 22, 'created': '2017-07-25 17:13:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea48ad223020ca95ce1dba1aca4f400061f81ae4', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 23, 'created': '2017-07-27 08:25:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/85a22d9819b9131e26dbb041fa10e7500fc1daaa', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-pike\n'}, {'number': 24, 'created': '2017-09-05 12:37:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bf21954229304a9496318fb880366a3a6d417d01', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 25, 'created': '2017-09-07 13:03:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4ae49b6ff0836d35447e9c736f4ce60ffef5a929', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 26, 'created': '2017-09-12 17:30:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/baee67880b66fd1dc7b1f1f575c2e66cd26a61a4', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 27, 'created': '2017-09-25 16:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d3effebba75798d5bf7b7ca1f3f6f4f2e308a65e', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 28, 'created': '2017-09-26 11:04:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0fea3d0dda65f92fcbfd8453825606fe71a73f1f', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 29, 'created': '2017-11-21 15:04:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bb0f2b2b0318ac1cfeba70730f8487264fdcce70', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 30, 'created': '2017-11-23 12:10:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2914e7177fe397f8ab55badfc098acc64696d0f0', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 31, 'created': '2017-11-23 14:58:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/318ee244e329c4c5ccfbff83330bb3912ac9a37d', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 32, 'created': '2017-12-14 11:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c228d2f96234da6216bd3e5d2441915b83b9fac3', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 33, 'created': '2017-12-18 17:37:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/88ef03d232a031aa893717f5c2fa43276b716e1f', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 34, 'created': '2018-01-08 13:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d60fbd01012fceee6ebc5d845be1a1f4b5c6758c', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-queens\n'}, {'number': 35, 'created': '2018-03-07 14:31:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3138556c402bdc0d64835b066cc121223e4aefae', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 36, 'created': '2018-04-25 17:28:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/042f92730a7980a50053864e1a63b9c4824a711e', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 37, 'created': '2018-05-14 14:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/563683a48286e98e752af47707b6675954db6c3a', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 38, 'created': '2018-07-02 13:31:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fc92474e0e1213e17512f4f5018c15803671ad3e', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 39, 'created': '2018-07-03 08:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/65be643683d4c216ef284085249cc86336d8f3a6', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 40, 'created': '2018-07-04 15:20:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/bc09251bdfe7c8460d398b51bbb6722a9cc95f58', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 41, 'created': '2018-07-10 08:17:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b3428e62db3e46a682af7f5958799f0312b47042', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 42, 'created': '2018-07-17 13:18:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/811f52d8059de30ce7fd1545d474cdb66cc73be7', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 43, 'created': '2018-07-23 13:13:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/731b8a64165c6edbea471a2483a5a5c530fa80b9', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-rocky\n'}, {'number': 44, 'created': '2018-08-29 11:40:53.000000000', 'files': ['doc/notification_samples/instance-delete-end_not_scheduled.json', 'doc/notification_samples/instance-delete-start_not_scheduled.json', 'nova/tests/unit/conductor/test_conductor.py', 'nova/tests/functional/api/client.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'doc/notification_samples/instance-delete-start_compute_down.json', 'nova/tests/unit/compute/test_compute_utils.py', 'nova/tests/unit/compute/test_compute_api.py', 'doc/notification_samples/instance-delete-end_compute_down.json', 'nova/conductor/manager.py', 'nova/tests/unit/utils.py', 'nova/compute/manager.py', 'nova/compute/utils.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/d3097e52b3c5138a1521422dd2cea1c1f4f173da', 'message': 'Transform missing delete notifications\n\nThe Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered\ninstance delete in the happy case when the instance is scheduled to a\ncompute successfully and the compute is available when the delete\naction is executed. If the instance is never scheduled to a compute or\nthe compute is not available when the instance is deleted legacy delete\nnotifications are emitted from different places, compute.api instead of\ncompute.manager. The original patch missed these places.\n\nThere will be subsequent patch(es) handling the same edge cases\nfor soft_delete and force_delete.\n\nChange-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442\nImplements: bp versioned-notification-transformation-stein\n'}]",35,410297,d3097e52b3c5138a1521422dd2cea1c1f4f173da,739,40,44,9708,,,0,"Transform missing delete notifications

The Iddbe50ce0ad3c14562df800bbc09ec5a7e840485 patch only considered
instance delete in the happy case when the instance is scheduled to a
compute successfully and the compute is available when the delete
action is executed. If the instance is never scheduled to a compute or
the compute is not available when the instance is deleted legacy delete
notifications are emitted from different places, compute.api instead of
compute.manager. The original patch missed these places.

There will be subsequent patch(es) handling the same edge cases
for soft_delete and force_delete.

Change-Id: If0693eab2ed31b5fbfe6cbafa5d67b69c2ed8442
Implements: bp versioned-notification-transformation-stein
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/410297/5 && git format-patch -1 --stdout FETCH_HEAD,"['doc/notification_samples/instance-delete-end_not_scheduled.json', 'doc/notification_samples/instance-delete-start_not_scheduled.json', 'nova/tests/functional/notification_sample_tests/notification_sample_base.py', 'nova/tests/unit/compute/test_compute_api.py', 'doc/notification_samples/instance-delete-end_compute_down.json', 'nova/tests/functional/api/client.py', 'nova/tests/functional/notification_sample_tests/test_instance.py', 'nova/tests/unit/compute/test_compute.py', 'doc/notification_samples/instance-delete-start_compute_down.json', 'nova/compute/api.py']",10,910fcbf433e605f66f501a099f348fb42b8d5434,bp/versioned-notification-transformation-stein," if delete_type == 'delete': compute_utils.notify_about_instance_action( context, instance, host=CONF.host, binary='nova-api', action=fields_obj.NotificationAction.DELETE, phase=fields_obj.NotificationPhase.START) if delete_type == 'delete': compute_utils.notify_about_instance_action( context, instance, host=CONF.host, binary='nova-api', action=fields_obj.NotificationAction.DELETE, phase=fields_obj.NotificationPhase.END) if delete_type == 'delete': compute_utils.notify_about_instance_action( context, instance, host=CONF.host, binary='nova-api', action=fields_obj.NotificationAction.DELETE, phase=fields_obj.NotificationPhase.START) if delete_type == 'delete': compute_utils.notify_about_instance_action( context, instance, host=CONF.host, binary='nova-api', action=fields_obj.NotificationAction.DELETE, phase=fields_obj.NotificationPhase.END)",,348,4
openstack%2Frequirements~stable%2Focata~I6312bad9a8c06222d2f9319de53a2ff1b1740755,openstack/requirements,stable/ocata,I6312bad9a8c06222d2f9319de53a2ff1b1740755,update constraint for openstackdocstheme to new release 1.22.0,ABANDONED,2018-08-15 05:21:18.000000000,2018-09-26 20:48:47.000000000,,"[{'_account_id': 11131}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-15 05:21:18.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/eb631d70dd29f377add694b31a5ff20fb478845b', 'message': 'update constraint for openstackdocstheme to new release 1.22.0\n\nConflicts:\n upper-constraints.txt\n\nChange-Id: I6312bad9a8c06222d2f9319de53a2ff1b1740755\nmeta:version: 1.22.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Andreas Jaeger <aj@suse.com>\nmeta:release:Commit: Andreas Jaeger <aj@suse.com>\nmeta:release:Change-Id: Icd6b5a61929e6740125455d633892d6f774cca04\nmeta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>\nmeta:release:Code-Review+1: Kylian Mbapp <lijiawang8866@gmail.com>\nmeta:release:Code-Review+1: Petr Kovar <pkovar@redhat.com>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n(cherry picked from commit adfe2d05a72e917868ae191bcb69091f13e8df8b)\n(cherry picked from commit 352f96f2d3a640d5883729e2fd8bef51f7dba89a)\n'}]",0,591896,eb631d70dd29f377add694b31a5ff20fb478845b,10,4,1,12898,,,0,"update constraint for openstackdocstheme to new release 1.22.0

Conflicts:
 upper-constraints.txt

Change-Id: I6312bad9a8c06222d2f9319de53a2ff1b1740755
meta:version: 1.22.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Andreas Jaeger <aj@suse.com>
meta:release:Commit: Andreas Jaeger <aj@suse.com>
meta:release:Change-Id: Icd6b5a61929e6740125455d633892d6f774cca04
meta:release:Code-Review+2: Tony Breeds <tony@bakeyournoodle.com>
meta:release:Code-Review+1: Kylian Mbapp <lijiawang8866@gmail.com>
meta:release:Code-Review+1: Petr Kovar <pkovar@redhat.com>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
(cherry picked from commit adfe2d05a72e917868ae191bcb69091f13e8df8b)
(cherry picked from commit 352f96f2d3a640d5883729e2fd8bef51f7dba89a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/96/591896/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,eb631d70dd29f377add694b31a5ff20fb478845b,openstackdocstheme,openstackdocstheme===1.22.0,openstackdocstheme===1.6.1,1,1
openstack%2Fironic~master~Ia83b92c86e7ffe582047780ec12946ad2effa9fd,openstack/ironic,master,Ia83b92c86e7ffe582047780ec12946ad2effa9fd,Change BFV tempest job to explicitly use ipxe,ABANDONED,2018-07-17 22:31:17.000000000,2018-09-26 20:45:30.000000000,,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 14208}, {'_account_id': 14629}, {'_account_id': 19003}, {'_account_id': 19339}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-17 22:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a56f21b3ae10931b4ba9d6964e03c3800088ba11', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}, {'number': 2, 'created': '2018-07-18 18:57:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/e2a49d7548d4a13ba5e498cc9f66533afd246d21', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}, {'number': 3, 'created': '2018-07-19 02:36:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/70038c12ca4000e395fe2eee27df84e88260ae29', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}, {'number': 4, 'created': '2018-07-31 16:12:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/575ce10de151feda47ccf2a38fe7ed73214dafc9', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}, {'number': 5, 'created': '2018-08-09 14:22:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f34e5153be7495ac02b03ddd93bbb29cf520e561', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}, {'number': 6, 'created': '2018-08-31 20:27:44.000000000', 'files': ['zuul.d/ironic-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/214353904743511e5d60ac0019f8474c4805ffaf', 'message': 'Change BFV tempest job to explicitly use ipxe\n\nChange-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd\n'}]",1,583410,214353904743511e5d60ac0019f8474c4805ffaf,35,7,6,11655,,,0,"Change BFV tempest job to explicitly use ipxe

Change-Id: Ia83b92c86e7ffe582047780ec12946ad2effa9fd
",git fetch https://review.opendev.org/openstack/ironic refs/changes/10/583410/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/legacy/tempest-dsvm-ironic-bfv/run.yaml'],1,a56f21b3ae10931b4ba9d6964e03c3800088ba11,583407," export DEVSTACK_LOCAL_CONFIG+=$'\n'""IRONIC_DEFAULT_BOOT_INTERFACE=ipxe""",,1,0
openstack%2Ftripleo-quickstart-extras~master~I024cdc4f0e18ec7bce77d677e44cd0efcb60588e,openstack/tripleo-quickstart-extras,master,I024cdc4f0e18ec7bce77d677e44cd0efcb60588e,Set different branch in zuul_changes,ABANDONED,2018-09-20 10:59:38.000000000,2018-09-26 19:55:04.000000000,,"[{'_account_id': 9592}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-09-20 10:59:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/e89f6daa28263df305d12dcb35e6197f72e62137', 'message': 'Set different branch in zuul_changes\n\n* If ""zuul_changes"": ""testproject:master:refs/changes/42/13942/1^\n  openstack/manila:stable/pike:refs/changes/71/603171/3^\n  testproject:master:refs/changes/43/13943/36"" in this format that time\n  the zuul_deps checks for branch needs to be equal to changed branch\n  but sometime different branch is also used to test stuff that it is\n  ignored, it fixes the same.\n\nChange-Id: I024cdc4f0e18ec7bce77d677e44cd0efcb60588e\n'}, {'number': 2, 'created': '2018-09-20 11:01:43.000000000', 'files': ['roles/build-test-packages/library/zuul_deps.py'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8e19dd59a81c3d58c4cbacdb311b29c651442414', 'message': 'Set different branch in zuul_changes\n\n* If ""zuul_changes"": ""testproject:master:refs/changes/42/13942/1^\n  openstack/manila:stable/pike:refs/changes/71/603171/3^\n  testproject:master:refs/changes/43/13943/36"" in this format that time\n  the zuul_deps checks for branch needs to be equal to changed branch\n  but sometime different branch is also used to test stuff that it is\n  ignored, it fixes the same.\n\nChange-Id: I024cdc4f0e18ec7bce77d677e44cd0efcb60588e\n'}]",1,604035,8e19dd59a81c3d58c4cbacdb311b29c651442414,9,5,2,12393,,,0,"Set different branch in zuul_changes

* If ""zuul_changes"": ""testproject:master:refs/changes/42/13942/1^
  openstack/manila:stable/pike:refs/changes/71/603171/3^
  testproject:master:refs/changes/43/13943/36"" in this format that time
  the zuul_deps checks for branch needs to be equal to changed branch
  but sometime different branch is also used to test stuff that it is
  ignored, it fixes the same.

Change-Id: I024cdc4f0e18ec7bce77d677e44cd0efcb60588e
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/35/604035/2 && git format-patch -1 --stdout FETCH_HEAD,['roles/build-test-packages/library/zuul_deps.py'],1,e89f6daa28263df305d12dcb35e6197f72e62137,test_deps, import pdb; pdb.set_trace() branch = params[1], continue,2,1
openstack%2Frally-openstack~master~I17c774f030c77bc9e8b58e4733be92b7551a5675,openstack/rally-openstack,master,I17c774f030c77bc9e8b58e4733be92b7551a5675,Specify keystone version while creating env from system environment,MERGED,2018-09-25 02:37:00.000000000,2018-09-26 19:53:06.000000000,2018-09-26 19:53:06.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 02:37:00.000000000', 'files': ['rally_openstack/platforms/existing.py', 'tests/unit/platforms/test_existing.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/f715f24967145b03b550a6f3bde03942f39f4273', 'message': 'Specify keystone version while creating env from system environment\n\nChange-Id: I17c774f030c77bc9e8b58e4733be92b7551a5675\n'}]",0,604954,f715f24967145b03b550a6f3bde03942f39f4273,10,2,1,21528,,,0,"Specify keystone version while creating env from system environment

Change-Id: I17c774f030c77bc9e8b58e4733be92b7551a5675
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/54/604954/1 && git format-patch -1 --stdout FETCH_HEAD,"['rally_openstack/platforms/existing.py', 'tests/unit/platforms/test_existing.py']",2,f715f24967145b03b550a6f3bde03942f39f4273,keystone_versions," ""profiler_conn_str"": ""https://example2.com"", ""api_info"": { ""keystone"": { ""version"": 2, ""service_type"": ""identity"" } } ""profiler_conn_str"": ""https://example2.com"", ""api_info"": { ""keystone"": { ""version"": 3, ""service_type"": ""identityv3"" } }"," ""profiler_conn_str"": ""https://example2.com"" ""profiler_conn_str"": ""https://example2.com""",27,3
openstack%2Fopenstack-ansible~stable%2Fpike~I33f7994a50ba5fcea7fca171dfca6b4d32011900,openstack/openstack-ansible,stable/pike,I33f7994a50ba5fcea7fca171dfca6b4d32011900,Remove broken uptime tests during upgrade,MERGED,2018-09-25 17:12:49.000000000,2018-09-26 19:43:33.000000000,2018-09-26 19:43:33.000000000,"[{'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-25 17:12:49.000000000', 'files': ['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/ff907e177b24873dd4fbdc0b436d0434b043c32a', 'message': 'Remove broken uptime tests during upgrade\n\nThe uptime tests during upgrades have not been\nworking for some time, and we really need a better\nway to implement them anyway.\n\nTo at least allow upgrade tests to work without\ntheir interference, we remove the scripts and\nimplementation.\n\nChange-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900\n(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)\n'}]",0,605153,ff907e177b24873dd4fbdc0b436d0434b043c32a,7,3,1,6816,,,0,"Remove broken uptime tests during upgrade

The uptime tests during upgrades have not been
working for some time, and we really need a better
way to implement them anyway.

To at least allow upgrade tests to work without
their interference, we remove the scripts and
implementation.

Change-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900
(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/53/605153/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh']",4,ff907e177b24873dd4fbdc0b436d0434b043c32a,cleanup-role-tests-stable/pike,,"#!/bin/bash # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## Shell Opts ---------------------------------------------------------------- set -e ## Vars ---------------------------------------------------------------------- # Test script socket file location TEST_SOCKET_FILE=""/var/run/disk-access-test.socket"" # The location to write to TEST_DATA_FILE=""/mnt/test"" # Setup counters PASS=0 FAIL=0 ## Functions ----------------------------------------------------------------- # Tests to execute tests() { # We want the output format to be: # YYYY-MM-DD HH:MM:SS <result> echo -n ""$(date -u '+%Y-%m-%d %H:%M:%S') "" # A simple disk write test to validate whether # we are able to write to disk. CMD_WRITE=""timeout 1s dd bs=1M count=50 if=/dev/zero of=${TEST_DATA_FILE} conv=fdatasync"" if ${CMD_WRITE}; then echo ""PASS"" PASS=$((PASS+1)) else echo ""FAIL"" FAIL=$((FAIL+1)) fi } # Steps to execute when finishing finish() { rm -f ${TEST_SOCKET_FILE} > /dev/null echo ""PASS: ${PASS}"" echo ""FAIL: ${FAIL}"" } # Setup the trap for the interrupt trap finish SIGHUP SIGINT SIGTERM ## Main ---------------------------------------------------------------------- # Partition the volume echo ';' | sfdisk --quiet /dev/vdb > /dev/null # Format the volume mkfs /dev/vdb1 > /dev/null # Mount the volume mount /dev/vdb1 /mnt # Setup the socket file to allow termination later echo $$ > ${TEST_SOCKET_FILE} # Execute the test loop while [ -f ""${TEST_SOCKET_FILE}"" ]; do tests sleep 1 done # This point will only be reached if the # socket file is removed finish ",0,329
openstack%2Fmistral~master~I6c546f5f219e9df6df3feebe2559cb4075e37510,openstack/mistral,master,I6c546f5f219e9df6df3feebe2559cb4075e37510,Make using trusts for action execution optional,NEW,2018-09-06 13:11:12.000000000,2018-09-26 19:42:26.000000000,,"[{'_account_id': 7065}, {'_account_id': 8532}, {'_account_id': 8731}, {'_account_id': 9712}, {'_account_id': 22348}, {'_account_id': 27008}]","[{'number': 1, 'created': '2018-09-06 13:11:12.000000000', 'files': ['mistral/config.py', 'mistral/executors/default_executor.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/36015429f5f0bfb76eea92a8f51fb022b35746e0', 'message': 'Make using trusts for action execution optional\n\nAdds a configuration flag to opt out from using trusts for all\naction executions.\n\nRemark: this is required in cases when the target cloud is accessed\nusing Keystone V2 authentication.\n\nChange-Id: I6c546f5f219e9df6df3feebe2559cb4075e37510\n'}]",0,600440,36015429f5f0bfb76eea92a8f51fb022b35746e0,6,6,1,21970,,,0,"Make using trusts for action execution optional

Adds a configuration flag to opt out from using trusts for all
action executions.

Remark: this is required in cases when the target cloud is accessed
using Keystone V2 authentication.

Change-Id: I6c546f5f219e9df6df3feebe2559cb4075e37510
",git fetch https://review.opendev.org/openstack/mistral refs/changes/40/600440/1 && git format-patch -1 --stdout FETCH_HEAD,"['mistral/config.py', 'mistral/executors/default_executor.py']",2,36015429f5f0bfb76eea92a8f51fb022b35746e0,bug/1595084,from oslo_config import cfg force_trusts = cfg.CONF.use_trusts_for_action_execution if force_trusts and not action_ctx.trust_id:, if not action_ctx.trust_id:,9,1
openstack%2Fcinder~master~I19d94c13288dd574f6eafaf3fb430c3452961ce5,openstack/cinder,master,I19d94c13288dd574f6eafaf3fb430c3452961ce5,ZFSSA iSCSI implement get_manageable_volumes(),MERGED,2018-09-20 21:57:17.000000000,2018-09-26 19:41:30.000000000,2018-09-26 03:11:45.000000000,"[{'_account_id': 24}, {'_account_id': 1736}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23561}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-20 21:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/a08580f587f1440e21dbcf93a28745a736811900', 'message': 'ZFSSA iSCSI implement get_manageable_volumes()\n\nImplement get_manageable_volumes() to augment existing implementation\nof volume manage/unmanage.\n\nChange-Id: I19d94c13288dd574f6eafaf3fb430c3452961ce5\nCloses-Bug: #1793599\n'}, {'number': 2, 'created': '2018-09-21 19:04:36.000000000', 'files': ['cinder/volume/drivers/zfssa/zfssarest.py', 'releasenotes/notes/zfssa-iscsi-get-manageable-volumes-eb23a11570c813d7.yaml', 'cinder/volume/drivers/zfssa/zfssaiscsi.py', 'cinder/tests/unit/volume/drivers/test_zfssa.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/fe0a71b593fe0a89f9093ffb163d6e08f4a0f11d', 'message': 'ZFSSA iSCSI implement get_manageable_volumes()\n\nImplement get_manageable_volumes() to augment existing implementation\nof volume manage/unmanage.\n\nChange-Id: I19d94c13288dd574f6eafaf3fb430c3452961ce5\nCloses-Bug: #1793599\n'}]",22,604230,fe0a71b593fe0a89f9093ffb163d6e08f4a0f11d,75,37,2,23561,,,0,"ZFSSA iSCSI implement get_manageable_volumes()

Implement get_manageable_volumes() to augment existing implementation
of volume manage/unmanage.

Change-Id: I19d94c13288dd574f6eafaf3fb430c3452961ce5
Closes-Bug: #1793599
",git fetch https://review.opendev.org/openstack/cinder refs/changes/30/604230/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/zfssa/zfssarest.py', 'releasenotes/notes/zfssa-iscsi-get-manageable-volumes-eb23a11570c813d7.yaml', 'cinder/volume/drivers/zfssa/zfssaiscsi.py', 'cinder/tests/unit/volume/drivers/test_zfssa.py']",4,a08580f587f1440e21dbcf93a28745a736811900,bug/1793599," def test_get_manageable_volumes(self): lcfg = self.configuration self.drv.zfssa.get_all_luns.return_value = [ {'name': 'volume-11111111-1111-1111-1111-111111111111', 'size': 111 * units.Gi, 'cinder_managed': True}, {'name': 'volume2', 'size': 222 * units.Gi, 'cinder_managed': False}, {'name': 'volume-33333333-3333-3333-3333-333333333333', 'size': 333 * units.Gi, 'cinder_managed': True}, {'name': 'volume4', 'size': 444 * units.Gi} ] cinder_vols = [{'id': '11111111-1111-1111-1111-111111111111'}] args = (cinder_vols, None, 1000, 0, ['size'], ['asc']) lcfg.zfssa_manage_policy = 'strict' expected = [ {'reference': {'source-name': 'volume-11111111-1111-1111-1111-111111111111'}, 'size': 111, 'safe_to_manage': False, 'reason_not_safe': 'already managed', 'cinder_id': '11111111-1111-1111-1111-111111111111', 'extra_info': None}, {'reference': {'source-name': 'volume2'}, 'size': 222, 'safe_to_manage': True, 'reason_not_safe': None, 'cinder_id': None, 'extra_info': None}, {'reference': {'source-name': 'volume-33333333-3333-3333-3333-333333333333'}, 'size': 333, 'safe_to_manage': False, 'reason_not_safe': 'managed by another cinder instance?', 'cinder_id': None, 'extra_info': None}, {'reference': {'source-name': 'volume4'}, 'size': 444, 'safe_to_manage': False, 'reason_not_safe': 'cinder_managed schema not present', 'cinder_id': None, 'extra_info': None}, ] result = self.drv.get_manageable_volumes(*args) self.assertEqual(expected, result) lcfg.zfssa_manage_policy = 'loose' expected[3]['safe_to_manage'] = True expected[3]['reason_not_safe'] = None result = self.drv.get_manageable_volumes(*args) self.assertEqual(expected, result) ",,157,34
openstack%2Fopenstack-ansible-ops~master~I854befd283b62c98e956a5e677ca9d7dbd33416b,openstack/openstack-ansible-ops,master,I854befd283b62c98e956a5e677ca9d7dbd33416b,MNAIO: Remove mnaio_hosts group and use vm_hosts only,MERGED,2018-09-26 11:30:46.000000000,2018-09-26 19:29:52.000000000,2018-09-26 19:29:52.000000000,"[{'_account_id': 6816}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 11:30:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/35d28dc1c9727d9aa0f3507ebfdd69ad60b55320', 'message': 'Remove mnaio_hosts group and use vm_hosts only\n\nThe mnaio_hosts group is redundant. We switch to just using the\nvm_hosts group instead.\n\nChange-Id: I854befd283b62c98e956a5e677ca9d7dbd33416b\n'}, {'number': 2, 'created': '2018-09-26 13:01:08.000000000', 'files': ['multi-node-aio/playbooks/setup-host.yml', 'multi-node-aio/playbooks/inventory/hosts', 'multi-node-aio/playbooks/deploy-vms.yml', 'multi-node-aio/playbooks/group_vars/vm_hosts.yml', 'multi-node-aio/build.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ops/commit/14567e0c3c0a67d26ece5040f0663a0d02f3f43f', 'message': 'MNAIO: Remove mnaio_hosts group and use vm_hosts only\n\nThe mnaio_hosts group is redundant. We switch to just using the\nvm_hosts group instead.\n\nChange-Id: I854befd283b62c98e956a5e677ca9d7dbd33416b\n'}]",0,605401,14567e0c3c0a67d26ece5040f0663a0d02f3f43f,7,2,2,6816,,,0,"MNAIO: Remove mnaio_hosts group and use vm_hosts only

The mnaio_hosts group is redundant. We switch to just using the
vm_hosts group instead.

Change-Id: I854befd283b62c98e956a5e677ca9d7dbd33416b
",git fetch https://review.opendev.org/openstack/openstack-ansible-ops refs/changes/01/605401/2 && git format-patch -1 --stdout FETCH_HEAD,"['multi-node-aio/playbooks/setup-host.yml', 'multi-node-aio/playbooks/inventory/hosts', 'multi-node-aio/playbooks/deploy-vms.yml', 'multi-node-aio/playbooks/group_vars/vm_hosts.yml', 'multi-node-aio/build.sh']",5,35d28dc1c9727d9aa0f3507ebfdd69ad60b55320,,ansible vm_hosts \,ansible mnaio_hosts \,3,9
openstack%2Fopenstack-ansible~stable%2Fqueens~I33f7994a50ba5fcea7fca171dfca6b4d32011900,openstack/openstack-ansible,stable/queens,I33f7994a50ba5fcea7fca171dfca6b4d32011900,Remove broken uptime tests during upgrade,MERGED,2018-09-25 17:11:31.000000000,2018-09-26 19:21:19.000000000,2018-09-26 19:21:19.000000000,"[{'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 23163}]","[{'number': 1, 'created': '2018-09-25 17:11:31.000000000', 'files': ['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/967542ba36e8800dbe50781767d19b757194a1e9', 'message': 'Remove broken uptime tests during upgrade\n\nThe uptime tests during upgrades have not been\nworking for some time, and we really need a better\nway to implement them anyway.\n\nTo at least allow upgrade tests to work without\ntheir interference, we remove the scripts and\nimplementation.\n\nChange-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900\n(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)\n'}]",0,605152,967542ba36e8800dbe50781767d19b757194a1e9,7,3,1,6816,,,0,"Remove broken uptime tests during upgrade

The uptime tests during upgrades have not been
working for some time, and we really need a better
way to implement them anyway.

To at least allow upgrade tests to work without
their interference, we remove the scripts and
implementation.

Change-Id: I33f7994a50ba5fcea7fca171dfca6b4d32011900
(cherry picked from commit 889e0599098e479b9d5a580a81a928ec39186047)
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/52/605152/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/data-plane-test.sh', 'scripts/gate-check-commit.sh', 'scripts/scripts-library.sh', 'tests/disk-access-test.sh']",4,967542ba36e8800dbe50781767d19b757194a1e9,cleanup-role-tests-stable/queens,,"#!/bin/bash # Copyright 2017, Rackspace US, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ## Shell Opts ---------------------------------------------------------------- set -e ## Vars ---------------------------------------------------------------------- # Test script socket file location TEST_SOCKET_FILE=""/var/run/disk-access-test.socket"" # The location to write to TEST_DATA_FILE=""/mnt/test"" # Setup counters PASS=0 FAIL=0 ## Functions ----------------------------------------------------------------- # Tests to execute tests() { # We want the output format to be: # YYYY-MM-DD HH:MM:SS <result> echo -n ""$(date -u '+%Y-%m-%d %H:%M:%S') "" # A simple disk write test to validate whether # we are able to write to disk. CMD_WRITE=""timeout 1s dd bs=1M count=50 if=/dev/zero of=${TEST_DATA_FILE} conv=fdatasync"" if ${CMD_WRITE}; then echo ""PASS"" PASS=$((PASS+1)) else echo ""FAIL"" FAIL=$((FAIL+1)) fi } # Steps to execute when finishing finish() { rm -f ${TEST_SOCKET_FILE} > /dev/null echo ""PASS: ${PASS}"" echo ""FAIL: ${FAIL}"" } # Setup the trap for the interrupt trap finish SIGHUP SIGINT SIGTERM ## Main ---------------------------------------------------------------------- # Partition the volume echo ';' | sfdisk --quiet /dev/vdb > /dev/null # Format the volume mkfs /dev/vdb1 > /dev/null # Mount the volume mount /dev/vdb1 /mnt # Setup the socket file to allow termination later echo $$ > ${TEST_SOCKET_FILE} # Execute the test loop while [ -f ""${TEST_SOCKET_FILE}"" ]; do tests sleep 1 done # This point will only be reached if the # socket file is removed finish ",0,329
openstack%2Fopenstacksdk~master~Ic5eb8b028fbbcdb08b0b7dee7695857321e89089,openstack/openstacksdk,master,Ic5eb8b028fbbcdb08b0b7dee7695857321e89089,Add compute API info and fix provider names,MERGED,2018-09-25 22:30:46.000000000,2018-09-26 19:05:48.000000000,2018-09-26 19:05:47.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 22:30:46.000000000', 'files': ['doc/source/user/config/vendor-support.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/70d665b02bd93b7a99a88fac77e5b3f739cbe69e', 'message': 'Add compute API info and fix provider names\n\nSets the default Compute API to v2.1 and fix the provider names, as\nthey appear on the internet (respecting uppercase letters).\n\nChange-Id: Ic5eb8b028fbbcdb08b0b7dee7695857321e89089\n'}]",0,605253,70d665b02bd93b7a99a88fac77e5b3f739cbe69e,6,2,1,17860,,,0,"Add compute API info and fix provider names

Sets the default Compute API to v2.1 and fix the provider names, as
they appear on the internet (respecting uppercase letters).

Change-Id: Ic5eb8b028fbbcdb08b0b7dee7695857321e89089
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/53/605253/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/config/vendor-support.rst'],1,70d665b02bd93b7a99a88fac77e5b3f739cbe69e,vendor-support,* Compute API Version is 2.1AUROBetacloudCatalystCity Cloud ----------ConoHaDreamComputeDreamHostOpen Telekom Cloud ------------------ELASTXEnter Cloud Suite -----------------FugaInternapLimestone Networks ------------------OVHRackspaceSWITCHenginesUltimumUnitedStackVEXXHOSTZetta,aurobetacloudcatalystcitycloud ---------conohadreamcomputedreamhostotc ---elastxentercloudsuite ---------------fugainternaplimestonenetworks -----------------ovhrackspaceswitchenginesultimumunitedstackvexxhostzetta,25,24
openstack%2Fopenstacksdk~master~I8ac3e5b33cc5de55526e4fa4e05065870316edc8,openstack/openstacksdk,master,I8ac3e5b33cc5de55526e4fa4e05065870316edc8,Update vendor support info for vexxhost,MERGED,2018-09-25 22:22:25.000000000,2018-09-26 19:05:47.000000000,2018-09-26 19:05:47.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 22:22:25.000000000', 'files': ['doc/source/user/config/vendor-support.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/23c6f3a3821fe0801258c4a1af0cc9a43395c2c7', 'message': 'Update vendor support info for vexxhost\n\nThe service URLs (via discovery [1]) for vexxhost are as follow:\n\nidentity: https://example.com/v3/\ncompute: https://example.com/v2.1\nimage: https://example.com/v2/\nnetwork: https://example.com/v2.0/\nblock-storage: https://example.com/v3/70dadafa31184691b8f1a97c95bcfa1b\nobject-store: https://example.com/v1/70dadafa31184691b8f1a97c95bcfa1b\n\nThe new region sjc1 in Santa Clara, CA was added.\n\n[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url\n\nChange-Id: I8ac3e5b33cc5de55526e4fa4e05065870316edc8\n'}]",0,605252,23c6f3a3821fe0801258c4a1af0cc9a43395c2c7,6,2,1,17860,,,0,"Update vendor support info for vexxhost

The service URLs (via discovery [1]) for vexxhost are as follow:

identity: https://example.com/v3/
compute: https://example.com/v2.1
image: https://example.com/v2/
network: https://example.com/v2.0/
block-storage: https://example.com/v3/70dadafa31184691b8f1a97c95bcfa1b
object-store: https://example.com/v1/70dadafa31184691b8f1a97c95bcfa1b

The new region sjc1 in Santa Clara, CA was added.

[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url

Change-Id: I8ac3e5b33cc5de55526e4fa4e05065870316edc8
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/52/605252/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/config/vendor-support.rst'],1,23c6f3a3821fe0801258c4a1af0cc9a43395c2c7,vendor-support-vexxhost,"sjc1 Santa Clara, CA* Volume API Version is 3",,2,0
openstack%2Fopenstacksdk~master~I8a1c856e723c2fb6a6d1f907d51d2952e8b05b21,openstack/openstacksdk,master,I8a1c856e723c2fb6a6d1f907d51d2952e8b05b21,Update vendor support info for switchengines,MERGED,2018-09-25 22:16:04.000000000,2018-09-26 19:05:46.000000000,2018-09-26 19:05:46.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 22:16:04.000000000', 'files': ['doc/source/user/config/vendor-support.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/12a4679145ac98b41a06d99d5f32bee9845aeb6b', 'message': 'Update vendor support info for switchengines\n\nThe service URLs (via discovery [1]) for switchengines are as follow:\n\nidentity: https://example.com:5000/v3/\ncompute: https://example.com:8774/v2/7d04eab08a194304a8942217a8292be3\nimage: https://example.com:9292/v2/\nnetwork: https://example.com:9696/v2.0\nblock-storage: https://example.com:8776/v3/7d04eab08a194304a8942217a8292be3\nobject-store: https://example.com/swift/v1\n\nImage creation was checked and upload via PUT is possible.\n\n[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url\n\nChange-Id: I8a1c856e723c2fb6a6d1f907d51d2952e8b05b21\n'}]",0,605249,12a4679145ac98b41a06d99d5f32bee9845aeb6b,6,2,1,17860,,,0,"Update vendor support info for switchengines

The service URLs (via discovery [1]) for switchengines are as follow:

identity: https://example.com:5000/v3/
compute: https://example.com:8774/v2/7d04eab08a194304a8942217a8292be3
image: https://example.com:9292/v2/
network: https://example.com:9696/v2.0
block-storage: https://example.com:8776/v3/7d04eab08a194304a8942217a8292be3
object-store: https://example.com/swift/v1

Image creation was checked and upload via PUT is possible.

[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url

Change-Id: I8a1c856e723c2fb6a6d1f907d51d2952e8b05b21
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/49/605249/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/config/vendor-support.rst'],1,12a4679145ac98b41a06d99d5f32bee9845aeb6b,vendor-support-switchengines,* Identity API Version is 3 * Compute API Version is 2* Volume API Version is 3,* Images must be uploaded using the Glance Task Interface * Volume API Version is 1,3,2
openstack%2Fopenstacksdk~master~I6a176977f620ac5b55b2cc311f15f47f897ae42c,openstack/openstacksdk,master,I6a176977f620ac5b55b2cc311f15f47f897ae42c,Update vendor support info for ecs,MERGED,2018-09-25 22:11:22.000000000,2018-09-26 19:05:45.000000000,2018-09-26 19:05:45.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 22:11:22.000000000', 'files': ['doc/source/user/config/vendor-support.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/97bd7e4f7f227bc359a34473c143680185fd68fe', 'message': 'Update vendor support info for ecs\n\nThe service URLs (via discovery [1]) for ECS are as follow:\n\nidentity: https://example.com/v2.0/\ncompute: https://example.com/v2/cb7088c9306742858e8a38b97744fba8\nimage: https://example.com/v2/\nnetwork: https://example.com/v2.0\nblock-storage: https://example.com/v2/cb7088c9306742858e8a38b97744fba8\nobject-store: https://example.com/v1/KEY_cb7088c9306742858e8a38b97744fba8\n\n[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url\n\nChange-Id: I6a176977f620ac5b55b2cc311f15f47f897ae42c\n'}]",0,605248,97bd7e4f7f227bc359a34473c143680185fd68fe,6,2,1,17860,,,0,"Update vendor support info for ecs

The service URLs (via discovery [1]) for ECS are as follow:

identity: https://example.com/v2.0/
compute: https://example.com/v2/cb7088c9306742858e8a38b97744fba8
image: https://example.com/v2/
network: https://example.com/v2.0
block-storage: https://example.com/v2/cb7088c9306742858e8a38b97744fba8
object-store: https://example.com/v1/KEY_cb7088c9306742858e8a38b97744fba8

[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url

Change-Id: I6a176977f620ac5b55b2cc311f15f47f897ae42c
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/48/605248/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/config/vendor-support.rst'],1,97bd7e4f7f227bc359a34473c143680185fd68fe,vendor-support-ecs,* Compute API Version is 2,* Image API Version is 1 * Volume API Version is 1,1,2
openstack%2Fopenstacksdk~master~If2a8c7a936c7bd8cdb4554a91ba25bb7a9b85459,openstack/openstacksdk,master,If2a8c7a936c7bd8cdb4554a91ba25bb7a9b85459,Update vendor support info for catalyst,MERGED,2018-09-25 22:05:38.000000000,2018-09-26 18:56:35.000000000,2018-09-26 18:56:35.000000000,"[{'_account_id': 2}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 22:05:38.000000000', 'files': ['doc/source/user/config/vendor-support.rst'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/943f60679809144fb841894d1495240c3a751033', 'message': 'Update vendor support info for catalyst\n\nThe service URLs (via discovery [1]) for catalyst are as follow:\n\nidentity: https://example.com:5000/v3/\ncompute: https://example.com:8774/v2/16ccee5e96ed466d86b23a5b7d95d377\nimage: https://example.com:9292/v2/\nnetwork: https://example.com:9696/v2.0\nblock-storage: https://example.com:8776/v3/16ccee5e96ed466d86b23a5b7d95d377\nobject-store: https://example.com:443/v1/AUTH_16ccee5e96ed466d86b23a5b7d95d377\n\n[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url\n\nChange-Id: If2a8c7a936c7bd8cdb4554a91ba25bb7a9b85459\n'}]",0,605245,943f60679809144fb841894d1495240c3a751033,6,2,1,17860,,,0,"Update vendor support info for catalyst

The service URLs (via discovery [1]) for catalyst are as follow:

identity: https://example.com:5000/v3/
compute: https://example.com:8774/v2/16ccee5e96ed466d86b23a5b7d95d377
image: https://example.com:9292/v2/
network: https://example.com:9696/v2.0
block-storage: https://example.com:8776/v3/16ccee5e96ed466d86b23a5b7d95d377
object-store: https://example.com:443/v1/AUTH_16ccee5e96ed466d86b23a5b7d95d377

[1] cloud.session.auth.get_endpoint_data(cloud.session, service).url

Change-Id: If2a8c7a936c7bd8cdb4554a91ba25bb7a9b85459
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/45/605245/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/config/vendor-support.rst'],1,943f60679809144fb841894d1495240c3a751033,vendor-support-catalyst,* Identity API Version is 3 * Compute API Version is 2* Volume API Version is 3,* Image API Version is 1* Volume API Version is 1,3,2
openstack%2Fpuppet-nova~master~I3297172d8a0be600290513a88b98222a7412a7c1,openstack/puppet-nova,master,I3297172d8a0be600290513a88b98222a7412a7c1,Dont warn on service default value,ABANDONED,2018-09-23 13:33:54.000000000,2018-09-26 18:46:40.000000000,,"[{'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 17216}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-23 13:33:54.000000000', 'files': ['manifests/db.pp'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/061ca1c0d8e6aaa7374604728a1bb8df20189414', 'message': 'Dont warn on service default value\n\nSome placement database parameters default to\nservice default but will warn about deprecation\nanyway.\n\nChange-Id: I3297172d8a0be600290513a88b98222a7412a7c1\n'}]",0,604615,061ca1c0d8e6aaa7374604728a1bb8df20189414,7,4,1,16137,,,0,"Dont warn on service default value

Some placement database parameters default to
service default but will warn about deprecation
anyway.

Change-Id: I3297172d8a0be600290513a88b98222a7412a7c1
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/15/604615/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/db.pp'],1,061ca1c0d8e6aaa7374604728a1bb8df20189414,, if $placement_database_connection and !is_service_default($placement_database_connection) { if $placement_slave_connection and !is_service_default($placement_slave_connection) {, if $placement_database_connection { if $placement_slave_connection {,2,2
openstack%2Fcharm-heat~stable%2F18.08~I6998fe0543b26232c65c43bc9b2a8cc4b20bcbc5,openstack/charm-heat,stable/18.08,I6998fe0543b26232c65c43bc9b2a8cc4b20bcbc5,Specify domain when looking up heat user,MERGED,2018-09-26 08:01:30.000000000,2018-09-26 18:40:06.000000000,2018-09-26 18:40:06.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 08:01:30.000000000', 'files': ['actions/domain-setup'], 'web_link': 'https://opendev.org/openstack/charm-heat/commit/4081434abfb79b9c824d4f2c288e6a19ad7ed689', 'message': 'Specify domain when looking up heat user\n\nThe domain-setup action checks if the heat domain, user and roles\nare setup before creating them, but in the case of the user it\nwas not checking the users existence in the correct domain.\n\nChange-Id: I6998fe0543b26232c65c43bc9b2a8cc4b20bcbc5\nCloses-Bug: #1793170\n(cherry picked from commit e8354a1b6804bb2fcf091dc12cc50a753f561a86)\n'}]",0,605346,4081434abfb79b9c824d4f2c288e6a19ad7ed689,11,4,1,12549,,,0,"Specify domain when looking up heat user

The domain-setup action checks if the heat domain, user and roles
are setup before creating them, but in the case of the user it
was not checking the users existence in the correct domain.

Change-Id: I6998fe0543b26232c65c43bc9b2a8cc4b20bcbc5
Closes-Bug: #1793170
(cherry picked from commit e8354a1b6804bb2fcf091dc12cc50a753f561a86)
",git fetch https://review.opendev.org/openstack/charm-heat refs/changes/46/605346/1 && git format-patch -1 --stdout FETCH_HEAD,['actions/domain-setup'],1,4081434abfb79b9c824d4f2c288e6a19ad7ed689,bug/1793170-stable/18.08,openstack user show --domain heat heat_domain_admin || {,openstack user show heat_domain_admin || {,1,1
openstack%2Fsahara~stable%2Frocky~I826dbebb446d49e01e3cd6d7e525b43aa4523434,openstack/sahara,stable/rocky,I826dbebb446d49e01e3cd6d7e525b43aa4523434,Add template param for ambari pkg install timeout,MERGED,2018-09-25 20:18:27.000000000,2018-09-26 18:07:16.000000000,2018-09-26 18:07:16.000000000,"[{'_account_id': 8932}, {'_account_id': 22348}, {'_account_id': 23078}, {'_account_id': 26181}]","[{'number': 1, 'created': '2018-09-25 20:18:27.000000000', 'files': ['sahara/plugins/ambari/configs.py', 'sahara/plugins/ambari/deploy.py', 'sahara/utils/ssh_remote.py', 'releasenotes/notes/ambari-agent-pkg-install-timeout-param-d50e5c15e06fa51e.yaml', 'doc/source/user/ambari-plugin.rst'], 'web_link': 'https://opendev.org/openstack/sahara/commit/b7eef40f67c1a6ce96b35709897bb1c63dbe7caa', 'message': 'Add template param for ambari pkg install timeout\n\nOften time ambari fails during cluster installation/service\nstarting stage. This is quiet prominent when  there is\na large number of nodes in the cluster. Review of the\nlogs from the cluster indicates that ambari installation\nscripts has a timeout parameter set to 1800 sec, this\nrequires adjustment depending on the environment and\nspeed of package installation.\n\nThis fix provides one parameter named\n""agent.package.install.task.timeout""  inside the Ambari tab\nof the HDP cluster template UI . User may change the\nvalues and accordingly the ambari server will be setup\nfor package installation timeout.\'\n\nChange-Id: I826dbebb446d49e01e3cd6d7e525b43aa4523434\nStory: #2003176\nTask: #23320\n(cherry picked from commit e7a4b58c5a638a422540f19e5d34d4f9d84a9c93)\n'}]",0,605226,b7eef40f67c1a6ce96b35709897bb1c63dbe7caa,8,4,1,10459,,,0,"Add template param for ambari pkg install timeout

Often time ambari fails during cluster installation/service
starting stage. This is quiet prominent when  there is
a large number of nodes in the cluster. Review of the
logs from the cluster indicates that ambari installation
scripts has a timeout parameter set to 1800 sec, this
requires adjustment depending on the environment and
speed of package installation.

This fix provides one parameter named
""agent.package.install.task.timeout""  inside the Ambari tab
of the HDP cluster template UI . User may change the
values and accordingly the ambari server will be setup
for package installation timeout.'

Change-Id: I826dbebb446d49e01e3cd6d7e525b43aa4523434
Story: #2003176
Task: #23320
(cherry picked from commit e7a4b58c5a638a422540f19e5d34d4f9d84a9c93)
",git fetch https://review.opendev.org/openstack/sahara refs/changes/26/605226/1 && git format-patch -1 --stdout FETCH_HEAD,"['sahara/plugins/ambari/configs.py', 'sahara/plugins/ambari/deploy.py', 'sahara/utils/ssh_remote.py', 'releasenotes/notes/ambari-agent-pkg-install-timeout-param-d50e5c15e06fa51e.yaml', 'doc/source/user/ambari-plugin.rst']",5,b7eef40f67c1a6ce96b35709897bb1c63dbe7caa,," Adjusting Ambari Agent Package Installation timeout Parameter ------------------------------------------------------------- For a cluster with large number of nodes or slow connectivity to HDP repo server, a Sahara HDP Cluster creation may fail due to ambari agent reaching the timeout threshold while installing the packages in the nodes. Such failures will occur during the ""cluster start"" stage which can be monitored from Cluster Events tab of Sahara Dashboard. The timeout error will be visible from the Ambari Dashboard as well. * To avoid the package installation timeout by ambari agent you need to change the default value of ``Ambari Agent Package Install timeout`` parameter which can be found in the ``General Parameters`` section of the cluster template configuration.",,57,2
openstack%2Fcinder~stable%2Fqueens~If7b1dc408375d724fdc9ce6a3e256ad37e7c946f,openstack/cinder,stable/queens,If7b1dc408375d724fdc9ce6a3e256ad37e7c946f,VMAX driver - Block revert to snapshot for replicated volumes,MERGED,2018-08-28 11:22:53.000000000,2018-09-26 18:05:41.000000000,2018-09-26 18:05:41.000000000,"[{'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 8871}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12369}, {'_account_id': 12670}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 15670}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23414}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 26561}, {'_account_id': 27615}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-08-28 11:22:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d3efc04749ae59f498ad08cdaa5b17dce2486940', 'message': 'VMAX driver - Block revert to snapshot for replicated volumes\n\nAttempting to restore a replicated volume to snapshot will result in an\nerror, as this operation requires the RDF relationship to be suspended\nfirst. It would be safest to throw an exception and block this operation\non replicated volumes. The user could instead create a new volume from\nthe snapshot and attach that, instead of reverting the original volume.\nThis patch implements this change.\n\nChange-Id: If7b1dc408375d724fdc9ce6a3e256ad37e7c946f\nCloses-bug: 1777871\n(cherry picked from commit 92fbe37087f75ac698e39f2fd635caefac1a4e6d)\n'}, {'number': 2, 'created': '2018-09-12 09:50:53.000000000', 'files': ['cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py', 'cinder/volume/drivers/dell_emc/vmax/common.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/847c70644712ceab35536392c0212b82cabaa4b3', 'message': 'VMAX driver - Block revert to snapshot for replicated volumes\n\nAttempting to restore a replicated volume to snapshot will result in an\nerror, as this operation requires the RDF relationship to be suspended\nfirst. It would be safest to throw an exception and block this operation\non replicated volumes. The user could instead create a new volume from\nthe snapshot and attach that, instead of reverting the original volume.\nThis patch implements this change.\n\nChange-Id: If7b1dc408375d724fdc9ce6a3e256ad37e7c946f\nCloses-bug: 1777871\n(cherry picked from commit 92fbe37087f75ac698e39f2fd635caefac1a4e6d)\n'}]",0,597049,847c70644712ceab35536392c0212b82cabaa4b3,63,28,2,12670,,,0,"VMAX driver - Block revert to snapshot for replicated volumes

Attempting to restore a replicated volume to snapshot will result in an
error, as this operation requires the RDF relationship to be suspended
first. It would be safest to throw an exception and block this operation
on replicated volumes. The user could instead create a new volume from
the snapshot and attach that, instead of reverting the original volume.
This patch implements this change.

Change-Id: If7b1dc408375d724fdc9ce6a3e256ad37e7c946f
Closes-bug: 1777871
(cherry picked from commit 92fbe37087f75ac698e39f2fd635caefac1a4e6d)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/49/597049/2 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/volume/drivers/dell_emc/vmax/fc.py', 'cinder/tests/unit/volume/drivers/dell_emc/vmax/test_vmax.py', 'cinder/volume/drivers/dell_emc/vmax/common.py', 'cinder/volume/drivers/dell_emc/vmax/iscsi.py']",4,d3efc04749ae59f498ad08cdaa5b17dce2486940,bug/1777871, - Block revert to snapshot for replicated volumes (bug #1777871),,17,1
openstack%2Fpython-tripleoclient~master~I56c5f3a094094f7ba2158d8a434122ccb496f6b4,openstack/python-tripleoclient,master,I56c5f3a094094f7ba2158d8a434122ccb496f6b4,Start websocket client before workflows,MERGED,2018-09-26 09:33:56.000000000,2018-09-26 17:57:26.000000000,2018-09-26 17:57:26.000000000,"[{'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10873}, {'_account_id': 10969}, {'_account_id': 12393}, {'_account_id': 12715}, {'_account_id': 13861}, {'_account_id': 17888}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 27898}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-09-26 09:33:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2e05544a2e3d1f718c58a1b1afb52af0483cdf91', 'message': ""Start websocket client before workflows\n\nWhen we start a workflow in the client, we need to create the websocket\nconnection beforehand. If the workflow is very quick (like\ncreate_overcloudrc), it could be finished before we subscribe to the\nZaqar queue properly, and thus we wouldn't get the message.\n\nChange-Id: I56c5f3a094094f7ba2158d8a434122ccb496f6b4\nCloses-Bug: #1794418\n""}, {'number': 2, 'created': '2018-09-26 09:43:33.000000000', 'files': ['tripleoclient/workflows/deployment.py', 'tripleoclient/workflows/support.py', 'tripleoclient/workflows/plan_management.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2a26ef2cf19571e39fc3071b19500808c6d14fcc', 'message': ""Start websocket client before workflows\n\nWhen we start a workflow in the client, we need to create the websocket\nconnection beforehand. If the workflow is very quick (like\ncreate_overcloudrc), it could be finished before we subscribe to the\nZaqar queue properly, and thus we wouldn't get the message.\n\nChange-Id: I56c5f3a094094f7ba2158d8a434122ccb496f6b4\nCloses-Bug: #1794418\n""}]",0,605377,2a26ef2cf19571e39fc3071b19500808c6d14fcc,14,16,2,7385,,,0,"Start websocket client before workflows

When we start a workflow in the client, we need to create the websocket
connection beforehand. If the workflow is very quick (like
create_overcloudrc), it could be finished before we subscribe to the
Zaqar queue properly, and thus we wouldn't get the message.

Change-Id: I56c5f3a094094f7ba2158d8a434122ccb496f6b4
Closes-Bug: #1794418
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/77/605377/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/workflows/deployment.py'],1,2e05544a2e3d1f718c58a1b1afb52af0483cdf91,bug/1794418," with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.create_overcloudrc', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.config_download_export', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.get_deployment_status', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.get_deployment_failures', workflow_input=workflow_input ) "," execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.create_overcloudrc', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.config_download_export', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.get_deployment_status', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws: execution = base.start_workflow( workflow_client, 'tripleo.deployment.v1.get_deployment_failures', workflow_input=workflow_input ) with tripleoclients.messaging_websocket() as ws:",24,24
openstack%2Fproject-config~master~I07c5931e97310cfcc9347aabb5aaf2ec99f2f608,openstack/project-config,master,I07c5931e97310cfcc9347aabb5aaf2ec99f2f608,Move glare legacy jobs in-repo,MERGED,2018-09-25 13:48:46.000000000,2018-09-26 17:57:15.000000000,2018-09-26 17:57:15.000000000,"[{'_account_id': 4146}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 13:48:46.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d6679c2dd4567c18c2fd4c088756f30c5bb81c94', 'message': 'Move glare legacy jobs in-repo\n\nThese jobs are now in-repo, remove them here.\n\nDepends-On: https://review.openstack.org/596544\nChange-Id: I07c5931e97310cfcc9347aabb5aaf2ec99f2f608\n'}]",0,605076,d6679c2dd4567c18c2fd4c088756f30c5bb81c94,7,3,1,6547,,,0,"Move glare legacy jobs in-repo

These jobs are now in-repo, remove them here.

Depends-On: https://review.openstack.org/596544
Change-Id: I07c5931e97310cfcc9347aabb5aaf2ec99f2f608
",git fetch https://review.opendev.org/openstack/project-config refs/changes/76/605076/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,d6679c2dd4567c18c2fd4c088756f30c5bb81c94,legacy-glare,, check: jobs: - legacy-glare-dsvm gate: jobs: - legacy-glare-dsvm,0,6
openstack%2Freleases~master~I9f5ed6e9f0d9cbfb1a248d4c7c800fa0cfffddf3,openstack/releases,master,I9f5ed6e9f0d9cbfb1a248d4c7c800fa0cfffddf3,Release pymod2pkg 0.15.0,MERGED,2018-09-26 10:02:12.000000000,2018-09-26 17:41:50.000000000,2018-09-26 17:41:50.000000000,"[{'_account_id': 2472}, {'_account_id': 6593}, {'_account_id': 11904}, {'_account_id': 13294}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 10:02:12.000000000', 'files': ['deliverables/_independent/pymod2pkg.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/3bb627d1364f31f15a08e13c1554391191274d1f', 'message': 'Release pymod2pkg 0.15.0\n\nChange-Id: I9f5ed6e9f0d9cbfb1a248d4c7c800fa0cfffddf3\n'}]",0,605384,3bb627d1364f31f15a08e13c1554391191274d1f,9,5,1,8482,,,0,"Release pymod2pkg 0.15.0

Change-Id: I9f5ed6e9f0d9cbfb1a248d4c7c800fa0cfffddf3
",git fetch https://review.opendev.org/openstack/releases refs/changes/84/605384/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/pymod2pkg.yaml'],1,3bb627d1364f31f15a08e13c1554391191274d1f,release-pymod2pkg, - projects: - hash: 2554db65616feb2d0ea4af3b4336ac9763118726 repo: openstack/pymod2pkg version: 0.15.0,,4,0
openstack%2Fneutron-fwaas~master~I7ece3a500fc488a8c8365036734be2dc16ce716c,openstack/neutron-fwaas,master,I7ece3a500fc488a8c8365036734be2dc16ce716c,opt in for neutron-lib consumption patches,MERGED,2018-09-25 19:24:00.000000000,2018-09-26 17:36:06.000000000,2018-09-26 17:36:06.000000000,"[{'_account_id': 4694}, {'_account_id': 6854}, {'_account_id': 6995}, {'_account_id': 10850}, {'_account_id': 13702}, {'_account_id': 13995}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:24:00.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/314e1de7fcdae751bb5b354ed5496d94267266cb', 'message': 'opt in for neutron-lib consumption patches\n\nAs part of the Denver PTG [1] we decided networking related projects\nthat are ""current"" and want to receive neutron-lib consumption patches\non an on-going basis should indicate such with a well defined comment\nin their requirements.txt. This allows us to easily find the list of\nproject to receive neutron-lib consumption patches [2] by searching for\nthe string.\n\nIn addition, projects opting-in for these patches are also attesting\nthey will stay up to date with TC and infra initiatives to ensure\nconsumption patches can flow freely.\n\nThis patch adds the ""neutron-lib-current"" string to requirements.txt\nopting in for neutron-lib consumption patches.\n\n[1] https://etherpad.openstack.org/p/neutron-stein-ptg\n[2] https://docs.openstack.org/neutron-lib/latest/contributor/contributing.html#phase-4-consume\n\nChange-Id: I7ece3a500fc488a8c8365036734be2dc16ce716c\n'}]",0,605184,314e1de7fcdae751bb5b354ed5496d94267266cb,10,7,1,5367,,,0,"opt in for neutron-lib consumption patches

As part of the Denver PTG [1] we decided networking related projects
that are ""current"" and want to receive neutron-lib consumption patches
on an on-going basis should indicate such with a well defined comment
in their requirements.txt. This allows us to easily find the list of
project to receive neutron-lib consumption patches [2] by searching for
the string.

In addition, projects opting-in for these patches are also attesting
they will stay up to date with TC and infra initiatives to ensure
consumption patches can flow freely.

This patch adds the ""neutron-lib-current"" string to requirements.txt
opting in for neutron-lib consumption patches.

[1] https://etherpad.openstack.org/p/neutron-stein-ptg
[2] https://docs.openstack.org/neutron-lib/latest/contributor/contributing.html#phase-4-consume

Change-Id: I7ece3a500fc488a8c8365036734be2dc16ce716c
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/84/605184/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,314e1de7fcdae751bb5b354ed5496d94267266cb,neutron-lib-current-optin, # The comment below indicates this project repo is current with neutron-lib # and should receive neutron-lib consumption patches as they are released # in neutron-lib. It also implies the project will stay current with TC # and infra initiatives ensuring consumption patches can land. # neutron-lib-current,,6,0
openstack%2Fopenstacksdk~master~Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14,openstack/openstacksdk,master,Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14,Restore timeout_scaling_factor,MERGED,2018-09-23 14:43:18.000000000,2018-09-26 17:18:30.000000000,2018-09-26 17:18:30.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-23 14:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/6b1b0efbbe4b87b6df71ae232d4f3d70321d7c1b', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}, {'number': 2, 'created': '2018-09-23 17:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/dbd382adfebb4f0d6fa6879e052e67ca43168252', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}, {'number': 3, 'created': '2018-09-24 12:37:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/36219fb375243d93456d7e1a28201879b8fc088b', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nAlso, turn off keepalive in the underlying session. For devstack\nfunctional tests, we\'re seeing a lot of ""Resetting dropped connection""\nso I\'m thinking we should just disable that.\n\nAlso, increase the individual test timeout.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}, {'number': 4, 'created': '2018-09-24 14:49:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/003ccfe4408055d79953423aecd83762acb6606b', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nAlso, turn off keepalive in the underlying session. For devstack\nfunctional tests, we\'re seeing a lot of ""Resetting dropped connection""\nso I\'m thinking we should just disable that.\n\nAlso, increase the individual test timeout.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}, {'number': 5, 'created': '2018-09-24 18:45:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3c86bb5b68fda914161e982cc31edf03564c428f', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nAlso, turn off keepalive in the underlying session. For devstack\nfunctional tests, we\'re seeing a lot of ""Resetting dropped connection""\nso I\'m thinking we should just disable that.\n\nAlso, increase the individual test timeout.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}, {'number': 6, 'created': '2018-09-25 19:05:40.000000000', 'files': ['openstack/tests/base.py', 'openstack/tests/functional/base.py', 'openstack/tests/functional/network/v2/test_trunk.py', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/b5c96c5e44e43ca47e396cb4a9c8986fd684edf4', 'message': 'Restore timeout_scaling_factor\n\nIn a previous refactor, we lost the part where we actually multiple\nTIMEOUT_SCALING_FACTOR to the timeout. Whoops.\n\nAlso, turn off keepalive in the underlying session. For devstack\nfunctional tests, we\'re seeing a lot of ""Resetting dropped connection""\nso I\'m thinking we should just disable that.\n\nAlso, increase the individual test timeout, and bump the scaling factor\non trunk tests, which always seem to be timing out.\n\nChange-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14\n'}]",0,604628,b5c96c5e44e43ca47e396cb4a9c8986fd684edf4,23,3,6,2,,,0,"Restore timeout_scaling_factor

In a previous refactor, we lost the part where we actually multiple
TIMEOUT_SCALING_FACTOR to the timeout. Whoops.

Also, turn off keepalive in the underlying session. For devstack
functional tests, we're seeing a lot of ""Resetting dropped connection""
so I'm thinking we should just disable that.

Also, increase the individual test timeout, and bump the scaling factor
on trunk tests, which always seem to be timing out.

Change-Id: Ie5b3eb319fed10cabfb2e818f3fcfd52b6fd7b14
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/28/604628/2 && git format-patch -1 --stdout FETCH_HEAD,['openstack/tests/base.py'],1,6b1b0efbbe4b87b6df71ae232d4f3d70321d7c1b,discovery," test_timeout = int(os.environ.get('OS_TEST_TIMEOUT', 5)) try: test_timeout = int(test_timeout * self.TIMEOUT_SCALING_FACTOR) self.useFixture( fixtures.EnvironmentVariable('OS_TEST_TIMEOUT', test_timeout)) except ValueError: # Let oslotest do its thing pass"," self.useFixture( fixtures.EnvironmentVariable( 'OS_TEST_TIMEOUT', os.environ.get('OS_TEST_TIMEOUT', '5')))",8,3
openstack%2Fcinder~stable%2Fpike~I6b49c2590d0bd3946fa03dbac08ab4f778007111,openstack/cinder,stable/pike,I6b49c2590d0bd3946fa03dbac08ab4f778007111,VMware: Improve scalability of querying volumes,MERGED,2018-09-21 16:18:13.000000000,2018-09-26 17:01:47.000000000,2018-09-25 03:33:00.000000000,"[{'_account_id': 2243}, {'_account_id': 7198}, {'_account_id': 9171}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21976}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 25243}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-21 16:18:13.000000000', 'files': ['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/unit/volume/drivers/vmware/test_vmware_volumeops.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/247b997eafb6d8fc271c94dca3643e84126abe00', 'message': 'VMware: Improve scalability of querying volumes\n\nCurrently we query volumes in vCenter by name which is not scalable.\nCommit 6b9464e91840f6e006f537dcd3c0f656ae90a179 sets the backend\nvolume ID to Cinder volume ID so that we can use vCenter SearchIndex\nAPI to query backend volumes by Cinder volume ID.\n\nThis patch uses SearchIndex API to improve scalability. But this type\nof querying will not work for legacy volumes whose vCenter ID is not\nset to Cinder volume ID. To handle those volumes, we build a cache to\nmap their names to vCenter references during driver setup.\n\nCloses-bug: #1600754\nChange-Id: I6b49c2590d0bd3946fa03dbac08ab4f778007111\n(cherry picked from commit 46b8da35d79121df34ec9befd353c8c428be846b)\n'}]",1,604408,247b997eafb6d8fc271c94dca3643e84126abe00,24,22,1,14892,,,0,"VMware: Improve scalability of querying volumes

Currently we query volumes in vCenter by name which is not scalable.
Commit 6b9464e91840f6e006f537dcd3c0f656ae90a179 sets the backend
volume ID to Cinder volume ID so that we can use vCenter SearchIndex
API to query backend volumes by Cinder volume ID.

This patch uses SearchIndex API to improve scalability. But this type
of querying will not work for legacy volumes whose vCenter ID is not
set to Cinder volume ID. To handle those volumes, we build a cache to
map their names to vCenter references during driver setup.

Closes-bug: #1600754
Change-Id: I6b49c2590d0bd3946fa03dbac08ab4f778007111
(cherry picked from commit 46b8da35d79121df34ec9befd353c8c428be846b)
",git fetch https://review.opendev.org/openstack/cinder refs/changes/08/604408/1 && git format-patch -1 --stdout FETCH_HEAD,"['cinder/tests/unit/volume/drivers/vmware/test_vmware_vmdk.py', 'cinder/volume/drivers/vmware/vmdk.py', 'cinder/volume/drivers/vmware/volumeops.py', 'cinder/tests/unit/volume/drivers/vmware/test_vmware_volumeops.py']",4,247b997eafb6d8fc271c94dca3643e84126abe00,bug/1600754-stable/pike," @mock.patch('cinder.volume.drivers.vmware.volumeops.VMwareVolumeOps.' 'get_backing_by_uuid') def test_get_backing(self, get_backing_by_uuid): ref = mock.sentinel.ref get_backing_by_uuid.return_value = ref name = mock.sentinel.name backing_uuid = mock.sentinel.backing_uuid ret = self.vops.get_backing(name, backing_uuid) self.assertEqual(ref, ret) get_backing_by_uuid.assert_called_once_with(backing_uuid) @mock.patch('cinder.volume.drivers.vmware.volumeops.VMwareVolumeOps.' 'get_backing_by_uuid') def test_get_backing_legacy(self, get_backing_by_uuid): ref = mock.sentinel.ref get_backing_by_uuid.return_value = None name = mock.sentinel.name self.vops._backing_ref_cache[name] = ref backing_uuid = mock.sentinel.backing_uuid ret = self.vops.get_backing(name, backing_uuid) self.assertEqual(ref, ret) get_backing_by_uuid.assert_called_once_with(backing_uuid) def _create_property(self, name, val): prop = mock.Mock() prop.name = name prop.val = val return prop def _create_backing_obj(self, name, ref, instance_uuid=None, vol_id=None): name_prop = self._create_property('name', name) instance_uuid_prop = self._create_property('config.instanceUuid', instance_uuid) vol_id_val = mock.Mock(value=vol_id) vol_id_prop = self._create_property( 'config.extraConfig[""cinder.volume.id""]', vol_id_val) backing = mock.Mock() backing.obj = ref backing.propSet = [name_prop, instance_uuid_prop, vol_id_prop] return backing @mock.patch('cinder.volume.drivers.vmware.volumeops.VMwareVolumeOps.' 'continue_retrieval', return_value=None) def test_build_backing_ref_cache(self, continue_retrieval): uuid1 = 'd68cbee0-c1f7-4886-98a4-cf2201461c6e' ref1 = mock.sentinel.ref1 non_vol_backing = self._create_backing_obj( 'foo', ref1, instance_uuid=uuid1) uuid2 = 'f36f0e87-97e0-4a1c-b788-2f84f1376960' ref2 = mock.sentinel.ref2 legacy_vol_backing = self._create_backing_obj( 'volume-f36f0e87-97e0-4a1c-b788-2f84f1376960', ref2, instance_uuid=uuid2) uuid3 = '405d6afd-43be-4ce0-9e5f-fd49559e2763' ref3 = mock.sentinel.ref3 vol_backing = self._create_backing_obj( 'volume-405d6afd-43be-4ce0-9e5f-fd49559e2763', ref3, instance_uuid=uuid3, vol_id=uuid3) result = mock.Mock(objects=[ non_vol_backing, legacy_vol_backing, vol_backing]) self.session.invoke_api.return_value = result self.vops.build_backing_ref_cache() exp_cache = {'foo': ref1, 'volume-f36f0e87-97e0-4a1c-b788-2f84f1376960': ref2} self.assertEqual(exp_cache, self.vops._backing_ref_cache) self.session.invoke_api.assert_called_once_with( vim_util, 'get_objects', self.session.vim, 'VirtualMachine', self.MAX_OBJECTS, properties_to_collect=[ 'name', 'config.instanceUuid', 'config.extraConfig[""cinder.volume.id""]']) continue_retrieval.assert_called_once_with(result) "," def test_get_backing(self): name = 'mock-backing' # Test no result self.session.invoke_api.return_value = None result = self.vops.get_backing(name) self.assertIsNone(result) self.session.invoke_api.assert_called_once_with(vim_util, 'get_objects', self.session.vim, 'VirtualMachine', self.MAX_OBJECTS) # Test single result vm = self.vm(name) vm.obj = mock.sentinel.vm_obj retrieve_result = mock.Mock(spec=object) retrieve_result.objects = [vm] self.session.invoke_api.return_value = retrieve_result self.vops.cancel_retrieval = mock.Mock(spec=object) result = self.vops.get_backing(name) self.assertEqual(mock.sentinel.vm_obj, result) self.session.invoke_api.assert_called_with(vim_util, 'get_objects', self.session.vim, 'VirtualMachine', self.MAX_OBJECTS) self.vops.cancel_retrieval.assert_called_once_with(retrieve_result) # Test multiple results retrieve_result2 = mock.Mock(spec=object) retrieve_result2.objects = [vm('1'), vm('2'), vm('3')] self.session.invoke_api.return_value = retrieve_result2 self.vops.continue_retrieval = mock.Mock(spec=object) self.vops.continue_retrieval.return_value = retrieve_result result = self.vops.get_backing(name) self.assertEqual(mock.sentinel.vm_obj, result) self.session.invoke_api.assert_called_with(vim_util, 'get_objects', self.session.vim, 'VirtualMachine', self.MAX_OBJECTS) self.vops.continue_retrieval.assert_called_once_with(retrieve_result2) self.vops.cancel_retrieval.assert_called_with(retrieve_result)",190,89
openstack%2Fcharm-vault~stable%2F18.08~I2574da2f7e6520d4c9bc8e5b9f03b5723840b5c8,openstack/charm-vault,stable/18.08,I2574da2f7e6520d4c9bc8e5b9f03b5723840b5c8,Only try to unseal vault when leader has set keys,MERGED,2018-09-26 08:01:59.000000000,2018-09-26 16:58:56.000000000,2018-09-26 16:58:55.000000000,"[{'_account_id': 12549}, {'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 08:01:59.000000000', 'files': ['src/lib/charm/vault.py', 'unit_tests/test_lib_charm_vault.py'], 'web_link': 'https://opendev.org/openstack/charm-vault/commit/c0152218ce6f2814e516e52f442c3c67c9409978', 'message': 'Only try to unseal vault when leader has set keys\n\nChange-Id: I2574da2f7e6520d4c9bc8e5b9f03b5723840b5c8\nCloses-Bug: #1792603\n(cherry picked from commit e621b4dec01aab895e33e3d66f6a22fc39435664)\n'}]",0,605347,c0152218ce6f2814e516e52f442c3c67c9409978,9,5,1,12549,,,0,"Only try to unseal vault when leader has set keys

Change-Id: I2574da2f7e6520d4c9bc8e5b9f03b5723840b5c8
Closes-Bug: #1792603
(cherry picked from commit e621b4dec01aab895e33e3d66f6a22fc39435664)
",git fetch https://review.opendev.org/openstack/charm-vault refs/changes/47/605347/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/lib/charm/vault.py', 'unit_tests/test_lib_charm_vault.py']",2,c0152218ce6f2814e516e52f442c3c67c9409978,bug/1792603-stable/18.08," @patch.object(vault.hookenv, 'leader_get') setup_charm_vault_access, leader_set, leader_get): leader_get.return_value = ""[]"" @patch.object(vault.hookenv, 'leader_get') unseal_vault, is_leader, leader_set, leader_get): leader_get.return_value = ""[]"" @patch.object(vault.hookenv, 'leader_get') leader_set, leader_get): leader_get.return_value = ""[]"""," setup_charm_vault_access, leader_set): unseal_vault, is_leader, leader_set): leader_set):",12,4
openstack%2Fnova~master~I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be,openstack/nova,master,I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be,placement: Always reset conf.CONF when starting the wsgi app,MERGED,2018-09-24 08:03:09.000000000,2018-09-26 16:58:52.000000000,2018-09-26 16:58:52.000000000,"[{'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26490}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-09-24 08:03:09.000000000', 'files': ['nova/api/openstack/placement/wsgi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/601aa94a2fb9b0d1a884ddecc7a6a5e1f5f8686b', 'message': 'placement: Always reset conf.CONF when starting the wsgi app\n\nThis ensures that options loaded during any prior run of the application\nare dropped before being added again during init_application.\n\nChange-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be\nCloses-bug: #1784155\n(cherry picked from commit ac88b596c60f6c48c0e4c8e878a3ee70c4c2b756)\n'}]",0,604693,601aa94a2fb9b0d1a884ddecc7a6a5e1f5f8686b,46,16,1,10135,,,0,"placement: Always reset conf.CONF when starting the wsgi app

This ensures that options loaded during any prior run of the application
are dropped before being added again during init_application.

Change-Id: I41b5c7990d4d62a3a397f1686261f3fb7dc1a0be
Closes-bug: #1784155
(cherry picked from commit ac88b596c60f6c48c0e4c8e878a3ee70c4c2b756)
",git fetch https://review.opendev.org/openstack/nova refs/changes/93/604693/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/placement/wsgi.py'],1,601aa94a2fb9b0d1a884ddecc7a6a5e1f5f8686b,bug/1784155, # NOTE(lyarwood): Call reset to ensure the ConfigOpts object doesn't # already contain registered options if the app is reloaded. conf.CONF.reset() ,,5,0
openstack%2Fopenstack-ansible-lxc_hosts~master~Ia41ffaa21fede271263c1757de949e65f6f30a67,openstack/openstack-ansible-lxc_hosts,master,Ia41ffaa21fede271263c1757de949e65f6f30a67,tasks: lxc_install_zypper: Use the 'state' option for external repos,MERGED,2018-09-25 15:21:47.000000000,2018-09-26 16:43:12.000000000,2018-09-26 16:43:12.000000000,"[{'_account_id': 538}, {'_account_id': 1004}, {'_account_id': 2799}, {'_account_id': 6816}, {'_account_id': 7353}, {'_account_id': 7414}, {'_account_id': 10607}, {'_account_id': 12402}, {'_account_id': 13095}, {'_account_id': 14805}, {'_account_id': 15993}, {'_account_id': 17068}, {'_account_id': 17799}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2018-09-25 15:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/b8d9658a02c8b17d382a32ebcb087b143495d95f', 'message': ""tasks: lxc_install_zypper: Use the 'state' option for external repos\n\nThe state of the Containers repository depends on the Leap version\nthat's being used. Before this patch, we did not override the default\nvalue of the 'state' option so the repository was always added. However,\nwe don't need to use this repo for Leap 15 so we need to use the 'state'\nvalue from the distro variables.\n\nChange-Id: Ia41ffaa21fede271263c1757de949e65f6f30a67\n""}, {'number': 2, 'created': '2018-09-26 07:23:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/bbf7d57bb0f914a953393795870a199067c570b8', 'message': ""tasks: lxc_install_zypper: Use the 'state' option for external repos\n\nThe state of the Containers repository depends on the Leap version\nthat's being used. Before this patch, we did not override the default\nvalue of the 'state' option so the repository was always added. However,\nwe don't need to use this repo for Leap 15 so we need to use the 'state'\nvalue from the distro variables.\n\nChange-Id: Ia41ffaa21fede271263c1757de949e65f6f30a67\n""}, {'number': 3, 'created': '2018-09-26 09:19:32.000000000', 'files': ['vars/suse-42-host.yml', 'tasks/lxc_install_zypper.yml', 'vars/suse-host.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/79bdebb9defbe6eeb9b7b46d749b58371143489c', 'message': ""tasks: lxc_install_zypper: Use the 'state' option for external repos\n\nThe state of the Containers repository depends on the Leap version\nthat's being used. Before this patch, we did not override the default\nvalue of the 'state' option so the repository was always added. However,\nwe don't need to use this repo for Leap 15 so we need to use the 'state'\nvalue from the distro variables.\n\nChange-Id: Ia41ffaa21fede271263c1757de949e65f6f30a67\n""}]",0,605102,79bdebb9defbe6eeb9b7b46d749b58371143489c,11,15,3,23163,,,0,"tasks: lxc_install_zypper: Use the 'state' option for external repos

The state of the Containers repository depends on the Leap version
that's being used. Before this patch, we did not override the default
value of the 'state' option so the repository was always added. However,
we don't need to use this repo for Leap 15 so we need to use the 'state'
value from the distro variables.

Change-Id: Ia41ffaa21fede271263c1757de949e65f6f30a67
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/02/605102/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/lxc_install_zypper.yml'],1,b8d9658a02c8b17d382a32ebcb087b143495d95f,osa-add-leap-150," state: ""{{ item.state }}""",,1,0
openstack%2Fneutron~master~I0a954de724384a81cb45446da20fa6b17d4bd63a,openstack/neutron,master,I0a954de724384a81cb45446da20fa6b17d4bd63a,doc: add known limitation about attaching SR-IOV ports,MERGED,2018-08-21 15:40:48.000000000,2018-09-26 16:29:24.000000000,2018-08-25 00:23:13.000000000,"[{'_account_id': 1131}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 25625}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2018-08-21 15:40:48.000000000', 'files': ['doc/source/admin/config-sriov.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/60a9248b17cad8d2e7dd49cea120348dda99dc2b', 'message': 'doc: add known limitation about attaching SR-IOV ports\n\nNova does not currently support attaching SR-IOV ports to\nexisting instances, you can only create a server with an\nSR-IOV port at this time. This adds an item about that\nlimitation to the SR-IOV admin docs.\n\nChange-Id: I0a954de724384a81cb45446da20fa6b17d4bd63a\nRelated-Bug: #1708433\n'}]",0,594325,60a9248b17cad8d2e7dd49cea120348dda99dc2b,14,9,1,6873,,,0,"doc: add known limitation about attaching SR-IOV ports

Nova does not currently support attaching SR-IOV ports to
existing instances, you can only create a server with an
SR-IOV port at this time. This adds an item about that
limitation to the SR-IOV admin docs.

Change-Id: I0a954de724384a81cb45446da20fa6b17d4bd63a
Related-Bug: #1708433
",git fetch https://review.opendev.org/openstack/neutron refs/changes/25/594325/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-sriov.rst'],1,60a9248b17cad8d2e7dd49cea120348dda99dc2b,bug/1708433,"* Attaching SR-IOV ports to existing servers is not currently supported, see `bug 1708433 <https://bugs.launchpad.net/nova/+bug/1708433>`_ for details.",,2,0
openstack%2Ftempest~master~I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4,openstack/tempest,master,I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4,Set max microversion 2.43 for add_fixed_ip,MERGED,2018-08-01 09:15:43.000000000,2018-09-26 16:23:21.000000000,2018-08-17 17:26:02.000000000,"[{'_account_id': 6167}, {'_account_id': 8556}, {'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20190}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-08-01 09:15:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8240a5201f0d766f4ee1801580801ee422244f19', 'message': 'Set max microversion 2.43 for add_fixed_ip\n\nadd_fixed_ip is deprecated from microversion 2.44, so this is\nto set microversion 2.43 for add_fixed_ip.\n\nhttps://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated\n\nChange-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4\n'}, {'number': 2, 'created': '2018-08-02 01:31:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/b5800d30166933d075bf0c8e61bfc26fdda22477', 'message': 'Set max microversion 2.43 for add_fixed_ip\n\nadd_fixed_ip is deprecated from microversion 2.44, so this is\nto set microversion 2.43 for add_fixed_ip.\n\nhttps://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated\n\npartially-implements: blueprint clear-deprecated-api\n\nChange-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4\n'}, {'number': 3, 'created': '2018-08-02 03:39:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/5e3c5d3dfc96c51bb977b8a47bc3b825ac3f7089', 'message': 'Set max microversion 2.43 for add_fixed_ip\n\nadd_fixed_ip is deprecated from microversion 2.44, so this is\nto set microversion 2.43 for add_fixed_ip.\n\nhttps://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated\n\npartially-implements: blueprint clear-deprecated-api\n\nChange-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4\n'}, {'number': 4, 'created': '2018-08-14 02:24:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/feb9359871fa4a432dd444f8b30a4b438c735b6f', 'message': 'Set max microversion 2.43 for add_fixed_ip\n\nadd_fixed_ip is deprecated from microversion 2.44, so this is\nto set microversion 2.43 for add_fixed_ip.\n\nhttps://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated\n\npartially-implements: blueprint clear-deprecated-api\n\nChange-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4\n'}, {'number': 5, 'created': '2018-08-14 05:55:45.000000000', 'files': ['tempest/api/compute/servers/test_attach_interfaces.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/615e63b77c35389532a0a1e4706861561f6dee85', 'message': 'Set max microversion 2.43 for add_fixed_ip\n\nadd_fixed_ip is deprecated from microversion 2.44, so this is\nto set microversion 2.43 for add_fixed_ip.\n\nhttps://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated\n\npartially-implements: blueprint clear-deprecated-api\n\nChange-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4\n'}]",16,587734,615e63b77c35389532a0a1e4706861561f6dee85,41,7,5,20190,,,0,"Set max microversion 2.43 for add_fixed_ip

add_fixed_ip is deprecated from microversion 2.44, so this is
to set microversion 2.43 for add_fixed_ip.

https://developer.openstack.org/api-ref/compute/#add-associate-fixed-ip-addfixedip-action-deprecated

partially-implements: blueprint clear-deprecated-api

Change-Id: I78b19b06fecc0191958e9ff0e8b203cd5ab9a8a4
",git fetch https://review.opendev.org/openstack/tempest refs/changes/34/587734/2 && git format-patch -1 --stdout FETCH_HEAD,['tempest/api/compute/servers/test_attach_interfaces.py'],1,8240a5201f0d766f4ee1801580801ee422244f19,bp/clear-deprecated-api,"class AttachInterfacesTestBase(base.BaseV2ComputeTest): def _create_server_get_interfaces(self): server = self.create_test_server(wait_until='ACTIVE') ifs = (self.interfaces_client.list_interfaces(server['id']) ['interfaceAttachments']) body = waiters.wait_for_interface_status( self.interfaces_client, server['id'], ifs[0]['port_id'], 'ACTIVE') ifs[0]['port_state'] = body['port_state'] return server, ifs class AttachInterfacesTestJSON(AttachInterfacesTestBase): class AttachInterfacesTestV243(AttachInterfacesTestBase): max_microversion = '2.43' @decorators.attr(type='smoke') @decorators.idempotent_id('c7e0e60b-ee45-43d0-abeb-8596fd42a2f9') @utils.services('network') def test_add_remove_fixed_ip(self): # Add and Remove the fixed IP to server. server, ifs = self._create_server_get_interfaces() interface_count = len(ifs) self.assertGreater(interface_count, 0) network_id = ifs[0]['net_id'] self.servers_client.add_fixed_ip(server['id'], networkId=network_id) # Remove the fixed IP from server. server_detail = self.os_primary.servers_client.show_server( server['id'])['server'] # Get the Fixed IP from server. fixed_ip = None for ip_set in server_detail['addresses']: for ip in server_detail['addresses'][ip_set]: if ip['OS-EXT-IPS:type'] == 'fixed': fixed_ip = ip['addr'] break if fixed_ip is not None: break self.servers_client.remove_fixed_ip(server['id'], address=fixed_ip)","class AttachInterfacesTestJSON(base.BaseV2ComputeTest): def _create_server_get_interfaces(self): server = self.create_test_server(wait_until='ACTIVE') ifs = (self.interfaces_client.list_interfaces(server['id']) ['interfaceAttachments']) body = waiters.wait_for_interface_status( self.interfaces_client, server['id'], ifs[0]['port_id'], 'ACTIVE') ifs[0]['port_state'] = body['port_state'] return server, ifs @decorators.attr(type='smoke') @decorators.idempotent_id('c7e0e60b-ee45-43d0-abeb-8596fd42a2f9') @utils.services('network') def test_add_remove_fixed_ip(self): # Add and Remove the fixed IP to server. server, ifs = self._create_server_get_interfaces() interface_count = len(ifs) self.assertGreater(interface_count, 0) network_id = ifs[0]['net_id'] self.servers_client.add_fixed_ip(server['id'], networkId=network_id) # Remove the fixed IP from server. server_detail = self.os_primary.servers_client.show_server( server['id'])['server'] # Get the Fixed IP from server. fixed_ip = None for ip_set in server_detail['addresses']: for ip in server_detail['addresses'][ip_set]: if ip['OS-EXT-IPS:type'] == 'fixed': fixed_ip = ip['addr'] break if fixed_ip is not None: break self.servers_client.remove_fixed_ip(server['id'], address=fixed_ip) ",40,34
openstack%2Fnova~master~I1d2965b436c896e5a8dacbce26f74055faa89128,openstack/nova,master,I1d2965b436c896e5a8dacbce26f74055faa89128,VMware: ensure that live migration attaches to correct interface,ABANDONED,2017-06-29 08:29:19.000000000,2018-09-26 15:53:28.000000000,,"[{'_account_id': 1653}, {'_account_id': 6873}, {'_account_id': 7400}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9172}, {'_account_id': 10118}, {'_account_id': 11564}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 20040}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2017-06-29 08:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2c7eef89b0f03b364ad7c8b02f1d3fa13ad517de', 'message': 'VMware: ensure that live migration attaches to correct interface\n\nEnsure that the live mifgration attaches to the correct neutron\nport group or opaque network\n\nWhen we do the live migration we make sure that the correct\nnetwork backings are used.\n\nChange-Id: I1d2965b436c896e5a8dacbce26f74055faa89128\n'}, {'number': 2, 'created': '2017-06-29 08:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ce6ab2ea486493947f7e0ac256f3a3e26778a08c', 'message': 'VMware: ensure that live migration attaches to correct interface\n\nEnsure that the live mifgration attaches to the correct neutron\nport group or opaque network\n\nWhen we do the live migration we make sure that the correct\nnetwork backings are used.\n\nChange-Id: I1d2965b436c896e5a8dacbce26f74055faa89128\n'}, {'number': 3, 'created': '2017-09-20 11:01:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7c3bdc939c8ab82602d3743c7c9b9b736e2b2c02', 'message': 'VMware: ensure that live migration attaches to correct interface\n\nEnsure that the live mifgration attaches to the correct neutron\nport group or opaque network\n\nWhen we do the live migration we make sure that the correct\nnetwork backings are used.\n\nChange-Id: I1d2965b436c896e5a8dacbce26f74055faa89128\n'}, {'number': 4, 'created': '2018-07-12 12:01:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/569e816aff8fbd899bb40e67a040dd6ece4e5ad3', 'message': 'VMware: ensure that live migration attaches to correct interface\n\nEnsure that the live migration attaches to the correct neutron\nport group or opaque network.\n\nWhen we do the live migration we make sure that the correct\nnetwork backings are used.\n\nChange-Id: I1d2965b436c896e5a8dacbce26f74055faa89128\n'}, {'number': 5, 'created': '2018-07-12 14:08:27.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/ce3d1bff59ba705a9dc6428fc0644b5d954fdfcb', 'message': 'VMware: ensure that live migration attaches to correct interface\n\nEnsure that the live migration attaches to the correct neutron\nport group or opaque network.\n\nWhen we do the live migration we make sure that the correct\nnetwork backings are used.\n\nChange-Id: I1d2965b436c896e5a8dacbce26f74055faa89128\n'}]",5,478797,ce3d1bff59ba705a9dc6428fc0644b5d954fdfcb,57,20,5,1653,,,0,"VMware: ensure that live migration attaches to correct interface

Ensure that the live migration attaches to the correct neutron
port group or opaque network.

When we do the live migration we make sure that the correct
network backings are used.

Change-Id: I1d2965b436c896e5a8dacbce26f74055faa89128
",git fetch https://review.opendev.org/openstack/nova refs/changes/97/478797/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py', 'nova/virt/vmwareapi/vm_util.py']",3,2c7eef89b0f03b364ad7c8b02f1d3fa13ad517de,live-migration-networking,"def update_vif_spec(client_factory, vif_info, device): """"""Updates the backing for the VIF spec."""""" network_spec = client_factory.create('ns0:VirtualDeviceConfigSpec') network_spec.operation = 'edit' network_ref = vif_info['network_ref'] network_name = vif_info['network_name'] if network_ref and network_ref['type'] == 'OpaqueNetwork': backing = client_factory.create( 'ns0:VirtualEthernetCardOpaqueNetworkBackingInfo') backing.opaqueNetworkId = network_ref['network-id'] backing.opaqueNetworkType = network_ref['network-type'] # Configure externalId if network_ref['use-external-id']: if hasattr(device, 'externalId'): device.externalId = vif_info['iface_id'] else: dp = client_factory.create('ns0:DynamicProperty') dp.name = ""__externalId__"" dp.val = vif_info['iface_id'] device.dynamicProperty = [dp] elif (network_ref and network_ref['type'] == ""DistributedVirtualPortgroup""): backing = client_factory.create( 'ns0:VirtualEthernetCardDistributedVirtualPortBackingInfo') portgroup = client_factory.create( 'ns0:DistributedVirtualSwitchPortConnection') portgroup.switchUuid = network_ref['dvsw'] portgroup.portgroupKey = network_ref['dvpg'] backing.port = portgroup else: backing = client_factory.create( 'ns0:VirtualEthernetCardNetworkBackingInfo') backing.deviceName = network_name device.backing = backing network_spec.device = device return network_spec disk_move_type=""moveAllDiskBackingsAndAllowSharing"", devices=None): if devices is not None: rel_spec.deviceChange = devices disk_move_type=""moveAllDiskBackingsAndAllowSharing"", devices=None): disk_move_type, devices)"," disk_move_type=""moveAllDiskBackingsAndAllowSharing""): disk_move_type=""moveAllDiskBackingsAndAllowSharing""): disk_move_type)",88,10
openstack%2Fansible-role-redhat-subscription~master~I5658fa97e32193045c9da29126e824a884054e60,openstack/ansible-role-redhat-subscription,master,I5658fa97e32193045c9da29126e824a884054e60,Add support for RHSM Pools,MERGED,2018-09-26 01:44:39.000000000,2018-09-26 15:51:52.000000000,2018-09-26 15:51:51.000000000,"[{'_account_id': 14985}, {'_account_id': 18851}, {'_account_id': 22348}, {'_account_id': 27253}, {'_account_id': 28223}]","[{'number': 1, 'created': '2018-09-26 01:44:39.000000000', 'files': ['tasks/portal.yml', 'README.md'], 'web_link': 'https://opendev.org/openstack/ansible-role-redhat-subscription/commit/8797a909ea50f477be6dfa11c14b920fe78938ef', 'message': 'Add support for RHSM Pools\n\nSupport rhsm_pool_ids parameter (it was documented but not used).\nThis parameter helps to specify the subscription pool IDs to consume.\n\nA pool ID may be specified as a string - just the pool ID\n(ex. 0123456789abcdef0123456789abcdef), or as a dict with the pool ID as the\nkey, and a quantity as the value (ex. 0123456789abcdef0123456789abcdef: 2).\nIf the quantity is provided, it is used to consume multiple entitlements from\na pool (the pool must support this).\n\nChange-Id: I5658fa97e32193045c9da29126e824a884054e60\n'}]",0,605290,8797a909ea50f477be6dfa11c14b920fe78938ef,9,5,1,3153,,,0,"Add support for RHSM Pools

Support rhsm_pool_ids parameter (it was documented but not used).
This parameter helps to specify the subscription pool IDs to consume.

A pool ID may be specified as a string - just the pool ID
(ex. 0123456789abcdef0123456789abcdef), or as a dict with the pool ID as the
key, and a quantity as the value (ex. 0123456789abcdef0123456789abcdef: 2).
If the quantity is provided, it is used to consume multiple entitlements from
a pool (the pool must support this).

Change-Id: I5658fa97e32193045c9da29126e824a884054e60
",git fetch https://review.opendev.org/openstack/ansible-role-redhat-subscription refs/changes/90/605290/1 && git format-patch -1 --stdout FETCH_HEAD,"['tasks/portal.yml', 'README.md']",2,8797a909ea50f477be6dfa11c14b920fe78938ef,pool,| `rhsm_pool_ids` | `[undefined]` | Red Hat Subscription pool IDs to consume. |,,2,0
openstack%2Fnova~master~Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d,openstack/nova,master,Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d,Explicitly fail if trying to attach SR-IOV port,MERGED,2018-08-15 05:40:01.000000000,2018-09-26 15:47:02.000000000,2018-09-18 20:13:52.000000000,"[{'_account_id': 782}, {'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 8871}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 10608}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15334}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17120}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 28375}]","[{'number': 1, 'created': '2018-08-15 05:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0de199e504d7925ebbe1e764698097c43e6ad26d', 'message': 'WIP: Explicitly fail if trying to attach SR-IOV port\n\nAttaching SR-IOV ports to existing instances is not supported\nsince the compute service does not perform any kind of PCI\ndevice allocation, so we should fail fast with a clear error\nif attempted. Note that the compute RPC API ""attach_interface""\nmethod is an RPC call from nova-api to nova-compute so the error\nraised here will result in a 400 response to the user.\n\nChange-Id: Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d\nCloses-Bug: #1708433\n'}, {'number': 2, 'created': '2018-08-16 05:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/107cdd2cf818a8c6f6aee6d41bd3b6ec8e922a2b', 'message': 'Explicitly fail if trying to attach SR-IOV port\n\nAttaching SR-IOV ports to existing instances is not supported\nsince the compute service does not perform any kind of PCI\ndevice allocation, so we should fail fast with a clear error\nif attempted. Note that the compute RPC API ""attach_interface""\nmethod is an RPC call from nova-api to nova-compute so the error\nraised here will result in a 400 response to the user.\n\nBlueprint sriov-interface-attach-detach would need to be\nimplemented to support this use case, and could arguably involve\na microversion to indicate when the feature was made available.\n\nChange-Id: Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d\nCloses-Bug: #1708433\n'}, {'number': 3, 'created': '2018-08-21 15:42:08.000000000', 'files': ['nova/tests/unit/network/test_neutronv2.py', 'nova/network/neutronv2/api.py', 'nova/exception.py', 'doc/source/admin/pci-passthrough.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/68011c40ae2ab0900674408a88f62a60a802fef7', 'message': 'Explicitly fail if trying to attach SR-IOV port\n\nAttaching SR-IOV ports to existing instances is not supported\nsince the compute service does not perform any kind of PCI\ndevice allocation, so we should fail fast with a clear error\nif attempted. Note that the compute RPC API ""attach_interface""\nmethod is an RPC call from nova-api to nova-compute so the error\nraised here will result in a 400 response to the user.\n\nBlueprint sriov-interface-attach-detach would need to be\nimplemented to support this use case, and could arguably involve\na microversion to indicate when the feature was made available.\n\nA related neutron docs patch https://review.openstack.org/594325\nis posted for mentioning the limitation with SR-IOV port attach\nas well.\n\nChange-Id: Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d\nCloses-Bug: #1708433\n'}]",7,591898,68011c40ae2ab0900674408a88f62a60a802fef7,94,25,3,6873,,,0,"Explicitly fail if trying to attach SR-IOV port

Attaching SR-IOV ports to existing instances is not supported
since the compute service does not perform any kind of PCI
device allocation, so we should fail fast with a clear error
if attempted. Note that the compute RPC API ""attach_interface""
method is an RPC call from nova-api to nova-compute so the error
raised here will result in a 400 response to the user.

Blueprint sriov-interface-attach-detach would need to be
implemented to support this use case, and could arguably involve
a microversion to indicate when the feature was made available.

A related neutron docs patch https://review.openstack.org/594325
is posted for mentioning the limitation with SR-IOV port attach
as well.

Change-Id: Ibbf2bd3cdd45bcd61eebff883c30ded525b2495d
Closes-Bug: #1708433
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/591898/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/network/neutronv2/api.py', 'nova/exception.py']",2,0de199e504d7925ebbe1e764698097c43e6ad26d,bug/1708433,class AttachSRIOVPortNotSupported(Invalid): msg_fmt = _('Attaching SR-IOV port %(port_id)s to server ' '%(instance_uuid)s is not supported. SR-IOV ports must be ' 'specified during server creation.') ,,28,4
openstack%2Fnova~stable%2Fqueens~Ia3fbb9c46c15826fc363286ce48984f59cbe1e62,openstack/nova,stable/queens,Ia3fbb9c46c15826fc363286ce48984f59cbe1e62,nova-status - don't count deleted compute_nodes,MERGED,2018-09-24 13:48:26.000000000,2018-09-26 15:46:35.000000000,2018-09-26 15:46:35.000000000,"[{'_account_id': 782}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}, {'_account_id': 23561}]","[{'number': 1, 'created': '2018-09-24 13:48:26.000000000', 'files': ['nova/tests/unit/cmd/test_status.py', 'nova/cmd/status.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/72d2e82e1275035c70cb6862ff15dc41b3d9b621', 'message': ""nova-status - don't count deleted compute_nodes\n\nWhen counting rows in the compute_nodes table to compare against\nresource records, those which have been marked as deleted should\nnot be counted, otherwise the result is artificially high.\n\nChange-Id: Ia3fbb9c46c15826fc363286ce48984f59cbe1e62\nCloses-Bug: #1757207\n(cherry picked from commit 3e902313e9c3117e76d6adf88a2f104bc229374c)\n""}]",0,604786,72d2e82e1275035c70cb6862ff15dc41b3d9b621,18,9,1,9373,,,0,"nova-status - don't count deleted compute_nodes

When counting rows in the compute_nodes table to compare against
resource records, those which have been marked as deleted should
not be counted, otherwise the result is artificially high.

Change-Id: Ia3fbb9c46c15826fc363286ce48984f59cbe1e62
Closes-Bug: #1757207
(cherry picked from commit 3e902313e9c3117e76d6adf88a2f104bc229374c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/86/604786/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/cmd/test_status.py', 'nova/cmd/status.py']",2,72d2e82e1275035c70cb6862ff15dc41b3d9b621,bug/1757207, return select([sqlfunc.count()]).select_from(compute_nodes).where( compute_nodes.c.deleted == 0).scalar(), return select([sqlfunc.count()]).select_from(compute_nodes).scalar(),18,1
openstack%2Fnova~stable%2Fqueens~Ib3c71593a9fad48eb86ccc4f5c0209fbef89edb9,openstack/nova,stable/queens,Ib3c71593a9fad48eb86ccc4f5c0209fbef89edb9,Follow devstack-plugin-ceph job rename,MERGED,2018-09-12 12:45:05.000000000,2018-09-26 15:46:28.000000000,2018-09-26 15:46:28.000000000,"[{'_account_id': 6547}, {'_account_id': 6873}, {'_account_id': 8556}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 10385}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-12 12:45:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af561eb3045eca703e6c5afeb95e2a06c8605530', 'message': 'Follow devstack-plugin-ceph job rename\n\nThe devstack-plugin-ceph jobs have migrated to zuul v3\n& in-repo and renamed[1], this commit use the new job.\n\nPatch removing old job from openstack-infra/openstack-zuul-jobs[2]\n[1] https://review.openstack.org/543048\n[2] https://review.openstack.org/#/c/601316/\n\nChange-Id: Ib3c71593a9fad48eb86ccc4f5c0209fbef89edb9\n(cherry picked from commit e18ed6b00caeaace11d2cd6a355bc53780157b08)\n'}, {'number': 2, 'created': '2018-09-12 12:49:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/nova/commit/4472c11be8858bb21c5f86ef8ffc6650a3e11cbb', 'message': 'Follow devstack-plugin-ceph job rename\n\nThe devstack-plugin-ceph jobs have migrated to zuul v3\n& in-repo and renamed[1], this commit use the new job.\n\nPatch removing old job from openstack-infra/openstack-zuul-jobs[2]\n[1] https://review.openstack.org/543048\n[2] https://review.openstack.org/#/c/601316/\n\nChange-Id: Ib3c71593a9fad48eb86ccc4f5c0209fbef89edb9\n(cherry picked from commit e18ed6b00caeaace11d2cd6a355bc53780157b08)\n'}]",1,602019,4472c11be8858bb21c5f86ef8ffc6650a3e11cbb,18,10,2,8556,,,0,"Follow devstack-plugin-ceph job rename

The devstack-plugin-ceph jobs have migrated to zuul v3
& in-repo and renamed[1], this commit use the new job.

Patch removing old job from openstack-infra/openstack-zuul-jobs[2]
[1] https://review.openstack.org/543048
[2] https://review.openstack.org/#/c/601316/

Change-Id: Ib3c71593a9fad48eb86ccc4f5c0209fbef89edb9
(cherry picked from commit e18ed6b00caeaace11d2cd6a355bc53780157b08)
",git fetch https://review.opendev.org/openstack/nova refs/changes/19/602019/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,af561eb3045eca703e6c5afeb95e2a06c8605530,, - devstack-plugin-ceph-tempest: - devstack-plugin-ceph-tempest-py3:, - legacy-tempest-dsvm-full-devstack-plugin-ceph: - legacy-tempest-dsvm-nova-v20-api: irrelevant-files: - legacy-tempest-dsvm-py35-full-devstack-plugin-ceph:,2,4
openstack%2Fneutron~master~I11ae8f6f3c8e018c1fcf7b22de4675976a1a7eb7,openstack/neutron,master,I11ae8f6f3c8e018c1fcf7b22de4675976a1a7eb7,WIP: Add Ironic notifications,ABANDONED,2016-07-21 07:38:06.000000000,2018-09-26 15:36:46.000000000,,"[{'_account_id': 3}, {'_account_id': 748}, {'_account_id': 4491}, {'_account_id': 5170}, {'_account_id': 9732}, {'_account_id': 10386}, {'_account_id': 15752}, {'_account_id': 16376}]","[{'number': 1, 'created': '2016-07-21 07:38:06.000000000', 'files': ['neutron/plugins/ml2/drivers/mech_baremetal/mech_driver/ironic_notifier.py', 'neutron/plugins/ml2/drivers/mech_baremetal/mech_driver/mech_baremetal.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/7c6cdff049090fb91da41e5d57481c49d9412831', 'message': 'WIP: Add Ironic notifications\n\nChange-Id: I11ae8f6f3c8e018c1fcf7b22de4675976a1a7eb7\n'}]",0,345211,7c6cdff049090fb91da41e5d57481c49d9412831,9,8,1,14525,,,0,"WIP: Add Ironic notifications

Change-Id: I11ae8f6f3c8e018c1fcf7b22de4675976a1a7eb7
",git fetch https://review.opendev.org/openstack/neutron refs/changes/11/345211/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/plugins/ml2/drivers/mech_baremetal/mech_driver/ironic_notifier.py', 'neutron/plugins/ml2/drivers/mech_baremetal/mech_driver/mech_baremetal.py']",2,7c6cdff049090fb91da41e5d57481c49d9412831,ironic_notifications,from neutron.plugins.ml2.drivers.mech_baremetal.mech_driver \ import ironic_notifier ironic_notifier.Notifier(),,109,0
openstack%2Frally~master~I4bb3e0bc4b2f5a9e44b7b434b2b05fc13ab064a7,openstack/rally,master,I4bb3e0bc4b2f5a9e44b7b434b2b05fc13ab064a7,Use a more clear error message.,MERGED,2018-09-26 09:56:37.000000000,2018-09-26 15:13:08.000000000,2018-09-26 15:13:07.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-26 09:56:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally/commit/aef9944feef8f40794ed1e3030e5631b661f58c1', 'message': ""Improve error message of db api's serialize.\n\nChange-Id: I4bb3e0bc4b2f5a9e44b7b434b2b05fc13ab064a7\n""}, {'number': 2, 'created': '2018-09-26 10:45:23.000000000', 'files': ['rally/common/db/api.py'], 'web_link': 'https://opendev.org/openstack/rally/commit/e41d018d2dddcdbbb79b37d27616fb830fe01b2a', 'message': 'Use a more clear error message.\n\nChange-Id: I4bb3e0bc4b2f5a9e44b7b434b2b05fc13ab064a7\n'}]",1,605383,e41d018d2dddcdbbb79b37d27616fb830fe01b2a,8,2,2,26505,,,0,"Use a more clear error message.

Change-Id: I4bb3e0bc4b2f5a9e44b7b434b2b05fc13ab064a7
",git fetch https://review.opendev.org/openstack/rally refs/changes/83/605383/2 && git format-patch -1 --stdout FETCH_HEAD,['rally/common/db/api.py'],1,aef9944feef8f40794ed1e3030e5631b661f58c1,error-message," raise ValueError(""data has wrong type %r"" % type(data).__name__)"," raise ValueError(""data has wrong type %s"" % data)",1,1
openstack%2Fshade~master~Ia99ea6f5937140d7ce0a9a637a21fc3ebad46dc6,openstack/shade,master,Ia99ea6f5937140d7ce0a9a637a21fc3ebad46dc6,Trim away the cover and py35 jobs,MERGED,2018-09-25 18:49:15.000000000,2018-09-26 15:07:09.000000000,2018-09-26 15:07:08.000000000,"[{'_account_id': 3099}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 18:49:15.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/shade/commit/0dc9e9ab8f9e295a88ad0404b267e763dbcc7e02', 'message': ""Trim away the cover and py35 jobs\n\nWe're doing py36, so skip py35, it's just duplicative.\n\nAlso, we don't really care about the cover jobs.\n\nChange-Id: Ia99ea6f5937140d7ce0a9a637a21fc3ebad46dc6\n""}]",0,605168,0dc9e9ab8f9e295a88ad0404b267e763dbcc7e02,6,2,1,2,,,0,"Trim away the cover and py35 jobs

We're doing py36, so skip py35, it's just duplicative.

Also, we don't really care about the cover jobs.

Change-Id: Ia99ea6f5937140d7ce0a9a637a21fc3ebad46dc6
",git fetch https://review.opendev.org/openstack/shade refs/changes/68/605168/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0dc9e9ab8f9e295a88ad0404b267e763dbcc7e02,,, - openstack-cover-jobs - openstack-python35-jobs,0,2
openstack%2Fshade~master~I04be3937589a805a5f9686c91a78933eebcfa022,openstack/shade,master,I04be3937589a805a5f9686c91a78933eebcfa022,Remove the task manager,MERGED,2018-09-25 12:19:14.000000000,2018-09-26 15:07:09.000000000,2018-09-26 15:07:09.000000000,"[{'_account_id': 3099}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 12:19:14.000000000', 'files': ['shade/tests/unit/test_task_manager.py', 'doc/source/user/logging.rst', 'shade/task_manager.py', 'releasenotes/notes/removed-task-manager-5dd9a98d85b987b1.yaml', 'shade/openstackcloud.py'], 'web_link': 'https://opendev.org/openstack/shade/commit/28e95889a0fd8105d12c20575fa66637564a6f89', 'message': 'Remove the task manager\n\nThe underlying openstacksdk library is shifting how task manager works,\nso stop trying to send it a task manager. This is a feature basically in\nplace just for nodepool which is being expanded to be more usable by\neveryone. The likelihood that anyone other than nodepool is using it is\n... very low.\n\nChange-Id: I04be3937589a805a5f9686c91a78933eebcfa022\n'}]",0,605052,28e95889a0fd8105d12c20575fa66637564a6f89,6,2,1,2,,,0,"Remove the task manager

The underlying openstacksdk library is shifting how task manager works,
so stop trying to send it a task manager. This is a feature basically in
place just for nodepool which is being expanded to be more usable by
everyone. The likelihood that anyone other than nodepool is using it is
... very low.

Change-Id: I04be3937589a805a5f9686c91a78933eebcfa022
",git fetch https://review.opendev.org/openstack/shade refs/changes/52/605052/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/user/logging.rst', 'shade/tests/unit/test_task_manager.py', 'shade/task_manager.py', 'releasenotes/notes/removed-task-manager-5dd9a98d85b987b1.yaml', 'shade/openstackcloud.py']",5,28e95889a0fd8105d12c20575fa66637564a6f89,,,"import collectionsfrom openstack import task_manager task_manager=manager, def _upload_object(self, endpoint, filename, headers): return self._object_store_client.put( endpoint, headers=headers, data=open(filename, 'r')) def _get_file_segments(self, endpoint, filename, file_size, segment_size): # Use an ordered dict here so that testing can replicate things segments = collections.OrderedDict() for (index, offset) in enumerate(range(0, file_size, segment_size)): remaining = file_size - (index * segment_size) segment = _utils.FileSegment( filename, offset, segment_size if segment_size < remaining else remaining) name = '{endpoint}/{index:0>6}'.format( endpoint=endpoint, index=index) segments[name] = segment return segments def _object_name_from_url(self, url): '''Get container_name/object_name from the full URL called. Remove the Swift endpoint from the front of the URL, and remove the leaving / that will leave behind.''' endpoint = self._object_store_client.get_endpoint() object_name = url.replace(endpoint, '') if object_name.startswith('/'): object_name = object_name[1:] return object_name def _add_etag_to_manifest(self, segment_results, manifest): for result in segment_results: if 'Etag' not in result.headers: continue name = self._object_name_from_url(result.url) for entry in manifest: if entry['path'] == '/{name}'.format(name=name): entry['etag'] = result.headers['Etag'] def _upload_large_object( self, endpoint, filename, headers, file_size, segment_size, use_slo): # If the object is big, we need to break it up into segments that # are no larger than segment_size, upload each of them individually # and then upload a manifest object. The segments can be uploaded in # parallel, so we'll use the async feature of the TaskManager. segment_futures = [] segment_results = [] retry_results = [] retry_futures = [] manifest = [] # Get an OrderedDict with keys being the swift location for the # segment, the value a FileSegment file-like object that is a # slice of the data for the segment. segments = self._get_file_segments( endpoint, filename, file_size, segment_size) # Schedule the segments for upload for name, segment in segments.items(): # Async call to put - schedules execution and returns a future segment_future = self._object_store_client.put( name, headers=headers, data=segment, run_async=True) segment_futures.append(segment_future) # TODO(mordred) Collect etags from results to add to this manifest # dict. Then sort the list of dicts by path. manifest.append(dict( path='/{name}'.format(name=name), size_bytes=segment.length)) # Try once and collect failed results to retry segment_results, retry_results = task_manager.wait_for_futures( segment_futures, raise_on_error=False) self._add_etag_to_manifest(segment_results, manifest) for result in retry_results: # Grab the FileSegment for the failed upload so we can retry name = self._object_name_from_url(result.url) segment = segments[name] segment.seek(0) # Async call to put - schedules execution and returns a future segment_future = self._object_store_client.put( name, headers=headers, data=segment, run_async=True) # TODO(mordred) Collect etags from results to add to this manifest # dict. Then sort the list of dicts by path. retry_futures.append(segment_future) # If any segments fail the second time, just throw the error segment_results, retry_results = task_manager.wait_for_futures( retry_futures, raise_on_error=True) self._add_etag_to_manifest(segment_results, manifest) if use_slo: return self._finish_large_object_slo(endpoint, headers, manifest) else: return self._finish_large_object_dlo(endpoint, headers) def _finish_large_object_slo(self, endpoint, headers, manifest): # TODO(mordred) send an etag of the manifest, which is the md5sum # of the concatenation of the etags of the results headers = headers.copy() return self._object_store_client.put( endpoint, params={'multipart-manifest': 'put'}, headers=headers, data=json.dumps(manifest)) def _finish_large_object_dlo(self, endpoint, headers): headers = headers.copy() headers['X-Object-Manifest'] = endpoint return self._object_store_client.put(endpoint, headers=headers) ",6,565
openstack%2Fos-vif~stable%2Fqueens~I89e97fdb9f5ef53f6dd5fc540514d0f294cf6a2e,openstack/os-vif,stable/queens,I89e97fdb9f5ef53f6dd5fc540514d0f294cf6a2e,Updated from global requirements,ABANDONED,2018-02-13 01:57:32.000000000,2018-09-26 14:51:54.000000000,,"[{'_account_id': 6873}, {'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-02-13 01:57:32.000000000', 'files': ['requirements.txt', 'test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e59497ba73962b75eeaa8583a6593ce00451a242', 'message': 'Updated from global requirements\n\nChange-Id: I89e97fdb9f5ef53f6dd5fc540514d0f294cf6a2e\n'}]",1,543705,e59497ba73962b75eeaa8583a6593ce00451a242,5,3,1,11131,,,0,"Updated from global requirements

Change-Id: I89e97fdb9f5ef53f6dd5fc540514d0f294cf6a2e
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/05/543705/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'test-requirements.txt']",2,e59497ba73962b75eeaa8583a6593ce00451a242,openstack/requirements,"sphinx!=1.6.6,>=1.6.2 # BSD openstackdocstheme>=1.18.1 # Apache-2.0 oslotest>=3.2.0 # Apache-2.0",sphinx>=1.6.2 # BSD openstackdocstheme>=1.17.0 # Apache-2.0 oslotest>=1.10.0 # Apache-2.0,6,6
openstack%2Fos-vif~stable%2Focata~I0447323548fc51293d2c88c4438f248f4fc1d66a,openstack/os-vif,stable/ocata,I0447323548fc51293d2c88c4438f248f4fc1d66a,Updated from global requirements,ABANDONED,2017-08-03 00:00:31.000000000,2018-09-26 14:50:06.000000000,,"[{'_account_id': 3}, {'_account_id': 11604}, {'_account_id': 12898}]","[{'number': 1, 'created': '2017-08-03 00:00:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/78691c2f2e75dc84178d45bfa7bde73fc562f5fd', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 2, 'created': '2017-09-26 13:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/246d81f1f12905b526c8ac68cdc9b13621498f95', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 3, 'created': '2017-09-27 14:49:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/67238ea2bfe9bcc071beddb41ea34022c1e9b856', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 4, 'created': '2017-09-28 12:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/2d3439cba412e52d824d4ff7b9bb32bb917bd7c2', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 5, 'created': '2017-09-28 13:25:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/ecaa0f64d065af2a9201b504a9eeef78a68b231f', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 6, 'created': '2017-10-04 12:54:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/8ac71c54e768f6fd4588e660c8495efc564cab75', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}, {'number': 7, 'created': '2017-10-06 13:02:33.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/ecebd4b948487c71ef5ae6b2955890963648126f', 'message': 'Updated from global requirements\n\nChange-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a\n'}]",0,490256,ecebd4b948487c71ef5ae6b2955890963648126f,19,3,7,11131,,,0,"Updated from global requirements

Change-Id: I0447323548fc51293d2c88c4438f248f4fc1d66a
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/56/490256/7 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,78691c2f2e75dc84178d45bfa7bde73fc562f5fd,openstack/requirements,oslo.versionedobjects>=1.17.0 # Apache-2.0,oslo.versionedobjects>=1.13.0 # Apache-2.0,1,1
openstack%2Fos-vif~stable%2Fpike~I6639436ef7589085fc17fedb65cb7fc912a13566,openstack/os-vif,stable/pike,I6639436ef7589085fc17fedb65cb7fc912a13566,Updated from global requirements,ABANDONED,2017-08-11 19:03:39.000000000,2018-09-26 14:49:38.000000000,,"[{'_account_id': 11604}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2017-08-11 19:03:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/61cbcd26dc69de1900e66e8d860f73e57854370b', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 2, 'created': '2017-09-21 01:04:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/404057e26a5065ff0458cb49b79144df736d0bf6', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 3, 'created': '2017-09-27 14:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/c8fc4e27f8dc0266c27c824a46dcc8c9058731e7', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 4, 'created': '2017-09-27 14:23:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/3fc9e61815f9f6fe810f0d13843e83ef0d9a6935', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 5, 'created': '2017-09-27 14:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/20f4f536b643905834f84947b344b3339a73257f', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 6, 'created': '2017-09-27 15:01:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/cf10f1c7d476fda899ca44c2039c9c39df443c9d', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 7, 'created': '2017-09-27 15:15:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e47a26a56404176b564985139fc38e6a01effe69', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 8, 'created': '2017-09-27 17:32:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/d7157f52e79c8988ab66dba4bc017130a73f19ab', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 9, 'created': '2017-09-28 06:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/fe0d0bb07faac90dad65929400d969362e6f72cc', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 10, 'created': '2017-09-28 06:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/167f389b3980d96c6cbb095d889e0327a1acec2d', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 11, 'created': '2017-10-04 22:55:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/02046ce90a449f589dc1893838e491ed7c860fb9', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 12, 'created': '2017-10-04 23:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e314229a127c0ded549b7d946174b90efde2864f', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 13, 'created': '2017-10-05 05:55:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e5312ddea9b6e11b629924f08f47d9ac050294ec', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 14, 'created': '2017-10-05 06:26:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/a190ad1af7899da87c4380df9e3f34b813e271ed', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 15, 'created': '2017-10-10 20:42:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/32821ff98cd07a5022471455b47b9721bc680a26', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 16, 'created': '2017-10-11 00:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/ce8562401b5b9b37b5d8f3876e49e69865cc5141', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 17, 'created': '2017-10-11 00:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/9180ab21b007b4d3a251ba4ce2b0f47e5a085cc7', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 18, 'created': '2017-10-11 00:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/96ab2705f0cfeedf77bc8708c0c1f3f298008100', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 19, 'created': '2017-10-27 13:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/8622e01c019c7920d1622e51246f44fccacd8987', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 20, 'created': '2017-10-27 21:57:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1caeea170b7b09a20bbacf5beccd07615a9522c9', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 21, 'created': '2017-11-02 04:04:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/a91881fa93c9e748b9c5bb3ad8b25ef604a14f35', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 22, 'created': '2017-11-06 03:33:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/05e079529ac32bf11e0530b4748562fa249e1cfa', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 23, 'created': '2017-11-06 03:35:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/dd34317c153aaa1ab9b2e23e385e0024070737ca', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 24, 'created': '2017-11-06 03:35:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/4f469860e748fb362bc74a5a05c0a0d670885c17', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 25, 'created': '2017-11-06 03:46:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/8835ef6fcc32ee40b4735a01fc369172c6750b03', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 26, 'created': '2017-11-06 03:53:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/e9d9712bbed43fc56ca6c350bdd0e05547cbaeb4', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 27, 'created': '2017-11-14 21:04:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/1e9935fa54caf60343f0849c4bee6aa10ad88cca', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 28, 'created': '2017-11-15 01:29:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-vif/commit/cb574bacd74b71d83c5dfbd17391da8bc4a79d60', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}, {'number': 29, 'created': '2017-11-15 01:48:08.000000000', 'files': ['test-requirements.txt'], 'web_link': 'https://opendev.org/openstack/os-vif/commit/6a194d9304c123170ceec3bc9b86b1997647a981', 'message': 'Updated from global requirements\n\nChange-Id: I6639436ef7589085fc17fedb65cb7fc912a13566\n'}]",0,493146,6a194d9304c123170ceec3bc9b86b1997647a981,53,3,29,11131,,,0,"Updated from global requirements

Change-Id: I6639436ef7589085fc17fedb65cb7fc912a13566
",git fetch https://review.opendev.org/openstack/os-vif refs/changes/46/493146/15 && git format-patch -1 --stdout FETCH_HEAD,['test-requirements.txt'],1,61cbcd26dc69de1900e66e8d860f73e57854370b,openstack/requirements,openstackdocstheme>=1.16.0 # Apache-2.0,openstackdocstheme>=1.11.0 # Apache-2.0,1,1
openstack%2Fnova~stable%2Fqueens~Icb1d33c6e602467e21efe4838cb6edbadab14834,openstack/nova,stable/queens,Icb1d33c6e602467e21efe4838cb6edbadab14834,Skip ServerActionsTestJSON.test_rebuild_server for cells v1 job,MERGED,2018-09-25 15:46:55.000000000,2018-09-26 14:49:01.000000000,2018-09-26 14:49:01.000000000,"[{'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 15:46:55.000000000', 'files': ['devstack/tempest-dsvm-cells-rc'], 'web_link': 'https://opendev.org/openstack/nova/commit/c223869a22f8e3290e31ed059ceac006e8b03ed8', 'message': ""Skip ServerActionsTestJSON.test_rebuild_server for cells v1 job\n\nThis is another occurrence of a rebuild test randomly timing out\nwaiting for status changes in the cells v1 job, so blacklist it.\nCells v1 is deprecated and should be gone soon anyway, so we don't\nneed to waste time hitting stuff like this.\n\nChange-Id: Icb1d33c6e602467e21efe4838cb6edbadab14834\nRelated-Bug: #1709985\n(cherry picked from commit 927b6ccced40a189ce9ee6b1486b54599b74c444)\n""}]",0,605115,c223869a22f8e3290e31ed059ceac006e8b03ed8,16,7,1,6873,,,0,"Skip ServerActionsTestJSON.test_rebuild_server for cells v1 job

This is another occurrence of a rebuild test randomly timing out
waiting for status changes in the cells v1 job, so blacklist it.
Cells v1 is deprecated and should be gone soon anyway, so we don't
need to waste time hitting stuff like this.

Change-Id: Icb1d33c6e602467e21efe4838cb6edbadab14834
Related-Bug: #1709985
(cherry picked from commit 927b6ccced40a189ce9ee6b1486b54599b74c444)
",git fetch https://review.opendev.org/openstack/nova refs/changes/15/605115/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/tempest-dsvm-cells-rc'],1,c223869a22f8e3290e31ed059ceac006e8b03ed8,bug/1709985,"# tempest.api.compute.servers.test_server_actions.ServerActionsTestJSON.test_rebuild_server r=""$r|(?:.*id\-aaa6cdf3\-55a7\-461a\-add9\-1c8596b9a07c.*)""",,2,0
openstack%2Frequirements~master~Icfbe5d5c54e4673d6482ef0d51dcb65a2a16b7dc,openstack/requirements,master,Icfbe5d5c54e4673d6482ef0d51dcb65a2a16b7dc,update constraint for osprofiler to new release 2.4.1,MERGED,2018-09-25 19:51:47.000000000,2018-09-26 14:48:58.000000000,2018-09-26 14:48:58.000000000,"[{'_account_id': 8871}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:51:47.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/b5d9fef8f1be33e1f1c4f45c5213ece0a60f23c4', 'message': 'update constraint for osprofiler to new release 2.4.1\n\nChange-Id: Icfbe5d5c54e4673d6482ef0d51dcb65a2a16b7dc\nmeta:version: 2.4.1\nmeta:diff-start: 2.3.0\nmeta:series: stein\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605198,b5d9fef8f1be33e1f1c4f45c5213ece0a60f23c4,9,3,1,11131,,,0,"update constraint for osprofiler to new release 2.4.1

Change-Id: Icfbe5d5c54e4673d6482ef0d51dcb65a2a16b7dc
meta:version: 2.4.1
meta:diff-start: 2.3.0
meta:series: stein
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/98/605198/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,b5d9fef8f1be33e1f1c4f45c5213ece0a60f23c4,new-release,osprofiler===2.4.1,osprofiler===2.3.0,1,1
openstack%2Freleases~master~I0e3dca1e42278374b03ad6e83c48aa98a8f2e2c4,openstack/releases,master,I0e3dca1e42278374b03ad6e83c48aa98a8f2e2c4,add a 'releasefix' mode for re-tagging existing releases,MERGED,2018-09-24 18:46:53.000000000,2018-09-26 14:42:15.000000000,2018-09-26 14:42:15.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-24 18:46:53.000000000', 'files': ['openstack_releases/cmds/new_release.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/41c0c1deeac96d406db3ad9fabd936c05be0150a', 'message': ""add a 'releasefix' mode for re-tagging existing releases\n\nWhen we have a lot of release jobs fail, it is easier to just\nre-release things than to try to fix the problems one at a time. This\nchange makes it easier to prepare the relevant changes.\n\nChange-Id: I0e3dca1e42278374b03ad6e83c48aa98a8f2e2c4\nSigned-off-by: Doug Hellmann <doug@doughellmann.com>\n""}]",0,604876,41c0c1deeac96d406db3ad9fabd936c05be0150a,7,3,1,2472,,,0,"add a 'releasefix' mode for re-tagging existing releases

When we have a lot of release jobs fail, it is easier to just
re-release things than to try to fix the problems one at a time. This
change makes it easier to prepare the relevant changes.

Change-Id: I0e3dca1e42278374b03ad6e83c48aa98a8f2e2c4
Signed-off-by: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/76/604876/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_releases/cmds/new_release.py'],1,41c0c1deeac96d406db3ad9fabd936c05be0150a,recover-twine-1-12," all_series = sorted( s for s in os.listdir('deliverables') if s != 'series_status.yaml' ) 'procedural', 'eol', 'releasefix'), is_procedural = args.release_type in 'procedural' is_retagging = is_procedural or args.release_type == 'releasefix' this_series_history = release_history[0] diff_start = None elif args.release_type == 'releasefix': increment = (0, 0, 1) new_version_parts = increment_version(last_version, increment) last_version_hashes = { p['repo']: p['hash'] for p in last_release['projects'] } # Go back 2 releases so the release announcement includes the # actual changes. try: diff_start_release = this_series_history[-2] except IndexError: # We do not have 2 releases in this series yet, so go back # to the stable branch creation point. prev_info = get_last_series_info(series, args.deliverable) for b in prev_info['branches']: if b['name'].startswith('stable/'): diff_start = b['location'] LOG.info('using branch point from previous ' 'series as diff-start: %r', diff_start) break else: diff_start = diff_start_release['version'] LOG.info('using release from same series as diff-start: %r', diff_start) if is_retagging: if is_retagging: if is_procedural: comment = 'procedural tag to support creating stable branch' else: comment = 'procedural tag to handle release job failure' 'comment': comment, elif is_eol: new_release_info = { } if diff_start: new_release_info['diff-start'] = diff_start deliverable_info['releases'].append(new_release_info)"," all_series = sorted(os.listdir('deliverables')) 'procedural', 'eol'), is_procedural = args.release_type == 'procedural' if args.release_type == 'procedural': if is_procedural: 'comment': 'procedural tag to support creating stable branch', if is_eol: deliverable_info['releases'].append({ })",49,9
openstack%2Frequirements~stable%2Frocky~I95903b59fccff13897de168a57983065a1d457b8,openstack/requirements,stable/rocky,I95903b59fccff13897de168a57983065a1d457b8,update constraint for oslo.service to new release 1.31.5,MERGED,2018-09-25 19:59:10.000000000,2018-09-26 14:39:24.000000000,2018-09-26 14:39:23.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:59:10.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/ddcf2e44959d39872af7d29c351d41230c8c120d', 'message': 'update constraint for oslo.service to new release 1.31.5\n\nChange-Id: I95903b59fccff13897de168a57983065a1d457b8\nmeta:version: 1.31.5\nmeta:diff-start: 1.31.3\nmeta:series: rocky\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605213,ddcf2e44959d39872af7d29c351d41230c8c120d,8,2,1,11131,,,0,"update constraint for oslo.service to new release 1.31.5

Change-Id: I95903b59fccff13897de168a57983065a1d457b8
meta:version: 1.31.5
meta:diff-start: 1.31.3
meta:series: rocky
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/13/605213/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,ddcf2e44959d39872af7d29c351d41230c8c120d,new-release,oslo.service===1.31.5,oslo.service===1.31.3,1,1
openstack%2Frequirements~stable%2Fqueens~Id5a0f37a96d694a8ba56491e4f1b63f664269359,openstack/requirements,stable/queens,Id5a0f37a96d694a8ba56491e4f1b63f664269359,update constraint for oslo.messaging to new release 5.35.3,MERGED,2018-09-25 19:51:44.000000000,2018-09-26 14:39:22.000000000,2018-09-26 14:39:21.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:51:44.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/9c26e2c9a8714286b9c569a0b0b32b58c00d6223', 'message': 'update constraint for oslo.messaging to new release 5.35.3\n\nChange-Id: Id5a0f37a96d694a8ba56491e4f1b63f664269359\nmeta:version: 5.35.3\nmeta:diff-start: 5.35.1\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605197,9c26e2c9a8714286b9c569a0b0b32b58c00d6223,8,2,1,11131,,,0,"update constraint for oslo.messaging to new release 5.35.3

Change-Id: Id5a0f37a96d694a8ba56491e4f1b63f664269359
meta:version: 5.35.3
meta:diff-start: 5.35.1
meta:series: queens
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/97/605197/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,9c26e2c9a8714286b9c569a0b0b32b58c00d6223,new-release,oslo.messaging===5.35.3,oslo.messaging===5.35.1,1,1
openstack%2Fcinder~master~I81951da141ed7948e48b92da718b3a0e9c12e859,openstack/cinder,master,I81951da141ed7948e48b92da718b3a0e9c12e859,Fix bug of renaming volume with same name,MERGED,2018-09-13 09:16:01.000000000,2018-09-26 14:39:19.000000000,2018-09-26 14:39:19.000000000,"[{'_account_id': 24}, {'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 9236}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11611}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 15961}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 18883}, {'_account_id': 19933}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25677}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28706}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-13 09:16:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/4176f8f5b47d6e3990fc3d4478f20a4db0183536', 'message': 'Fix bug of retyping volume for rbd driver\n\nIf the volume is already in the pool, renaming causes exception.\nThe Scene is that the same pool is seti into two backends with\ndifferent volume_backend_name. Then create two volume types with\ndifferent volume_backend_name which was defined in cinder.conf.\nCreate a volume by one volume type, then try to retype it to another\nvolume type. It failed because of ImageExists.\n\nChange-Id: I81951da141ed7948e48b92da718b3a0e9c12e859\nCloses-Bug: #1792339\n'}, {'number': 2, 'created': '2018-09-13 14:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8e5d275c881c4f48d2ff8c9bb78830ec12b8e990', 'message': 'Fix bug of retyping volume for rbd driver\n\nIf the volume is already in the pool, renaming causes exception.\nThe Scene is that the same pool is seti into two backends with\ndifferent volume_backend_name. Then create two volume types with\ndifferent volume_backend_name which was defined in cinder.conf.\nCreate a volume by one volume type, then try to retype it to another\nvolume type. It failed because of ImageExists.\n\nChange-Id: I81951da141ed7948e48b92da718b3a0e9c12e859\nCloses-Bug: #1792339\n'}, {'number': 3, 'created': '2018-09-19 01:34:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/9179279272a7d8f1a5ac706f35904c4e19bf0beb', 'message': 'Fix bug of retyping volume for rbd driver\n\nIf the volume is already in the pool, renaming causes exception.\nThe Scene is that the same pool is set into two backends with\ndifferent volume_backend_name. Then create two volume types with\ndifferent volume_backend_name which was defined in cinder.conf.\nCreate a volume by one volume type, then try to retype it to another\nvolume type. It failed because of ImageExists.\n\nChange-Id: I81951da141ed7948e48b92da718b3a0e9c12e859\nCloses-Bug: #1792339\n'}, {'number': 4, 'created': '2018-09-21 02:59:15.000000000', 'files': ['cinder/volume/drivers/rbd.py', 'cinder/tests/unit/volume/drivers/test_rbd.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/764b7b736ecc73015cd1cf81279aab444ab03b9c', 'message': 'Fix bug of renaming volume with same name\n\nIf the volume is already in the pool, renaming causes exception.\nIt failed because of ImageExists.\n\nChange-Id: I81951da141ed7948e48b92da718b3a0e9c12e859\nCloses-Bug: #1792339\n'}]",3,602275,764b7b736ecc73015cd1cf81279aab444ab03b9c,140,41,4,28706,,,0,"Fix bug of renaming volume with same name

If the volume is already in the pool, renaming causes exception.
It failed because of ImageExists.

Change-Id: I81951da141ed7948e48b92da718b3a0e9c12e859
Closes-Bug: #1792339
",git fetch https://review.opendev.org/openstack/cinder refs/changes/75/602275/4 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/drivers/rbd.py'],1,4176f8f5b47d6e3990fc3d4478f20a4db0183536,bug/1792339," except (self.rbd.ImageNotFound, self.rbd.ImageExists):", except self.rbd.ImageNotFound:,1,1
openstack%2Fswift~master~Iede1d7450e94ba05d2610030e975f566275da88b,openstack/swift,master,Iede1d7450e94ba05d2610030e975f566275da88b,Allow kmip_keymaster to be configured in proxy-server.conf,MERGED,2018-09-24 23:55:07.000000000,2018-09-26 14:39:16.000000000,2018-09-26 14:39:16.000000000,"[{'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 7233}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-24 23:55:07.000000000', 'files': ['test/unit/common/middleware/crypto/test_kmip_keymaster.py', 'swift/common/middleware/crypto/kmip_keymaster.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b7fda3b4a23fbb86c2341ab60cdc435889b880f9', 'message': 'Allow kmip_keymaster to be configured in proxy-server.conf\n\n... and in particular, in the filter:kmip_keymaster section. We thought\nwe\'d done that before, but we didn\'t: __name__ is *just* the filter\nname, and doesn\'t include the ""filter:"" prefix for the section.\n\nChange-Id: Iede1d7450e94ba05d2610030e975f566275da88b\n'}]",0,604937,b7fda3b4a23fbb86c2341ab60cdc435889b880f9,9,4,1,15343,,,0,"Allow kmip_keymaster to be configured in proxy-server.conf

... and in particular, in the filter:kmip_keymaster section. We thought
we'd done that before, but we didn't: __name__ is *just* the filter
name, and doesn't include the ""filter:"" prefix for the section.

Change-Id: Iede1d7450e94ba05d2610030e975f566275da88b
",git fetch https://review.opendev.org/openstack/swift refs/changes/37/604937/1 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/common/middleware/crypto/test_kmip_keymaster.py', 'swift/common/middleware/crypto/kmip_keymaster.py']",2,b7fda3b4a23fbb86c2341ab60cdc435889b880f9,," # __name__ is just the filter name, not the whole section name. # Luckily, PasteDeploy only uses the one prefix for filters. section = 'filter:' + conf['__name__']", section = conf['__name__'],15,12
openstack%2Frequirements~stable%2Fqueens~I66ca5ca7fcb45566ae5914df240994bf0ff4acf4,openstack/requirements,stable/queens,I66ca5ca7fcb45566ae5914df240994bf0ff4acf4,update constraint for instack-undercloud to new release 8.4.6,MERGED,2018-09-25 19:46:58.000000000,2018-09-26 14:39:11.000000000,2018-09-26 14:39:11.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:46:58.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/cca2e8237b916fde95d8862511cd19f349787e0a', 'message': 'update constraint for instack-undercloud to new release 8.4.6\n\nChange-Id: I66ca5ca7fcb45566ae5914df240994bf0ff4acf4\nmeta:version: 8.4.6\nmeta:diff-start: 8.4.4\nmeta:series: queens\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: no\nmeta:release:Author: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Commit: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5\nmeta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>\nmeta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>\nmeta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>\nmeta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>\nmeta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>\n'}]",0,605196,cca2e8237b916fde95d8862511cd19f349787e0a,8,2,1,11131,,,0,"update constraint for instack-undercloud to new release 8.4.6

Change-Id: I66ca5ca7fcb45566ae5914df240994bf0ff4acf4
meta:version: 8.4.6
meta:diff-start: 8.4.4
meta:series: queens
meta:release-type: release
meta:pypi: no
meta:first: no
meta:release:Author: Doug Hellmann <doug@doughellmann.com>
meta:release:Commit: Doug Hellmann <doug@doughellmann.com>
meta:release:Change-Id: Iaea87ebe23bcad27d4422f3c477bf2fa37cf5bc5
meta:release:Code-Review+1: Alex Schultz <aschultz@redhat.com>
meta:release:Code-Review+1: Julia Kreger <juliaashleykreger@gmail.com>
meta:release:Code-Review+1: Sergii Golovatiuk <sgolovat@redhat.com>
meta:release:Code-Review+2: Doug Hellmann <doug@doughellmann.com>
meta:release:Workflow+1: Doug Hellmann <doug@doughellmann.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/96/605196/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,cca2e8237b916fde95d8862511cd19f349787e0a,new-release,instack-undercloud===8.4.6,instack-undercloud===8.4.4,1,1
openstack%2Fswift~master~Idb5c0b25969b839cc71c487208447bdd6817c2cf,openstack/swift,master,Idb5c0b25969b839cc71c487208447bdd6817c2cf,Clean up comment about 404s leaking out during COPYs,MERGED,2018-01-19 22:24:07.000000000,2018-09-26 14:39:10.000000000,2018-09-26 14:39:10.000000000,"[{'_account_id': 330}, {'_account_id': 2622}, {'_account_id': 7233}, {'_account_id': 14766}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-01-19 22:24:07.000000000', 'files': ['test/functional/tests.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/b2fbc742c6e61b5607f5a31cd9cac49e29c25284', 'message': ""Clean up comment about 404s leaking out during COPYs\n\nApparently that isn't a thing we have to worry about any more? Probably\ngot fixed when we pulled COPY out to middleware.\n\nAdd some tests where we definitely expect 403s across the board, too.\n\nChange-Id: Idb5c0b25969b839cc71c487208447bdd6817c2cf\n""}]",0,535981,b2fbc742c6e61b5607f5a31cd9cac49e29c25284,12,6,1,15343,,,0,"Clean up comment about 404s leaking out during COPYs

Apparently that isn't a thing we have to worry about any more? Probably
got fixed when we pulled COPY out to middleware.

Add some tests where we definitely expect 403s across the board, too.

Change-Id: Idb5c0b25969b839cc71c487208447bdd6817c2cf
",git fetch https://review.opendev.org/openstack/swift refs/changes/81/535981/1 && git format-patch -1 --stdout FETCH_HEAD,['test/functional/tests.py'],1,b2fbc742c6e61b5607f5a31cd9cac49e29c25284,," self.assert_status(403) def testCopyFromAccountHeader403s(self): acct = self.env.conn2.account_name src_cont = self.env.account2.container(Utils.create_name()) self.assertTrue(src_cont.create()) # Primary user has no access source_filename = Utils.create_name() file_item = src_cont.file(source_filename) file_item.write_random() dest_cont = self.env.account.container(Utils.create_name()) self.assertTrue(dest_cont.create()) for prefix in ('', '/'): # invalid source container file_item = dest_cont.file(Utils.create_name()) self.assertRaises(ResponseError, file_item.write, hdrs={'X-Copy-From-Account': acct, 'X-Copy-From': '%s%s/%s' % (prefix, Utils.create_name(), source_filename)}) self.assert_status(403) # invalid source object file_item = self.env.container.file(Utils.create_name()) self.assertRaises(ResponseError, file_item.write, hdrs={'X-Copy-From-Account': acct, 'X-Copy-From': '%s%s/%s' % (prefix, src_cont, Utils.create_name())}) self.assert_status(403) # invalid destination container dest_cont = self.env.account.container(Utils.create_name()) file_item = dest_cont.file(Utils.create_name()) self.assertRaises(ResponseError, file_item.write, hdrs={'X-Copy-From-Account': acct, 'X-Copy-From': '%s%s/%s' % (prefix, src_cont, source_filename)}) self.assert_status(403) "," # looks like cached responses leak ""not found"" # to un-authorized users, not going to fix it now, but... self.assert_status([403, 404])",43,3
openstack%2Fneutron~stable%2Frocky~Ia681a5e929df5bf8c97ae9445876c306c34061b5,openstack/neutron,stable/rocky,Ia681a5e929df5bf8c97ae9445876c306c34061b5,Parse dhcp leases file in a more robust way,MERGED,2018-09-21 09:57:37.000000000,2018-09-26 14:39:08.000000000,2018-09-26 14:39:08.000000000,"[{'_account_id': 1131}, {'_account_id': 1653}, {'_account_id': 6062}, {'_account_id': 6876}, {'_account_id': 8871}, {'_account_id': 9373}, {'_account_id': 10385}, {'_account_id': 13995}, {'_account_id': 19307}, {'_account_id': 22348}, {'_account_id': 23312}]","[{'number': 1, 'created': '2018-09-21 09:57:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/304504ed36402cbe8e05656d2325145b3bc63f14', 'message': ""Parse dhcp leases file in a more robust way\n\nIt turns out that in environments with a big number of VMs, sometimes\nthe neutron dhcp agent fails to read the dhcp lease file because some\nlines with the ipv4/ipv6 entries don't have enough fields and causes the\ndhcp agent to fail.\n\nWhen this happens the agent calls sync_state to\nfully resync the agent state, that causes a serious performance problems\nin scale environments.\n\nWe need to be more robust reading the file to handle these exceptions.\n\nCo-authored-by: stephen-ma\nPartial-Bug: #1788556\n\nChange-Id: Ia681a5e929df5bf8c97ae9445876c306c34061b5\n(cherry picked from commit 8a3ff8a19ec39630d24b71cec86740b6b9f16bbe)\n""}, {'number': 2, 'created': '2018-09-21 17:03:32.000000000', 'files': ['neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/ffcb22f6338ae62c56b2f6e0d531b61f33349167', 'message': ""Parse dhcp leases file in a more robust way\n\nIt turns out that in environments with a big number of VMs, sometimes\nthe neutron dhcp agent fails to read the dhcp lease file because some\nlines with the ipv4/ipv6 entries don't have enough fields and causes the\ndhcp agent to fail.\n\nWhen this happens the agent calls sync_state to\nfully resync the agent state, that causes a serious performance problems\nin scale environments.\n\nWe need to be more robust reading the file to handle these exceptions.\n\nCo-authored-by: stephen-ma\nPartial-Bug: #1788556\n\nChange-Id: Ia681a5e929df5bf8c97ae9445876c306c34061b5\n(cherry picked from commit 8a3ff8a19ec39630d24b71cec86740b6b9f16bbe)\n""}]",0,604320,ffcb22f6338ae62c56b2f6e0d531b61f33349167,27,11,2,19307,,,0,"Parse dhcp leases file in a more robust way

It turns out that in environments with a big number of VMs, sometimes
the neutron dhcp agent fails to read the dhcp lease file because some
lines with the ipv4/ipv6 entries don't have enough fields and causes the
dhcp agent to fail.

When this happens the agent calls sync_state to
fully resync the agent state, that causes a serious performance problems
in scale environments.

We need to be more robust reading the file to handle these exceptions.

Co-authored-by: stephen-ma
Partial-Bug: #1788556

Change-Id: Ia681a5e929df5bf8c97ae9445876c306c34061b5
(cherry picked from commit 8a3ff8a19ec39630d24b71cec86740b6b9f16bbe)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/20/604320/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/tests/unit/agent/linux/test_dhcp.py', 'neutron/agent/linux/dhcp.py']",2,304504ed36402cbe8e05656d2325145b3bc63f14,bug/1788556-stable/rocky," if len(parts) != 5: LOG.warning('Invalid lease entry %s found in %s ' 'lease file, ignoring', parts, filename) continue",,16,2
openstack%2Fhorizon~master~I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2,openstack/horizon,master,I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2,Imported Translations from Zanata,MERGED,2018-09-21 06:21:51.000000000,2018-09-26 14:34:55.000000000,2018-09-26 14:34:55.000000000,"[{'_account_id': 1736}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-21 06:21:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8a9580029ec8434525449665e7a3e3ef496f9f8c', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2\n'}, {'number': 2, 'created': '2018-09-22 07:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0f962a4952e1b4f7d7d1a12b18dd979b608297cb', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2\n'}, {'number': 3, 'created': '2018-09-23 07:51:57.000000000', 'files': ['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_auth/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_auth/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'horizon/locale/ko_KR/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'doc/source/locale/id/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po'], 'web_link': 'https://opendev.org/openstack/horizon/commit/1cc2b7fcf68d193b0b608ec0bb9489dfd8d237bc', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2\n'}]",0,604270,1cc2b7fcf68d193b0b608ec0bb9489dfd8d237bc,16,2,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I30c4ff7dbda78781c32b27e455b9d75c7f4ddac2
",git fetch https://review.opendev.org/openstack/horizon refs/changes/70/604270/2 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_dashboard/locale/bn_IN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pl_PL/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kn/LC_MESSAGES/django.po', 'horizon/locale/id/LC_MESSAGES/djangojs.po', 'openstack_dashboard/locale/ne/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/djangojs.po', 'openstack_auth/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ks/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ja/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ru/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ta/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_CN/LC_MESSAGES/django.po', 'openstack_dashboard/locale/zh_TW/LC_MESSAGES/django.po', 'openstack_dashboard/locale/tr_TR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ur/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mni/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mr/LC_MESSAGES/django.po', 'openstack_dashboard/locale/en_AU/LC_MESSAGES/django.po', 'openstack_dashboard/locale/fr/LC_MESSAGES/django.po', 'releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'openstack_dashboard/locale/en_GB/LC_MESSAGES/django.po', 'openstack_dashboard/locale/as/LC_MESSAGES/django.po', 'openstack_dashboard/locale/de/LC_MESSAGES/django.po', 'openstack_dashboard/locale/id/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pa_IN/LC_MESSAGES/django.po', 'doc/source/locale/id/LC_MESSAGES/doc-install.po', 'openstack_dashboard/locale/cs/LC_MESSAGES/django.po', 'openstack_dashboard/locale/gu/LC_MESSAGES/django.po', 'openstack_dashboard/locale/ko_KR/LC_MESSAGES/django.po', 'openstack_dashboard/locale/brx/LC_MESSAGES/django.po', 'openstack_dashboard/locale/es/LC_MESSAGES/django.po', 'openstack_dashboard/locale/mai/LC_MESSAGES/django.po', 'openstack_dashboard/locale/it/LC_MESSAGES/django.po', 'openstack_dashboard/locale/kok/LC_MESSAGES/django.po', 'openstack_dashboard/locale/eo/LC_MESSAGES/django.po', 'openstack_dashboard/locale/pt_BR/LC_MESSAGES/django.po']",36,8a9580029ec8434525449665e7a3e3ef496f9f8c,zanata/translations,"""POT-Creation-Date: 2018-09-21 05:00+0000\n""","""POT-Creation-Date: 2018-08-08 22:48+0000\n""""If no container name is provided, a default container named volumebackups "" ""will be provisioned for you. Backups will be the same size as the volume "" ""they originate from."" msgstr """" ""Se nenhum nome de recipiente  fornecido, um continer padro chamado "" ""volumebackups ser provisionado para voc. Cpias de segurana ser o mesmo "" ""tamanho que o volume que se originam a partir de."" msgid """"msgid """" ""Volume Backups are stored using the Object Storage service. You must have "" ""this service activated in order to create a backup."" msgstr """" ""Volume backups so armazenados usando o servio de armazenamento de objetos. "" ""Voc deve ter este servio ativado, a fim de criar um backup."" ",326,530
openstack%2Foslo.messaging~master~Ie93ff74de84ff4d6cc75a3c89dd9a03fdcba5d35,openstack/oslo.messaging,master,Ie93ff74de84ff4d6cc75a3c89dd9a03fdcba5d35,Refactor GetTransportSadPathTestCase,MERGED,2018-09-25 03:17:04.000000000,2018-09-26 14:24:46.000000000,2018-09-26 14:24:46.000000000,"[{'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 03:17:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/36920664ef66ff540c3285c124d75313e084b33e', 'message': 'Remove dead code in GetTransportSadPathTestCase\n\nGetTransportSadPathTestCase did an awful lot of mocking for things that\nwere no longer called, par down the try block to one call. Also tighten\nthe exception caught so unexpected exceptions will fail.\n\nChange-Id: Ie93ff74de84ff4d6cc75a3c89dd9a03fdcba5d35\n'}, {'number': 2, 'created': '2018-09-25 04:20:20.000000000', 'files': ['oslo_messaging/tests/test_transport.py'], 'web_link': 'https://opendev.org/openstack/oslo.messaging/commit/95b487ba6bd62dca73908bed67b6dffcb5331674', 'message': 'Refactor GetTransportSadPathTestCase\n\nGetTransportSadPathTestCase did an awful lot of mocking for things that\nwere no longer called. Since we only have one callable now, make use of\nself.assertRaises.\n\nChange-Id: Ie93ff74de84ff4d6cc75a3c89dd9a03fdcba5d35\n'}]",0,604959,95b487ba6bd62dca73908bed67b6dffcb5331674,8,3,2,9369,,,0,"Refactor GetTransportSadPathTestCase

GetTransportSadPathTestCase did an awful lot of mocking for things that
were no longer called. Since we only have one callable now, make use of
self.assertRaises.

Change-Id: Ie93ff74de84ff4d6cc75a3c89dd9a03fdcba5d35
",git fetch https://review.opendev.org/openstack/oslo.messaging refs/changes/59/604959/1 && git format-patch -1 --stdout FETCH_HEAD,['oslo_messaging/tests/test_transport.py'],1,36920664ef66ff540c3285c124d75313e084b33e,remove-dead-test-code, except oslo_messaging.MessagingException as ex:," driver.DriverManager = mock.Mock() invoke_args = [self.conf, oslo_messaging.TransportURL.parse(self.conf, self.url)] invoke_kwds = dict(default_exchange='openstack', allowed_remote_exmods=[]) driver.DriverManager.side_effect = RuntimeError() driver.DriverManager.assert_called_once_with( 'oslo.messaging.drivers', invoke_on_load=True, invoke_args=invoke_args, invoke_kwds=invoke_kwds) except Exception as ex: self.assertIsInstance(ex, oslo_messaging.MessagingException)",1,13
openstack%2Fnova~master~I328a18a723d0f593eea491f788a6e256d6e0c127,openstack/nova,master,I328a18a723d0f593eea491f788a6e256d6e0c127,Consumer gen: remove_provider_from_instance_allocation,MERGED,2018-08-14 16:57:40.000000000,2018-09-26 14:24:41.000000000,2018-09-26 14:24:41.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2018-08-14 16:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/68a938670e2c9d2fdeeef2061b0d850598413bb4', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to retry the whole\nfunction if it receives 409 from placement that indicates a consumer\ngeneration conflict. If we run out of retries then the function returns\nFalse indicating an unsuccessful allocation removal.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the exiting coverage. However based\non the other patches in this series the error handling in these cases\nsuspected to be imperfect.\n\nTODO:\n* make the unit test pass\n\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}, {'number': 2, 'created': '2018-08-14 18:15:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7bdf5b59a639f337a3e0e1517f0a7855ec5c447', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to retry the whole\nfunction if it receives 409 from placement that indicates a consumer\ngeneration conflict. If we run out of retries then the function returns\nFalse indicating an unsuccessful allocation removal.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the exiting coverage. However based\non the other patches in this series the error handling in these cases\nsuspected to be imperfect.\n\nTODO:\n* make the unit test pass\n\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}, {'number': 3, 'created': '2018-09-11 16:43:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/92471337fb57eb86502a806729bd9922de85ffb7', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to use placement API\nmicroversion 1.28 that includes consumer generation handling. If\nplacement returns 409 conflict remove_provider_from_instance_allocation\nreturns False in the same way as in case of other non 204 results.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the exiting coverage. However based\non the other patches in this series the error handling in these cases\nsuspected to be imperfect.\n\nTODO:\n* make the unit test pass\n\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}, {'number': 4, 'created': '2018-09-12 22:40:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/df7891164250ddff9df7ea1f058ca3c4f38a15a1', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to use placement API\nmicroversion 1.28 that includes consumer generation handling. If\nplacement returns 409 conflict remove_provider_from_instance_allocation\nreturns False in the same way as in case of other non 204 results.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the exiting coverage. However based\non the other patches in this series the error handling in these cases\nsuspected to be imperfect.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}, {'number': 5, 'created': '2018-09-17 09:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/be545a80564c4d1e17f033e084a94577ffdf6209', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to use placement API\nmicroversion 1.28 that includes consumer generation handling. If\nplacement returns 409 conflict remove_provider_from_instance_allocation\nreturns False in the same way as in case of other non 204 results.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the exiting coverage. However based\non the other patches in this series the error handling in these cases\nsuspected to be imperfect.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}, {'number': 6, 'created': '2018-09-25 11:26:47.000000000', 'files': ['nova/tests/unit/scheduler/client/test_report.py', 'nova/scheduler/client/report.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1ced5905716300b9dbc308c8d3b68f38386fb2c0', 'message': 'Consumer gen: remove_provider_from_instance_allocation\n\nThis patch changes the scheduler report client\nremove_provider_from_instance_allocation function to use placement API\nmicroversion 1.28 that includes consumer generation handling. If\nplacement returns 409 conflict remove_provider_from_instance_allocation\nreturns False in the same way as in case of other non 204 results.\n\nThere are plenty of places in nova calling\nremove_provider_from_instance_allocation:\n* dropping allocation on the destination of a live migrate if pre check\n  fails\n* compute host startup deletes allocation of an instance that was\n  successfully evacuated from the host while it was down\n* rebuild fails on the destination of an evacuation and therefore\n  the allocation on the destination is deleted\n* pre resize fails therefore allocation on the destination is deleted\n\nThis patch does not change the external behavior of\nremove_provider_from_instance_allocation as it still returns False in\ncaes of failure. Therefore this patch does not introduce new functional\ntest for the above cases but rely on the existing coverage. However based\non the other patches in this series the error handling in these cases\nis suspected to be imperfect.\n\nBlueprint: use-nested-allocation-candidates\nChange-Id: I328a18a723d0f593eea491f788a6e256d6e0c127\n'}]",4,591784,1ced5905716300b9dbc308c8d3b68f38386fb2c0,81,19,6,9708,,,0,"Consumer gen: remove_provider_from_instance_allocation

This patch changes the scheduler report client
remove_provider_from_instance_allocation function to use placement API
microversion 1.28 that includes consumer generation handling. If
placement returns 409 conflict remove_provider_from_instance_allocation
returns False in the same way as in case of other non 204 results.

There are plenty of places in nova calling
remove_provider_from_instance_allocation:
* dropping allocation on the destination of a live migrate if pre check
  fails
* compute host startup deletes allocation of an instance that was
  successfully evacuated from the host while it was down
* rebuild fails on the destination of an evacuation and therefore
  the allocation on the destination is deleted
* pre resize fails therefore allocation on the destination is deleted

This patch does not change the external behavior of
remove_provider_from_instance_allocation as it still returns False in
caes of failure. Therefore this patch does not introduce new functional
test for the above cases but rely on the existing coverage. However based
on the other patches in this series the error handling in these cases
is suspected to be imperfect.

Blueprint: use-nested-allocation-candidates
Change-Id: I328a18a723d0f593eea491f788a6e256d6e0c127
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/591784/6 && git format-patch -1 --stdout FETCH_HEAD,['nova/scheduler/client/report.py'],1,68a938670e2c9d2fdeeef2061b0d850598413bb4,bp/use-nested-allocation-candidates," @retries r = self.get(url, global_request_id=context.global_id, version=CONSUMER_GENERATION_VERSION) else: current_consumer_generation = r.json()['consumer_generation'] new_allocs = { alloc_rp_uuid: { } 'resources': current_allocs[rp_uuid]['resources'], new_allocs[rp_uuid] = peer_alloc payload['consumer_generation'] = current_consumer_generation r = self.put(url, payload, version=CONSUMER_GENERATION_VERSION, if r.status_code == 409: reason = ('another process changed the consumer %s we are about ' 'to change' % consumer_uuid) raise Retry('remove_provider_from_instance_allocation', reason) elif r.status_code != 204:"," r = self.get(url, global_request_id=context.global_id) new_allocs = [ { 'resource_provider': { 'uuid': alloc_rp_uuid, }, ] 'resource_provider': { 'uuid': rp_uuid, }, 'resources': current_allocs[rp_uuid]['resources'] new_allocs.append(peer_alloc) r = self.put(url, payload, version='1.10', if r.status_code != 204:",17,15
openstack%2Foslo.log~stable%2Frocky~Ib64837c1ae93a27bef3d30a776320a373f18dd1c,openstack/oslo.log,stable/rocky,Ib64837c1ae93a27bef3d30a776320a373f18dd1c,Filter args dict in JSONFormatter,MERGED,2018-08-30 20:09:06.000000000,2018-09-26 14:24:22.000000000,2018-09-03 14:22:59.000000000,"[{'_account_id': 2472}, {'_account_id': 6928}, {'_account_id': 8770}, {'_account_id': 9796}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-08-30 20:09:06.000000000', 'files': ['oslo_log/tests/unit/test_log.py', 'oslo_log/formatters.py'], 'web_link': 'https://opendev.org/openstack/oslo.log/commit/871d2df290d829b9cafb0dc383dc3d65810c2dac', 'message': 'Filter args dict in JSONFormatter\n\nIn most formatters, any unused keys in the args dict will just be\ndiscarded.  Because JSONFormatter logged the entire dict in addition\nto the message, some values were included in the output that may\nnot have been intended.  This could include sensitive data, so we\nshould stop that.\n\nIn the interest of maintaining compatibility with any tools that are\nreading the args dict, we leave the dict but filter out any unused\nkeys.\n\nChange-Id: Ib64837c1ae93a27bef3d30a776320a373f18dd1c\nCloses-Bug: 1571714\nCloses-Bug: 1787214\n(cherry picked from commit a93c6ef98c8aeddc5a4ae87083689225fbc728bb)\n'}]",0,598338,871d2df290d829b9cafb0dc383dc3d65810c2dac,14,5,1,6928,,,0,"Filter args dict in JSONFormatter

In most formatters, any unused keys in the args dict will just be
discarded.  Because JSONFormatter logged the entire dict in addition
to the message, some values were included in the output that may
not have been intended.  This could include sensitive data, so we
should stop that.

In the interest of maintaining compatibility with any tools that are
reading the args dict, we leave the dict but filter out any unused
keys.

Change-Id: Ib64837c1ae93a27bef3d30a776320a373f18dd1c
Closes-Bug: 1571714
Closes-Bug: 1787214
(cherry picked from commit a93c6ef98c8aeddc5a4ae87083689225fbc728bb)
",git fetch https://review.opendev.org/openstack/oslo.log refs/changes/38/598338/1 && git format-patch -1 --stdout FETCH_HEAD,"['oslo_log/formatters.py', 'oslo_log/tests/unit/test_log.py']",2,871d2df290d829b9cafb0dc383dc3d65810c2dac,bug/1571714-stable/rocky," def test_extra_args_filtered(self): test_msg = 'This is a %(test)s line %%(unused)' test_data = {'test': 'log', 'unused': 'removeme'} self.log.debug(test_msg, test_data) data = jsonutils.loads(self.stream.getvalue()) self.assertNotIn('unused', data['args']) def test_entire_dict(self): test_msg = 'This is a %s dict' test_data = {'test': 'log', 'other': 'value'} self.log.debug(test_msg, test_data) data = jsonutils.loads(self.stream.getvalue()) self.assertEqual(test_data, data['args']) ",,32,1
openstack%2Fhorizon~master~Ie95132d0fdb1e7aae5e32faad752f92ff76b238a,openstack/horizon,master,Ie95132d0fdb1e7aae5e32faad752f92ff76b238a,Move to '404' page when resource type or resource not found,MERGED,2018-07-04 09:26:43.000000000,2018-09-26 14:21:17.000000000,2018-09-26 14:21:16.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 8478}, {'_account_id': 14151}, {'_account_id': 16352}, {'_account_id': 16628}, {'_account_id': 22348}, {'_account_id': 27336}]","[{'number': 1, 'created': '2018-07-04 09:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/0a52b807dc50e6c761cab8949e1dedef2af027ce', 'message': ""Move to '404' page when resource type or resource not found\n\nWhen refresh or link directly to ngdetails without existing resource type\nor ID for the resource, ngdetails view shows blank view.\n\nThis patch jump to 404 page in this situation.\n\nChange-Id: Ie95132d0fdb1e7aae5e32faad752f92ff76b238a\nCloses-Bug: #1746709\n""}, {'number': 2, 'created': '2018-07-10 00:52:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/cc6d35a8244993fba50fc1ce8800e33b27c25b14', 'message': ""Move to '404' page when resource type or resource not found\n\nWhen refresh or link directly to ngdetails without existing resource type\nor ID for the resource, ngdetails view shows blank view.\n\nThis patch jump to 404 page in this situation.\n\nChange-Id: Ie95132d0fdb1e7aae5e32faad752f92ff76b238a\nCloses-Bug: #1746709\n""}, {'number': 3, 'created': '2018-07-24 00:48:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/30fd78d79cd34c0c70168ad1d2da0c9e06ae3a3c', 'message': ""Move to '404' page when resource type or resource not found\n\nWhen refresh or link directly to ngdetails without existing resource type\nor ID for the resource, ngdetails view shows blank view.\n\nThis patch jump to 404 page in this situation.\n\nChange-Id: Ie95132d0fdb1e7aae5e32faad752f92ff76b238a\nCloses-Bug: #1746709\n""}, {'number': 4, 'created': '2018-08-28 05:15:30.000000000', 'files': ['horizon/static/framework/framework.module.js', 'horizon/static/framework/widgets/details/routed-details-view.controller.js', 'horizon/karma.conf.js', 'horizon/static/framework/widgets/details/routed-details-view.controller.spec.js'], 'web_link': 'https://opendev.org/openstack/horizon/commit/58af8067966539dd3417f113e7356298b48386e5', 'message': ""Move to '404' page when resource type or resource not found\n\nWhen refresh or link directly to ngdetails without existing resource type\nor ID for the resource, ngdetails view shows blank view.\n\nThis patch jump to 404 page in this situation.\n\nChange-Id: Ie95132d0fdb1e7aae5e32faad752f92ff76b238a\nCloses-Bug: #1746709\n""}]",3,580103,58af8067966539dd3417f113e7356298b48386e5,34,8,4,16352,,,0,"Move to '404' page when resource type or resource not found

When refresh or link directly to ngdetails without existing resource type
or ID for the resource, ngdetails view shows blank view.

This patch jump to 404 page in this situation.

Change-Id: Ie95132d0fdb1e7aae5e32faad752f92ff76b238a
Closes-Bug: #1746709
",git fetch https://review.opendev.org/openstack/horizon refs/changes/03/580103/2 && git format-patch -1 --stdout FETCH_HEAD,"['horizon/static/framework/widgets/details/routed-details-view.controller.js', 'horizon/static/framework/widgets/details/routed-details-view.controller.spec.js']",2,0a52b807dc50e6c761cab8949e1dedef2af027ce,bug/1746709," var ctrl, deferred, $timeout, $q, $window, service, actionResultService, navigationsService; $window = {location: {href: ''}}; service = { resourceTypes: {'OS::Glance::Image': {}}, getActivePanelUrl: function() { return 'project/fancypanel'; }, nav: true, isNavigationExists: function() { return navigationsService.nav; } }, '$window': $window describe('RoutedDetailsViewController', function() { beforeEach(inject(function($controller) { service.resourceTypes = {}; ctrl = $controller(""RoutedDetailsViewController"", { 'horizon.framework.conf.resource-type-registry.service': service, 'horizon.framework.util.actions.action-result.service': actionResultService, 'horizon.framework.util.navigations.service': navigationsService, 'horizon.framework.widgets.modal-wait-spinner.service': { showModalSpinner: angular.noop, hideModalSpinner: angular.noop }, '$routeParams': { type: 'not exist', path: 'xxxx' }, '$window': $window }); })); it('sets $window.location.href when resource type is not registered', function() { expect($window.location.href).toEqual('/ng404'); }); }); it('sets $window.location.href when item not found', function() { deferred.reject({status: 404}); $timeout.flush(); expect($window.location.href).toEqual('/ng404'); }); it('does not set $window.location.href when server error occurred', function() { deferred.reject({status: 500}); $timeout.flush(); expect($window.location.href).toEqual(''); }); "," var ctrl, deferred, $timeout, $q, actionResultService, navigationsService; var service = { getActivePanelUrl: function() { return 'project/fancypanel'; } }",64,7
openstack%2Ftripleo-ci~master~Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674,openstack/tripleo-ci,master,Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674,Prepare Docker Registry + Containers in pre-run,ABANDONED,2018-07-04 05:20:17.000000000,2018-09-26 14:10:46.000000000,,"[{'_account_id': 1955}, {'_account_id': 3153}, {'_account_id': 4162}, {'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-07-04 05:20:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b6b33ca86f082c1d4b36528f0d0169f4d217dbe0', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 2, 'created': '2018-07-04 05:29:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/45273e8ad2131657dcd0dcdb5bdf30eb3e8c039e', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 3, 'created': '2018-07-04 05:45:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/dd95e959ebcdc9c7e96e3181648c4357eaaeb5e1', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 4, 'created': '2018-07-04 05:50:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/eb982cd23e5aeca245c2f254b283431fb572baa5', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 5, 'created': '2018-07-04 05:59:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b76aa692f98f270657786cafc0681837521799d6', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 6, 'created': '2018-07-04 13:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/193c8719353632128d1aa27346204939866df5a9', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 7, 'created': '2018-07-04 14:50:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3941758b412c4669d85616a58806f7d6ede01b2', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 8, 'created': '2018-07-04 15:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/003a366fc25bb96f6127a661ab24c784baa96068', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 9, 'created': '2018-07-04 16:53:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8fbe293019d35a9c64ab00ff36531879d9db083d', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 10, 'created': '2018-07-04 17:26:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7c8a2ef554547e224d300986fa519cacc59e8277', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 11, 'created': '2018-07-04 18:41:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cb6ff06c42077544b8b0ede78eb97e002d4cd813', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 12, 'created': '2018-07-04 18:54:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cb3afbe03b5f57a23e22ae6e3ce8f1a10fa5f92c', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 13, 'created': '2018-07-04 19:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/642f1e276b550937e2f71773caa8e5e6e5cd5d41', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 14, 'created': '2018-07-04 19:35:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6919282696250ae2f1eec0c2f7b6b60dfe725a31', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 15, 'created': '2018-07-04 19:58:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6ec1a76f7f9e90bd81a9bc7efbed1ec4c52dea90', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 16, 'created': '2018-07-04 20:09:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fe1b47e9683508e8ab74ed6b98c4dbba2d8725ec', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 17, 'created': '2018-07-04 20:24:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2a868f5d023a864424ae6f5834c83bfd8abf71ed', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 18, 'created': '2018-07-04 20:32:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/834d5d7530a990dfc73cf86bd8406d92bbe9c1cf', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 19, 'created': '2018-07-04 20:52:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9a7701e1c3b1fda27b0d610eb653b0895e321dcc', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 20, 'created': '2018-07-04 20:58:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1a3fcc2de249798e65f174f01e57d2f2bd5b69c6', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 21, 'created': '2018-07-04 22:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e3216eb04d36c19368a73a372936e3508827122b', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 22, 'created': '2018-07-05 00:29:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/283c6ed2c5e925fd004c041e1049e60bc4d5d201', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 23, 'created': '2018-07-05 01:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fa44cd3fa7b9849103aeb78938200049089b7f2c', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 24, 'created': '2018-07-05 01:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a4714917c66159e4e23f35c8a9ba62dcc64dcff6', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 25, 'created': '2018-07-05 02:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/47628474ca3ae006834adac94728554fa7703aed', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 26, 'created': '2018-07-05 02:27:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1cee1632ebbc8474401890c5acfc6af5c2e59602', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 27, 'created': '2018-07-05 02:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/61df97a4b882f689a110a4c1370fadc6cfc488f4', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 28, 'created': '2018-07-05 02:44:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/afa2058f3c40e55bd8f98e65f8fd8531846b86d0', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 29, 'created': '2018-07-05 04:39:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1935bfb33cfa00aae478c68b9c372d67afd21c20', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 30, 'created': '2018-07-05 05:03:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fe07d199dca83eba7e5e907650f1b84e3d2db877', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 31, 'created': '2018-07-05 11:15:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/db44bc67d70f3b9d1e1abfdc1d66f971c13bce4f', 'message': 'WIP - Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 32, 'created': '2018-07-05 15:13:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4ace1f6497fcdce88a309d91802eb9cbdae2024e', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 33, 'created': '2018-07-05 21:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ea15702619b00f5e2ea7636215d529cbe3429bb7', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 34, 'created': '2018-07-05 22:38:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/687d4362e1e7ab4405422b5485049a03257b65de', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 35, 'created': '2018-07-05 22:40:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9849f01d8fb58cf8316bd3e2f0d7d6c4f633f320', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 36, 'created': '2018-07-05 23:21:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8762d41ccbca9f08cec44aa6c219cf405bf6bcf8', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 37, 'created': '2018-07-06 00:02:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/94d09bcb66d1cf431686004a68cf5ca4626dfa4d', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 38, 'created': '2018-07-06 00:14:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/4313a5e6b37ce47e170c019bf23d684d9c696ae6', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 39, 'created': '2018-07-06 00:55:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/fc26cd42cc7f554f40fb739a9bba7b8a2035e6b5', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 40, 'created': '2018-07-06 01:32:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9801888b2d1bd3c7ba5563a92011940b652c1491', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 41, 'created': '2018-07-06 01:48:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b3896124ced4b753e48e62b5c476729524441b2f', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 42, 'created': '2018-07-06 09:11:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/cef718434d51857298c0000a31a7c495d6a325c5', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 43, 'created': '2018-07-06 19:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3c1d54067479bbafe13a5ffc693d6ce4c69361e2', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 44, 'created': '2018-07-07 03:23:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9b6794e97c4921d4aadc8667e4c5176599c2a068', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 45, 'created': '2018-07-09 18:53:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d1a2d36cd1671bc76d6043177d25181a298a9654', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 46, 'created': '2018-07-09 22:54:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e168f4a7570ff2ea7d8c873fd234672faaf26632', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 47, 'created': '2018-07-10 00:10:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/2f04a9baf1f0a1d171e34c130cbafee360bc6d25', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 48, 'created': '2018-07-10 01:59:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0845568f0cd97c3732e95836f0e28167dce5e3fc', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 49, 'created': '2018-07-11 14:21:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3ac3087325ac074666268910a30a9d757b53672f', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 50, 'created': '2018-07-11 20:21:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c8cdc5a28f1c09bed8e7af6dde7557b31bd1b7bf', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 51, 'created': '2018-07-11 21:01:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e036d73af423563581c06602417acb2c86b3bc8a', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 52, 'created': '2018-07-11 22:29:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8ad09cc844dcc4e676d15a6431f50fb18ca19d43', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 53, 'created': '2018-07-12 18:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a447876bcad1f4cc2de61b6b9d88d8c5c7f22861', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 54, 'created': '2018-07-12 19:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/919a9fd264a346316006d64cd9c5ce8146a88af8', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 55, 'created': '2018-07-12 19:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e2fef023888f760fe00cc1b72f131d4caa9431ec', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 56, 'created': '2018-07-12 23:19:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/228089a31607bd1f5b3435f1013af407f9fee8a2', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 57, 'created': '2018-07-12 23:20:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/78360b4e391dc8be1e8fd2878909154c1c64c0e3', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 58, 'created': '2018-07-30 20:35:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/a6ac4b9fafe1ac635f6ce78cc0225decac4f490a', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 59, 'created': '2018-09-24 22:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/0b29c303ac6d66d9e2c90fbf4eff35507f7cb384', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 60, 'created': '2018-09-24 22:16:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/146bbc0cc7a808de0aa61fdb494b798129c0626d', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 61, 'created': '2018-09-25 20:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c49614f755e7e9bc6111acffd688eb95ff66367e', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}, {'number': 62, 'created': '2018-09-25 22:02:43.000000000', 'files': ['playbooks/containers/pre-prep-docker.yaml', 'zuul.d/base.yaml', 'playbooks/containers/pre-stop-docker.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9949303ab289d2178f4e83c35572df6793a1f55a', 'message': 'Prepare Docker Registry + Containers in pre-run\n\nTo save time during the deployment of TripleO, prepare the Docker\nRegistry v2 and populate it with the containers used by TripleO.\n\nThis patch adds 2 playbooks:\n\n1) pre-prep-docker\n\n- Deploy Docker\n- Deploy Docker Registry v2\n- Download a list of containers from tripleo-common\n- Push containers from remote mirror to the local registry\n\n2) pre-stop-docker\n\nStop and disable Docker services so undercloud deployment can\nre-configure it as fresh.\n\nChange-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674\n'}]",21,580037,9949303ab289d2178f4e83c35572df6793a1f55a,143,14,62,3153,,,0,"Prepare Docker Registry + Containers in pre-run

To save time during the deployment of TripleO, prepare the Docker
Registry v2 and populate it with the containers used by TripleO.

This patch adds 2 playbooks:

1) pre-prep-docker

- Deploy Docker
- Deploy Docker Registry v2
- Download a list of containers from tripleo-common
- Push containers from remote mirror to the local registry

2) pre-stop-docker

Stop and disable Docker services so undercloud deployment can
re-configure it as fresh.

Change-Id: Ic3ba76c7f38a5ba27fcbf4f7a18cb185fda98674
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/37/580037/15 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/containers/pre.yaml', 'zuul.d/base.yaml']",2,b6b33ca86f082c1d4b36528f0d0169f4d217dbe0,containers-prerun, - playbooks/containers/pre.yaml pre-run: - playbooks/multinode-networking/pre.yaml - playbooks/containers/pre.yaml, pre-run: playbooks/multinode-networking/pre.yaml,34,1
openstack%2Fironic-tempest-plugin~master~If8a201fe2ae8f82c3e17e5aaf48e014ab4bd876e,openstack/ironic-tempest-plugin,master,If8a201fe2ae8f82c3e17e5aaf48e014ab4bd876e,switch documentation job to new PTI,MERGED,2018-08-16 13:52:32.000000000,2018-09-26 14:10:14.000000000,2018-09-26 14:10:14.000000000,"[{'_account_id': 6547}, {'_account_id': 10239}, {'_account_id': 13689}, {'_account_id': 22348}, {'_account_id': 27153}, {'_account_id': 28543}]","[{'number': 1, 'created': '2018-08-16 13:52:32.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-tempest-plugin/commit/dab1c6acda12c114d7c33f6614193847a05dbf45', 'message': 'switch documentation job to new PTI\n\nThis is a mechanically generated patch to switch the documentation\njobs to use the new PTI versions of the jobs as part of the\npython3-first goal.\n\nSee the python3-first goal document for details:\nhttps://governance.openstack.org/tc/goals/stein/python3-first.html\n\nChange-Id: If8a201fe2ae8f82c3e17e5aaf48e014ab4bd876e\nStory: #2002586\nTask: #24302\n'}]",0,592400,dab1c6acda12c114d7c33f6614193847a05dbf45,11,6,1,2472,,,0,"switch documentation job to new PTI

This is a mechanically generated patch to switch the documentation
jobs to use the new PTI versions of the jobs as part of the
python3-first goal.

See the python3-first goal document for details:
https://governance.openstack.org/tc/goals/stein/python3-first.html

Change-Id: If8a201fe2ae8f82c3e17e5aaf48e014ab4bd876e
Story: #2002586
Task: #24302
",git fetch https://review.opendev.org/openstack/ironic-tempest-plugin refs/changes/00/592400/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/project.yaml'],1,dab1c6acda12c114d7c33f6614193847a05dbf45,python3-first, - publish-openstack-docs-pti, - publish-openstack-sphinx-docs,1,1
openstack%2Fblazar-nova~stable%2Frocky~I31030cfa1c94ed92c03eb000fdf8958cff9bf84b,openstack/blazar-nova,stable/rocky,I31030cfa1c94ed92c03eb000fdf8958cff9bf84b,Update UPPER_CONSTRAINTS_FILE for stable/rocky,MERGED,2018-07-20 12:53:14.000000000,2018-09-26 14:04:15.000000000,2018-09-26 14:04:15.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}, {'_account_id': 28239}]","[{'number': 1, 'created': '2018-07-20 12:53:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/f46cf11dd7968319d61bcaa92e9e3f495c9885dd', 'message': ""Update UPPER_CONSTRAINTS_FILE for stable/rocky\n\nThe new stable upper-constraints file is only available\nafter the openstack/requirements repository is branched.\nThis will happen around the RC1 timeframe.\n\nRecheck and merge this change once the requirements\nrepository has been branched.\n\nThe CI system will work with this patch before the requirements\nrepository is branched because zuul configues the job to run\nwith a local copy of the file and defaults to the master branch.\nHowever, accepting the patch will break the test configuration\non developers' local systems, so please wait until after the\nrequirements repository is branched to merge the patch.\n\nChange-Id: I31030cfa1c94ed92c03eb000fdf8958cff9bf84b\n""}, {'number': 2, 'created': '2018-09-18 07:45:25.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/blazar-nova/commit/a358d26cd0ba6389a74f462907d88e01ce040a5f', 'message': ""Update UPPER_CONSTRAINTS_FILE for stable/rocky\n\nThe new stable upper-constraints file is only available\nafter the openstack/requirements repository is branched.\nThis will happen around the RC1 timeframe.\n\nRecheck and merge this change once the requirements\nrepository has been branched.\n\nThe CI system will work with this patch before the requirements\nrepository is branched because zuul configues the job to run\nwith a local copy of the file and defaults to the master branch.\nHowever, accepting the patch will break the test configuration\non developers' local systems, so please wait until after the\nrequirements repository is branched to merge the patch.\n\nChange-Id: I31030cfa1c94ed92c03eb000fdf8958cff9bf84b\n""}]",0,584360,a358d26cd0ba6389a74f462907d88e01ce040a5f,13,4,2,22816,,,0,"Update UPPER_CONSTRAINTS_FILE for stable/rocky

The new stable upper-constraints file is only available
after the openstack/requirements repository is branched.
This will happen around the RC1 timeframe.

Recheck and merge this change once the requirements
repository has been branched.

The CI system will work with this patch before the requirements
repository is branched because zuul configues the job to run
with a local copy of the file and defaults to the master branch.
However, accepting the patch will break the test configuration
on developers' local systems, so please wait until after the
requirements repository is branched to merge the patch.

Change-Id: I31030cfa1c94ed92c03eb000fdf8958cff9bf84b
",git fetch https://review.opendev.org/openstack/blazar-nova refs/changes/60/584360/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,f46cf11dd7968319d61bcaa92e9e3f495c9885dd,create-rocky,install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt?h=stable/rocky} {opts} {packages},install_command = {toxinidir}/tools/tox_install.sh {env:UPPER_CONSTRAINTS_FILE:https://git.openstack.org/cgit/openstack/requirements/plain/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fblazar~master~If4240b5a191e2a4e3acee120c53517af029d96b7,openstack/blazar,master,If4240b5a191e2a4e3acee120c53517af029d96b7,Raise database exception instead of returning None,MERGED,2018-07-24 15:47:50.000000000,2018-09-26 14:03:49.000000000,2018-09-26 14:03:49.000000000,"[{'_account_id': 8878}, {'_account_id': 15197}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-07-24 15:47:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/blazar/commit/deb38b06772aac8bf50276475dd1e20033fbe0fc', 'message': ""Raise database exception instead of returning None\n\nIn case of database errors when creating a new compute host, the host\nplugin would not raise the database exception after removing the host\nfrom the freepool, but would instead return None. This is not helpful\nfor operators who get the following message from the CLI:\n\n    'NoneType' object has no attribute 'items'\n\nThis patch raises the database exception again, which results in error\nmessages such as:\n\n    ERROR: BlazarDBDuplicateEntry: A database error occurred\n\nThe code returning None is removed as it is now unneeded.\n\nChange-Id: If4240b5a191e2a4e3acee120c53517af029d96b7\n""}, {'number': 2, 'created': '2018-07-27 14:28:11.000000000', 'files': ['blazar/plugins/oshosts/host_plugin.py', 'blazar/tests/plugins/oshosts/test_physical_host_plugin.py'], 'web_link': 'https://opendev.org/openstack/blazar/commit/29d28fe82fd9f0f6afa4983bb9d3c08590129c17', 'message': ""Raise database exception instead of returning None\n\nIn case of database errors when creating a new compute host, the host\nplugin would not raise the database exception after removing the host\nfrom the freepool, but would instead return None. This is not helpful\nfor operators who get the following message from the CLI:\n\n    'NoneType' object has no attribute 'items'\n\nThis patch raises the database exception again, which results in error\nmessages such as:\n\n    ERROR: BlazarDBDuplicateEntry: A database error occurred\n\nThe code returning None is removed as it is now unneeded.\n\nChange-Id: If4240b5a191e2a4e3acee120c53517af029d96b7\n""}]",0,585409,29d28fe82fd9f0f6afa4983bb9d3c08590129c17,11,3,2,15197,,,0,"Raise database exception instead of returning None

In case of database errors when creating a new compute host, the host
plugin would not raise the database exception after removing the host
from the freepool, but would instead return None. This is not helpful
for operators who get the following message from the CLI:

    'NoneType' object has no attribute 'items'

This patch raises the database exception again, which results in error
messages such as:

    ERROR: BlazarDBDuplicateEntry: A database error occurred

The code returning None is removed as it is now unneeded.

Change-Id: If4240b5a191e2a4e3acee120c53517af029d96b7
",git fetch https://review.opendev.org/openstack/blazar refs/changes/09/585409/1 && git format-patch -1 --stdout FETCH_HEAD,"['blazar/plugins/oshosts/host_plugin.py', 'blazar/tests/plugins/oshosts/test_physical_host_plugin.py']",2,deb38b06772aac8bf50276475dd1e20033fbe0fc,soft-delete," self.assertRaises(db_exceptions.BlazarDBException, self.fake_phys_plugin.create_computehost, self.fake_host)", host = self.fake_phys_plugin.create_computehost(self.fake_host) self.assertIsNone(host),15,17
openstack%2Ftripleo-ci~master~I3c5e6e771377f2d03d4964c00e51740e358cf556,openstack/tripleo-ci,master,I3c5e6e771377f2d03d4964c00e51740e358cf556,Increase post-timeout to 1 hour,MERGED,2018-09-25 19:24:06.000000000,2018-09-26 13:48:53.000000000,2018-09-26 13:48:52.000000000,"[{'_account_id': 3153}, {'_account_id': 7065}, {'_account_id': 9592}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-09-25 19:24:06.000000000', 'files': ['zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/c5e94275ad404622a6bb288a9bf3ba31dde45bfc', 'message': ""Increase post-timeout to 1 hour\n\nThis used to be 3 hours prior to the change in zuul dropping this down\nto 30 mins. It appears that when we cut over to v3, we set it to 40\nminutes however we are hitting POST_FAILUREs when log collection fails\ndue to timeouts. Let's increase this to 1 hour.\n\nChange-Id: I3c5e6e771377f2d03d4964c00e51740e358cf556\n""}]",0,605185,c5e94275ad404622a6bb288a9bf3ba31dde45bfc,9,4,1,14985,,,0,"Increase post-timeout to 1 hour

This used to be 3 hours prior to the change in zuul dropping this down
to 30 mins. It appears that when we cut over to v3, we set it to 40
minutes however we are hitting POST_FAILUREs when log collection fails
due to timeouts. Let's increase this to 1 hour.

Change-Id: I3c5e6e771377f2d03d4964c00e51740e358cf556
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/85/605185/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/base.yaml'],1,c5e94275ad404622a6bb288a9bf3ba31dde45bfc,fix-post-timeout, post-timeout: 3600, post-timeout: 2400,1,1
openstack%2Frequirements~master~I7df68a67a040fb7372a9edf54dc29b69aa0168e7,openstack/requirements,master,I7df68a67a040fb7372a9edf54dc29b69aa0168e7,Add ceilometer to global-requirements.txt,MERGED,2018-09-11 04:10:42.000000000,2018-09-26 13:48:06.000000000,2018-09-17 19:24:42.000000000,"[{'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 12898}, {'_account_id': 14288}, {'_account_id': 17068}, {'_account_id': 17499}, {'_account_id': 19316}, {'_account_id': 22348}, {'_account_id': 26507}, {'_account_id': 28706}, {'_account_id': 28935}]","[{'number': 1, 'created': '2018-09-11 04:10:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/4e6543027dfb3a9375daea788723664056676ddb', 'message': '[Q] Is the library actively maintained?\n[A] Yes.\n\n[Q] Is the library good code?\n[A] Yes.\n\n[Q] Is the library python 3 compatible?\n[A] Yes. It has a python 3.x voting jobs\n\n[Q] Is the library license compatible?\n[A] Yes. Apache 2.0\n\n[Q] Is the library already packaged in the distros we target\n    (Ubuntu latest / Fedora latest)?\n[A] Yes.\n\n[Q] Is the function of this library already covered by other\n    libraries in global-requirements.txt?\n[A] No.\n\n[Q] Is the library required for OpenStack project or related dev\n    or infrastructure setup? (Answer to this should be Yes,\n    of course) Which?\n[A] This is an openstack services that provides library-like features.\n\nChange-Id: I7df68a67a040fb7372a9edf54dc29b69aa0168e7\n'}, {'number': 2, 'created': '2018-09-11 04:11:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/a8e1a33a098f041a0c10a34a394390cb318980f2', 'message': 'Add ceilomter to global-requirements.txt\n\n[Q] Is the library actively maintained?\n[A] Yes.\n\n[Q] Is the library good code?\n[A] Yes.\n\n[Q] Is the library python 3 compatible?\n[A] Yes. It has a python 3.x voting jobs\n\n[Q] Is the library license compatible?\n[A] Yes. Apache 2.0\n\n[Q] Is the library already packaged in the distros we target\n    (Ubuntu latest / Fedora latest)?\n[A] Yes.\n\n[Q] Is the function of this library already covered by other\n    libraries in global-requirements.txt?\n[A] No.\n\n[Q] Is the library required for OpenStack project or related dev\n    or infrastructure setup? (Answer to this should be Yes,\n    of course) Which?\n[A] This is an openstack services that provides library-like features.\n\nChange-Id: I7df68a67a040fb7372a9edf54dc29b69aa0168e7\n'}, {'number': 3, 'created': '2018-09-11 09:54:52.000000000', 'files': ['global-requirements.txt', 'upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/33c4e6a90ad2a082a41a0652f9dbbe82f3bdb347', 'message': 'Add ceilometer to global-requirements.txt\n\n[Q] Is the library actively maintained?\n[A] Yes.\n\n[Q] Is the library good code?\n[A] Yes.\n\n[Q] Is the library python 3 compatible?\n[A] Yes. It has a python 3.x voting jobs\n\n[Q] Is the library license compatible?\n[A] Yes. Apache 2.0\n\n[Q] Is the library already packaged in the distros we target\n    (Ubuntu latest / Fedora latest)?\n[A] Yes.\n\n[Q] Is the function of this library already covered by other\n    libraries in global-requirements.txt?\n[A] No.\n\n[Q] Is the library required for OpenStack project or related dev\n    or infrastructure setup? (Answer to this should be Yes,\n    of course) Which?\n[A] This is an openstack services that provides library-like features.\n\nChange-Id: I7df68a67a040fb7372a9edf54dc29b69aa0168e7\n'}]",4,601487,33c4e6a90ad2a082a41a0652f9dbbe82f3bdb347,39,11,3,12898,,,0,"Add ceilometer to global-requirements.txt

[Q] Is the library actively maintained?
[A] Yes.

[Q] Is the library good code?
[A] Yes.

[Q] Is the library python 3 compatible?
[A] Yes. It has a python 3.x voting jobs

[Q] Is the library license compatible?
[A] Yes. Apache 2.0

[Q] Is the library already packaged in the distros we target
    (Ubuntu latest / Fedora latest)?
[A] Yes.

[Q] Is the function of this library already covered by other
    libraries in global-requirements.txt?
[A] No.

[Q] Is the library required for OpenStack project or related dev
    or infrastructure setup? (Answer to this should be Yes,
    of course) Which?
[A] This is an openstack services that provides library-like features.

Change-Id: I7df68a67a040fb7372a9edf54dc29b69aa0168e7
",git fetch https://review.opendev.org/openstack/requirements refs/changes/87/601487/3 && git format-patch -1 --stdout FETCH_HEAD,['global-requirements.txt'],1,4e6543027dfb3a9375daea788723664056676ddb,add-ceilometer,# NOTE(tonyb): Generally adding OpenSatck services isn't allowed but some consumers of ceilometer # use it like a library so until there is a ceilometer-lib (or similar) this is our best option. ceilometer # Apache-2.0 ,,4,0
openstack%2Ftempest~master~I6820e84a27dd04f8a4b8b490c935941135b6aa94,openstack/tempest,master,I6820e84a27dd04f8a4b8b490c935941135b6aa94,Make some test_list_users tests work w/ pre-prov,ABANDONED,2018-08-15 21:25:23.000000000,2018-09-26 13:47:02.000000000,,"[{'_account_id': 10385}, {'_account_id': 12033}, {'_account_id': 20378}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2018-08-15 21:25:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/d4e47c930edc2d24d669ece94022f47e72beec6c', 'message': 'Make some test_list_users tests work w/ pre-prov\n\nThis is part 2 of 2 commits to not force dynamic creds to execute\nthe following tests:\n  * test_list_user_domains\n  * test_list_users_with_name\n  * test_list_users\n  * test_get_user\nso that users with a cloud using the pre-provisioned credential\nprovider can execute these tests.\nPart 1 did some refactoring[1]\n\nThe other test cannot be moved because they require resources to\nbe created explained below:\n  * test_list_users_with_not_enabled\n    - if this test requires users that are disabled then we\n      cannot use pre-provisioned credentials because there is no\n      way to provide an account that is disabled with the current\n      implementation of the pre-provisioned credential provider.\n\nChange-Id: I6820e84a27dd04f8a4b8b490c935941135b6aa94\n'}, {'number': 2, 'created': '2018-08-16 16:32:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/457b16a65c75177f83ef922bc7587d39622df090', 'message': 'Make some test_list_users tests work w/ pre-prov\n\nThis is part 2 of 2 commits to not force dynamic creds to execute\nthe following tests:\n  * test_list_user_domains\n  * test_list_users_with_name\n  * test_list_users\n  * test_get_user\nso that users with a cloud using the pre-provisioned credential\nprovider can execute these tests.\nPart 1 did some refactoring[1]\n\nThe other test cannot be moved because they require resources to\nbe created explained below:\n  * test_list_users_with_not_enabled\n    - if this test requires users that are disabled then we\n      cannot use pre-provisioned credentials because there is no\n      way to provide an account that is disabled with the current\n      implementation of the pre-provisioned credential provider.\n\n[1] https://review.openstack.org/#/c/592202/\n\nChange-Id: I6820e84a27dd04f8a4b8b490c935941135b6aa94\n'}, {'number': 3, 'created': '2018-08-16 16:36:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/6a10935a8fb01b76310da0f552000833c21ae7ac', 'message': 'Make some test_list_users tests work w/ pre-prov\n\nThis is part 2 of 2 commits to not force dynamic creds to execute\nthe following tests:\n  * test_list_user_domains\n  * test_list_users_with_name\n  * test_list_users\n  * test_get_user\nso that users with a cloud using the pre-provisioned credential\nprovider can execute these tests.\nPart 1 did some refactoring[1]\n\nThe other test cannot be moved because they require resources to\nbe created explained below:\n  * test_list_users_with_not_enabled\n    - if this test requires users that are disabled then we\n      cannot use pre-provisioned credentials because there is no\n      way to provide an account that is disabled with the current\n      implementation of the pre-provisioned credential provider.\n\n[1] https://review.openstack.org/#/c/592202/\n\nChange-Id: I6820e84a27dd04f8a4b8b490c935941135b6aa94\n'}, {'number': 4, 'created': '2018-08-16 16:40:55.000000000', 'files': ['tempest/api/identity/v3/test_list_users.py', 'tempest/api/identity/admin/v3/test_list_users.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/69e98162c9335951230b783ecb95c58d2f7ec2fb', 'message': 'Make some test_list_users tests work w/ pre-prov\n\nThis is part 2 of 2 commits to not force dynamic creds to execute\nthe following tests:\n  * test_list_user_domains\n  * test_list_users_with_name\n  * test_list_users\n  * test_get_user\nso that users with a cloud using the pre-provisioned credential\nprovider can execute these tests.\nPart 1 did some refactoring[1]\n\nThe other test cannot be moved because they require resources to\nbe created explained below:\n  * test_list_users_with_not_enabled\n    - if this test requires users that are disabled then we\n      cannot use pre-provisioned credentials because there is no\n      way to provide an account that is disabled with the current\n      implementation of the pre-provisioned credential provider.\n\n[1] https://review.openstack.org/#/c/592202/\n\nChange-Id: I6820e84a27dd04f8a4b8b490c935941135b6aa94\n'}]",1,592203,69e98162c9335951230b783ecb95c58d2f7ec2fb,14,5,4,20378,,,0,"Make some test_list_users tests work w/ pre-prov

This is part 2 of 2 commits to not force dynamic creds to execute
the following tests:
  * test_list_user_domains
  * test_list_users_with_name
  * test_list_users
  * test_get_user
so that users with a cloud using the pre-provisioned credential
provider can execute these tests.
Part 1 did some refactoring[1]

The other test cannot be moved because they require resources to
be created explained below:
  * test_list_users_with_not_enabled
    - if this test requires users that are disabled then we
      cannot use pre-provisioned credentials because there is no
      way to provide an account that is disabled with the current
      implementation of the pre-provisioned credential provider.

[1] https://review.openstack.org/#/c/592202/

Change-Id: I6820e84a27dd04f8a4b8b490c935941135b6aa94
",git fetch https://review.opendev.org/openstack/tempest refs/changes/03/592203/4 && git format-patch -1 --stdout FETCH_HEAD,"['tempest/api/identity/v3/test_list_users.py', 'tempest/api/identity/admin/v3/test_list_users.py']",2,d4e47c930edc2d24d669ece94022f47e72beec6c,bug/1714277,," @decorators.idempotent_id('08f9aabb-dcfe-41d0-8172-82b5fa0bd73d') def test_list_user_domains(self): # List users with domain params = {'domain_id': self.domain['id']} self._list_users_with_params(params, 'domain_id', [self.domain_enabled_user], []) @decorators.idempotent_id('c285bb37-7325-4c02-bff3-3da5d946d683') def test_list_users_with_name(self): # List users with name params = {'name': self.domain_enabled_user['name']} # When domain specific drivers are enabled the operations # of listing all users and listing all groups are not supported, # they need a domain filter to be specified if CONF.identity_feature_enabled.domain_specific_drivers: params['domain_id'] = self.domain_enabled_user['domain_id'] self._list_users_with_params(params, 'name', [self.domain_enabled_user], []) @decorators.idempotent_id('b30d4651-a2ea-4666-8551-0c0e49692635') def test_list_users(self): # List users # When domain specific drivers are enabled the operations # of listing all users and listing all groups are not supported, # they need a domain filter to be specified if CONF.identity_feature_enabled.domain_specific_drivers: body = self.users_client.list_users( domain_id=self.domain_enabled_user['domain_id'])['users'] else: body = self.users_client.list_users()['users'] fetched_ids = [u['id'] for u in body] missing_users = [u['id'] for u in self.users if u['id'] not in fetched_ids] self.assertEmpty(missing_users, ""Failed to find user %s in fetched list"" % ', '.join(m_user for m_user in missing_users)) @decorators.idempotent_id('b4baa3ae-ac00-4b4e-9e27-80deaad7771f') def test_get_user(self): # Get a user detail user = self.users_client.show_user(self.users[0]['id'])['user'] self.assertEqual(self.users[0]['id'], user['id']) self.assertEqual(self.users[0]['name'], user['name']) self.assertEqual(self.domain['id'], user['domain_id'])",90,46
