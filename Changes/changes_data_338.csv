id,project,branch,change_id,subject,status,created,updated,submitted,reviewers,revisions,total_comment_count,number,current_revision,discussion_messages_count,reviewers_count,revisions_count,owner_account_id,owner_name,owner_username,is_owner_bot,commit_message,git_command,changed_files,files_count,commit_id,topic,added_lines,deleted_lines,insertions,deletions
openstack%2Foperations-guide~master~I1bc60eab58055bd6217ddb7c7c5c2e3bd6fb539e,openstack/operations-guide,master,I1bc60eab58055bd6217ddb7c7c5c2e3bd6fb539e,setup.cfg: Cleanup,MERGED,2019-10-18 02:00:55.000000000,2019-10-18 02:45:11.000000000,2019-10-18 02:43:45.000000000,"[{'_account_id': 11904}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-10-18 02:00:55.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/operations-guide/commit/aeb5268df7bf6581bac05907fe5af077608ef771', 'message': ""setup.cfg: Cleanup\n\n- pbr hasn't need the hook configuration since forever [1]\n\n[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2\n\nChange-Id: I1bc60eab58055bd6217ddb7c7c5c2e3bd6fb539e\n""}]",0,689296,aeb5268df7bf6581bac05907fe5af077608ef771,9,4,1,28471,,,0,"setup.cfg: Cleanup

- pbr hasn't need the hook configuration since forever [1]

[1] https://github.com/openstack/pbr/commit/c84876dc0f559a66fec19b2f81f5717204b253e2

Change-Id: I1bc60eab58055bd6217ddb7c7c5c2e3bd6fb539e
",git fetch https://review.opendev.org/openstack/operations-guide refs/changes/96/689296/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,aeb5268df7bf6581bac05907fe5af077608ef771,,,[global] setup-hooks = pbr.hooks.setup_hook ,0,4
openstack%2Fnetworking-ovn~stable%2Fqueens~I6b659cbede25f271fa3b6a1c9e72019694ab6608,openstack/networking-ovn,stable/queens,I6b659cbede25f271fa3b6a1c9e72019694ab6608,Set binding profile directly from OVNTrunkDriver (redo),MERGED,2019-10-10 20:02:34.000000000,2019-10-18 02:34:53.000000000,2019-10-18 02:34:52.000000000,"[{'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-10 20:02:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/523cf15b698227ad590c8395e731a99c137bd585', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 7bdf2eb824083b6785d78dd67b3effe071e3f7a4)\n(cherry picked from commit e14b6cd76bade8291764a88b6a2fa851a3a86b87)\n(cherry picked from commit e63c5c97ce662656c84988ff2f47616a0e36ca81)\n(cherry picked from commit c5d97dab248ca5c5cc576f70d4e819bc582bb65a)\n'}, {'number': 2, 'created': '2019-10-10 21:03:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9bf08665dd4c04eb64537ff020e6fc7374710b0b', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 7bdf2eb824083b6785d78dd67b3effe071e3f7a4)\n(cherry picked from commit e14b6cd76bade8291764a88b6a2fa851a3a86b87)\n(cherry picked from commit e63c5c97ce662656c84988ff2f47616a0e36ca81)\n(cherry picked from commit c5d97dab248ca5c5cc576f70d4e819bc582bb65a)\n'}, {'number': 3, 'created': '2019-10-14 12:12:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/a62c62e0c432871669986cbef5c8227234348ca5', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 62eb828186f9248e99fa12cc9c0c8397e1520514)\n'}, {'number': 4, 'created': '2019-10-14 15:44:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5a942fe240afdb0ccfbefdc835066159085ff690', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nNote: While this is a bac-merge from Rocky, special care was\nneeded to account for the fact that in Queens release there\nis only one port binding for a db_port. Thus no iteration over\ndb_port.bindings is used.\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 62eb828186f9248e99fa12cc9c0c8397e1520514)\n'}, {'number': 5, 'created': '2019-10-14 15:44:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/440ea6ef9489272979f390adbe5ccf88e8d1694d', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nNote: While this is a back-merge from Rocky, special care was\nneeded to account for the fact that in Queens release there\nis only one port binding for a db_port. Thus no iteration over\ndb_port.bindings is used.\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 62eb828186f9248e99fa12cc9c0c8397e1520514)\n'}, {'number': 6, 'created': '2019-10-14 19:31:47.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/01d86c3c97b196279769522532ccdef2c3bf52ec', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nNote: While this is a back-merge from Rocky, special care was\nneeded to account for the fact that in Queens release there\nis only one port binding for a db_port. Thus no iteration over\ndb_port.bindings is used.\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 62eb828186f9248e99fa12cc9c0c8397e1520514)\n'}]",0,687972,01d86c3c97b196279769522532ccdef2c3bf52ec,28,7,6,11952,,,0,"Set binding profile directly from OVNTrunkDriver (redo)

Setting binding profile for Trunk subports takes
time - for 125 subports rally CreateAndListTrunks
scenario [0] takes about 150 seconds. We need to
bump up the perfomance because large number of
subports is widly used in Kuryr deployments.

To achieve that I changed setting the binding
profile to be saved directly to the neutron DB.
Instead calling port_update I update only related
fields in OVN NorthBound DB rows. That gave performance
improvement in trunk port creation:

from 101 sec to 35.6 for 95%ile
from 99 sec to 34.2 for 50%ile

The same thing has been done for Trunk deletion.

This reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd

[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37

Note: While this is a back-merge from Rocky, special care was
needed to account for the fact that in Queens release there
is only one port binding for a db_port. Thus no iteration over
db_port.bindings is used.

Change-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608
Closes-Bug: #1834637
Related-Bug: #1845479
Co-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>
(cherry picked from commit 62eb828186f9248e99fa12cc9c0c8397e1520514)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/72/687972/6 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py']",2,523cf15b698227ad590c8395e731a99c137bd585,bug/1834637,"from neutron.objects import ports as port_obj def _set_sub_ports(self, parent_port, subports): txn = self.plugin_driver._nb_ovn.transaction context = n_context.get_admin_context() with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._set_binding_profile(context, port, parent_port, ovn_txn) txn = self.plugin_driver._nb_ovn.transaction context = n_context.get_admin_context() with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._unset_binding_profile(context, port, ovn_txn) def _set_binding_profile(self, context, subport, parent_port, ovn_txn): db_port = port_obj.Port.get_object(context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.update({ 'parent_name': parent_port, 'tag': subport.segmentation_id}) # host + port_id is primary key port_obj.PortBinding.update_object( context, {'profile': binding.profile}, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=parent_port, tag=subport.segmentation_id)) def _unset_binding_profile(self, context, subport, ovn_txn): db_port = port_obj.Port.get_object(context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.pop('tag', None) binding.profile.pop('parent_name', None) # host + port_id is primary key port_obj.PortBinding.update_object( context, {'profile': binding.profile, 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'vif_details': '', 'host': ''}, port_id=subport.port_id, host=binding.host) port_obj.PortBindingLevel.delete_objects( context, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=[], up=False, tag=[])) if trunk.sub_ports: self._set_sub_ports(trunk.port_id, trunk.sub_ports) if trunk.sub_ports: self._unset_sub_ports(trunk.sub_ports) if subports: self._set_sub_ports(trunk.port_id, subports) if subports: self._unset_sub_ports(subports)","from oslo_db import exception as os_db_exc def _set_binding_profile(self, port_id, parent_port, tag=None): context = n_context.get_admin_context() binding_profile = {} if parent_port and tag: binding_profile = {'parent_name': parent_port, 'tag': tag} port = {'port': {'binding:profile': binding_profile}} if not tag: port['port']['binding:host_id'] = None try: self.plugin_driver._plugin.update_port(context, port_id, port) except (os_db_exc.DBReferenceError, n_exc.PortNotFound): LOG.debug(""Port not found trying to set binding_profile: %s"", port_id) def _set_sub_ports(self, parent_port, subports): for port in subports: self._set_binding_profile(port.port_id, parent_port, tag=port.segmentation_id) for port in subports: self._set_binding_profile(port.port_id, None) self._set_sub_ports(trunk.port_id, trunk.sub_ports) self._unset_sub_ports(trunk.sub_ports) self._set_sub_ports(trunk.port_id, subports) self._unset_sub_ports(subports)",274,107
openstack%2Fkarbor~master~I70c5ae7d3ea79ef5868a222509e583d510d8607c,openstack/karbor,master,I70c5ae7d3ea79ef5868a222509e583d510d8607c,Do not use 'self' in classmethod,MERGED,2019-09-29 08:23:43.000000000,2019-10-18 02:04:10.000000000,2019-10-18 02:02:48.000000000,"[{'_account_id': 21224}, {'_account_id': 22348}, {'_account_id': 29272}]","[{'number': 1, 'created': '2019-09-29 08:23:43.000000000', 'files': ['karbor/services/protection/protection_plugins/network/neutron_protection_plugin.py', 'karbor/services/protection/checkpoint.py'], 'web_link': 'https://opendev.org/openstack/karbor/commit/798ba058ae13b78c870bd52326a5dba1d3c9ac39', 'message': ""Do not use 'self' in classmethod\n\n'cls' should be used in classmethd, instead of 'self'.\nThis patch corrects this in the following places:\n    - karbor/services/protection/checkpoint.py\n    - karbor/services/protection/protection_plugins/network/neutron_protection_plugin.py\n\nChange-Id: I70c5ae7d3ea79ef5868a222509e583d510d8607c\n""}]",0,685591,798ba058ae13b78c870bd52326a5dba1d3c9ac39,8,3,1,29729,,,0,"Do not use 'self' in classmethod

'cls' should be used in classmethd, instead of 'self'.
This patch corrects this in the following places:
    - karbor/services/protection/checkpoint.py
    - karbor/services/protection/protection_plugins/network/neutron_protection_plugin.py

Change-Id: I70c5ae7d3ea79ef5868a222509e583d510d8607c
",git fetch https://review.opendev.org/openstack/karbor refs/changes/91/685591/1 && git format-patch -1 --stdout FETCH_HEAD,"['karbor/services/protection/protection_plugins/network/neutron_protection_plugin.py', 'karbor/services/protection/checkpoint.py']",2,798ba058ae13b78c870bd52326a5dba1d3c9ac39,, def _generate_id(cls):, def _generate_id(self):,7,7
openstack%2Fmanila~stable%2Frocky~I6dade5907cb53422a302a43f63271aa89a04e1f5,openstack/manila,stable/rocky,I6dade5907cb53422a302a43f63271aa89a04e1f5,Fix [Unity] verification and convert mgmt ipv6,ABANDONED,2019-10-12 09:12:21.000000000,2019-10-18 02:02:40.000000000,,"[{'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 09:12:21.000000000', 'files': ['manila/share/drivers/dell_emc/plugins/unity/connection.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/d5d2eaa5687a1613c41bff96f4de790ea883a0d6', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\nCloses-bug: #1845135\n\n(cherry picked from commit 923edff7264905e54a307e4fdf95273a6548bc29)\n\nChange-Id: I6dade5907cb53422a302a43f63271aa89a04e1f5\n'}]",1,688264,d5d2eaa5687a1613c41bff96f4de790ea883a0d6,5,3,1,29291,,,0,"Fix [Unity] verification and convert mgmt ipv6

The IPv6 format need change to [ipv6]
Closes-bug: #1845135

(cherry picked from commit 923edff7264905e54a307e4fdf95273a6548bc29)

Change-Id: I6dade5907cb53422a302a43f63271aa89a04e1f5
",git fetch https://review.opendev.org/openstack/manila refs/changes/64/688264/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/dell_emc/plugins/unity/connection.py'],1,d5d2eaa5687a1613c41bff96f4de790ea883a0d6,bug/1845135,"VERSION = ""4.0.1"" """"""Version history: 4.0.1 - Fix parsing management IPv6 address """""" VERSION = ""4.0.1"" storage_ip = enas_utils.convert_ipv6_format_if_needed( config.emc_nas_server)","VERSION = ""4.0.0"" storage_ip = config.emc_nas_server",8,2
openstack%2Fmanila~stable%2Fqueens~I2491b44fc102838a8897f13b1e3ec42539efaca1,openstack/manila,stable/queens,I2491b44fc102838a8897f13b1e3ec42539efaca1,Fix [Unity] verification and convert mgmt ipv6,ABANDONED,2019-10-12 09:08:53.000000000,2019-10-18 02:02:28.000000000,,"[{'_account_id': 16643}, {'_account_id': 18742}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}]","[{'number': 1, 'created': '2019-10-12 09:08:53.000000000', 'files': ['manila/share/drivers/dell_emc/plugins/unity/connection.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/304ae5816ea036207b62a51b514834c5fa916348', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\n\nCloses-bug: #1845135\n\n(cherry picked from commit 923edff7264905e54a307e4fdf95273a6548bc29)\n\nChange-Id: I2491b44fc102838a8897f13b1e3ec42539efaca1\n'}]",1,688262,304ae5816ea036207b62a51b514834c5fa916348,7,5,1,29291,,,0,"Fix [Unity] verification and convert mgmt ipv6

The IPv6 format need change to [ipv6]

Closes-bug: #1845135

(cherry picked from commit 923edff7264905e54a307e4fdf95273a6548bc29)

Change-Id: I2491b44fc102838a8897f13b1e3ec42539efaca1
",git fetch https://review.opendev.org/openstack/manila refs/changes/62/688262/1 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/dell_emc/plugins/unity/connection.py'],1,304ae5816ea036207b62a51b514834c5fa916348,bug/1845135,"VERSION = ""4.0.1"" """"""Version history: 4.0.1 - Fix parsing management IPv6 address """""" VERSION = ""4.0.1"" storage_ip = enas_utils.convert_ipv6_format_if_needed( config.emc_nas_server)","VERSION = ""4.0.0"" storage_ip = config.emc_nas_server",8,2
openstack%2Fkarbor-dashboard~master~If66f8edc7208b406d39cce90d22be53dd7e21301,openstack/karbor-dashboard,master,If66f8edc7208b406d39cce90d22be53dd7e21301,Use Horizon project template for django jobs,MERGED,2019-10-09 16:10:23.000000000,2019-10-18 01:59:01.000000000,2019-10-18 01:59:01.000000000,"[{'_account_id': 1736}, {'_account_id': 21224}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 29272}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-10-09 16:10:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/karbor-dashboard/commit/ee977c2e8551f7daa2ba370a8729877ffe60b4de', 'message': ""Use Horizon project template for django jobs\n\nHorizon defined a project template 'horizon-non-primary-django-jobs'\nfor django jobs. This patch use that template to run django jobs\nhere. For information please refer [1]\n\n[1] https://review.opendev.org/#/c/681969/\n\nChange-Id: If66f8edc7208b406d39cce90d22be53dd7e21301\n""}, {'number': 2, 'created': '2019-10-14 15:31:49.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/karbor-dashboard/commit/7a7cea07999c733dd1522f43bc6ebc77a314c67b', 'message': ""Use Horizon project template for django jobs\n\nHorizon defined a project template 'horizon-non-primary-django-jobs'\nfor django jobs. This patch use that template to run django jobs\nhere. For information please refer [1]\n\n[1] https://review.opendev.org/#/c/681969/\n\nChange-Id: If66f8edc7208b406d39cce90d22be53dd7e21301\n""}]",2,687607,7a7cea07999c733dd1522f43bc6ebc77a314c67b,13,6,2,29313,,,0,"Use Horizon project template for django jobs

Horizon defined a project template 'horizon-non-primary-django-jobs'
for django jobs. This patch use that template to run django jobs
here. For information please refer [1]

[1] https://review.opendev.org/#/c/681969/

Change-Id: If66f8edc7208b406d39cce90d22be53dd7e21301
",git fetch https://review.opendev.org/openstack/karbor-dashboard refs/changes/07/687607/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,ee977c2e8551f7daa2ba370a8729877ffe60b4de,django22,"envlist = py27,py37,py3-{dj111,dj22},pep8commands = dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3 {toxinidir}/manage.py test karbor_dashboard --settings=karbor_dashboard.test.settings","envlist = py27,py37,py27dj18,pep8commands = {toxinidir}/manage.py test karbor_dashboard --settings=karbor_dashboard.test.settings[testenv:py27dj18] basepython = python2.7 commands = pip install django>=1.8,<1.9 /bin/bash run_tests.sh -N --no-pep8 {posargs} ",6,7
openstack%2Fdevstack~master~I51e8354e99972757253ce259e6c03c91da24398c,openstack/devstack,master,I51e8354e99972757253ce259e6c03c91da24398c,Remove deprecated PostgreSQL database driver,MERGED,2019-08-26 09:16:45.000000000,2019-10-18 01:35:58.000000000,2019-10-17 11:39:34.000000000,"[{'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 15334}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 26458}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-08-26 09:16:45.000000000', 'files': ['functions', 'doc/source/configuration.rst', 'lib/databases/postgresql', 'unstack.sh', 'doc/source/zuul_ci_jobs_migration.rst', 'stack.sh'], 'web_link': 'https://opendev.org/openstack/devstack/commit/168ca7f0a474f1207ee01dab0ca2e70f34783e9c', 'message': ""Remove deprecated PostgreSQL database driver\n\nThis was deprecated for removal in Pike. It's probably time to drop it.\nNote that the 'postgresql-devel'/'postgresql-server-dev-all' packages\nare retained since some packages still include 'psycopg2' in their\ngeneral requirements.\n\nChange-Id: I51e8354e99972757253ce259e6c03c91da24398c\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",4,678496,168ca7f0a474f1207ee01dab0ca2e70f34783e9c,18,7,1,15334,,,0,"Remove deprecated PostgreSQL database driver

This was deprecated for removal in Pike. It's probably time to drop it.
Note that the 'postgresql-devel'/'postgresql-server-dev-all' packages
are retained since some packages still include 'psycopg2' in their
general requirements.

Change-Id: I51e8354e99972757253ce259e6c03c91da24398c
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/96/678496/1 && git format-patch -1 --stdout FETCH_HEAD,"['functions', 'doc/source/configuration.rst', 'lib/databases/postgresql', 'unstack.sh', 'doc/source/zuul_ci_jobs_migration.rst', 'stack.sh']",6,168ca7f0a474f1207ee01dab0ca2e70f34783e9c,move-db-deps-to-extras,"# DevStack provides a MySQL database backend. Additional backends may be # provided by external plugins and can be enabled using the usual service # functions and ``ENABLED_SERVICES``. For example, to disable MySQL:","# To select between database backends, add the following to ``local.conf``:# enable_service postgresql # # The available database backends are listed in ``DATABASE_BACKENDS`` after # ``lib/database`` is sourced. ``mysql`` is the default. ",14,166
openstack%2Fpuppet-barbican~master~I5eb9e151994fdd9e320d02bf5b7bbc8ba0d5cda1,openstack/puppet-barbican,master,I5eb9e151994fdd9e320d02bf5b7bbc8ba0d5cda1,add Bugs link to README,ABANDONED,2018-09-27 07:58:57.000000000,2019-10-18 01:35:36.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2018-09-27 07:58:57.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/c15b8ccdda1b0512d6828ebba142a5f2f944aa8b', 'message': 'add Bugs link to README\n\nChange-Id: I5eb9e151994fdd9e320d02bf5b7bbc8ba0d5cda1\n'}]",0,605609,c15b8ccdda1b0512d6828ebba142a5f2f944aa8b,3,1,1,23312,,,0,"add Bugs link to README

Change-Id: I5eb9e151994fdd9e320d02bf5b7bbc8ba0d5cda1
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/09/605609/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,c15b8ccdda1b0512d6828ebba142a5f2f944aa8b,,Bugs ---------- * https://bugs.launchpad.net/puppet-barbican ,,5,0
openstack%2Fpuppet-openstack-guide~master~Ic46e32ea932556c62b47d64fc5369d23016df290,openstack/puppet-openstack-guide,master,Ic46e32ea932556c62b47d64fc5369d23016df290,Update Train versions and add puppet-placement,MERGED,2019-10-17 12:38:15.000000000,2019-10-18 01:16:22.000000000,2019-10-18 01:15:13.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 12:38:15.000000000', 'files': ['doc/source/install/releases.rst'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-guide/commit/af83938565c757bd3bddad4171ac48e36eb44057', 'message': 'Update Train versions and add puppet-placement\n\nChange-Id: Ic46e32ea932556c62b47d64fc5369d23016df290\n'}]",0,689142,af83938565c757bd3bddad4171ac48e36eb44057,7,2,1,16137,,,0,"Update Train versions and add puppet-placement

Change-Id: Ic46e32ea932556c62b47d64fc5369d23016df290
",git fetch https://review.opendev.org/openstack/puppet-openstack-guide refs/changes/42/689142/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/install/releases.rst'],1,af83938565c757bd3bddad4171ac48e36eb44057,update-train-versions,| puppet-aodh_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-aodh/>`__ || puppet-barbican_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-barbican/>`__ || puppet-ceilometer_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-ceilometer/>`__ || puppet-cinder_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-cinder/>`__ || puppet-cloudkitty_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-cloudkitty/>`__ || puppet-congress_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-congress/>`__ || puppet-designate_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-designate/>`__ || puppet-ec2api_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-ec2api/>`__ || puppet-freezer_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-freezer/>`__ || puppet-glance_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-glance/>`__ || puppet-glare_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-glare/>`__ || puppet-gnocchi_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-gnocchi/>`__ || puppet-heat_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-heat/>`__ || puppet-horizon_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-horizon/>`__ || puppet-ironic_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-ironic/>`__ || puppet-keystone_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-keystone/>`__ || puppet-magnum_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-magnum/>`__ || puppet-manila_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-manila/>`__ || puppet-mistral_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-mistral/>`__ || puppet-monasca_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-monasca/>`__ || puppet-murano_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-murano/>`__ || puppet-neutron_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-neutron/>`__ || puppet-nova_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-nova/>`__ || puppet-octavia_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-octavia/>`__ || puppet-openstack_extras_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-openstack_extras/>`__ || puppet-openstack_spec_helper_ | `15.0.0 <http://docs.openstack.org/releasenotes/puppet-openstack_spec_helper/>`__|| puppet-openstacklib_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-openstacklib/>`__ || puppet-oslo_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-oslo/>`__ || puppet-ovn_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-ova/>`__ || puppet-panko_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-panko/>`__ || puppet-placement_ | `2.4.0 <http://docs.openstack.org/releasenotes/puppet-placement/>`__ || puppet-qdr_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-qdr/>`__ || puppet-rally_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-rally/>`__ || puppet-sahara_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-sahara/>`__ || puppet-senlin_ | `2.2.0 <http://docs.openstack.org/releasenotes/puppet-senlin/>`__ || puppet-swift_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-swift/>`__ || puppet-tacker_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-tacker/>`__ || puppet-tempest_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-tempest/>`__ || puppet-trove_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-trove/>`__ || puppet-vitrage_ | `5.4.0 <http://docs.openstack.org/releasenotes/puppet-vitrage/>`__ || puppet-vswitch_ | `11.4.0 <http://docs.openstack.org/releasenotes/puppet-vswitch/>`__ || puppet-watcher_ | `15.4.0 <http://docs.openstack.org/releasnotes/puppet-watcher/>`__ | +---------------------------------+----------------------------------------------------------------------------------+ | puppet-zaqar_ | `15.4.0 <http://docs.openstack.org/releasenotes/puppet-zaqar/>`__ |.. _puppet-placement: https://opendev.org/openstack/puppet-placement,| puppet-aodh_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-aodh/>`__ || puppet-barbican_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-barbican/>`__ || puppet-ceilometer_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-ceilometer/>`__ || puppet-cinder_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-cinder/>`__ || puppet-cloudkitty_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-cloudkitty/>`__ || puppet-congress_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-congress/>`__ || puppet-designate_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-designate/>`__ || puppet-ec2api_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-ec2api/>`__ || puppet-freezer_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-freezer/>`__ || puppet-glance_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-glance/>`__ || puppet-glare_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-glare/>`__ || puppet-gnocchi_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-gnocchi/>`__ || puppet-heat_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-heat/>`__ || puppet-horizon_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-horizon/>`__ || puppet-ironic_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-ironic/>`__ || puppet-keystone_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-keystone/>`__ || puppet-magnum_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-magnum/>`__ || puppet-manila_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-manila/>`__ || puppet-mistral_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-mistral/>`__ || puppet-monasca_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-monasca/>`__ || puppet-murano_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-murano/>`__ || puppet-neutron_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-neutron/>`__ || puppet-nova_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-nova/>`__ || puppet-octavia_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-octavia/>`__ || puppet-openstack_extras_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-openstack_extras/>`__ || puppet-openstack_spec_helper_ | `14.0.0 <http://docs.openstack.org/releasenotes/puppet-openstack_spec_helper/>`__|| puppet-openstacklib_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-openstacklib/>`__ || puppet-oslo_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-oslo/>`__ || puppet-ovn_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-ova/>`__ || puppet-panko_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-panko/>`__ || puppet-qdr_ | `3.4.0 <http://docs.openstack.org/releasenotes/puppet-qdr/>`__ || puppet-rally_ | `2.4.0 <http://docs.openstack.org/releasenotes/puppet-rally/>`__ || puppet-sahara_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-sahara/>`__ || puppet-senlin_ | `1.2.0 <http://docs.openstack.org/releasenotes/puppet-senlin/>`__ || puppet-swift_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-swift/>`__ || puppet-tacker_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-tacker/>`__ || puppet-tempest_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-tempest/>`__ || puppet-trove_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-trove/>`__ || puppet-vitrage_ | `4.4.0 <http://docs.openstack.org/releasenotes/puppet-vitrage/>`__ || puppet-vswitch_ | `10.4.0 <http://docs.openstack.org/releasenotes/puppet-vswitch/>`__ || puppet-watcher_ | `14.4.0 <http://docs.openstack.org/releasnotes/puppet-watcher/>`__ || puppet-zaqar_ | `14.4.0 <http://docs.openstack.org/releasenotes/puppet-zaqar/>`__ |,45,42
openstack%2Fkuryr-kubernetes~master~I4ed15a158cbe24d443a8166fc2584d419eba7004,openstack/kuryr-kubernetes,master,I4ed15a158cbe24d443a8166fc2584d419eba7004,WIP: Use pyroute2 to modify vf properties instead of shell cmd,ABANDONED,2019-10-17 09:59:43.000000000,2019-10-18 01:14:07.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-10-17 09:59:43.000000000', 'files': ['kuryr_kubernetes/cni/binding/sriov.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/844ab521d5f032d09c5b6168bc2f15d667071d62', 'message': 'WIP: Use pyroute2 to modify vf properties instead of shell cmd\n\nChange-Id: I4ed15a158cbe24d443a8166fc2584d419eba7004\n'}]",0,689116,844ab521d5f032d09c5b6168bc2f15d667071d62,3,1,1,29615,,,0,"WIP: Use pyroute2 to modify vf properties instead of shell cmd

Change-Id: I4ed15a158cbe24d443a8166fc2584d419eba7004
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/16/689116/1 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/cni/binding/sriov.py'],1,844ab521d5f032d09c5b6168bc2f15d667071d62,,"import pyroute2 try: with pyroute2.IPRoute() as ip: pf_index = ip.link_lookup(ifname=pf)[0] ip.link(""set"", index=pf_index, vf={""vf"": vf_index, ""mac"": mac}) except Exception: LOG.debug(""Unable to set VF MAC: pf = %s, vf_index = %s, mac = %s"", pf, vf_index, mac) try: with pyroute2.IPRoute() as ip: pf_index = ip.link_lookup(ifname=pf)[0] ip.link(""set"", index=pf_index, vf={""vf"": vf_index, ""vlan"": vlan_id}) except Exception: LOG.debug(""Unable to set VF VLAN: pf = %s, vf_index = %s, vlan = %s"", pf, vf_index, vlan_id)"," cmd = [ 'ip', 'link', 'set', pf, 'vf', vf_index, 'mac', mac ] try: return processutils.execute(*cmd, run_as_root=True) except Exception: LOG.exception(""Unable to execute %s"", cmd) cmd = [ 'ip', 'link', 'set', pf, 'vf', vf_index, 'vlan', vlan_id ] try: return processutils.execute(*cmd, run_as_root=True) except Exception: LOG.exception(""Unable to execute %s"", cmd)",18,12
openstack%2Fnetworking-ovn~stable%2Ftrain~I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8,openstack/networking-ovn,stable/train,I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8,Disable ip_version checking while updating member without new ip,MERGED,2019-10-08 07:05:40.000000000,2019-10-18 01:10:50.000000000,2019-10-18 01:09:43.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-08 07:05:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/d5f477a9cdcac6f63df855c7a4f72da3bcda1262', 'message': ""Disable ip_version checking while updating member without new ip\n\nIf member gets updated with new data, but without IP version\nwe shouldn't be checking if ip_version differs from the listener.\n\nRelated-Bug: #1843553\n\nChange-Id: I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8\n(cherry picked from commit 7f802007843bc9177d7f6a3081045f444b9e5968)\n""}, {'number': 2, 'created': '2019-10-14 10:24:18.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e24adcf5778252095d8f13edf513d402978ff6f1', 'message': ""Disable ip_version checking while updating member without new ip\n\nIf member gets updated with new data, but without IP version\nwe shouldn't be checking if ip_version differs from the listener.\n\nRelated-Bug: #1843553\n\nChange-Id: I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8\n(cherry picked from commit 7f802007843bc9177d7f6a3081045f444b9e5968)\n""}]",0,687219,e24adcf5778252095d8f13edf513d402978ff6f1,36,4,2,24791,,,0,"Disable ip_version checking while updating member without new ip

If member gets updated with new data, but without IP version
we shouldn't be checking if ip_version differs from the listener.

Related-Bug: #1843553

Change-Id: I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8
(cherry picked from commit 7f802007843bc9177d7f6a3081045f444b9e5968)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/19/687219/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py']",2,d5f477a9cdcac6f63df855c7a4f72da3bcda1262,ovn-provider-driver-train-cherry-picks," @mock.patch.object(ovn_driver.OvnProviderDriver, '_ip_version_differs') def test_member_update_no_ip_addr(self, mock_ip_differs): self.update_member.address = None self.driver.member_update(self.ref_member, self.update_member) mock_ip_differs.assert_not_called() ",,8,2
openstack%2Fos-api-ref~master~I6797d2f373a1a1870d8881ef31e4e4da9f27f007,openstack/os-api-ref,master,I6797d2f373a1a1870d8881ef31e4e4da9f27f007,Use Ussuri jobs,MERGED,2019-10-16 20:11:06.000000000,2019-10-18 01:02:44.000000000,2019-10-18 01:00:56.000000000,"[{'_account_id': 8099}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 20:11:06.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/os-api-ref/commit/5052c2949ede07d7a86478c2797769fdd0c0dd4b', 'message': 'Use Ussuri jobs\n\nSwitch from Train to Ussuri python3 jobs.\n\nChange-Id: I6797d2f373a1a1870d8881ef31e4e4da9f27f007\n'}]",0,689032,5052c2949ede07d7a86478c2797769fdd0c0dd4b,8,3,1,6547,,,0,"Use Ussuri jobs

Switch from Train to Ussuri python3 jobs.

Change-Id: I6797d2f373a1a1870d8881ef31e4e4da9f27f007
",git fetch https://review.opendev.org/openstack/os-api-ref refs/changes/32/689032/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5052c2949ede07d7a86478c2797769fdd0c0dd4b,ussuri, - openstack-python3-ussuri-jobs, - openstack-python3-train-jobs,1,1
openstack%2Frequirements~master~I001a45de5484e040006e3941a285e99ef5095f4d,openstack/requirements,master,I001a45de5484e040006e3941a285e99ef5095f4d,update constraint for os-traits to new release 1.1.0,MERGED,2019-10-17 17:09:17.000000000,2019-10-18 00:25:21.000000000,2019-10-18 00:23:08.000000000,"[{'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 17:09:17.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/e865306829841672da3189994a00aa6124678c59', 'message': 'update constraint for os-traits to new release 1.1.0\n\nChange-Id: I001a45de5484e040006e3941a285e99ef5095f4d\nmeta:version: 1.1.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Eric Fried <openstack@fried.cc>\nmeta:release:Commit: Eric Fried <openstack@fried.cc>\nmeta:release:Change-Id: I23519891bb68899a641ed5dd5bd74cfc0cdd9758\nmeta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,689221,e865306829841672da3189994a00aa6124678c59,11,3,1,11131,,,0,"update constraint for os-traits to new release 1.1.0

Change-Id: I001a45de5484e040006e3941a285e99ef5095f4d
meta:version: 1.1.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Eric Fried <openstack@fried.cc>
meta:release:Commit: Eric Fried <openstack@fried.cc>
meta:release:Change-Id: I23519891bb68899a641ed5dd5bd74cfc0cdd9758
meta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/689221/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,e865306829841672da3189994a00aa6124678c59,new-release,os-traits===1.1.0,os-traits===1.0.0,1,1
openstack%2Frequirements~master~If45ce922d6c5da3bd62dddbca6d89fd403d93eef,openstack/requirements,master,If45ce922d6c5da3bd62dddbca6d89fd403d93eef,Add Source links to readme,MERGED,2019-10-17 07:51:11.000000000,2019-10-18 00:24:16.000000000,2019-10-18 00:23:07.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 07:51:11.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/requirements/commit/fca5c491fbf84f52d1027044103d51763a15834e', 'message': 'Add Source links to readme\n\nChange-Id: If45ce922d6c5da3bd62dddbca6d89fd403d93eef\n'}]",0,689092,fca5c491fbf84f52d1027044103d51763a15834e,11,2,1,30384,,,0,"Add Source links to readme

Change-Id: If45ce922d6c5da3bd62dddbca6d89fd403d93eef
",git fetch https://review.opendev.org/openstack/requirements refs/changes/92/689092/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,fca5c491fbf84f52d1027044103d51763a15834e,,- Source: https://opendev.org/openstack/requirements,,1,0
openstack%2Fswift~stable%2Ftrain~If3ead999bff21dff6d0a46af2e92b15fbe7b4958,openstack/swift,stable/train,If3ead999bff21dff6d0a46af2e92b15fbe7b4958,CHANGELOG for 2.23.1,MERGED,2019-10-16 04:52:29.000000000,2019-10-18 00:19:32.000000000,2019-10-18 00:18:14.000000000,"[{'_account_id': 330}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 04:52:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/f031f8f1d8f331f4434007d93029dd30c6487de3', 'message': 'CHANGELOG for 2.23.1\n\nChange-Id: If3ead999bff21dff6d0a46af2e92b15fbe7b4958\n'}, {'number': 2, 'created': '2019-10-17 17:16:22.000000000', 'files': ['releasenotes/notes/2_23_1_release-a2ce9e7092f28dbe.yaml', 'CHANGELOG'], 'web_link': 'https://opendev.org/openstack/swift/commit/4e05fa832a48db113386b40be7ccacfe73bfbcc6', 'message': 'CHANGELOG for 2.23.1\n\nChange-Id: If3ead999bff21dff6d0a46af2e92b15fbe7b4958\n'}]",0,688848,4e05fa832a48db113386b40be7ccacfe73bfbcc6,11,3,2,15343,,,0,"CHANGELOG for 2.23.1

Change-Id: If3ead999bff21dff6d0a46af2e92b15fbe7b4958
",git fetch https://review.opendev.org/openstack/swift refs/changes/48/688848/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/2_23_1_release-a2ce9e7092f28dbe.yaml', 'CHANGELOG']",2,f031f8f1d8f331f4434007d93029dd30c6487de3,release-2_23_1,"swift (2.23.1, train stable backports) * On Python 3, the KMS keymaster now works with secrets stored in Barbican with a text/plain payload-content-type. * Several utility scripts now work better on Python 3: * swift-account-audit * swift-dispersion-populate * swift-drive-recon * swift-recon ",,32,0
openstack%2Fnova~stable%2Fqueens~I857ad7264f1a7ef1263d8a9d4eca491d6c8dce0f,openstack/nova,stable/queens,I857ad7264f1a7ef1263d8a9d4eca491d6c8dce0f,Fix rebuild of baremetal instance when vm_state is ERROR,MERGED,2019-09-08 15:12:59.000000000,2019-10-18 00:18:11.000000000,2019-10-18 00:18:11.000000000,"[{'_account_id': 7166}, {'_account_id': 7634}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-09-08 15:12:59.000000000', 'files': ['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/81056d1293ef47ae47cd5f89a7b7937dedf43c3c', 'message': 'Fix rebuild of baremetal instance when vm_state is ERROR\n\nNova allows rebuild of instance when vm_state is ERROR. [1]\n\nThe vm_state is restored to ACTIVE only after a successful build.\nThis means rebuilding a baremetal instance using the Ironic driver\nis impossible because wait_for_active fails if vm_state=ERROR is found.\n\nThis is a regression introduced in a previous change which added\nthe ability to delete an instance in spawning state. [2]\n\nThis present change will skip the abort installation logic\nif task_state is REBUILD_SPAWNING while preserving the previous logic.\n\n[1] https://bugs.launchpad.net/nova/+bug/1183946\n[2] https://bugs.launchpad.net/nova/+bug/1455000\n\nChange-Id: I857ad7264f1a7ef1263d8a9d4eca491d6c8dce0f\nCloses-bug: #1735009\n(cherry picked from commit 1819718e798fb904644391badc3beb40c181ac39)\n(cherry picked from commit c21cbf296495b0604cc995d5d17ed164ae8562c5)\n(cherry picked from commit e8f418909eb0f6c319e28d6a1eac0471a0a9cee8)\n'}]",0,680873,81056d1293ef47ae47cd5f89a7b7937dedf43c3c,11,7,1,6873,,,0,"Fix rebuild of baremetal instance when vm_state is ERROR

Nova allows rebuild of instance when vm_state is ERROR. [1]

The vm_state is restored to ACTIVE only after a successful build.
This means rebuilding a baremetal instance using the Ironic driver
is impossible because wait_for_active fails if vm_state=ERROR is found.

This is a regression introduced in a previous change which added
the ability to delete an instance in spawning state. [2]

This present change will skip the abort installation logic
if task_state is REBUILD_SPAWNING while preserving the previous logic.

[1] https://bugs.launchpad.net/nova/+bug/1183946
[2] https://bugs.launchpad.net/nova/+bug/1455000

Change-Id: I857ad7264f1a7ef1263d8a9d4eca491d6c8dce0f
Closes-bug: #1735009
(cherry picked from commit 1819718e798fb904644391badc3beb40c181ac39)
(cherry picked from commit c21cbf296495b0604cc995d5d17ed164ae8562c5)
(cherry picked from commit e8f418909eb0f6c319e28d6a1eac0471a0a9cee8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/73/680873/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/ironic/driver.py', 'nova/tests/unit/virt/ironic/test_driver.py']",2,81056d1293ef47ae47cd5f89a7b7937dedf43c3c,bug/1735009," def test__wait_for_active_from_error(self, fake_validate, fake_refresh): instance = fake_instance.fake_instance_obj(self.ctx, uuid=uuidutils.generate_uuid(), vm_state=vm_states.ERROR, task_state=task_states.REBUILD_SPAWNING) node = ironic_utils.get_test_node( provision_state=ironic_states.ACTIVE) fake_validate.return_value = node self.assertRaises(loopingcall.LoopingCallDone, self.driver._wait_for_active, instance) fake_validate.assert_called_once_with(instance) fake_refresh.assert_called_once_with() @mock.patch.object(objects.Instance, 'refresh') @mock.patch.object(ironic_driver.IronicDriver, '_validate_instance_and_node') self._wait_for_active_abort({'task_state': task_states.SPAWNING, 'vm_state': vm_states.ERROR})", self._wait_for_active_abort({'vm_state': vm_states.ERROR}),23,3
openstack%2Fopenstacksdk~stable%2Fqueens~Ib9f80eb809317483f83f79952470c2b57b2bb7c6,openstack/openstacksdk,stable/queens,Ib9f80eb809317483f83f79952470c2b57b2bb7c6,Update python-openstacksdk references to openstacksdk,MERGED,2019-10-17 11:43:52.000000000,2019-10-17 23:32:15.000000000,2019-10-17 23:32:15.000000000,"[{'_account_id': 2}, {'_account_id': 1131}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 11:43:52.000000000', 'files': ['doc/source/contributor/testing.rst', '.gitreview', 'doc/source/install/index.rst', 'SHADE-MERGE-TODO.rst', 'README.rst', 'doc/source/user/guides/clustering/receiver.rst', 'doc/source/user/guides/compute.rst', 'CONTRIBUTING.rst', 'doc/source/contributor/index.rst', 'doc/source/user/guides/clustering/profile_type.rst', 'doc/source/user/guides/clustering/action.rst', 'doc/source/user/guides/clustering/policy_type.rst', 'doc/source/user/guides/network.rst', 'doc/source/user/guides/clustering/profile.rst', 'doc/source/contributor/setup.rst', 'doc/source/user/guides/clustering/policy.rst', 'doc/source/conf.py', 'doc/source/user/guides/clustering/node.rst', 'doc/source/user/guides/clustering/event.rst', 'doc/source/user/guides/connect.rst', 'openstack/tests/ansible/hooks/post_test_hook.sh', 'doc/source/releasenotes.rst', 'doc/source/user/transition_from_profile.rst', 'setup.cfg', 'doc/source/user/guides/clustering/cluster.rst', 'doc/source/user/guides/identity.rst', 'doc/source/user/guides/image.rst', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/3b9f3694101f92965ab421cc45554edd16eca99b', 'message': ""Update python-openstacksdk references to openstacksdk\n\nNow that the repo is renamed, update all of the references.\nWhile we're at it, remote unused translation config.\n\nNote: intentionally not trying to update all of the openstack>opendev\nchanges since then as they are not really needed in an old stable\nbranch.\n\nChange-Id: Ib9f80eb809317483f83f79952470c2b57b2bb7c6\n(cherry picked from commit f44ed7ab3541a38d277479ea510e3bbf0373d289)\n""}]",1,689131,3b9f3694101f92965ab421cc45554edd16eca99b,8,3,1,11904,,,0,"Update python-openstacksdk references to openstacksdk

Now that the repo is renamed, update all of the references.
While we're at it, remote unused translation config.

Note: intentionally not trying to update all of the openstack>opendev
changes since then as they are not really needed in an old stable
branch.

Change-Id: Ib9f80eb809317483f83f79952470c2b57b2bb7c6
(cherry picked from commit f44ed7ab3541a38d277479ea510e3bbf0373d289)
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/31/689131/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/contributor/testing.rst', '.gitreview', 'doc/source/install/index.rst', 'SHADE-MERGE-TODO.rst', 'README.rst', 'doc/source/user/guides/clustering/receiver.rst', 'doc/source/user/guides/compute.rst', 'CONTRIBUTING.rst', 'doc/source/contributor/index.rst', 'doc/source/user/guides/clustering/profile_type.rst', 'doc/source/user/guides/clustering/action.rst', 'doc/source/user/guides/clustering/policy_type.rst', 'doc/source/user/guides/network.rst', 'doc/source/user/guides/clustering/profile.rst', 'doc/source/contributor/setup.rst', 'doc/source/user/guides/clustering/policy.rst', 'doc/source/conf.py', 'doc/source/user/guides/clustering/node.rst', 'doc/source/user/guides/clustering/event.rst', 'doc/source/user/guides/connect.rst', 'openstack/tests/ansible/hooks/post_test_hook.sh', 'doc/source/releasenotes.rst', 'doc/source/user/transition_from_profile.rst', 'setup.cfg', 'doc/source/user/guides/clustering/cluster.rst', 'doc/source/user/guides/identity.rst', 'doc/source/user/guides/image.rst', 'releasenotes/source/conf.py']",28,3b9f3694101f92965ab421cc45554edd16eca99b,,repository_name = 'openstack/openstacksdk',repository_name = 'openstack/python-openstacksdk',51,65
openstack%2Fnova~stable%2Fstein~I633faae47ad5a33b27f5e2eef6e0107f60335146,openstack/nova,stable/stein,I633faae47ad5a33b27f5e2eef6e0107f60335146,Stop sending bad values from libosinfo to libvirt,MERGED,2019-10-11 08:32:12.000000000,2019-10-17 23:20:32.000000000,2019-10-17 23:17:47.000000000,"[{'_account_id': 782}, {'_account_id': 6873}, {'_account_id': 9732}, {'_account_id': 11904}, {'_account_id': 14595}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-11 08:32:12.000000000', 'files': ['nova/virt/osinfo.py', 'nova/tests/unit/virt/test_osinfo.py', 'nova/tests/unit/virt/fakelibosinfo.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/a06922d546a26c9e6550a93cbe0718cf841b6b9f', 'message': 'Stop sending bad values from libosinfo to libvirt\n\nWhen we try to use either virtio1.0-block or virtio1.0-net it is\ncorrectly rejected by libvirt. We get these returned from libosinfo for\nnewer operating systems that support virtio1.0.\n\nAs we want to support libvirts older than 5.2.0, its best we just request\n""virtio"", please see:\nhttps://libvirt.org/formatdomain.html#elementsVirtioTransitional\n\nYou can see virtio1.0-net and virtio-block being added here:\nhttps://gitlab.com/libosinfo/osinfo-db/blob/master/data/os/fedoraproject.org/fedora-23.xml.in#L31\n\nChange-Id: I633faae47ad5a33b27f5e2eef6e0107f60335146\nCloses-Bug: #1835400\n(cherry picked from commit 6be668e51992df53a4d871bea70bc738a9beacb8)\n'}]",0,688067,a06922d546a26c9e6550a93cbe0718cf841b6b9f,13,8,1,10135,,,0,"Stop sending bad values from libosinfo to libvirt

When we try to use either virtio1.0-block or virtio1.0-net it is
correctly rejected by libvirt. We get these returned from libosinfo for
newer operating systems that support virtio1.0.

As we want to support libvirts older than 5.2.0, its best we just request
""virtio"", please see:
https://libvirt.org/formatdomain.html#elementsVirtioTransitional

You can see virtio1.0-net and virtio-block being added here:
https://gitlab.com/libosinfo/osinfo-db/blob/master/data/os/fedoraproject.org/fedora-23.xml.in#L31

Change-Id: I633faae47ad5a33b27f5e2eef6e0107f60335146
Closes-Bug: #1835400
(cherry picked from commit 6be668e51992df53a4d871bea70bc738a9beacb8)
",git fetch https://review.opendev.org/openstack/nova refs/changes/67/688067/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/osinfo.py', 'nova/tests/unit/virt/test_osinfo.py', 'nova/tests/unit/virt/fakelibosinfo.py']",3,a06922d546a26c9e6550a93cbe0718cf841b6b9f,bug/1835400," def _get_fedora19(self): devs = [] net = Device() net._class = 'net' net.name = 'rtl8139' devs.append(net) net._class = 'block' net.name = 'ide' devs.append(net) devlist = DeviceList() devlist.devices = devs fedora = Os() fedora.name = 'Fedora 19' fedora.id = 'http://fedoraproject.org/fedora/19' fedora.short_id = 'fedora19' fedora.dev_list = devlist return fedora def _get_fedora22(self): devs = [] net = Device() devs.append(net) devs.append(net) devlist.devices = devs return fedora def _get_fedora23(self): devs = [] net = Device() net._class = 'net' net.name = 'virtio1.0-net' devs.append(net) net = Device() net._class = 'block' net.name = 'virtio1.0-block' devs.append(net) devlist = DeviceList() devlist.devices = devs fedora = Os() fedora.name = 'Fedora 23' fedora.id = 'http://fedoraproject.org/fedora/23' fedora.short_id = 'fedora23' fedora.dev_list = devlist return fedora def __init__(self): self.oslist.os_list = [ self._get_fedora19(), self._get_fedora22(), self._get_fedora23(), ]", def __init__(self): # Generate test devices self.devs = [] self.oslist = None self.devs.append(net) self.devs.append(net) devlist.devices = self.devs self.oslist.os_list = [fedora],99,17
openstack%2Fnova~stable%2Fqueens~Ie9e294db7e24d0e3cbe83eee847f0fbfb7478900,openstack/nova,stable/queens,Ie9e294db7e24d0e3cbe83eee847f0fbfb7478900,Add functional recreate test for regression bug 1825537,MERGED,2019-08-08 14:37:01.000000000,2019-10-17 23:17:52.000000000,2019-10-17 23:17:52.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-08-08 14:37:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a3f6df54f9ae537df2d3b8af11dd6c5ff51ccca8', 'message': ""Add functional recreate test for regression bug 1825537\n\nChange I2d9ab06b485f76550dbbff46f79f40ff4c97d12f in Rocky\n(and backported through to Pike) added error handling to\nthe resize_instance and finish_resize methods to revert\nallocations in placement when a failure occurs.\n\nThis is OK for resize_instance, which runs on the source\ncompute, as long as the instance.host/node values have not\nyet been changed to the dest host/node before RPC casting\nto the finish_resize method on the dest compute. It's OK\nbecause the instance is still on the source compute and the\nDB says so, so any attempt to recover the instance via hard\nreboot or rebuild will be on the source host.\n\nThis is not OK for finish_resize because if we fail there\nand revert the allocations, the instance host/node values\nare already pointing at the dest compute and by reverting\nthe allocations in placement, placement will be incorrectly\ntracking the instance usage with the old flavor against the\nsource node resource provider rather than the new flavor\nagainst the dest node resource provider - where the instance\nis actually running and the nova DB says the instance lives.\n\nThis change adds a simple functional regression test to\nrecreate the bug with a multi-host resize. There is already\na same-host resize functional test marked here which will\nneed to be fixed as well.\n\nChange-Id: Ie9e294db7e24d0e3cbe83eee847f0fbfb7478900\nRelated-Bug: #1825537\n(cherry picked from commit f4bb67210602914e1b9a678419cf22cfbeaf1431)\n(cherry picked from commit eaa1fc6159ca4437a1e0cbaa77a3da779afb8cb2)\n(cherry picked from commit 9a977cb28c1c4f2e8d950476fa373326f636dfd6)\n""}, {'number': 2, 'created': '2019-08-08 22:48:33.000000000', 'files': ['nova/virt/fake.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/regressions/test_bug_1825537.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1bb555c4c981d33de03cf70dfd73cc391d36cb89', 'message': ""Add functional recreate test for regression bug 1825537\n\nChange I2d9ab06b485f76550dbbff46f79f40ff4c97d12f in Rocky\n(and backported through to Pike) added error handling to\nthe resize_instance and finish_resize methods to revert\nallocations in placement when a failure occurs.\n\nThis is OK for resize_instance, which runs on the source\ncompute, as long as the instance.host/node values have not\nyet been changed to the dest host/node before RPC casting\nto the finish_resize method on the dest compute. It's OK\nbecause the instance is still on the source compute and the\nDB says so, so any attempt to recover the instance via hard\nreboot or rebuild will be on the source host.\n\nThis is not OK for finish_resize because if we fail there\nand revert the allocations, the instance host/node values\nare already pointing at the dest compute and by reverting\nthe allocations in placement, placement will be incorrectly\ntracking the instance usage with the old flavor against the\nsource node resource provider rather than the new flavor\nagainst the dest node resource provider - where the instance\nis actually running and the nova DB says the instance lives.\n\nThis change adds a simple functional regression test to\nrecreate the bug with a multi-host resize. There is already\na same-host resize functional test marked here which will\nneed to be fixed as well.\n\nNOTE(mriedem): The import in the test is changed because\nIa69fabce8e7fd7de101e291fe133c6f5f5f7056a is not in Queens.\n\nChange-Id: Ie9e294db7e24d0e3cbe83eee847f0fbfb7478900\nRelated-Bug: #1825537\n(cherry picked from commit f4bb67210602914e1b9a678419cf22cfbeaf1431)\n(cherry picked from commit eaa1fc6159ca4437a1e0cbaa77a3da779afb8cb2)\n(cherry picked from commit 9a977cb28c1c4f2e8d950476fa373326f636dfd6)\n""}]",5,675355,1bb555c4c981d33de03cf70dfd73cc391d36cb89,20,8,2,6873,,,0,"Add functional recreate test for regression bug 1825537

Change I2d9ab06b485f76550dbbff46f79f40ff4c97d12f in Rocky
(and backported through to Pike) added error handling to
the resize_instance and finish_resize methods to revert
allocations in placement when a failure occurs.

This is OK for resize_instance, which runs on the source
compute, as long as the instance.host/node values have not
yet been changed to the dest host/node before RPC casting
to the finish_resize method on the dest compute. It's OK
because the instance is still on the source compute and the
DB says so, so any attempt to recover the instance via hard
reboot or rebuild will be on the source host.

This is not OK for finish_resize because if we fail there
and revert the allocations, the instance host/node values
are already pointing at the dest compute and by reverting
the allocations in placement, placement will be incorrectly
tracking the instance usage with the old flavor against the
source node resource provider rather than the new flavor
against the dest node resource provider - where the instance
is actually running and the nova DB says the instance lives.

This change adds a simple functional regression test to
recreate the bug with a multi-host resize. There is already
a same-host resize functional test marked here which will
need to be fixed as well.

NOTE(mriedem): The import in the test is changed because
Ia69fabce8e7fd7de101e291fe133c6f5f5f7056a is not in Queens.

Change-Id: Ie9e294db7e24d0e3cbe83eee847f0fbfb7478900
Related-Bug: #1825537
(cherry picked from commit f4bb67210602914e1b9a678419cf22cfbeaf1431)
(cherry picked from commit eaa1fc6159ca4437a1e0cbaa77a3da779afb8cb2)
(cherry picked from commit 9a977cb28c1c4f2e8d950476fa373326f636dfd6)
",git fetch https://review.opendev.org/openstack/nova refs/changes/55/675355/2 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/fake.py', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/regressions/test_bug_1825537.py']",3,a3f6df54f9ae537df2d3b8af11dd6c5ff51ccca8,bug/1825537,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.tests.functional import integrated_helpers class FinishResizeErrorAllocationCleanupTestCase( integrated_helpers.ProviderUsageBaseTestCase): """"""Test for bug 1825537 introduced in Rocky and backported down to Pike. Tests a scenario where finish_resize fails on the dest compute during a resize and ensures resource provider allocations are properly cleaned up in placement. """""" compute_driver = 'fake.FakeFinishMigrationFailDriver' def setUp(self): super(FinishResizeErrorAllocationCleanupTestCase, self).setUp() # Get the flavors we're going to use. flavors = self.api.get_flavors() self.flavor1 = flavors[0] self.flavor2 = flavors[1] def _resize_and_assert_error(self, server, dest_host): # Now resize the server and wait for it to go to ERROR status because # the finish_migration virt driver method in host2 should fail. req = {'resize': {'flavorRef': self.flavor2['id']}} self.api.post_server_action(server['id'], req) # The instance is set to ERROR status before the fault is recorded so # to avoid a race we need to wait for the task_state to change # to None which happens after the fault is recorded. server = self._wait_for_server_parameter( self.admin_api, server, {'status': 'ERROR', 'OS-EXT-STS:task_state': None}) # The server should be pointing at $dest_host because resize_instance # will have updated the host/node value on the instance before casting # to the finish_resize method on the dest compute. self.assertEqual(dest_host, server['OS-EXT-SRV-ATTR:host']) # In this case the FakeFinishMigrationFailDriver.finish_migration # method raises VirtualInterfaceCreateException. self.assertIn('Virtual Interface creation failed', server['fault']['message']) def test_finish_resize_fails_allocation_cleanup(self): # Start two computes so we can resize across hosts. self._start_compute('host1') self._start_compute('host2') # Create a server on host1. server = self._boot_and_check_allocations(self.flavor1, 'host1') # Resize to host2 which should fail. self._resize_and_assert_error(server, 'host2') # Check the resource provider allocations. Since the server is pointed # at the dest host in the DB now, the dest node resource provider # allocations should still exist with the new flavor. source_rp_uuid = self._get_provider_uuid_by_host('host1') dest_rp_uuid = self._get_provider_uuid_by_host('host2') # FIXME(mriedem): This is bug 1825537 where the allocations are # reverted when finish_resize fails so the dest node resource provider # does not have any allocations and the instance allocations are for # the old flavor on the source node resource provider even though the # instance is not running on the source host nor pointed at the source # host in the DB. # self.assertFlavorMatchesAllocation( # self.flavor2, server['id'], dest_rp_uuid) dest_rp_usages = self._get_provider_usages(dest_rp_uuid) no_usage = {'VCPU': 0, 'MEMORY_MB': 0, 'DISK_GB': 0} self.assertEqual(no_usage, dest_rp_usages) source_usages = self._get_provider_usages(source_rp_uuid) self.assertFlavorMatchesAllocation(self.flavor1, source_usages) ",,90,0
openstack%2Freleases~master~I7b1f7579676fe4c9f2f3ab43eb8b595ea0aa98bf,openstack/releases,master,I7b1f7579676fe4c9f2f3ab43eb8b595ea0aa98bf,Release sushy 1.10.0 from during Train,ABANDONED,2019-10-14 19:58:51.000000000,2019-10-17 23:09:11.000000000,,"[{'_account_id': 7160}, {'_account_id': 10239}, {'_account_id': 10250}, {'_account_id': 10379}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 23847}, {'_account_id': 26340}]","[{'number': 1, 'created': '2019-10-14 19:58:51.000000000', 'files': ['deliverables/train/sushy.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/fcfe78c75324a9a8817f2fe6af7270bb0dcf891b', 'message': 'Release sushy 1.10.0 from during Train\n\nSushy released 1.9.0 and ultimately 2.0.0 after making a backwards\nincompatible change in terms of the OEM interface.\n\nIn between those changes, a fix for incomplete message registries\nmerged. This change is needed in a 1.x release as version pins may\nhave not been changed, and sushy was found to be incompatible with\ncertian Redfish APIs with incomplete message registries. As such,\nan intermediate 1.10.0 release is needed, marked as it does\ncontain some newer functionality, but not the later breaking change.\n\nMore information can be found in the openstack/ironic[0]\ndriver-requirements.txt change as well as the IRC logs[1].\n\n[0]: https://review.opendev.org/#/c/687983\n[1]: http://eavesdrop.openstack.org/irclogs/%23openstack-ironic/%23openstack-ironic.2019-10-10.log.html#t2019-10-10T20:42:00\n\nChange-Id: I7b1f7579676fe4c9f2f3ab43eb8b595ea0aa98bf\n'}]",5,688551,fcfe78c75324a9a8817f2fe6af7270bb0dcf891b,8,10,1,11655,,,0,"Release sushy 1.10.0 from during Train

Sushy released 1.9.0 and ultimately 2.0.0 after making a backwards
incompatible change in terms of the OEM interface.

In between those changes, a fix for incomplete message registries
merged. This change is needed in a 1.x release as version pins may
have not been changed, and sushy was found to be incompatible with
certian Redfish APIs with incomplete message registries. As such,
an intermediate 1.10.0 release is needed, marked as it does
contain some newer functionality, but not the later breaking change.

More information can be found in the openstack/ironic[0]
driver-requirements.txt change as well as the IRC logs[1].

[0]: https://review.opendev.org/#/c/687983
[1]: http://eavesdrop.openstack.org/irclogs/%23openstack-ironic/%23openstack-ironic.2019-10-10.log.html#t2019-10-10T20:42:00

Change-Id: I7b1f7579676fe4c9f2f3ab43eb8b595ea0aa98bf
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/688551/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/sushy.yaml'],1,fcfe78c75324a9a8817f2fe6af7270bb0dcf891b,, - projects: - hash: d479b46ec95dc588da7f45d4b4ec044acaa80669 repo: openstack/sushy version: 1.10.0,,4,0
openstack%2Foslo.concurrency~master~Ia04d1de7e10783350e3aa091eab64d1cbd7f070a,openstack/oslo.concurrency,master,Ia04d1de7e10783350e3aa091eab64d1cbd7f070a,Bump the openstackdocstheme extension to 1.20,MERGED,2019-10-12 06:46:20.000000000,2019-10-17 23:07:57.000000000,2019-10-17 23:06:39.000000000,"[{'_account_id': 708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 06:46:20.000000000', 'files': ['doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/a052a044bc28d5ea2e2f02c496009d06c9ab941f', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: Ia04d1de7e10783350e3aa091eab64d1cbd7f070a\n'}]",0,688238,a052a044bc28d5ea2e2f02c496009d06c9ab941f,9,2,1,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: Ia04d1de7e10783350e3aa091eab64d1cbd7f070a
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/38/688238/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'lower-constraints.txt', 'doc/requirements.txt', 'releasenotes/source/conf.py']",4,a052a044bc28d5ea2e2f02c496009d06c9ab941f,openstackdocstheme,,"html_last_updated_fmt = '%Y-%m-%d %H:%M'project = u'oslo.concurrency Release Notes'latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } ",2,16
openstack%2Fopenstacksdk~stable%2Ftrain~Id1720774bc0f6f398d0739a466c7bd5c54182642,openstack/openstacksdk,stable/train,Id1720774bc0f6f398d0739a466c7bd5c54182642,Fix server for later microversion,MERGED,2019-10-04 12:57:40.000000000,2019-10-17 22:35:20.000000000,2019-10-17 22:34:08.000000000,"[{'_account_id': 2}, {'_account_id': 22348}, {'_account_id': 27900}]","[{'number': 1, 'created': '2019-10-04 12:57:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/c0256d66758385871061342beb89806b109eb628', 'message': ""Fix server for later microversion\n\nWe updated the server record for 2.72 but missed some bits of inventory\nbecause we weren't actually gettting 2.72. Whoops.\n\nWe need to clean the policy/policies fields in ServerGroup because\notherwise they're considered dirty and None values are sent.\n\nChange-Id: Id1720774bc0f6f398d0739a466c7bd5c54182642\n""}, {'number': 2, 'created': '2019-10-05 07:17:18.000000000', 'files': ['openstack/tests/functional/cloud/test_inventory.py', 'openstack/compute/v2/server_group.py', 'releasenotes/notes/fix-for-microversion-70cd686b6d6e3fd0.yaml', 'openstack/cloud/meta.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/7d53fb8322b00216371b682fb1c46ca46ec24e5f', 'message': ""Fix server for later microversion\n\nWe updated the server record for 2.72 but missed some bits of inventory\nbecause we weren't actually gettting 2.72. Whoops.\n\nWe need to clean the policy/policies fields in ServerGroup because\notherwise they're considered dirty and None values are sent.\n\nChange-Id: Id1720774bc0f6f398d0739a466c7bd5c54182642\n""}]",0,686600,7d53fb8322b00216371b682fb1c46ca46ec24e5f,12,3,2,2,,,0,"Fix server for later microversion

We updated the server record for 2.72 but missed some bits of inventory
because we weren't actually gettting 2.72. Whoops.

We need to clean the policy/policies fields in ServerGroup because
otherwise they're considered dirty and None values are sent.

Change-Id: Id1720774bc0f6f398d0739a466c7bd5c54182642
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/00/686600/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack/tests/functional/cloud/test_inventory.py', 'openstack/compute/v2/server_group.py', 'releasenotes/notes/fix-for-microversion-70cd686b6d6e3fd0.yaml', 'openstack/cloud/meta.py']",4,c0256d66758385871061342beb89806b109eb628,fix-auth-discovery," flavor_id = server['flavor'].get('id') if flavor_id: # In newer nova, the flavor record can be kept around for flavors # that no longer exist. The id and name are not there. flavor_name = cloud.get_flavor_name(flavor_id) if flavor_name: server_vars['flavor']['name'] = flavor_name", flavor_id = server['flavor']['id'] flavor_name = cloud.get_flavor_name(flavor_id) if flavor_name: server_vars['flavor']['name'] = flavor_name,18,9
openstack%2Ftripleo-heat-templates~master~Iac6efde9dd283906274d95c3a239b4b882ec052e,openstack/tripleo-heat-templates,master,Iac6efde9dd283906274d95c3a239b4b882ec052e,Undercloud hosts entries in overcloud nodes,MERGED,2019-10-08 16:16:08.000000000,2019-10-17 22:27:44.000000000,2019-10-17 21:29:25.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-10-08 16:16:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5204cc3831851c2e2d4ea544f804e5c7689b2aa0', 'message': ""Undercloud hosts entries in overcloud nodes\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding hosts entries\nfor the undercloud a name can be used instead of the IPv6\naddress.\n\nThe parameter 'UndercloudHostsEntries' is populated with\nentries from the HEAT_HOSTS section of /etc/hosts on the\nundercloud.\n\nRelated-Bug: #1836578\nDepends-On: Id9271460b20e602f935f1eddd70f989cd605b1f4\nChange-Id: Iac6efde9dd283906274d95c3a239b4b882ec052e\n""}, {'number': 2, 'created': '2019-10-08 23:11:13.000000000', 'files': ['overcloud.j2.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/97f388a00e4c83dbae988bef3238ebae2728f703', 'message': ""Undercloud hosts entries in overcloud nodes\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding hosts entries\nfor the undercloud a name can be used instead of the IPv6\naddress.\n\nThe parameter 'UndercloudHostsEntries' is populated with\nentries from the HEAT_HOSTS section of /etc/hosts on the\nundercloud.\n\nRelated-Bug: #1836578\nDepends-On: Id9271460b20e602f935f1eddd70f989cd605b1f4\nChange-Id: Iac6efde9dd283906274d95c3a239b4b882ec052e\n""}]",0,687349,97f388a00e4c83dbae988bef3238ebae2728f703,21,5,2,24245,,,0,"Undercloud hosts entries in overcloud nodes

With IPv6 the overcloud nodes cannot pull images from the
undercloud using an IPv6 address. By adding hosts entries
for the undercloud a name can be used instead of the IPv6
address.

The parameter 'UndercloudHostsEntries' is populated with
entries from the HEAT_HOSTS section of /etc/hosts on the
undercloud.

Related-Bug: #1836578
Depends-On: Id9271460b20e602f935f1eddd70f989cd605b1f4
Change-Id: Iac6efde9dd283906274d95c3a239b4b882ec052e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/49/687349/2 && git format-patch -1 --stdout FETCH_HEAD,['overcloud.j2.yaml'],1,5204cc3831851c2e2d4ea544f804e5c7689b2aa0,bug/1836578, UndercloudHostsEntries: default: [] description: > List of undercloud hosts entries to be appended to /etc/hosts. The value is populated with the HEAT_HOSTS entries on the undercloud by tripleoclient when running deploy. type: comma_delimited_list - {get_param: UndercloudHostsEntries},,8,0
openstack%2Fopenstack-helm-infra~master~Icce660415d43baefbbf768a785c5dedf04ea2930,openstack/openstack-helm-infra,master,Icce660415d43baefbbf768a785c5dedf04ea2930,Allow multiple containers per daemonset pod,MERGED,2019-03-22 23:18:09.000000000,2019-10-17 21:41:27.000000000,2019-10-17 21:39:11.000000000,"[{'_account_id': 8898}, {'_account_id': 19124}, {'_account_id': 20466}, {'_account_id': 21428}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 30118}]","[{'number': 1, 'created': '2019-03-22 23:18:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ca30319f418cd39db5ecf44cce5fb5fe39c458e', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}, {'number': 2, 'created': '2019-04-07 06:49:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6c57a312cb33188cdb9e4083659b35bd9d8a4f0b', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}, {'number': 3, 'created': '2019-04-08 16:08:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/735b546805f3887e4a3a254c8136612a50d55701', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}, {'number': 4, 'created': '2019-07-29 20:41:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3a7913ace7c019321d312f737caa2e95b034f4b0', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}, {'number': 5, 'created': '2019-10-16 19:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/411d3cf173d9f75f19da2d324ae3a1d47be3e799', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}, {'number': 6, 'created': '2019-10-17 14:31:08.000000000', 'files': ['helm-toolkit/templates/utils/_daemonset_overrides.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5b32e6e30974c4ed87aa0e7a729607f6731b4259', 'message': 'Allow multiple containers per daemonset pod\n\nRemove code that restricted daemonset pods to single containers.\nContainer names will default to name from helm chart template.\nRequired for nova cold migrations to work.\n\nStory: 2003876\nTask: 26735\nChange-Id: Icce660415d43baefbbf768a785c5dedf04ea2930\nSigned-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>\n'}]",0,645958,5b32e6e30974c4ed87aa0e7a729607f6731b4259,33,7,6,19124,,,0,"Allow multiple containers per daemonset pod

Remove code that restricted daemonset pods to single containers.
Container names will default to name from helm chart template.
Required for nova cold migrations to work.

Story: 2003876
Task: 26735
Change-Id: Icce660415d43baefbbf768a785c5dedf04ea2930
Signed-off-by: Gerry Kopec <Gerry.Kopec@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/58/645958/4 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/utils/_daemonset_overrides.tpl'],1,7ca30319f418cd39db5ecf44cce5fb5fe39c458e,helm_nova_cold_migration,," {{/* set container name assume not more than one container is defined */}} {{- $container := first $context.Values.__daemonset_yaml.spec.template.spec.containers }} {{- $_ := set $container ""name"" $current_dict.dns_1123_name }} {{- $cont_list := list $container }} {{- $_ := set $context.Values.__daemonset_yaml.spec.template.spec ""containers"" $cont_list }} ",0,7
openstack%2Fcharm-keystone~master~I11ed4688b41014ec53a6d57b0032d927f6e4d5a0,openstack/charm-keystone,master,I11ed4688b41014ec53a6d57b0032d927f6e4d5a0,test gerrit,ABANDONED,2019-10-17 21:40:02.000000000,2019-10-17 21:41:05.000000000,,[{'_account_id': 10068}],"[{'number': 1, 'created': '2019-10-17 21:40:02.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/3526b4de9b168a56143a6aae24a29de7dca0c463', 'message': 'test gerrit\n\nChange-Id: I11ed4688b41014ec53a6d57b0032d927f6e4d5a0\nSigned-off-by: Xiyue Wang <celia.wang@canonical.com>\n'}]",0,689277,3526b4de9b168a56143a6aae24a29de7dca0c463,3,1,1,31107,,,0,"test gerrit

Change-Id: I11ed4688b41014ec53a6d57b0032d927f6e4d5a0
Signed-off-by: Xiyue Wang <celia.wang@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/77/689277/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,3526b4de9b168a56143a6aae24a29de7dca0c463,test-gerrit,test-gerrit,,1,0
openstack%2Fopenstack-helm-infra~master~I4ece5c71df18c21f0cdff536140f63881ff24e30,openstack/openstack-helm-infra,master,I4ece5c71df18c21f0cdff536140f63881ff24e30,Update Grafana Helm test to use python3,MERGED,2019-10-14 15:07:12.000000000,2019-10-17 21:40:24.000000000,2019-10-17 21:39:09.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 28618}, {'_account_id': 28849}, {'_account_id': 30692}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-14 15:07:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f56ad9e2341831268744d77b7954f99bf3f711d5', 'message': '[WIP] Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 2, 'created': '2019-10-14 15:59:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/60f849a10c14bbaa35e6464a364500808dfae359', 'message': '[WIP] Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 3, 'created': '2019-10-14 16:36:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/98121fb26452d4690fe07be385495b530d29d734', 'message': '[WIP] Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 4, 'created': '2019-10-14 17:29:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ca2830bb5f5ee46cdb4eb50c9243a201d47a40b', 'message': '[WIP] Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 5, 'created': '2019-10-14 19:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8366730046a8aeddb7030492986526d3b5541965', 'message': '[WIP] Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 6, 'created': '2019-10-15 14:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eae2b63e9df23c27ca89c56f2ed3f43bd4cd6491', 'message': 'Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 7, 'created': '2019-10-16 14:42:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/da93ec0af2b22bbb1c9494e26f72a886bd19b0a9', 'message': '[WIP] Update Grafana Helm test to use python3\n\nTagged as WIP while osh-selenium image change is not official\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}, {'number': 8, 'created': '2019-10-17 16:39:51.000000000', 'files': ['grafana/values.yaml', 'grafana/templates/bin/_selenium-tests.py.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/998885c33065193f4279c0a736a535d5dbbf58ec', 'message': 'Update Grafana Helm test to use python3\n\nThis change updates the selenium_tests container image\nto one which installs python3.\n\nThe selenium-test.py template file has been refactored\nto match the structure of the selenium tests in\n/tools/gate/selenium\n\nDepends on: https://review.opendev.org/688436\nChange-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30\n'}]",7,688422,998885c33065193f4279c0a736a535d5dbbf58ec,29,7,8,30777,,,0,"Update Grafana Helm test to use python3

This change updates the selenium_tests container image
to one which installs python3.

The selenium-test.py template file has been refactored
to match the structure of the selenium tests in
/tools/gate/selenium

Depends on: https://review.opendev.org/688436
Change-Id: I4ece5c71df18c21f0cdff536140f63881ff24e30
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/22/688422/7 && git format-patch -1 --stdout FETCH_HEAD,"['grafana/values.yaml', 'grafana/templates/bin/_selenium-tests.py.tpl']",2,f56ad9e2341831268744d77b7954f99bf3f711d5,grafana-selenium-py3,"from selenium.common.exceptions import TimeoutException from selenium.common.exceptions import NoSuchElementExceptionformatter = logging.Formatter( '%(asctime)s - %(name)s - %(levelname)s - %(message)s' )def get_variable(env_var): if env_var in os.environ: logger.info('Found ""{}""'.format(env_var)) return os.environ[env_var] else: logger.critical('Variable ""{}"" is not defined!'.format(env_var)) sys.exit(1) username = get_variable('GRAFANA_USER') password = get_variable('GRAFANA_PASSWORD') grafana_uri = get_variable('GRAFANA_URI') chrome_driver = '/etc/selenium/chromedriver'browser = webdriver.Chrome(chrome_driver, chrome_options=options) browser.get(grafana_uri) el = WebDriverWait(browser, 15).until( EC.title_contains('Grafana') ) logger.info('Connected to Grafana') except TimeoutException: logger.critical('Timed out waiting for Grafana') browser.quit() sys.exit(1) browser.find_element_by_name('username').send_keys(grafana_user) browser.find_element_by_name('password').send_keys(grafana_password) browser.find_element_by_css_selector( 'body > grafana-app > div.main-view > div > div:nth-child(1) > div > ' 'div > div.login-inner-box > form > div.login-button-group > button' ).click() logger.info(""Successfully logged in to Grafana"") except NoSuchElementException: logger.error(""Failed to log in to Grafana"") browser.quit() sys.exit(1) browser.quit()","formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')# Get Grafana admin user name if ""GRAFANA_USER"" in os.environ: grafana_user = os.environ['GRAFANA_USER'] logger.info('Found Grafana username') else: logger.critical('Grafana username environment variable not set') sys.exit(1) if ""GRAFANA_PASSWORD"" in os.environ: grafana_password = os.environ['GRAFANA_PASSWORD'] logger.info('Found Grafana password') else: logger.critical('Grafana password environment variable not set') sys.exit(1) if ""GRAFANA_URI"" in os.environ: grafana_uri = os.environ['GRAFANA_URI'] logger.info('Found Grafana URI') else: logger.critical('Grafana URI environment variable not set') sys.exit(1) browser = webdriver.Chrome('/etc/selenium/chromedriver', chrome_options=options) logger.info(""Successfully opened Grafana dashboard"") except Exception as e: logger.error(""Unable to open Grafana"") browser.close() sys.exit(1) browser.get(grafana_uri) browser.find_element_by_name('username').send_keys(grafana_user) browser.find_element_by_name('password').send_keys(grafana_password) browser.find_element_by_css_selector('body > grafana-app > div.main-view > div > div:nth-child(1) > div > div > div.login-inner-box > form > div.login-button-group > button').click() logger.info(""Successfully logged in to Grafana"") except Exception as e: logger.error(""Failed to log in to Grafana"") browser.close() sys.exit(1) browser.close()",39,38
openstack%2Fironic~master~I8b0f69d13420fa0a3fc21f044ed2bba6a540e638,openstack/ironic,master,I8b0f69d13420fa0a3fc21f044ed2bba6a540e638,Fix drive sensors collection in `redfish` mgmt interface,MERGED,2019-09-27 16:22:47.000000000,2019-10-17 21:37:00.000000000,2019-10-14 18:28:18.000000000,"[{'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10379}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 26340}]","[{'number': 1, 'created': '2019-09-27 16:22:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/f6b4015d4c14b56dc4600e0135985e6e02bd2149', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}, {'number': 2, 'created': '2019-09-30 11:27:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/834f73d2e5cbb20623ecdb0a6d700d95b3ae15b3', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}, {'number': 3, 'created': '2019-09-30 13:15:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06cc0fd4695660590e009fec0431775b20a3f109', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}, {'number': 4, 'created': '2019-09-30 15:58:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8b1aac83a5aa24108c96420549eaccffa70a601d', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}, {'number': 5, 'created': '2019-10-09 13:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/57271d9e64152f15f6b49045a189b112c2eeea4a', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}, {'number': 6, 'created': '2019-10-14 14:55:31.000000000', 'files': ['ironic/drivers/modules/redfish/management.py', 'ironic/tests/unit/drivers/modules/redfish/test_management.py', 'releasenotes/notes/fix-sensors-storage-ed5d5bbda9b46645.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/a2ae57c457962e6fa5e590c0de19f4d457637881', 'message': 'Fix drive sensors collection in `redfish` mgmt interface\n\nFixes drive sensors information collection in `redfish` management\ninterface. Prior to this fix, wrong Redfish schema has been used for\nDrive resource what has been causing exception and ultimately sensor\ndata collection failure.\n\nChange-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638\n'}]",0,685398,a2ae57c457962e6fa5e590c0de19f4d457637881,38,9,6,26340,,,0,"Fix drive sensors collection in `redfish` mgmt interface

Fixes drive sensors information collection in `redfish` management
interface. Prior to this fix, wrong Redfish schema has been used for
Drive resource what has been causing exception and ultimately sensor
data collection failure.

Change-Id: I8b0f69d13420fa0a3fc21f044ed2bba6a540e638
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/685398/4 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/redfish/management.py', 'ironic/tests/unit/drivers/modules/redfish/test_management.py', 'releasenotes/notes/fix-sensors-storage-ed5d5bbda9b46645.yaml']",3,f6b4015d4c14b56dc4600e0135985e6e02bd2149,03-fix-sensors-drive,"--- fixes: - | Fixes drive sensors information collection in ``redfish`` management interface. Prior to this fix, wrong Redfish schema has been used for Drive resource what has been causing exception and ultimately sensor data collection failure. ",,13,8
openstack%2Fironic-specs~master~Ie05553ad638b2729e080590e77c95cd73b2c0921,openstack/ironic-specs,master,Ie05553ad638b2729e080590e77c95cd73b2c0921,Update collect-logs-from-agent-ramdisk spec,ABANDONED,2016-10-10 12:27:19.000000000,2019-10-17 21:34:38.000000000,,"[{'_account_id': 3}, {'_account_id': 7711}, {'_account_id': 10342}, {'_account_id': 13295}, {'_account_id': 14614}]","[{'number': 1, 'created': '2016-10-10 12:27:19.000000000', 'files': ['specs/approved/collect-logs-from-agent-ramdisk.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4789face7541109daff4d556bd85f91579d70545', 'message': 'Update collect-logs-from-agent-ramdisk spec\n\nThis patch update security impact section for\ncollect-logs-from-agent-ramdisk.\n\nChange-Id: Ie05553ad638b2729e080590e77c95cd73b2c0921\n'}]",0,384470,4789face7541109daff4d556bd85f91579d70545,8,5,1,14525,,,0,"Update collect-logs-from-agent-ramdisk spec

This patch update security impact section for
collect-logs-from-agent-ramdisk.

Change-Id: Ie05553ad638b2729e080590e77c95cd73b2c0921
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/70/384470/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/collect-logs-from-agent-ramdisk.rst'],1,4789face7541109daff4d556bd85f91579d70545,(HEAD,Syslog port should be opened between ramdisk and conductor/logging server node.,None.,1,1
openstack%2Fironic-specs~master~Iccd7d4c967c3c3fd164b9137577f49314e3d7e35,openstack/ironic-specs,master,Iccd7d4c967c3c3fd164b9137577f49314e3d7e35,Add System Event Log support to management interface,ABANDONED,2015-11-18 14:52:40.000000000,2019-10-17 21:33:55.000000000,,"[{'_account_id': 3}, {'_account_id': 6618}, {'_account_id': 6773}, {'_account_id': 7711}, {'_account_id': 10239}, {'_account_id': 10342}, {'_account_id': 11655}, {'_account_id': 12356}, {'_account_id': 14614}]","[{'number': 1, 'created': '2015-11-18 14:52:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/7e25a6fac6c74f9fd9cede8b4e02ca8ef660812e', 'message': 'Add System Event Log support to management interface\n\nThis spec proposes extend driver management interface, add System\nEvent Log support.\n\nChange-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35\n'}, {'number': 2, 'created': '2015-11-19 09:51:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/6587121e3ad15bb382cacffd18d69ffc64e983c5', 'message': 'Add System Event Log support to management interface\n\nThis spec proposes extend driver management interface, add System\nEvent Log support.\n\nChange-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35\n'}, {'number': 3, 'created': '2015-11-24 11:31:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/4369c558207b59f94c59e33ef0c847b93d158b84', 'message': 'Add System Event Log support to management interface\n\nThis spec proposes extend driver management interface, add System\nEvent Log support.\n\nChange-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35\n'}, {'number': 4, 'created': '2016-02-03 10:21:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/eb0eb57deb27bfaa510ada448ccdc912fb52f973', 'message': 'Add System Event Log support to management interface\n\nThis spec proposes extend driver management interface, add System\nEvent Log support.\n\nRelated-bug: #1526478\nChange-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35\n'}, {'number': 5, 'created': '2016-02-08 14:12:20.000000000', 'files': ['specs/approved/ironic-system-logs.rst', 'specs/not-implemented/ironic-system-logs.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/08d39de7407ba35c75799618b905274a135d15f4', 'message': 'Add System Event Log support to management interface\n\nThis spec proposes extend driver management interface, add System\nEvent Log support.\n\nRelated-bug: #1526478\nChange-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35\n'}]",22,246965,08d39de7407ba35c75799618b905274a135d15f4,31,9,5,7711,,,0,"Add System Event Log support to management interface

This spec proposes extend driver management interface, add System
Event Log support.

Related-bug: #1526478
Change-Id: Iccd7d4c967c3c3fd164b9137577f49314e3d7e35
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/65/246965/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/approved/ironic-system-logs.rst'],1,7e25a6fac6c74f9fd9cede8b4e02ca8ef660812e,bug/1526478,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode ============================================================ Extend driver management interface with system logs support ============================================================ https://blueprints.launchpad.net/ironic/+spec/ironic-system-logs This spec proposes extend driver management interface, add methods for System Event Log (SEL) support. Problem description =================== System Event Log (SEL) is a non-volatile storage area and associated interfaces for storing system platform event information. There are different standards for dealing with SEL. Most known is IPMI [#]_, other examples are Dell management profile [#]_ and support in Intel AMT [#]_. Usage of SEL in mixed hardware environment is a hard task, because operator should know a method for log retrieving for each type of hardware. This spec proposes a standard way for SEL usage via Ironic. Proposed change =============== * Extend Ironic driver management interface for SEL support, details described in ``Driver API impact`` section. * Create new REST API endpoints for operate with SEL (also requires RPC API changes). * Implement new management methods for ``IPMIManagement`` interface. Alternatives ------------ Usage of ``ipmitool`` and vendors' tools for SEL. Data model impact ----------------- None State Machine Impact -------------------- None. REST API impact --------------- New REST API endpoints will be added: - To get SEL log from a node:: GET /v1/nodes/<UUID>/system_log Optional parameter ``length`` (return only last ``length`` lines). Returns JSON { ""system_log"": ""log_content"" } - To clean SEL:: DELETE /v1/nodes/<UUID>/system_log Client (CLI) impact ------------------- New options should be added for SEL: $ ironic node-get-system-log [--lines number] <node-uuid> $ ironic node-clean-system-log <node-uuid> RPC API impact -------------- New RPC API methods will be created: * ``get_system_log`` - get SEL data. * ``clean_system_log`` - clean SEL. These methods are linked to driver API method below. Driver API impact ----------------- New methods should be added to Ironic base ``class ManagementInterface``:: def get_system_log(task, length=None): """"""Get System Event Log. :param task: a task from TaskManager. :param length: integer, the number of lines from tail to return. :returns: a string with System Event Log content in human-readable form. """""" raise NotImplementedError() def clean_system_log(task): """"""Clean System Event Log. :param task: a task from TaskManager. """""" raise NotImplementedError() Nova driver impact ------------------ None Security impact --------------- None Other end user impact --------------------- None Scalability impact ------------------ None Performance Impact ------------------ None Other deployer impact --------------------- None Developer impact ---------------- Developers may implement these new management methods for drivers. Implementation ============== Assignee(s) ----------- Primary assignee: yuriyz Other contributors: vdrok Work Items ---------- * Modyfy base driver ``ManagementInterface`` class. * Implement new RPC API methods. * Create new REST API entrypoints. * Implement new methods for ``IPMIManagement`` interface. Dependencies ============ None Testing ======= Unit tests will be added. Upgrades and Backwards Compatibility ==================================== None. Documentation Impact ==================== Documentation will be provided. References ========== .. [#] http://www.intel.com/content/www/us/en/servers/ipmi/ipmi-intelligent-platform-mgt-interface-spec-2nd-gen-v2-0-spec-update.html .. [#] http://en.community.dell.com/techcenter/extras/m/white_papers/20441093 .. [#] https://software.intel.com/sites/manageability/AMT_Implementation_and_Reference_Guide/default.htm?turl=HTMLDocuments%2FWS-Management_Class_Reference%2FAMT_MessageLog.htm ",,190,0
openstack%2Fironic-specs~master~Iaacdc4ba75c7466cff20691908f28b9b724800de,openstack/ironic-specs,master,Iaacdc4ba75c7466cff20691908f28b9b724800de,Support for virtual macs - HP Oneview,ABANDONED,2016-05-24 09:44:29.000000000,2019-10-17 21:33:03.000000000,,"[{'_account_id': 3}, {'_account_id': 6637}, {'_account_id': 7239}, {'_account_id': 11956}]","[{'number': 1, 'created': '2016-05-24 09:44:29.000000000', 'files': ['specs/approved/support-for-virtual-macs-HP-Oneview.rst', 'specs/not-implemented/support-for-virtual-macs-HP-Oneview.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/64951b5f749659116b9e62c09102dc0af4431e29', 'message': 'Support for virtual macs - HP Oneview\n\nChange-Id: Iaacdc4ba75c7466cff20691908f28b9b724800de\n'}]",9,320331,64951b5f749659116b9e62c09102dc0af4431e29,6,4,1,11956,,,0,"Support for virtual macs - HP Oneview

Change-Id: Iaacdc4ba75c7466cff20691908f28b9b724800de
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/31/320331/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/approved/support-for-virtual-macs-HP-Oneview.rst', 'specs/not-implemented/support-for-virtual-macs-HP-Oneview.rst']",2,64951b5f749659116b9e62c09102dc0af4431e29,,../approved/support-for-virtual-macs-HP-Oneview.rst,,178,0
openstack%2Fpython-tripleoclient~stable%2Ftrain~Id9271460b20e602f935f1eddd70f989cd605b1f4,openstack/python-tripleoclient,stable/train,Id9271460b20e602f935f1eddd70f989cd605b1f4,Undercloud hosts entries in overcloud parameters,MERGED,2019-10-17 13:45:59.000000000,2019-10-17 21:30:48.000000000,2019-10-17 21:29:24.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-10-17 13:45:59.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/tests/v1/overcloud_update/test_overcloud_update.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/261c255369d2fee45c66a613e4bd69ba23943dfa', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane entry from\n/etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n(cherry picked from commit 8617dd1cacb95e9dc39460d50064e303d9534ad6)\n'}]",0,689159,261c255369d2fee45c66a613e4bd69ba23943dfa,9,4,1,3153,,,0,"Undercloud hosts entries in overcloud parameters

When running overcloud deploy set the UndercloudHostsEntries
parameter to include the <shortname>.ctlplane entry from
/etc/hosts on the undercloud.

With IPv6 the overcloud nodes cannot pull images from the
undercloud using an IPv6 address. By adding the host entry
for the undercloud in the overcloud nodes hosts file a name
can be used instead of the IPv6 address.

Related-Bug: #1836578
Change-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4
(cherry picked from commit 8617dd1cacb95e9dc39460d50064e303d9534ad6)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/59/689159/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/tests/v1/overcloud_update/test_overcloud_update.py', 'tripleoclient/v1/overcloud_deploy.py']",3,261c255369d2fee45c66a613e4bd69ba23943dfa,bug/1836578-stable/train,"import subprocess parameters[ 'UndercloudHostsEntries'] = [self._get_undercloud_host_entry()] def _get_undercloud_host_entry(self): """"""Get hosts entry for undercloud ctlplane network The host entry will be added on overcloud nodes """""" ctlplane_hostname = '.'.join([utils.get_short_hostname(), 'ctlplane']) cmd = ['getent', 'hosts', ctlplane_hostname] process = subprocess.Popen(cmd, stdout=subprocess.PIPE) out, err = process.communicate() if process.returncode != 0: raise exceptions.DeploymentError('No entry for %s in /etc/hosts' % ctlplane_hostname) return out.rstrip() ",,118,20
openstack%2Fironic-specs~master~I5fc2a62510114197e22e46f43cb9d16bb01b828b,openstack/ironic-specs,master,I5fc2a62510114197e22e46f43cb9d16bb01b828b,[RFE] Support network switches provisioning,ABANDONED,2016-08-03 13:03:34.000000000,2019-10-17 21:30:06.000000000,,"[{'_account_id': 3}, {'_account_id': 7080}, {'_account_id': 9542}, {'_account_id': 10375}, {'_account_id': 11655}, {'_account_id': 21626}]","[{'number': 1, 'created': '2016-08-03 13:03:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/5210433ebbbe8104e7cfc469ade6da7af1244d29', 'message': '[RFE] Support network switches provisioning\n\nThis Specification should allow a broader discussion if the RFE\ncan/should be implemented.\n\nChange-Id: I5fc2a62510114197e22e46f43cb9d16bb01b828b\nPartial-Bug: #1583065\n'}, {'number': 2, 'created': '2016-08-11 13:30:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/bb7a8e6a298f86332c2463166b93c452836100dc', 'message': '[RFE] Support network switches provisioning\n\nThis Specification should allow a broader discussion if the RFE\ncan/should be implemented.\n\nPartial-Bug: #1583065\nChange-Id: I5fc2a62510114197e22e46f43cb9d16bb01b828b\n'}, {'number': 3, 'created': '2016-08-15 12:55:27.000000000', 'files': ['specs/not-implemented/network-switches-provisioning.rst', 'specs/approved/network-switches-provisioning.rst'], 'web_link': 'https://opendev.org/openstack/ironic-specs/commit/92c95a8366ca5e78199d827ad8b948b098cb4465', 'message': '[RFE] Support network switches provisioning\n\nThis Specification should allow a broader discussion if the RFE\ncan/should be implemented.\n\nPartial-Bug: #1583065\nChange-Id: I5fc2a62510114197e22e46f43cb9d16bb01b828b\n'}]",13,350570,92c95a8366ca5e78199d827ad8b948b098cb4465,11,6,3,22622,,,0,"[RFE] Support network switches provisioning

This Specification should allow a broader discussion if the RFE
can/should be implemented.

Partial-Bug: #1583065
Change-Id: I5fc2a62510114197e22e46f43cb9d16bb01b828b
",git fetch https://review.opendev.org/openstack/ironic-specs refs/changes/70/350570/3 && git format-patch -1 --stdout FETCH_HEAD,"['specs/not-implemented/network-switches-provisioning.rst', 'specs/approved/network-switches-provisioning.rst']",2,5210433ebbbe8104e7cfc469ade6da7af1244d29,bug/1583065,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode =========================================== [RFE] Support network switches provisioning =========================================== https://bugs.launchpad.net/ironic/+bug/1583065 We want to enable Ironic to provision switches using ZTP Zero Touch Provisioning. This technology uses DHCP and TFTP and is similar to PXE. This would enable Operators to deploy whole bare metal infrastructures using Ironic. Problem description =================== We want to enable Ironic to provision whitebox/blackbox switches. This provisioning would consist out of the deployment of software updates and configuration files. This would open up the following use cases. Provisioning switches for tenants. Automate the network setup for under cloud deployment. Proposed change =============== Our main problem is that we can not use The ISCSI and PXE deployment since the underlying architecture is highly diverse (whitebox) and not all switches can run code (blackbox) this makes it impossible to use the IPA. We would need a deployment process which doesn't use the IPA. Alternatives ------------ Currently, no OSS projects are known to the authors Data model impact ----------------- We would aim to model switches as nodes with a special driver, so the only changes required on the data model would be to enter our new driver. The only required Informations for a succesfull deployment using ztp are the mac adress of the mgmt-interface of the switch and the name and path of the config file we want to deploy. State Machine Impact -------------------- If the current implementation of the IPA triggers any transition in the state machine, we would need to derive a way to trigger this changes with resources present on the switch since we can't execute arbitrary code on the switches. The switches used for our experimentation provide some scripting capabilities like python or bash. theu also contain a tool like Wget. This would make it possible to trigger transitions using HTTP or HTTPS. REST API impact --------------- Since we want to model switches as nodes with special drivers we can use the crud functionality of the current REST-API so no changes are needed. Client (CLI) impact ------------------- None (unknown) ""ironic"" CLI ~~~~~~~~~~~~ None (unknown) ""openstack baremetal"" CLI ~~~~~~~~~~~~~~~~~~~~~~~~~ None (unknown) RPC API impact -------------- None (unknown) Driver API impact ----------------- The API calls regarding the RAMdisk need to be faked (leave them empty), since it is not possible to deploy a RAMdisk on a blackbox switch. The same problem occurs with power management, since most switches boot automatically if they receive power. This could be circumvented if we would use IP enabled Power Outlets on the switches so we could manage the booting and the power management indirectly. (The Question for using a driver which not supports power management is, if this is compatible with ironic itself.) Nova driver impact ------------------ None (unknown) Ramdisk impact -------------- None (unknown) Security impact --------------- This feature may touch sensitive information of the switch like certs and credentials. This would also happen with compute notes if the deployed image would contain any sensitive information Other end user impact --------------------- We would need to adapt the GUI contained in the Openstack Frontend Scalability impact ------------------ Since the proposed method uses the same technology as PXE, there should not be a negative impact on scalability Performance Impact ------------------ Since the proposed method uses the same technology as PXE, there should not be a negative impact on the performance Other deployer impact --------------------- Developer impact ---------------- We would need to adapt the graphical user interface for ironic, if this is part of Horizon we would have to touch Horizon code. Implementation ============== Assignee(s) ----------- this will be decided in a more advanced version of the spec. Primary assignee: <launchpad-id or None> Other contributors: <launchpad-id or None> Work Items ---------- this will be decided in a more advanced version of the spec. Dependencies ============ ZTP depends on the availability of a DHCP and a TFTP server. Since they are already part of Ironic we could depend on them Testing ======= this will be decided in a more advanced version of the spec. Upgrades and Backwards Compatibility ==================================== Documentation Impact ==================== this will be decided in a more advanced version of the spec. References ========== * Links to mailing list or IRC discussions http://eavesdrop.openstack.org/meetings/ironic/2016/ironic.2016-05-23-17.00.log.html * Links to notes from a summit session none * Links to relevant research, if appropriate none * Related specifications as appropriate (e.g. if it's an EC2 thing, link the EC2 docs) none * Anything else you feel it is worthwhile to refer to ",,208,0
openstack%2Fpython-tripleoclient~stable%2Ftrain~Iec0f4f8279e5628dcb867312504acdc4fafc8152,openstack/python-tripleoclient,stable/train,Iec0f4f8279e5628dcb867312504acdc4fafc8152,Use name for container registry,MERGED,2019-10-17 02:46:25.000000000,2019-10-17 21:14:06.000000000,2019-10-17 21:09:34.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-10-17 02:46:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1707133c278438913098947451aaeb4f40c83717', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n(cherry picked from commit e3064514a6113e89f4cb24ffe2e341ee91628741)\n'}, {'number': 2, 'created': '2019-10-17 02:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/33b67e41d23854ad26452793463dec237a239dc5', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n(cherry picked from commit e3064514a6113e89f4cb24ffe2e341ee91628741)\n'}, {'number': 3, 'created': '2019-10-17 02:47:11.000000000', 'files': ['tripleoclient/v1/undercloud_config.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0c57e6914dd0a10bf39b59b91eaee13ca67911cf', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n(cherry picked from commit e3064514a6113e89f4cb24ffe2e341ee91628741)\n'}]",0,689068,0c57e6914dd0a10bf39b59b91eaee13ca67911cf,11,4,3,3153,,,0,"Use name for container registry

For Docker/Podman using an IPv6 address in a docker reference
is invalid. A name must be used:
      https://github.com/containers/libpod/issues/3516

Use the undercloud hostname on the ctlplane network.
<shortname>.ctlplane.<domain> for local container registry.

Related-Bug: #1836578
Change-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152
(cherry picked from commit e3064514a6113e89f4cb24ffe2e341ee91628741)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/68/689068/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/undercloud_config.py'],1,1707133c278438913098947451aaeb4f40c83717,bug/1836578-stable/train," if CONF.get('undercloud_hostname'): utils.set_hostname(CONF.get('undercloud_hostname')) local_registry_name = '.'.join([utils.get_short_hostname(), 'ctlplane', CONF['overcloud_domain_name']]) if CONF.get('container_cli', 'podman') == 'podman': env_data['DockerInsecureRegistryAddress'] = [local_registry_name] env_data['DockerInsecureRegistryAddress'].append( CONF['local_ip'].split('/')[0]) '%s:8787' % local_registry_name] env_data['DockerInsecureRegistryAddress'].append( '%s:8787' % CONF['local_ip'].split('/')[0]) env_data['LocalContainerRegistry'] = local_registry_name"," if CONF.get('container_cli', 'podman') == 'podman': env_data['DockerInsecureRegistryAddress'] = [ CONF['local_ip'].split('/')[0]] '%s:8787' % CONF['local_ip'].split('/')[0]] env_data['LocalContainerRegistry'] = CONF['local_ip'].split('/')[0] if CONF.get('undercloud_hostname'): utils.set_hostname(CONF.get('undercloud_hostname')) ",13,7
openstack%2Ftripleo-ci~master~I793b6e2e9031679d40f27d19c0c63ba0b6c80fc6,openstack/tripleo-ci,master,I793b6e2e9031679d40f27d19c0c63ba0b6c80fc6,Disable octavia multinode on n > stein,MERGED,2019-10-15 12:50:39.000000000,2019-10-17 21:09:33.000000000,2019-10-17 21:09:33.000000000,"[{'_account_id': 6469}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 12:50:39.000000000', 'files': ['zuul.d/multinode-jobs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/1fa2fff0cc5f278331f688399037e3dec6c27727', 'message': ""Disable octavia multinode on n > stein\n\nThe multinode environment isn't expected to work on train and newer at\nall at the moment so we might as well not be eating up the resources.\n\nChange-Id: I793b6e2e9031679d40f27d19c0c63ba0b6c80fc6\n""}]",0,688700,1fa2fff0cc5f278331f688399037e3dec6c27727,10,6,1,6681,,,0,"Disable octavia multinode on n > stein

The multinode environment isn't expected to work on train and newer at
all at the moment so we might as well not be eating up the resources.

Change-Id: I793b6e2e9031679d40f27d19c0c63ba0b6c80fc6
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/00/688700/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/multinode-jobs.yaml'],1,1fa2fff0cc5f278331f688399037e3dec6c27727,, branches: ^(stable/(queens|rocky|stein)).*$, branches: ^(?!stable/(newton|ocata|pike)).*$,1,1
openstack%2Fcharm-mysql-router~master~I31565983ad8ede264f69997668b194c6f320689c,openstack/charm-mysql-router,master,I31565983ad8ede264f69997668b194c6f320689c,Upstream charm,MERGED,2019-10-16 21:11:53.000000000,2019-10-17 20:55:43.000000000,2019-10-17 20:55:43.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-10-16 21:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/5e8382b5b2a41cb9e5e5f4029124ab71a211c69f', 'message': 'Bring charm into upstream\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox and zuul.yaml.\n\nChange-Id: I31565983ad8ede264f69997668b194c6f320689c\n'}, {'number': 2, 'created': '2019-10-16 21:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/b092b1d4975891590c6eb079b76254e752cb7c7d', 'message': 'Upstream charm\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox, README and zuul.yaml.\n\nChange-Id: I31565983ad8ede264f69997668b194c6f320689c\n'}, {'number': 3, 'created': '2019-10-17 17:25:40.000000000', 'files': ['src/tests/bundles/eoan.yaml', 'src/files/.gitkeep', '.gitreview', 'test-requirements.txt', 'src/tox.ini', '.zuul.yaml', 'src/test-requirements.txt', 'src/layer.yaml', 'src/README.md', 'requirements.txt', 'unit_tests/test_lib_charm_openstack_mysql_router.py', 'src/HACKING.md', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-router/commit/e15346f46a4aae94265f38cd39592f96a3b53c08', 'message': 'Upstream charm\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox, README and zuul.yaml.\n\nChange-Id: I31565983ad8ede264f69997668b194c6f320689c\n'}]",24,689046,e15346f46a4aae94265f38cd39592f96a3b53c08,21,5,3,20805,,,0,"Upstream charm

Bring charm into alignment with other OpenStack charms.
Updates to requirements, tox, README and zuul.yaml.

Change-Id: I31565983ad8ede264f69997668b194c6f320689c
",git fetch https://review.opendev.org/openstack/charm-mysql-router refs/changes/46/689046/1 && git format-patch -1 --stdout FETCH_HEAD,"['src/tests/bundles/eoan.yaml', 'requirements.txt', 'src/files/.gitkeep', '.gitreview', 'test-requirements.txt', 'src/tox.ini', '.zuul.yaml', 'src/test-requirements.txt', 'src/HACKING.md', 'tox.ini', 'src/layer.yaml']",11,5e8382b5b2a41cb9e5e5f4029124ab71a211c69f,mysql8,repo: https://opendev.org/openstack/charm-mysql-router,repo: https://github.com/openstack-charmers/charm-mysql-router,69,22
openstack%2Fironic~master~I1f6d60a1db272293b701b44d705efc92933682a7,openstack/ironic,master,I1f6d60a1db272293b701b44d705efc92933682a7,Document systemd-nspawn as a nice trick for patching a ramdisk,MERGED,2019-10-17 09:48:42.000000000,2019-10-17 20:55:11.000000000,2019-10-17 12:44:21.000000000,"[{'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-10-17 09:48:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/febb3edce7cc46334fa5478129e9cc055e3ed0a2', 'message': 'Document systemd-nspawn as a nice trick for patching a ramdisk\n\nChange-Id: I1f6d60a1db272293b701b44d705efc92933682a7\n'}, {'number': 2, 'created': '2019-10-17 11:05:52.000000000', 'files': ['doc/source/admin/troubleshooting.rst'], 'web_link': 'https://opendev.org/openstack/ironic/commit/5d5cd90ddf9247ed179a71293777d2fcd430bd14', 'message': 'Document systemd-nspawn as a nice trick for patching a ramdisk\n\nChange-Id: I1f6d60a1db272293b701b44d705efc92933682a7\n'}]",2,689113,5d5cd90ddf9247ed179a71293777d2fcd430bd14,12,4,2,10239,,,0,"Document systemd-nspawn as a nice trick for patching a ramdisk

Change-Id: I1f6d60a1db272293b701b44d705efc92933682a7
",git fetch https://review.opendev.org/openstack/ironic refs/changes/13/689113/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/troubleshooting.rst'],1,febb3edce7cc46334fa5478129e9cc055e3ed0a2,nspawn,".. note:: On a systemd-based system you can use ``systemd-nspawn`` to create a lightweight container from the unpacked filesystem tree:: sudo systemd-nspawn --directory /path/to/unpacked/ramdisk/ /bin/bash This will allow you to run commands within the filesystem, e.g. use package manager. If the ramdisk is also systemd-based, and you have login credentials set up, you can even boot a real ramdisk enviroment with :: sudo systemd-nspawn --directory /home/dtantsur/Work/unpack/ --boot ",,14,0
openstack%2Fpuppet-placement~master~Ie80fb4e7d0514b65ec6a798a10cd7079c3ffa813,openstack/puppet-placement,master,Ie80fb4e7d0514b65ec6a798a10cd7079c3ffa813,New placement::keystone::authtoken::interface parameter,MERGED,2019-10-16 07:11:12.000000000,2019-10-17 20:35:49.000000000,2019-10-17 20:14:16.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-10-16 07:11:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-placement/commit/ea049bb3ed5677d4d53ce1645092afc70e6374e8', 'message': 'New placement::keystone::authtoken::interface parameter\n\nAdds interface parameter to placement::keystone::authtoken to configure\nthe interface to use for the Identity API endpoint. Valid values are\n""public"", ""internal"" or ""admin""(default).\n\nChange-Id: Ie80fb4e7d0514b65ec6a798a10cd7079c3ffa813\n'}, {'number': 2, 'created': '2019-10-16 07:54:36.000000000', 'files': ['spec/classes/placement_keystone_authtoken_spec.rb', 'releasenotes/notes/keystone_authtoken_interface-4537941bc250a05d.yaml', 'manifests/keystone/authtoken.pp'], 'web_link': 'https://opendev.org/openstack/puppet-placement/commit/5e5d7deffadfd93434e2b6d68339ae136686e308', 'message': 'New placement::keystone::authtoken::interface parameter\n\nAdds interface parameter to placement::keystone::authtoken to configure\nthe interface to use for the Identity API endpoint. Valid values are\n""public"", ""internal"" or ""admin""(default).\n\nDepends-On: I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9\n\nChange-Id: Ie80fb4e7d0514b65ec6a798a10cd7079c3ffa813\n'}]",0,688862,5e5d7deffadfd93434e2b6d68339ae136686e308,16,7,2,17216,,,0,"New placement::keystone::authtoken::interface parameter

Adds interface parameter to placement::keystone::authtoken to configure
the interface to use for the Identity API endpoint. Valid values are
""public"", ""internal"" or ""admin""(default).

Depends-On: I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9

Change-Id: Ie80fb4e7d0514b65ec6a798a10cd7079c3ffa813
",git fetch https://review.opendev.org/openstack/puppet-placement refs/changes/62/688862/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/placement_keystone_authtoken_spec.rb', 'releasenotes/notes/keystone_authtoken_interface-4537941bc250a05d.yaml', 'manifests/keystone/authtoken.pp']",3,ea049bb3ed5677d4d53ce1645092afc70e6374e8,interface,"# [*interface*] # (Optional) Interface to use for the Identity API endpoint. Valid values are # ""public"", ""internal"" or ""admin""(default). # Defaults to $::os_service_default. # $interface = $::os_service_default, interface => $interface,",,16,0
openstack%2Fpython-glanceclient~stable%2Fqueens~Ie080f9a8fa7f4407b1fcbb7fb7c763152c5ec295,openstack/python-glanceclient,stable/queens,Ie080f9a8fa7f4407b1fcbb7fb7c763152c5ec295,Remove deprecated ssl options,ABANDONED,2019-03-12 08:37:36.000000000,2019-10-17 20:35:05.000000000,,"[{'_account_id': 11904}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 25111}]","[{'number': 1, 'created': '2019-03-12 08:37:36.000000000', 'files': ['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py', 'releasenotes/notes/rm-deprecate-ssl-opts-c88225a4ba2285ad.yaml', 'doc/source/cli/details.rst'], 'web_link': 'https://opendev.org/openstack/python-glanceclient/commit/2f2d272c46f60fbf8c091ef1c2ecc2d0d2d0d353', 'message': 'Remove deprecated ssl options\n\nOld deprecated ssl options block the new keystoneauth parser get the\ncorrect value, should be removed.\n\nChange-Id: Ie080f9a8fa7f4407b1fcbb7fb7c763152c5ec295\nCloses-Bug: 1697163\n(cherry picked from commit 8e862b6018404117263e817a896728e344858d94)\n'}]",0,642691,2f2d272c46f60fbf8c091ef1c2ecc2d0d2d0d353,7,4,1,8478,,,0,"Remove deprecated ssl options

Old deprecated ssl options block the new keystoneauth parser get the
correct value, should be removed.

Change-Id: Ie080f9a8fa7f4407b1fcbb7fb7c763152c5ec295
Closes-Bug: 1697163
(cherry picked from commit 8e862b6018404117263e817a896728e344858d94)
",git fetch https://review.opendev.org/openstack/python-glanceclient refs/changes/91/642691/1 && git format-patch -1 --stdout FETCH_HEAD,"['glanceclient/tests/unit/test_shell.py', 'glanceclient/shell.py', 'releasenotes/notes/rm-deprecate-ssl-opts-c88225a4ba2285ad.yaml', 'doc/source/cli/details.rst']",4,2f2d272c46f60fbf8c091ef1c2ecc2d0d2d0d353,bug/1697163, [--profile HMAC_KEY] [--os-region-name OS_REGION_NAME], [--profile HMAC_KEY] [--key-file OS_KEY] [--ca-file OS_CACERT] [--cert-file OS_CERT] [--os-region-name OS_REGION_NAME]``--key-file OS_KEY`` **DEPRECATED!** Use --os-key. ``--ca-file OS_CACERT`` **DEPRECATED!** Use --os-cacert. ``--cert-file OS_CERT`` **DEPRECATED!** Use --os-cert. ,10,34
openstack%2Frequirements~stable%2Fstein~Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,openstack/requirements,stable/stein,Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,Switch to opensuse-15 nodeset,MERGED,2019-10-17 11:15:33.000000000,2019-10-17 20:34:24.000000000,2019-10-17 20:34:24.000000000,"[{'_account_id': 6593}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 11:15:33.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/d4f1977da2dc3c1e8c22bc835fa597ef09a7b8bc', 'message': 'Switch to opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThe new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,\nchange tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.\n\nChange-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32\n(cherry picked from commit 1577c44e8ce14e36dc0c7a52207624779148554a)\n'}]",0,689127,d4f1977da2dc3c1e8c22bc835fa597ef09a7b8bc,9,3,1,6547,,,0,"Switch to opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

The new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,
change tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.

Change-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32
(cherry picked from commit 1577c44e8ce14e36dc0c7a52207624779148554a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/27/689127/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,d4f1977da2dc3c1e8c22bc835fa597ef09a7b8bc,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Frequirements~stable%2Ftrain~Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,openstack/requirements,stable/train,Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,Switch to opensuse-15 nodeset,MERGED,2019-10-17 11:15:11.000000000,2019-10-17 20:34:23.000000000,2019-10-17 20:34:23.000000000,"[{'_account_id': 6593}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 11:15:11.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/532d80f1b506e7f284d90d1fcd4bdc9431c3fc5e', 'message': 'Switch to opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThe new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,\nchange tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.\n\nChange-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32\n(cherry picked from commit 1577c44e8ce14e36dc0c7a52207624779148554a)\n'}]",0,689126,532d80f1b506e7f284d90d1fcd4bdc9431c3fc5e,9,4,1,6547,,,0,"Switch to opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

The new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,
change tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.

Change-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32
(cherry picked from commit 1577c44e8ce14e36dc0c7a52207624779148554a)
",git fetch https://review.opendev.org/openstack/requirements refs/changes/26/689126/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,532d80f1b506e7f284d90d1fcd4bdc9431c3fc5e,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Ftripleo-heat-templates~stable%2Fstein~I3428dc3e99afb7027284bccf582ade43dfcc097d,openstack/tripleo-heat-templates,stable/stein,I3428dc3e99afb7027284bccf582ade43dfcc097d,DNM - Change InternalApiNet for vexxhost,ABANDONED,2019-10-17 17:25:18.000000000,2019-10-17 20:30:56.000000000,,[],"[{'number': 1, 'created': '2019-10-17 17:25:18.000000000', 'files': ['ci/environments/network/multiple-nics/network-environment.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1896979732b44a580da60abb82ae6d2876c71455', 'message': 'DNM - Change InternalApiNet for vexxhost\n\nChange-Id: I3428dc3e99afb7027284bccf582ade43dfcc097d\n'}]",0,689226,1896979732b44a580da60abb82ae6d2876c71455,2,0,1,9976,,,0,"DNM - Change InternalApiNet for vexxhost

Change-Id: I3428dc3e99afb7027284bccf582ade43dfcc097d
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/689226/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/network/multiple-nics/network-environment.yaml'],1,1896979732b44a580da60abb82ae6d2876c71455,adjust_internal_network," InternalApiNetCidr: 172.20.0.0/24 InternalApiAllocationPools: [{""start"": ""172.20.0.10"", ""end"": ""172.20.0.250""}]"," InternalApiNetCidr: 172.17.0.0/24 InternalApiAllocationPools: [{""start"": ""172.17.0.10"", ""end"": ""172.17.0.250""}]",2,2
openstack%2Fnova~master~I84107c8f956f911ecf8c4e33af4ae17c8a1c6878,openstack/nova,master,I84107c8f956f911ecf8c4e33af4ae17c8a1c6878,Return security groups by name,ABANDONED,2019-08-27 10:02:05.000000000,2019-10-17 20:05:53.000000000,,"[{'_account_id': 4690}, {'_account_id': 6873}, {'_account_id': 10118}, {'_account_id': 10135}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 16515}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-08-27 10:02:05.000000000', 'files': ['nova/db/sqlalchemy/api.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/1679b4bb22e66886c8fa985db077774e8303e59b', 'message': 'Return security groups by name\n\nIf we query the security groups by names, in case\nof severals occurences by name appear, it will raise\na TypeError.\nSimple return all the sg by name will avoid to raise\nand exception and let the caller handle the result\nlike here:\nhttps://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L4105\n\nChange-Id: I84107c8f956f911ecf8c4e33af4ae17c8a1c6878\nRelated-Bug: #1824435\n'}]",9,678776,1679b4bb22e66886c8fa985db077774e8303e59b,17,13,1,16515,,,0,"Return security groups by name

If we query the security groups by names, in case
of severals occurences by name appear, it will raise
a TypeError.
Simple return all the sg by name will avoid to raise
and exception and let the caller handle the result
like here:
https://github.com/openstack/nova/blob/master/nova/db/sqlalchemy/api.py#L4105

Change-Id: I84107c8f956f911ecf8c4e33af4ae17c8a1c6878
Related-Bug: #1824435
",git fetch https://review.opendev.org/openstack/nova refs/changes/76/678776/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/db/sqlalchemy/api.py'],1,1679b4bb22e66886c8fa985db077774e8303e59b,bug/1824435, # Find the missing group and raise # Return the security groups return sg_models, if len(sg_models) == len(group_names): return sg_models # Find the first one missing and raise # Not Reached,3,4
openstack%2Fnova~master~Iac4dd9feebb1a405826c95cb6b046b82c61140a2,openstack/nova,master,Iac4dd9feebb1a405826c95cb6b046b82c61140a2,Add compute side revert allocation test for bug 1848343,MERGED,2019-10-16 19:25:39.000000000,2019-10-17 19:39:36.000000000,2019-10-17 19:17:18.000000000,"[{'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-16 19:25:39.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1848343.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/760ccb32dbbb0baf40ce4ea01977f9886d0d3a3b', 'message': 'Add compute side revert allocation test for bug 1848343\n\nThis adds a functional recreate test for a scenario where\nreverting migration-based allocations during resize failure\nin the compute service results in leaking allocations for a\ndeleted server.\n\nChange-Id: Iac4dd9feebb1a405826c95cb6b046b82c61140a2\nRelated-Bug: #1848343\n'}]",0,689013,760ccb32dbbb0baf40ce4ea01977f9886d0d3a3b,23,10,1,6873,,,0,"Add compute side revert allocation test for bug 1848343

This adds a functional recreate test for a scenario where
reverting migration-based allocations during resize failure
in the compute service results in leaking allocations for a
deleted server.

Change-Id: Iac4dd9feebb1a405826c95cb6b046b82c61140a2
Related-Bug: #1848343
",git fetch https://review.opendev.org/openstack/nova refs/changes/13/689013/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1848343.py'],1,760ccb32dbbb0baf40ce4ea01977f9886d0d3a3b,bug/1848343,"from nova.compute import manager as compute_manager def test_migrate_on_compute_fail(self): """"""Tests a scenario where during the _prep_resize on the dest host the instance is gone which triggers a failure and revert of the migration-based allocations created in conductor. """""" server, source_host, target_host = self._create_server( 'test_resize_on_compute_fail') # Wrap _prep_resize so we can concurrently delete the server. original_prep_resize = compute_manager.ComputeManager._prep_resize def wrap_prep_resize(*args, **kwargs): self.api.delete_server(server['id']) self._wait_until_deleted(server) return original_prep_resize(*args, **kwargs) self.stub_out('nova.compute.manager.ComputeManager._prep_resize', wrap_prep_resize) # Now start the cold migration which will fail in the dest compute. self.api.post_server_action(server['id'], {'migrate': None}) # We cannot monitor the migration from the API since it is deleted # when the instance is deleted so just wait for the failed instance # action event after the allocation revert happens. self._wait_for_action_fail_completion( server, instance_actions.MIGRATE, 'compute_prep_resize', api=self.api) self._assert_no_allocations(server)", # TODO(mriedem): Should have similar tests for resize failing in the # compute service rather than conductor.,29,2
openstack%2Ftripleo-ci~master~I3f50f27bf349be6ceb5dc303e206ec83abe3c458,openstack/tripleo-ci,master,I3f50f27bf349be6ceb5dc303e206ec83abe3c458,fixed linters,MERGED,2019-10-17 11:42:36.000000000,2019-10-17 19:33:13.000000000,2019-10-17 19:33:13.000000000,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-17 11:42:36.000000000', 'files': ['tox.ini', '.pre-commit-config.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/747f4b87c9d08385d962e95e0643bc69931c3884', 'message': 'fixed linters\n\n* implemented workaround for https://github.com/ansible/ansible-lint/issues/590\n* bumped linter versions\n* added missing proxy variables to passenv\n* removed uneccesary use of hacking with flake8 hook\n\nChange-Id: I3f50f27bf349be6ceb5dc303e206ec83abe3c458\n'}]",2,689129,747f4b87c9d08385d962e95e0643bc69931c3884,13,9,1,24162,,,0,"fixed linters

* implemented workaround for https://github.com/ansible/ansible-lint/issues/590
* bumped linter versions
* added missing proxy variables to passenv
* removed uneccesary use of hacking with flake8 hook

Change-Id: I3f50f27bf349be6ceb5dc303e206ec83abe3c458
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/29/689129/1 && git format-patch -1 --stdout FETCH_HEAD,"['tox.ini', '.pre-commit-config.yaml']",2,747f4b87c9d08385d962e95e0643bc69931c3884,fix/lint, rev: v2.3.0 # commented to allow progressive adoption in smaller patches rev: v4.1.1a0," rev: v2.2.3 additional_dependencies: - hacking<1.2.0,>=1.1.0 # commented to allow progressive enablement in smaller patches rev: v4.1.0a0",10,6
openstack%2Fnova~master~Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee,openstack/nova,master,Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee,Add functional recreate test for bug 1848343,MERGED,2019-10-16 17:11:16.000000000,2019-10-17 19:26:43.000000000,2019-10-17 19:13:53.000000000,"[{'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-16 17:11:16.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1848343.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/24318f8cd4b71f1072c6f194a6f1e04a854acb06', 'message': 'Add functional recreate test for bug 1848343\n\nThis adds a functional test to recreate a bug where the\ninstance is deleted after conductor has swapped allocations\nto the migration consumer but before casting to compute. In\nthis case, the scheduler fails due to NoValidHost which is\nentirely reasonable. The bug is that the conductor task rollback\ncode re-creates the allocations on the source node for the\nnow-deleted instance and as such those allocations get leaked.\n\nNote that we have similar exposures in the live migration\ntask and reverting allocations when resize fails in the\ncompute service. A TODO is left inline to add tests for those\nseparately.\n\nChange-Id: Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee\nRelated-Bug: #1848343\n'}]",1,688980,24318f8cd4b71f1072c6f194a6f1e04a854acb06,23,10,1,6873,,,0,"Add functional recreate test for bug 1848343

This adds a functional test to recreate a bug where the
instance is deleted after conductor has swapped allocations
to the migration consumer but before casting to compute. In
this case, the scheduler fails due to NoValidHost which is
entirely reasonable. The bug is that the conductor task rollback
code re-creates the allocations on the source node for the
now-deleted instance and as such those allocations get leaked.

Note that we have similar exposures in the live migration
task and reverting allocations when resize fails in the
compute service. A TODO is left inline to add tests for those
separately.

Change-Id: Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee
Related-Bug: #1848343
",git fetch https://review.opendev.org/openstack/nova refs/changes/80/688980/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1848343.py'],1,24318f8cd4b71f1072c6f194a6f1e04a854acb06,bug/1848343,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from nova.compute import instance_actions from nova.scheduler.client import query as query_client from nova.tests.functional import integrated_helpers from nova.tests.unit.image import fake as fake_image class DeletedServerAllocationRevertTest( integrated_helpers.ProviderUsageBaseTestCase): """"""Tests for bug 1848343 introduced in Queens where reverting a migration-based allocation can re-create and leak allocations for a deleted server if the server is deleted during a migration (resize, cold or live). """""" compute_driver = 'fake.MediumFakeDriver' def setUp(self): super(DeletedServerAllocationRevertTest, self).setUp() # Start two computes so we can migrate between them. self._start_compute('host1') self._start_compute('host2') def _create_server(self, name): """"""Creates a server with the given name and returns the server, source host and target host. """""" server = self._build_minimal_create_server_request( self.api, name, image_uuid=fake_image.get_valid_image_id(), networks='none') server = self.api.post_server({'server': server}) server = self._wait_for_state_change(self.api, server, 'ACTIVE') source_host = server['OS-EXT-SRV-ATTR:host'] target_host = 'host2' if source_host == 'host1' else 'host1' return server, source_host, target_host def _assert_no_allocations(self, server): # There should be no allocations on either host1 or host2. providers = self._get_all_providers() for rp in providers: allocations = self._get_allocations_by_provider_uuid(rp['uuid']) # FIXME(mriedem): This is bug 1848343 where rollback # reverts the allocations and moves the source host allocations # held by the migration consumer back to the now-deleted instance # consumer. if rp['name'] == server['OS-EXT-SRV-ATTR:host']: self.assertFlavorMatchesAllocation( server['flavor'], server['id'], rp['uuid']) else: self.assertEqual({}, allocations, 'Leaked allocations on provider: %s (%s)' % (rp['uuid'], rp['name'])) def test_migration_task_rollback(self): """"""Tests a scenario where the MigrationTask swaps the allocations for a cold migrate (or resize, it does not matter) and then fails and rolls back allocations before RPC casting to prep_resize on the dest host. """""" server, source_host, target_host = self._create_server( 'test_migration_task_rollback') # Disable the target compute service to trigger a NoValidHost from # the scheduler which happens after MigrationTask has moved the source # node allocations to the migration record. target_service = self.computes[target_host].service_ref self.api.put_service(target_service.uuid, {'status': 'disabled'}) # Wrap the select_destinations call so we can delete the server # concurrently while scheduling. original_select_dests = \ query_client.SchedulerQueryClient.select_destinations def wrap_select_dests(*args, **kwargs): # Simulate concurrently deleting the server while scheduling. self.api.delete_server(server['id']) self._wait_until_deleted(server) return original_select_dests(*args, **kwargs) self.stub_out('nova.scheduler.client.query.SchedulerQueryClient.' 'select_destinations', wrap_select_dests) # Now start the cold migration which will fail due to NoValidHost. # Note that we get a 404 back because this is a blocking call until # conductor RPC casts to prep_resize on the selected dest host but # we never get that far. self.api.post_server_action(server['id'], {'migrate': None}, check_response_status=[404]) # We cannot monitor the migration from the API since it is deleted # when the instance is deleted so just wait for the failed instance # action event after the task rollback happens. self._wait_for_action_fail_completion( server, instance_actions.MIGRATE, 'cold_migrate', api=self.api) self._assert_no_allocations(server) # TODO(mriedem): Should have similar tests for live migration and # resize failing in the compute service rather than conductor. ",,106,0
openstack%2Fkuryr-kubernetes~master~I49ab21e56632cefaaa307ae0e453050e7ca5dd7f,openstack/kuryr-kubernetes,master,I49ab21e56632cefaaa307ae0e453050e7ca5dd7f,Just check k8s 1.16,MERGED,2019-10-07 17:31:18.000000000,2019-10-17 19:25:00.000000000,2019-10-17 19:21:55.000000000,"[{'_account_id': 11600}, {'_account_id': 14570}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 24604}, {'_account_id': 25900}, {'_account_id': 28082}, {'_account_id': 28396}]","[{'number': 1, 'created': '2019-10-07 17:31:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/84e4ad03a9d3c039cf26526e2cf66ae5f83be945', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\n'}, {'number': 2, 'created': '2019-10-08 16:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/dde480cf7ed826b5e66c75fbcc024d53bc241edf', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}, {'number': 3, 'created': '2019-10-09 16:10:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/4be2d3468909c753fda4e0d147681c01d4f1a799', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}, {'number': 4, 'created': '2019-10-10 06:31:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/4cbcb80019c39be0b82ae38b63e85662d1530378', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}, {'number': 5, 'created': '2019-10-11 11:48:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f9af7a9a4ed8dca685efbc70ebbaf07e2917c24d', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}, {'number': 6, 'created': '2019-10-15 12:26:09.000000000', 'files': ['devstack/plugin.sh', 'devstack/settings'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/1f3ee029dca37b85e8cb5d3ce85e183fcca5be9d', 'message': 'Just check k8s 1.16\n\nChange-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}]",0,687116,1f3ee029dca37b85e8cb5d3ce85e183fcca5be9d,29,8,6,28396,,,0,"Just check k8s 1.16

Change-Id: I49ab21e56632cefaaa307ae0e453050e7ca5dd7f
Signed-off-by: Alexey Perevalov <a.perevalov@samsung.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/16/687116/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/settings'],1,84e4ad03a9d3c039cf26526e2cf66ae5f83be945,,KURYR_HYPERKUBE_VERSION=${KURYR_HYPERKUBE_VERSION:-v1.16.0},KURYR_HYPERKUBE_VERSION=${KURYR_HYPERKUBE_VERSION:-v1.13.0},1,1
openstack%2Fkuryr-kubernetes~master~Ifa9c27a416c3347441a2568b37e1bb7b0eba2f28,openstack/kuryr-kubernetes,master,Ifa9c27a416c3347441a2568b37e1bb7b0eba2f28,Add not-ready tolerations to kuryr pods,MERGED,2019-10-15 12:25:45.000000000,2019-10-17 19:24:06.000000000,2019-10-17 19:21:54.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 28396}]","[{'number': 1, 'created': '2019-10-15 12:25:45.000000000', 'files': ['devstack/lib/kuryr_kubernetes'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9c9eac0c807c2a225d04acb3f23b061e3b56a27c', 'message': 'Add not-ready tolerations to kuryr pods\n\nSeems like Kubernetes 1.16 is more strict regarding not-ready taint on\nthe node and keeps it until CNI is correctly configured. This means that\nwe at least need kuryr-cni to have toleration for that. This commit adds\nit to both kuryr-cni and kuryr-controller as well as missing master\ntoleration to kuryr-controller.\n\nChange-Id: Ifa9c27a416c3347441a2568b37e1bb7b0eba2f28\n'}]",2,688695,9c9eac0c807c2a225d04acb3f23b061e3b56a27c,18,7,1,11600,,,0,"Add not-ready tolerations to kuryr pods

Seems like Kubernetes 1.16 is more strict regarding not-ready taint on
the node and keeps it until CNI is correctly configured. This means that
we at least need kuryr-cni to have toleration for that. This commit adds
it to both kuryr-cni and kuryr-controller as well as missing master
toleration to kuryr-controller.

Change-Id: Ifa9c27a416c3347441a2568b37e1bb7b0eba2f28
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/95/688695/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/kuryr_kubernetes'],1,9c9eac0c807c2a225d04acb3f23b061e3b56a27c,1.16-tolerations," tolerations: - key: ""node-role.kubernetes.io/master"" operator: ""Exists"" effect: ""NoSchedule"" - key: ""node.kubernetes.io/not-ready"" operator: ""Exists"" effect: ""NoSchedule"" - key: ""node.kubernetes.io/not-ready"" operator: ""Exists"" effect: ""NoSchedule""",,10,0
openstack%2Fnova~master~I856db36d63779d521fe26b27ef5a12b7a4d3bd91,openstack/nova,master,I856db36d63779d521fe26b27ef5a12b7a4d3bd91,Add live migration recreate test for bug 1848343,MERGED,2019-10-16 18:05:42.000000000,2019-10-17 19:18:47.000000000,2019-10-17 19:14:12.000000000,"[{'_account_id': 9008}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-16 18:05:42.000000000', 'files': ['nova/tests/functional/regressions/test_bug_1848343.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/252ee93086a4854c5a5922eec826ffb908f9b283', 'message': 'Add live migration recreate test for bug 1848343\n\nThis adds a live migration functional recreate test\nlike Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee is\nfor cold migrate/resize.\n\nChange-Id: I856db36d63779d521fe26b27ef5a12b7a4d3bd91\nRelated-Bug: #1848343\n'}]",0,688994,252ee93086a4854c5a5922eec826ffb908f9b283,22,10,1,6873,,,0,"Add live migration recreate test for bug 1848343

This adds a live migration functional recreate test
like Ifd156ac8789d3fc84d56d400cf1e160e2cd2fbee is
for cold migrate/resize.

Change-Id: I856db36d63779d521fe26b27ef5a12b7a4d3bd91
Related-Bug: #1848343
",git fetch https://review.opendev.org/openstack/nova refs/changes/94/688994/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/tests/functional/regressions/test_bug_1848343.py'],1,252ee93086a4854c5a5922eec826ffb908f9b283,bug/1848343," def _disable_target_host(self, target_host): # the scheduler which happens after conductor has moved the source def _stub_delete_server_during_scheduling(self, server): def test_migration_task_rollback(self): """"""Tests a scenario where the MigrationTask swaps the allocations for a cold migrate (or resize, it does not matter) and then fails and rolls back allocations before RPC casting to prep_resize on the dest host. """""" server, source_host, target_host = self._create_server( 'test_migration_task_rollback') self._disable_target_host(target_host) self._stub_delete_server_during_scheduling(server) def test_live_migration_task_rollback(self): """"""Tests a scenario where the LiveMigrationTask swaps the allocations for a live migration and then fails and rolls back allocations before RPC casting to live_migration on the source host. """""" server, source_host, target_host = self._create_server( 'test_live_migration_task_rollback') self._disable_target_host(target_host) self._stub_delete_server_during_scheduling(server) # Now start the live migration which will fail due to NoValidHost. body = {'os-migrateLive': {'host': None, 'block_migration': 'auto'}} self.api.post_server_action(server['id'], body) # We cannot monitor the migration from the API since it is deleted # when the instance is deleted so just wait for the failed instance # action event after the task rollback happens. self._wait_for_action_fail_completion( server, instance_actions.LIVE_MIGRATION, 'conductor_live_migrate_instance', api=self.api) self._assert_no_allocations(server) # TODO(mriedem): Should have similar tests for resize failing in the # compute service rather than conductor."," def test_migration_task_rollback(self): """"""Tests a scenario where the MigrationTask swaps the allocations for a cold migrate (or resize, it does not matter) and then fails and rolls back allocations before RPC casting to prep_resize on the dest host. """""" server, source_host, target_host = self._create_server( 'test_migration_task_rollback') # the scheduler which happens after MigrationTask has moved the source # TODO(mriedem): Should have similar tests for live migration and # resize failing in the compute service rather than conductor.",37,11
openstack%2Fproject-config~master~I6888b478e93021bbede4a647af990774126b0245,openstack/project-config,master,I6888b478e93021bbede4a647af990774126b0245,Remove qcow2 version 0.10 compat from our images,MERGED,2019-10-16 23:28:05.000000000,2019-10-17 19:13:23.000000000,2019-10-17 19:13:23.000000000,"[{'_account_id': 2}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 23:28:05.000000000', 'files': ['nodepool/nodepool.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/f903e7c6b315d8e2760fd862b5bb95dc86186351', 'message': 'Remove qcow2 version 0.10 compat from our images\n\nA long time ago in a galaxy far far away there existed the planet\nhpcloud. In order to breath the atmosphere of this planet VM images had\nto be compatible with the qcow2 0.10 version specification. Since then\nthis planet has been visited by a death star and none of our images are\nexpected to visit planets with this requirement.\n\nGo ahead and stop producing VM images that can live on HPCloud.\n\nNote that our Ubuntu and Debian images had already stopped doing this so\nthis should be safe. Improvements we should see as a result include\nsmaller images.\n\nChange-Id: I6888b478e93021bbede4a647af990774126b0245\n'}]",0,689055,f903e7c6b315d8e2760fd862b5bb95dc86186351,8,4,1,4146,,,0,"Remove qcow2 version 0.10 compat from our images

A long time ago in a galaxy far far away there existed the planet
hpcloud. In order to breath the atmosphere of this planet VM images had
to be compatible with the qcow2 0.10 version specification. Since then
this planet has been visited by a death star and none of our images are
expected to visit planets with this requirement.

Go ahead and stop producing VM images that can live on HPCloud.

Note that our Ubuntu and Debian images had already stopped doing this so
this should be safe. Improvements we should see as a result include
smaller images.

Change-Id: I6888b478e93021bbede4a647af990774126b0245
",git fetch https://review.opendev.org/openstack/project-config refs/changes/55/689055/1 && git format-patch -1 --stdout FETCH_HEAD,['nodepool/nodepool.yaml'],1,f903e7c6b315d8e2760fd862b5bb95dc86186351,remove-qcow2-old-version-compat,, QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10 QEMU_IMG_OPTIONS: compat=0.10,0,9
openstack%2Fopenstack-ansible-os_horizon~master~Ie81888d1838b4d387acdd55ff111d1409a4cd82e,openstack/openstack-ansible-os_horizon,master,Ie81888d1838b4d387acdd55ff111d1409a4cd82e,Author: Shannon Mitchell <shannon.mitchell@rackspace.com> Date: Thu Oct 17 14:07:29 CDT 2019,ABANDONED,2019-10-17 19:09:18.000000000,2019-10-17 19:11:15.000000000,,[],"[{'number': 1, 'created': '2019-10-17 19:09:18.000000000', 'files': ['vars/source_install.yml', 'tasks/horizon_install_source.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/272d6975b91b484b727b04928b587a6eb004cdc7', 'message': 'Author: Shannon Mitchell <shannon.mitchell@rackspace.com>\nDate: Thu Oct 17 14:07:29 CDT 2019\n\n  Broken panel registration fix\n\n  Fixes broken panel registration for source install method\n  due to python 3 changes changing the horizon_lib_dir path\n  dynamically.  This sets horizon_dashboard_panel_dir\n  dynamically based on the changed horizon_lib_dir modification\n  in the horizon_install_source.yml playbook.\n\n  Closes-Bug: 1848561\n\n  Change-Id: Ide5181c14fdc2c67df4df3adaa155d5959b4c468\n\nChange-Id: Ie81888d1838b4d387acdd55ff111d1409a4cd82e\n'}]",0,689246,272d6975b91b484b727b04928b587a6eb004cdc7,2,0,1,21714,,,0,"Author: Shannon Mitchell <shannon.mitchell@rackspace.com>
Date: Thu Oct 17 14:07:29 CDT 2019

  Broken panel registration fix

  Fixes broken panel registration for source install method
  due to python 3 changes changing the horizon_lib_dir path
  dynamically.  This sets horizon_dashboard_panel_dir
  dynamically based on the changed horizon_lib_dir modification
  in the horizon_install_source.yml playbook.

  Closes-Bug: 1848561

  Change-Id: Ide5181c14fdc2c67df4df3adaa155d5959b4c468

Change-Id: Ie81888d1838b4d387acdd55ff111d1409a4cd82e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/46/689246/1 && git format-patch -1 --stdout FETCH_HEAD,"['vars/source_install.yml', 'tasks/horizon_install_source.yml']",2,272d6975b91b484b727b04928b587a6eb004cdc7,bug/1848561,"- name: Set the horizon_dashboard_panel_dir to match the new horizon_lib_dir fact set_fact: horizon_dashboard_panel_dir: ""{{ horizon_lib_dir }}/openstack_dashboard/local/enabled"" ",,5,1
openstack%2Fswift~master~I948d65d0d3b58fcb13f8141fe095ccad4b8f1425,openstack/swift,master,I948d65d0d3b58fcb13f8141fe095ccad4b8f1425,docs: Fix then/than grammar,MERGED,2019-10-17 16:53:31.000000000,2019-10-17 19:07:51.000000000,2019-10-17 19:06:25.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:53:31.000000000', 'files': ['doc/source/cors.rst'], 'web_link': 'https://opendev.org/openstack/swift/commit/2ac50079c1a9f2dfe2db4f9671d823086915e9d2', 'message': 'docs: Fix then/than grammar\n\nChange-Id: I948d65d0d3b58fcb13f8141fe095ccad4b8f1425\nCloses-Bug: #1848485\n'}]",0,689217,2ac50079c1a9f2dfe2db4f9671d823086915e9d2,7,2,1,15343,,,0,"docs: Fix then/than grammar

Change-Id: I948d65d0d3b58fcb13f8141fe095ccad4b8f1425
Closes-Bug: #1848485
",git fetch https://review.opendev.org/openstack/swift refs/changes/17/689217/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/cors.rst'],1,2ac50079c1a9f2dfe2db4f9671d823086915e9d2,bug/1848485,example) make requests to a domain other than the one from where it originated.,example) make requests to a domain other then the one from where it originated.,1,1
openstack%2Fironic~master~I8ce4ac2f1b59fc682feea3a183c7d0e3d075f30d,openstack/ironic,master,I8ce4ac2f1b59fc682feea3a183c7d0e3d075f30d,Setup ipa-builder before building ramdisk,MERGED,2019-10-15 11:27:09.000000000,2019-10-17 19:06:11.000000000,2019-10-16 18:20:26.000000000,"[{'_account_id': 10239}, {'_account_id': 14629}, {'_account_id': 15519}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-15 11:27:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/30286c3eb03557b811a6f4ced108196cb7030fff', 'message': 'Setup ipa-builder before building ramdisk\n\nExtracted the logic to setup the ironic-python-agent-builder\nto a separate function that is called before building ithe ramdisk,\nthis is to avoid errors when deploying locally see [1]\n\n[1] http://paste.openstack.org/show/783890/\n\nChange-Id: I8ce4ac2f1b59fc682feea3a183c7d0e3d075f30d\n'}, {'number': 2, 'created': '2019-10-15 13:39:38.000000000', 'files': ['devstack/lib/ironic'], 'web_link': 'https://opendev.org/openstack/ironic/commit/8dc0a9641401a7c65080d4b45fe850eec3548399', 'message': 'Setup ipa-builder before building ramdisk\n\nExtracted the logic to setup the ironic-python-agent-builder\nto a separate function that is called before building ithe ramdisk,\nthis is to avoid errors when deploying locally see [1]\n\n[1] http://paste.openstack.org/show/783890/\n\nChange-Id: I8ce4ac2f1b59fc682feea3a183c7d0e3d075f30d\n'}]",5,688681,8dc0a9641401a7c65080d4b45fe850eec3548399,15,6,2,15519,,,0,"Setup ipa-builder before building ramdisk

Extracted the logic to setup the ironic-python-agent-builder
to a separate function that is called before building ithe ramdisk,
this is to avoid errors when deploying locally see [1]

[1] http://paste.openstack.org/show/783890/

Change-Id: I8ce4ac2f1b59fc682feea3a183c7d0e3d075f30d
",git fetch https://review.opendev.org/openstack/ironic refs/changes/81/688681/2 && git format-patch -1 --stdout FETCH_HEAD,['devstack/lib/ironic'],1,30286c3eb03557b811a6f4ced108196cb7030fff,clone_ipa," cd $IRONIC_PYTHON_AGENT_BUILDER_DIR/tinyipafunction setup_ipa_builder { echo ""Clonning ironic-python-agent-builder"" git_clone $IRONIC_PYTHON_AGENT_BUILDER_REPO $IRONIC_PYTHON_AGENT_BUILDER_DIR $IRONIC_PYTHON_AGENT_BUILDER_BRANCH export BUILD_AND_INSTALL_TINYIPA=true } # setup IRONIC_PYTHON_AGENT_BUILDER_DIR setup_ipa_builder", git_clone $IRONIC_PYTHON_AGENT_BUILDER_REPO $IRONIC_PYTHON_AGENT_BUILDER_DIR $IRONIC_PYTHON_AGENT_BUILDER_BRANCH cd $IRONIC_PYTHON_AGENT_BUILDER_DIR/tinyipa export BUILD_AND_INSTALL_TINYIPA=true,9,3
openstack%2Ftripleo-ansible~master~Ie8bda685c499ff5ef1dc2799a85287662b5af407,openstack/tripleo-ansible,master,Ie8bda685c499ff5ef1dc2799a85287662b5af407,"paunch: support a directory for ""config"" parameter",MERGED,2019-10-16 00:40:02.000000000,2019-10-17 19:02:41.000000000,2019-10-17 19:02:40.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 8449}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 00:40:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/95e65dd4e33ab086700c04f6eef5fd2d4f911ae5', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 2, 'created': '2019-10-16 03:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/e0f6cbe9a81d93c7dd5f4cedcd6f6f01f88cfe5b', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 3, 'created': '2019-10-16 12:14:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/fd306a6f8f960c58683e1873f08d68340f990b63', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 4, 'created': '2019-10-16 15:05:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/5cdadd7028d4b6a8fcc3ddef353ef81d7bfcfb73', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 5, 'created': '2019-10-16 18:21:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/cb1fde6698667dc4821f9673b37125f6fed8cc81', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 6, 'created': '2019-10-16 18:31:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/2be0dd92ebbf922e3d8c041c4bdf05be710f37ef', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}, {'number': 7, 'created': '2019-10-16 18:35:10.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/paunch.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/6992d5e88030a63920eb06196209ff4a37ce3531', 'message': 'paunch: support a directory for ""config"" parameter\n\nBefore, the ""config"" parameter would only support a JSON file, which\nwould be sent to Paunch via YAML.\nNow, we accept a directory path, where all .json files in that directory\nwill be sent as a single dict into Paunch via YAML.\n\nIt\'s part of the effort to break down the container config into\nindividual files per step and per container.\n\nStory: 2006732\nTask: 37162\nChange-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407\n'}]",2,688837,6992d5e88030a63920eb06196209ff4a37ce3531,26,5,7,3153,,,0,"paunch: support a directory for ""config"" parameter

Before, the ""config"" parameter would only support a JSON file, which
would be sent to Paunch via YAML.
Now, we accept a directory path, where all .json files in that directory
will be sent as a single dict into Paunch via YAML.

It's part of the effort to break down the container config into
individual files per step and per container.

Story: 2006732
Task: 37162
Change-Id: Ie8bda685c499ff5ef1dc2799a85287662b5af407
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/37/688837/5 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/paunch.py'],1,95e65dd4e33ab086700c04f6eef5fd2d4f911ae5,split,"import json import osimport yaml if os.path.isdir(self.config): container_configs = {} config_files = [c_json for c_json in os.listdir(self.config) if cc_json.endswith('.json')] for cf in config_files: with open(os.path.join(self.config, cf), 'r') as f: container_configs.update(yaml.safe_load(f)) self.config_yaml = container_configs else: with open(self.config, 'r') as f: self.config_yaml = yaml.safe_load(f)","import yaml with open(self.config, 'r') as f: self.config_yaml = yaml.safe_load(f)",15,3
openstack%2Fproject-config~master~I8ae788dfc98f5102aefef6b57f2b82e7c50922ac,openstack/project-config,master,I8ae788dfc98f5102aefef6b57f2b82e7c50922ac,Cache repos in /opt/git/opendev.org,MERGED,2019-09-18 15:49:07.000000000,2019-10-17 19:00:49.000000000,2019-10-17 19:00:49.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-18 15:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ced71816486ccc1ed3a96c6ac6fb051deef6e315', 'message': 'Cache repos in /opt/git/opendev.org\n\nThis is what prepare-workspace-git expects.  This change should be\nmerged after we have used the symlink (removed in this change) to\nmigrate to that role.\n\nChange-Id: I8ae788dfc98f5102aefef6b57f2b82e7c50922ac\n'}, {'number': 2, 'created': '2019-09-18 15:54:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/789131f9be38eec6c44d14c69b022ff5699a1ee8', 'message': 'Cache repos in /opt/git/opendev.org\n\nThis is what prepare-workspace-git expects.  This change should be\nmerged after we have used the symlink (removed in this change) to\nmigrate to that role.\n\nChange-Id: I8ae788dfc98f5102aefef6b57f2b82e7c50922ac\nDepends-On: https://review.opendev.org/680696\n'}, {'number': 3, 'created': '2019-09-18 16:09:32.000000000', 'files': ['nodepool/elements/openstack-repos/install.d/50-symlink', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list'], 'web_link': 'https://opendev.org/openstack/project-config/commit/56e6f90b7787ded713c5376f5561328c5719e58f', 'message': 'Cache repos in /opt/git/opendev.org\n\nThis is what prepare-workspace-git expects.  This change should be\nmerged after we have used the symlink (removed in this change) to\nmigrate to that role.\n\nChange-Id: I8ae788dfc98f5102aefef6b57f2b82e7c50922ac\nDepends-On: https://review.opendev.org/680696\n'}]",0,682935,56e6f90b7787ded713c5376f5561328c5719e58f,17,5,3,1,,,0,"Cache repos in /opt/git/opendev.org

This is what prepare-workspace-git expects.  This change should be
merged after we have used the symlink (removed in this change) to
migrate to that role.

Change-Id: I8ae788dfc98f5102aefef6b57f2b82e7c50922ac
Depends-On: https://review.opendev.org/680696
",git fetch https://review.opendev.org/openstack/project-config refs/changes/35/682935/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/openstack-repos/install.d/50-symlink', 'nodepool/elements/openstack-repos/extra-data.d/50-create-repo-list']",2,ced71816486ccc1ed3a96c6ac6fb051deef6e315,prepare-workspace-git," location=os.path.join('/opt/git/opendev.org', project),"," location=os.path.join('/opt/git', project),",1,19
openstack%2Fopenstack-ansible-rabbitmq_server~master~I0b200d57d7c92c959dc90fc540653aed71a6778c,openstack/openstack-ansible-rabbitmq_server,master,I0b200d57d7c92c959dc90fc540653aed71a6778c,PDF Documentation Build tox target,MERGED,2019-10-15 19:49:06.000000000,2019-10-17 18:54:08.000000000,2019-10-17 18:52:59.000000000,"[{'_account_id': 13095}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:49:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/b4df8f09ebd3419b2bdfa2b00cb40858c92b1037', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0b200d57d7c92c959dc90fc540653aed71a6778c\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-16 11:14:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/57fd92976b52caaaa24d501d3f0bd7e65217fdb8', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0b200d57d7c92c959dc90fc540653aed71a6778c\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-16 11:26:08.000000000', 'files': ['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-rabbitmq_server/commit/2332b70d4d1eec224aa833848fd2e7803ef07257', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0b200d57d7c92c959dc90fc540653aed71a6778c\nStory: 2006105\n'}]",0,688798,2332b70d4d1eec224aa833848fd2e7803ef07257,11,3,3,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I0b200d57d7c92c959dc90fc540653aed71a6778c
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-rabbitmq_server refs/changes/98/688798/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,b4df8f09ebd3419b2bdfa2b00cb40858c92b1037,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,4
openstack%2Fopenstack-ansible-openstack_hosts~master~I0ea6477cb62773a1c9c82e77204c9bc72255a892,openstack/openstack-ansible-openstack_hosts,master,I0ea6477cb62773a1c9c82e77204c9bc72255a892,PDF Documentation Build tox target,MERGED,2019-10-17 14:04:00.000000000,2019-10-17 18:45:30.000000000,2019-10-17 18:43:49.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 14:04:00.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_hosts/commit/d71b439ba2708dc333a2733dbc1a828ee75b4137', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}]",0,689162,d71b439ba2708dc333a2733dbc1a828ee75b4137,8,3,1,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_hosts refs/changes/62/689162/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,d71b439ba2708dc333a2733dbc1a828ee75b4137,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,28,6
openstack%2Fopenstack-ansible-lxc_container_create~master~Iabe812ee7e25838132fa2b1e0372df7bb0b0bd0d,openstack/openstack-ansible-lxc_container_create,master,Iabe812ee7e25838132fa2b1e0372df7bb0b0bd0d,PDF Documentation Build tox target,MERGED,2019-10-17 16:30:33.000000000,2019-10-17 18:41:56.000000000,2019-10-17 18:40:50.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:30:33.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/7ac02f39f414e04469057cd0d326b9a5618c3b74', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Iabe812ee7e25838132fa2b1e0372df7bb0b0bd0d\nStory: 2006105\n'}]",0,689211,7ac02f39f414e04469057cd0d326b9a5618c3b74,8,3,1,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Iabe812ee7e25838132fa2b1e0372df7bb0b0bd0d
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/11/689211/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,7ac02f39f414e04469057cd0d326b9a5618c3b74,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,28,6
openstack%2Fopenstack-ansible-ceph_client~master~I7c74939162e03b9ca08aeaf83893c51d0328dc61,openstack/openstack-ansible-ceph_client,master,I7c74939162e03b9ca08aeaf83893c51d0328dc61,PDF Documentation Build tox target,MERGED,2019-10-17 16:41:25.000000000,2019-10-17 18:33:47.000000000,2019-10-17 18:32:35.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:41:25.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-ceph_client/commit/21f85fae9a8d3113137acef81c728fd347688d7a', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I7c74939162e03b9ca08aeaf83893c51d0328dc61\nStory: 2006105\n'}]",0,689214,21f85fae9a8d3113137acef81c728fd347688d7a,8,3,1,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I7c74939162e03b9ca08aeaf83893c51d0328dc61
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-ceph_client refs/changes/14/689214/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,21f85fae9a8d3113137acef81c728fd347688d7a,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,28,6
openstack%2Fansible-role-systemd_networkd~master~I6e5d98ada4d1176b6c32dcbe8b5655e14a839a3d,openstack/ansible-role-systemd_networkd,master,I6e5d98ada4d1176b6c32dcbe8b5655e14a839a3d,PDF Documentation Build tox target,MERGED,2019-10-17 15:09:03.000000000,2019-10-17 18:30:38.000000000,2019-10-17 18:29:13.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 15:09:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/1b6c2fc65a5b250c7cf39971cb1157373bb0f5d4', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I6e5d98ada4d1176b6c32dcbe8b5655e14a839a3d\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-17 15:36:33.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_networkd/commit/658b32023d08e525e7b40b30c1b2dd8e41f9ed71', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I6e5d98ada4d1176b6c32dcbe8b5655e14a839a3d\nStory: 2006105\n'}]",0,689195,658b32023d08e525e7b40b30c1b2dd8e41f9ed71,10,3,2,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I6e5d98ada4d1176b6c32dcbe8b5655e14a839a3d
Story: 2006105
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_networkd refs/changes/95/689195/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,1b6c2fc65a5b250c7cf39971cb1157373bb0f5d4,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,6
openstack%2Fopenstack-helm-images~master~Icb1af8e1b76098c03f751ef265df9d6a1a731cac,openstack/openstack-helm-images,master,Icb1af8e1b76098c03f751ef265df9d6a1a731cac,Correct openstack-exporter image build job,MERGED,2019-10-17 18:07:54.000000000,2019-10-17 18:28:18.000000000,2019-10-17 18:25:01.000000000,"[{'_account_id': 17591}, {'_account_id': 22348}, {'_account_id': 22477}]","[{'number': 1, 'created': '2019-10-17 18:07:54.000000000', 'files': ['zuul.d/prometheus-openstack-exporter.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/07b365a9363498a006fa1eadcea76c1d72911cb0', 'message': ""Correct openstack-exporter image build job\n\nThis change updates two instances of 'xenial' to 'bionic' which\nwere missed in a previous PS.\n\nChange-Id: Icb1af8e1b76098c03f751ef265df9d6a1a731cac\n""}]",0,689237,07b365a9363498a006fa1eadcea76c1d72911cb0,8,3,1,30777,,,0,"Correct openstack-exporter image build job

This change updates two instances of 'xenial' to 'bionic' which
were missed in a previous PS.

Change-Id: Icb1af8e1b76098c03f751ef265df9d6a1a731cac
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/37/689237/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/prometheus-openstack-exporter.yaml'],1,07b365a9363498a006fa1eadcea76c1d72911cb0,POE-zuul-fix," - latest-ubuntu_bionic - ""ubuntu_bionic-{{ currentdate }}"""," - latest-ubuntu_xenial - ""ubuntu_xenial-{{ currentdate }}""",2,2
openstack%2Fopenstack-ansible-memcached_server~master~I0ea6477cb62773a1c9c82e77204c9bc72255a892,openstack/openstack-ansible-memcached_server,master,I0ea6477cb62773a1c9c82e77204c9bc72255a892,PDF Documentation Build tox target,MERGED,2019-10-17 14:29:27.000000000,2019-10-17 18:22:48.000000000,2019-10-17 18:21:11.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 14:29:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/5d8d904f1f96cce21ec1cb30d2a3e7832117399e', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-17 14:38:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/986497fc3da577010a7b55c2cfe2a0395dae4fd3', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-17 15:37:29.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-memcached_server/commit/88bc0fade74cb2eae04ff50e6b11b1e326bf66de', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}]",0,689175,88bc0fade74cb2eae04ff50e6b11b1e326bf66de,12,3,3,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-memcached_server refs/changes/75/689175/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,5d8d904f1f96cce21ec1cb30d2a3e7832117399e,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,29,18
openstack%2Fopenstack-ansible-lxc_hosts~master~Ie582a8d9d1a9fcd5a9766c351c9edb58ade47fd0,openstack/openstack-ansible-lxc_hosts,master,Ie582a8d9d1a9fcd5a9766c351c9edb58ade47fd0,PDF Documentation Build tox target,MERGED,2019-10-17 16:21:48.000000000,2019-10-17 18:22:21.000000000,2019-10-17 18:20:42.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:21:48.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/13e3edf9c1d07520bb321d5e6c4569775be17aa5', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ie582a8d9d1a9fcd5a9766c351c9edb58ade47fd0\nStory: 2006105\n'}]",0,689207,13e3edf9c1d07520bb321d5e6c4569775be17aa5,8,3,1,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Ie582a8d9d1a9fcd5a9766c351c9edb58ade47fd0
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/07/689207/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,13e3edf9c1d07520bb321d5e6c4569775be17aa5,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,28,6
openstack%2Fopenstack-ansible-os_horizon~master~I887bd71b3304a9a9078cf60c48b02b871dd8146f,openstack/openstack-ansible-os_horizon,master,I887bd71b3304a9a9078cf60c48b02b871dd8146f,PDF Documentation Build tox target,MERGED,2019-10-17 16:49:43.000000000,2019-10-17 18:21:53.000000000,2019-10-17 18:20:30.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:49:43.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/b7eaa12dcb5999a63c649c04710e2b7e7f95eb1a', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I887bd71b3304a9a9078cf60c48b02b871dd8146f\nStory: 2006105\n'}]",0,689216,b7eaa12dcb5999a63c649c04710e2b7e7f95eb1a,8,3,1,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I887bd71b3304a9a9078cf60c48b02b871dd8146f
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/16/689216/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,b7eaa12dcb5999a63c649c04710e2b7e7f95eb1a,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,31,22
openstack%2Fansible-role-systemd_service~master~Icaed495dab8520120b06dffa813ee77efb609a09,openstack/ansible-role-systemd_service,master,Icaed495dab8520120b06dffa813ee77efb609a09,PDF Documentation Build tox target,MERGED,2019-10-17 15:13:40.000000000,2019-10-17 18:20:12.000000000,2019-10-17 18:18:42.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 15:13:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/bbc678e3da1e3a838dd371f141e2a867418fa5d5', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Icaed495dab8520120b06dffa813ee77efb609a09\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-17 15:36:10.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-systemd_service/commit/83bff1a16ff2a182943bdc1c6157ee6b0823ad3f', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Icaed495dab8520120b06dffa813ee77efb609a09\nStory: 2006105\n'}]",0,689196,83bff1a16ff2a182943bdc1c6157ee6b0823ad3f,9,3,2,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Icaed495dab8520120b06dffa813ee77efb609a09
Story: 2006105
",git fetch https://review.opendev.org/openstack/ansible-role-systemd_service refs/changes/96/689196/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,bbc678e3da1e3a838dd371f141e2a867418fa5d5,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,6
openstack%2Fopenstack-ansible-lxc_hosts~master~Icf84a0a55654fa890947bae5b608870eddad7324,openstack/openstack-ansible-lxc_hosts,master,Icf84a0a55654fa890947bae5b608870eddad7324,Centos EPEL options default to global variable,MERGED,2019-10-17 14:55:12.000000000,2019-10-17 18:13:50.000000000,2019-10-17 18:12:42.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-17 14:55:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/71dbb7d3b375723fa9db81ae5c183ebe3dd0fb51', 'message': 'Centos EPEL options default to global variable\n\nRepository variables lxc_centos_epel_mirror and lxc_centos_epel_key will\ndefault to centos_epel_mirror and centos_epel_key\n\nChange-Id: Icf84a0a55654fa890947bae5b608870eddad7324\n'}, {'number': 2, 'created': '2019-10-17 15:26:17.000000000', 'files': ['releasenotes/notes/centos-private-epel-3fe4c9ff68ec3a18.yaml', 'defaults/main.yml', 'tasks/lxc_install_yum.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/921c98f67bb6cf61fbb7d1393245ab9e4aac8bdb', 'message': 'Centos EPEL options default to global variable\n\nRepository variables lxc_centos_epel_mirror and lxc_centos_epel_key will\ndefault to centos_epel_mirror and centos_epel_key\n\nChange-Id: Icf84a0a55654fa890947bae5b608870eddad7324\n'}]",0,689191,921c98f67bb6cf61fbb7d1393245ab9e4aac8bdb,13,4,2,23182,,,0,"Centos EPEL options default to global variable

Repository variables lxc_centos_epel_mirror and lxc_centos_epel_key will
default to centos_epel_mirror and centos_epel_key

Change-Id: Icf84a0a55654fa890947bae5b608870eddad7324
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/91/689191/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/centos-private-epel-3fe4c9ff68ec3a18.yaml', 'defaults/main.yml', 'tasks/lxc_install_yum.yml']",3,71dbb7d3b375723fa9db81ae5c183ebe3dd0fb51,centos-private-epel," key: ""{{ lxc_centos_epel_key }}"" baseurl: ""{{ lxc_centos_epel_mirror ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}"""," key: ""{{ lxc_centos_epel_gpg_key | default ('http://download.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7') }}"" baseurl: ""{{ (lxc_centos_epel_mirror | default ('http://download.fedoraproject.org/pub/epel')) ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}""",8,11
openstack%2Fopenstack-ansible-openstack_openrc~master~I6e1bcb984c94f885f7bfa8c78712daadfae3fc39,openstack/openstack-ansible-openstack_openrc,master,I6e1bcb984c94f885f7bfa8c78712daadfae3fc39,PDF Documentation Build tox target,MERGED,2019-10-17 14:42:32.000000000,2019-10-17 18:12:54.000000000,2019-10-17 18:11:27.000000000,"[{'_account_id': 15993}, {'_account_id': 17799}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 14:42:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_openrc/commit/2225f5c5847f82a691b706a3f309ac8f60d0fcf4', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I6e1bcb984c94f885f7bfa8c78712daadfae3fc39\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-17 15:39:39.000000000', 'files': ['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-openstack_openrc/commit/c24af1a2b9c228e2b0a3b54d5e70fed3ca35217d', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I6e1bcb984c94f885f7bfa8c78712daadfae3fc39\nStory: 2006105\n'}]",0,689184,c24af1a2b9c228e2b0a3b54d5e70fed3ca35217d,10,3,2,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I6e1bcb984c94f885f7bfa8c78712daadfae3fc39
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-openstack_openrc refs/changes/84/689184/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/.gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,2225f5c5847f82a691b706a3f309ac8f60d0fcf4,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,6
openstack%2Fkolla-ansible~stable%2Fstein~I169246a6ce8b15af76fd84b32029437016bd3c42,openstack/kolla-ansible,stable/stein,I169246a6ce8b15af76fd84b32029437016bd3c42,Fixes missing boolean for Neutron FWaaS,MERGED,2019-10-17 14:31:39.000000000,2019-10-17 17:58:52.000000000,2019-10-17 17:56:51.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-17 14:31:39.000000000', 'files': ['ansible/roles/neutron/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2e6814eff8a48b8d2c2b78c87862b3a20e13bd52', 'message': 'Fixes missing boolean for Neutron FWaaS\n\nThe missing boolean breaks Neutron FWaaS deployment.\n\nChange-Id: I169246a6ce8b15af76fd84b32029437016bd3c42\nCloses-Bug: #1847562\n(cherry picked from commit 0346dc124e8fec55e0196b69e87ac82991dc1ad1)\n'}]",0,689177,2e6814eff8a48b8d2c2b78c87862b3a20e13bd52,8,3,1,30523,,,0,"Fixes missing boolean for Neutron FWaaS

The missing boolean breaks Neutron FWaaS deployment.

Change-Id: I169246a6ce8b15af76fd84b32029437016bd3c42
Closes-Bug: #1847562
(cherry picked from commit 0346dc124e8fec55e0196b69e87ac82991dc1ad1)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/77/689177/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/neutron/defaults/main.yml'],1,2e6814eff8a48b8d2c2b78c87862b3a20e13bd52,bug/1847562-stable/stein," enabled: ""{{ enable_neutron_fwaas | bool }}"""," enabled: ""{{ enable_neutron_fwaas }}""",1,1
openstack%2Fproject-config~master~I2adbb575592eefe6958157d8fb007d0b50998e82,openstack/project-config,master,I2adbb575592eefe6958157d8fb007d0b50998e82,Remove packethost provider,MERGED,2019-10-17 17:04:48.000000000,2019-10-17 17:56:06.000000000,2019-10-17 17:56:05.000000000,"[{'_account_id': 5263}, {'_account_id': 6547}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 17:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/3a3004b6e4479a18baa3738971b8dac502a621e9', 'message': 'Remove packethost provider\n\nThis provider has already been disabled in these config files by\nsetting max-servers to 0 and diskimages to []. There are errors\nin the nodepool logs about not being able to contact this provider\nnow since it appears disabled/gone, so time to remove the entries.\n\nChange-Id: I2adbb575592eefe6958157d8fb007d0b50998e82\n'}, {'number': 2, 'created': '2019-10-17 17:30:50.000000000', 'files': ['nodepool/nodepool.yaml', 'grafana/create-nodepool.sh', 'grafana/nodepool-packethost.yaml', 'nodepool/nl02.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/c0278edda797d6033905136c17cec7627fcb2ee5', 'message': 'Remove packethost provider\n\nThis provider has already been disabled in these config files by\nsetting max-servers to 0 and diskimages to []. There are errors\nin the nodepool logs about not being able to contact this provider\nnow since it appears disabled/gone, so time to remove the entries.\n\nChange-Id: I2adbb575592eefe6958157d8fb007d0b50998e82\n'}]",0,689220,c0278edda797d6033905136c17cec7627fcb2ee5,11,4,2,3099,,,0,"Remove packethost provider

This provider has already been disabled in these config files by
setting max-servers to 0 and diskimages to []. There are errors
in the nodepool logs about not being able to contact this provider
now since it appears disabled/gone, so time to remove the entries.

Change-Id: I2adbb575592eefe6958157d8fb007d0b50998e82
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/689220/2 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nodepool.yaml', 'nodepool/nl02.openstack.org.yaml']",2,3a3004b6e4479a18baa3738971b8dac502a621e9,remove-packethost,, - name: packethost-us-west-1 region-name: 'us-west-1' cloud: packethost boot-timeout: 120 launch-timeout: 300 clean-floating-ips: true rate: 0.01 diskimages: *provider_diskimages pools: - name: main max-servers: 0 labels: - name: centos-7 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: centos-7 key-name: infra-root-keys-2018-06-15 - name: centos-8 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: centos-8 key-name: infra-root-keys-2018-06-15 - name: debian-buster min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: debian-buster key-name: infra-root-keys-2018-06-15 - name: debian-stretch min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: debian-stretch key-name: infra-root-keys-2018-06-15 - name: fedora-28 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: fedora-28 key-name: infra-root-keys-2018-06-15 - name: fedora-29 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: fedora-29 key-name: infra-root-keys-2018-06-15 - name: fedora-30 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: fedora-30 key-name: infra-root-keys-2018-06-15 - name: gentoo-17-0-systemd min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: gentoo-17-0-systemd key-name: infra-root-keys-2018-06-15 - name: opensuse-150 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: opensuse-150 key-name: infra-root-keys-2018-06-15 - name: opensuse-15 min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: opensuse-15 key-name: infra-root-keys-2018-06-15 - name: opensuse-tumbleweed min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: opensuse-tumbleweed key-name: infra-root-keys-2018-06-15 - name: ubuntu-bionic min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: ubuntu-bionic key-name: infra-root-keys-2018-06-15 - name: ubuntu-trusty min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: ubuntu-trusty key-name: infra-root-keys-2018-06-15 - name: ubuntu-xenial min-ram: 8000 flavor-name: 'zuul-flavor' diskimage: ubuntu-xenial key-name: infra-root-keys-2018-06-15 ,0,89
openstack%2Fpuppet-keystone~master~I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9,openstack/puppet-keystone,master,I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9,New keystone::resource::authtoken::interface parameter,MERGED,2019-10-16 07:53:22.000000000,2019-10-17 17:55:31.000000000,2019-10-17 11:21:35.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 17216}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-10-16 07:53:22.000000000', 'files': ['manifests/resource/authtoken.pp', 'spec/defines/keystone_resource_authtoken_spec.rb', 'releasenotes/notes/authtoken_interface-2e8ccbd3e961e0fb.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-keystone/commit/a8f3616a483db3314dc9b4ed9eeac368814c99fd', 'message': 'New keystone::resource::authtoken::interface parameter\n\nAdds interface parameter to keystone::resource::authtoken allow\nservices to configure the interface to use for the Identity API\nendpoint.\nValid values are ""public"", ""internal"" or ""admin"".\n\nChange-Id: I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9\n'}]",0,688869,a8f3616a483db3314dc9b4ed9eeac368814c99fd,15,8,1,17216,,,0,"New keystone::resource::authtoken::interface parameter

Adds interface parameter to keystone::resource::authtoken allow
services to configure the interface to use for the Identity API
endpoint.
Valid values are ""public"", ""internal"" or ""admin"".

Change-Id: I90584d3b5900d2dc74ae8ae1ff293822e5d6ecd9
",git fetch https://review.opendev.org/openstack/puppet-keystone refs/changes/69/688869/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/resource/authtoken.pp', 'spec/defines/keystone_resource_authtoken_spec.rb', 'releasenotes/notes/authtoken_interface-2e8ccbd3e961e0fb.yaml']",3,a8f3616a483db3314dc9b4ed9eeac368814c99fd,authtoken_interface,"--- features: - | Adds interface parameter to keystone::resource::authtoken allow services to configure the interface to use for the Identity API endpoint. Valid values are ""public"", ""internal"" or ""admin"". ",,16,0
openstack%2Ftraining-guides~master~I886749fff18e2ec058824e16b3d79a629d022b0a,openstack/training-guides,master,I886749fff18e2ec058824e16b3d79a629d022b0a,Tweak Commit Message Exercises,MERGED,2019-10-15 19:20:32.000000000,2019-10-17 17:42:29.000000000,2019-10-17 17:40:47.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 14482}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/f8168a00d3cdd288782ddd713207729d4997ac5e', 'message': 'Tweak Commit Message Exercises\n\nBring task tracking accounts exercses together with these to help direct\nthe patches they will push to the sandbox later.\n\nChange-Id: I886749fff18e2ec058824e16b3d79a629d022b0a\n'}, {'number': 2, 'created': '2019-10-16 19:13:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/d40ea71481da31877bde6e113b9a6461cb333d10', 'message': 'Tweak Commit Message Exercises\n\nBring task tracking accounts exercses together with these to help direct\nthe patches they will push to the sandbox later.\n\nChange-Id: I886749fff18e2ec058824e16b3d79a629d022b0a\n'}, {'number': 3, 'created': '2019-10-17 17:24:11.000000000', 'files': ['doc/upstream-training/source/slides/workflow-setup-git-and-commit-messages.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/442e4d6b8744f8cb3762cb3036b13c4b61ac457b', 'message': 'Tweak Commit Message Exercises\n\nBring task tracking accounts exercses together with these to help direct\nthe patches they will push to the sandbox later.\n\nChange-Id: I886749fff18e2ec058824e16b3d79a629d022b0a\n'}]",5,688789,442e4d6b8744f8cb3762cb3036b13c4b61ac457b,15,5,3,16708,,,0,"Tweak Commit Message Exercises

Bring task tracking accounts exercses together with these to help direct
the patches they will push to the sandbox later.

Change-Id: I886749fff18e2ec058824e16b3d79a629d022b0a
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/89/688789/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/workflow-setup-git-and-commit-messages.rst'],1,f8168a00d3cdd288782ddd713207729d4997ac5e,commit_message_updates," Write a summary line for each bug, blueprint, and story you created during our task tracking exercises. Share them in our IRC channel.Write a commit message body to expand on two of the summary lines you just wrote. Feel free to make up details to make the context more realistic. Share them in IRC.Put the pieces together and finish your commit message! Make sure to include the summary line, body, and the required exernal references along with any optional external references you think it may benefit from. Share the commit message with people at your table. Give them","Write a summary line for each of the following scenarios: - Someone left a print statement that was used for testing during development that is being added to the logs - There are unused arguments being passed into a method that is used in several different files Share both in our IRC channel.Write a commit message body to expand on each of the following summary lines. Feel free to make up details to make the context more realistic. Share your favorite in IRC. - Minimize database queries - Added unit tests to cover untested methodsWrite a commit message for the bug you created during our earlier exercise. Include a summary line, body, and the required exernal references along with any optional external references you think it may benefit from. Share the commit message with one or two people at your table. Give them",13,17
openstack%2Fopenstack-helm-infra~master~Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725,openstack/openstack-helm-infra,master,Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725,Add support for multiple VIPS,ABANDONED,2019-02-28 17:15:31.000000000,2019-10-17 17:42:03.000000000,,"[{'_account_id': 2062}, {'_account_id': 9963}, {'_account_id': 11934}, {'_account_id': 12281}, {'_account_id': 17068}, {'_account_id': 17966}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 24580}]","[{'number': 1, 'created': '2019-02-28 17:15:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/06330a3e5b54bdf1808ee02e7949434cb3e7ce32', 'message': 'Add support for mulitple VIPS\n\nThis adds support for configuring multiple VIPS when installed\nin multi network environment.\n\nChange-Id: Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725\nStory: 2004982\nTask: 29441\n'}, {'number': 2, 'created': '2019-05-02 15:51:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/500178902c73a539192a594fd942a00458d266f0', 'message': 'Add support for multiple VIPS\n\nThis adds support for configuring multiple VIPS when installed\nin multi network environment.\n\nChange-Id: Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725\nStory: 2004982\nTask: 29441\n'}, {'number': 3, 'created': '2019-05-13 14:51:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bc69589e98ada3f733ebe32f200669f176452871', 'message': 'Add support for multiple VIPS\n\nThis adds support for configuring multiple VIPS when installed\nin multi network environment.\n\nChange-Id: Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725\nStory: 2004982\nTask: 29441\n'}, {'number': 4, 'created': '2019-05-21 13:02:09.000000000', 'files': ['ingress/templates/configmap-conf.yaml', 'ingress/templates/endpoints-ingress.yaml', 'ingress/templates/bin/_ingress-vip-keepalived.sh.tpl', 'ingress/templates/bin/_ingress-vip-routed.sh.tpl', 'ingress/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/acdab0cd7f7c4c718d09029e4fb2722f616ecf4b', 'message': 'Add support for multiple VIPS\n\nThis adds support for configuring multiple VIPS when installed\nin multi network environment.\n\nChange-Id: Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725\nStory: 2004982\nTask: 29441\n'}]",11,640115,acdab0cd7f7c4c718d09029e4fb2722f616ecf4b,17,10,4,11934,,,0,"Add support for multiple VIPS

This adds support for configuring multiple VIPS when installed
in multi network environment.

Change-Id: Ia7b777ee26dd7fc00cb3fac4e732f9b698d5f725
Story: 2004982
Task: 29441
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/15/640115/1 && git format-patch -1 --stdout FETCH_HEAD,"['ingress/templates/configmap-conf.yaml', 'ingress/templates/endpoints-ingress.yaml', 'ingress/templates/bin/_ingress-vip-keepalived.sh.tpl', 'ingress/templates/bin/_ingress-vip-routed.sh.tpl', 'ingress/values.yaml']",5,06330a3e5b54bdf1808ee02e7949434cb3e7ce32,," # comma separated lists interfaces: ingress-vip,admin-vip addrs: 172.18.0.1,172.17.0.1", interface: ingress-vip addr: 172.18.0.1/32,57,30
openstack%2Ftraining-guides~master~I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f,openstack/training-guides,master,I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f,Tweak Release Exercises,MERGED,2019-10-15 18:25:10.000000000,2019-10-17 17:34:46.000000000,2019-10-17 17:32:16.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 14482}, {'_account_id': 16708}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 18:25:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/e9c02ca3d8b01239b4d3ab8c00b88d9f4b632176', 'message': ""Tweak Release Exercises\n\nWe don't always ask the questions that are there and we often cover\nones that aren't currently in the slides. This patch bring the questions\nmore in line with the information we normally walk though.\n\nChange-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f\n""}, {'number': 2, 'created': '2019-10-16 19:07:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/6ffa132eb66fd1acfb3fa42f91b89d6142fc5710', 'message': ""Tweak Release Exercises\n\nWe don't always ask the questions that are there and we often cover\nones that aren't currently in the slides. This patch bring the questions\nmore in line with the information we normally walk though.\n\nChange-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f\n""}, {'number': 3, 'created': '2019-10-16 19:41:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/bc8cafae93bb17973f899620fd3d52899552ac24', 'message': ""Tweak Release Exercises\n\nWe don't always ask the questions that are there and we often cover\nones that aren't currently in the slides. This patch bring the questions\nmore in line with the information we normally walk though.\n\nChange-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f\n""}, {'number': 4, 'created': '2019-10-16 19:51:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/0d9a75f12f801682861eb074b88e9baef874f38b', 'message': ""Tweak Release Exercises\n\nWe don't always ask the questions that are there and we often cover\nones that aren't currently in the slides. This patch bring the questions\nmore in line with the information we normally walk though.\n\nChange-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f\n""}, {'number': 5, 'created': '2019-10-16 19:52:55.000000000', 'files': ['doc/upstream-training/source/slides/howitsmade-release-cycle.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ef5d32ff71f84bd250e6b3f90c4f9ee04ea7849a', 'message': ""Tweak Release Exercises\n\nWe don't always ask the questions that are there and we often cover\nones that aren't currently in the slides. This patch bring the questions\nmore in line with the information we normally walk though.\n\nChange-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f\n""}]",10,688777,ef5d32ff71f84bd250e6b3f90c4f9ee04ea7849a,17,5,5,16708,,,0,"Tweak Release Exercises

We don't always ask the questions that are there and we often cover
ones that aren't currently in the slides. This patch bring the questions
more in line with the information we normally walk though.

Change-Id: I6262f4a3b04c8998040e6e057105fd3e1f7d8a9f
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/77/688777/5 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/howitsmade-release-cycle.rst'],1,e9c02ca3d8b01239b4d3ab8c00b88d9f4b632176,releases_exercises,- How many release models are there? - Which two models are most OpenStack projects following?- How long are OpenStack releases 'Maintained' by the community? - What action is done on 'Maintained' branches but not branches that are in 'Extended Maintence'?- Look up the release schedule for the current active and previous OpenStack release cycles - What are the focuses for the three milestones? - Compare the different deadlines for different project activties that are on the release schedules - Why are there different dates for some teams and no dates for others? ,- Look up the release schedule for the current and past two OpenStack release cycles & share links - Identify common characteristics of these cycles- How many release models are there? - Describe and contrast them- How many OpenStack releases are currently maintained by the community? - Post the information on the IRC channel- Find some of the feature proposal freeze deadlines in the current release schedule - Compare the deadlines between two different project teams and discuss the differences with your group - Why are there different dates for some teams? - What are some of the different freeze dates for different activities in the release? Exercise 6 ========== ,13,19
openstack%2Fkeystone~master~I03017b6595199e4af2f6e568ab58089517d689fe,openstack/keystone,master,I03017b6595199e4af2f6e568ab58089517d689fe,Switch to opensuse-15 nodeset,MERGED,2019-10-16 19:42:04.000000000,2019-10-17 17:33:53.000000000,2019-10-17 17:31:06.000000000,"[{'_account_id': 15054}, {'_account_id': 16465}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 19:42:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/acfb602492037a34d9b0ef3a1af8706a57d11220', 'message': 'Switch to opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThe new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,\nchange tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.\n\nChange-Id: I03017b6595199e4af2f6e568ab58089517d689fe\n'}]",0,689019,acfb602492037a34d9b0ef3a1af8706a57d11220,10,3,1,6547,,,0,"Switch to opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

The new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,
change tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.

Change-Id: I03017b6595199e4af2f6e568ab58089517d689fe
",git fetch https://review.opendev.org/openstack/keystone refs/changes/19/689019/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,acfb602492037a34d9b0ef3a1af8706a57d11220,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Ftraining-guides~master~I15b3f6953c6000a6b4064994f8e8d19212c02501,openstack/training-guides,master,I15b3f6953c6000a6b4064994f8e8d19212c02501,Reorder Accounts Exercises,MERGED,2019-10-15 19:09:43.000000000,2019-10-17 17:32:12.000000000,2019-10-17 17:29:37.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 14482}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:09:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/f6e2c13d45ca8fedb25879bcd8875bb891a71bff', 'message': ""Reorder Accounts Exercises\n\nThe phrasing in the current order doesn't make sense.\n\nChange-Id: I15b3f6953c6000a6b4064994f8e8d19212c02501\n""}, {'number': 2, 'created': '2019-10-16 19:10:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/16aefb35f0ae95b77cdecd308ace9bd7baa74197', 'message': ""Reorder Accounts Exercises\n\nThe phrasing in the current order doesn't make sense.\n\nChange-Id: I15b3f6953c6000a6b4064994f8e8d19212c02501\n""}, {'number': 3, 'created': '2019-10-16 19:40:11.000000000', 'files': ['doc/upstream-training/source/slides/workflow-accounts.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/4c37ae2b58b681eb6885ce4f18e7c4ba3fb1fc82', 'message': ""Reorder Accounts Exercises\n\nThe phrasing in the current order doesn't make sense.\n\nChange-Id: I15b3f6953c6000a6b4064994f8e8d19212c02501\n""}]",4,688787,4c37ae2b58b681eb6885ce4f18e7c4ba3fb1fc82,14,4,3,16708,,,0,"Reorder Accounts Exercises

The phrasing in the current order doesn't make sense.

Change-Id: I15b3f6953c6000a6b4064994f8e8d19212c02501
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/87/688787/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/workflow-accounts.rst'],1,f6e2c13d45ca8fedb25879bcd8875bb891a71bff,accounts_exercises, Exercise 2 ========== What can individual Foundation members do that community members can't? Exercise 2,Exercise 1Exercise 2 ========== What can individual Foundation members do that community members can't?,6,5
openstack%2Fnova~stable%2Fqueens~I25616c5761ea625a15d725777ae58175651558f8,openstack/nova,stable/queens,I25616c5761ea625a15d725777ae58175651558f8,lxc: make use of filter python3 compatible,MERGED,2019-08-14 19:25:52.000000000,2019-10-17 17:30:49.000000000,2019-10-17 17:30:48.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14595}, {'_account_id': 16128}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-08-14 19:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/c730be194bfb10d812dcd6c4ee0857f3cd6029bf', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit 4dd4f3228022a1072f8735360eb908abfa6976de)\n'}, {'number': 2, 'created': '2019-10-02 13:41:45.000000000', 'files': ['nova/virt/disk/mount/nbd.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/04bcb98678c1289810f5a8542b5bf9fe7aeeaa12', 'message': 'lxc: make use of filter python3 compatible\n\n_detect_nbd_devices uses the filter\nbuiltin internally to filter valid devices.\n\nIn python 2, filter returns a list. In python 3,\nfilter returns an iterable or generator function.\nThis change eagerly converts the result of calling filter\nto a list to preserve the python 2 behaviour under python 3.\n\nCloses-Bug: #1840068\n\nChange-Id: I25616c5761ea625a15d725777ae58175651558f8\n(cherry picked from commit fc9fb383c16ecb98b1b546f21e7fabb5f00a42ac)\n(cherry picked from commit e135afec851e33148644d024a9d78e56f962efd4)\n(cherry picked from commit 944c08ff764c1cb598dbebbad8aa51bbdd0a692c)\n'}]",0,676500,04bcb98678c1289810f5a8542b5bf9fe7aeeaa12,28,10,2,11604,,,0,"lxc: make use of filter python3 compatible

_detect_nbd_devices uses the filter
builtin internally to filter valid devices.

In python 2, filter returns a list. In python 3,
filter returns an iterable or generator function.
This change eagerly converts the result of calling filter
to a list to preserve the python 2 behaviour under python 3.

Closes-Bug: #1840068

Change-Id: I25616c5761ea625a15d725777ae58175651558f8
(cherry picked from commit fc9fb383c16ecb98b1b546f21e7fabb5f00a42ac)
(cherry picked from commit e135afec851e33148644d024a9d78e56f962efd4)
(cherry picked from commit 944c08ff764c1cb598dbebbad8aa51bbdd0a692c)
",git fetch https://review.opendev.org/openstack/nova refs/changes/00/676500/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/disk/mount/nbd.py', 'nova/tests/unit/virt/disk/mount/test_nbd.py']",2,c730be194bfb10d812dcd6c4ee0857f3cd6029bf,bug/1840068,"def _fake_detect_nbd_devices_none():def _fake_detect_nbd_devices():class NbdTestCaseNoStub(test.NoDBTestCase): @mock.patch('os.listdir') def test_detect_nbd_devices(self, list_dir_mock): list_dir_mock.return_value = _fake_detect_nbd_devices() result = nbd.NbdMount._detect_nbd_devices() self.assertIsNotNone(result) self.assertIsInstance(result, list) self.assertEqual(len(list_dir_mock.return_value), len(result)) for path in list_dir_mock.return_value: self.assertIn(path, result) @mock.patch('os.listdir') def test_detect_nbd_devices_empty(self, list_dir_mock): list_dir_mock.return_value = [ ""nbdz"", ""fake0"", ""not-nbd1""] result = nbd.NbdMount._detect_nbd_devices() self.assertIsNotNone(result) self.assertIsInstance(result, list) self.assertEqual(0, len(result)) free_devices = _fake_detect_nbd_devices()[:]",def _fake_detect_nbd_devices_none(self):def _fake_detect_nbd_devices(self): free_devices = _fake_detect_nbd_devices(None)[:],28,5
openstack%2Fcharm-mysql-innodb-cluster~master~I8a30200a2047146f94af0b45198c07d82f04a1fa,openstack/charm-mysql-innodb-cluster,master,I8a30200a2047146f94af0b45198c07d82f04a1fa,Upstream charm,MERGED,2019-10-16 21:08:50.000000000,2019-10-17 17:19:54.000000000,2019-10-17 17:19:54.000000000,"[{'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-10-16 21:08:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/08dff00ab74f783ea7d8673ec31131c81c95ad6a', 'message': 'Bring charm into upstream\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox and zuul.yaml.\n\nChange-Id: I8a30200a2047146f94af0b45198c07d82f04a1fa\n'}, {'number': 2, 'created': '2019-10-16 21:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/2458aba9d952d0f292218274146735628df9613c', 'message': 'Upstream charm\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox, README and zuul.yaml.\n\nChange-Id: I8a30200a2047146f94af0b45198c07d82f04a1fa\n'}, {'number': 3, 'created': '2019-10-16 22:09:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/05e12bd948a6f743ad5ed98b9e1a27c8bcc42035', 'message': 'Upstream charm\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox, README and zuul.yaml.\n\nChange-Id: I8a30200a2047146f94af0b45198c07d82f04a1fa\n'}, {'number': 4, 'created': '2019-10-17 16:11:09.000000000', 'files': ['src/files/.gitkeep', '.gitreview', 'test-requirements.txt', 'src/tox.ini', 'unit_tests/test_lib_charm_openstack_mysql_innodb_cluster.py', '.zuul.yaml', 'src/test-requirements.txt', 'src/layer.yaml', 'src/README.md', 'requirements.txt', 'src/reactive/mysql_innodb_cluster_handlers.py', 'src/HACKING.md', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-mysql-innodb-cluster/commit/1ad5a1a78e02ba396053e43e234285571f90a1df', 'message': 'Upstream charm\n\nBring charm into alignment with other OpenStack charms.\nUpdates to requirements, tox, README and zuul.yaml.\n\nChange-Id: I8a30200a2047146f94af0b45198c07d82f04a1fa\n'}]",24,689045,1ad5a1a78e02ba396053e43e234285571f90a1df,21,5,4,20805,,,0,"Upstream charm

Bring charm into alignment with other OpenStack charms.
Updates to requirements, tox, README and zuul.yaml.

Change-Id: I8a30200a2047146f94af0b45198c07d82f04a1fa
",git fetch https://review.opendev.org/openstack/charm-mysql-innodb-cluster refs/changes/45/689045/1 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'src/files/.gitkeep', '.gitreview', 'test-requirements.txt', 'src/tox.ini', '.zuul.yaml', 'src/test-requirements.txt', 'src/HACKING.md', 'tox.ini', 'src/layer.yaml']",10,08dff00ab74f783ea7d8673ec31131c81c95ad6a,mysql8,repo: https://opendev.org/openstack/charm-mysql-innodb-cluster,repo: https://github.com/openstack-charmers/charm-mysql-innodb-cluster,65,24
openstack%2Ftripleo-heat-templates~master~I53dec308d359b27e62ed44e91a8eaae38d945a4f,openstack/tripleo-heat-templates,master,I53dec308d359b27e62ed44e91a8eaae38d945a4f,Set bridge-nf-call-* values to 1,MERGED,2019-09-30 18:03:17.000000000,2019-10-17 17:14:09.000000000,2019-10-17 17:12:36.000000000,"[{'_account_id': 3153}, {'_account_id': 5756}, {'_account_id': 6681}, {'_account_id': 6796}, {'_account_id': 6926}, {'_account_id': 11975}, {'_account_id': 12398}, {'_account_id': 13995}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-09-30 18:03:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/9fdd85c4a6fd7a3d737e6ff0dfb335179afee73e', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 2, 'created': '2019-09-30 19:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/13270d91e66e647458a258f5c86727b1b2cb03d0', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 3, 'created': '2019-10-03 16:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/83b9c3dec50f22dfd9943113a572ed73763108ec', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 4, 'created': '2019-10-03 20:40:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e4dd7b9e9b540285f5afdaebd407df24283c12c6', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 5, 'created': '2019-10-08 17:55:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7f5e9166fc164b4bdd2049bb84250d18dcbe7355', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nDepends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 6, 'created': '2019-10-08 18:25:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8c23ac8426c50f5be8a88177def63d2200c25fc8', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nCo-Author: Luke Short <ekultails@gmail.com>\nDepends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb\nDepends-On: I570b996fd8eca8b653c57b43155a6549ba6e5fae\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 7, 'created': '2019-10-11 18:16:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/96302e5d33605f1049ee09efd13a42df9e949156', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nCo-Author: Luke Short <ekultails@gmail.com>\nDepends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 8, 'created': '2019-10-15 23:45:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/57704d2733de645d632b15c5b43a54a2a87ef0da', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nCo-Author: Luke Short <ekultails@gmail.com>\nDepends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}, {'number': 9, 'created': '2019-10-16 14:29:44.000000000', 'files': ['deployment/kernel/kernel-baremetal-ansible.yaml', 'deployment/deprecated/kernel/kernel-baremetal-puppet.yaml', 'releasenotes/notes/fix-bridge-nf-call-defaults.rst'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3d722dbc810b0f9521ce1cfc461789bdfe20e36d', 'message': ""Set bridge-nf-call-* values to 1\n\nAlthough the kernel default is 1, some distros override the defaults\nvia sysctl.conf. Loading br_netfilter manually will show values of\n1, but then doing a 'sysctl network restart' will set the values to\n0--so go ahead and override these values.\n\nCo-Author: Luke Short <ekultails@gmail.com>\nDepends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb\nChange-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f\nCloses-Bug: #1843259\n""}]",1,685766,3d722dbc810b0f9521ce1cfc461789bdfe20e36d,51,13,9,5756,,,0,"Set bridge-nf-call-* values to 1

Although the kernel default is 1, some distros override the defaults
via sysctl.conf. Loading br_netfilter manually will show values of
1, but then doing a 'sysctl network restart' will set the values to
0--so go ahead and override these values.

Co-Author: Luke Short <ekultails@gmail.com>
Depends-On: Ia28f2fdef34e739801c51828c99e9e6598dd2efb
Change-Id: I53dec308d359b27e62ed44e91a8eaae38d945a4f
Closes-Bug: #1843259
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/66/685766/4 && git format-patch -1 --stdout FETCH_HEAD,['deployment/kernel/kernel-baremetal-ansible.yaml'],1,9fdd85c4a6fd7a3d737e6ff0dfb335179afee73e,bug/1843259, BridgeNfCallArpTables: default: 1 description: Configures sysctl net.bridge.bridge-nf-call-arptables key type: number BridgeNfCallIpTables: default: 1 description: Configures sysctl net.bridge.bridge-nf-call-iptables key BridgeNfCallIp6Tables: default: 1 description: Configures sysctl net.bridge.bridge-nf-call-ip6tables key net.bridge.bridge-nf-call-arptables: value: {get_param: BridgeNfCallArpTables} net.bridge.bridge-nf-call-iptables: value: {get_param: BridgeNfCallIpTables} net.bridge.bridge-nf-call-ip6tables: value: {get_param: BridgeNfCallIp6Tables},,16,0
openstack%2Fpython-tripleoclient~master~I052d9958f52479e196d5e5dd4531f3971d7c0eb8,openstack/python-tripleoclient,master,I052d9958f52479e196d5e5dd4531f3971d7c0eb8,Add test for the function check_deprecated_parameters.,MERGED,2019-08-05 05:35:40.000000000,2019-10-17 17:11:00.000000000,2019-10-17 17:07:36.000000000,"[{'_account_id': 7144}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28522}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-08-05 05:35:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/05bd6d53ff00393472f0b028f54537d4f22e7813', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674327\n'}, {'number': 2, 'created': '2019-08-05 10:30:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c2688c866c41da05869bc953df9d9fa9dc1ec5f3', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 3, 'created': '2019-08-28 10:27:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5c8d99a7df1dd79ed92bcff4477f46c894ff353a', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 4, 'created': '2019-09-04 15:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ca6b2157f045703155abb59a6baef29fc1332d42', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 5, 'created': '2019-09-10 11:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b10affa3fff472220bf7a5a643417e737593fb48', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 6, 'created': '2019-09-20 06:36:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f7f35e7657cf69de77eddd599779c356de41c9d6', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 7, 'created': '2019-10-01 12:14:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6f527b198983d0d346e38462282f210f635153d8', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 8, 'created': '2019-10-07 08:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c60cfa845591ef10d2844c0287acc4f6d94593e4', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 9, 'created': '2019-10-07 09:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/872b670019ca86c8c5167cb533cbdde204cf6be2', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 10, 'created': '2019-10-11 10:58:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f7ed970d09ac785f7872881c732e8f1ffaf609e8', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}, {'number': 11, 'created': '2019-10-14 09:47:46.000000000', 'files': ['tripleoclient/tests/workflows/test_parameters.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ddb9970aef5abf111482ac680840665f34ad7a42', 'message': 'Add test for the function check_deprecated_parameters.\n\nAdd test for the function check_deprecated_parameters in workflows\nparameters file. Test the unused_params and invalid_role_specific_params\nparts.\n\nChange-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8\nCloses-Bug: #1838923\nDepends-On: https://review.opendev.org/#/c/674570/\n'}]",0,674531,ddb9970aef5abf111482ac680840665f34ad7a42,56,6,11,29222,,,0,"Add test for the function check_deprecated_parameters.

Add test for the function check_deprecated_parameters in workflows
parameters file. Test the unused_params and invalid_role_specific_params
parts.

Change-Id: I052d9958f52479e196d5e5dd4531f3971d7c0eb8
Closes-Bug: #1838923
Depends-On: https://review.opendev.org/#/c/674570/
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/31/674531/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/workflows/test_parameters.py'],1,05bd6d53ff00393472f0b028f54537d4f22e7813,1838923-add_test_check_deprecated_parameters," def test_check_unused_parameters(self): msg = (""WARNING: Following parameter(s) are defined but not used in"" "" plan. Could be possible that parameter"" "" is valid but currently not used. TestParameter1"") unused_params = [{'parameter': 'TestParameter1', 'unused': True}] self.websocket.wait_for_messages.return_value = iter([{ ""execution_id"": ""IDID"", ""status"": ""SUCCESS"", ""unused"": unused_params }]) with mock.patch('tripleoclient.workflows.parameters.LOG') as mock_log: parameters.check_deprecated_parameters( self.app.client_manager, container='container-name') self.workflow.executions.create.assert_called_once_with( 'tripleo.plan_management.v1.get_deprecated_parameters', workflow_input={'container': 'container-name'}) mock_log.warning.assert_called_once_with(msg) def test_check_unused_multiple_parameters(self): msg = (""WARNING: Following parameter(s) are defined but not used in"" "" plan. Could be possible that parameter"" "" is valid but currently not used. TestParameter1,"" "" TestParameter2"") unused_params = [ {'parameter': 'TestParameter1', 'unused': True}, {'parameter': 'TestParameter2', 'unused': True}] self.websocket.wait_for_messages.return_value = iter([{ ""execution_id"": ""IDID"", ""status"": ""SUCCESS"", ""unused"": unused_params }]) with mock.patch('tripleoclient.workflows.parameters.LOG') as mock_log: parameters.check_deprecated_parameters( self.app.client_manager, container='container-name') self.workflow.executions.create.assert_called_once_with( 'tripleo.plan_management.v1.get_deprecated_parameters', workflow_input={'container': 'container-name'}) mock_log.warning.assert_called_once_with(msg) def test_check_invalid_role_specific_parameters(self): msg = (""WARNING: Following parameter(s) are not supported as"" "" role-specific inputs. TestParameter1"") invalid_role_specific_params = [{ 'parameter': 'TestParameter1', 'invalid_role_specific': True }] self.websocket.wait_for_messages.return_value = iter([{ ""execution_id"": ""IDID"", ""status"": ""SUCCESS"", ""invalid_role_specific"": invalid_role_specific_params }]) with mock.patch('tripleoclient.workflows.parameters.LOG') as mock_log: parameters.check_deprecated_parameters( self.app.client_manager, container='container-name') self.workflow.executions.create.assert_called_once_with( 'tripleo.plan_management.v1.get_deprecated_parameters', workflow_input={'container': 'container-name'}) mock_log.warning.assert_called_once_with(msg) ",,65,0
openstack%2Fpython-tripleoclient~master~I73bb46a5011b188712f931778b3cbc6d0aefc8ca,openstack/python-tripleoclient,master,I73bb46a5011b188712f931778b3cbc6d0aefc8ca,Refactoring the join part.,MERGED,2019-10-07 10:58:10.000000000,2019-10-17 17:09:21.000000000,2019-10-17 17:07:35.000000000,"[{'_account_id': 7144}, {'_account_id': 11491}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}, {'_account_id': 26297}, {'_account_id': 28522}, {'_account_id': 28935}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-10-07 10:58:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fd6aef6ac1fa5923b82eb29cd3addfec2e70f577', 'message': 'Refactoring the join part.\n\nThe format call is not necessary there.\n\nChange-Id: I73bb46a5011b188712f931778b3cbc6d0aefc8ca\n'}, {'number': 2, 'created': '2019-10-16 10:32:46.000000000', 'files': ['tripleoclient/workflows/parameters.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/802624f3fa7519eefab99d3fca94df3aef69c85e', 'message': 'Refactoring the join part.\n\nThe format call is not necessary there.\n\nChange-Id: I73bb46a5011b188712f931778b3cbc6d0aefc8ca\n'}]",0,686998,802624f3fa7519eefab99d3fca94df3aef69c85e,24,10,2,29222,,,0,"Refactoring the join part.

The format call is not necessary there.

Change-Id: I73bb46a5011b188712f931778b3cbc6d0aefc8ca
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/98/686998/2 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/workflows/parameters.py'],1,fd6aef6ac1fa5923b82eb29cd3addfec2e70f577,simplify_join_in_check_deprecated_parameters," deprecated_join = ', '.join(deprecated_params) unused_join = ', '.join(unused_params) invalid_join = ', '.join(invalid_role_specific_params)"," deprecated_join = ', '.join( ['{param}'.format(param=param) for param in deprecated_params]) unused_join = ', '.join( ['{param}'.format(param=param) for param in unused_params]) invalid_join = ', '.join( ['{param}'.format( param=param) for param in invalid_role_specific_params])",3,7
openstack%2Ftripleo-heat-templates~master~I4ea9bfadbcc71c847232c8585d99f8698daffc9a,openstack/tripleo-heat-templates,master,I4ea9bfadbcc71c847232c8585d99f8698daffc9a,"Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""",MERGED,2019-10-03 09:51:24.000000000,2019-10-17 17:07:37.000000000,2019-10-17 17:07:37.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23811}]","[{'number': 1, 'created': '2019-10-03 09:51:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ae5e711b9b0091c82697b817199d76886c8bd742', 'message': 'Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""\n\nInflight validations are now properly deactivated within the tripleoclient/tripleo-common code.\n\nThis reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.\n\nChange-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a\n'}, {'number': 2, 'created': '2019-10-07 06:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dca627129490b562d902259c32c8584ca644623a', 'message': 'Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""\n\nInflight validations are now properly deactivated within the tripleoclient/tripleo-common code.\n\nThis reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.\n\nChange-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a\n'}, {'number': 3, 'created': '2019-10-10 09:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3751911b4577dd368aee32afa0089fa0f4d4b577', 'message': 'Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""\n\nInflight validations are now properly deactivated within the tripleoclient/tripleo-common code.\n\nThis reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.\n\nChange-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a\n'}, {'number': 4, 'created': '2019-10-10 13:59:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c18a4a3159f1fbdaf1f3dd0b001c609e50511857', 'message': 'Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""\n\nInflight validations are now properly deactivated within the\ntripleoclient/tripleo-common code.\n\nThis reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.\n\nChange-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a\n'}, {'number': 5, 'created': '2019-10-15 12:36:05.000000000', 'files': ['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/nova/nova-migration-target-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/nova/nova-scheduler-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/affbe57a8b66e96052930ef6421ebf339988612d', 'message': 'Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""\n\nInflight validations are now properly deactivated within the\ntripleoclient/tripleo-common code.\n\nThis reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.\n\nChange-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a\n'}]",1,686367,affbe57a8b66e96052930ef6421ebf339988612d,22,7,5,28223,,,0,"Revert ""Temporaily disable nova inflight healthchecks to unblock the gate""

Inflight validations are now properly deactivated within the
tripleoclient/tripleo-common code.

This reverts commit 1761fc81c252e3dd565fe4f27e13f2c26426c806.

Change-Id: I4ea9bfadbcc71c847232c8585d99f8698daffc9a
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/67/686367/5 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/nova/nova-migration-target-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/nova/nova-scheduler-container-puppet.yaml']",8,ae5e711b9b0091c82697b817199d76886c8bd742,bug/1842687,, - false,0,8
openstack%2Fsenlin~master~I4b74f97ad5af02dfdb55545275a7fbe8fd9eb73c,openstack/senlin,master,I4b74f97ad5af02dfdb55545275a7fbe8fd9eb73c,Enable health policy checks,MERGED,2019-10-17 02:14:21.000000000,2019-10-17 16:59:04.000000000,2019-10-17 16:56:53.000000000,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-10-17 02:14:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/senlin/commit/427acad1e2fb3a12ed49ae0dfddf3c3e0eec19f7', 'message': 'Enable health policy checks\n\nDepends-On: https://review.opendev.org/#/c/689054/\nChange-Id: I4b74f97ad5af02dfdb55545275a7fbe8fd9eb73c\n'}]",0,689065,427acad1e2fb3a12ed49ae0dfddf3c3e0eec19f7,10,3,1,22623,,,0,"Enable health policy checks

Depends-On: https://review.opendev.org/#/c/689054/
Change-Id: I4b74f97ad5af02dfdb55545275a7fbe8fd9eb73c
",git fetch https://review.opendev.org/openstack/senlin refs/changes/65/689065/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,427acad1e2fb3a12ed49ae0dfddf3c3e0eec19f7,enable_health_test, health_policy_version: '1.1',,1,0
openstack%2Freleases~master~I23519891bb68899a641ed5dd5bd74cfc0cdd9758,openstack/releases,master,I23519891bb68899a641ed5dd5bd74cfc0cdd9758,Release os-traits 1.1.0,MERGED,2019-10-17 16:07:04.000000000,2019-10-17 16:58:06.000000000,2019-10-17 16:58:06.000000000,"[{'_account_id': 11564}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 16:07:04.000000000', 'files': ['deliverables/_independent/os-traits.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/997ab6144206003b685c135b20e5bc07b8693f6b', 'message': 'Release os-traits 1.1.0\n\n...to pick up the COMPUTE_NODE trait https://review.opendev.org/688969\n\nChange-Id: I23519891bb68899a641ed5dd5bd74cfc0cdd9758\n'}]",0,689206,997ab6144206003b685c135b20e5bc07b8693f6b,7,3,1,14070,,,0,"Release os-traits 1.1.0

...to pick up the COMPUTE_NODE trait https://review.opendev.org/688969

Change-Id: I23519891bb68899a641ed5dd5bd74cfc0cdd9758
",git fetch https://review.opendev.org/openstack/releases refs/changes/06/689206/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/os-traits.yaml'],1,997ab6144206003b685c135b20e5bc07b8693f6b,os-traits-1.1.0, - version: 1.1.0 projects: - repo: openstack/os-traits hash: 308fef970233943703dec13970d6022b71c0c0a0,,4,0
openstack%2Fsenlin-tempest-plugin~master~I025aada17db6900d3e4328d5c09890e4f260f4d6,openstack/senlin-tempest-plugin,master,I025aada17db6900d3e4328d5c09890e4f260f4d6,Fix Health Check tests,MERGED,2019-10-16 23:07:01.000000000,2019-10-17 16:50:34.000000000,2019-10-17 16:50:33.000000000,"[{'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-10-16 23:07:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/49189ae02c54cb5fd4bd7d24b46405ce8e0860be', 'message': '[DNM] Testing Health\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}, {'number': 2, 'created': '2019-10-16 23:20:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/71a07d0acecccb5574acf9deaf93ee83f5374f9f', 'message': '[DNM] Testing Health\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}, {'number': 3, 'created': '2019-10-17 00:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/5605d3284546c5c0ccb1726d0fb5c95fa59ed691', 'message': '[DNM] Testing Health\n\nDepends-On: https://review.opendev.org/#/c/688784/\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}, {'number': 4, 'created': '2019-10-17 01:47:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/9a5d6a55acf0bc705d9ba1f2815ba7ff71a257cb', 'message': ""Don't skip Health checks\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n""}, {'number': 5, 'created': '2019-10-17 02:11:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/cc49f85bf42bc7a28c8b643782c0ea22f246dcba', 'message': 'Fix Health Check tests\n\nIntroduced a new configuration variable to set the\nsupported health policy version that is used to\nhelp determine if we can run the health related\ntests.\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}, {'number': 6, 'created': '2019-10-17 02:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/31a6b857cad57ec4937256a234506ebed9ffff33', 'message': 'Fix Health Check tests\n\nIntroduced a new configuration variable to set the\nsupported health policy version that is used to\nhelp determine if we can run the health related\ntests.\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}, {'number': 7, 'created': '2019-10-17 02:51:25.000000000', 'files': ['senlin_tempest_plugin/common/utils.py', 'senlin_tempest_plugin/tests/integration/test_health_policy.py', 'senlin_tempest_plugin/config.py', 'senlin_tempest_plugin/tests/functional/test_health_policy.py'], 'web_link': 'https://opendev.org/openstack/senlin-tempest-plugin/commit/44310b8364949ae2e2a6994ad34d2a28f92650f5', 'message': 'Fix Health Check tests\n\nIntroduced a new configuration variable to set the\nsupported health policy version that is used to\nhelp determine if we can run the health related\ntests.\n\nChange-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6\n'}]",0,689054,44310b8364949ae2e2a6994ad34d2a28f92650f5,16,3,7,22623,,,0,"Fix Health Check tests

Introduced a new configuration variable to set the
supported health policy version that is used to
help determine if we can run the health related
tests.

Change-Id: I025aada17db6900d3e4328d5c09890e4f260f4d6
",git fetch https://review.opendev.org/openstack/senlin-tempest-plugin refs/changes/54/689054/3 && git format-patch -1 --stdout FETCH_HEAD,['senlin_tempest_plugin/tests/integration/test_health_policy.py'],1,49189ae02c54cb5fd4bd7d24b46405ce8e0860be,,"#@testtools.skipUnless(utils.is_policy_supported('senlin.policy.health-1.1'), # ""senlin.policy.health-1.1 is not supported"")","@testtools.skipUnless(utils.is_policy_supported('senlin.policy.health-1.1'), ""senlin.policy.health-1.1 is not supported"")",2,2
openstack%2Fopenstack-helm-images~master~I27de3d7f6b6877430751d33b940de3ead7906dc6,openstack/openstack-helm-images,master,I27de3d7f6b6877430751d33b940de3ead7906dc6,Python 2.7 to 3.x for openstack-exporter,MERGED,2019-10-02 19:07:52.000000000,2019-10-17 16:49:09.000000000,2019-10-17 16:46:09.000000000,"[{'_account_id': 8749}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22636}, {'_account_id': 28618}, {'_account_id': 28849}, {'_account_id': 30692}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-02 19:07:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/f88c24c5e6dcfb8c93c35417c04cd850f4178da5', 'message': '[AICMON-1227] - [WIP] Python 2.7 to 3.x for openstack-exporter\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\n'}, {'number': 2, 'created': '2019-10-03 14:25:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/c5541d8fdc847d2e802df5774797582493f1171a', 'message': '[AICMON-1227] - [WIP] Python 2.7 to 3.x for openstack-exporter\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 3, 'created': '2019-10-03 14:25:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/b35953a7010c7d895cf0c73d727947062a2bc381', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 4, 'created': '2019-10-03 14:26:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/48370914032a159561e0de85a534fbfd7c6bf28d', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 5, 'created': '2019-10-03 15:06:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/11087303f0eca4ebae444d0c43f7d41f9e15ed52', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 6, 'created': '2019-10-03 15:59:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d0245c2c23cc468a0eab63d452746fc13eb71e3f', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 7, 'created': '2019-10-04 20:36:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d5a5819e97cc6cc63c54e1252c09fe29af494266', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 8, 'created': '2019-10-08 14:02:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/0e920e5c6544c8684b8cf279728e5daa36d46ffe', 'message': '[WIP] Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 9, 'created': '2019-10-08 17:58:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/83ad2e7db951f821eb9bec1c9ebecd7850f71d14', 'message': 'Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}, {'number': 10, 'created': '2019-10-16 20:36:25.000000000', 'files': ['prometheus-openstack-exporter/Dockerfile.ubuntu_bionic', 'prometheus-openstack-exporter/Dockerfile.ubuntu_xenial', 'prometheus-openstack-exporter/build.sh', 'prometheus-openstack-exporter/exporter/nova_services.py', 'prometheus-openstack-exporter/exporter/hypervisor_stats.py', 'prometheus-openstack-exporter/exporter/main.py', 'prometheus-openstack-exporter/exporter/neutron_agents.py', 'zuul.d/prometheus-openstack-exporter.yaml', 'prometheus-openstack-exporter/exporter/base.py', 'prometheus-openstack-exporter/exporter/osclient.py', 'prometheus-openstack-exporter/exporter/cinder_services.py', 'prometheus-openstack-exporter/exporter/oscache.py', 'prometheus-openstack-exporter/exporter/check_os_api.py'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/fefb87874064e4fcdecdea370e8dd308171d877f', 'message': 'Python 2.7 to 3.x for openstack-exporter\n\nMake required changes in openstack helm image of\nPrometheus-openstack-exporter to move from python 2.7 to 3.x\n\nChange-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6\nCo-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>\n'}]",15,686252,fefb87874064e4fcdecdea370e8dd308171d877f,36,9,10,30692,,,0,"Python 2.7 to 3.x for openstack-exporter

Make required changes in openstack helm image of
Prometheus-openstack-exporter to move from python 2.7 to 3.x

Change-Id: I27de3d7f6b6877430751d33b940de3ead7906dc6
Co-Authored By: Steven Fitzpatrick <steven.fitzpatrick@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/52/686252/9 && git format-patch -1 --stdout FETCH_HEAD,"['prometheus-openstack-exporter/Dockerfile.ubuntu_xenial', 'prometheus-openstack-exporter/exporter/__init__.py', 'prometheus-openstack-exporter/exporter/base.py', 'prometheus-openstack-exporter/exporter/nova_services.py', 'prometheus-openstack-exporter/exporter/osclient.py', 'prometheus-openstack-exporter/exporter/cinder_services.py', 'prometheus-openstack-exporter/exporter/oscache.py', 'prometheus-openstack-exporter/exporter/hypervisor_stats.py', 'prometheus-openstack-exporter/exporter/check_os_api.py', 'prometheus-openstack-exporter/exporter/main.py', 'prometheus-openstack-exporter/exporter/neutron_agents.py']",11,f88c24c5e6dcfb8c93c35417c04cd850f4178da5,POE-python3-ps7,#!/usr/bin/env python3,#!/usr/bin/env python,24,21
openstack%2Fopenstack-helm-infra~master~I324f9665a24c9383c59376fb77cdb853facd0f18,openstack/openstack-helm-infra,master,I324f9665a24c9383c59376fb77cdb853facd0f18,Update Kubernetes version to 1.16.2,MERGED,2019-09-30 18:43:46.000000000,2019-10-17 16:23:09.000000000,2019-10-17 16:21:23.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 20676}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-09-30 18:43:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2de1244bce07f96bf4b01415a08f71013e7571d2', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-09-30 19:02:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ff8b0a1c0cd27e20f0aa3823e832ad2bdf943781', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-09-30 19:13:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e44f2d72c91e7b931bb09443e44ebb08a858e8fe', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-09-30 20:09:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5badfa7d9139cf9589b9f01bcc68e98846cdd562', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-09-30 20:39:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/000cafd143f4af2db8fb009bb918c4345e2e6731', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 6, 'created': '2019-09-30 21:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d895bb7cc7111157d329b02c8f79d43f4be9c95b', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 7, 'created': '2019-09-30 21:44:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3e8db3ea38e1f0acc48a53dde2c76b39a196a95e', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 8, 'created': '2019-10-01 15:56:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a9971c56c3f81f4949ed68c75cf82f1bf1733aad', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 9, 'created': '2019-10-01 15:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9f991b5d06615ccdbe66908c610f14c03bb1ebe4', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 10, 'created': '2019-10-01 16:13:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/889a9086dda434b5b66044af4a16648ff7df23e9', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 11, 'created': '2019-10-01 17:38:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/11e71b52508e2fa75d02a01bd9c8bd5be8d079f8', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 12, 'created': '2019-10-01 20:11:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/80297adc0e291a9a9b83594ad8e0b3920880c732', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 13, 'created': '2019-10-01 20:58:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/145b20f97fda6fec2fe6e400d7e989efad9bc4d7', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 14, 'created': '2019-10-01 22:05:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6108964b0e81ba9be4c3fbd876dcac131fb61b46', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 15, 'created': '2019-10-02 12:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/99555b46c789d71631ea487fab05872eb26449f7', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 16, 'created': '2019-10-02 12:53:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7bedfe2e080b646dfbd4071f0bc3d3498511bb3d', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 17, 'created': '2019-10-02 13:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c87eeb55681e96ef0ba5a68c83d3886fb8518751', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 18, 'created': '2019-10-02 13:10:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2e0b0edcc0d27c74844b43c91a86086d35a5fdab', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 19, 'created': '2019-10-02 13:47:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f87e0d3c66acb8fe4b1c939a6f1b0c1cddf066b9', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 20, 'created': '2019-10-02 14:18:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9a76ab8f7ec320bb689a9d1752ffa081bcfa8a21', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 21, 'created': '2019-10-02 14:27:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e0026229f2925de20eeff56f4d357f7209690c9f', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 22, 'created': '2019-10-02 14:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/52956a372c6c4608b91c6ad0d56f7e0edf059c89', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 23, 'created': '2019-10-02 15:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/48d5a63fd1dd97b049014579b92ed79b582df46b', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 24, 'created': '2019-10-02 15:36:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/eed71a5ec64d9161628ef2065eee8dc500789b57', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 25, 'created': '2019-10-02 17:24:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/1c7e99667c23e2ca6fbf0fc33d975dd9fb2dbd4b', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 26, 'created': '2019-10-02 17:58:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/715ab9b9dfc2d7c759026c8063efb2be75e0c5a6', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 27, 'created': '2019-10-02 18:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d195079613161837b80594dfd93b5cf2994bc82f', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 28, 'created': '2019-10-02 18:50:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/75d8a87de3e5be73f077ce9340f06cf03cdae69a', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 29, 'created': '2019-10-02 19:12:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/60deaa1b2f679becde900b920f8fcfcf0c9a73d7', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 30, 'created': '2019-10-02 20:12:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/361ec2ab745cbae9e9e3bd5deadbef4bc4072364', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 31, 'created': '2019-10-02 20:27:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9561d2c49fba8984f63bd3798c9209809330df8c', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 32, 'created': '2019-10-04 14:58:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5e3218610fb1ca4679e0b1198d702857e7bfd4a4', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 33, 'created': '2019-10-04 15:41:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c0e399479ac22b708fbef9c24550a9447cd8e993', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 34, 'created': '2019-10-04 17:03:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/294042d0fd5c6f2ff1f30c21bfdd93469d54b51c', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 35, 'created': '2019-10-04 18:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e0058009d134978bc7fea34241cb13bb1c69a010', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 36, 'created': '2019-10-04 18:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/02b21773baf3db57c63e3439dc0091780ab0a910', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 37, 'created': '2019-10-04 19:36:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7597019509c7a6ffd3ed430e5e1e9885151aceee', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 38, 'created': '2019-10-04 19:46:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ad98ed05642dd500e8190078e26debddf0bc3c1f', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 39, 'created': '2019-10-08 13:00:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/99d14fd5a783d8f7cc91a9444d363b700f82e94b', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 40, 'created': '2019-10-11 13:29:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/229c989ba2428070f14dc74ff574396cea06170f', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 41, 'created': '2019-10-14 13:03:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/98ffdf282113a835a67f411d3cb264ab6ef402c9', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 42, 'created': '2019-10-14 13:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/505c17845a34dd1c98156e4ad5505c90a014e34a', 'message': 'WIP: Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 43, 'created': '2019-10-14 13:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3178669431d99e71a890bba2252272d925955957', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 44, 'created': '2019-10-14 13:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/031a42e22996d7a72a8f652673311b1695bef927', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 45, 'created': '2019-10-15 19:01:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/54703f659e16bee7217c45fa97072283142fa1d5', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 46, 'created': '2019-10-16 13:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/18137ebb869afc7c75989eb9110c6c2766a5c3a3', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 47, 'created': '2019-10-16 15:07:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/32db093a65a206f1e8cd83a3ce1df63e38cdfbcd', 'message': 'Update Kubernetes version to 1.16.0\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.0\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 48, 'created': '2019-10-16 19:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/cc15da728a14248f82bb83c048e709754288a0e0', 'message': 'Update Kubernetes version to 1.16.2\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.2\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 49, 'created': '2019-10-16 19:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/84f7a2388d8139b5c4bba651d03b336d5d863c2b', 'message': 'Update Kubernetes version to 1.16.2\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.2\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 50, 'created': '2019-10-16 19:33:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e9086dfb6d683444ec85d6ab9bc2aba665ad55f0', 'message': 'Update Kubernetes version to 1.16.2\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.2\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 51, 'created': '2019-10-16 21:54:53.000000000', 'files': ['elastic-filebeat/templates/daemonset.yaml', 'tools/images/kubeadm-aio/assets/opt/playbooks/vars.yaml', 'ingress/templates/deployment-ingress.yaml', 'registry/values.yaml', 'nfs-provisioner/templates/deployment.yaml', 'tools/images/kubeadm-aio/Dockerfile', 'tools/images/kubeadm-aio/assets/opt/playbooks/roles/deploy-kubeadm-master/templates/kubeadm-conf.yaml.j2', 'tools/deployment/osh-infra-logging/025-ceph-ns-activate.sh', 'roles/build-images/defaults/main.yml', 'fluentd/templates/deployment-fluentd.yaml', 'podsecuritypolicy/templates/podsecuritypolicy.yaml', 'helm-toolkit/templates/manifests/_ingress.tpl', 'elastic-packetbeat/templates/daemonset.yaml', 'tools/deployment/common/005-deploy-k8s.sh', 'fluentbit/templates/daemonset-fluent-bit.yaml', 'mariadb/templates/deployment-ingress.yaml', 'tools/deployment/openstack-support/025-ceph-ns-activate.sh', 'ingress/templates/ingress.yaml', 'falco/templates/daemonset.yaml', 'elastic-metricbeat/templates/daemonset-node-metrics.yaml', 'prometheus-kube-state-metrics/templates/deployment.yaml', 'tools/images/kubeadm-aio/assets/opt/playbooks/roles/deploy-kubelet/templates/10-kubeadm.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c9acad238c084cf993b21ace2f3ce711f091c5b8', 'message': 'Update Kubernetes version to 1.16.2\n\nThis updates the kubeadm and minikube Kubernetes deployments to\ndeploy version 1.16.2\n\nChange-Id: I324f9665a24c9383c59376fb77cdb853facd0f18\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,685775,c9acad238c084cf993b21ace2f3ce711f091c5b8,100,7,51,17591,,,0,"Update Kubernetes version to 1.16.2

This updates the kubeadm and minikube Kubernetes deployments to
deploy version 1.16.2

Change-Id: I324f9665a24c9383c59376fb77cdb853facd0f18
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/75/685775/18 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/common/005-deploy-k8s.sh', 'tools/images/kubeadm-aio/assets/opt/playbooks/vars.yaml', 'tools/images/kubeadm-aio/Dockerfile', 'tools/images/kubeadm-aio/assets/opt/playbooks/roles/deploy-kubeadm-master/templates/kubeadm-conf.yaml.j2', 'roles/build-images/defaults/main.yml', 'tools/images/kubeadm-aio/assets/opt/playbooks/roles/deploy-kubelet/templates/10-kubeadm.conf.j2']",6,2de1244bce07f96bf4b01415a08f71013e7571d2,k8s-1.16.2,"Environment=""KUBELET_SYSTEM_PODS_ARGS=--pod-manifest-path=/etc/kubernetes/manifests --cgroup-driver={{ kubelet_cgroup_driver }}""Environment=""KUBELET_EXTRA_ARGS=--max-pods=220 --pods-per-core=0 --feature-gates=PodShareProcessNamespace=true""","Environment=""KUBELET_SYSTEM_PODS_ARGS=--pod-manifest-path=/etc/kubernetes/manifests --allow-privileged=true --cgroup-driver={{ kubelet_cgroup_driver }}""Environment=""KUBELET_EXTRA_ARGS=--max-pods=220 --pods-per-core=0 --feature-gates=MountPropagation=true --feature-gates=PodShareProcessNamespace=true""",8,12
openstack%2Fopenstack-helm-images~master~Id47448a55866dcf582b9e3801ea5f57f11068242,openstack/openstack-helm-images,master,Id47448a55866dcf582b9e3801ea5f57f11068242,Update osh-selenium for python3,MERGED,2019-10-14 15:56:10.000000000,2019-10-17 16:19:53.000000000,2019-10-17 16:16:50.000000000,"[{'_account_id': 8749}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 28618}, {'_account_id': 30692}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-14 15:56:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/0494dc8db57a972dc430f5d622df3742d90698f3', 'message': '[WIP] Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 2, 'created': '2019-10-14 17:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/3992ad040b31416dbb3307975d9b7935a65199c3', 'message': '[WIP] Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 3, 'created': '2019-10-15 14:41:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/abf26ccfebcd2ed72eb3491f0fdc38face74d8d3', 'message': 'Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 4, 'created': '2019-10-15 16:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/0c7ed2164c847805277a23212522c98b13605598', 'message': 'Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 5, 'created': '2019-10-15 16:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/3dcc502191c501fd5ca8397bf3fb1fef0816761c', 'message': 'Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 6, 'created': '2019-10-16 13:29:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/9c2050c89c83c9032e88752f97bcc37180ab16fc', 'message': 'Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}, {'number': 7, 'created': '2019-10-16 18:35:59.000000000', 'files': ['osh-selenium/build.sh', 'osh-selenium/Dockerfile.ubuntu_bionic', 'zuul.d/osh-selenium.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8c633a76c1b0929e819c0d688e288719b1df3a56', 'message': 'Update osh-selenium for python3\n\nThis change updates the osh-selenium image to be built\non ubuntu:bionic and to use python3 instead of python2\n\nChange-Id: Id47448a55866dcf582b9e3801ea5f57f11068242\n'}]",7,688436,8c633a76c1b0929e819c0d688e288719b1df3a56,32,8,7,30777,,,0,"Update osh-selenium for python3

This change updates the osh-selenium image to be built
on ubuntu:bionic and to use python3 instead of python2

Change-Id: Id47448a55866dcf582b9e3801ea5f57f11068242
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/36/688436/7 && git format-patch -1 --stdout FETCH_HEAD,"['osh-selenium/build.sh', 'osh-selenium/Dockerfile.ubuntu_bionic']",2,0494dc8db57a972dc430f5d622df3742d90698f3,py3-selenium,"FROM docker.io/ubuntu:bionic RUN apt-get -y update \ && apt-get install -y python3 python3-pip unzip wget \ && python3 -m pip install --upgrade pip \ && python3 -m pip install selenium RUN wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add - \ && sh -c 'echo ""deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main"" >> /etc/apt/sources.list.d/google.list' \ && wget --directory-prefix=/tmp/ https://chromedriver.storage.googleapis.com/2.44/chromedriver_linux64.zip \ && unzip /tmp/chromedriver_linux64.zip -d /etc/selenium RUN apt-get -y update \ && apt-get install -y google-chrome-stable \ && apt-get clean \ && rm -rf /var/lib/apt/lists/* ",,17,1
openstack%2Fneutron~stable%2Fstein~I6b3881a77de0419e0c3612661bf60cc2e55da0a7,openstack/neutron,stable/stein,I6b3881a77de0419e0c3612661bf60cc2e55da0a7,switch to the newly created opensuse-15 nodeset,MERGED,2019-10-16 19:15:36.000000000,2019-10-17 16:16:13.000000000,2019-10-17 16:12:11.000000000,"[{'_account_id': 1131}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-16 19:15:36.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f522fa3fa8a793e4acdf9cb8f9382bd7fe8b80a2', 'message': 'switch to the newly created opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThis is the remaining work to be done after https://review.opendev.org/#/c/667539\ngot merged earlier\n\nChange-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7\nDepends-On: https://review.opendev.org/#/c/682843\n(cherry picked from commit 0528068a35b8ffecaf69d1cffb325604b97d30ed)\n'}]",0,689008,f522fa3fa8a793e4acdf9cb8f9382bd7fe8b80a2,16,6,1,6547,,,0,"switch to the newly created opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

This is the remaining work to be done after https://review.opendev.org/#/c/667539
got merged earlier

Change-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7
Depends-On: https://review.opendev.org/#/c/682843
(cherry picked from commit 0528068a35b8ffecaf69d1cffb325604b97d30ed)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/08/689008/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f522fa3fa8a793e4acdf9cb8f9382bd7fe8b80a2,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Fneutron~stable%2Ftrain~I6b3881a77de0419e0c3612661bf60cc2e55da0a7,openstack/neutron,stable/train,I6b3881a77de0419e0c3612661bf60cc2e55da0a7,switch to the newly created opensuse-15 nodeset,MERGED,2019-10-16 19:15:17.000000000,2019-10-17 16:16:06.000000000,2019-10-17 16:12:14.000000000,"[{'_account_id': 1131}, {'_account_id': 6547}, {'_account_id': 6593}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-16 19:15:17.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/e3f83c216aef232a474f4c45862b731846ae3439', 'message': 'switch to the newly created opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThis is the remaining work to be done after https://review.opendev.org/#/c/667539\ngot merged earlier\n\nChange-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7\nDepends-On: https://review.opendev.org/#/c/682843\n(cherry picked from commit 0528068a35b8ffecaf69d1cffb325604b97d30ed)\n'}]",0,689007,e3f83c216aef232a474f4c45862b731846ae3439,16,6,1,6547,,,0,"switch to the newly created opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

This is the remaining work to be done after https://review.opendev.org/#/c/667539
got merged earlier

Change-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7
Depends-On: https://review.opendev.org/#/c/682843
(cherry picked from commit 0528068a35b8ffecaf69d1cffb325604b97d30ed)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/07/689007/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,e3f83c216aef232a474f4c45862b731846ae3439,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Fec2-api~stable%2Ftrain~I83f5c66d80601bd241b2e7e5ed0682c96000c32f,openstack/ec2-api,stable/train,I83f5c66d80601bd241b2e7e5ed0682c96000c32f,Remove version attribute from setup.cfg,MERGED,2019-10-17 14:30:19.000000000,2019-10-17 16:01:16.000000000,2019-10-17 15:59:45.000000000,"[{'_account_id': 10234}, {'_account_id': 13294}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 14:30:19.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/fb16aa422b45e1c1c836f7429dad452ff69ee3cd', 'message': 'Remove version attribute from setup.cfg\n\nThis project uses pbr so it uses git tags and Sem-Ver pseudo header in\ncommit messages. Having versin setup.cfg can lead to conflicts and\nerrors when trying to get the package version using setup.py --version.\n\nNote that pbr provides the Sem-Ver ""magic"" works to bump releases\nwithout adding a tag [1].\n\n[1] https://docs.openstack.org/pbr/latest/user/features.html#version\n\nChange-Id: I83f5c66d80601bd241b2e7e5ed0682c96000c32f\nCloses-Bug: #1848364\n(cherry picked from commit 6e56a244f713cbf8531c6ed79322cf63ab029ea9)\n'}]",0,689176,fb16aa422b45e1c1c836f7429dad452ff69ee3cd,17,4,1,16312,,,0,"Remove version attribute from setup.cfg

This project uses pbr so it uses git tags and Sem-Ver pseudo header in
commit messages. Having versin setup.cfg can lead to conflicts and
errors when trying to get the package version using setup.py --version.

Note that pbr provides the Sem-Ver ""magic"" works to bump releases
without adding a tag [1].

[1] https://docs.openstack.org/pbr/latest/user/features.html#version

Change-Id: I83f5c66d80601bd241b2e7e5ed0682c96000c32f
Closes-Bug: #1848364
(cherry picked from commit 6e56a244f713cbf8531c6ed79322cf63ab029ea9)
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/76/689176/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,fb16aa422b45e1c1c836f7429dad452ff69ee3cd,fix-version-stable/train,,version = 9.0.0,0,1
openstack%2Fneutron~stable%2Fstein~I93f35eade6aa081160902d9d47278123815c04d1,openstack/neutron,stable/stein,I93f35eade6aa081160902d9d47278123815c04d1,Handle ports assigned to routers without routerports,MERGED,2019-10-15 09:18:15.000000000,2019-10-17 15:59:05.000000000,2019-10-17 15:57:15.000000000,"[{'_account_id': 1131}, {'_account_id': 7016}, {'_account_id': 9732}, {'_account_id': 16688}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-15 09:18:15.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/objects/ports.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/626eca984f08b0c073d7a1be29f5075e0324dabe', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n(cherry picked from commit c952b5960001faf98186b630fde75deafe5a7b8f)\n(cherry picked from commit e5650d19bf6ccb87dd7a4c67153a23cca70b3ab3)\n'}]",0,688659,626eca984f08b0c073d7a1be29f5075e0324dabe,13,7,1,16688,,,0,"Handle ports assigned to routers without routerports

In the case of having a port attached to a router but the routerport
register is missing (as seen in the bug reported), this patch retrieves
the full list of ports attached to a router, filtering by router ID
and network ID or port ID. In case of having a port attached to this
router with missing routerport register, a warning message is logged.

Closes-Bug: #1842937

Change-Id: I93f35eade6aa081160902d9d47278123815c04d1
(cherry picked from commit c952b5960001faf98186b630fde75deafe5a7b8f)
(cherry picked from commit e5650d19bf6ccb87dd7a4c67153a23cca70b3ab3)
",git fetch https://review.opendev.org/openstack/neutron refs/changes/59/688659/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/objects/ports.py', 'neutron/tests/unit/db/test_l3_db.py']",3,626eca984f08b0c073d7a1be29f5075e0324dabe,bug/1842937,"from neutron_lib.plugins import constants as plugin_constantsfrom neutron.objects import network as network_obj from neutron.objects import ports as port_objfrom neutron.objects import subnet as subnet_objfrom neutron.tests.unit.db import test_db_base_plugin_v2 class FakeL3Plugin(l3_db.L3_NAT_dbonly_mixin): pass class L3TestCase(test_db_base_plugin_v2.NeutronDbPluginV2TestCase): GET_PORTS_BY_ROUTER_MSG = ( 'The following ports, assigned to router %(router_id)s, do not have a ' '""routerport"" register: %(port_ids)s') def setUp(self, *args, **kwargs): super(L3TestCase, self).setUp(plugin='ml2') self.core_plugin = directory.get_plugin() self.ctx = context.get_admin_context() self.mixin = FakeL3Plugin() directory.add_plugin(plugin_constants.L3, self.mixin) self.network = self.create_network() self.subnets = [] self.subnets.append(self.create_subnet(self.network, '1.1.1.1', '1.1.1.0/24')) self.subnets.append(self.create_subnet(self.network, '1.1.2.1', '1.1.2.0/24')) router = {'router': {'name': 'foo_router', 'admin_state_up': True, 'tenant_id': 'foo_tenant'}} self.router = self.create_router(router) self.ports = [] for subnet in self.subnets: ipa = str(netaddr.IPNetwork(subnet['subnet']['cidr']).ip + 10) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': ipa}] self.ports.append(self.create_port( self.network['network']['id'], {'fixed_ips': fixed_ips})) self.addCleanup(self._clean_objs) def _clean_objs(self): port_obj.Port.delete_objects( self.ctx, network_id=self.network['network']['id']) subnet_obj.Subnet.delete_objects( self.ctx, network_id=self.network['network']['id']) network_obj.Network.get_object( self.ctx, id=self.network['network']['id']).delete() l3_obj.Router.get_object(self.ctx, id=self.router['id']).delete() def create_router(self, router): with self.ctx.session.begin(subtransactions=True): return self.mixin.create_router(self.ctx, router) def create_port(self, net_id, port_info): with self.ctx.session.begin(subtransactions=True): return self._make_port(self.fmt, net_id, **port_info) def create_network(self, name=None, **kwargs): name = name or 'network1' with self.ctx.session.begin(subtransactions=True): return self._make_network(self.fmt, name, True, **kwargs) def create_subnet(self, network, gateway, cidr, **kwargs): with self.ctx.session.begin(subtransactions=True): return self._make_subnet(self.fmt, network, gateway, cidr, **kwargs) def _add_router_interfaces(self): return [self.mixin.add_router_interface( self.ctx, self.router['id'], interface_info={'port_id': port['port']['id']}) for port in self.ports] def _check_routerports(self, ri_statuses): port_ids = [] for idx, ri_status in enumerate(ri_statuses): rp_obj = l3_obj.RouterPort.get_object( self.ctx, port_id=self.ports[idx]['port']['id'], router_id=self.router['id']) if ri_status: self.assertEqual(self.ports[idx]['port']['id'], rp_obj.port_id) port_ids.append(rp_obj.port_id) else: self.assertIsNone(rp_obj) _router_obj = l3_obj.Router.get_object(self.ctx, id=self.router['id']) router_port_ids = [rp.port_id for rp in _router_obj.db_obj.attached_ports] self.assertEqual(sorted(port_ids), sorted(router_port_ids)) @mock.patch.object(port_obj, 'LOG') def test_remove_router_interface_by_port(self, mock_log): self._add_router_interfaces() self._check_routerports((True, True)) interface_info = {'port_id': self.ports[0]['port']['id']} self.mixin.remove_router_interface(self.ctx, self.router['id'], interface_info) mock_log.warning.assert_not_called() self._check_routerports((False, True)) @mock.patch.object(port_obj, 'LOG') def test_remove_router_interface_by_port_removed_rport(self, mock_log): self._add_router_interfaces() self._check_routerports((True, True)) rp_obj = l3_obj.RouterPort.get_object( self.ctx, router_id=self.router['id'], port_id=self.ports[0]['port']['id']) rp_obj.delete() interface_info = {'port_id': self.ports[0]['port']['id']} self.mixin.remove_router_interface(self.ctx, self.router['id'], interface_info) msg_vars = {'router_id': self.router['id'], 'port_ids': {self.ports[0]['port']['id']}} mock_log.warning.assert_called_once_with(self.GET_PORTS_BY_ROUTER_MSG, msg_vars) self._check_routerports((False, True)) @mock.patch.object(port_obj, 'LOG') def test_remove_router_interface_by_subnet(self, mock_log): self._add_router_interfaces() self._check_routerports((True, True)) interface_info = {'subnet_id': self.subnets[1]['subnet']['id']} self.mixin.remove_router_interface(self.ctx, self.router['id'], interface_info) mock_log.warning.not_called_once() self._check_routerports((True, False)) @mock.patch.object(port_obj, 'LOG') def test_remove_router_interface_by_subnet_removed_rport(self, mock_log): self._add_router_interfaces() self._check_routerports((True, True)) rp_obj = l3_obj.RouterPort.get_object( self.ctx, router_id=self.router['id'], port_id=self.ports[0]['port']['id']) rp_obj.delete() interface_info = {'subnet_id': self.subnets[0]['subnet']['id']} self.mixin.remove_router_interface(self.ctx, self.router['id'], interface_info) msg_vars = {'router_id': self.router['id'], 'port_ids': {self.ports[0]['port']['id']}} mock_log.warning.assert_called_once_with(self.GET_PORTS_BY_ROUTER_MSG, msg_vars) self._check_routerports((False, True))",,240,53
openstack%2Fmetalsmith~master~Ic9949928d51a442d92913bdd988a7cae4fd75d50,openstack/metalsmith,master,Ic9949928d51a442d92913bdd988a7cae4fd75d50,Add ironic-python-agent-builder to required-projects,MERGED,2019-10-17 11:42:46.000000000,2019-10-17 15:56:06.000000000,2019-10-17 15:53:25.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 11:42:46.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/metalsmith/commit/3d24ba84956a6c4f43db45be95cc0ebb6605f2c9', 'message': ""Add ironic-python-agent-builder to required-projects\n\nIt's not unconditionally used in the ironic devstack plugin.\n\nChange-Id: Ic9949928d51a442d92913bdd988a7cae4fd75d50\n""}]",0,689130,3d24ba84956a6c4f43db45be95cc0ebb6605f2c9,7,2,1,10239,,,0,"Add ironic-python-agent-builder to required-projects

It's not unconditionally used in the ironic devstack plugin.

Change-Id: Ic9949928d51a442d92913bdd988a7cae4fd75d50
",git fetch https://review.opendev.org/openstack/metalsmith refs/changes/30/689130/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,3d24ba84956a6c4f43db45be95cc0ebb6605f2c9,gate2, - openstack/ironic-python-agent-builder,,1,0
openstack%2Fdevstack~master~I452f6016fbdb10c8cda1d81d134dccb77509402f,openstack/devstack,master,I452f6016fbdb10c8cda1d81d134dccb77509402f,Stop installing LIBS_FROM_GIT on both Python 2 and 3,ABANDONED,2019-10-09 15:16:41.000000000,2019-10-17 15:53:27.000000000,,"[{'_account_id': 7118}, {'_account_id': 8556}, {'_account_id': 13252}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 15:16:41.000000000', 'files': ['inc/python'], 'web_link': 'https://opendev.org/openstack/devstack/commit/24f9a42795994818cb748152c498388bdc36f93b', 'message': ""Stop installing LIBS_FROM_GIT on both Python 2 and 3\n\nWe're in Ussuri, which means we should be able to drop support for\nPython 2. To do this, we need to essentially revert commit\na2eb89417fbb6d61526b1819cbe3d0a60537eedd since it should no longer be\nnecessary.\n\nChange-Id: I452f6016fbdb10c8cda1d81d134dccb77509402f\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\n""}]",0,687585,24f9a42795994818cb748152c498388bdc36f93b,11,5,1,15334,,,0,"Stop installing LIBS_FROM_GIT on both Python 2 and 3

We're in Ussuri, which means we should be able to drop support for
Python 2. To do this, we need to essentially revert commit
a2eb89417fbb6d61526b1819cbe3d0a60537eedd since it should no longer be
necessary.

Change-Id: I452f6016fbdb10c8cda1d81d134dccb77509402f
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
",git fetch https://review.opendev.org/openstack/devstack refs/changes/85/687585/1 && git format-patch -1 --stdout FETCH_HEAD,['inc/python'],1,24f9a42795994818cb748152c498388bdc36f93b,python3-everywhere,," if python3_enabled; then # Turn off Python 3 mode and install the package again, # forcing a Python 2 installation. This ensures that all libs # being used for development are installed under both versions # of Python. echo ""Installing $name again without Python 3 enabled"" USE_PYTHON3=False setup_develop $bindep $dir USE_PYTHON3=True fi",0,10
openstack%2Fos-traits~master~I036dd5cab15144447df5346814d5f0e8fd91135d,openstack/os-traits,master,I036dd5cab15144447df5346814d5f0e8fd91135d,Add COMPUTE_NODE trait,MERGED,2019-10-16 16:22:12.000000000,2019-10-17 15:48:50.000000000,2019-10-17 15:47:31.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 9708}, {'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 16:22:12.000000000', 'files': ['os_traits/compute/__init__.py'], 'web_link': 'https://opendev.org/openstack/os-traits/commit/308fef970233943703dec13970d6022b71c0c0a0', 'message': 'Add COMPUTE_NODE trait\n\nWe have at least one use case [1] for identifying resource providers\nwhich represent compute nodes. There are a few ways we could do that\nhackishly (e.g. [2], [3]) but the clean way is to have nova-compute mark\nthe provider with a trait, since nova-compute knows which one it is\nanyway.\n\nThis commit adds a COMPUTE_NODE trait for this purpose.\n\n[1] https://review.opendev.org/#/c/670112/7/nova/cmd/manage.py@2921\n[2] Assume a provider with a certain resource class, like MEMORY_MB, is\nalways a compute node. This is not necessarily future-proof (maybe all\nMEMORY_MB will someday reside on NUMA node providers; similar for other\nresource classes) and isn\'t necessarily true in all cases today anyway\n(ironic nodes don\'t have MEMORY_MB inventory) and there\'s also currently\nno easy way to query for that (GET /resource_providers?MEMORY_MB:1 won\'t\nreturn ""full"" providers, and you can\'t ask for :0).\n[3] Assume a root provider without the MISC_SHARES_VIA_AGGREGATE trait\nis a compute node. This assumes you\'re only using placement for nova-ish\nthings.\n\nChange-Id: I036dd5cab15144447df5346814d5f0e8fd91135d\n'}]",0,688969,308fef970233943703dec13970d6022b71c0c0a0,13,6,1,14070,,,0,"Add COMPUTE_NODE trait

We have at least one use case [1] for identifying resource providers
which represent compute nodes. There are a few ways we could do that
hackishly (e.g. [2], [3]) but the clean way is to have nova-compute mark
the provider with a trait, since nova-compute knows which one it is
anyway.

This commit adds a COMPUTE_NODE trait for this purpose.

[1] https://review.opendev.org/#/c/670112/7/nova/cmd/manage.py@2921
[2] Assume a provider with a certain resource class, like MEMORY_MB, is
always a compute node. This is not necessarily future-proof (maybe all
MEMORY_MB will someday reside on NUMA node providers; similar for other
resource classes) and isn't necessarily true in all cases today anyway
(ironic nodes don't have MEMORY_MB inventory) and there's also currently
no easy way to query for that (GET /resource_providers?MEMORY_MB:1 won't
return ""full"" providers, and you can't ask for :0).
[3] Assume a root provider without the MISC_SHARES_VIA_AGGREGATE trait
is a compute node. This assumes you're only using placement for nova-ish
things.

Change-Id: I036dd5cab15144447df5346814d5f0e8fd91135d
",git fetch https://review.opendev.org/openstack/os-traits refs/changes/69/688969/1 && git format-patch -1 --stdout FETCH_HEAD,['os_traits/compute/__init__.py'],1,308fef970233943703dec13970d6022b71c0c0a0,COMPUTE_NODE," # A provider with this trait is a compute *node*. (As distinct from # ""compute host"" or ""hypervisor"". These may be synonymous in some cases, # but the distinction matters e.g. when using the ironic virt driver.) 'NODE',",,4,0
openstack%2Fopenstack-helm~master~I2f93f9c9ddcb236a233cba391add0de33bbae350,openstack/openstack-helm,master,I2f93f9c9ddcb236a233cba391add0de33bbae350,Armada: Update OSH manifest pre delete actions,ABANDONED,2019-09-11 13:06:06.000000000,2019-10-17 15:45:19.000000000,,"[{'_account_id': 12281}, {'_account_id': 17499}, {'_account_id': 17591}, {'_account_id': 21420}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 28543}, {'_account_id': 28618}, {'_account_id': 28849}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-09-11 13:06:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/bd0fdd1bc84ffde196ce4a6321be19330fe58dbc', 'message': 'Armada: Update OSH manifest pre delete actions\n\nThis updates the armada-osh manifest to include pre delete actions\nfor helm test pods that were missed. This also updates the nova\nand neutron pre delete actions to target all jobs for deletion\nusing the release_group label instead of declaring each job\nindividually\n\nChange-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 2, 'created': '2019-09-16 13:31:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/36332f44f461e5bd32d4f29d399c2712751b8a45', 'message': 'Armada: Update OSH manifest pre delete actions\n\nThis updates the armada-osh manifest to include pre delete actions\nfor helm test pods that were missed. This also updates the nova\nand neutron pre delete actions to target all jobs for deletion\nusing the release_group label instead of declaring each job\nindividually\n\nChange-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 3, 'created': '2019-09-18 12:52:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/76d8ffde7d189f9c7c8bdab770a982eb9906bf6f', 'message': 'Armada: Update OSH manifest pre delete actions\n\nThis updates the armada-osh manifest to include pre delete actions\nfor helm test pods that were missed. This also updates the nova\nand neutron pre delete actions to target all jobs for deletion\nusing the release_group label instead of declaring each job\nindividually\n\nChange-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 4, 'created': '2019-09-19 13:52:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5d85d83b8c40d0cd7ddb1412b160f5ef8bcb3506', 'message': 'Armada: Update OSH manifest pre delete actions\n\nThis updates the armada-osh manifest to include pre delete actions\nfor helm test pods that were missed. This also updates the nova\nand neutron pre delete actions to target all jobs for deletion\nusing the release_group label instead of declaring each job\nindividually\n\nChange-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}, {'number': 5, 'created': '2019-10-14 13:45:32.000000000', 'files': ['tools/deployment/armada/manifests/armada-osh.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/fd396f5a642f38541585ef839ae70c43c8b844bd', 'message': 'Armada: Update OSH manifest pre delete actions\n\nThis updates the armada-osh manifest to include pre delete actions\nfor helm test pods that were missed. This also updates the nova\nand neutron pre delete actions to target all jobs for deletion\nusing the release_group label instead of declaring each job\nindividually\n\nChange-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350\nSigned-off-by: Steve Wilkerson <sw5822@att.com>\n'}]",0,681467,fd396f5a642f38541585ef839ae70c43c8b844bd,30,10,5,17591,,,0,"Armada: Update OSH manifest pre delete actions

This updates the armada-osh manifest to include pre delete actions
for helm test pods that were missed. This also updates the nova
and neutron pre delete actions to target all jobs for deletion
using the release_group label instead of declaring each job
individually

Change-Id: I2f93f9c9ddcb236a233cba391add0de33bbae350
Signed-off-by: Steve Wilkerson <sw5822@att.com>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/67/681467/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/armada/manifests/armada-osh.yaml'],1,bd0fdd1bc84ffde196ce4a6321be19330fe58dbc,osh-armada-updates, - type: pod labels: release_group: osh-openstack-ceph-config component: test - type: pod labels: release_group: osh-mariadb component: test - type: pod labels: release_group: osh-radosgw-openstack component: test release_group: osh-nova - type: pod labels: release_group: osh-nova component: test release_group: osh-neutron - type: pod labels: release_group: osh-neutron component: test, application: nova component: db-init - type: job labels: application: nova component: db-sync - type: job labels: application: nova component: ks-user - type: job labels: application: nova component: ks-service - type: job labels: application: nova component: ks-endpoints - type: job labels: application: placement component: ks-user - type: job labels: application: placement component: ks-service - type: job labels: application: placement component: ks-endpoints - type: job labels: application: nova component: cell-setup application: neutron component: db-init - type: job labels: application: neutron component: db-sync - type: job labels: application: neutron component: ks-user - type: job labels: application: neutron component: ks-service - type: job labels: application: neutron component: ks-endpoints,20,50
openstack%2Fproject-config~master~Ic01915d85c0978bd962f9159f5a2ddfc7a53e787,openstack/project-config,master,Ic01915d85c0978bd962f9159f5a2ddfc7a53e787,Add OVN charms,MERGED,2019-10-10 15:00:18.000000000,2019-10-17 15:44:29.000000000,2019-10-17 15:44:28.000000000,"[{'_account_id': 935}, {'_account_id': 1004}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-10 15:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/985f198db0e55c118a704bd8d73bd8316327d1dd', 'message': 'Add OVN charms\n\nNeeded-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db\nChange-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787\n'}, {'number': 2, 'created': '2019-10-10 15:17:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/59bbfd4e38b35aee2f45100a14f9897161c65fb0', 'message': 'Add OVN charms\n\nNeeded-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db\nChange-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787\n'}, {'number': 3, 'created': '2019-10-10 18:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/c56c3f5666e86cd0d3a8be24c72b675a0fe966be', 'message': 'Add OVN charms\n\nNeeded-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db\nChange-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787\n'}, {'number': 4, 'created': '2019-10-10 19:07:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/cae2d57c069c9eb26c06cbf849ff4fd18dc11201', 'message': 'Add OVN charms\n\nNeeded-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db\nChange-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787\n'}, {'number': 5, 'created': '2019-10-10 19:09:38.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/9663354b14744b3d72ba813c91e50779c4514055', 'message': 'Add OVN charms\n\nNeeded-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db\nChange-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787\n'}]",1,687925,9663354b14744b3d72ba813c91e50779c4514055,14,4,5,13686,,,0,"Add OVN charms

Needed-By: Ief1de4be550c852ba6daa9c5f25ff06a2dffb3db
Change-Id: Ic01915d85c0978bd962f9159f5a2ddfc7a53e787
",git fetch https://review.opendev.org/openstack/project-config refs/changes/25/687925/2 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/main.yaml']",2,985f198db0e55c118a704bd8d73bd8316327d1dd,project-update, - openstack/charm-neutron-api-plugin-ovn - x/charm-ovn-central - x/charm-ovn-chassis - x/charm-ovn-dedicated-chassis,,29,0
openstack%2Fcharm-guide~master~I6fae01401ddc3824796c2fe04af81b3c2551e0d6,openstack/charm-guide,master,I6fae01401ddc3824796c2fe04af81b3c2551e0d6,Add 19.10 release notes for Placement charm,MERGED,2019-10-08 18:39:27.000000000,2019-10-17 15:27:52.000000000,2019-10-17 15:26:49.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20635}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-10-08 18:39:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/969083a939e112daa67fdf66e1c66e0a9f3b1b56', 'message': 'Add 19.10 release notes for Placement charm\n\nChange-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6\n'}, {'number': 2, 'created': '2019-10-08 20:01:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/2b28ecd87df6eff38a9fc63c00e443d9c48b18d0', 'message': 'Add 19.10 release notes for Placement charm\n\nChange-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6\n'}, {'number': 3, 'created': '2019-10-08 20:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/e4ee486a2128f1d2c300fdea6ac9e969d374fbed', 'message': 'Add 19.10 release notes for Placement charm\n\nChange-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6\n'}, {'number': 4, 'created': '2019-10-08 20:17:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/22c9f954df54a132c827ce5deb5dbfcde367ac62', 'message': 'Add 19.10 release notes for Placement charm\n\nChange-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6\n'}, {'number': 5, 'created': '2019-10-11 19:34:12.000000000', 'files': ['doc/source/1910.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/9ffe7f23c490061718442dc3d0659557e7628451', 'message': 'Add 19.10 release notes for Placement charm\n\nChange-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6\n'}]",10,687382,9ffe7f23c490061718442dc3d0659557e7628451,21,5,5,11805,,,0,"Add 19.10 release notes for Placement charm

Change-Id: I6fae01401ddc3824796c2fe04af81b3c2551e0d6
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/82/687382/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/1910.rst'],1,969083a939e112daa67fdf66e1c66e0a9f3b1b56,charms-train-placement,"* placementPlease note the Placement charm must be deployed alongside nova-cloud-controller as of OpenStack Train. See `Placement Charm` for more details. Placement Charm --------------- The 19.10 OpenStack Charms release introduces a new charm for the Placement API. The Placement API code was removed from the Nova project in OpenStack Train and has been split into its own project. The Placement charm must be deployed alongside the nova-cloud-controller charm for OpenStack Train deployments. Please see `Upgrading OpenStack` for more details introducing the Placement charm into existing deployments when upgrading to OpenStack Train. Prior to upgrading nova-cloud-controller to Train, the placement charm must first be deployed for Train. Once the placement charm is deployed for Train, nova-cloud-controller can then be upgraded to Train: .. code:: bash juju deploy --series bionic --config openstack-origin=cloud:bionic-train cs:placement juju config nova-cloud-controller openstack-origin=cloud:bionic-train ",,23,0
openstack%2Fopenstack-helm~master~If549d4c6924c990d1a48bca193935ed9a2ed6864,openstack/openstack-helm,master,If549d4c6924c990d1a48bca193935ed9a2ed6864,"[horizon] enable the Apache ""Header"" module by default",MERGED,2019-10-16 18:00:18.000000000,2019-10-17 15:27:05.000000000,2019-10-17 15:25:37.000000000,"[{'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 18:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/ce1cbfaa1af7c040ad6f41c9abf6f287fce508c8', 'message': '[horizon] enable the Apache ""Header"" module by default\n\nSome configuration when enable will explicitly set headers, for this\nto work the header module should be enabled.\n\nChange-Id: If549d4c6924c990d1a48bca193935ed9a2ed6864\n'}, {'number': 2, 'created': '2019-10-16 21:45:35.000000000', 'files': ['horizon/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/be3a4f65de6faba22a25d9bb5d9ed1e4247b97ed', 'message': '[horizon] enable the Apache ""Header"" module by default\n\nSome configuration when enable will explicitly set headers, for this\nto work the header module should be enabled.\n\nChange-Id: If549d4c6924c990d1a48bca193935ed9a2ed6864\n'}]",0,688993,be3a4f65de6faba22a25d9bb5d9ed1e4247b97ed,12,3,2,8898,,,0,"[horizon] enable the Apache ""Header"" module by default

Some configuration when enable will explicitly set headers, for this
to work the header module should be enabled.

Change-Id: If549d4c6924c990d1a48bca193935ed9a2ed6864
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/93/688993/1 && git format-patch -1 --stdout FETCH_HEAD,['horizon/values.yaml'],1,ce1cbfaa1af7c040ad6f41c9abf6f287fce508c8,hzn-enable-headers, - headers,,1,0
openstack%2Fopenstack-ansible-lxc_hosts~master~Icb4e14664e41911c480c920d2f007f5d43425986,openstack/openstack-ansible-lxc_hosts,master,Icb4e14664e41911c480c920d2f007f5d43425986,Make centos_epel_mirror usable in CI,ABANDONED,2019-10-17 10:50:41.000000000,2019-10-17 15:25:49.000000000,,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 23182}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-17 10:50:41.000000000', 'files': ['defaults/main.yml', 'tasks/lxc_install_yum.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/5ca0d4a0ecba851141ec8589341794763f9c1740', 'message': 'Make centos_epel_mirror usable in CI\n\nAs we use centos_epel_mirror to globaly override mirror in CI,\nwe need to return ability to use it. If centos_epel_mirror\nis not defined, default repo will be used instead.\n\nChange-Id: Icb4e14664e41911c480c920d2f007f5d43425986\n'}]",0,689122,5ca0d4a0ecba851141ec8589341794763f9c1740,8,4,1,28619,,,0,"Make centos_epel_mirror usable in CI

As we use centos_epel_mirror to globaly override mirror in CI,
we need to return ability to use it. If centos_epel_mirror
is not defined, default repo will be used instead.

Change-Id: Icb4e14664e41911c480c920d2f007f5d43425986
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/22/689122/1 && git format-patch -1 --stdout FETCH_HEAD,"['defaults/main.yml', 'tasks/lxc_install_yum.yml']",2,5ca0d4a0ecba851141ec8589341794763f9c1740,centos-private-epel," key: ""{{ lxc_centos_epel_gpg_key }}"" baseurl: ""{{ lxc_centos_epel_mirror ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}"""," key: ""{{ lxc_centos_epel_gpg_key | default ('http://download.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7') }}"" baseurl: ""{{ (lxc_centos_epel_mirror | default ('http://download.fedoraproject.org/pub/epel')) ~ '/' ~ ansible_distribution_major_version ~ '/' ~ ansible_architecture }}""",4,4
openstack%2Fcharm-openstack-dashboard~master~I4e19e7ab35f09f4e828632b4dc6074d2bd367356,openstack/charm-openstack-dashboard,master,I4e19e7ab35f09f4e828632b4dc6074d2bd367356,Correct resolve_CONFIGS force_update,MERGED,2019-10-17 09:24:03.000000000,2019-10-17 15:23:15.000000000,2019-10-17 15:03:24.000000000,"[{'_account_id': 935}, {'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 09:24:03.000000000', 'files': ['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-openstack-dashboard/commit/5d9592ddca66ca14b6315e5abd534e0eeb157db4', 'message': 'Correct resolve_CONFIGS force_update\n\nA typo in resolve_CONFIGS reveresed the desired behaviour so\nforce_update=True would not force an update and vice versa.\n\nChange-Id: I4e19e7ab35f09f4e828632b4dc6074d2bd367356\nCloses-Bug: #1848440\n'}]",0,689107,5d9592ddca66ca14b6315e5abd534e0eeb157db4,14,4,1,12549,,,0,"Correct resolve_CONFIGS force_update

A typo in resolve_CONFIGS reveresed the desired behaviour so
force_update=True would not force an update and vice versa.

Change-Id: I4e19e7ab35f09f4e828632b4dc6074d2bd367356
Closes-Bug: #1848440
",git fetch https://review.opendev.org/openstack/charm-openstack-dashboard refs/changes/07/689107/1 && git format-patch -1 --stdout FETCH_HEAD,"['hooks/horizon_hooks.py', 'unit_tests/test_horizon_hooks.py']",2,5d9592ddca66ca14b6315e5abd534e0eeb157db4,bug/1848440," hooks.CONFIGS = None @patch.object(hooks, 'register_configs') def test_resolve_CONFIGS(self, _register_configs): _register_configs.return_value = 'new configs' self.assertEqual( hooks.resolve_CONFIGS(), 'new configs') _register_configs.assert_called_once_with() @patch.object(hooks, 'register_configs') def test_resolve_CONFIGS_existing_configs(self, _register_configs): hooks.CONFIGS = 'existing stuff' self.assertEqual( hooks.resolve_CONFIGS(), 'existing stuff') self.assertFalse(_register_configs.called) @patch.object(hooks, 'register_configs') def test_resolve_CONFIGS_existing_configs_force(self, _register_configs): _register_configs.return_value = 'new configs from force' hooks.CONFIGS = 'existing stuff' self.assertEqual( hooks.resolve_CONFIGS(force_update=True), 'new configs from force') _register_configs.assert_called_once_with() config_mocks = [config_mock2, config_mock1]"," config_mocks = [config_mock1, config_mock2]",28,2
openstack%2Foslo.concurrency~master~I5442806ef2f107e3b7569a79bffdc344769545b0,openstack/oslo.concurrency,master,I5442806ef2f107e3b7569a79bffdc344769545b0,Document management and history of lock files,MERGED,2019-10-15 22:05:59.000000000,2019-10-17 14:59:43.000000000,2019-10-17 14:58:12.000000000,"[{'_account_id': 708}, {'_account_id': 7198}, {'_account_id': 22348}, {'_account_id': 28522}]","[{'number': 1, 'created': '2019-10-15 22:05:59.000000000', 'files': ['doc/source/admin/index.rst', 'doc/source/index.rst'], 'web_link': 'https://opendev.org/openstack/oslo.concurrency/commit/f6bf926db713b2bb0f19e138a70d145eefae73a5', 'message': 'Document management and history of lock files\n\nSomething that comes up regularly on the mailing list is the topic\nof leftover lock files from interprocess locks. An Oslo developer\nthen has to explain why they work the way they do, and this is a\nnot-inconsiderable time suck because it is a complex topic.\n\nThis change adds an administrator guide that explains what should\nand should not be done with lock files, and provides an FAQ section\nto (hopefully) pre-emptively answer many of the common questions\npeople ask.\n\nChange-Id: I5442806ef2f107e3b7569a79bffdc344769545b0\n'}]",0,688825,f6bf926db713b2bb0f19e138a70d145eefae73a5,9,4,1,6928,,,0,"Document management and history of lock files

Something that comes up regularly on the mailing list is the topic
of leftover lock files from interprocess locks. An Oslo developer
then has to explain why they work the way they do, and this is a
not-inconsiderable time suck because it is a complex topic.

This change adds an administrator guide that explains what should
and should not be done with lock files, and provides an FAQ section
to (hopefully) pre-emptively answer many of the common questions
people ask.

Change-Id: I5442806ef2f107e3b7569a79bffdc344769545b0
",git fetch https://review.opendev.org/openstack/oslo.concurrency refs/changes/25/688825/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/index.rst', 'doc/source/index.rst']",2,f6bf926db713b2bb0f19e138a70d145eefae73a5,lock-file-docs, admin/index,,97,0
openstack%2Fopenstack-chef~master~I2eb418130e4a606c962b0d891a9de22192fcfa4a,openstack/openstack-chef,master,I2eb418130e4a606c962b0d891a9de22192fcfa4a,Update the community page,MERGED,2019-10-17 12:24:05.000000000,2019-10-17 14:31:50.000000000,2019-10-17 14:30:41.000000000,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 12:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/30bbb90513e5dc52bb55451aa994de5a5c696d97', 'message': 'Fix review link.\n\nChange-Id: I2eb418130e4a606c962b0d891a9de22192fcfa4a\n'}, {'number': 2, 'created': '2019-10-17 12:35:12.000000000', 'files': ['doc/source/contributor/community.rst'], 'web_link': 'https://opendev.org/openstack/openstack-chef/commit/a766dddc2c8ce1f4d196ff2a86305e18ac05980f', 'message': 'Update the community page\n\n- Update the project name\n- Update some links\n\nChange-Id: I2eb418130e4a606c962b0d891a9de22192fcfa4a\n'}]",0,689141,a766dddc2c8ce1f4d196ff2a86305e18ac05980f,8,2,2,30717,,,0,"Update the community page

- Update the project name
- Update some links

Change-Id: I2eb418130e4a606c962b0d891a9de22192fcfa4a
",git fetch https://review.opendev.org/openstack/openstack-chef refs/changes/41/689141/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/community.rst'],1,30bbb90513e5dc52bb55451aa994de5a5c696d97,689141,".. _core reviewers: https://review.opendev.org/#/admin/groups/1260,members .. _subteam: https://review.opendev.org/#/admin/groups/1261,members",".. _core reviewers: https://review.openstack.org/#/admin/groups/1260,members .. _subteam: https://review.openstack.org/#/admin/groups/1261,members",2,2
openstack%2Fkolla-ansible~master~I169246a6ce8b15af76fd84b32029437016bd3c42,openstack/kolla-ansible,master,I169246a6ce8b15af76fd84b32029437016bd3c42,Fixes missing boolean for Neutron FWaaS,MERGED,2019-10-16 11:24:54.000000000,2019-10-17 14:31:39.000000000,2019-10-17 14:04:22.000000000,"[{'_account_id': 14826}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 30356}, {'_account_id': 30523}]","[{'number': 1, 'created': '2019-10-16 11:24:54.000000000', 'files': ['ansible/roles/neutron/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0346dc124e8fec55e0196b69e87ac82991dc1ad1', 'message': 'Fixes missing boolean for Neutron FWaaS\n\nThe missing boolean breaks Neutron FWaaS deployment.\n\nChange-Id: I169246a6ce8b15af76fd84b32029437016bd3c42\nCloses-Bug: #1847562\n'}]",0,688906,0346dc124e8fec55e0196b69e87ac82991dc1ad1,12,5,1,30523,,,0,"Fixes missing boolean for Neutron FWaaS

The missing boolean breaks Neutron FWaaS deployment.

Change-Id: I169246a6ce8b15af76fd84b32029437016bd3c42
Closes-Bug: #1847562
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/06/688906/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/neutron/defaults/main.yml'],1,0346dc124e8fec55e0196b69e87ac82991dc1ad1,bug/1847562," enabled: ""{{ enable_neutron_fwaas | bool }}"""," enabled: ""{{ enable_neutron_fwaas }}""",1,1
openstack%2Fec2-api~master~I83f5c66d80601bd241b2e7e5ed0682c96000c32f,openstack/ec2-api,master,I83f5c66d80601bd241b2e7e5ed0682c96000c32f,Remove version attribute from setup.cfg,MERGED,2019-10-16 17:47:47.000000000,2019-10-17 14:30:19.000000000,2019-10-17 13:56:33.000000000,"[{'_account_id': 10234}, {'_account_id': 13294}, {'_account_id': 16312}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 17:47:47.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/ec2-api/commit/6e56a244f713cbf8531c6ed79322cf63ab029ea9', 'message': 'Remove version attribute from setup.cfg\n\nThis project uses pbr so it uses git tags and Sem-Ver pseudo header in\ncommit messages. Having versin setup.cfg can lead to conflicts and\nerrors when trying to get the package version using setup.py --version.\n\nNote that pbr provides the Sem-Ver ""magic"" works to bump releases\nwithout adding a tag [1].\n\n[1] https://docs.openstack.org/pbr/latest/user/features.html#version\n\nChange-Id: I83f5c66d80601bd241b2e7e5ed0682c96000c32f\nCloses-Bug: #1848364\n'}]",0,688991,6e56a244f713cbf8531c6ed79322cf63ab029ea9,16,4,1,16312,,,0,"Remove version attribute from setup.cfg

This project uses pbr so it uses git tags and Sem-Ver pseudo header in
commit messages. Having versin setup.cfg can lead to conflicts and
errors when trying to get the package version using setup.py --version.

Note that pbr provides the Sem-Ver ""magic"" works to bump releases
without adding a tag [1].

[1] https://docs.openstack.org/pbr/latest/user/features.html#version

Change-Id: I83f5c66d80601bd241b2e7e5ed0682c96000c32f
Closes-Bug: #1848364
",git fetch https://review.opendev.org/openstack/ec2-api refs/changes/91/688991/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,6e56a244f713cbf8531c6ed79322cf63ab029ea9,fix-version,,version = 9.0.0,0,1
openstack%2Frequirements~master~Ib39eb6ef3acb87b32493f4d1ed863654d36a44c3,openstack/requirements,master,Ib39eb6ef3acb87b32493f4d1ed863654d36a44c3,change upper-constraints.txt for taas,ABANDONED,2019-09-06 09:05:14.000000000,2019-10-17 14:17:15.000000000,,"[{'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 30931}]","[{'number': 1, 'created': '2019-09-06 09:05:14.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/63812c7e4cb12d080016e27aed739783bfb026b3', 'message': 'change upper-constraints.txt for taas\n\nChange-Id: Ib39eb6ef3acb87b32493f4d1ed863654d36a44c3\n'}]",3,680634,63812c7e4cb12d080016e27aed739783bfb026b3,19,6,1,30931,,,0,"change upper-constraints.txt for taas

Change-Id: Ib39eb6ef3acb87b32493f4d1ed863654d36a44c3
",git fetch https://review.opendev.org/openstack/requirements refs/changes/34/680634/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,63812c7e4cb12d080016e27aed739783bfb026b3,taas_patchset,git+https://git.openstack.org/openstack/tap-as-a-service@master#egg=tap-as-a-service git+https://git.openstack.org/openstack/tap-as-a-service-dashboard@master#egg=tap-as-a-service-dashboard,,2,0
openstack%2Fopenstack-ansible-galera_server~master~I0ea6477cb62773a1c9c82e77204c9bc72255a892,openstack/openstack-ansible-galera_server,master,I0ea6477cb62773a1c9c82e77204c9bc72255a892,PDF Documentation Build tox target,MERGED,2019-10-15 19:54:30.000000000,2019-10-17 14:06:46.000000000,2019-10-17 14:05:04.000000000,"[{'_account_id': 13095}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-10-15 19:54:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/642f9b720f17f396ffe42b672ddef9399e2c3535', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-16 11:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/556073d81684def0c33ab77581a816a4c20721f8', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-16 11:26:31.000000000', 'files': ['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_server/commit/7132d760bee431635855559596803a6f80aa3090', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892\nStory: 2006105\n'}]",0,688800,7132d760bee431635855559596803a6f80aa3090,11,3,3,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: I0ea6477cb62773a1c9c82e77204c9bc72255a892
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_server refs/changes/00/688800/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,642f9b720f17f396ffe42b672ddef9399e2c3535,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,4
openstack%2Fkuryr-kubernetes~master~Ib477213bab7e09bf6520f60b31d7d30584d90199,openstack/kuryr-kubernetes,master,Ib477213bab7e09bf6520f60b31d7d30584d90199,NestedVIFPool: React when status.hostIP is missing,MERGED,2019-10-15 10:18:44.000000000,2019-10-17 14:04:07.000000000,2019-10-17 12:00:55.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-10-15 10:18:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5e8700599b895745d1b839c067e7336906c3913c', 'message': ""NestedVIFPool: React when status.hostIP is missing\n\nSeems like there's a race condition or bug in K8s that on DELETE events\nwe can end up with annotated pod that doesn't have `status.hostIP` field\nset. This is problematic for NestedVIFPool driver that used it as one of\nthe pool key elements.\n\nThis patch solves that by looking up host IP through Neutron and trunks\ninfo if the field is missing from the pod.\n\nChange-Id: Ib477213bab7e09bf6520f60b31d7d30584d90199\nCloses-Bug: 1848172\n""}, {'number': 2, 'created': '2019-10-15 10:38:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/fca1d6bdc6ecb707e1fb9ad9e836a0a30878fc66', 'message': ""NestedVIFPool: React when status.hostIP is missing\n\nSeems like there's a race condition or bug in K8s that on DELETE events\nwe can end up with annotated pod that doesn't have `status.hostIP` field\nset. This is problematic for NestedVIFPool driver that used it as one of\nthe pool key elements.\n\nThis patch solves that by looking up host IP through Neutron and trunks\ninfo if the field is missing from the pod.\n\nChange-Id: Ib477213bab7e09bf6520f60b31d7d30584d90199\nCloses-Bug: 1848172\n""}, {'number': 3, 'created': '2019-10-15 15:20:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/e888cb262cb6b82aa21317c5135a2a03e72e8c01', 'message': ""NestedVIFPool: React when status.hostIP is missing\n\nSeems like there's a race condition or bug in K8s that on DELETE events\nwe can end up with annotated pod that doesn't have `status.hostIP` field\nset. This is problematic for NestedVIFPool driver that used it as one of\nthe pool key elements.\n\nThis patch solves that by looking up host IP through Neutron and trunks\ninfo if the field is missing from the pod.\n\nChange-Id: Ib477213bab7e09bf6520f60b31d7d30584d90199\nCloses-Bug: 1848172\n""}, {'number': 4, 'created': '2019-10-16 15:52:57.000000000', 'files': ['kuryr_kubernetes/controller/drivers/vif_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/5fb1f5908a7f212ff3d84e7928b2ea9e50f03f2d', 'message': ""NestedVIFPool: React when status.hostIP is missing\n\nSeems like there's a race condition or bug in K8s that on DELETE events\nwe can end up with annotated pod that doesn't have `status.hostIP` field\nset. This is problematic for NestedVIFPool driver that used it as one of\nthe pool key elements.\n\nThis patch solves that by looking up host IP through Neutron and trunks\ninfo if the field is missing from the pod.\n\nChange-Id: Ib477213bab7e09bf6520f60b31d7d30584d90199\nCloses-Bug: 1848172\n""}]",5,688670,5fb1f5908a7f212ff3d84e7928b2ea9e50f03f2d,23,6,4,11600,,,0,"NestedVIFPool: React when status.hostIP is missing

Seems like there's a race condition or bug in K8s that on DELETE events
we can end up with annotated pod that doesn't have `status.hostIP` field
set. This is problematic for NestedVIFPool driver that used it as one of
the pool key elements.

This patch solves that by looking up host IP through Neutron and trunks
info if the field is missing from the pod.

Change-Id: Ib477213bab7e09bf6520f60b31d7d30584d90199
Closes-Bug: 1848172
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/70/688670/4 && git format-patch -1 --stdout FETCH_HEAD,['kuryr_kubernetes/controller/drivers/vif_pool.py'],1,5e8700599b895745d1b839c067e7336906c3913c,bug/1848172," def release_vif(self, pod, vif, project_id, security_groups, host_addr=None): if not host_addr: host_addr = self._get_host_addr(pod) def _get_parent_port_id(self, vif): neutron = clients.get_neutron_client() trunks = neutron.list_trunks() for trunk in trunks['trunks']: for sp in trunk['sub_ports']: if sp == vif.id: return trunk['port_id'] return None def release_vif(self, pod, vif, project_id, security_groups): host_addr = None try: self._get_host_addr(pod) except KeyError: LOG.warning(""Pod %s does not have status.hostIP field set when "" ""getting deleted. This is unusual. Trying to "" ""determine the IP by calling Neutron."") parent_id = self._get_parent_port_id(vif) if not parent_id: LOG.warning(""Port %s not found, ignoring its release request."", vif.id) return host_addr = self._get_parent_port_ip(parent_id) super(NestedVIFPool, self).release_vif( pod, vif, project_id, security_groups, host_addr=host_addr) "," def release_vif(self, pod, vif, project_id, security_groups): host_addr = self._get_host_addr(pod)",34,2
openstack%2Fnetworking-ovn~stable%2Fstein~I6b659cbede25f271fa3b6a1c9e72019694ab6608,openstack/networking-ovn,stable/stein,I6b659cbede25f271fa3b6a1c9e72019694ab6608,Set binding profile directly from OVNTrunkDriver (redo),MERGED,2019-10-10 15:09:13.000000000,2019-10-17 13:59:12.000000000,2019-10-17 13:57:20.000000000,"[{'_account_id': 6773}, {'_account_id': 8655}, {'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-10 15:09:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e63c5c97ce662656c84988ff2f47616a0e36ca81', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 7bdf2eb824083b6785d78dd67b3effe071e3f7a4)\n(cherry picked from commit e14b6cd76bade8291764a88b6a2fa851a3a86b87)\n'}, {'number': 2, 'created': '2019-10-10 20:39:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/9aa079e1d03be03205f0ff09bd61fb22165fbd81', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 7bdf2eb824083b6785d78dd67b3effe071e3f7a4)\n(cherry picked from commit e14b6cd76bade8291764a88b6a2fa851a3a86b87)\n'}, {'number': 3, 'created': '2019-10-14 12:07:57.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/c6dee38266b662a2bb90c95af891045c731daf41', 'message': 'Set binding profile directly from OVNTrunkDriver (redo)\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 35.6 for 95%ile\nfrom 99 sec to 34.2 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\nThis reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nChange-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608\nCloses-Bug: #1834637\nRelated-Bug: #1845479\nCo-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>\n(cherry picked from commit 1e20b9bf866e3001ad1cd71186caada647c54929)\n'}]",0,687930,c6dee38266b662a2bb90c95af891045c731daf41,18,7,3,11952,,,0,"Set binding profile directly from OVNTrunkDriver (redo)

Setting binding profile for Trunk subports takes
time - for 125 subports rally CreateAndListTrunks
scenario [0] takes about 150 seconds. We need to
bump up the perfomance because large number of
subports is widly used in Kuryr deployments.

To achieve that I changed setting the binding
profile to be saved directly to the neutron DB.
Instead calling port_update I update only related
fields in OVN NorthBound DB rows. That gave performance
improvement in trunk port creation:

from 101 sec to 35.6 for 95%ile
from 99 sec to 34.2 for 50%ile

The same thing has been done for Trunk deletion.

This reverts commit 2e0832f7b8bfc31780b657aa0abda4e8b244fbbd

[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37

Change-Id: I6b659cbede25f271fa3b6a1c9e72019694ab6608
Closes-Bug: #1834637
Related-Bug: #1845479
Co-authored-by: Maciej Józefczyk <mjozefcz@redhat.com>
(cherry picked from commit 1e20b9bf866e3001ad1cd71186caada647c54929)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/30/687930/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py']",2,e63c5c97ce662656c84988ff2f47616a0e36ca81,bug/1834637,"from neutron.objects import ports as port_obj def _set_sub_ports(self, parent_port, subports): txn = self.plugin_driver._nb_ovn.transaction context = n_context.get_admin_context() with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._set_binding_profile(context, port, parent_port, ovn_txn) txn = self.plugin_driver._nb_ovn.transaction context = n_context.get_admin_context() with context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._unset_binding_profile(context, port, ovn_txn) def _set_binding_profile(self, context, subport, parent_port, ovn_txn): db_port = port_obj.Port.get_object(context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.update({ 'parent_name': parent_port, 'tag': subport.segmentation_id}) # host + port_id is primary key port_obj.PortBinding.update_object( context, {'profile': binding.profile}, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=parent_port, tag=subport.segmentation_id)) def _unset_binding_profile(self, context, subport, ovn_txn): db_port = port_obj.Port.get_object(context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.pop('tag', None) binding.profile.pop('parent_name', None) # host + port_id is primary key port_obj.PortBinding.update_object( context, {'profile': binding.profile, 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'vif_details': '', 'host': ''}, port_id=subport.port_id, host=binding.host) port_obj.PortBindingLevel.delete_objects( context, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=[], up=False, tag=[])) if trunk.sub_ports: self._set_sub_ports(trunk.port_id, trunk.sub_ports) if trunk.sub_ports: self._unset_sub_ports(trunk.sub_ports) if subports: self._set_sub_ports(trunk.port_id, subports) if subports: self._unset_sub_ports(subports)","from oslo_db import exception as os_db_exc def _set_binding_profile(self, port_id, parent_port, tag=None): context = n_context.get_admin_context() binding_profile = {} if parent_port and tag: binding_profile = {'parent_name': parent_port, 'tag': tag} port = {'port': {'binding:profile': binding_profile}} if not tag: port['port']['binding:host_id'] = None try: self.plugin_driver._plugin.update_port(context, port_id, port) except (os_db_exc.DBReferenceError, n_exc.PortNotFound): LOG.debug(""Port not found trying to set binding_profile: %s"", port_id) def _set_sub_ports(self, parent_port, subports): for port in subports: self._set_binding_profile(port.port_id, parent_port, tag=port.segmentation_id) for port in subports: self._set_binding_profile(port.port_id, None) self._set_sub_ports(trunk.port_id, trunk.sub_ports) self._unset_sub_ports(trunk.sub_ports) self._set_sub_ports(trunk.port_id, subports) self._unset_sub_ports(subports)",275,107
openstack%2Fcharm-nova-cloud-controller~master~I672ae9538dc687a1c868bf99001041a54241ec24,openstack/charm-nova-cloud-controller,master,I672ae9538dc687a1c868bf99001041a54241ec24,Remove ``nova-consoleauth`` package as of Train,MERGED,2019-10-17 10:31:40.000000000,2019-10-17 13:55:02.000000000,2019-10-17 13:55:01.000000000,"[{'_account_id': 935}, {'_account_id': 13686}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 10:31:40.000000000', 'files': ['unit_tests/test_nova_cc_utils.py', 'hooks/nova_cc_common.py', 'hooks/nova_cc_utils.py', 'hooks/nova_cc_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-cloud-controller/commit/bf2cd49829e720a449898caa6c6e835f26b52e9e', 'message': 'Remove ``nova-consoleauth`` package as of Train\n\nThe Nova console authorization has been moved to the database\nbackend and the separate service and package is no longer\nnecessary.\n\nChange-Id: I672ae9538dc687a1c868bf99001041a54241ec24\nCloses-Bug: #1848478\n'}]",0,689120,bf2cd49829e720a449898caa6c6e835f26b52e9e,12,4,1,13686,,,0,"Remove ``nova-consoleauth`` package as of Train

The Nova console authorization has been moved to the database
backend and the separate service and package is no longer
necessary.

Change-Id: I672ae9538dc687a1c868bf99001041a54241ec24
Closes-Bug: #1848478
",git fetch https://review.opendev.org/openstack/charm-nova-cloud-controller refs/changes/20/689120/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_nova_cc_utils.py', 'hooks/nova_cc_common.py', 'hooks/nova_cc_utils.py', 'hooks/nova_cc_hooks.py']",4,bf2cd49829e720a449898caa6c6e835f26b52e9e,bug/1848478, ncc_utils.is_consoleauth_enabled()):, ncc_utils.is_console_auth_enabled()):,77,24
openstack%2Fpython-tripleoclient~master~Id9271460b20e602f935f1eddd70f989cd605b1f4,openstack/python-tripleoclient,master,Id9271460b20e602f935f1eddd70f989cd605b1f4,Undercloud hosts entries in overcloud parameters,MERGED,2019-10-08 16:15:12.000000000,2019-10-17 13:45:59.000000000,2019-10-17 13:40:46.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 18575}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-10-08 16:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/cee6b78c80245c2b451d64e2212330ca9dd11f3d', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter with the list of HEAT_HOSTS entries on the undercloud\nso that these entries can be added to the hosts file on the\novercloud nodes.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding hosts entries\na name can be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 2, 'created': '2019-10-10 03:37:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/091e39a8c440bc20345153cb333e23c46762d2db', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter with the list of HEAT_HOSTS entries on the undercloud\nso that these entries can be added to the hosts file on the\novercloud nodes.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding hosts entries\na name can be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 3, 'created': '2019-10-10 04:27:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b002b7e3c064e6425941208d1a01ad461fc2f819', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane.localdomain entry\nfrom /etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 4, 'created': '2019-10-11 09:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/4dfcf02d886cc13d8ee10d772b3093d9f4e4db34', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane.localdomain entry\nfrom /etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 5, 'created': '2019-10-11 09:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8f125d49d04e78a6699a408d3de547f6334e156f', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane.localdomain entry\nfrom /etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 6, 'created': '2019-10-11 17:35:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3df19638beec45422eb0fc296fae277eedc6f30c', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane entry from\n/etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}, {'number': 7, 'created': '2019-10-14 08:36:52.000000000', 'files': ['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/tests/v1/overcloud_update/test_overcloud_update.py', 'tripleoclient/v1/overcloud_deploy.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/8617dd1cacb95e9dc39460d50064e303d9534ad6', 'message': 'Undercloud hosts entries in overcloud parameters\n\nWhen running overcloud deploy set the UndercloudHostsEntries\nparameter to include the <shortname>.ctlplane entry from\n/etc/hosts on the undercloud.\n\nWith IPv6 the overcloud nodes cannot pull images from the\nundercloud using an IPv6 address. By adding the host entry\nfor the undercloud in the overcloud nodes hosts file a name\ncan be used instead of the IPv6 address.\n\nRelated-Bug: #1836578\nChange-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4\n'}]",6,687347,8617dd1cacb95e9dc39460d50064e303d9534ad6,51,7,7,24245,,,0,"Undercloud hosts entries in overcloud parameters

When running overcloud deploy set the UndercloudHostsEntries
parameter to include the <shortname>.ctlplane entry from
/etc/hosts on the undercloud.

With IPv6 the overcloud nodes cannot pull images from the
undercloud using an IPv6 address. By adding the host entry
for the undercloud in the overcloud nodes hosts file a name
can be used instead of the IPv6 address.

Related-Bug: #1836578
Change-Id: Id9271460b20e602f935f1eddd70f989cd605b1f4
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/47/687347/3 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_deploy/test_overcloud_deploy.py', 'tripleoclient/v1/overcloud_deploy.py']",2,cee6b78c80245c2b451d64e2212330ca9dd11f3d,bug/1836578," parameters[ 'UndercloudHostsEntries'] = self._get_undercloud_host_entries() def _get_undercloud_host_entries(self): """"""Get hosts entries for undercloud to be added on overcloud nodes"""""" with open('/etc/hosts', 'r') as hostsfile: hosts = hostsfile.read() hosts = [entry for entry in hosts.split('\n') if entry != ''] try: start = [idx for idx, item in enumerate(hosts) if item.startswith('# HEAT_HOSTS_START')][0] end = [idx for idx, item in enumerate(hosts) if item.startswith('# HEAT_HOSTS_END')][0] hosts = hosts[start + 1:end] except IndexError: hosts = [] return hosts ",,52,4
openstack%2Fpuppet-openstack_extras~master~Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8,openstack/puppet-openstack_extras,master,Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8,Move repo defaults to Ussuri,MERGED,2019-10-10 09:17:31.000000000,2019-10-17 13:45:47.000000000,2019-10-17 13:45:47.000000000,"[{'_account_id': 3153}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-10 09:17:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/92f45175f529cb84f46eab1db8ffb45ac84be5a4', 'message': 'Move repo defaults to Ussuri\n\nChange-Id: Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8\n'}, {'number': 2, 'created': '2019-10-11 07:48:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/62353901bdc1f3ca3d26944e6402fe660d64f0ae', 'message': 'Move repo defaults to Ussuri\n\nMove the EPEL testing to its own context\nbecause we were testing with a specified\nvalue that was not the default.\n\nChange-Id: Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8\n'}, {'number': 3, 'created': '2019-10-11 15:36:45.000000000', 'files': ['manifests/repo/redhat/params.pp', 'manifests/repo/redhat/redhat.pp', 'spec/classes/openstack_extras_repo_debian_debian_spec.rb', 'spec/classes/openstack_extras_repo_debian_ubuntu_spec.rb', 'manifests/repo/debian/params.pp', 'spec/classes/openstack_extras_repo_redhat_redhat_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/19e42853dba24b19d41db30f80516e2f3f62d3dd', 'message': 'Move repo defaults to Ussuri\n\nMove the EPEL testing to its own context\nbecause we were testing with a specified\nvalue that was not the default.\n\nChange-Id: Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8\n'}]",0,687834,19e42853dba24b19d41db30f80516e2f3f62d3dd,22,4,3,16137,,,0,"Move repo defaults to Ussuri

Move the EPEL testing to its own context
because we were testing with a specified
value that was not the default.

Change-Id: Ib51009fb3584ea6ec8f423a5e8b2486714e47fe8
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/34/687834/3 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/repo/redhat/params.pp', 'spec/classes/openstack_extras_repo_debian_debian_spec.rb', 'manifests/repo/debian/params.pp', 'spec/classes/openstack_extras_repo_debian_ubuntu_spec.rb', 'spec/classes/openstack_extras_repo_redhat_redhat_spec.rb']",5,92f45175f529cb84f46eab1db8ffb45ac84be5a4,ussuri," {} :baseurl => ""http://mirror.centos.org/centos/7/cloud/$basearch/openstack-ussuri/"", :descr => 'OpenStack Ussuri Repository',"," default_params :baseurl => ""http://mirror.centos.org/centos/7/cloud/$basearch/openstack-train/"", :descr => 'OpenStack Train Repository',",15,15
openstack%2Fpuppet-openstack-integration~master~If29d5507c965cce2fdaef253b95275dec65769e8,openstack/puppet-openstack-integration,master,If29d5507c965cce2fdaef253b95275dec65769e8,Updated from Puppet OpenStack modules constraints,MERGED,2019-10-17 06:05:48.000000000,2019-10-17 13:39:02.000000000,2019-10-17 13:39:01.000000000,"[{'_account_id': 3153}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-17 06:05:48.000000000', 'files': ['Puppetfile'], 'web_link': 'https://opendev.org/openstack/puppet-openstack-integration/commit/db125ef4bb5ba3217c5032f619c17fed89a41075', 'message': 'Updated from Puppet OpenStack modules constraints\n\nChange-Id: If29d5507c965cce2fdaef253b95275dec65769e8\n'}]",0,689076,db125ef4bb5ba3217c5032f619c17fed89a41075,8,4,1,11131,,,0,"Updated from Puppet OpenStack modules constraints

Change-Id: If29d5507c965cce2fdaef253b95275dec65769e8
",git fetch https://review.opendev.org/openstack/puppet-openstack-integration refs/changes/76/689076/1 && git format-patch -1 --stdout FETCH_HEAD,['Puppetfile'],1,db125ef4bb5ba3217c5032f619c17fed89a41075,openstack/puppet/constraints, :ref => 'v4.3.0', :ref => 'v4.2.0',1,1
openstack%2Fcloudkitty~master~I51df67821d77482f3fcffae7b4120f0e5823418c,openstack/cloudkitty,master,I51df67821d77482f3fcffae7b4120f0e5823418c,Update .zuul.yaml to run separate tempest tests for each API version,MERGED,2019-10-15 07:38:09.000000000,2019-10-17 13:15:21.000000000,2019-10-17 13:12:45.000000000,"[{'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-10-15 07:38:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/99df2490099c358e2fd8def0e40bc9e57e4ea3ab', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 2, 'created': '2019-10-15 07:40:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/143b4a1a6e0ab88864b3c06b17433adaff951968', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 3, 'created': '2019-10-15 08:00:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/b993f34513ea4946e8c9614bd121d45820c08e42', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 4, 'created': '2019-10-15 08:43:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/9f8b6f00e00c3d36bb8c7fc0efeea96b1c6295ed', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 5, 'created': '2019-10-15 10:05:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/8eebd861218f4cb55f842d2e26af55f14b2f7de3', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nDepends-On: https://review.opendev.org/#/c/686210\nStory: 2006578\nTask: 37108\n'}, {'number': 6, 'created': '2019-10-15 14:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/2995c7fd751932e69091b1a63bf13216d1085d22', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 7, 'created': '2019-10-15 14:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/bd53d58bd0d8fc3166020dade52674b71a1516f3', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}, {'number': 8, 'created': '2019-10-15 15:22:29.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/cloudkitty/commit/ebe06543f1914fed1a9509cb82a8e139241ac14f', 'message': 'Update .zuul.yaml to run separate tempest tests for each API version\n\nChange-Id: I51df67821d77482f3fcffae7b4120f0e5823418c\nStory: 2006578\nTask: 37108\n'}]",19,688643,ebe06543f1914fed1a9509cb82a8e139241ac14f,24,3,8,29503,,,0,"Update .zuul.yaml to run separate tempest tests for each API version

Change-Id: I51df67821d77482f3fcffae7b4120f0e5823418c
Story: 2006578
Task: 37108
",git fetch https://review.opendev.org/openstack/cloudkitty refs/changes/43/688643/8 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,99df2490099c358e2fd8def0e40bc9e57e4ea3ab,cloudkitty-api-migration, name: base-cloudkitty-tempest-job Job testing cloudkitty installation and running tempest tests name: base-cloudkitty-v1-tempest-job parent: base-cloudkitty-tempest-job description: | Job testing cloudkitty installation on devstack without the InfluxDB v2 storage driver and running tempest tests vars: tempest_test_regex: cloudkitty_tempest_plugin.tests.api.v1.* - job: name: base-cloudkitty-v2-tempest-job parent: base-cloudkitty-tempest-job description: | Job testing cloudkitty installation on devstack with the InfluxDB v2 storage driver and running tempest tests vars: tempest_test_regex: cloudkitty_tempest_plugin.tests.api.v2.* - job: name: base-cloudkitty-v2-api-tempest-job-py3 parent: base-cloudkitty-v2-tempest-job parent: base-cloudkitty-v2-api-tempest-job parent: base-cloudkitty-v2-api-tempest-job - base-cloudkitty-v2-api-tempest-job - base-cloudkitty-v2-api-tempest-job-py3 - base-cloudkitty-v2-api-tempest-job - base-cloudkitty-v2-api-tempest-job-py3, name: cloudkitty-tempest-full-v2-storage-influxdb Job testing cloudkitty installation on devstack with the InfluxDB v2 storage driver and running tempest tests name: cloudkitty-tempest-full-v2-storage-influxdb-py3 parent: cloudkitty-tempest-full-v2-storage-influxdb parent: cloudkitty-tempest-full-v2-storage-influxdb parent: cloudkitty-tempest-full-v2-storage-influxdb - cloudkitty-tempest-full-v2-storage-influxdb - cloudkitty-tempest-full-v2-storage-influxdb-py3 - cloudkitty-tempest-full-v2-storage-influxdb - cloudkitty-tempest-full-v2-storage-influxdb-py3,28,11
openstack%2Fkolla-cli~master~I55bdac059dd474280dc35855a269c67fec58b022,openstack/kolla-cli,master,I55bdac059dd474280dc35855a269c67fec58b022,Blacklist sphinx 2.1.0 (autodoc bug),MERGED,2019-10-17 09:43:08.000000000,2019-10-17 13:02:51.000000000,2019-10-17 13:01:39.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-10-17 09:43:08.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/kolla-cli/commit/ecff34a3320c9de84b33a0361fab12473923f9dc', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nSee https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details\n\nChange-Id: I55bdac059dd474280dc35855a269c67fec58b022\n'}]",0,689109,ecff34a3320c9de84b33a0361fab12473923f9dc,8,3,1,28743,,,0,"Blacklist sphinx 2.1.0 (autodoc bug)

See https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details

Change-Id: I55bdac059dd474280dc35855a269c67fec58b022
",git fetch https://review.opendev.org/openstack/kolla-cli refs/changes/09/689109/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,ecff34a3320c9de84b33a0361fab12473923f9dc,,"sphinx>=1.8.0,!=2.1.0;python_version>='3.4' # BSD",sphinx>=1.8.0;python_version>='3.4' # BSD,1,1
openstack%2Fpuppet-octavia~stable%2Ftrain~I26ad5d41239b6e770e975dc6f78fc46a87803220,openstack/puppet-octavia,stable/train,I26ad5d41239b6e770e975dc6f78fc46a87803220,Add keepalivd vrrp parameters,MERGED,2019-10-12 18:02:58.000000000,2019-10-17 12:54:47.000000000,2019-10-17 12:53:35.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-12 18:02:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/f9ec3e241043748698b4c5a0aa023a16bd4d615f', 'message': 'Add keepalivd vrrp parameters\n\nChange-Id: I26ad5d41239b6e770e975dc6f78fc46a87803220\n(cherry picked from commit 8fd7b2e0ff231a602167af98f8fe7729c872b319)\n'}, {'number': 2, 'created': '2019-10-13 19:18:32.000000000', 'files': ['spec/classes/octavia_controller_spec.rb', 'manifests/controller.pp', 'releasenotes/notes/add-vrrp-keepalived-params-81f235f8cc411c42.yaml'], 'web_link': 'https://opendev.org/openstack/puppet-octavia/commit/b659647dbd21a48560750e611a9b7646f39f48be', 'message': 'Add keepalivd vrrp parameters\n\nChange-Id: I26ad5d41239b6e770e975dc6f78fc46a87803220\n(cherry picked from commit 8fd7b2e0ff231a602167af98f8fe7729c872b319)\n'}]",0,688279,b659647dbd21a48560750e611a9b7646f39f48be,11,3,2,6469,,,0,"Add keepalivd vrrp parameters

Change-Id: I26ad5d41239b6e770e975dc6f78fc46a87803220
(cherry picked from commit 8fd7b2e0ff231a602167af98f8fe7729c872b319)
",git fetch https://review.opendev.org/openstack/puppet-octavia refs/changes/79/688279/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/octavia_controller_spec.rb', 'manifests/controller.pp', 'releasenotes/notes/add-vrrp-keepalived-params-81f235f8cc411c42.yaml']",3,f9ec3e241043748698b4c5a0aa023a16bd4d615f,,--- features: - Added Keepalived VRRP parameters. ,,94,38
openstack%2Freleases~master~I75ebdb23613020624afeb33520e8c6d6eb15d186,openstack/releases,master,I75ebdb23613020624afeb33520e8c6d6eb15d186,"Revert ""Openstacksdk Queens 0.11.4""",MERGED,2019-10-17 11:45:25.000000000,2019-10-17 12:53:07.000000000,2019-10-17 12:53:07.000000000,"[{'_account_id': 308}, {'_account_id': 1131}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 11:45:25.000000000', 'files': ['deliverables/queens/openstacksdk.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5d6430deabb4bce5ba28613422ea18f5439b18c3', 'message': 'Revert ""Openstacksdk Queens 0.11.4""\n\nThe .gitreview file in stable/queens was not updated with\nthe new repo name, resulting in the tag job failing for\nthis release. Since it was not able to do anything, the\neasiest fix is to just revert this patch, merge an update\nto the .gitreview file [0], and resubmit it with the hash\nincluding that change.\n\n[0] https://review.opendev.org/689131\n\nThis reverts commit 9713aa37805c2d308a2a26c5f994b5c3a1adc854.\n\nChange-Id: I75ebdb23613020624afeb33520e8c6d6eb15d186\n'}]",0,689132,5d6430deabb4bce5ba28613422ea18f5439b18c3,7,4,1,11904,,,0,"Revert ""Openstacksdk Queens 0.11.4""

The .gitreview file in stable/queens was not updated with
the new repo name, resulting in the tag job failing for
this release. Since it was not able to do anything, the
easiest fix is to just revert this patch, merge an update
to the .gitreview file [0], and resubmit it with the hash
including that change.

[0] https://review.opendev.org/689131

This reverts commit 9713aa37805c2d308a2a26c5f994b5c3a1adc854.

Change-Id: I75ebdb23613020624afeb33520e8c6d6eb15d186
",git fetch https://review.opendev.org/openstack/releases refs/changes/32/689132/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/openstacksdk.yaml'],1,5d6430deabb4bce5ba28613422ea18f5439b18c3,openstacksdk-queens-0.11.4,, - projects: - hash: 3d71e2a7197b6d42cf680769b6a0fd3490d536fb repo: openstack/openstacksdk version: 0.11.4,0,4
openstack%2Fcharm-swift-proxy~master~I80b265614ac96fc72ea6832f27379cc2529a787e,openstack/charm-swift-proxy,master,I80b265614ac96fc72ea6832f27379cc2529a787e,Resync charmhelpers for new Swift Train versions,MERGED,2019-10-17 09:45:40.000000000,2019-10-17 12:42:26.000000000,2019-10-17 12:42:26.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 09:45:40.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/python/__init__.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-proxy/commit/778eb1560308f27eeee42aa1a054521f9f7109d8', 'message': 'Resync charmhelpers for new Swift Train versions\n\n2.23.0 was added to the list of supported version for Train.\n\nChange-Id: I80b265614ac96fc72ea6832f27379cc2529a787e\n'}]",0,689111,778eb1560308f27eeee42aa1a054521f9f7109d8,7,3,1,935,,,0,"Resync charmhelpers for new Swift Train versions

2.23.0 was added to the list of supported version for Train.

Change-Id: I80b265614ac96fc72ea6832f27379cc2529a787e
",git fetch https://review.opendev.org/openstack/charm-swift-proxy refs/changes/11/689111/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/contrib/python/__init__.py']",6,778eb1560308f27eeee42aa1a054521f9f7109d8,train-ch-resync,,,112,62
openstack%2Fcharm-swift-storage~master~I1c23de5b56350c1d8b25e3cddae54c7b97d4f963,openstack/charm-swift-storage,master,I1c23de5b56350c1d8b25e3cddae54c7b97d4f963,Resync charmhelpers for new Swift Train versions,MERGED,2019-10-17 09:47:03.000000000,2019-10-17 12:40:26.000000000,2019-10-17 12:40:26.000000000,"[{'_account_id': 12549}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 09:47:03.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/775493a270c2c1b52bdc9533997f45eea487d98a', 'message': 'Resync charmhelpers for new Swift Train versions\n\n2.23.0 was added to the list of supported version for Train.\n\nChange-Id: I1c23de5b56350c1d8b25e3cddae54c7b97d4f963\n'}]",0,689112,775493a270c2c1b52bdc9533997f45eea487d98a,7,3,1,935,,,0,"Resync charmhelpers for new Swift Train versions

2.23.0 was added to the list of supported version for Train.

Change-Id: I1c23de5b56350c1d8b25e3cddae54c7b97d4f963
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/12/689112/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/hookenv.py', 'charmhelpers/contrib/openstack/policyd.py', 'charmhelpers/contrib/openstack/context.py', 'charmhelpers/contrib/storage/linux/ceph.py']",5,775493a270c2c1b52bdc9533997f45eea487d98a,train-ch-resync," if six.PY3: modules = modules.decode('UTF-8') def add_op(self, op): """"""Add an op if it is not already in the list. :param op: Operation to add. :type op: dict """""" if op not in self.ops: self.ops.append(op) self.add_op({ self.add_op({'op': 'create-pool', 'name': name, 'replicas': replica_count, 'pg_num': pg_num, 'weight': weight, 'group': group, 'group-namespace': namespace, 'app-name': app_name, 'max-bytes': max_bytes, 'max-objects': max_objects}) self.add_op({'op': 'create-pool', 'name': name, 'pool-type': 'erasure', 'erasure-profile': erasure_profile, 'weight': weight, 'group': group, 'app-name': app_name, 'max-bytes': max_bytes, 'max-objects': max_objects})"," self.ops.append({ self.ops.append({'op': 'create-pool', 'name': name, 'replicas': replica_count, 'pg_num': pg_num, 'weight': weight, 'group': group, 'group-namespace': namespace, 'app-name': app_name, 'max-bytes': max_bytes, 'max-objects': max_objects}) self.ops.append({'op': 'create-pool', 'name': name, 'pool-type': 'erasure', 'erasure-profile': erasure_profile, 'weight': weight, 'group': group, 'app-name': app_name, 'max-bytes': max_bytes, 'max-objects': max_objects})",112,62
openstack%2Ftripleo-common~stable%2Fstein~Ic5a1f29e25380b1badf653fccce982cd5b8690aa,openstack/tripleo-common,stable/stein,Ic5a1f29e25380b1badf653fccce982cd5b8690aa,Do not repeat setting defaults for image layers,MERGED,2019-10-16 13:50:53.000000000,2019-10-17 12:28:47.000000000,2019-10-17 12:27:39.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-10-16 13:50:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/0e2ae8a7636fffe1a0e27d3e17db2cfce64e9d0c', 'message': 'Do not repeat setting defaults for image layers\n\nChange-Id: Ic5a1f29e25380b1badf653fccce982cd5b8690aa\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-10-16 14:30:31.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/5cf40c1115f3ac790bb7c9ad6bf5c43a66d9b70d', 'message': 'Do not repeat setting defaults for image layers\n\nChange-Id: Ic5a1f29e25380b1badf653fccce982cd5b8690aa\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n(cherry picked from commit 8ddaddea201e2be83833699bb8134a9df7d8a186)\n'}]",0,688937,5cf40c1115f3ac790bb7c9ad6bf5c43a66d9b70d,13,5,2,11090,,,0,"Do not repeat setting defaults for image layers

Change-Id: Ic5a1f29e25380b1badf653fccce982cd5b8690aa
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
(cherry picked from commit 8ddaddea201e2be83833699bb8134a9df7d8a186)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/37/688937/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,0e2ae8a7636fffe1a0e27d3e17db2cfce64e9d0c,bug/1847225-stable/stein,," for layer in source_layers: self.image_layers.setdefault(layer, t.target_image_url)",0,2
openstack%2Ftripleo-heat-templates~stable%2Fstein~I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f,openstack/tripleo-heat-templates,stable/stein,I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f,Add missing step tag in updates/upgrades/ffu tasks,MERGED,2019-10-16 14:56:03.000000000,2019-10-17 12:27:41.000000000,2019-10-17 12:27:40.000000000,"[{'_account_id': 6926}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 14:56:03.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e625554d147d4f9ba2fd7bb3087075ce217666d', 'message': 'Add missing step tag in updates/upgrades/ffu tasks\n\nWe are missing some step tags in updates/upgrades/ffu\ntasks to make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n(cherry picked from commit af1e393e07dc595db72c26b330955cc60a36f922)\n'}]",0,688950,1e625554d147d4f9ba2fd7bb3087075ce217666d,7,4,1,11090,,,0,"Add missing step tag in updates/upgrades/ffu tasks

We are missing some step tags in updates/upgrades/ffu
tasks to make the Ansible lint check to work.

Change-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f
(cherry picked from commit af1e393e07dc595db72c26b330955cc60a36f922)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/688950/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml']",2,1e625554d147d4f9ba2fd7bb3087075ce217666d,ansible-syntax-check, when: step|int == 1,,28,22
openstack%2Freleases~master~I21de9164c1ecceb71f43890adc28e756b4e02313,openstack/releases,master,I21de9164c1ecceb71f43890adc28e756b4e02313,Openstacksdk Queens 0.11.4,MERGED,2019-10-15 13:51:05.000000000,2019-10-17 11:45:25.000000000,2019-10-17 10:10:19.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 13:51:05.000000000', 'files': ['deliverables/queens/openstacksdk.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/9713aa37805c2d308a2a26c5f994b5c3a1adc854', 'message': 'Openstacksdk Queens 0.11.4\n\nChange-Id: I21de9164c1ecceb71f43890adc28e756b4e02313\n'}]",0,688713,9713aa37805c2d308a2a26c5f994b5c3a1adc854,8,3,1,1131,,,0,"Openstacksdk Queens 0.11.4

Change-Id: I21de9164c1ecceb71f43890adc28e756b4e02313
",git fetch https://review.opendev.org/openstack/releases refs/changes/13/688713/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/queens/openstacksdk.yaml'],1,9713aa37805c2d308a2a26c5f994b5c3a1adc854,openstacksdk-queens-0.11.4, - projects: - hash: 3d71e2a7197b6d42cf680769b6a0fd3490d536fb repo: openstack/openstacksdk version: 0.11.4,,4,0
openstack%2Fpuppet-tripleo~stable%2Fqueens~I30f03bc8eb81db0243c137d4af08924adeebc951,openstack/puppet-tripleo,stable/queens,I30f03bc8eb81db0243c137d4af08924adeebc951,Deep merge hiera keys for mysqld_options,MERGED,2019-10-16 17:57:16.000000000,2019-10-17 11:45:02.000000000,2019-10-17 11:45:01.000000000,"[{'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 17:57:16.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/82fa648afad9835be368ba856e9ec95aa7b24165', 'message': ""Deep merge hiera keys for mysqld_options\n\nCurrently when adding some tuning options via hiera, galera won't start because\noverriding even a single mysql option will reset the whole key in the hash. So\nfor example, when adding:\n    tripleo::profile::base::database::mysql::mysql_server_options:\n      mysqld:\n        # MySQL InnoDB equally divided in 1GB instances\n        innodb_buffer_pool_instances: 2\n        # Query network write timeout raised to 120 seconds\n        net_write_timeout: 120\n        # Query network read timeout raised to 120 seconds\n        net_read_timeout: 120\n        # MySQL connection timeout set to 8 hours\n        connect_timeout: 28800\n\nThings will break because all the wsrep options that are set normally will be\noverridden and galera will refuse to start\n\nTested by passing the above hiera keys and observing the deploy complete\nsuccessfully and the settings correctly applied to galera/mysql on the overcloud.\n\nChange-Id: I30f03bc8eb81db0243c137d4af08924adeebc951\nCloses-Bug: #1848060\n(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)\n(cherry picked from commit d12fe87318264c9423e6bc0ac509fa2978261f1c)\n(cherry picked from commit 82e304a419698e1243765557b66ee2ebd83d03bc)\n""}]",0,688992,82fa648afad9835be368ba856e9ec95aa7b24165,9,4,1,20172,,,0,"Deep merge hiera keys for mysqld_options

Currently when adding some tuning options via hiera, galera won't start because
overriding even a single mysql option will reset the whole key in the hash. So
for example, when adding:
    tripleo::profile::base::database::mysql::mysql_server_options:
      mysqld:
        # MySQL InnoDB equally divided in 1GB instances
        innodb_buffer_pool_instances: 2
        # Query network write timeout raised to 120 seconds
        net_write_timeout: 120
        # Query network read timeout raised to 120 seconds
        net_read_timeout: 120
        # MySQL connection timeout set to 8 hours
        connect_timeout: 28800

Things will break because all the wsrep options that are set normally will be
overridden and galera will refuse to start

Tested by passing the above hiera keys and observing the deploy complete
successfully and the settings correctly applied to galera/mysql on the overcloud.

Change-Id: I30f03bc8eb81db0243c137d4af08924adeebc951
Closes-Bug: #1848060
(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)
(cherry picked from commit d12fe87318264c9423e6bc0ac509fa2978261f1c)
(cherry picked from commit 82e304a419698e1243765557b66ee2ebd83d03bc)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/92/688992/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,82fa648afad9835be368ba856e9ec95aa7b24165,fix-stable/stein-stable/rocky-stable/queens," $mysqld_options = deep_merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)"," $mysqld_options = merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)",1,1
openstack%2Ftripleo-heat-templates~master~I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da,openstack/tripleo-heat-templates,master,I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da,Normalise all pacemaker resource upgrade tasks for staged upgrades,MERGED,2019-10-04 16:31:55.000000000,2019-10-17 11:44:59.000000000,2019-10-17 11:44:59.000000000,"[{'_account_id': 6816}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-04 16:31:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2ec56dad57f560b1830fffc2f842d2b5f8029968', 'message': 'Normalise all pacemaker resource upgrade tasks for staged upgrades\n\nTo follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now\nnormalise all the resource upgrade tasks to improve idempotency and\nspeed up the process of verifying and upgrading images as necessary.\n\nChange-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da\nRelated-Bug: #1838971\nCloses: rhbz#1758578\n'}, {'number': 2, 'created': '2019-10-04 17:01:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/41fa59a24d09a9c5e422d8b6b7b3c51b5f15fdf0', 'message': ""Normalise all pacemaker resource upgrade tasks for staged upgrades\n\nTo follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now\nnormalise all the resource upgrade tasks to improve idempotency and\nspeed up the process of verifying and upgrading images as necessary.\n\nIn doing so we clean up a few things as well:\n\n1. There were some unnecessary blocks present without conditions\n   or any shared properties for the tasks.\n2. Use the pacemaker_resource module where possible rather than\n   the command module.\n3. Use 'failed_when: false' rather than 'ignore_errors: true'\n   because ignoring errors shows a failed task which is confusing\n   to users.\n4. Some tasks had an empty conditional.\n\nChange-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da\nRelated-Bug: #1838971\nCloses: rhbz#1758578\n""}, {'number': 3, 'created': '2019-10-08 15:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1ac570d509624685ca847ff725eebd7ff60cdc35', 'message': ""Normalise all pacemaker resource upgrade tasks for staged upgrades\n\nTo follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now\nnormalise all the resource upgrade tasks to improve idempotency and\nspeed up the process of verifying and upgrading images as necessary.\n\nIn doing so we clean up a few things as well:\n\n1. There were some unnecessary blocks present without conditions\n   or any shared properties for the tasks.\n2. Use 'failed_when: false' rather than 'ignore_errors: true'\n   because ignoring errors shows a failed task which is confusing\n   to users.\n3. Some tasks had an empty conditional.\n\nChange-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da\nRelated-Bug: #1838971\nCloses: rhbz#1758578\n""}, {'number': 4, 'created': '2019-10-08 15:19:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/afa5e75b2e51167b7b52225c048bc2f96ac8f04b', 'message': ""Normalise all pacemaker resource upgrade tasks for staged upgrades\n\nTo follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now\nnormalise all the resource upgrade tasks to improve idempotency and\nspeed up the process of verifying and upgrading images as necessary.\n\nIn doing so we clean up a few things as well:\n\n1. There were some unnecessary blocks present without conditions\n   or any shared properties for the tasks.\n2. Use 'failed_when: false' rather than 'ignore_errors: true'\n   because ignoring errors shows a failed task which is confusing\n   to users.\n3. Some tasks had an empty conditional.\n\nChange-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da\nRelated-Bug: #1838971\nCloses: rhbz#1758578\n""}, {'number': 5, 'created': '2019-10-16 10:57:19.000000000', 'files': ['deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dfd8b730049d47d58c02ba3d27e3c3406a19a840', 'message': ""Normalise all pacemaker resource upgrade tasks for staged upgrades\n\nTo follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now\nnormalise all the resource upgrade tasks to improve idempotency and\nspeed up the process of verifying and upgrading images as necessary.\n\nIn doing so we clean up a few things as well:\n\n1. There were some unnecessary blocks present without conditions\n   or any shared properties for the tasks.\n2. Use 'failed_when: false' rather than 'ignore_errors: true'\n   because ignoring errors shows a failed task which is confusing\n   to users.\n3. Some tasks had an empty conditional.\n\nChange-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da\nRelated-Bug: #1838971\nCloses: rhbz#1758578\n""}]",4,686769,dfd8b730049d47d58c02ba3d27e3c3406a19a840,36,6,5,6816,,,0,"Normalise all pacemaker resource upgrade tasks for staged upgrades

To follow on from I2e88dc34fa59624523de4c52a1873438c78e972f we now
normalise all the resource upgrade tasks to improve idempotency and
speed up the process of verifying and upgrading images as necessary.

In doing so we clean up a few things as well:

1. There were some unnecessary blocks present without conditions
   or any shared properties for the tasks.
2. Use 'failed_when: false' rather than 'ignore_errors: true'
   because ignoring errors shows a failed task which is confusing
   to users.
3. Some tasks had an empty conditional.

Change-Id: I8b5b25d03b86b2c44b2d47e5a0624e7dd13873da
Related-Bug: #1838971
Closes: rhbz#1758578
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/69/686769/5 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml']",7,2ec56dad57f560b1830fffc2f842d2b5f8029968,," - name: Temporarily tag the current galera image id with the upgraded image name import_role: name: tripleo-container-tag vars: container_image: ""{{galera_image_current}}"" container_image_latest: ""{{galera_image_latest}}"" pull_image: false when: - galera_image_current != '' - galera_image_current != galera_image_latest pacemaker_resource: resource: galera_bundle state: show check_mode: false ignore_errors: true"," - name: Prepare the switch to new galera container image name in pacemaker block: - name: Temporarily tag the current galera image id with the upgraded image name import_role: name: tripleo-container-tag vars: container_image: ""{{galera_image_current}}"" container_image_latest: ""{{galera_image_latest}}"" pull_image: false when: - galera_image_current != '' - galera_image_current != galera_image_latest shell: pcs resource config galera-bundle failed_when: false",251,216
openstack%2Ftripleo-quickstart-extras~master~I7d105d5f7167ffc0dda5241b3bd96aeda11dd451,openstack/tripleo-quickstart-extras,master,I7d105d5f7167ffc0dda5241b3bd96aeda11dd451,Enusre that clouds.yaml can be copied from remote,MERGED,2019-10-11 15:28:24.000000000,2019-10-17 11:44:51.000000000,2019-10-17 11:44:51.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 11491}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-10-11 15:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/532a6071984cf28a8e7fef5f711350d94a8159af', 'message': 'check both /etc/ and home for clouds.yaml\n\nmaster now only builds the clouds.yaml file in\n/etc/openstack.  Check both dirs for creds.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n'}, {'number': 2, 'created': '2019-10-11 17:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/409514d22efc80ddaf145cc178b3a7633169b8b8', 'message': 'check both /etc/ and home for clouds.yaml\n\nmaster now only builds the clouds.yaml file in\n/etc/openstack.  Check both dirs for creds.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n'}, {'number': 3, 'created': '2019-10-14 02:23:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/9e321cf5893cd110384260cb27277fde162be5cf', 'message': 'check both /etc/ and home for clouds.yaml\n\nmaster now only builds the clouds.yaml file in\n/etc/openstack.  Check both dirs for creds.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n'}, {'number': 4, 'created': '2019-10-16 12:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/af3b1291551f2e7cb3347ca6269994aebbb28a89', 'message': ""check both /etc/ and home for clouds.yaml\n\nAddr emote_src: true in that copy task\nfor clouds.yaml for when the 'primary' host is\ndifferent than undercloud in the deployment.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n""}, {'number': 5, 'created': '2019-10-16 12:55:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a9916340b53149b6fd85fee2a9a5b426774cf079', 'message': ""Enusre that clouds.yaml can be copied from remote\n\nAdd remote_src: true in that copy task\nfor clouds.yaml for when the 'primary' host is\ndifferent than undercloud in the deployment.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n""}, {'number': 6, 'created': '2019-10-16 16:34:54.000000000', 'files': ['playbooks/tempest.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/d7128c52d11bf947d84fd9b01c6d2e89f7fb32d0', 'message': ""Enusre that clouds.yaml can be copied from remote\n\nAdd remote_src: true in that copy task\nfor clouds.yaml for when the 'primary' host is\ndifferent than undercloud in the deployment.\n\nCloses-Bug: #1847790\nChange-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451\n""}]",7,688148,d7128c52d11bf947d84fd9b01c6d2e89f7fb32d0,37,11,6,9592,,,0,"Enusre that clouds.yaml can be copied from remote

Add remote_src: true in that copy task
for clouds.yaml for when the 'primary' host is
different than undercloud in the deployment.

Closes-Bug: #1847790
Change-Id: I7d105d5f7167ffc0dda5241b3bd96aeda11dd451
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/48/688148/4 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/tempest.yml'],1,532a6071984cf28a8e7fef5f711350d94a8159af,I7d105d5f7167ffc0dda5241b3bd96aeda11dd451,# master now places clouds.yaml in /etc/openstack/ # older versions may still drop the file in the user # home directory. block: - name: check $HOME/.config/openstack/clouds.yaml copy: src: '{{ ansible_user_dir }}/.config/openstack/clouds.yaml' dest: '/root/.config/openstack/clouds.yaml' mode: 0600 become: true rescue: - name: check /etc/openstack copy: src: '/etc/openstack/clouds.yaml' dest: '/root/.config/openstack/clouds.yaml' mode: 0600 become: true, copy: src: '{{ ansible_user_dir }}/.config/openstack/clouds.yaml' dest: '/root/.config/openstack/clouds.yaml' mode: 0600 become: true,17,5
openstack%2Freleases~master~Ifee25a01b6296c542feebe6d611ec057729f8fbb,openstack/releases,master,Ifee25a01b6296c542feebe6d611ec057729f8fbb,train: release and branch tripleo-common,MERGED,2019-10-17 02:42:56.000000000,2019-10-17 11:43:18.000000000,2019-10-17 11:43:18.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 02:42:56.000000000', 'files': ['deliverables/train/tripleo-common.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/5b4994348d3aec62868ef569495b9ee1e7ee084d', 'message': ""train: release and branch tripleo-common\n\nWe branched tripleoclient, now we want to branch tripleo-common and when\nwe know it all works fine, we'll finish with all other projects at the\nsame time.\n\nChange-Id: Ifee25a01b6296c542feebe6d611ec057729f8fbb\n""}]",0,689067,5b4994348d3aec62868ef569495b9ee1e7ee084d,7,3,1,3153,,,0,"train: release and branch tripleo-common

We branched tripleoclient, now we want to branch tripleo-common and when
we know it all works fine, we'll finish with all other projects at the
same time.

Change-Id: Ifee25a01b6296c542feebe6d611ec057729f8fbb
",git fetch https://review.opendev.org/openstack/releases refs/changes/67/689067/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/tripleo-common.yaml'],1,5b4994348d3aec62868ef569495b9ee1e7ee084d,tripleo/train/branch, - version: 11.3.0 projects: - repo: openstack/tripleo-common hash: 027a33befd385875a1f8b521bcf649e5adace156 branches: - location: 11.3.0 name: stable/train,,7,0
openstack%2Fnova~master~I8e97781973c2964526641d7dac2a28aa0133564d,openstack/nova,master,I8e97781973c2964526641d7dac2a28aa0133564d,Should not raise when restore power on failed,NEW,2018-12-13 03:27:36.000000000,2019-10-17 11:39:43.000000000,,"[{'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 10385}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15888}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 23676}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2018-12-13 03:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/428770d6f9e7f84c81a257224cdd04cf6f9dee6f', 'message': 'ESFIX: Should not raise while restore power on failed\n\ninstance task_state will be reverted to None if raise exception while\npower on failed, and will be reclaimed in ``_reclaim_queued_deletes``\nfor its deleted_at=None, task_state=None, vm_state=SOFT_DELETED\n\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\nCloses-Bug: #EAS-21604\n'}, {'number': 2, 'created': '2018-12-13 03:30:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ccf92569c84e670ec8b2d3e4d8f159f7e9936235', 'message': 'Should not raise while restore power on failed\n\ninstance task_state will be reverted to None if raise exception while\npower on failed, and will be reclaimed in ``_reclaim_queued_deletes``\nfor its deleted_at=None, task_state=None, vm_state=SOFT_DELETED\n\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n'}, {'number': 3, 'created': '2018-12-14 09:30:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/45835d62881fc83aa899a89c8c8971a76fd60dcd', 'message': 'Should not raise while restore power on failed\n\ninstance task_state will be reverted to None if raise exception while\npower on failed, and will be reclaimed in ``_reclaim_queued_deletes``\nfor its deleted_at=None, task_state=None, vm_state=SOFT_DELETED\n\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n'}, {'number': 4, 'created': '2018-12-14 11:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/915e8bdc1e379eaac124dd8f3b31ff9f4608c5e8', 'message': 'Should not raise while restore power on failed\n\ninstance task_state will be reverted to None if raise exception while\npower on failed, and will be reclaimed in ``_reclaim_queued_deletes``\nfor its deleted_at=None, task_state=None, vm_state=SOFT_DELETED\n\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n'}, {'number': 5, 'created': '2019-08-27 08:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/21db5edec1b1156c1165b0e1aa3dcb7e59f4489a', 'message': ""Should not raise when restore power on failed\n\nSoft deleted instance will be reclaimed if any exceptions raised when\npowering on during a instance restore. Instance state will be set to\n`{'vm_state': 'soft_delete', 'task_state': None, 'deleted_at': None}`\nif above situation happend, and instance in this state will be\nreclaimed in nova compute periodic task `_reclaim_queued_deletes`\nthat running every 60s. Catch the exception that may raise, keep\nrestoring instance even if power on failed.\n\nCloses-Bug: 1841509\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n""}, {'number': 6, 'created': '2019-08-27 12:07:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e79bf92613528ee22d191b2d7db56da2eb2613ce', 'message': ""Should not raise when restore power on failed\n\nSoft deleted instance will be reclaimed if any exceptions raised when\npowering on during a instance restore. Instance state will be set to\n`{'vm_state': 'soft_delete', 'task_state': None, 'deleted_at': None}`\nif above situation happend, and instance in this state will be\nreclaimed in nova compute periodic task `_reclaim_queued_deletes`\nthat running every 60s. Catch the exception that may raise, keep\nrestoring instance even if power on failed.\n\nCloses-Bug: 1841509\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n""}, {'number': 7, 'created': '2019-10-16 02:11:38.000000000', 'files': ['nova/tests/unit/compute/test_compute_mgr.py', 'nova/compute/manager.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/8449388634daebf976b4120d359a6ea8cd6fdc03', 'message': ""Should not raise when restore power on failed\n\nSoft deleted instance will be reclaimed if any exceptions raised when\npowering on during a instance restore. Instance state will be set to\n`{'vm_state': 'soft_delete', 'task_state': None, 'deleted_at': None}`\nif above situation happend, and instance in this state will be\nreclaimed in nova compute periodic task `_reclaim_queued_deletes`\nthat running every 60s. Catch the exception that may raise, keep\nrestoring instance even if power on failed.\n\nCloses-Bug: 1841509\nChange-Id: I8e97781973c2964526641d7dac2a28aa0133564d\n""}]",5,624854,8449388634daebf976b4120d359a6ea8cd6fdc03,69,17,7,23676,,,0,"Should not raise when restore power on failed

Soft deleted instance will be reclaimed if any exceptions raised when
powering on during a instance restore. Instance state will be set to
`{'vm_state': 'soft_delete', 'task_state': None, 'deleted_at': None}`
if above situation happend, and instance in this state will be
reclaimed in nova compute periodic task `_reclaim_queued_deletes`
that running every 60s. Catch the exception that may raise, keep
restoring instance even if power on failed.

Closes-Bug: 1841509
Change-Id: I8e97781973c2964526641d7dac2a28aa0133564d
",git fetch https://review.opendev.org/openstack/nova refs/changes/54/624854/5 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/manager.py'],1,428770d6f9e7f84c81a257224cdd04cf6f9dee6f,bug/1841509," try: # should not raise exception while power on failed # its task_state will be reverted to None if raise exception # and will be reclaimed in _reclaim_queued_deletes for its # deleted_at=None, task_state=None, vm_state=SOFT_DELETED self._power_on(context, instance) except Exception as ex: LOG.exception(_LE(""Something wrong happened when trying to "" ""power on while restore instance. ex:%s""), ex, instance=instance) # set vm_state to STOPPED if power on failed if instance.power_state == power_state.SHUTDOWN: instance.vm_state = vm_states.STOPPED else: instance.vm_state = vm_states.ACTIVE"," self._power_on(context, instance) instance.vm_state = vm_states.ACTIVE",16,2
openstack%2Freleases~master~I3fb5f42928475151d0e1ceb4136557ef5ea5b569,openstack/releases,master,I3fb5f42928475151d0e1ceb4136557ef5ea5b569,Release vitrage 5.0.1 for Train,MERGED,2019-10-17 06:07:25.000000000,2019-10-17 11:35:34.000000000,2019-10-17 11:35:33.000000000,"[{'_account_id': 308}, {'_account_id': 1736}, {'_account_id': 11904}, {'_account_id': 19159}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 06:07:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/0a1ea75b0e640f0061cdf01c216ba3bd0c45356b', 'message': 'Release vitrage 5.0.1 for Train\n\nChange-Id: I3fb5f42928475151d0e1ceb4136557ef5ea5b569\n'}, {'number': 2, 'created': '2019-10-17 06:21:19.000000000', 'files': ['deliverables/train/vitrage.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/cf37bfdb2a235ea885809219968e2e519e424c23', 'message': 'Release vitrage 5.0.1 for Train\n\nChange-Id: I3fb5f42928475151d0e1ceb4136557ef5ea5b569\n'}]",0,689077,cf37bfdb2a235ea885809219968e2e519e424c23,9,5,2,19134,,,0,"Release vitrage 5.0.1 for Train

Change-Id: I3fb5f42928475151d0e1ceb4136557ef5ea5b569
",git fetch https://review.opendev.org/openstack/releases refs/changes/77/689077/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/vitrage.yaml'],1,0a1ea75b0e640f0061cdf01c216ba3bd0c45356b,, - version: 5.0.1 projects: - repo: openstack/vitrage hash: 1e1c7d7b320715a65b199ee8548ddce68a25d7ad,,4,0
openstack%2Frequirements~master~Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,openstack/requirements,master,Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32,Switch to opensuse-15 nodeset,MERGED,2019-10-16 19:43:33.000000000,2019-10-17 11:15:33.000000000,2019-10-17 10:33:26.000000000,"[{'_account_id': 6547}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 19:43:33.000000000', 'files': ['.zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/requirements/commit/1577c44e8ce14e36dc0c7a52207624779148554a', 'message': 'Switch to opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThe new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,\nchange tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.\n\nChange-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32\n'}]",0,689022,1577c44e8ce14e36dc0c7a52207624779148554a,12,4,1,6547,,,0,"Switch to opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

The new job tempest-full-py3-opensuse15 use the opensuse-15 nodeset,
change tempest-full-py3-opensuse150 to tempest-full-py3-opensuse15.

Change-Id: Ib7b4893d3f3b5fe75bb660f9273bafde4bb5ae32
",git fetch https://review.opendev.org/openstack/requirements refs/changes/22/689022/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/project.yaml'],1,1577c44e8ce14e36dc0c7a52207624779148554a,opensuse-150, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Fmonasca-ui~master~Ia2d2c41ecc11173229e9c73bd5bc89c9a0ad48f1,openstack/monasca-ui,master,Ia2d2c41ecc11173229e9c73bd5bc89c9a0ad48f1,Switch to official Ussuri jobs,MERGED,2019-10-14 07:02:04.000000000,2019-10-17 10:43:23.000000000,2019-10-17 10:43:23.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-10-14 07:02:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/ea41551103ad4819fe4977b32d8d4b16d57eeeec', 'message': 'Switch to official Ussuri jobs\n\nChange-Id: Ia2d2c41ecc11173229e9c73bd5bc89c9a0ad48f1\n'}]",0,688339,ea41551103ad4819fe4977b32d8d4b16d57eeeec,7,3,1,29313,,,0,"Switch to official Ussuri jobs

Change-Id: Ia2d2c41ecc11173229e9c73bd5bc89c9a0ad48f1
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/39/688339/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,ea41551103ad4819fe4977b32d8d4b16d57eeeec,, - openstack-python3-ussuri-jobs-horizon, - openstack-python3-train-jobs-horizon,1,1
openstack%2Fkolla-ansible~master~I324c250e57125910b64fad6c06a4d68acf0600b4,openstack/kolla-ansible,master,I324c250e57125910b64fad6c06a4d68acf0600b4,Add a spec for ceph-ansible,MERGED,2018-02-15 14:24:18.000000000,2019-10-17 10:41:57.000000000,2019-10-17 10:38:58.000000000,"[{'_account_id': 14826}, {'_account_id': 17491}, {'_account_id': 19316}, {'_account_id': 20663}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22582}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 28743}, {'_account_id': 30491}]","[{'number': 1, 'created': '2018-02-15 14:24:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b4371051e790b62e8c7781ceeb5370dd2ca8ed56', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 2, 'created': '2018-02-22 12:29:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c8693c5d40247e06151d4fd82a829714b948ca93', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 3, 'created': '2019-08-19 08:02:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6e887ed78a4245b50521f6f1984f1b68b464f189', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 4, 'created': '2019-08-19 08:04:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fc24a4a8028e6cf845c8c07a2aff01f3251417c1', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 5, 'created': '2019-08-21 08:31:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ca6e4f376ddeaa22593bf4e7486d6bbd7d8a4744', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 6, 'created': '2019-08-21 14:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c99002cc0149ccc3677d5e5796e94e1c3ba7324c', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}, {'number': 7, 'created': '2019-10-17 09:06:48.000000000', 'files': ['specs/ceph-ansible.rst'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10ca56b9810484b9f65111daf86871d5e01c50e1', 'message': 'Add a spec for ceph-ansible\n\nChange-Id: I324c250e57125910b64fad6c06a4d68acf0600b4\n'}]",11,544980,10ca56b9810484b9f65111daf86871d5e01c50e1,39,11,7,1390,,,0,"Add a spec for ceph-ansible

Change-Id: I324c250e57125910b64fad6c06a4d68acf0600b4
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/80/544980/3 && git format-patch -1 --stdout FETCH_HEAD,['specs/ceph-ansible.rst'],1,b4371051e790b62e8c7781ceeb5370dd2ca8ed56,,".. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. The filename in the git repository should match the launchpad URL, for example a URL of https://blueprints.launchpad.net/kolla/+spec/awesome-thing should be named awesome-thing.rst . Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: None For help with syntax, see http://www.sphinx-doc.org/en/stable/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ================================= Moving to ceph-ansible for Kolla ================================= Include the URL of your launchpad blueprint: https://blueprints.launchpad.net/kolla/+spec/example It has been discussed within the Kolla community that we should look at moving from our own orchestration and containers for Ceph to those provided by the 'ceph-ansible' project. This spec proposes how this should happen. Problem description =================== Ceph is a complex project that exists outside of OpenStack. As new versions of Ceph are released, the Kolla community have had to spend time and resources ensuring that our implementation is up to date, upgrade works correctly, etc, in addition to the multiple OpenStack services we support. Meanwhile, there are other existing projects that work just on Ceph, and can potentially do this much better. ceph-ansible is one such project that is part of the official Ceph project namespace[0]. This gives us a reasonable degree of certainty that it can provide a more complete and well maintained implementation of Ceph than Kolla can provide on it's own. Security impact --------------- From a high level this should not have any security impact. It is possible security would be even improved over what we have now, due to the active community maintaining the ceph-ansible project[1]. Performance Impact ------------------ We see no potential performance impact. The time for deploying ceph-ansible may end up being slightly longer or shorter when compared to Kolla's Ceph, but the difference should not be big. Implementation ============== Assignee(s) ----------- Primary assignee: pbourke Milestones ---------- Target Milestone for completion: rocky Work Items ---------- 1. Mark the current implementation of Ceph in Kolla as deprecated in the Queens cycle. The ceph-ansible implementation should be ready for the release of Rocky. 2. Provide concise documentation on how a Kolla operator should go about deploying ceph-ansible in a way that's consistent with Kolla best practices. 3. Ensure we have a sensible and easy to follow upgrade path for those currently running Kolla's implementation of Ceph in production. 4. The current Kolla gates for Ceph will need to be updated. Testing ======= See work item number 4 above. Documentation Impact ==================== See work item number 2 above. References ========== [0] http://docs.ceph.com/ceph-ansible/master/ [1] https://github.com/ceph/ceph-ansible/graphs/contributors ",,94,0
openstack%2Fkolla-ansible~master~I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1,openstack/kolla-ansible,master,I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1,Set RabbitMQ cluster_partition_handling to pause_minority,MERGED,2019-07-24 16:42:39.000000000,2019-10-17 10:40:55.000000000,2019-10-17 10:38:56.000000000,"[{'_account_id': 14826}, {'_account_id': 16006}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-07-24 16:42:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ea5cb7126d1b290d61ab1f50ea7d98d696a6d6af', 'message': 'Add RabbitMQ network partition policy option\n\nBy defaut, the RabbitMQ network policy should not be\nset to autoheal which could result to a split-brain\nbut to pause_minority or even ignore.\n\nUser should be able to choose the policy by using an\noption in globals.yml.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 2, 'created': '2019-07-24 17:31:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/70a0b9a38d83ed94a94dab124e0e81444dabd134', 'message': 'Determine RabbitMQ network partition policy\n\nSet RabbitMQ network partition handling policy automatically\nto pause_minority if role_rabbitmq_groups group has three\nnodes and more.\n\nautoheal policy will remains for two nodes and all-in-one\ndeployments.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 3, 'created': '2019-07-24 17:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b1e6f55a3318e31808efe826e4a97f06e11d537c', 'message': 'Adapt RabbitMQ network partition policy\n\nSet RabbitMQ network partition handling policy automatically\nto pause_minority if rabbitmq group has three nodes or more.\n\nautoheal policy will stay for two nodes and all-in-one\ndeployments.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 4, 'created': '2019-07-24 19:33:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2c4631777a7a55290241d2b56a14559a83462500', 'message': 'Adapt RabbitMQ network partition policy\n\nSet RabbitMQ network partition handling policy automatically\nto pause_minority if rabbitmq group has three nodes or more.\n\nautoheal policy will stay for two nodes and all-in-one\ndeployments.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 5, 'created': '2019-07-25 08:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/98d21da12978929be8bde7f37269496d9eec14cb', 'message': 'Adapt RabbitMQ cluster_partition_handling\n\nSet RabbitMQ cluster_partition_handling to pause_minority\nif deploying at least a 3-node RabbitMQ cluster.\nThis is to avoid split-brain.\nautoheal policy stays for 2-node clusters.\n\nNote that the setting is irrelevant for 1-node deployments.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 6, 'created': '2019-10-01 16:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3310407336989667373138061ae97f489a046052', 'message': 'Adapt RabbitMQ cluster_partition_handling\n\nSet RabbitMQ cluster_partition_handling to pause_minority\nif deploying at least a 3-node RabbitMQ cluster.\nThis is to avoid split-brain.\nautoheal policy stays for 2-node clusters.\n\nNote that the setting is irrelevant for 1-node deployments.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 7, 'created': '2019-10-01 19:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d20c4c8f6b47c3e50404de17b7b1784d6ef186e9', 'message': 'Adapt RabbitMQ cluster_partition_handling\n\nSet RabbitMQ cluster_partition_handling to pause_minority\nif deploying at least a 3-node RabbitMQ cluster.\nThis is to avoid split-brain.\nautoheal policy stays for 2-node clusters.\n\nNote that the setting is irrelevant for 1-node deployments.\n\nFIXME\n\nDepends-on: https://review.opendev.org/686032\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\n'}, {'number': 8, 'created': '2019-10-14 08:42:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e56f3c532a6612b384e616ea173112e9c1dd9a8d', 'message': 'Set RabbitMQ cluster_partition_handling to pause_minority\n\nThis is to avoid split-brain.\n\nThis change also adds relevant docs that sort out the\nHA/quorum questions.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\nCo-authored-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 9, 'created': '2019-10-14 08:44:30.000000000', 'files': ['ansible/roles/rabbitmq/templates/rabbitmq.conf.j2', 'doc/source/admin/production-architecture-guide.rst', 'releasenotes/notes/change-rabbitmq-partition-handling-5aebe0bf7e361239.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5b0a281d5122d1806f2e689f5b5c7f48658b41d7', 'message': 'Set RabbitMQ cluster_partition_handling to pause_minority\n\nThis is to avoid split-brain.\n\nThis change also adds relevant docs that sort out the\nHA/quorum questions.\n\nChange-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1\nCloses-Bug: #1837761\nCo-authored-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}]",16,672562,5b0a281d5122d1806f2e689f5b5c7f48658b41d7,47,6,9,16006,,,0,"Set RabbitMQ cluster_partition_handling to pause_minority

This is to avoid split-brain.

This change also adds relevant docs that sort out the
HA/quorum questions.

Change-Id: I9a8c2ec4dbbd0318beb488548b2cde8f4e487dc1
Closes-Bug: #1837761
Co-authored-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/62/672562/6 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-rabbitmq-partition-handling-option-5aebe0bf7e361239.yaml', 'ansible/group_vars/all.yml', 'ansible/roles/rabbitmq/templates/rabbitmq.conf.j2']",3,ea5cb7126d1b290d61ab1f50ea7d98d696a6d6af,bug/1837761,cluster_partition_handling = {{ rabbitmq_cluster_partition_handling }},cluster_partition_handling = autoheal,10,1
openstack%2Fnova~stable%2Fqueens~I4b606fce473d064b9bb00213696c075cea020aaf,openstack/nova,stable/queens,I4b606fce473d064b9bb00213696c075cea020aaf,Fix 'has_calls' method calls in unit tests,MERGED,2019-08-20 03:41:04.000000000,2019-10-17 10:33:30.000000000,2019-10-17 10:33:30.000000000,"[{'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 17685}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-08-20 03:41:04.000000000', 'files': ['nova/tests/unit/virt/hyperv/test_hostops.py', 'nova/tests/unit/virt/hyperv/test_vmops.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/virt/hyperv/test_snapshotops.py', 'nova/tests/unit/virt/libvirt/test_driver.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/eca5608fe35728b12fc4d817f4a7e0a783219047', 'message': ""Fix 'has_calls' method calls in unit tests\n\nThe 'has_calls' method does not exist in assertion methods of mock.\nReplace the 'has_calls' method with an 'assert_has_calls' method or\nan 'assert_called_once_with' method.\nAdd an 'assertEqual' check before an 'assert_has_calls' method.\n\nConflicts:\n    nova/tests/unit/virt/ironic/test_driver.py\n\nNOTE(takashin): The conflict is due to not having the following change\nin stable/queens.\n\n    I87f085589bb663c519650f307f25d087c88bbdb1\n\nChange-Id: I4b606fce473d064b9bb00213696c075cea020aaf\nCloses-Bug: #1840200\n(cherry picked from commit ad482e53fbb956288e73692f6bff5f74d862fe5d)\n(cherry picked from commit fa59033c40745febc26399e668ceb9911f8ec45d)\n(cherry picked from commit 8e7e54f60b0374d6439a4cedc098c5a3c97b79d9)\n""}]",0,677378,eca5608fe35728b12fc4d817f4a7e0a783219047,9,5,1,7634,,,0,"Fix 'has_calls' method calls in unit tests

The 'has_calls' method does not exist in assertion methods of mock.
Replace the 'has_calls' method with an 'assert_has_calls' method or
an 'assert_called_once_with' method.
Add an 'assertEqual' check before an 'assert_has_calls' method.

Conflicts:
    nova/tests/unit/virt/ironic/test_driver.py

NOTE(takashin): The conflict is due to not having the following change
in stable/queens.

    I87f085589bb663c519650f307f25d087c88bbdb1

Change-Id: I4b606fce473d064b9bb00213696c075cea020aaf
Closes-Bug: #1840200
(cherry picked from commit ad482e53fbb956288e73692f6bff5f74d862fe5d)
(cherry picked from commit fa59033c40745febc26399e668ceb9911f8ec45d)
(cherry picked from commit 8e7e54f60b0374d6439a4cedc098c5a3c97b79d9)
",git fetch https://review.opendev.org/openstack/nova refs/changes/78/677378/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/virt/hyperv/test_hostops.py', 'nova/tests/unit/compute/test_compute_mgr.py', 'nova/tests/unit/virt/hyperv/test_vmops.py', 'nova/tests/unit/virt/hyperv/test_snapshotops.py', 'nova/tests/unit/virt/libvirt/test_driver.py']",5,eca5608fe35728b12fc4d817f4a7e0a783219047,bug/1840200," ' <address bus=""0x00"" domain=""0x0000"" ' 'function=""0x0"" slot=""0x00""/>\n' ' <address bus=""0x00"" domain=""0x0000"" ' 'function=""0x1"" slot=""0x00""/>\n' self.assertEqual(2, mock_detachDeviceFlags.call_count) mock_detachDeviceFlags.assert_has_calls(["," ' <address bus=""0x00"" domain=""0x0000"" \ function=""0x0"" slot=""0x00""/>\n' ' <address bus=""0x00"" domain=""0x0000"" \ function=""0x1"" slot=""0x00""/>\n' mock_detachDeviceFlags.has_calls([",25,17
openstack%2Freleases~master~I8b1509d88fb57e35eb0b30c33f56a3eebb6574b6,openstack/releases,master,I8b1509d88fb57e35eb0b30c33f56a3eebb6574b6,Add pike-eol tags for kolla and kolla-ansible,MERGED,2019-10-10 08:02:39.000000000,2019-10-17 10:10:18.000000000,2019-10-17 10:10:18.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 28543}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-10 08:02:39.000000000', 'files': ['deliverables/pike/kolla.yaml', 'deliverables/pike/kolla-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/f288586b5e657182968b9ee730e41e17dac7a140', 'message': 'Add pike-eol tags for kolla and kolla-ansible\n\nWe agreed at the last meeting to move to EOL.\n\nChange-Id: I8b1509d88fb57e35eb0b30c33f56a3eebb6574b6\n'}]",0,687816,f288586b5e657182968b9ee730e41e17dac7a140,13,9,1,14826,,,0,"Add pike-eol tags for kolla and kolla-ansible

We agreed at the last meeting to move to EOL.

Change-Id: I8b1509d88fb57e35eb0b30c33f56a3eebb6574b6
",git fetch https://review.opendev.org/openstack/releases refs/changes/16/687816/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/pike/kolla.yaml', 'deliverables/pike/kolla-ansible.yaml']",2,f288586b5e657182968b9ee730e41e17dac7a140,, - projects: - hash: dd69cc96de9e35755b2752a286ea30301e31caed repo: openstack/kolla-ansible version: pike-eol,,8,0
openstack%2Freleases~master~If272edb5ced55f0214bb64b8c70d9958b6658156,openstack/releases,master,If272edb5ced55f0214bb64b8c70d9958b6658156,Bug-fix releases for manila-ui,MERGED,2019-10-16 21:16:43.000000000,2019-10-17 10:10:17.000000000,2019-10-17 10:10:17.000000000,"[{'_account_id': 308}, {'_account_id': 9003}, {'_account_id': 11904}, {'_account_id': 14892}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 21:16:43.000000000', 'files': ['deliverables/train/manila-ui.yaml', 'deliverables/rocky/manila-ui.yaml', 'deliverables/stein/manila-ui.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/8d2e21fc588d2ad0e6eafe7827df3adcd0121610', 'message': 'Bug-fix releases for manila-ui\n\nRelease manila-ui 2.16.2 (stable/rocky),\n2.18.1 (stable/stein) and 2.19.1 (stable/train)\nto gather a critical bug-fix that affects\nquota control on all OpenStack resources\nvia OpenStack dashboard.\n\nChange-Id: If272edb5ced55f0214bb64b8c70d9958b6658156\nRelated-Bug: #1842119\n'}]",0,689047,8d2e21fc588d2ad0e6eafe7827df3adcd0121610,9,5,1,16643,,,0,"Bug-fix releases for manila-ui

Release manila-ui 2.16.2 (stable/rocky),
2.18.1 (stable/stein) and 2.19.1 (stable/train)
to gather a critical bug-fix that affects
quota control on all OpenStack resources
via OpenStack dashboard.

Change-Id: If272edb5ced55f0214bb64b8c70d9958b6658156
Related-Bug: #1842119
",git fetch https://review.opendev.org/openstack/releases refs/changes/47/689047/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/train/manila-ui.yaml', 'deliverables/rocky/manila-ui.yaml', 'deliverables/stein/manila-ui.yaml']",3,8d2e21fc588d2ad0e6eafe7827df3adcd0121610,manila-ui, - projects: - repo: openstack/manila-ui hash: cc52163a36cd4863ebe96bfef0a163b4190d01b2 version: 2.18.1,,12,0
openstack%2Ftripleo-quickstart~master~I18f7d3f1e29851b280f4c42549d41632c474c1d4,openstack/tripleo-quickstart,master,I18f7d3f1e29851b280f4c42549d41632c474c1d4,increase deploy timeout in ci.centos,MERGED,2019-10-10 15:12:21.000000000,2019-10-17 09:49:29.000000000,2019-10-12 08:01:12.000000000,"[{'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-10 15:12:21.000000000', 'files': ['config/environments/ci_centos_libvirt.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/f87828ce9cfbc2d5b342c72833ca77df218e0971', 'message': 'increase deploy timeout in ci.centos\n\nChange-Id: I18f7d3f1e29851b280f4c42549d41632c474c1d4\n'}]",2,687932,f87828ce9cfbc2d5b342c72833ca77df218e0971,14,4,1,9592,,,0,"increase deploy timeout in ci.centos

Change-Id: I18f7d3f1e29851b280f4c42549d41632c474c1d4
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/32/687932/1 && git format-patch -1 --stdout FETCH_HEAD,['config/environments/ci_centos_libvirt.yml'],1,f87828ce9cfbc2d5b342c72833ca77df218e0971,, # timeout overrides due to slow hardware # default is 90 deploy_timeout: 120,,4,0
openstack%2Fdevstack~master~I5f957e21a55b0fbc71837cb42cc0457819e97251,openstack/devstack,master,I5f957e21a55b0fbc71837cb42cc0457819e97251,lib/nova: Install mysql extra,ABANDONED,2019-08-26 09:16:45.000000000,2019-10-17 09:35:21.000000000,,"[{'_account_id': 11604}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-26 09:16:45.000000000', 'files': ['lib/nova'], 'web_link': 'https://opendev.org/openstack/devstack/commit/be0353e840ad96a4d51fa5724c94c390fb977c48', 'message': ""lib/nova: Install mysql extra\n\nnova is no longer providing 'mysql' in 'requirements.txt' but rather\nprovides a 'mysql' extra. Start using this.\n\nChange-Id: I5f957e21a55b0fbc71837cb42cc0457819e97251\nSigned-off-by: Stephen Finucane <sfinucan@redhat.com>\nDepends-on: 97e2339c3c1ad943ac616f08aaf7f6bb90cb7ab9\n""}]",1,678497,be0353e840ad96a4d51fa5724c94c390fb977c48,4,2,1,15334,,,0,"lib/nova: Install mysql extra

nova is no longer providing 'mysql' in 'requirements.txt' but rather
provides a 'mysql' extra. Start using this.

Change-Id: I5f957e21a55b0fbc71837cb42cc0457819e97251
Signed-off-by: Stephen Finucane <sfinucan@redhat.com>
Depends-on: 97e2339c3c1ad943ac616f08aaf7f6bb90cb7ab9
",git fetch https://review.opendev.org/openstack/devstack refs/changes/97/678497/1 && git format-patch -1 --stdout FETCH_HEAD,['lib/nova'],1,be0353e840ad96a4d51fa5724c94c390fb977c48,move-db-deps-to-extras, setup_develop $NOVA_DIR mysql, setup_develop $NOVA_DIR,1,1
openstack%2Fceilometer-powervm~master~Ia74d470a6d593a6a81779788e2848c5b5995c44f,openstack/ceilometer-powervm,master,Ia74d470a6d593a6a81779788e2848c5b5995c44f,Enable support for both python3.6 and python3.7,MERGED,2019-09-12 14:02:37.000000000,2019-10-17 09:35:07.000000000,2019-10-17 09:35:07.000000000,"[{'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28063}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-09-12 14:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ceilometer-powervm/commit/d27e32107047e18f388046b1ff627e894a9b0304', 'message': 'Enable support for both python3.6 and python3.7\n\nChange-Id: Ia74d470a6d593a6a81779788e2848c5b5995c44f\n'}, {'number': 2, 'created': '2019-09-17 03:52:22.000000000', 'files': ['setup.cfg', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ceilometer-powervm/commit/7ca211e7007b4444b543457c8627c29ab37483cb', 'message': 'Enable support for both python3.6 and python3.7\n\nChange-Id: Ia74d470a6d593a6a81779788e2848c5b5995c44f\n'}]",0,681755,7ca211e7007b4444b543457c8627c29ab37483cb,11,4,2,28063,,,0,"Enable support for both python3.6 and python3.7

Change-Id: Ia74d470a6d593a6a81779788e2848c5b5995c44f
",git fetch https://review.opendev.org/openstack/ceilometer-powervm refs/changes/55/681755/2 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'tox.ini']",2,d27e32107047e18f388046b1ff627e894a9b0304,,"envlist = py27,py36,py37,pep8","envlist = py36,py27,pep8",2,1
openstack%2Ftaskflow~master~Id2c82ce9563e114d34b68d8def04bb1a7a665726,openstack/taskflow,master,Id2c82ce9563e114d34b68d8def04bb1a7a665726,Instead of simple executor dispatch limiting use a custom semaphore,ABANDONED,2015-10-28 01:16:33.000000000,2019-10-17 09:24:35.000000000,,"[{'_account_id': 1297}, {'_account_id': 5164}, {'_account_id': 6486}, {'_account_id': 9648}, {'_account_id': 29911}]","[{'number': 1, 'created': '2015-10-28 01:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e69ebb4e3b8a0357f7e6433d36304387a016731f', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimulatenously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 2, 'created': '2015-10-28 01:22:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/783235d450f3db6c35e5f44c519aa40194fe3fed', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimulatenously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 3, 'created': '2015-10-28 02:33:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3a8dac62ad854aa35343798e69beb96b1acfd81e', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimulatenously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 4, 'created': '2015-10-28 04:00:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/de87b7d06a22fe408dfcf39d5e866f14e8992a82', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 5, 'created': '2015-10-28 05:11:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fe5b33765d104023f0d5870c668852c05d19d6f3', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 6, 'created': '2015-10-28 05:19:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/aa1fa6ed6d5ffe5304e9e81f0bab096f365c6410', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 7, 'created': '2015-10-28 05:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/74d5fbdf2c2d20e317c4a23c6217439ef52c63e0', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 8, 'created': '2015-10-28 05:25:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d2a065e51bacb805a92837291feeaacf43147969', 'message': 'Instead of simple dispatch limiting use a sempahore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 9, 'created': '2015-10-28 06:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e198db80a5f1affe5ee305ee402f69624f061aef', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a sempahore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 10, 'created': '2015-10-28 06:36:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/0dc0a8eabd0e2612585c646281e8ab4d722bf7b2', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 11, 'created': '2015-10-28 06:37:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/99b71b4ab876e5f6f96acd72b6a78a3eacbb8a13', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 12, 'created': '2015-10-29 00:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/f10ad4d3fbe96df3b3baf3c793d1df4e589fb1c9', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 13, 'created': '2015-10-29 02:02:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/20273a2026b86b0a39628d5956910f8afe360f5c', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 14, 'created': '2015-10-29 03:09:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2d71130a98714a4dbebd074ca7b7f2894110bb00', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 15, 'created': '2015-10-29 08:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/3d62d7fd500491bb2ee0a936ac8ca6e676e43f09', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 16, 'created': '2015-10-30 07:41:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/020377212f96241873a584ab1138b6347153988a', 'message': 'Instead of simple dispatch limiting use a semaphore\n\nInstead of having the iterator stop and the run loop\nof a conductor wait to do more work, just have the run loop\nuse a semaphore that is limited by the maximum number of\njobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 17, 'created': '2015-10-31 19:14:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/53b21829935bb91dca69fc232f50578f78ad6f51', 'message': 'Instead of simple dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a\nconductor wait to do more work, just have the run loop use a\ninterruptible semaphore that is limited by the maximum number\nof jobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 18, 'created': '2015-11-13 17:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/31be5b2a01debe2b82f4cdddaedc0069ea542570', 'message': 'Instead of simple dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a\nconductor wait to do more work, just have the run loop use a\ninterruptible semaphore that is limited by the maximum number\nof jobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 19, 'created': '2015-11-13 17:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/d72893206033585c822c907693544ff8c34ed643', 'message': 'Instead of simple dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a\nconductor wait to do more work, just have the run loop use a\ninterruptible semaphore that is limited by the maximum number\nof jobs that can be ran at the same time. During each claim\nand dispatch the semaphore is acquired (which may block)\nand after dispatching it is released (and then the iterator\ncontinues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are\nsimultaneously worked on and does not involve spinning\nand breaking out of iteration loops due to the current\nmax dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 20, 'created': '2015-11-18 22:07:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/be53a960203dc3487c8314f2e04cfbe76ca88cf5', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 21, 'created': '2015-12-01 00:51:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/fd01ffd18a2b3aa766a8d88cfed59fea54fa493e', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 22, 'created': '2015-12-30 22:31:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/e78122c108152bda7d4d6b7306c76901c1325cb0', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 23, 'created': '2015-12-31 02:18:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/28fd046aee7c07900bea4c10ae4ead044abf4e91', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 24, 'created': '2016-01-10 21:54:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/taskflow/commit/68988b93bc5cc419eb722763c8647a2917853ae4', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}, {'number': 25, 'created': '2016-05-13 05:13:48.000000000', 'files': ['taskflow/conductors/backends/impl_executor.py', 'taskflow/types/semaphore.py', 'taskflow/tests/utils.py', 'doc/source/types.rst', 'taskflow/tests/unit/test_types.py', 'taskflow/tests/unit/test_utils_threading_utils.py', 'taskflow/types/latch.py'], 'web_link': 'https://opendev.org/openstack/taskflow/commit/2e91be25c23bcfef9d7cac4e9c21519f5c08271f', 'message': 'Instead of simple executor dispatch limiting use a custom semaphore\n\nInstead of having the iterator stop and the run loop of a conductor\nwait (and spin) to do more work, just have the run loop use a interruptible\nsemaphore that is limited by the maximum number of jobs that can be\nran at the same time. During each claim and dispatch the semaphore\nis acquired (which may block) and after dispatching it is released (and then\nthe iterator continues and this repeats).\n\nThis is a more elegant way of limiting how many jobs are simultaneously worked\non and does not involve spinning and breaking out of iteration loops due to\nthe current max dispatch limit being reached.\n\nChange-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726\n'}]",28,239780,2e91be25c23bcfef9d7cac4e9c21519f5c08271f,68,5,25,1297,,,0,"Instead of simple executor dispatch limiting use a custom semaphore

Instead of having the iterator stop and the run loop of a conductor
wait (and spin) to do more work, just have the run loop use a interruptible
semaphore that is limited by the maximum number of jobs that can be
ran at the same time. During each claim and dispatch the semaphore
is acquired (which may block) and after dispatching it is released (and then
the iterator continues and this repeats).

This is a more elegant way of limiting how many jobs are simultaneously worked
on and does not involve spinning and breaking out of iteration loops due to
the current max dispatch limit being reached.

Change-Id: Id2c82ce9563e114d34b68d8def04bb1a7a665726
",git fetch https://review.opendev.org/openstack/taskflow refs/changes/80/239780/7 && git format-patch -1 --stdout FETCH_HEAD,"['taskflow/conductors/backends/impl_executor.py', 'taskflow/utils/threading_utils.py']",2,e69ebb4e3b8a0357f7e6433d36304387a016731f,248156,"class DummySemaphore(object): """"""Not a real semaphore."""""" def __init__(self, value=1): pass def __enter__(self): self.acquire() def __exit__(self, exc_type, exc_value, traceback): self.release() def acquire(self): """"""Does nothing."""""" def release(self): """"""Does nothing."""""" ",,65,33
openstack%2Fkolla~stable%2Frocky~Id9312830fb9961927ac8d317c432f52a4ad7af24,openstack/kolla,stable/rocky,Id9312830fb9961927ac8d317c432f52a4ad7af24,CI: increase both limits to 3h,MERGED,2019-10-16 15:11:41.000000000,2019-10-17 09:19:58.000000000,2019-10-17 09:19:58.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 15:11:41.000000000', 'files': ['.zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/4436837c66058d763deda9164ce626cd70a0da9f', 'message': 'CI: increase both limits to 3h\n\nOur publishing job is barely managing to fit in 2h time so let add\nanother one.\n\nChange-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24\n(cherry picked from commit 7e1d3eba928ec54899f90368b0235b6737fda3b0)\n'}]",0,688956,4436837c66058d763deda9164ce626cd70a0da9f,9,3,1,14826,,,0,"CI: increase both limits to 3h

Our publishing job is barely managing to fit in 2h time so let add
another one.

Change-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24
(cherry picked from commit 7e1d3eba928ec54899f90368b0235b6737fda3b0)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/56/688956/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/base.yaml'],1,4436837c66058d763deda9164ce626cd70a0da9f,, timeout: 10800 post-timeout: 10800, timeout: 10200 post-timeout: 4800,2,2
openstack%2Fwatcher~master~I44360c32495bb5e7c899033b24e1094681c53acf,openstack/watcher,master,I44360c32495bb5e7c899033b24e1094681c53acf,create audit failed,ABANDONED,2017-12-26 14:02:15.000000000,2019-10-17 09:03:13.000000000,,"[{'_account_id': 13111}, {'_account_id': 14039}, {'_account_id': 19055}, {'_account_id': 21692}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 24501}, {'_account_id': 27947}]","[{'number': 1, 'created': '2017-12-26 14:02:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/f8b8691a8704052b9527b2d3081f4255ebc25756', 'message': 'create audit failed\n\nWhen creating an audit directly by api with the name of strategy,\ngoal or audit_template, it will get an exception.\n\nChange-Id: I44360c32495bb5e7c899033b24e1094681c53acf\nCloses-Bug: #1739737\n'}, {'number': 2, 'created': '2018-01-10 09:19:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/8b0f7acac3b87427f5ef50be70bb096a7baede5d', 'message': 'create audit failed\n\nWhen creating an audit directly by api with the name of strategy,\ngoal or audit_template, it will get an exception.\n\nChange-Id: I44360c32495bb5e7c899033b24e1094681c53acf\nCloses-Bug: #1739737\n'}, {'number': 3, 'created': '2018-01-22 08:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/c19fcb4151cff10600f8b9b06f626d835762f830', 'message': 'create audit failed\n\nWhen creating an audit directly by api with the name of strategy,\ngoal or audit_template, it will get an exception.\n\nChange-Id: I44360c32495bb5e7c899033b24e1094681c53acf\nCloses-Bug: #1739737\n'}, {'number': 4, 'created': '2018-02-09 08:33:46.000000000', 'files': ['watcher/api/controllers/v1/audit.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/6bb618eb49b28310ebfe03220b63338b85de1829', 'message': 'create audit failed\n\nWhen creating an audit directly by api with the name of strategy,\ngoal or audit_template, it will get an exception.\n\nChange-Id: I44360c32495bb5e7c899033b24e1094681c53acf\nCloses-Bug: #1739737\n'}]",14,530105,6bb618eb49b28310ebfe03220b63338b85de1829,26,8,4,24501,,,0,"create audit failed

When creating an audit directly by api with the name of strategy,
goal or audit_template, it will get an exception.

Change-Id: I44360c32495bb5e7c899033b24e1094681c53acf
Closes-Bug: #1739737
",git fetch https://review.opendev.org/openstack/watcher refs/changes/05/530105/3 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/tests/api/v1/test_audits.py', 'watcher/api/controllers/v1/audit.py']",2,f8b8691a8704052b9527b2d3081f4255ebc25756,bug/1739737," audit_template = wtypes.wsattr(wtypes.text, mandatory=False) # If goal, strategy, or audit_template was provide by name, # override the value by uuid of them if self.goal and not utils.is_uuid_like(self.goal): goal = objects.Goal.get_by_name(context, self.goal) self.goal = goal.uuid if self.strategy and not utils.is_uuid_like(self.strategy): strategy = objects.Strategy.get_by_name(context, self.strategy) self.strategy = strategy.uuid if self.audit_template and not utils.is_uuid_like(self.audit_template): audit_template = objects.AuditTemplate.get_by_name( context, self.audit_template) self.audit_template = audit_template.uuid # If audit_template was provided, we will provide any if self.audit_template: context, self.audit_template) elif self.audit_template: context, self.audit_template)"," audit_template_uuid = wtypes.wsattr(types.uuid, mandatory=False) # If audit_template_uuid was provided, we will provide any if self.audit_template_uuid: context, self.audit_template_uuid) elif self.audit_template_uuid: context, self.audit_template_uuid)",24,11
openstack%2Fopenstack-ansible-lxc_hosts~master~Ia30f20df6971a9a44a69e5cc22020831a95a1489,openstack/openstack-ansible-lxc_hosts,master,Ia30f20df6971a9a44a69e5cc22020831a95a1489,Add Centos GPG key custom url,MERGED,2019-10-11 16:17:21.000000000,2019-10-17 09:02:44.000000000,2019-10-15 12:29:38.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-11 16:17:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/4c2ec9ba8aa99a543a89fda9c42d563c1f90d6af', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}, {'number': 2, 'created': '2019-10-11 16:26:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/e87ddabd3ac8215e6480b66b0d2a9fa44bf2041e', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}, {'number': 3, 'created': '2019-10-14 12:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/b8cb5a1da8ea6e70af4eb1583454384e261bae39', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}, {'number': 4, 'created': '2019-10-14 14:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/aa33d46c288d2ff85a522a635939d1579033c9c5', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}, {'number': 5, 'created': '2019-10-15 07:53:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/7778db05c30d0fbea7a0a2ff025a810358f98634', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: lxc_centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}, {'number': 6, 'created': '2019-10-15 09:01:33.000000000', 'files': ['releasenotes/notes/centos-private-epel-3fe4c9ff68ec3a18.yaml', 'defaults/main.yml', 'tasks/lxc_install_yum.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_hosts/commit/62c3a2cbe177cd32072bce92116b58ac247c2f6d', 'message': 'Add Centos GPG key custom url\n\nWhen using a custom repo with centos_epel_mirror, you maybe need to\nchange the gpg key url because offline env\n\nYou can use this variable: lxc_centos_epel_gpg_key\n\nChange-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489\n'}]",1,688164,62c3a2cbe177cd32072bce92116b58ac247c2f6d,19,4,6,23182,,,0,"Add Centos GPG key custom url

When using a custom repo with centos_epel_mirror, you maybe need to
change the gpg key url because offline env

You can use this variable: lxc_centos_epel_gpg_key

Change-Id: Ia30f20df6971a9a44a69e5cc22020831a95a1489
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_hosts refs/changes/64/688164/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/centos-private-epel-3fe4c9ff68ec3a18.yaml', 'tasks/lxc_install_yum.yml']",2,4c2ec9ba8aa99a543a89fda9c42d563c1f90d6af,centos-private-epel," key: ""{{ centos_epel_gpg_key | default ('http://download.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7') }}"""," key: ""http://download.fedoraproject.org/pub/epel/RPM-GPG-KEY-EPEL-7""",6,1
openstack%2Fkolla~stable%2Fstein~Id9312830fb9961927ac8d317c432f52a4ad7af24,openstack/kolla,stable/stein,Id9312830fb9961927ac8d317c432f52a4ad7af24,CI: increase both limits to 3h,MERGED,2019-10-16 15:08:02.000000000,2019-10-17 08:58:49.000000000,2019-10-17 08:56:38.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 15:08:02.000000000', 'files': ['.zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/c8cddefbe7f9e89cda08530aa4ce772e7b28abcc', 'message': 'CI: increase both limits to 3h\n\nOur publishing job is barely managing to fit in 2h time so let add\nanother one.\n\nChange-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24\n(cherry picked from commit 7e1d3eba928ec54899f90368b0235b6737fda3b0)\n'}]",0,688954,c8cddefbe7f9e89cda08530aa4ce772e7b28abcc,10,3,1,14826,,,0,"CI: increase both limits to 3h

Our publishing job is barely managing to fit in 2h time so let add
another one.

Change-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24
(cherry picked from commit 7e1d3eba928ec54899f90368b0235b6737fda3b0)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/54/688954/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/base.yaml'],1,c8cddefbe7f9e89cda08530aa4ce772e7b28abcc,686134-stable/stein, timeout: 10800 post-timeout: 10800, timeout: 10200 post-timeout: 7200,2,2
openstack%2Fkolla-ansible~master~I810aad7d49db3f5a7fd9a2f0f746fd912fe03917,openstack/kolla-ansible,master,I810aad7d49db3f5a7fd9a2f0f746fd912fe03917,Support multiple nova cells,MERGED,2019-08-09 16:15:05.000000000,2019-10-17 08:47:10.000000000,2019-10-17 08:44:23.000000000,"[{'_account_id': 14826}, {'_account_id': 17669}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 28614}, {'_account_id': 28743}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-08-09 16:15:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1131e4422f85bf076ff7114dc6e749a276ea35a5', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 2, 'created': '2019-08-14 17:37:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b6c44cb256f0d28fe52c69c0f0477e92b08d1a06', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 3, 'created': '2019-08-19 15:18:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fa1e006628c82a8fd23b06ab119a56c554635ce9', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 4, 'created': '2019-08-19 15:19:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b02df0cc378d5be4aab059741fcc8d846d4bf767', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 5, 'created': '2019-08-19 15:22:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b1f5657b2984df86b68179610bb2a37405ad68f9', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 6, 'created': '2019-08-19 17:19:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/05ade7db678d3945cfd865f3b721d6778019e403', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 7, 'created': '2019-08-19 17:44:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a94cb166d9ae3d7c97430d4836319720b389f156', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nDepends-On: https://review.opendev.org/677263\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 8, 'created': '2019-08-21 14:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1e948a763cfd5bfc9f1313de639d4ae203ba8014', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 9, 'created': '2019-08-28 16:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bcc05c28f6ec5f97c0b591b445ca9eaf087e8239', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 10, 'created': '2019-08-29 06:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e436f04267950e8def2775f4f4bca98601c0d83b', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 11, 'created': '2019-08-29 07:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4b424673817a6f51f9f9b44db6b3a58da90384ba', 'message': '[WIP] Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 12, 'created': '2019-09-16 13:51:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/658bcccda1230ed342509e6c2750302187ec1fa8', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 13, 'created': '2019-09-16 14:00:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fdbcf6d4ecbf36a88607df09e585d454bb1de03c', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 14, 'created': '2019-09-17 15:28:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8520baec93e467f13fa090f135ebbacdec5bf8b7', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 15, 'created': '2019-09-17 15:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9837902d61c489cd6913a4822a3dc87815f5d14e', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 16, 'created': '2019-09-17 16:40:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/47b26cea6d0efa7c48b34f3e8a5dd3173cb07943', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 17, 'created': '2019-09-20 16:04:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3ee29a63ec7c12f26c8d72df681a4b84ded29576', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 18, 'created': '2019-09-21 08:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/dd09ec471d16b534d2dbc842e01b4ed97e64818c', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 19, 'created': '2019-09-21 11:29:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/712415e695d96a05daea79a8e4b1a96d69ba9624', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 20, 'created': '2019-09-23 14:15:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/b1cf78e63c5f61036d6045739174cd959dfedb6f', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 21, 'created': '2019-09-25 17:02:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/72aa4c698eef8123378f3ee8303d101f51c6d99d', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 22, 'created': '2019-09-27 17:01:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d3b0086d4c6eb363733f4b9d0541aac4ee12da70', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 23, 'created': '2019-10-02 17:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f53ff89ecb84ede02f4a1939c3c091dd4f7805bb', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 24, 'created': '2019-10-03 13:52:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/598bff6a5f4a746c16f7f4b49c28406864075396', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 25, 'created': '2019-10-05 07:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e1414556243b0d6697a84fee5857d9660cb07fb5', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 26, 'created': '2019-10-06 07:00:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/31e67ca78724bf200c7b9fad8334357c99209543', 'message': 'Factor out nova-cell role\n\nSplitting this role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services. It paves the\nway for having a role which can be used to deploy multiple Nova cells.\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A Future patch will add a multi-cell test.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 27, 'created': '2019-10-09 13:57:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6c6436be0204dd50267456c3e332ac51941033fe', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 28, 'created': '2019-10-10 12:26:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0c9a18d540f3e4e1ec2346754ca5c20ac5ae898c', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 29, 'created': '2019-10-10 14:05:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/00e3c3c26f3ca4acdc6e5cf1252aafe6a1439f10', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 30, 'created': '2019-10-10 16:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f011c5e325ed4acd1f136a140484eb6b9464af82', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 31, 'created': '2019-10-15 15:55:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/06912bb66535c1f272ec857b43f55322e038b238', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nceph-mon has been removed from the play hosts list as it is not\nnecessary - delegate_to does not require the host to be in the play.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 32, 'created': '2019-10-15 18:34:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/acf9361efafdeb24bea1ed539368d329a73d6f75', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nceph-mon has been removed from the play hosts list as it is not\nnecessary - delegate_to does not require the host to be in the play.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 33, 'created': '2019-10-16 16:53:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6e51e2568a2488e3f8a5d52eacd4df28c98276eb', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nceph-mon has been removed from the play hosts list as it is not\nnecessary - delegate_to does not require the host to be in the play.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}, {'number': 34, 'created': '2019-10-16 17:42:41.000000000', 'files': ['ansible/roles/nova-cell/tasks/check-containers.yml', 'ansible/roles/nova-cell/filter_plugins/filters.py', 'ansible/roles/nova-cell/defaults/main.yml', 'ansible/roles/nova-cell/tasks/bootstrap_service.yml', 'ansible/roles/nova-cell/tasks/rabbitmq.yml', 'ansible/roles/nova-cell/tasks/proxy_loadbalancer.yml', 'ansible/roles/nova/tasks/deploy.yml', 'ansible/roles/nova/templates/nova-compute.json.j2', 'ansible/roles/nova/templates/nova-scheduler.json.j2', 'ansible/site.yml', 'ansible/roles/nova-cell/templates/nova-novncproxy.json.j2', 'ansible/roles/nova/templates/nova-novncproxy.json.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/nova/templates/nova-api-bootstrap.json.j2', 'ansible/roles/nova-cell/tasks/external_ceph.yml', 'ansible/roles/nova-cell/templates/nova-api.json.j2', 'ansible/roles/nova-cell/tasks/config-nova-fake.yml', 'ansible/roles/nova/tasks/config-nova-fake.yml', 'etc/kolla/globals.yml', 'ansible/roles/nova/tasks/create_cells.yml', 'ansible/roles/nova/tasks/rolling_upgrade.yml', 'ansible/roles/nova-cell/tasks/precheck.yml', 'ansible/roles/nova-cell/tasks/upgrade.yml', 'ansible/roles/nova/tasks/precheck.yml', 'ansible/roles/nova-cell/tasks/bootstrap.yml', 'ansible/roles/nova-cell/tasks/bootstrap_upgrade.yml', 'ansible/roles/nova-cell/tasks/discover_computes.yml', 'tests/templates/globals-default.j2', 'ansible/roles/nova-cell/tasks/pull.yml', 'ansible/roles/nova/tasks/upgrade.yml', 'ansible/roles/nova/templates/libvirtd.conf.j2', 'ansible/roles/nova-cell/tasks/get_cell_settings.yml', 'ansible/roles/nova/templates/nova-compute-ironic.json.j2', 'ansible/roles/nova-cell/templates/nova.conf.j2', 'ansible/roles/nova/tasks/config_bootstrap.yml', 'ansible/roles/nova/tasks/bootstrap_xenapi.yml', 'ansible/roles/nova-cell/templates/nova-cell-bootstrap.json.j2', 'ansible/roles/nova/templates/nova.conf.d/libvirt.conf.j2', 'ansible/roles/nova/defaults/main.yml', 'releasenotes/notes/nova-cells-02810dd035caded1.yaml', 'tests/templates/inventory.j2', 'ansible/roles/nova/tasks/reload_super_conductor.yml', 'zuul.d/jobs.yaml', 'ansible/roles/nova-cell/templates/nova-scheduler.json.j2', 'ansible/inventory/multinode', 'ansible/roles/nova/tasks/discover_computes.yml', 'ansible/roles/nova-cell/tasks/loadbalancer.yml', 'ansible/roles/nova/tasks/map_cell0.yml', 'ansible/roles/nova/tasks/config-libvirt-tls.yml', 'ansible/roles/nova/templates/ssh_config.j2', 'ansible/roles/nova-cell/handlers/main.yml', 'ansible/roles/nova-cell/tasks/deploy.yml', 'ansible/roles/nova-cell/tasks/reload.yml', 'ansible/roles/nova/templates/id_rsa.pub', 'ansible/roles/nova/tasks/bootstrap_upgrade.yml', 'ansible/roles/nova/templates/nova-conductor.json.j2', 'ansible/inventory/all-in-one', 'ansible/roles/nova-cell/templates/nova-spicehtml5proxy.json.j2', 'ansible/roles/nova/tasks/refresh_scheduler_cell_cache.yml', 'ansible/roles/nova/templates/nova-spicehtml5proxy.json.j2', 'ansible/roles/nova/templates/secret.xml.j2', 'ansible/roles/nova/templates/nova-libvirt.json.j2', 'ansible/roles/nova/templates/nova-super-conductor.json.j2', 'ansible/nova.yml', 'ansible/roles/nova/handlers/main.yml', 'ansible/roles/nova/templates/nova-ssh.json.j2', 'ansible/roles/nova-cell/tasks/create_cells.yml', 'ansible/roles/nova/tasks/reload_api.yml', 'ansible/roles/nova/tasks/external_ceph.yml', 'ansible/roles/nova-cell/tasks/config_bootstrap.yml', 'ansible/roles/nova/templates/sshd_config.j2', 'ansible/roles/nova/tasks/bootstrap.yml', 'ansible/roles/nova-cell/tasks/online_data_migrations.yml', 'ansible/roles/nova/templates/qemu.conf.j2', 'ansible/roles/nova-cell/tasks/ceph.yml', 'ansible/roles/nova/tasks/bootstrap_service.yml', 'ansible/roles/nova/tasks/config.yml', 'ansible/roles/nova-cell/tasks/config.yml', 'ansible/roles/nova-cell/tasks/cell_proxy_loadbalancer.yml', 'ansible/roles/nova/tasks/ceph.yml', 'ansible/roles/nova-cell/tasks/register.yml', 'ansible/group_vars/all.yml', 'ansible/roles/nova-cell/templates/nova.conf.d/libvirt.conf.j2', 'ansible/roles/nova/templates/id_rsa', 'zuul.d/project.yaml', 'ansible/roles/nova/tasks/stop.yml', 'ansible/roles/nova-cell/tasks/rolling_upgrade.yml', 'ansible/roles/nova/tasks/online_data_migrations.yml', 'ansible/roles/nova-cell/tasks/stop.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/78a828ef42160d161f944308ec51af0303778ca7', 'message': 'Support multiple nova cells\n\nThis patch adds initial support for deploying multiple Nova cells.\n\nSplitting a nova-cell role out from the Nova role allows a more granular\napproach to deploying and configuring Nova services.\n\nA new enable_cells flag has been added that enables the support of\nmultiple cells via the introduction of a super conductor in addition to\ncell-specific conductors. When this flag is not set (the default), nova\nis configured in the same manner as before - with a single conductor.\n\nThe nova role now deploys the global services:\n\n* nova-api\n* nova-scheduler\n* nova-super-conductor (if enable_cells is true)\n\nThe nova-cell role handles services specific to a cell:\n\n* nova-compute\n* nova-compute-ironic\n* nova-conductor\n* nova-libvirt\n* nova-novncproxy\n* nova-serialproxy\n* nova-spicehtml5proxy\n* nova-ssh\n\nThis patch does not support using a single cell controller for managing\nmore than one cell. Support for sharing a cell controller will be added\nin a future patch.\n\nThis patch should be backwards compatible and is tested by existing CI\njobs. A new CI job has been added that tests a multi-cell environment.\n\nceph-mon has been removed from the play hosts list as it is not\nnecessary - delegate_to does not require the host to be in the play.\n\nDocumentation will be added in a separate patch.\n\nPartially Implements: blueprint support-nova-cells\nCo-Authored-By: Mark Goddard <mark@stackhpc.com>\nChange-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917\n'}]",138,675659,78a828ef42160d161f944308ec51af0303778ca7,112,8,34,17669,,,0,"Support multiple nova cells

This patch adds initial support for deploying multiple Nova cells.

Splitting a nova-cell role out from the Nova role allows a more granular
approach to deploying and configuring Nova services.

A new enable_cells flag has been added that enables the support of
multiple cells via the introduction of a super conductor in addition to
cell-specific conductors. When this flag is not set (the default), nova
is configured in the same manner as before - with a single conductor.

The nova role now deploys the global services:

* nova-api
* nova-scheduler
* nova-super-conductor (if enable_cells is true)

The nova-cell role handles services specific to a cell:

* nova-compute
* nova-compute-ironic
* nova-conductor
* nova-libvirt
* nova-novncproxy
* nova-serialproxy
* nova-spicehtml5proxy
* nova-ssh

This patch does not support using a single cell controller for managing
more than one cell. Support for sharing a cell controller will be added
in a future patch.

This patch should be backwards compatible and is tested by existing CI
jobs. A new CI job has been added that tests a multi-cell environment.

ceph-mon has been removed from the play hosts list as it is not
necessary - delegate_to does not require the host to be in the play.

Documentation will be added in a separate patch.

Partially Implements: blueprint support-nova-cells
Co-Authored-By: Mark Goddard <mark@stackhpc.com>
Change-Id: I810aad7d49db3f5a7fd9a2f0f746fd912fe03917
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/59/675659/32 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/nova/tasks/discover_computes.yml', 'ansible/roles/nova-cell/defaults/main.yml', 'ansible/roles/nova-cell/tasks/bootstrap_service.yml', 'ansible/roles/nova/tasks/deploy.yml', 'ansible/roles/nova/templates/nova-compute.json.j2', 'ansible/roles/nova/templates/ssh_config.j2', 'ansible/site.yml', 'ansible/roles/nova-cell/handlers/main.yml', 'ansible/roles/nova-cell/tasks/deploy.yml', 'ansible/roles/nova-cell/tasks/reload.yml', 'ansible/roles/nova/templates/id_rsa.pub', 'ansible/roles/nova/templates/nova-conductor.json.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/nova-cell/tasks/external_ceph.yml', 'ansible/roles/nova-cell/tasks/config-nova-fake.yml', 'ansible/roles/nova/tasks/config-nova-fake.yml', 'ansible/roles/nova/templates/nova-libvirt.json.j2', 'ansible/roles/nova/handlers/main.yml', 'ansible/roles/nova/templates/nova-ssh.json.j2', 'ansible/roles/nova-cell/tasks/precheck.yml', 'ansible/roles/nova-cell/tasks/upgrade.yml', 'ansible/roles/nova/tasks/precheck.yml', 'ansible/roles/nova-cell/tasks/create_cells.yml', 'ansible/roles/nova-cell/tasks/bootstrap.yml', 'ansible/roles/nova/tasks/external_ceph.yml', 'ansible/roles/nova/templates/sshd_config.j2', 'ansible/roles/nova-cell/tasks/ceph.yml', 'ansible/roles/nova-cell/tasks/pull.yml', 'ansible/roles/nova/tasks/config.yml', 'ansible/roles/nova/templates/libvirtd.conf.j2', 'ansible/roles/nova-cell/tasks/config.yml', 'ansible/roles/nova/tasks/ceph.yml', 'ansible/roles/nova-cell/tasks/register.yml', 'ansible/roles/nova-cell/templates/nova.conf.j2', 'ansible/roles/nova/tasks/bootstrap_xenapi.yml', 'ansible/roles/nova/templates/nova.conf.d/libvirt.conf.j2', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/nova/templates/id_rsa', 'ansible/roles/nova/tasks/legacy_upgrade.yml', 'ansible/roles/nova-cell/tasks/rolling_upgrade.yml', 'ansible/roles/nova-cell/tasks/stop.yml']",41,1131e4422f85bf076ff7114dc6e749a276ea35a5,bp/support-nova-cells," project_services: ""{{ nova_cell_services }}"""," project_services: ""{{ nova_services }}""",153,1715
openstack%2Fmagnum~stable%2Ftrain~I2b64bf9819e3bfa81d9d0220a6ba7c25e9798d53,openstack/magnum,stable/train,I2b64bf9819e3bfa81d9d0220a6ba7c25e9798d53,zuul: drop secret from stable branch,MERGED,2019-10-16 12:06:21.000000000,2019-10-17 08:45:31.000000000,2019-10-17 08:42:40.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 12:06:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/b449ed8964ce06cc89ba26c26da63f10ee57a98a', 'message': 'zuul: drop secret from stable branch\n\nZuul does not allow secrets which are not identical acros branches,\ntherefore if we want to rotate our current secrets, we have to drop\nall the old ones before the new one can be added.\n\nThe secret will continue to be read from the master branch, even for\nthe stable branch jobs so it can continue to live there.\n\nChange-Id: I2b64bf9819e3bfa81d9d0220a6ba7c25e9798d53\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n'}]",0,688912,b449ed8964ce06cc89ba26c26da63f10ee57a98a,8,3,1,20498,,,0,"zuul: drop secret from stable branch

Zuul does not allow secrets which are not identical acros branches,
therefore if we want to rotate our current secrets, we have to drop
all the old ones before the new one can be added.

The secret will continue to be read from the master branch, even for
the stable branch jobs so it can continue to live there.

Change-Id: I2b64bf9819e3bfa81d9d0220a6ba7c25e9798d53
Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>
",git fetch https://review.opendev.org/openstack/magnum refs/changes/12/688912/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,b449ed8964ce06cc89ba26c26da63f10ee57a98a,drop-secrets-train,,- secret: name: magnum_docker_login data: user: !encrypted/pkcs1-oaep - mM1s+mysmyzj5pIxVhuGVkvOSmTPqJkYtnfngIyOhzJyAINIPw+CwoVVPBhVa0jXgoACq s7a01eDSmyGjOtMVvCB1rpJMf9KlmIIs7wXa44VRvU6ZN1IHbmCHyK4cnGBDTNBktfSag FLBJ0c8/QCATJeKBhK3ynwQPKTT6IHB38RsHE9kqU8RgUK95MvvUVIeEKC1fVvlETIS5x kKty+NWaeLZGkLO4lbWlF+LlVcdgOthhp7OO2Ivjrbt9P+jCOiIliMKVM6lTuRTki3D7o ucVeEM2SCfZXQGeMz5cZgyv/dD5krb2W+/VHHx/M3TVvNLwWPwcjl2fOCEh+HUEIAa3bW muHPRHu8CirS5hIxjHIh1hsykwYtYCoZTFbTmJwjWD4URyev8fCEmbrMHD8KNi4cgWjos nHlR7L79YVE6LaIOfxAe4OjBv48I+Mq2P/s84RgjAJyfp7TgR+mJ+wSW4W6SkM0PkfpHx 5gIQ1W8NLvEbHWul1P7kv5ikLr4wStNkEDc2VH1gflI7VSM4KLhANwedx3f6qVGBAPsrY vw7QsmUHGUiunX1SABZf1nhc0Xu0FFCLujnMSuuccfC90RbYZk+4xIo6CRFKy+q9Ko4ju pH1gUp+GKiHDXme61oI9M+rjy11MzzeaFHacOZbccZhJBy7EcnYvxPxH22nPds= password: !encrypted/pkcs1-oaep - DeKrk9fGHRFpf1pGXCfX0gItAAUyS1ZmuRIqq7iMvioz8P6k0NdYaPRGtQG5f0ijJSaG0 /TTxKySQ5Dtnf7PumH5U2nXDQzi0oieH+u6h9Iu5x6sPDcOsO3XryPouQGhs+T1iqMd0j cXnbhM4/0QxtMD3b9rxL4WAp16nJ0c1p8Nh0d7KxulhF2n0fNcHgCxSpDU09Ehf5z1X+r z4fc9K7jxr/P5wJ5mTQ85NVEOGchMq5H2a3MuJGU7B7NViv3nBd8nd39sQrvsCMAD/es0 vABLC5HJyZj5wrjh2b0sgAbHdM89TXDXg6FAk3HlS0jXdu7Sd6BUEZuHcymd680qV+bui gF6RT+qO9D3Q/9koGrNabi8VFUSNqOavBJVn0W/ZTG/vGy3DmgjtGtgQu+2Q1zuwodaa+ tiZwyrd2t9g33ePZgjBiCF8ehPgkkzgHmKEYDrc2itBb3T4PxcdMCfwt1KtmhNfYnSpSF VY57IV7OGysaedKuYpb8aJ0ckj47lJLS669ZoOFGPIMTuVFpdFTILaQOPqws/HTZgKlTk aidm/zvriGovFY8tAjcOnpbkJ44lGUPNH09aoMh47q7yfPoMJJ9QDVb3WLxhY18jfwfCY eD4eIWo2s0YG37VX0N5lPeHR6Y5HZq9AI0oOTmXjmRKHkq2JdpeBz7avdZBu7M= ,0,26
openstack%2Fmagnum~master~Ic10485eda8b4ddd8d63197d1f7be2cf205d3acbd,openstack/magnum,master,Ic10485eda8b4ddd8d63197d1f7be2cf205d3acbd,"Release k8s v1.13.12, v1.14.8, v1.15.5, v1.16.2",MERGED,2019-10-16 20:57:18.000000000,2019-10-17 08:41:42.000000000,2019-10-17 08:40:10.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-10-16 20:57:18.000000000', 'files': ['playbooks/container-builder-vars.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/1b1d8410976b715e6ca752bd6f09a503eb9243c9', 'message': 'Release k8s v1.13.12, v1.14.8, v1.15.5, v1.16.2\n\nStory: 2005124\nTask: 37198\n\nChange-Id: Ic10485eda8b4ddd8d63197d1f7be2cf205d3acbd\n'}]",0,689042,1b1d8410976b715e6ca752bd6f09a503eb9243c9,10,4,1,6484,,,0,"Release k8s v1.13.12, v1.14.8, v1.15.5, v1.16.2

Story: 2005124
Task: 37198

Change-Id: Ic10485eda8b4ddd8d63197d1f7be2cf205d3acbd
",git fetch https://review.opendev.org/openstack/magnum refs/changes/42/689042/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/container-builder-vars.yaml'],1,1b1d8410976b715e6ca752bd6f09a503eb9243c9,story/2005124-37198,kubernetes_version_v1_13: v1.13.12 kubernetes_version_v1_14: v1.14.8 kubernetes_version_v1_15: v1.15.5 kubernetes_version_v1_16: v1.16.2,kubernetes_version_v1_13: v1.13.11 kubernetes_version_v1_14: v1.14.7 kubernetes_version_v1_15: v1.15.4 kubernetes_version_v1_16: v1.16.0,4,4
openstack%2Fcharm-hacluster~master~I3c6acdef401e9ec18fedc65e9c77db4719fe60ec,openstack/charm-hacluster,master,I3c6acdef401e9ec18fedc65e9c77db4719fe60ec,Stop resource before deleting it.,MERGED,2019-10-10 21:26:43.000000000,2019-10-17 08:37:07.000000000,2019-10-17 08:37:07.000000000,"[{'_account_id': 2424}, {'_account_id': 6737}, {'_account_id': 17499}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 28543}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-10-10 21:26:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/7e722c3151900d14d9b4ec2e45cff1e9336b636d', 'message': ""Stop resource before deleting it.\n\nPacemaker will refuse to delete a resource that it's running, so it needs\nto be stopped always before deleting it.\n\nChange-Id: I3c6acdef401e9ec18fedc65e9c77db4719fe60ec\nCloses-Bug: #1838528\n""}, {'number': 2, 'created': '2019-10-11 20:34:27.000000000', 'files': ['hooks/hooks.py', 'unit_tests/test_hacluster_hooks.py'], 'web_link': 'https://opendev.org/openstack/charm-hacluster/commit/666055844e13b556ded97f4c92f3089e272507e8', 'message': ""Stop resource before deleting it.\n\nPacemaker will refuse to delete a resource that it's running, so it needs\nto be stopped always before deleting it.\n\nChange-Id: I3c6acdef401e9ec18fedc65e9c77db4719fe60ec\nCloses-Bug: #1838528\n""}]",0,687987,666055844e13b556ded97f4c92f3089e272507e8,20,9,2,2424,,,0,"Stop resource before deleting it.

Pacemaker will refuse to delete a resource that it's running, so it needs
to be stopped always before deleting it.

Change-Id: I3c6acdef401e9ec18fedc65e9c77db4719fe60ec
Closes-Bug: #1838528
",git fetch https://review.opendev.org/openstack/charm-hacluster refs/changes/87/687987/1 && git format-patch -1 --stdout FETCH_HEAD,['hooks/hooks.py'],1,7e722c3151900d14d9b4ec2e45cff1e9336b636d,bug/1838528," # Stop the resource before the deletion (LP: #1838528) log('Stopping %s' % res_name, level=INFO) pcmk.commit('crm -w -F resource stop %s' % res_name) log('Deleting %s' % res_name, level=INFO)",,5,0
openstack%2Ftripleo-validations~master~Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a,openstack/tripleo-validations,master,Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a,Use dynamic argument_spec from documentation,MERGED,2019-10-11 13:43:52.000000000,2019-10-17 08:31:32.000000000,2019-10-17 08:31:31.000000000,"[{'_account_id': 7353}, {'_account_id': 11491}, {'_account_id': 17888}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-11 13:43:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5095f82f616021b1d15e5e9a7f7ad2998b256090', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2019-10-11 15:12:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/9f2f77cac526deef606e26e597b5d3406a24d0e8', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 3, 'created': '2019-10-14 10:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/c6eb1be8b42fb41b72f6d6dfceccfd81d65aae1a', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 4, 'created': '2019-10-14 14:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/174a1797f53c641203a56924342a4c61d4a9c177', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 5, 'created': '2019-10-14 14:43:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/e66d077edeb37338d60b7a8ef60d144b0709d2cb', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 6, 'created': '2019-10-15 12:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/acd5a5634916359f8d39d4da927b78165fc057aa', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 7, 'created': '2019-10-16 09:27:46.000000000', 'files': ['library/warn.py', 'library/overcloudrc.py', 'library/check_ironic_boot_config.py', 'library/advanced_format.py', 'library/verify_profiles.py', 'library/check_package_update.py', 'library/icmp_ping.py', 'library/reportentry.py', 'library/haproxy_conf.py', 'library/hiera.py', 'library/node_disks.py', 'library/ini.py', 'library/ip_range.py', 'library/ovs_dpdk_pmd_cpus_check.py', 'library/pacemaker.py', 'library/switch_vlans.py', 'library/network_environment.py', 'library/check_flavors.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/08533b45c3258a848a9669eafb55f735fb89afea', 'message': 'Use dynamic argument_spec from documentation\n\nThis change modifies the argument_spec making it so we load the options\nkey from the documentation constant. This will reduce the code we have\nto maintain and ensure our documentation is always in sync with the\nmodule capabilities.\n\nChange-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a\nCo-Authored-by: Kevin Carter <kecarter@redhat.com>\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}]",4,688127,08533b45c3258a848a9669eafb55f735fb89afea,21,6,7,11491,,,0,"Use dynamic argument_spec from documentation

This change modifies the argument_spec making it so we load the options
key from the documentation constant. This will reduce the code we have
to maintain and ensure our documentation is always in sync with the
module capabilities.

Change-Id: Iaf94b6300a58de4367b4c9f2c83cc112e7c5361a
Co-Authored-by: Kevin Carter <kecarter@redhat.com>
Signed-off-by: Gael Chamoulaud <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/27/688127/5 && git format-patch -1 --stdout FETCH_HEAD,"['library/warn.py', 'library/overcloudrc.py', 'library/check_ironic_boot_config.py', 'library/advanced_format.py', 'library/verify_profiles.py', 'library/check_package_update.py', 'library/icmp_ping.py', 'library/reportentry.py', 'library/haproxy_conf.py', 'library/hiera.py', 'library/node_disks.py', 'library/ini.py', 'library/ip_range.py', 'library/ovs_dpdk_pmd_cpus_check.py', 'library/pacemaker.py', 'library/switch_vlans.py', 'library/network_environment.py', 'library/check_flavors.py']",18,5095f82f616021b1d15e5e9a7f7ad2998b256090,dynamic_argument_spec,import yaml module = AnsibleModule( argument_spec=yaml.safe_load(DOCUMENTATION)['options'] )," module = AnsibleModule(argument_spec=dict( roles_info=dict(required=True, type='list'), flavors=dict(required=True, type='dict') ))",79,77
openstack%2Fkuryr-kubernetes~master~I725ba22f0babf496af219a37e42e1c33b247308a,openstack/kuryr-kubernetes,master,I725ba22f0babf496af219a37e42e1c33b247308a,Avoid race between Retries and Deletion actions,MERGED,2019-10-11 12:00:02.000000000,2019-10-17 08:12:34.000000000,2019-10-17 08:11:00.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 28543}, {'_account_id': 30963}]","[{'number': 1, 'created': '2019-10-11 12:00:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9f792f70e9140807f7e85cea87bf310b11d3d691', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 2, 'created': '2019-10-11 12:03:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/6ea98433ea8c55eb0e6d71eb160e363284b6c393', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 3, 'created': '2019-10-11 12:35:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/b1f2f64660ac660a8c83639a845d1be15bca946e', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 4, 'created': '2019-10-14 08:17:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/532919019eceb6b4cb3b375d1054a4aec449bf40', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 5, 'created': '2019-10-14 16:40:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/40e2e7b447a84cdd7589347ed3b915e1de86ef4a', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 6, 'created': '2019-10-15 08:16:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/580ae779bea467b16d56c551f4086896e285fa87', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 7, 'created': '2019-10-15 09:05:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c068f35ddc47389d1a68dd71a73b2aca7389598b', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 8, 'created': '2019-10-15 09:42:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/21bf1a417a9ba9ee26011c4200afdf266ebe4af4', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 9, 'created': '2019-10-16 10:43:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/0868b59792160fec89d858e9e91397db27b7373f', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 10, 'created': '2019-10-16 11:52:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ffd496eac5c78c72723cc9f7e234d23bebaa6170', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 11, 'created': '2019-10-16 13:49:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7331a1c0aef0ae6a2b8ab89489392862fed70194', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}, {'number': 12, 'created': '2019-10-16 16:25:13.000000000', 'files': ['kuryr_kubernetes/controller/handlers/pod_label.py', 'kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/tests/unit/handlers/test_retry.py', 'kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/controller/drivers/network_policy_security_groups.py', 'kuryr_kubernetes/controller/drivers/namespace_subnet.py', 'kuryr_kubernetes/controller/handlers/namespace.py', 'kuryr_kubernetes/handlers/retry.py', 'kuryr_kubernetes/utils.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/998be3bbdad5f42c9aa4ef322b520338dafb269c', 'message': 'Avoid race between Retries and Deletion actions\n\nThis patch set increases the timeout to wait for resources to be\ncreated/deleted. This is needed to better support spikes without\nrestarting the kuryr-controller. This patch also ensures that\nfuture retry events are not afecting the kuryr controller if\nthey are retried once the related resources are already deleted,\ni.e., the on_delete event was executed before one of the retries.\n\nCloses-Bug: 1847753\nChange-Id: I725ba22f0babf496af219a37e42e1c33b247308a\n'}]",21,688109,998be3bbdad5f42c9aa4ef322b520338dafb269c,58,9,12,23567,,,0,"Avoid race between Retries and Deletion actions

This patch set increases the timeout to wait for resources to be
created/deleted. This is needed to better support spikes without
restarting the kuryr-controller. This patch also ensures that
future retry events are not afecting the kuryr controller if
they are retried once the related resources are already deleted,
i.e., the on_delete event was executed before one of the retries.

Closes-Bug: 1847753
Change-Id: I725ba22f0babf496af219a37e42e1c33b247308a
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/09/688109/10 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/controller/handlers/lbaas.py', 'kuryr_kubernetes/controller/handlers/vif.py', 'kuryr_kubernetes/controller/drivers/network_policy_security_groups.py', 'kuryr_kubernetes/utils.py']",4,9f792f70e9140807f7e85cea87bf310b11d3d691,retries-problems,DEFAULT_TIMEOUT = 500,DEFAULT_TIMEOUT = 180,7,5
openstack%2Fkolla-ansible~master~Ia64ae385168f43787a95b55a48de0eb8c3e85f39,openstack/kolla-ansible,master,Ia64ae385168f43787a95b55a48de0eb8c3e85f39,DNM: CI: test cells with IPv6,ABANDONED,2019-10-16 16:58:32.000000000,2019-10-17 08:09:04.000000000,,"[{'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 16:58:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/99313eed7714dda472654b11b2f2be7eaa0906b3', 'message': 'DNM: CI: test cells with IPv6\n\nChange-Id: Ia64ae385168f43787a95b55a48de0eb8c3e85f39\n'}, {'number': 2, 'created': '2019-10-16 17:43:42.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d7ede3adaa85e2f9f74ead78c3ba7e3db20f6798', 'message': 'DNM: CI: test cells with IPv6\n\nChange-Id: Ia64ae385168f43787a95b55a48de0eb8c3e85f39\n'}]",0,688978,d7ede3adaa85e2f9f74ead78c3ba7e3db20f6798,8,2,2,30491,,,0,"DNM: CI: test cells with IPv6

Change-Id: Ia64ae385168f43787a95b55a48de0eb8c3e85f39
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/78/688978/2 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,99313eed7714dda472654b11b2f2be7eaa0906b3,dnm-cells-ipv6, scenario: cells,,1,35
openstack%2Fheat~master~I3b1ed30967e9235e9e830c5e4156f739303be618,openstack/heat,master,I3b1ed30967e9235e9e830c5e4156f739303be618,Fix cfn-init-data path in ignition,MERGED,2019-10-14 03:53:19.000000000,2019-10-17 07:52:00.000000000,2019-10-17 07:50:41.000000000,"[{'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6484}, {'_account_id': 12404}, {'_account_id': 22348}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-10-14 03:53:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/1f5163cc2799d44c9ede5c9526c0854fe1ebc75c', 'message': ""Fix cfn-init-data path in ignition\n\nThe 'local-data' in path /var/lib/os-collect-config/local-data should\nbe a directly not a file. This patch fixes it. And now there is an\nissue when doing merging configs in os-apply-config, so we need to be\nbackward compatible by writing file to /var/lib/heat-cfntools/cfn-init-data\nand /var/lib/cloud/data/cfn-init-data.\n\nStory: 2006566\nTask: 36851\n\nChange-Id: I3b1ed30967e9235e9e830c5e4156f739303be618\n""}, {'number': 2, 'created': '2019-10-15 02:40:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/ae47a18bc812fecad8c61c1dab0f3c33a78929ab', 'message': ""Fix cfn-init-data path in ignition\n\nThe 'local-data' in path /var/lib/os-collect-config/local-data should\nbe a directly not a file. And now there is an issue[1] when doing merging\nconfigs in os-apply-config, so at this moment we have to use\n/var/lib/heat-cfntools/cfn-init-data and /var/lib/cloud/data/cfn-init-data\nuntil the issue in os-apply-config being fixed.\n\n[1] https://review.opendev.org/688317\n\nStory: 2006566\nTask: 36851\n\nChange-Id: I3b1ed30967e9235e9e830c5e4156f739303be618\n""}, {'number': 3, 'created': '2019-10-17 04:22:42.000000000', 'files': ['heat/engine/clients/os/nova.py', 'heat/tests/clients/test_nova_client.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/ea18c18188f94fe3e58f9ea423255060a3be45eb', 'message': ""Fix cfn-init-data path in ignition\n\nThe 'local-data' in path /var/lib/os-collect-config/local-data should\nbe a directory, not a file. However, even if we can fix this, now\nos-apply-config will merge configs based on the order [ec2, heat and\nlocal], but actually there is no deployments collected local. Then\nunfortunately, the deployments collected from Heat will be\noverwriten because the merging order in os-apply-config. At this\nmoment, we can't change os-apply-config since it's deliberate.\nSo the only reasonable way we can do now is using\n/var/lib/heat-cfntools/cfn-init-data and /var/lib/cloud/data/cfn-init-data.\n\nStory: 2006566\nTask: 36851\n\nChange-Id: I3b1ed30967e9235e9e830c5e4156f739303be618\n""}]",9,688322,ea18c18188f94fe3e58f9ea423255060a3be45eb,20,6,3,6484,,,0,"Fix cfn-init-data path in ignition

The 'local-data' in path /var/lib/os-collect-config/local-data should
be a directory, not a file. However, even if we can fix this, now
os-apply-config will merge configs based on the order [ec2, heat and
local], but actually there is no deployments collected local. Then
unfortunately, the deployments collected from Heat will be
overwriten because the merging order in os-apply-config. At this
moment, we can't change os-apply-config since it's deliberate.
So the only reasonable way we can do now is using
/var/lib/heat-cfntools/cfn-init-data and /var/lib/cloud/data/cfn-init-data.

Story: 2006566
Task: 36851

Change-Id: I3b1ed30967e9235e9e830c5e4156f739303be618
",git fetch https://review.opendev.org/openstack/heat refs/changes/22/688322/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/nova.py', 'heat/tests/clients/test_nova_client.py']",2,1f5163cc2799d44c9ede5c9526c0854fe1ebc75c,story/2006566-36851," self.assertEqual(""/var/lib/heat-cfntools/cfn-init-data"", self.assertEqual(""/var/lib/cloud/data/cfn-init-data"", ig[""storage""][""files""][1][""path""]) self.assertEqual(""/var/lib/os-collect-config/local-data/cfn-init-data"", ig[""storage""][""files""][2][""path""])"," self.assertEqual(""/var/lib/os-collect-config/local-data"",",20,10
openstack%2Fnova-powervm~master~I127cfaacfb7f567e650ae5d62861ae28085c7fa4,openstack/nova-powervm,master,I127cfaacfb7f567e650ae5d62861ae28085c7fa4,Adding LPAR Detailed Settings section.,MERGED,2019-06-13 13:18:11.000000000,2019-10-17 07:28:08.000000000,2019-10-17 07:28:07.000000000,"[{'_account_id': 8190}, {'_account_id': 10608}, {'_account_id': 13557}, {'_account_id': 13637}, {'_account_id': 14070}, {'_account_id': 14532}, {'_account_id': 14806}, {'_account_id': 16128}, {'_account_id': 16551}, {'_account_id': 16710}, {'_account_id': 22348}, {'_account_id': 28063}, {'_account_id': 30534}]","[{'number': 1, 'created': '2019-06-13 13:18:11.000000000', 'files': ['doc/source/devref/usage.rst'], 'web_link': 'https://opendev.org/openstack/nova-powervm/commit/f1f9b000b02f760bdd44cd0b38f78c894b4fe8aa', 'message': 'Adding LPAR Detailed Settings section.\n\nChange-Id: I127cfaacfb7f567e650ae5d62861ae28085c7fa4\n'}]",1,665134,f1f9b000b02f760bdd44cd0b38f78c894b4fe8aa,14,13,1,30534,,,0,"Adding LPAR Detailed Settings section.

Change-Id: I127cfaacfb7f567e650ae5d62861ae28085c7fa4
",git fetch https://review.opendev.org/openstack/nova-powervm refs/changes/34/665134/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/devref/usage.rst'],1,f1f9b000b02f760bdd44cd0b38f78c894b4fe8aa,updusage,"LPAR Detailed Settings ~~~~~~~~~~~~~~~~~~~~~~ Fine grained control over LPAR settings can be achieved by setting PowerVM specific properties (``extra-specs``) on the flavors being used to instantiate a VM. For the complete list of PowerVM properties see `IBM PowerVC documentation`_. .. _`IBM PowerVC documentation`: https://www.ibm.com/support/knowledgecenter/en/SSXK2N_1.4.2/com.ibm.powervc.standard.help.doc/powervc_pg_flavorsextraspecs_hmc.html For example, to create a VM with one VCPU and 0.7 entitlement (0.7 of the physical CPU resource), a user could use a flavor created as follows:: openstack flavor create --vcpus 1 --ram 6144 --property \ powervm:proc_units=0.7 pvm-6-1-0.7 In the example above ``powervm:proc_units`` property was used to specify CPU entitlement for the VM. ",,17,0
openstack%2Fkuryr-kubernetes~master~I037a882e1231118b3e85abace8cc13c4e79ee6da,openstack/kuryr-kubernetes,master,I037a882e1231118b3e85abace8cc13c4e79ee6da,Avoid controller crash upon unexpected neutron error handling ports,MERGED,2019-10-14 14:26:19.000000000,2019-10-17 06:48:10.000000000,2019-10-16 23:01:06.000000000,"[{'_account_id': 11600}, {'_account_id': 13692}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}]","[{'number': 1, 'created': '2019-10-14 14:26:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2998de60021daf9d58638741ae51023288ff2026', 'message': 'Avoid controller crash upon unexpected neutron error handling ports\n\nThis PS ensures that kuryr-controller does not crash if neutron\ncannot be reached to check the port status, or if neutron replies\nwith unexpected error when trying to add ports to the trunks\n\nChange-Id: I037a882e1231118b3e85abace8cc13c4e79ee6da\nCloses-Bug: 1848012\n'}, {'number': 2, 'created': '2019-10-14 16:11:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/cfb87fda354dd6056c94b08d9e3a6863fbdfc04b', 'message': 'Avoid controller crash upon unexpected neutron error handling ports\n\nThis PS ensures that kuryr-controller does not crash if neutron\ncannot be reached to check the port status, or if neutron replies\nwith unexpected error when trying to add ports to the trunks\n\nChange-Id: I037a882e1231118b3e85abace8cc13c4e79ee6da\nCloses-Bug: 1848012\n'}, {'number': 3, 'created': '2019-10-14 16:54:19.000000000', 'files': ['kuryr_kubernetes/tests/unit/controller/drivers/test_nested_vlan_vif.py', 'kuryr_kubernetes/controller/drivers/neutron_vif.py', 'kuryr_kubernetes/controller/drivers/nested_vlan_vif.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/9cd4ad3b14a4e6e59b9178743d04f6d22ebb5eb8', 'message': 'Avoid controller crash upon unexpected neutron error handling ports\n\nThis PS ensures that kuryr-controller does not crash if neutron\ncannot be reached to check the port status, or if neutron replies\nwith unexpected error when trying to add ports to the trunks\n\nChange-Id: I037a882e1231118b3e85abace8cc13c4e79ee6da\nCloses-Bug: 1848012\n'}]",4,688410,9cd4ad3b14a4e6e59b9178743d04f6d22ebb5eb8,14,6,3,23567,,,0,"Avoid controller crash upon unexpected neutron error handling ports

This PS ensures that kuryr-controller does not crash if neutron
cannot be reached to check the port status, or if neutron replies
with unexpected error when trying to add ports to the trunks

Change-Id: I037a882e1231118b3e85abace8cc13c4e79ee6da
Closes-Bug: 1848012
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/10/688410/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/tests/unit/controller/drivers/test_nested_vlan_vif.py', 'kuryr_kubernetes/controller/drivers/neutron_vif.py', 'kuryr_kubernetes/controller/drivers/nested_vlan_vif.py', 'kuryr_kubernetes/controller/drivers/vif_pool.py']",4,2998de60021daf9d58638741ae51023288ff2026,neutron-failures, if vifs: self._last_update[pool_key] = {security_groups: now}, self._last_update[pool_key] = {security_groups: now},16,11
openstack%2Fproject-config~master~I81a1381c18fdc7188bdd87ab18d0b92c31a978fb,openstack/project-config,master,I81a1381c18fdc7188bdd87ab18d0b92c31a978fb,Normalize projects.yaml,MERGED,2019-10-17 06:10:49.000000000,2019-10-17 06:42:28.000000000,2019-10-17 06:42:28.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 06:10:49.000000000', 'files': ['gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/03c1ee3840bc341979a04f2fb2f9bfacb43dd587', 'message': 'Normalize projects.yaml\n\nChange-Id: I81a1381c18fdc7188bdd87ab18d0b92c31a978fb\n'}]",0,689078,03c1ee3840bc341979a04f2fb2f9bfacb43dd587,6,2,1,11131,,,0,"Normalize projects.yaml

Change-Id: I81a1381c18fdc7188bdd87ab18d0b92c31a978fb
",git fetch https://review.opendev.org/openstack/project-config refs/changes/78/689078/1 && git format-patch -1 --stdout FETCH_HEAD,['gerrit/projects.yaml'],1,03c1ee3840bc341979a04f2fb2f9bfacb43dd587,project-yaml-normalization,, upstream: https://github.com/openstack-charmers/charm-interface-mysql-innodb-cluster.git upstream: https://github.com/openstack-charmers/charm-interface-mysql-router.git upstream: https://github.com/openstack-charmers/charm-mysql-innodb-cluster.git upstream: https://github.com/openstack-charmers/charm-mysql-router.git,0,4
openstack%2Fnetworking-bagpipe~stable%2Ftrain~Ia3df29060a6dfeb0f7b10769e8016762148a0a5b,openstack/networking-bagpipe,stable/train,Ia3df29060a6dfeb0f7b10769e8016762148a0a5b,"Force copy of dict items in ""for"" loop",ABANDONED,2019-10-15 20:18:54.000000000,2019-10-17 06:29:21.000000000,,"[{'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 20:18:54.000000000', 'files': ['networking_bagpipe/bagpipe_bgp/common/dataplane_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/dbdbb2a92c6b64d9c521fdc9247fcaa342c7f1f9', 'message': 'Force copy of dict items in ""for"" loop\n\nIn module bagpipe_bgp.common.dataplane_utils in\nObjectLifecycleManager.clear_objects() method there is for loop\nwhich iterates over items from dict.\nTo avoid changes of dict during iterations this patch forces always\nto create list which is copy of items from dict.\n\nChange-Id: Ia3df29060a6dfeb0f7b10769e8016762148a0a5b\nCloses-Bug: #1846767\n'}]",2,688812,dbdbb2a92c6b64d9c521fdc9247fcaa342c7f1f9,5,3,1,12021,,,0,"Force copy of dict items in ""for"" loop

In module bagpipe_bgp.common.dataplane_utils in
ObjectLifecycleManager.clear_objects() method there is for loop
which iterates over items from dict.
To avoid changes of dict during iterations this patch forces always
to create list which is copy of items from dict.

Change-Id: Ia3df29060a6dfeb0f7b10769e8016762148a0a5b
Closes-Bug: #1846767
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/12/688812/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/bagpipe_bgp/common/dataplane_utils.py'],1,dbdbb2a92c6b64d9c521fdc9247fcaa342c7f1f9,bug/1846767-stable/train," for object_key, users in list(self.object_used_for.items()):"," for object_key, users in self.object_used_for.items():",1,1
openstack%2Fnetworking-hyperv~master~I879aae06f3aeb31607654234a99d5812acb50f2d,openstack/networking-hyperv,master,I879aae06f3aeb31607654234a99d5812acb50f2d,Bump the openstackdocstheme extension to 1.20,MERGED,2019-10-11 09:07:39.000000000,2019-10-17 06:24:52.000000000,2019-10-17 06:22:35.000000000,"[{'_account_id': 8543}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 09:07:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/a69bdf2b9502a759735eca7b07a7df79cdd69007', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I879aae06f3aeb31607654234a99d5812acb50f2d\n'}, {'number': 2, 'created': '2019-10-12 05:47:05.000000000', 'files': ['test-requirements.txt', 'doc/source/conf.py', 'lower-constraints.txt', 'releasenotes/source/conf.py'], 'web_link': 'https://opendev.org/openstack/networking-hyperv/commit/03844a7846e0d1f4f61341c351ae0a1bb19d58df', 'message': 'Bump the openstackdocstheme extension to 1.20\n\nSome options are now automatically configured by the version 1.20:\n- project\n- html_last_updated_fmt\n- latex_engine\n- latex_elements\n- version\n- release.\n\nChange-Id: I879aae06f3aeb31607654234a99d5812acb50f2d\n'}]",0,688085,03844a7846e0d1f4f61341c351ae0a1bb19d58df,9,2,2,27822,,,0,"Bump the openstackdocstheme extension to 1.20

Some options are now automatically configured by the version 1.20:
- project
- html_last_updated_fmt
- latex_engine
- latex_elements
- version
- release.

Change-Id: I879aae06f3aeb31607654234a99d5812acb50f2d
",git fetch https://review.opendev.org/openstack/networking-hyperv refs/changes/85/688085/1 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'doc/source/conf.py', 'releasenotes/source/conf.py']",3,a69bdf2b9502a759735eca7b07a7df79cdd69007,openstackdocstheme,,"project = u'Networking-Hyperv Release Notes'latex_elements = { # The paper size ('letterpaper' or 'a4paper'). # 'papersize': 'letterpaper', # The font size ('10pt', '11pt' or '12pt'). # 'pointsize': '10pt', # Additional stuff for the LaTeX preamble. # 'preamble': '', } ",1,15
openstack%2Fkolla~stable%2Frocky~Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,openstack/kolla,stable/rocky,Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,Add disk dev name check function,MERGED,2019-10-16 12:42:18.000000000,2019-10-17 06:10:42.000000000,2019-10-17 06:10:42.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30687}]","[{'number': 1, 'created': '2019-10-16 12:42:18.000000000', 'files': ['docker/ceph/ceph-osd/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/5da1c35cc3d113ef702e8e2515c8178c413a4af2', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n'}]",0,688918,5da1c35cc3d113ef702e8e2515c8178c413a4af2,14,4,1,30687,,,0,"Add disk dev name check function

This patch will add new function in extend_start.sh for OSD
creation. Not only support loop device but also others that
disk dev layout is end with numbers.

Change-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48
Closes-Bug: #1847014
",git fetch https://review.opendev.org/openstack/kolla refs/changes/18/688918/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/ceph/ceph-osd/extend_start.sh'],1,5da1c35cc3d113ef702e8e2515c8178c413a4af2,bug/1847014,"# Few storage device like loop or NVMe, wiil add ""p"" between disk & partition # name if disk layout is end with number. This function will fix to correct format. function part_name_checker { if [[ $1 =~ .*[0-9] ]]; then echo ${1}p${2} else echo ${1}${2} fi } sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" sgdisk --zap-all -- ""$(part_name_checker ${OSD_BS_BLK_DEV} ${OSD_BS_BLK_PARTNUM})"" wait_partition_appear ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_WAL_DEV $OSD_BS_WAL_PARTNUM)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DB_DEV $OSD_BS_DB_PARTNUM)"" mkfs.xfs -f ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" mount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" ""${OSD_DIR}"" umount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" "," if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi if [[ ""${OSD_BS_BLK_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""p${OSD_BS_BLK_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""${OSD_BS_BLK_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then wait_partition_appear ""${OSD_BS_DEV}""p2 sgdisk --zap-all -- ""${OSD_BS_DEV}""p2 else wait_partition_appear ""${OSD_BS_DEV}""2 sgdisk --zap-all -- ""${OSD_BS_DEV}""2 fi if [[ ""${OSD_BS_WAL_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""p${OSD_BS_WAL_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""${OSD_BS_WAL_PARTNUM}"" fi if [[ ""${OSD_BS_DB_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""p${OSD_BS_DB_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""${OSD_BS_DB_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then mkfs.xfs -f ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" else mkfs.xfs -f ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then umount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else umount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi",21,39
openstack%2Fpython-tripleoclient~stable%2Ftrain~Ic19076436f3b07e57c6a906ae02eb0fd2b3595dd,openstack/python-tripleoclient,stable/train,Ic19076436f3b07e57c6a906ae02eb0fd2b3595dd,Update TOX/UPPER_CONSTRAINTS_FILE for stable/train,MERGED,2019-10-15 16:19:03.000000000,2019-10-17 05:42:19.000000000,2019-10-17 05:40:14.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 16:19:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b8c55fcfe7537eb7a6f450255761bb572f350b57', 'message': 'Update TOX/UPPER_CONSTRAINTS_FILE for stable/train\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/train branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: Ic19076436f3b07e57c6a906ae02eb0fd2b3595dd\n'}, {'number': 2, 'created': '2019-10-16 15:50:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9a8cd2794d1febc5aba0c4804129dabac35c9e87', 'message': 'Update TOX/UPPER_CONSTRAINTS_FILE for stable/train\n\nUpdate the URL to the upper-constraints file to point to the redirect\nrule on releases.openstack.org so that anyone working on this branch\nwill switch to the correct upper-constraints list automatically when\nthe requirements repository branches.\n\nUntil the requirements repository has as stable/train branch, tests will\ncontinue to use the upper-constraints list on master.\n\nChange-Id: Ic19076436f3b07e57c6a906ae02eb0fd2b3595dd\n'}]",0,688749,9a8cd2794d1febc5aba0c4804129dabac35c9e87,9,2,2,22816,,,0,"Update TOX/UPPER_CONSTRAINTS_FILE for stable/train

Update the URL to the upper-constraints file to point to the redirect
rule on releases.openstack.org so that anyone working on this branch
will switch to the correct upper-constraints list automatically when
the requirements repository branches.

Until the requirements repository has as stable/train branch, tests will
continue to use the upper-constraints list on master.

Change-Id: Ic19076436f3b07e57c6a906ae02eb0fd2b3595dd
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/49/688749/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b8c55fcfe7537eb7a6f450255761bb572f350b57,create-train, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/train}, -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},3,3
openstack%2Fpython-tripleoclient~stable%2Ftrain~I2488a8bdda1eab8f46d5dfda027633174f52e342,openstack/python-tripleoclient,stable/train,I2488a8bdda1eab8f46d5dfda027633174f52e342,Prepare stable/train,MERGED,2019-10-16 15:50:23.000000000,2019-10-17 05:41:24.000000000,2019-10-17 05:40:13.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 22816}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-10-16 15:50:23.000000000', 'files': ['.gitreview', 'tripleoclient/tests/v1/test_container_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e7132d47ea9b90c70fa2414d79c86c9a1dfc73a3', 'message': 'Prepare stable/train\n\nUpdate .gitreview for stable/train\n\nChange-Id: Ifae2ec26e9ccf125ba84d3b20795b3912d756811\n\nAdd mocks to fix unit tests\n\nChange: https://review.opendev.org/687305 broke\nthe unit tests. We need to mock the method:\n  get_undercloud_registry()\n\nChange-Id: I2488a8bdda1eab8f46d5dfda027633174f52e342\nCloses-Bug: #1848275\n(cherry picked from commit 0b21efc53df8352d63c3f07582c0efe3c6179373)\n'}]",0,688964,e7132d47ea9b90c70fa2414d79c86c9a1dfc73a3,10,6,1,3153,,,0,"Prepare stable/train

Update .gitreview for stable/train

Change-Id: Ifae2ec26e9ccf125ba84d3b20795b3912d756811

Add mocks to fix unit tests

Change: https://review.opendev.org/687305 broke
the unit tests. We need to mock the method:
  get_undercloud_registry()

Change-Id: I2488a8bdda1eab8f46d5dfda027633174f52e342
Closes-Bug: #1848275
(cherry picked from commit 0b21efc53df8352d63c3f07582c0efe3c6179373)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/64/688964/1 && git format-patch -1 --stdout FETCH_HEAD,"['.gitreview', 'tripleoclient/tests/v1/test_container_image.py']",2,e7132d47ea9b90c70fa2414d79c86c9a1dfc73a3,create-train," @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_local(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_local_path(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_oserror(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_all_options(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_oserror(self, mock_manager, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action(self, mock_manager, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_auth(self, mock_manager, mock_get_uc_registry):"," def test_take_action(self, mock_manager, mock_task): def test_take_action_local(self, mock_manager, mock_task): def test_take_action_local_path(self, mock_manager, mock_task): def test_take_action_oserror(self, mock_manager, mock_task): def test_take_action_all_options(self, mock_manager, mock_task): def test_oserror(self, mock_manager): def test_take_action(self, mock_manager): def test_take_action_auth(self, mock_manager):",29,8
openstack%2Fpuppet-nova~master~I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776,openstack/puppet-nova,master,I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776,Add ability to collocate pinned and unpinned instance on same host,MERGED,2019-09-10 10:32:52.000000000,2019-10-17 05:32:36.000000000,2019-10-15 08:21:43.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 15334}, {'_account_id': 16137}, {'_account_id': 17130}, {'_account_id': 17216}, {'_account_id': 17499}, {'_account_id': 18575}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28543}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-09-10 10:32:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/4c0d04424c8163792c2ea40f9c2893f0f1f9fbc7', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 2, 'created': '2019-09-10 13:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e640248206fae393dad1511e0c31002b448c0b7b', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 3, 'created': '2019-09-11 05:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/344f693080cec5594f0529ca45f53a920997ba07', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 4, 'created': '2019-09-11 07:05:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/776cac2c9919b6131cc4e5b2b6d24a2b334f5578', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 5, 'created': '2019-09-11 08:17:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/aa4ff9c7070ccdb5fbbf2d9a555ee070a75ec2ec', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 6, 'created': '2019-09-11 08:25:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/2b141b0d67db040292aa17e4e2668f558cd94e3d', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 7, 'created': '2019-09-11 08:49:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a1d1ef6845ab2b330670078daa7ecc290ccafca6', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 8, 'created': '2019-09-11 09:04:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/95fd1b49bb6f2802f6c99294a9061b25cbb1a629', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 9, 'created': '2019-09-11 10:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c419d9f985d39099af98278bdc6a138014ea4b17', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 10, 'created': '2019-09-12 07:36:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5315d6c1c8db99dcb3e7d7ef2bdbc0b3053a0cd1', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 11, 'created': '2019-09-12 08:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5b7b7ec8f9c2ccb5a35fcbd13defb2e5255f415b', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 12, 'created': '2019-09-12 10:28:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/27d7af2e08e3b5c543c258047d6ad44ae2333883', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 13, 'created': '2019-09-13 07:01:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/901a9e2023687b7f63bc7a559ce2319394a732b9', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 14, 'created': '2019-09-13 09:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/14ed178d6f78c97032f14dad978ab83fa1e60f02', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 15, 'created': '2019-09-13 10:46:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/84c0cb45639c6b18f10b7ddf9fb0c87259122885', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\nAlso add `enable_pinning_policy_translation` parameter in\nscheduler section to enable/disable this feature.\n\nFor new deployments this feature will be disabled by default\nand enabled during deployment.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 16, 'created': '2019-09-13 11:15:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/28cad4dd39c4911c0ed8c60a42f349ddde80abdf', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 17, 'created': '2019-09-16 09:52:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d41013f88f8a622a7b9f9eda131fb6c81a82ffe6', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 18, 'created': '2019-09-16 10:43:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e2a23ea983e39838cbe16c82d8bfe1ec46e9fdc2', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 19, 'created': '2019-09-17 05:21:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/a82d9107a14406ce8067cea6f8eab1a947ed4c3b', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 20, 'created': '2019-09-17 05:40:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8e4e24ed0a284615919154394f4c4b51964d3edb', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 21, 'created': '2019-09-19 12:57:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/5203f02b65b3601ce524fce7628630098efe4596', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 22, 'created': '2019-09-20 05:20:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/30d77dc275039e53e704be05f7ee625ec7b4ac30', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 23, 'created': '2019-09-23 05:28:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/8dd570d80e18045edc614a6b92ab8d78325b96b1', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 24, 'created': '2019-09-23 05:51:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/f6b075ae9da0a4079df9a5176e60d888224dc5bc', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 25, 'created': '2019-09-23 06:24:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d433aa3d4dfec25eaf88c1f5a04b4d62a9dcb726', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 26, 'created': '2019-09-23 06:58:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/d21b56917242aa72f21b114a940758ef2fa48600', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 27, 'created': '2019-09-23 12:34:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/2f21c7a1b2d967620964bafad899ba5b041f13c0', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 28, 'created': '2019-09-24 04:50:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7063abae622c6d47c45faca440e8137077dfdb06', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 29, 'created': '2019-09-24 07:25:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/7e8e2b5abbe319c24fd4172f0249fa2172cd33ec', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 30, 'created': '2019-09-24 11:02:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/c5973a5f8887c047c089f762ce3107fed9b20aa4', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 31, 'created': '2019-09-24 12:50:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/ad6300d345cf12b120ac0f5f219da13411bad4a7', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 32, 'created': '2019-09-25 05:06:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/e517a1f6311878fe55d014c3c2ebbd2d99246e97', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 33, 'created': '2019-09-25 11:27:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/38705715aa3216cc486d113c020bea66465a7127', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 34, 'created': '2019-09-30 11:43:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/1919702009476eeb2458c53b60d530d36e2c0efb', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 35, 'created': '2019-10-04 07:00:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/def8f223e8f37952a2787ada3418ea736721ee13', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 36, 'created': '2019-10-04 07:08:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/99f713343226a771403cead02f73af90e381e2ad', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 37, 'created': '2019-10-04 09:04:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/6717caca813a44aac6b68ed0314d77a7c5099733', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 38, 'created': '2019-10-04 12:06:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/fc5df9ff624c3f67538b9f0d186659b3c7e83163', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}, {'number': 39, 'created': '2019-10-07 13:23:06.000000000', 'files': ['releasenotes/notes/cpu-resources-39ce2f92ae6395ae.yaml', 'manifests/compute.pp', 'spec/classes/nova_compute_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-nova/commit/cf666bd557d2d5b94774cace4b09d91ea5822c2c', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd support for configuring `cpu_dedicated_set` parameter\nand modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters\nto add ability to collocate pinned and unpinned instances on same host.\n\nDeprecate `vcpu_pin_set` option as it is deprecated from config\noptions in nova [1] as well.\n\n[1] https://review.opendev.org/#/c/671793\n\nChange-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\n'}]",36,681207,cf666bd557d2d5b94774cace4b09d91ea5822c2c,144,15,39,20733,,,0,"Add ability to collocate pinned and unpinned instance on same host

Add support for configuring `cpu_dedicated_set` parameter
and modify logic for `vcpu_pin_set` and `cpu_shared_set` parameters
to add ability to collocate pinned and unpinned instances on same host.

Deprecate `vcpu_pin_set` option as it is deprecated from config
options in nova [1] as well.

[1] https://review.opendev.org/#/c/671793

Change-Id: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776
",git fetch https://review.opendev.org/openstack/puppet-nova refs/changes/07/681207/28 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/compute.pp', 'manifests/scheduler.pp', 'spec/classes/nova_compute_spec.rb', 'spec/classes/nova_scheduler_spec.rb']",4,4c0d04424c8163792c2ea40f9c2893f0f1f9fbc7,bp/cpu-resources, it { is_expected.to contain_nova_config('scheduler/enable_pinning_policy_translation').with_value('<SERVICE DEFAULT>') } context 'with enable_pinning_policy_translation' do let :params do { :enable_pinning_policy_translation => true } end it { is_expected.to contain_nova_config('scheduler/enable_pinning_policy_translation').with_value(true) } end ,,117,3
openstack%2Ftripleo-heat-templates~master~I894f339cdf03bc2a93c588f826f738b0b851a3ad,openstack/tripleo-heat-templates,master,I894f339cdf03bc2a93c588f826f738b0b851a3ad,Convert container environment from a list to a dict,MERGED,2019-10-08 13:23:49.000000000,2019-10-17 05:17:31.000000000,2019-10-17 05:17:30.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18002}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-08 13:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d461c13d2dcde2284d6ae00fbd24f8e700b4a760', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nDepends-On: I85999889d3328dc9d2116b8539ac959b39cb833a\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 2, 'created': '2019-10-08 14:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/30c90e90adcb21eeee0011b7a5b6ff0259204ec4', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nDepends-On: I85999889d3328dc9d2116b8539ac959b39cb833a\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 3, 'created': '2019-10-08 18:56:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d70d24e54bd25a279c3cad6e08e0f8e3784b84d9', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nDepends-On: I85999889d3328dc9d2116b8539ac959b39cb833a\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 4, 'created': '2019-10-09 12:38:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/03c395470ff25ea0469665be05ae22b3a2d3f6ec', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nDepends-On: I85999889d3328dc9d2116b8539ac959b39cb833a\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 5, 'created': '2019-10-10 01:36:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cfea0e7f2632bfeac6dc49f916b06b5af7b72d96', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 6, 'created': '2019-10-10 23:04:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/06631ec4dd9b538a8853bcaec3745dc80ab8c8e5', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\n'}, {'number': 7, 'created': '2019-10-11 22:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bf60d5b689edd987c8175d28042b76fe90cea57d', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 8, 'created': '2019-10-13 16:20:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b30502888a5f3b9ddf25652f78ff1db756968bdf', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 9, 'created': '2019-10-13 16:20:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a26e7fe7cbb147d88fcc00cde815dd5439b7c47', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 10, 'created': '2019-10-14 01:16:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4ecbfcf3536bf3fe65f26433ba88a9db46690d15', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 11, 'created': '2019-10-14 12:39:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/cafc63d37501a020b6f8c0f7640a58e34a68c0ba', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 12, 'created': '2019-10-14 16:58:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/441d4b198700c2bab94af809356b83ddcf158de3', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}, {'number': 13, 'created': '2019-10-15 14:24:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/050a54eef7298f50ac54698f431555ad3dd6c04b', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I98c75e03d78885173d829fa850f35c52c625e6bb\n'}, {'number': 14, 'created': '2019-10-15 14:24:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/5f564108072d875e5de8663766c644710dbbc6c5', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I98c75e03d78885173d829fa850f35c52c625e6bb\n'}, {'number': 15, 'created': '2019-10-15 18:03:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/8d1fa7ae1a24f31f2b53afe34cacce246d12169a', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I98c75e03d78885173d829fa850f35c52c625e6bb\n'}, {'number': 16, 'created': '2019-10-16 01:29:58.000000000', 'files': ['deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/ironic/ironic-neutron-agent-container-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/horizon/horizon-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml', 'deployment/ceilometer/ceilometer-agent-central-container-puppet.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'deployment/nova/nova-migration-target-container-puppet.yaml', 'deployment/heat/heat-engine-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'deployment/heat/heat-api-container-puppet.yaml', 'deployment/neutron/neutron-agents-ib-config-container-puppet.yaml', 'deployment/deprecated/opendaylight/opendaylight-api-container-puppet.yaml', 'deployment/gnocchi/gnocchi-statsd-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml', 'deployment/neutron/neutron-metadata-container-puppet.yaml', 'deployment/sahara/sahara-engine-container-puppet.yaml', 'deployment/logging/files/nova-api.yaml', 'deployment/ceilometer/ceilometer-agent-notification-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/multipathd/multipathd-container.yaml', 'deployment/ironic/ironic-pxe-container-puppet.yaml', 'deployment/swift/swift-storage-container-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'deployment/experimental/designate/designate-mdns-container-puppet.yaml', 'deployment/nova/nova-scheduler-container-puppet.yaml', 'deployment/experimental/designate/designate-worker-container-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/ironic/ironic-api-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/experimental/designate/designate-sink-container-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/sahara/sahara-api-container-puppet.yaml', 'deployment/mistral/mistral-event-engine-container-puppet.yaml', 'deployment/logging/stdout/haproxy.yaml', 'deployment/metrics/collectd-container-puppet.yaml', 'deployment/neutron/neutron-sriov-agent-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml', 'deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/experimental/designate/designate-api-container-puppet.yaml', 'deployment/nova/nova-ironic-container-puppet.yaml', 'deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/manila/manila-share-common.yaml', 'deployment/logging/files/nova-common.yaml', 'deployment/ceilometer/ceilometer-agent-compute-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/mistral/mistral-engine-container-puppet.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/messaging/rpc-qdrouterd-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/aodh/aodh-evaluator-container-puppet.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/mistral/mistral-executor-container-puppet.yaml', 'deployment/qdr/qdrouterd-container-puppet.yaml', 'deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cavium/liquidio-compute-config-container-puppet.yaml', 'deployment/deprecated/ec2/ec2-api-container-puppet.yaml', 'deployment/database/redis-container-puppet.yaml', 'deployment/database/mysql-container-puppet.yaml', 'deployment/ironic/ironic-conductor-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/aodh/aodh-notifier-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/keepalived/keepalived-container-puppet.yaml', 'deployment/mistral/mistral-api-container-puppet.yaml', 'deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'common/container-puppet.py', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/manila/manila-scheduler-container-puppet.yaml', 'deployment/placement/placement-api-container-puppet.yaml', 'deployment/metrics/qdr-container-puppet.yaml', 'deployment/aodh/aodh-api-container-puppet.yaml', 'deployment/logging/stdout/keystone.yaml', 'deployment/ceilometer/ceilometer-agent-ipmi-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/gnocchi/gnocchi-metricd-container-puppet.yaml', 'deployment/heat/heat-api-cfn-container-puppet.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/cinder/cinder-scheduler-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/manila/manila-api-container-puppet.yaml', 'deployment/pacemaker/clustercheck-container-puppet.yaml', 'deployment/ironic/ironic-inspector-container-puppet.yaml', 'deployment/neutron/neutron-mlnx-agent-container-puppet.yaml', 'deployment/experimental/designate/designate-central-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/zaqar/zaqar-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml', 'deployment/aodh/aodh-listener-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/nova/novajoin-container-puppet.yaml', 'deployment/experimental/designate/designate-producer-container-puppet.yaml', 'deployment/ovn/ovn-dbs-container-puppet.yaml', 'deployment/logrotate/logrotate-crond-container-puppet.yaml', 'deployment/logging/rsyslog-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/81258ae551f84237fe9028edd2ac7d3fba28e14b', 'message': 'Convert container environment from a list to a dict\n\nMoving all the container environments from lists to dicts, so they can\nbe consumed later by the podman_container ansible module which uses\ndict.\n\nUsing a dict is also easier to parse, since it doesn\'t involve ""="" for\neach item in the environment to export.\n\nChange-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad\nDepends-On: I98c75e03d78885173d829fa850f35c52c625e6bb\n'}]",9,687293,81258ae551f84237fe9028edd2ac7d3fba28e14b,63,8,16,3153,,,0,"Convert container environment from a list to a dict

Moving all the container environments from lists to dicts, so they can
be consumed later by the podman_container ansible module which uses
dict.

Using a dict is also easier to parse, since it doesn't involve ""="" for
each item in the environment to export.

Change-Id: I894f339cdf03bc2a93c588f826f738b0b851a3ad
Depends-On: I98c75e03d78885173d829fa850f35c52c625e6bb
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/93/687293/13 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/cinder/cinder-backup-pacemaker-puppet.yaml', 'deployment/ironic/ironic-neutron-agent-container-puppet.yaml', 'deployment/nova/nova-metadata-container-puppet.yaml', 'deployment/horizon/horizon-container-puppet.yaml', 'deployment/cinder/cinder-common-container-puppet.yaml', 'deployment/ceilometer/ceilometer-agent-central-container-puppet.yaml', 'deployment/swift/swift-proxy-container-puppet.yaml', 'deployment/nova/nova-migration-target-container-puppet.yaml', 'deployment/heat/heat-engine-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-container-puppet.yaml', 'deployment/heat/heat-api-container-puppet.yaml', 'deployment/neutron/neutron-agents-ib-config-container-puppet.yaml', 'deployment/deprecated/opendaylight/opendaylight-api-container-puppet.yaml', 'deployment/tacker/tacker-container-puppet.yaml', 'deployment/gnocchi/gnocchi-statsd-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-container-puppet.yaml', 'deployment/octavia/octavia-api-container-puppet.yaml', 'deployment/neutron/neutron-ovs-agent-container-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml', 'deployment/neutron/neutron-metadata-container-puppet.yaml', 'deployment/sahara/sahara-engine-container-puppet.yaml', 'deployment/logging/files/nova-api.yaml', 'deployment/ceilometer/ceilometer-agent-notification-container-puppet.yaml', 'deployment/cinder/cinder-api-container-puppet.yaml', 'deployment/multipathd/multipathd-container.yaml', 'deployment/ironic/ironic-pxe-container-puppet.yaml', 'deployment/swift/swift-storage-container-puppet.yaml', 'deployment/database/mysql-pacemaker-puppet.yaml', 'deployment/experimental/designate/designate-mdns-container-puppet.yaml', 'deployment/nova/nova-scheduler-container-puppet.yaml', 'deployment/experimental/designate/designate-worker-container-puppet.yaml', 'deployment/manila/manila-share-pacemaker-puppet.yaml', 'deployment/neutron/neutron-l3-container-puppet.yaml', 'deployment/ironic/ironic-api-container-puppet.yaml', 'deployment/gnocchi/gnocchi-api-container-puppet.yaml', 'deployment/neutron/neutron-api-container-puppet.yaml', 'deployment/experimental/designate/designate-sink-container-puppet.yaml', 'deployment/ovn/ovn-dbs-pacemaker-puppet.yaml', 'deployment/sahara/sahara-api-container-puppet.yaml', 'deployment/mistral/mistral-event-engine-container-puppet.yaml', 'deployment/logging/stdout/haproxy.yaml', 'deployment/metrics/collectd-container-puppet.yaml', 'deployment/neutron/neutron-sriov-agent-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml', 'deployment/deprecated/monitoring/sensu-client-container-puppet.yaml', 'deployment/nova/nova-vnc-proxy-container-puppet.yaml', 'deployment/experimental/designate/designate-api-container-puppet.yaml', 'deployment/nova/nova-ironic-container-puppet.yaml', 'deployment/octavia/octavia-worker-container-puppet.yaml', 'deployment/manila/manila-share-common.yaml', 'deployment/logging/files/nova-common.yaml', 'deployment/ceilometer/ceilometer-agent-compute-container-puppet.yaml', 'deployment/octavia/octavia-health-manager-container-puppet.yaml', 'deployment/mistral/mistral-engine-container-puppet.yaml', 'deployment/barbican/barbican-api-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-pacemaker-puppet.yaml', 'deployment/nova/nova-conductor-container-puppet.yaml', 'deployment/messaging/rpc-qdrouterd-container-puppet.yaml', 'deployment/keystone/keystone-container-puppet.yaml', 'deployment/aodh/aodh-evaluator-container-puppet.yaml', 'deployment/etcd/etcd-container-puppet.yaml', 'deployment/mistral/mistral-executor-container-puppet.yaml', 'deployment/qdr/qdrouterd-container-puppet.yaml', 'deployment/iscsid/iscsid-container-puppet.yaml', 'deployment/cavium/liquidio-compute-config-container-puppet.yaml', 'deployment/deprecated/ec2/ec2-api-container-puppet.yaml', 'deployment/database/redis-container-puppet.yaml', 'deployment/database/mysql-container-puppet.yaml', 'deployment/ironic/ironic-conductor-container-puppet.yaml', 'deployment/glance/glance-api-container-puppet.yaml', 'deployment/aodh/aodh-notifier-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-notify-pacemaker-puppet.yaml', 'deployment/keepalived/keepalived-container-puppet.yaml', 'deployment/mistral/mistral-api-container-puppet.yaml', 'deployment/haproxy/haproxy-pacemaker-puppet.yaml', 'deployment/database/redis-pacemaker-puppet.yaml', 'deployment/manila/manila-scheduler-container-puppet.yaml', 'deployment/placement/placement-api-container-puppet.yaml', 'deployment/metrics/qdr-container-puppet.yaml', 'deployment/aodh/aodh-api-container-puppet.yaml', 'deployment/logging/stdout/keystone.yaml', 'deployment/ceilometer/ceilometer-agent-ipmi-container-puppet.yaml', 'deployment/nova/nova-libvirt-container-puppet.yaml', 'deployment/cinder/cinder-volume-pacemaker-puppet.yaml', 'deployment/gnocchi/gnocchi-metricd-container-puppet.yaml', 'deployment/heat/heat-api-cfn-container-puppet.yaml', 'deployment/ovn/ovn-controller-container-puppet.yaml', 'deployment/neutron/neutron-dhcp-container-puppet.yaml', 'deployment/cinder/cinder-scheduler-container-puppet.yaml', 'deployment/ovn/ovn-metadata-container-puppet.yaml', 'deployment/manila/manila-api-container-puppet.yaml', 'deployment/pacemaker/clustercheck-container-puppet.yaml', 'deployment/ironic/ironic-inspector-container-puppet.yaml', 'deployment/neutron/neutron-mlnx-agent-container-puppet.yaml', 'deployment/experimental/designate/designate-central-container-puppet.yaml', 'deployment/nova/nova-api-container-puppet.yaml', 'deployment/nova/nova-compute-container-puppet.yaml', 'deployment/zaqar/zaqar-container-puppet.yaml', 'deployment/octavia/octavia-housekeeping-container-puppet.yaml', 'deployment/aodh/aodh-listener-container-puppet.yaml', 'deployment/rabbitmq/rabbitmq-messaging-rpc-container-puppet.yaml', 'deployment/nova/novajoin-container-puppet.yaml', 'deployment/experimental/designate/designate-producer-container-puppet.yaml', 'deployment/ovn/ovn-dbs-container-puppet.yaml', 'deployment/logrotate/logrotate-crond-container-puppet.yaml', 'deployment/logging/rsyslog-container-puppet.yaml']",106,d461c13d2dcde2284d6ae00fbd24f8e700b4a760,env, KOLLA_CONFIG_STRATEGY: COPY_ALWAYS, - KOLLA_CONFIG_STRATEGY=COPY_ALWAYS,321,424
openstack%2Ftacker~feature%2Ffalcon-api-framework~I85f813ef8911e518260a3026be91ba7f149edc6f,openstack/tacker,feature/falcon-api-framework,I85f813ef8911e518260a3026be91ba7f149edc6f,Tacker api framework design based on Falcon      - Base template implementation      - Added seperate schema and middleware      - We can use gunicorn server for request scalability      - configurable with wsgi      - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload,ABANDONED,2017-11-16 11:22:04.000000000,2019-10-17 05:15:54.000000000,,"[{'_account_id': 2874}, {'_account_id': 8580}, {'_account_id': 12455}, {'_account_id': 18955}, {'_account_id': 19853}, {'_account_id': 22348}, {'_account_id': 25505}]","[{'number': 1, 'created': '2017-11-16 11:22:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/8da59f24b99fd2dfd6f2fa16cfbdc39f6284b03a', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nBlueprint: bp/tacker-api-framework\n'}, {'number': 2, 'created': '2017-11-24 11:00:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/5ffd7aad19a4a3bc0426147bb945159fde81fe19', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nBlueprint: tacker-api-framework\n'}, {'number': 3, 'created': '2017-11-28 07:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/3f401e7cca3421b7802f67b67ae2879a5bb76dc0', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nImplements: blueprint tacker-api-framework\n'}, {'number': 4, 'created': '2017-11-28 08:56:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/4ddff15b0463ac2afc174a6c71c78b1139d2299c', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nImplements: blueprint tacker-api-framework\n'}, {'number': 5, 'created': '2017-12-12 10:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/dc602729da6b9901eb60510594a5ace96ab79036', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nImplements: blueprint tacker-api-framework\n'}, {'number': 6, 'created': '2017-12-12 10:13:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/64269709ae76c975b5951936708a98db9412fc27', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nImplements: blueprint tacker-api-framework\n'}, {'number': 7, 'created': '2017-12-18 08:37:22.000000000', 'files': ['tacker/api/controllers/app.py', 'tacker/api/controllers/v1/middleware/context.py', 'tacker/api/controllers/v1/__init__.py', 'tacker/api/controllers/v1/middleware/__init__.py', 'tacker/api/controllers/v1/vnffg.py', 'tacker/api/controllers/v1/vim.py', 'tacker/api/controllers/main.py', 'tacker/api/controllers/v1/schemas/vim.json', 'tacker/api/controllers/router.py', 'tacker/api/controllers/v1/schemas/__init__.py', 'tacker/api/controllers/__init__.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/788c76be8df07c51d2ab9f7b3c001ca234b5125d', 'message': 'Tacker api framework design based on Falcon\n     - Base template implementation\n     - Added seperate schema and middleware\n     - We can use gunicorn server for request scalability\n     - configurable with wsgi\n     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload\n\nChange-Id: I85f813ef8911e518260a3026be91ba7f149edc6f\nImplements: blueprint tacker-api-framework\n'}]",6,520495,788c76be8df07c51d2ab9f7b3c001ca234b5125d,25,7,7,8580,,,0,"Tacker api framework design based on Falcon
     - Base template implementation
     - Added seperate schema and middleware
     - We can use gunicorn server for request scalability
     - configurable with wsgi
     - Run - gunicorn -b 0.0.0.0:5000 main:api_app --reload

Change-Id: I85f813ef8911e518260a3026be91ba7f149edc6f
Implements: blueprint tacker-api-framework
",git fetch https://review.opendev.org/openstack/tacker refs/changes/95/520495/6 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/api/controllers/app.py', 'tacker/api/controllers/v1/__init__.py', 'tacker/api/controllers/v1/middleware/__init__.py', 'tacker/api/controllers/v1/middleware/context.py', 'tacker/api/controllers/v1/vim.py', 'tacker/api/controllers/v1/vnffg.py', 'tacker/api/controllers/main.py', 'tacker/api/controllers/v1/schemas/vim.json', 'tacker/api/controllers/router.py', 'tacker/api/controllers/v1/schemas/__init__.py', 'tacker/api/controllers/__init__.py']",11,8da59f24b99fd2dfd6f2fa16cfbdc39f6284b03a,bp/tacker-api-framework,,,224,0
openstack%2Ftacker~feature%2Ffalcon-api-framework~Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054,openstack/tacker,feature/falcon-api-framework,Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054,Base implementation for tacker API framework,ABANDONED,2017-03-08 01:30:50.000000000,2019-10-17 05:15:43.000000000,,[{'_account_id': 2874}],"[{'number': 1, 'created': '2017-03-08 01:30:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/818db5501e489c92b25cd3ae29f24ec0858f8630', 'message': 'Base implementation for tacker API framework\n\nChange-Id: Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054\nBlueprint: bp/tacker-api-framework\n'}, {'number': 2, 'created': '2017-03-16 05:23:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tacker/commit/ae579014c5f82ca02d6374bfb9794cf8b3685bba', 'message': 'Base implementation for tacker API framework\n\nChange-Id: Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054\nBlueprint: bp/tacker-api-framework\n'}, {'number': 3, 'created': '2017-04-19 04:43:35.000000000', 'files': ['tacker/api/controller/v1/__init__.py', 'tacker/api/controller/v1/things_resource.py', 'tacker/api/cmd.py', 'tacker/api/controller/router.py', 'tacker/api/controller/validator.py'], 'web_link': 'https://opendev.org/openstack/tacker/commit/2399958bc54c4ae8d885a96351f124b3d096a1f4', 'message': 'Base implementation for tacker API framework\n\nChange-Id: Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054\nBlueprint: bp/tacker-api-framework\n'}]",2,442887,2399958bc54c4ae8d885a96351f124b3d096a1f4,9,1,3,8580,,,0,"Base implementation for tacker API framework

Change-Id: Ieaafbc5cfc333a9ce3cda65452e4448c4cdd4054
Blueprint: bp/tacker-api-framework
",git fetch https://review.opendev.org/openstack/tacker refs/changes/87/442887/2 && git format-patch -1 --stdout FETCH_HEAD,"['tacker/api/controller/v1/__init__.py', 'tacker/api/controller/__init__.py', 'tacker/api/controller/v1/thing_resource.py', 'tacker/api/controller/validator.py', 'tacker/api/controller/api.py']",5,818db5501e489c92b25cd3ae29f24ec0858f8630,bp/bp,"import falcon from api.controller.v1.thing_resource import ThingsResource from wsgiref import simple_server # falcon.API instances are callable WSGI apps api = falcon.API() # Resources are represented by long-lived class instances things = ThingsResource() # things will handle all requests to the '/things' URL path app.add_route('/things', things) if __name__ == '__main__': httpd = simple_server.make_server('127.0.0.1', 8000, app) httpd.serve_forever() ",,45,0
openstack%2Fopenstack-helm-addons~master~I4af38d826fb1111d8bc6f0b5170fb1974f96ce86,openstack/openstack-helm-addons,master,I4af38d826fb1111d8bc6f0b5170fb1974f96ce86,sonobuoy: update image to v0.15.3,MERGED,2019-07-10 21:06:47.000000000,2019-10-17 05:01:37.000000000,2019-10-17 05:01:37.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28618}, {'_account_id': 28701}]","[{'number': 1, 'created': '2019-07-10 21:06:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6368a2a3a4c87b0e3c60e26f61e6485b8e612411', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 2, 'created': '2019-07-11 14:43:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/091cf1e5c2681a04d3ee101c472362809336cba6', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 3, 'created': '2019-07-11 15:06:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/5c858ff4baac5afc63b8064a860af7b2bd119f07', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 4, 'created': '2019-07-11 15:50:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/c053734260fa8dbbf68809c63f857bdee4897e43', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 5, 'created': '2019-07-11 16:02:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/9f51e6b66d7766c17d13bf6048a5f53e7a1bc25b', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 6, 'created': '2019-07-11 16:15:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/2f085c9bc4aff667d1d21084c2504335ce155128', 'message': 'wip: sonobuoy: update image to v0.15.0\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 7, 'created': '2019-08-05 17:46:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/651e2be8394b1761e5a1f717c8e337d458e225da', 'message': 'wip: sonobuoy: update image to v0.15.1\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 8, 'created': '2019-08-05 20:27:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/868b7622d1c63a2d86e3ecbc30a29b9bc5467479', 'message': 'wip: sonobuoy: update image to v0.15.1\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 9, 'created': '2019-08-12 12:22:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/5394e39bcf7a30bc76890e256d2d58c7e57adb00', 'message': 'wip: sonobuoy: update image to v0.15.1\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 10, 'created': '2019-08-12 13:46:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/5a866ee5e0c247df05ebe630280925db4ef59244', 'message': 'wip: sonobuoy: update image to v0.15.1\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 11, 'created': '2019-08-12 15:12:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/2ec52b3d433523ef10235b8c0f81ba424f6288fb', 'message': 'wip: sonobuoy: update image to v0.15.1\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 12, 'created': '2019-08-19 13:00:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/a50afc5e6da3dccc7f5b36990b73195a55621d25', 'message': 'wip: sonobuoy: update image to v0.15.2\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 13, 'created': '2019-09-03 13:12:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/c5242d211482b95a6920d038471f964bc001d54d', 'message': 'wip: sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 14, 'created': '2019-09-03 14:38:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/84cd42a7328f412ba649af4d1621d5ab75caf404', 'message': 'wip: sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 15, 'created': '2019-09-03 16:08:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/107511b07a8d634b52a760088a700c9687ad88cb', 'message': 'wip: sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 16, 'created': '2019-09-03 17:36:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/817e9f0f82ffec1844f1db50aee9425755613b4c', 'message': 'sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 17, 'created': '2019-10-16 19:19:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/d599545e0924f36d1f3b5b2fa7c3c5b5d4d4db53', 'message': 'sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}, {'number': 18, 'created': '2019-10-17 02:33:28.000000000', 'files': ['sonobuoy/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/f6537ed4f839e29d5b25cd6ff0dcd142c4c313eb', 'message': 'sonobuoy: update image to v0.15.3\n\nChange-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86\n'}]",0,670191,f6537ed4f839e29d5b25cd6ff0dcd142c4c313eb,46,5,18,28701,,,0,"sonobuoy: update image to v0.15.3

Change-Id: I4af38d826fb1111d8bc6f0b5170fb1974f96ce86
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/91/670191/16 && git format-patch -1 --stdout FETCH_HEAD,['sonobuoy/values.yaml'],1,6368a2a3a4c87b0e3c60e26f61e6485b8e612411,, sonobuoy_api: gcr.io/heptio-images/sonobuoy:v0.15.0, sonobuoy_api: gcr.io/heptio-images/sonobuoy:v0.11.4,1,1
openstack%2Fkolla~stable%2Fstein~Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,openstack/kolla,stable/stein,Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,Add disk dev name check function,MERGED,2019-10-16 13:23:27.000000000,2019-10-17 03:44:06.000000000,2019-10-17 03:43:05.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30687}]","[{'number': 1, 'created': '2019-10-16 13:23:27.000000000', 'files': ['docker/ceph/ceph-osd/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/6bc6469bc6750ccc388971d5b2f7e3fe98aba8f9', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n(cherry picked from commit 1d5f753fb13bcc3659b4abd1bb768de8550a6dc4)\n'}]",0,688926,6bc6469bc6750ccc388971d5b2f7e3fe98aba8f9,13,4,1,30687,,,0,"Add disk dev name check function

This patch will add new function in extend_start.sh for OSD
creation. Not only support loop device but also others that
disk dev layout is end with numbers.

Change-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48
Closes-Bug: #1847014
(cherry picked from commit 1d5f753fb13bcc3659b4abd1bb768de8550a6dc4)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/26/688926/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/ceph/ceph-osd/extend_start.sh'],1,6bc6469bc6750ccc388971d5b2f7e3fe98aba8f9,bug/1847014-stable/stein,"# Few storage device like loop or NVMe, wiil add ""p"" between disk & partition # name if disk layout is end with number. This function will fix to correct format. function part_name_checker { if [[ $1 =~ .*[0-9] ]]; then echo ${1}p${2} else echo ${1}${2} fi } sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" sgdisk --zap-all -- ""$(part_name_checker ${OSD_BS_BLK_DEV} ${OSD_BS_BLK_PARTNUM})"" wait_partition_appear ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_WAL_DEV $OSD_BS_WAL_PARTNUM)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DB_DEV $OSD_BS_DB_PARTNUM)"" mkfs.xfs -f ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" mount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" ""${OSD_DIR}"" umount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" "," if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi if [[ ""${OSD_BS_BLK_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""p${OSD_BS_BLK_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""${OSD_BS_BLK_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then wait_partition_appear ""${OSD_BS_DEV}""p2 sgdisk --zap-all -- ""${OSD_BS_DEV}""p2 else wait_partition_appear ""${OSD_BS_DEV}""2 sgdisk --zap-all -- ""${OSD_BS_DEV}""2 fi if [[ ""${OSD_BS_WAL_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""p${OSD_BS_WAL_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""${OSD_BS_WAL_PARTNUM}"" fi if [[ ""${OSD_BS_DB_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""p${OSD_BS_DB_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""${OSD_BS_DB_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then mkfs.xfs -f ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" else mkfs.xfs -f ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then umount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else umount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi",20,39
openstack%2Fmanila~stable%2Fqueens~Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f,openstack/manila,stable/queens,Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f,Remove backend spec from share type while creating replica,MERGED,2019-10-13 22:16:45.000000000,2019-10-17 03:37:09.000000000,2019-10-17 03:36:02.000000000,"[{'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-10-13 22:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/e1d949a1b0b29ab42b1f442183a89788ae22e186', 'message': 'Remove backend spec from share type while creating replica\n\nIf a share type includes the share_backend_name spec,\nthe scheduler may fail to schedule share replicas unless\nall backends in a replication domain share the same\nvalue for the capability ""share_backend_name"". Having\nthe same ""share_backend_name"" isn\'t desirable all the\ntime.\n\nIgnore the share_backend_name spec from share type\nwhile creating replica, so the scheduler will filter\na available backend according to the selection policy.\n\nChange-Id: Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f\nCloses-Bug: #1634734\n(cherry picked from commit 700c1a02f0a357312df8f47932f83e86a3d2dc86)\n(cherry picked from commit 19c4869a3f004e4ec699412c1831765b714aa93b)\n(cherry picked from commit e2fe03e25363a35bd07895505c18d349e4a330e7)\n'}, {'number': 2, 'created': '2019-10-16 21:08:08.000000000', 'files': ['manila/tests/scheduler/drivers/test_filter.py', 'manila/scheduler/drivers/filter.py', 'releasenotes/notes/bug-1634734-fix-backend-extraspec-for-replication-d611d2227997ae3e.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/c761bb559e9a79659ed5c4a6bfb79e30c5ecdc90', 'message': 'Remove backend spec from share type while creating replica\n\nIf a share type includes the share_backend_name spec,\nthe scheduler may fail to schedule share replicas unless\nall backends in a replication domain share the same\nvalue for the capability ""share_backend_name"". Having\nthe same ""share_backend_name"" isn\'t desirable all the\ntime.\n\nIgnore the share_backend_name spec from share type\nwhile creating replica, so the scheduler will filter\na available backend according to the selection policy.\n\nChange-Id: Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f\nCloses-Bug: #1634734\n(cherry picked from commit 700c1a02f0a357312df8f47932f83e86a3d2dc86)\n(cherry picked from commit 19c4869a3f004e4ec699412c1831765b714aa93b)\n(cherry picked from commit e2fe03e25363a35bd07895505c18d349e4a330e7)\n(cherry picked from commit bffeef11b4aea4a9e718fb7814336149b1d2abfd)\n'}]",0,688313,c761bb559e9a79659ed5c4a6bfb79e30c5ecdc90,17,6,2,16643,,,0,"Remove backend spec from share type while creating replica

If a share type includes the share_backend_name spec,
the scheduler may fail to schedule share replicas unless
all backends in a replication domain share the same
value for the capability ""share_backend_name"". Having
the same ""share_backend_name"" isn't desirable all the
time.

Ignore the share_backend_name spec from share type
while creating replica, so the scheduler will filter
a available backend according to the selection policy.

Change-Id: Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f
Closes-Bug: #1634734
(cherry picked from commit 700c1a02f0a357312df8f47932f83e86a3d2dc86)
(cherry picked from commit 19c4869a3f004e4ec699412c1831765b714aa93b)
(cherry picked from commit e2fe03e25363a35bd07895505c18d349e4a330e7)
(cherry picked from commit bffeef11b4aea4a9e718fb7814336149b1d2abfd)
",git fetch https://review.opendev.org/openstack/manila refs/changes/13/688313/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/scheduler/drivers/test_filter.py', 'manila/scheduler/drivers/filter.py', 'releasenotes/notes/bug-1634734-fix-backend-extraspec-for-replication-d611d2227997ae3e.yaml']",3,e1d949a1b0b29ab42b1f442183a89788ae22e186,bug/1634734-stable/train-stable/stein-stable/queens,--- fixes: - | Share type extra-specification ``share_backend_name`` is now ignored when creating share replicas. This ensures that backends in the same replication domain need not have the same value of ``share_backend_name``. See `launchpad bug #1634734 <https://bugs.launchpad.net/manila/+bug/1634734>`_ for details. ,,42,0
openstack%2Fopenstack-helm-infra~master~I09faa30b7402daa6f8ff8591d17040e2f94d1c20,openstack/openstack-helm-infra,master,I09faa30b7402daa6f8ff8591d17040e2f94d1c20,helm-toolkit: netpol requires DNS-1123 names,MERGED,2019-10-15 21:00:25.000000000,2019-10-17 03:20:36.000000000,2019-10-17 03:19:28.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28618}, {'_account_id': 28719}, {'_account_id': 28849}, {'_account_id': 29397}]","[{'number': 1, 'created': '2019-10-15 21:00:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9916f080cd6f6126007aab3de1d57e712a49fc93', 'message': 'helm-toolkit: netpol requires DNS-1123 names\n\nEnsures that network policy names do not have underscores.\n\nChange-Id: I09faa30b7402daa6f8ff8591d17040e2f94d1c20\n'}, {'number': 2, 'created': '2019-10-15 22:05:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6d962ffd69b2cc170838f831a4d5c073ccfd8510', 'message': 'helm-toolkit: netpol requires DNS-1123 names\n\nEnsures that network policy names do not have underscores.\n\nChange-Id: I09faa30b7402daa6f8ff8591d17040e2f94d1c20\n'}, {'number': 3, 'created': '2019-10-16 21:52:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e4aed31cb67858867c2cef70229df7812e183bc6', 'message': 'helm-toolkit: netpol requires DNS-1123 names\n\nEnsures that network policy names do not have underscores.\n\nChange-Id: I09faa30b7402daa6f8ff8591d17040e2f94d1c20\n'}, {'number': 4, 'created': '2019-10-17 01:29:42.000000000', 'files': ['helm-toolkit/templates/manifests/_network_policy.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ef58054dff356334cdbfd96f04dc7c149768c76d', 'message': 'helm-toolkit: netpol requires DNS-1123 names\n\nEnsures that network policy names do not have underscores.\n\nChange-Id: I09faa30b7402daa6f8ff8591d17040e2f94d1c20\n'}]",0,688814,ef58054dff356334cdbfd96f04dc7c149768c76d,30,7,4,28719,,,0,"helm-toolkit: netpol requires DNS-1123 names

Ensures that network policy names do not have underscores.

Change-Id: I09faa30b7402daa6f8ff8591d17040e2f94d1c20
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/14/688814/1 && git format-patch -1 --stdout FETCH_HEAD,['helm-toolkit/templates/manifests/_network_policy.tpl'],1,9916f080cd6f6126007aab3de1d57e712a49fc93,netpol,"{{- $name := index . ""name"" | replace ""_"" ""-"" -}}","{{- $name := index . ""name"" -}}",1,1
openstack%2Fwhereto~master~I337c1f756dde3ff6277b1e8d1ad1e3eff49a7e47,openstack/whereto,master,I337c1f756dde3ff6277b1e8d1ad1e3eff49a7e47,tox: Keeping going with docs,MERGED,2019-10-16 13:21:37.000000000,2019-10-17 03:06:24.000000000,2019-10-17 03:05:26.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 13:21:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/whereto/commit/7a8b4ae14961433157f89c8ff9a40f64dfd4d7dd', 'message': ""tox: Keeping going with docs\n\nSphinx 1.8 introduced [1] the '--keep-going' argument which, as its name\nsuggests, keeps the build running when it encounters non-fatal errors.\nThis is exceptionally useful in avoiding a continuous edit-build loop\nwhen undertaking large doc reworks where multiple errors may be\nintroduced.\n\n[1] sphinx-doc/sphinx@e3483e9\n\nChange-Id: I337c1f756dde3ff6277b1e8d1ad1e3eff49a7e47\n""}, {'number': 2, 'created': '2019-10-16 13:23:01.000000000', 'files': ['CONTRIBUTING.rst', 'doc/source/index.rst', 'test-requirements.txt', 'tox.ini', 'HACKING.rst'], 'web_link': 'https://opendev.org/openstack/whereto/commit/01a17424761ed1d38ca3af41c4223425a5fbc75c', 'message': ""tox: Keeping going with docs\n\n1. Sphinx 1.8 introduced [1] the '--keep-going' argument which, as its name\nsuggests, keeps the build running when it encounters non-fatal errors.\nThis is exceptionally useful in avoiding a continuous edit-build loop\nwhen undertaking large doc reworks where multiple errors may be\nintroduced.\n2. remove the unnecessary ==\n3. update the url to latest\n\n[1] sphinx-doc/sphinx@e3483e9\n\nChange-Id: I337c1f756dde3ff6277b1e8d1ad1e3eff49a7e47\n""}]",0,688925,01a17424761ed1d38ca3af41c4223425a5fbc75c,8,2,2,28614,,,0,"tox: Keeping going with docs

1. Sphinx 1.8 introduced [1] the '--keep-going' argument which, as its name
suggests, keeps the build running when it encounters non-fatal errors.
This is exceptionally useful in avoiding a continuous edit-build loop
when undertaking large doc reworks where multiple errors may be
introduced.
2. remove the unnecessary ==
3. update the url to latest

[1] sphinx-doc/sphinx@e3483e9

Change-Id: I337c1f756dde3ff6277b1e8d1ad1e3eff49a7e47
",git fetch https://review.opendev.org/openstack/whereto refs/changes/25/688925/2 && git format-patch -1 --stdout FETCH_HEAD,"['CONTRIBUTING.rst', 'doc/source/index.rst', 'test-requirements.txt', 'tox.ini', 'HACKING.rst']",5,7a8b4ae14961433157f89c8ff9a40f64dfd4d7dd,,==========================,===============================================,8,8
openstack%2Fkolla-cli~master~I8a214309eb04e8f25ddf6111d6fb31917e022b34,openstack/kolla-cli,master,I8a214309eb04e8f25ddf6111d6fb31917e022b34,Typo fixed: Update Upgrade to Check,MERGED,2019-10-16 05:43:58.000000000,2019-10-17 03:04:09.000000000,2019-10-17 03:03:03.000000000,"[{'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-10-16 05:43:58.000000000', 'files': ['kolla_cli/commands/kolla_action.py'], 'web_link': 'https://opendev.org/openstack/kolla-cli/commit/5a1662a2727e10553b831ec05d7a6f926b0c2803', 'message': 'Typo fixed: Update Upgrade to Check\n\nChange-Id: I8a214309eb04e8f25ddf6111d6fb31917e022b34\n'}]",0,688850,5a1662a2727e10553b831ec05d7a6f926b0c2803,8,3,1,28614,,,0,"Typo fixed: Update Upgrade to Check

Change-Id: I8a214309eb04e8f25ddf6111d6fb31917e022b34
",git fetch https://review.opendev.org/openstack/kolla-cli refs/changes/50/688850/1 && git format-patch -1 --stdout FETCH_HEAD,['kolla_cli/commands/kolla_action.py'],1,5a1662a2727e10553b831ec05d7a6f926b0c2803,, help=u._('Check service list')), help=u._('Upgrade service list')),1,1
openstack%2Fpython-tripleoclient~master~Iec0f4f8279e5628dcb867312504acdc4fafc8152,openstack/python-tripleoclient,master,Iec0f4f8279e5628dcb867312504acdc4fafc8152,Use name for container registry,MERGED,2019-10-08 18:54:54.000000000,2019-10-17 02:46:25.000000000,2019-10-17 02:44:14.000000000,"[{'_account_id': 4571}, {'_account_id': 7144}, {'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 18575}, {'_account_id': 21909}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}, {'_account_id': 28935}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-10-08 18:54:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/73105ad37171a339b18cf357ae3cf16e37cc0d0d', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 2, 'created': '2019-10-08 19:05:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c5f1312f703a093a297d2f504ce521a112420fc4', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 3, 'created': '2019-10-08 19:06:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d4c1d6fbd541a45b5463179010a7cfde69fe5000', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 4, 'created': '2019-10-08 20:53:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e52607752ef030db0402fdcd50fbb4d6eec0e6d4', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 5, 'created': '2019-10-10 03:21:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3baba5f93553c63966049e30441a0b0b4b6894a3', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 6, 'created': '2019-10-10 12:20:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/995ae202d504f442eb8cf8fe135d7b818aa2b351', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.localdomain for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 7, 'created': '2019-10-11 09:45:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/abc2f02ee6c5027792b633ea4306449f46fac382', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 8, 'created': '2019-10-14 08:37:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d780e25e3deba4f9f0a5580307b7b70e5081e922', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 9, 'created': '2019-10-16 09:06:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/35152fe4b69cb4fa0c5f268d0f97a8d1494088b4', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}, {'number': 10, 'created': '2019-10-16 11:11:16.000000000', 'files': ['tripleoclient/v1/undercloud_config.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/e3064514a6113e89f4cb24ffe2e341ee91628741', 'message': 'Use name for container registry\n\nFor Docker/Podman using an IPv6 address in a docker reference\nis invalid. A name must be used:\n      https://github.com/containers/libpod/issues/3516\n\nUse the undercloud hostname on the ctlplane network.\n<shortname>.ctlplane.<domain> for local container registry.\n\nRelated-Bug: #1836578\nDepends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2\nChange-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152\n'}]",10,687388,e3064514a6113e89f4cb24ffe2e341ee91628741,60,12,10,24245,,,0,"Use name for container registry

For Docker/Podman using an IPv6 address in a docker reference
is invalid. A name must be used:
      https://github.com/containers/libpod/issues/3516

Use the undercloud hostname on the ctlplane network.
<shortname>.ctlplane.<domain> for local container registry.

Related-Bug: #1836578
Depends-On: I23b8ca6a3f481781d9d91e1a5d83ab1311a272e2
Change-Id: Iec0f4f8279e5628dcb867312504acdc4fafc8152
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/88/687388/7 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/undercloud_config.py', 'tripleoclient/utils.py']",2,73105ad37171a339b18cf357ae3cf16e37cc0d0d,bug/1836578,"def get_shortbyaddr(address): """"""Get the systems shortname"""""" return socket.gethostbyaddr(address)[0][1] ",,14,7
openstack%2Fopenstack-helm-images~master~I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b,openstack/openstack-helm-images,master,I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b,Include default timeout values to the nagios plugins,MERGED,2019-10-15 04:39:30.000000000,2019-10-17 02:46:09.000000000,2019-10-17 02:44:50.000000000,"[{'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 18295}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-10-15 04:39:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/e7ad02cfeee3d711a93a14ec502bff51b215470b', 'message': 'Include timeout option to the prometheus plugin\n\nAdd the timeout option to nagios prometheus plugin.\n\nChange-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b\n'}, {'number': 2, 'created': '2019-10-15 19:11:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/2181aed8b1ebd06cc4ef8b4ae3519ab6825b9cf2', 'message': 'Include default timeout values to the nagios plugins\n\nThis will prevent the service checks queuing up\n\nChange-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b\n'}, {'number': 3, 'created': '2019-10-15 20:41:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/66f0df65c0a639925989de0c4e9e215d80e177e4', 'message': 'Include default timeout values to the nagios plugins\n\nThis will prevent the service checks queuing up\n\nChange-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b\n'}, {'number': 4, 'created': '2019-10-16 14:39:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/3fcde125cb30b9415e00e8f864b92c571fdf7edc', 'message': 'Include default timeout values to the nagios plugins\n\nThis will prevent the service checks queuing up\n\nChange-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b\n'}, {'number': 5, 'created': '2019-10-16 21:51:12.000000000', 'files': ['nagios/plugins/query_prometheus_alerts.py', 'nagios/plugins/query_elasticsearch.py'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8325c8d33fdccdbab76a5fe02fc68aa268019a70', 'message': 'Include default timeout values to the nagios plugins\n\nThis will prevent the service checks queuing up\n\nChange-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b\n'}]",16,688615,8325c8d33fdccdbab76a5fe02fc68aa268019a70,25,6,5,18295,,,0,"Include default timeout values to the nagios plugins

This will prevent the service checks queuing up

Change-Id: I8cd69ed393c107f5126b4d9d4ce931ecce86cd8b
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/15/688615/3 && git format-patch -1 --stdout FETCH_HEAD,['nagios/plugins/query_prometheus_alerts.py'],1,e7ad02cfeee3d711a93a14ec502bff51b215470b,," parser.add_argument( '--timeout', metavar='timeout', type=float, default=10, required=False, help='Number of seconds to wait for response.') args.prometheus_api, args.alertname, args.labels_csv,args.timeout) args.prometheus_api, args.metrics_csv.split("",""), args.labels_csv,args.timeout)def query_prometheus(prometheus_api, alertname, labels_csv,timeout): params=query,timeout=timeout) except requests.exceptions.Timeout as timeoutException: error_messages.append( ""ERROR while invoking prometheus api, Connection timed out, the maximum timeout value of {} seconds"".format(timeout)) ""ERROR while invoking prometheus api {}"".format(def check_prom_metrics_available(prometheus_api, metrics, labels_csv,timeout): params=query,timeout=timeout) except requests.exceptions.Timeout as timeoutException: error_messages.append( ""ERROR while invoking prometheus api, Connection timed out, the maximum timeout value of {} seconds"".format(timeout)) ""ERROR while invoking prometheus api {}"".format("," args.prometheus_api, args.alertname, args.labels_csv) args.prometheus_api, args.metrics_csv.split("",""), args.labels_csv)def query_prometheus(prometheus_api, alertname, labels_csv): params=query) ""ERROR invoking prometheus api {}"".format(def check_prom_metrics_available(prometheus_api, metrics, labels_csv): params=query) ""ERROR invoking prometheus api {}"".format(",22,8
openstack%2Ftripleo-heat-templates~stable%2Fstein~I8f71bf83ddafca167deae1a38ca819f7d930fb80,openstack/tripleo-heat-templates,stable/stein,I8f71bf83ddafca167deae1a38ca819f7d930fb80,Workaround ovn cluster failure during update when schema change.,MERGED,2019-10-16 04:43:03.000000000,2019-10-17 02:44:15.000000000,2019-10-17 02:44:15.000000000,"[{'_account_id': 8297}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 04:43:03.000000000', 'files': ['deployment/ovn/ovn-dbs-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d9c60ab05e9d67c35602d3fdf5f2658c49028874', 'message': ""Workaround ovn cluster failure during update when schema change.\n\nDuring update the ovndb server can have a schema change. The problem\nis that an updated slave ovndb wouldn't connect to a master which\nstill has the old db schema.  At some point (200000ms) pacemaker put\nthe resource in error Time Out.  Then it will wait for the operator to\ncleanup the resource.  Meaning that the update can goes like this:\n\n - Original state: (Master, Slave, Failed): nothing updated\n   - ctl0-M-old\n   - ctl1-S-old\n   - ctl2-S-old\n - First state: after update of ctl0\n   - ctl0-F-new\n   - ctl1-M-old\n   - ctl2-S-old\n - Second state: after update of ctl1\n   - ctl0-F-new\n   - ctl1-F-new\n   - ctl2-M-old\n - Third and final state: after update of ctl2\n   - ctl0-F-new\n   - ctl1-F-new\n   - ctl2-M-new\n\nDuring the third state we have a cut in the control plane as ctl2 is\nthe master and there is no slave to fall back to. Then we end up\nloosing HA as only one node is active.  The error persists after\nreboot.  Only a pcs resource cleanup will bring the cluster online.\n\nThe real solution will come from ovndb and the associated ocf agent,\nbut in the meantime, we workaround it by:\n - cleanup\n - ban the resource;\nin step 1 and:\n - cleanup\n - unban the resource\nin step 5.\n\nThis has the net effect of preventing the cut in the control plane for\nthe last node as we move master to the updated controller which will\nform a cluster of one master and one slave (as two are updated).  The\nlast one will happily join then when it will be updated.\n\nThat means:\n - we always have either 1 or 2 nodes working;\n - we end the update with the cluster converged back to a stable\n state.\n\nThe problems are :\n - we could hide a real ovndb cluster issue;\n- if the update break in-between we could have a leftover ban on one\n of the node;\n\nBut, all things considered, this looks like the best compromise for\nthe time being.\n\nChange-Id: I8f71bf83ddafca167deae1a38ca819f7d930fb80\nCloses-Bug: #1847780\n(cherry picked from commit 751b3fc09632cf184bf947be8f74d771554a23d0)\n""}]",0,688846,d9c60ab05e9d67c35602d3fdf5f2658c49028874,14,5,1,8297,,,0,"Workaround ovn cluster failure during update when schema change.

During update the ovndb server can have a schema change. The problem
is that an updated slave ovndb wouldn't connect to a master which
still has the old db schema.  At some point (200000ms) pacemaker put
the resource in error Time Out.  Then it will wait for the operator to
cleanup the resource.  Meaning that the update can goes like this:

 - Original state: (Master, Slave, Failed): nothing updated
   - ctl0-M-old
   - ctl1-S-old
   - ctl2-S-old
 - First state: after update of ctl0
   - ctl0-F-new
   - ctl1-M-old
   - ctl2-S-old
 - Second state: after update of ctl1
   - ctl0-F-new
   - ctl1-F-new
   - ctl2-M-old
 - Third and final state: after update of ctl2
   - ctl0-F-new
   - ctl1-F-new
   - ctl2-M-new

During the third state we have a cut in the control plane as ctl2 is
the master and there is no slave to fall back to. Then we end up
loosing HA as only one node is active.  The error persists after
reboot.  Only a pcs resource cleanup will bring the cluster online.

The real solution will come from ovndb and the associated ocf agent,
but in the meantime, we workaround it by:
 - cleanup
 - ban the resource;
in step 1 and:
 - cleanup
 - unban the resource
in step 5.

This has the net effect of preventing the cut in the control plane for
the last node as we move master to the updated controller which will
form a cluster of one master and one slave (as two are updated).  The
last one will happily join then when it will be updated.

That means:
 - we always have either 1 or 2 nodes working;
 - we end the update with the cluster converged back to a stable
 state.

The problems are :
 - we could hide a real ovndb cluster issue;
- if the update break in-between we could have a leftover ban on one
 of the node;

But, all things considered, this looks like the best compromise for
the time being.

Change-Id: I8f71bf83ddafca167deae1a38ca819f7d930fb80
Closes-Bug: #1847780
(cherry picked from commit 751b3fc09632cf184bf947be8f74d771554a23d0)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/688846/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-dbs-pacemaker-puppet.yaml'],1,d9c60ab05e9d67c35602d3fdf5f2658c49028874,bug/1847780-stable/stein," # When a schema change happens, the newer slaves don't connect # back to the older master and end up timing out. So we clean # up the error here until we get a fix for # https://bugzilla.redhat.com/show_bug.cgi?id=1759974 - name: Clear ovndb cluster pacemaker error shell: ""pcs resource cleanup ovn-dbs-bundle"" when: - step|int == 1 # Then we ban the resource for this node. It has no effect on # the first two controllers, but when we reach the last one, # it avoids a cut in the control plane as master get chosen in # one of the updated Stopped ovn. They are in error, that why # we need the cleanup just before. - name: Ban ovndb resource on the current node. shell: ""pcs resource ban ovn-dbs-bundle $(hostname | cut -d. -f1)"" when: - step|int == 1 # We remove any leftover error and remove the ban. - name: Ensure the cluster converge back even in case of schema change shell: ""pcs resource cleanup ovn-dbs-bundle"" when: - step|int == 5 - name: Remove the ban shell: ""pcs resource clear ovn-dbs-bundle"" when: - step|int == 5",,26,0
openstack%2Fpython-tripleoclient~master~I2488a8bdda1eab8f46d5dfda027633174f52e342,openstack/python-tripleoclient,master,I2488a8bdda1eab8f46d5dfda027633174f52e342,Add mocks to fix unit tests,MERGED,2019-10-16 09:45:14.000000000,2019-10-17 02:34:09.000000000,2019-10-17 02:33:04.000000000,"[{'_account_id': 3153}, {'_account_id': 8449}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}, {'_account_id': 24245}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-10-16 09:45:14.000000000', 'files': ['tripleoclient/tests/v1/test_container_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0b21efc53df8352d63c3f07582c0efe3c6179373', 'message': 'Add mocks to fix unit tests\n\nChange: https://review.opendev.org/687305 broke\nthe unit tests. We need to mock the method:\n  get_undercloud_registry()\n\nChange-Id: I2488a8bdda1eab8f46d5dfda027633174f52e342\nCloses-Bug: #1848275\n'}]",0,688890,0b21efc53df8352d63c3f07582c0efe3c6179373,15,8,1,24245,,,0,"Add mocks to fix unit tests

Change: https://review.opendev.org/687305 broke
the unit tests. We need to mock the method:
  get_undercloud_registry()

Change-Id: I2488a8bdda1eab8f46d5dfda027633174f52e342
Closes-Bug: #1848275
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/90/688890/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/v1/test_container_image.py'],1,0b21efc53df8352d63c3f07582c0efe3c6179373,bug/1848275," @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_local(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_local_path(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_oserror(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_all_options(self, mock_manager, mock_task, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_oserror(self, mock_manager, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action(self, mock_manager, mock_get_uc_registry): @mock.patch('tripleo_common.image.image_uploader.get_undercloud_registry', return_value='uc.ctlplane.somedomain') def test_take_action_auth(self, mock_manager, mock_get_uc_registry):"," def test_take_action(self, mock_manager, mock_task): def test_take_action_local(self, mock_manager, mock_task): def test_take_action_local_path(self, mock_manager, mock_task): def test_take_action_oserror(self, mock_manager, mock_task): def test_take_action_all_options(self, mock_manager, mock_task): def test_oserror(self, mock_manager): def test_take_action(self, mock_manager): def test_take_action_auth(self, mock_manager):",28,8
openstack%2Fmanila~stable%2Ftrain~Iba2761db53da68a1c497e2e5dd370c36a22ebbed,openstack/manila,stable/train,Iba2761db53da68a1c497e2e5dd370c36a22ebbed,Fix share network update erroneously returns success,MERGED,2019-10-14 19:22:58.000000000,2019-10-17 02:22:07.000000000,2019-10-17 00:49:40.000000000,"[{'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 29632}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-10-14 19:22:58.000000000', 'files': ['manila/api/v2/share_networks.py', 'releasenotes/notes/bug-1846836-fix-share-network-update-unexpected-success-eba8f40db392c467.yaml', 'manila/tests/api/v2/test_share_networks.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/0c10d54a096de7dbdf6eb1d781753317325f64db', 'message': 'Fix share network update erroneously returns success\n\nThis patch fixes an issue while performing share network update.\nManila was allowing the user to update a share network even if it\ndid not contain a default subnet. Now, we throw an error if there\nis no default subnet to be updated. Also, adds an extra validation.\nNow, Manila do not allow the default share network subnet update if\nit is going to have only `neutron_net_id` or `neutron_subnet_id`\nafter the update.\n\nChange-Id: Iba2761db53da68a1c497e2e5dd370c36a22ebbed\nCloses-Bug: #1846836\n(cherry picked from commit de2d94172bebc8d8771e2e67860d94559a86cece)\n'}]",0,688543,0c10d54a096de7dbdf6eb1d781753317325f64db,17,7,1,29632,,,0,"Fix share network update erroneously returns success

This patch fixes an issue while performing share network update.
Manila was allowing the user to update a share network even if it
did not contain a default subnet. Now, we throw an error if there
is no default subnet to be updated. Also, adds an extra validation.
Now, Manila do not allow the default share network subnet update if
it is going to have only `neutron_net_id` or `neutron_subnet_id`
after the update.

Change-Id: Iba2761db53da68a1c497e2e5dd370c36a22ebbed
Closes-Bug: #1846836
(cherry picked from commit de2d94172bebc8d8771e2e67860d94559a86cece)
",git fetch https://review.opendev.org/openstack/manila refs/changes/43/688543/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/api/v2/share_networks.py', 'releasenotes/notes/bug-1846836-fix-share-network-update-unexpected-success-eba8f40db392c467.yaml', 'manila/tests/api/v2/test_share_networks.py']",3,0c10d54a096de7dbdf6eb1d781753317325f64db,bug/1846836-stable/train," self.mock_object(db_api, 'share_network_subnet_get_default_subnet', mock.Mock(return_value=fake_share_network_subnet)) self.mock_object(db_api, 'share_network_subnet_update') db_api.share_network_subnet_get_default_subnet.assert_called_once_with( self.context, share_nw) db_api.share_network_subnet_update.assert_called_once_with( self.context, fake_share_network_subnet['id'], body['share_network']) @ddt.data((webob_exc.HTTPBadRequest, fake_share_network_subnet, None, 'new subnet'), (webob_exc.HTTPBadRequest, None, 'neutron net', None)) @ddt.unpack def test_update_default_subnet_errors(self, exception_to_raise, get_default_subnet_return, neutron_net_id, neutron_subnet_id): share_nw = 'fake network id' self.mock_object(db_api, 'share_network_get', mock.Mock(return_value=fake_share_network)) self.mock_object( self.controller, '_share_network_subnets_contain_share_servers', mock.Mock(return_value=False)) self.mock_object(db_api, 'share_network_subnet_get_default_subnet', mock.Mock(return_value=get_default_subnet_return)) if get_default_subnet_return: fake_subnet = copy.deepcopy(fake_share_network_subnet) fake_subnet['neutron_net_id'] = None fake_subnet['neutron_subnet_id'] = None db_api.share_network_subnet_get_default_subnet.return_value = ( fake_subnet) body = { share_networks.RESOURCE_NAME: { 'neutron_net_id': neutron_net_id, 'neutron_subnet_id': neutron_subnet_id } } self.assertRaises(exception_to_raise, self.controller.update, self.req, share_nw, body) db_api.share_network_subnet_get_default_subnet.assert_called_once_with( self.context, share_nw)",,81,4
openstack%2Ftripleo-upgrade~stable%2Fstein~Iec0cd44ee79708d48f9c40b58e0a9cbed76d3e9c,openstack/tripleo-upgrade,stable/stein,Iec0cd44ee79708d48f9c40b58e0a9cbed76d3e9c,Handle upgrade_prepare_extra_params as comma-separated string.,MERGED,2019-10-14 14:52:20.000000000,2019-10-17 01:28:37.000000000,2019-10-17 01:28:36.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 8297}, {'_account_id': 20775}, {'_account_id': 21537}, {'_account_id': 22348}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-10-14 14:52:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/127abbe04057cc793cb56466af47a42191948b88', 'message': 'Handle upgrade_prepare_extra_params as comma-separated string.\n\nInfrared handles the extra-vars parameters passed as a list as strings.\nCurrently, tripleo-upgrade differentiates if the parameter is a string\nor a list, but it does not cover the case when the parameter was a list\ncasted into a string. The solution implemented is to accept a comma\nseparated string like -e upgrade_prepare_extra_params=""/home/stack/\novercloud-params.yaml,/home/stack/overcloud-repos.yaml"" which then\nwill be passed into the overcloud upgrade prepare.\n\nChange-Id: Iec0cd44ee79708d48f9c40b58e0a9cbed76d3e9c\n(cherry picked from commit ab66d7e081476c098baea5518838a996f26a5e16)\n'}, {'number': 2, 'created': '2019-10-16 16:09:10.000000000', 'files': ['templates/overcloud_upgrade_prepare.sh.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-upgrade/commit/508aee8bb90b2d96db570b4a45928bb2ce24f7fd', 'message': 'Handle upgrade_prepare_extra_params as comma-separated string.\n\nInfrared handles the extra-vars parameters passed as a list as strings.\nCurrently, tripleo-upgrade differentiates if the parameter is a string\nor a list, but it does not cover the case when the parameter was a list\ncasted into a string. The solution implemented is to accept a comma\nseparated string like -e upgrade_prepare_extra_params=""/home/stack/\novercloud-params.yaml,/home/stack/overcloud-repos.yaml"" which then\nwill be passed into the overcloud upgrade prepare.\n\nChange-Id: Iec0cd44ee79708d48f9c40b58e0a9cbed76d3e9c\n(cherry picked from commit ab66d7e081476c098baea5518838a996f26a5e16)\n'}]",0,688417,508aee8bb90b2d96db570b4a45928bb2ce24f7fd,12,7,2,26343,,,0,"Handle upgrade_prepare_extra_params as comma-separated string.

Infrared handles the extra-vars parameters passed as a list as strings.
Currently, tripleo-upgrade differentiates if the parameter is a string
or a list, but it does not cover the case when the parameter was a list
casted into a string. The solution implemented is to accept a comma
separated string like -e upgrade_prepare_extra_params=""/home/stack/
overcloud-params.yaml,/home/stack/overcloud-repos.yaml"" which then
will be passed into the overcloud upgrade prepare.

Change-Id: Iec0cd44ee79708d48f9c40b58e0a9cbed76d3e9c
(cherry picked from commit ab66d7e081476c098baea5518838a996f26a5e16)
",git fetch https://review.opendev.org/openstack/tripleo-upgrade refs/changes/17/688417/2 && git format-patch -1 --stdout FETCH_HEAD,['templates/overcloud_upgrade_prepare.sh.j2'],1,127abbe04057cc793cb56466af47a42191948b88,," {% if ',' in upgrade_prepare_extra_params -%} -e {{ upgrade_prepare_extra_params.split(',') | join(' -e ') }} \ {% else -%} {% endif -%}",,4,0
openstack%2Fos-apply-config~master~I763567667ce5c8d4f30032c9bfde85ee7bda1754,openstack/os-apply-config,master,I763567667ce5c8d4f30032c9bfde85ee7bda1754,Avoid overwriting existing value,ABANDONED,2019-10-14 00:59:07.000000000,2019-10-17 01:26:11.000000000,,"[{'_account_id': 4257}, {'_account_id': 4571}, {'_account_id': 6484}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-14 00:59:07.000000000', 'files': ['os_apply_config/tests/test_collect_config.py', 'os_apply_config/collect_config.py'], 'web_link': 'https://opendev.org/openstack/os-apply-config/commit/97c0e9a2f13ec135de24c7a632656136e80c4b53', 'message': 'Avoid overwriting existing value\n\nWhen doing merge configs, we should avoid overwriting existing value,\nif the new value in the new config is empty, such as [].\n\nChange-Id: I763567667ce5c8d4f30032c9bfde85ee7bda1754\n'}]",0,688317,97c0e9a2f13ec135de24c7a632656136e80c4b53,6,5,1,6484,,,0,"Avoid overwriting existing value

When doing merge configs, we should avoid overwriting existing value,
if the new value in the new config is empty, such as [].

Change-Id: I763567667ce5c8d4f30032c9bfde85ee7bda1754
",git fetch https://review.opendev.org/openstack/os-apply-config refs/changes/17/688317/1 && git format-patch -1 --stdout FETCH_HEAD,"['os_apply_config/tests/test_collect_config.py', 'os_apply_config/collect_config.py']",2,97c0e9a2f13ec135de24c7a632656136e80c4b53,, if not v and k in new_dict: continue,,7,0
openstack%2Fdiskimage-builder~master~Ic5149826f443a29801237a250804660a3bb337b8,openstack/diskimage-builder,master,Ic5149826f443a29801237a250804660a3bb337b8,Blacklist sphinx 2.1.0 (autodoc bug),MERGED,2019-10-09 08:16:08.000000000,2019-10-17 01:17:56.000000000,2019-10-17 01:16:45.000000000,"[{'_account_id': 7118}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 08:16:08.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/diskimage-builder/commit/a871726834ade83c78b07ae0bc1eb48ddf8572e4', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nSee https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details\n\nChange-Id: Ic5149826f443a29801237a250804660a3bb337b8\n'}]",0,687475,a871726834ade83c78b07ae0bc1eb48ddf8572e4,7,2,1,27822,,,0,"Blacklist sphinx 2.1.0 (autodoc bug)

See https://github.com/sphinx-doc/sphinx/issues/6440 for upstream details

Change-Id: Ic5149826f443a29801237a250804660a3bb337b8
",git fetch https://review.opendev.org/openstack/diskimage-builder refs/changes/75/687475/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,a871726834ade83c78b07ae0bc1eb48ddf8572e4,sphinx,"sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD","sphinx!=1.6.6,!=1.6.7,>=1.6.2;python_version>='3.4' # BSD",1,1
openstack%2Fnova-specs~master~Ibbfa7548d00b762fc4971f5ecf9c6f1c7694caae,openstack/nova-specs,master,Ibbfa7548d00b762fc4971f5ecf9c6f1c7694caae,Remove the todo in the migrations spec,MERGED,2019-10-17 00:02:08.000000000,2019-10-17 00:45:13.000000000,2019-10-17 00:43:51.000000000,"[{'_account_id': 6873}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-17 00:02:08.000000000', 'files': ['specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/7147d2d8925e4edd15ec52aebeb33769a98d8164', 'message': 'Remove the todo in the migrations spec\n\nhttps://review.opendev.org/#/c/688042/ has already done the TODO\nmentioned in\nhttps://review.opendev.org/#/c/685857/3/specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst@213\n\nChange-Id: Ibbfa7548d00b762fc4971f5ecf9c6f1c7694caae\n'}]",0,689056,7147d2d8925e4edd15ec52aebeb33769a98d8164,7,3,1,26458,,,0,"Remove the todo in the migrations spec

https://review.opendev.org/#/c/688042/ has already done the TODO
mentioned in
https://review.opendev.org/#/c/685857/3/specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst@213

Change-Id: Ibbfa7548d00b762fc4971f5ecf9c6f1c7694caae
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/56/689056/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst'],1,7147d2d8925e4edd15ec52aebeb33769a98d8164,remove_todo,,.. todo:: Make this Brinh https://review.opendev.org/#/c/685857/3/specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst@213 ,0,2
openstack%2Fnova-specs~master~Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6,openstack/nova-specs,master,Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6,Add 'Feature Liaison' spec process,MERGED,2019-09-30 22:59:12.000000000,2019-10-17 00:04:56.000000000,2019-10-16 14:43:00.000000000,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7166}, {'_account_id': 8556}, {'_account_id': 8864}, {'_account_id': 9708}, {'_account_id': 14070}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2019-09-30 22:59:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/453addd12f6231288a8696e3590390d0f39f7fe2', 'message': 'Add \'Core Liaison\' section to spec template\n\nRequire a spec to be sponsored by a member of the core team.\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- ""Non-core contributors don\'t understand how nova dev culture works""-itis\n- ""Nobody but me cares about my feature"" syndrome\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them"" disorder\n\nIn the current commit, this section is optional in ussuri, but I would\nprefer to amend the existing approved specs to add it, and make it\nrequired immediately.\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 2, 'created': '2019-10-01 14:34:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/4ef48a18450ab5fc17aa595008457c6586132725', 'message': 'Add \'Core Liaison\' section to spec template\n\nRequire a spec to be sponsored by a member of the core team.\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- ""Non-core contributors don\'t understand how nova dev culture works""-itis\n- ""Nobody but me cares about my feature"" syndrome\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them"" disorder\n\nIn the current commit, this section is optional in ussuri, but I would\nprefer to amend the existing approved specs to add it, and make it\nrequired immediately.\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 3, 'created': '2019-10-03 15:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/998c332e19413883e561dc2b28e1777680bcefbf', 'message': 'Add \'Core Liaison\' section to spec template\n\nRequire a spec to be sponsored by a member of the core team.\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- ""Non-core contributors don\'t understand how nova dev culture works""-itis\n- ""Nobody but me cares about my feature"" syndrome\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them"" disorder\n\nThe current commit edits already-approved specs to include the new\nsection. Some are filled in, but some are still TBD. These should be\nedited ASAP via subsequent patches.\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 4, 'created': '2019-10-03 21:19:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/adbb8376b650afd7176563512b9f92aa8449980f', 'message': 'Add \'Core Liaison\' spec process\n\nAdd a mandatory \'Core Liaison\' section to the spec template, requiring\nspecs to be sponsored by an experienced nova developer (not necessarily\nan actual core -- this is explained in the docs).\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- ""Non-core contributors don\'t understand how nova dev culture works""-itis\n- ""Nobody but me cares about my feature"" syndrome\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them"" disorder\n\nThe current commit edits already-approved specs to include the new\nsection.\n\nThe main README is updated with a new section to describe more\nthoroughly what this core liaison thing is. At the same time, since this\nimpacts several aspects of the process, the remainder of the README is\ntweaked and updated accordingly. Of note:\n\n* We\'re now going to make distinct use of the launchpad blueprint\'s\n  ""Definition"" and ""Direction"" fields. As such, we can still decide to\n  defer a blueprint whose spec is merged in the \'approved\' directory.\n  (Which really isn\'t different than what we were doing before; it\'s\n  just that now we can do it for reasons other than ""oops, this didn\'t\n  get finished in time"".)\n* The single-core-approval rule for previously approved specifications\n  is removed [1].\n\n[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 5, 'created': '2019-10-04 14:32:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/2c14e37afb076eb14d3b58c5bae04adfa747193c', 'message': 'Add \'Core Liaison\' spec process\n\nAdd a mandatory \'Core Liaison\' section to the spec template, requiring\nspecs to be sponsored by an experienced nova developer (not necessarily\nan actual core -- this is explained in the docs).\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- Non-core contributors don\'t understand how nova dev culture works\n- ""Nobody but me cares about my feature""\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them?""\n\nThe current commit edits already-approved specs to include the new\nsection.\n\nThe main README is updated with a new section to describe more\nthoroughly what this core liaison thing is. At the same time, since this\nimpacts several aspects of the process, the remainder of the README is\ntweaked and updated accordingly. Of note:\n\n* We\'re now going to make distinct use of the launchpad blueprint\'s\n  ""Definition"" and ""Direction"" fields. As such, we can still decide to\n  defer a blueprint whose spec is merged in the \'approved\' directory.\n  (Which really isn\'t different than what we were doing before; it\'s\n  just that now we can do it for reasons other than ""oops, this didn\'t\n  get finished in time"".)\n* The single-core-approval rule for previously approved specifications\n  is removed [1].\n\n[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 6, 'created': '2019-10-07 19:35:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/249466f04306dd34bbd42c21cf86bd754c9ceb99', 'message': 'Add \'Feature Liaison\' spec process\n\nAdd a mandatory \'Feature Liaison\' section to the spec template,\nrequiring specs to be sponsored by an experienced nova developer (not\nnecessarily an actual core -- this is explained in the docs).\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- Inexperienced contributors don\'t understand how nova dev culture works\n- ""Nobody but me cares about my feature""\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them?""\n\nThe current commit edits already-approved specs to include the new\nsection.\n\nThe main README is updated with a new section to describe more\nthoroughly what this feature liaison thing is. At the same time, since\nthis impacts several aspects of the process, the remainder of the README\nis tweaked and updated accordingly. Of note:\n\n* We\'re now going to make distinct use of the launchpad blueprint\'s\n  ""Definition"" and ""Direction"" fields. As such, we can still decide to\n  defer a blueprint whose spec is merged in the \'approved\' directory.\n  (Which really isn\'t different than what we were doing before; it\'s\n  just that now we can do it for reasons other than ""oops, this didn\'t\n  get finished in time"".)\n* The single-core-approval rule for previously approved specifications\n  is removed [1].\n\n[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 7, 'created': '2019-10-14 16:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/ac72442e689d2e25abf097d4a7c20d711142fc04', 'message': 'Add \'Feature Liaison\' spec process\n\nAdd a mandatory \'Feature Liaison\' section to the spec template,\nrequiring specs to be sponsored by an experienced nova developer (not\nnecessarily an actual core -- this is explained in the docs).\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- Inexperienced contributors don\'t understand how nova dev culture works\n- ""Nobody but me cares about my feature""\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them?""\n\nThe current commit edits already-approved specs to include the new\nsection.\n\nThe main README is updated with a new section to describe more\nthoroughly what this feature liaison thing is. At the same time, since\nthis impacts several aspects of the process, the remainder of the README\nis tweaked and updated accordingly. Of note:\n\n* We\'re now going to make distinct use of the launchpad blueprint\'s\n  ""Definition"" and ""Direction"" fields. As such, we can still decide to\n  defer a blueprint whose spec is merged in the \'approved\' directory.\n  (Which really isn\'t different than what we were doing before; it\'s\n  just that now we can do it for reasons other than ""oops, this didn\'t\n  get finished in time"".)\n* The single-core-approval rule for previously approved specifications\n  is removed [1].\n\n[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}, {'number': 8, 'created': '2019-10-14 16:52:15.000000000', 'files': ['specs/ussuri-template.rst', 'specs/ussuri/approved/cross-cell-resize.rst', 'specs/ussuri/approved/image-precache-support.rst', 'README.rst', 'specs/ussuri/approved/nova-cyborg-interaction.rst', 'specs/ussuri/approved/add-user-id-field-to-the-migrations-table.rst', 'specs/ussuri/approved/openstacksdk-in-nova.rst', 'specs/ussuri/approved/image-metadata-prefiltering.rst', 'specs/ussuri/approved/provider-config-file.rst', 'specs/ussuri/approved/support-move-ops-with-qos-ports-ussuri.rst'], 'web_link': 'https://opendev.org/openstack/nova-specs/commit/a1421755787a6541a322f7add36f987a2920e882', 'message': 'Add \'Feature Liaison\' spec process\n\nAdd a mandatory \'Feature Liaison\' section to the spec template,\nrequiring specs to be sponsored by an experienced nova developer (not\nnecessarily an actual core -- this is explained in the docs).\n\nThis in an effort to mitigate several problems noted in previous\ndevelopment cycles:\n- Inexperienced contributors don\'t understand how nova dev culture works\n- ""Nobody but me cares about my feature""\n- ""Whom should I ask for reviews first, especially if I don\'t even know\n  whether I\'m ready for them?""\n\nThe current commit edits already-approved specs to include the new\nsection.\n\nThe main README is updated with a new section to describe more\nthoroughly what this feature liaison thing is. At the same time, since\nthis impacts several aspects of the process, the remainder of the README\nis tweaked and updated accordingly. Of note:\n\n* We\'re now going to make distinct use of the launchpad blueprint\'s\n  ""Definition"" and ""Direction"" fields. As such, we can still decide to\n  defer a blueprint whose spec is merged in the \'approved\' directory.\n  (Which really isn\'t different than what we were doing before; it\'s\n  just that now we can do it for reasons other than ""oops, this didn\'t\n  get finished in time"".)\n* The single-core-approval rule for previously approved specifications\n  is removed [1].\n\n[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05\n\nChange-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6\n'}]",75,685857,a1421755787a6541a322f7add36f987a2920e882,65,9,8,14070,,,0,"Add 'Feature Liaison' spec process

Add a mandatory 'Feature Liaison' section to the spec template,
requiring specs to be sponsored by an experienced nova developer (not
necessarily an actual core -- this is explained in the docs).

This in an effort to mitigate several problems noted in previous
development cycles:
- Inexperienced contributors don't understand how nova dev culture works
- ""Nobody but me cares about my feature""
- ""Whom should I ask for reviews first, especially if I don't even know
  whether I'm ready for them?""

The current commit edits already-approved specs to include the new
section.

The main README is updated with a new section to describe more
thoroughly what this feature liaison thing is. At the same time, since
this impacts several aspects of the process, the remainder of the README
is tweaked and updated accordingly. Of note:

* We're now going to make distinct use of the launchpad blueprint's
  ""Definition"" and ""Direction"" fields. As such, we can still decide to
  defer a blueprint whose spec is merged in the 'approved' directory.
  (Which really isn't different than what we were doing before; it's
  just that now we can do it for reasons other than ""oops, this didn't
  get finished in time"".)
* The single-core-approval rule for previously approved specifications
  is removed [1].

[1] http://eavesdrop.openstack.org/irclogs/%23openstack-nova/%23openstack-nova.2019-10-03.log.html#t2019-10-03T16:08:05

Change-Id: Ibb3a2990e23aecf3ea7ebc1b47413396b676f2d6
",git fetch https://review.opendev.org/openstack/nova-specs refs/changes/57/685857/1 && git format-patch -1 --stdout FETCH_HEAD,"['specs/ussuri-template.rst', 'tests/test_titles.py']",2,453addd12f6231288a8696e3590390d0f39f7fe2,bp/whose,"OPTIONAL_SUBSECTIONS['ussuri'] = ('Core Liaison',)",,17,0
openstack%2Fpython-octaviaclient~master~Ie82d53605be8df45c173391a9ff5f6c136ad3d49,openstack/python-octaviaclient,master,Ie82d53605be8df45c173391a9ff5f6c136ad3d49,Drop netifaces from requirements.txt,MERGED,2019-09-24 12:44:49.000000000,2019-10-16 23:56:35.000000000,2019-10-16 23:55:35.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-24 12:44:49.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/python-octaviaclient/commit/3f5fec9921ba02d03ad17896217771b0480e639f', 'message': 'Drop netifaces from requirements.txt\n\nIt is not used.\n\nChange-Id: Ie82d53605be8df45c173391a9ff5f6c136ad3d49\n'}]",0,684301,3f5fec9921ba02d03ad17896217771b0480e639f,8,3,1,7102,,,0,"Drop netifaces from requirements.txt

It is not used.

Change-Id: Ie82d53605be8df45c173391a9ff5f6c136ad3d49
",git fetch https://review.opendev.org/openstack/python-octaviaclient refs/changes/01/684301/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,3f5fec9921ba02d03ad17896217771b0480e639f,,,netifaces>=0.10.4 # MIT,0,1
openstack%2Fopenstack-helm-infra~master~Ic008934641540968927f5961783ed45b835e4d34,openstack/openstack-helm-infra,master,Ic008934641540968927f5961783ed45b835e4d34,Gnocchi: Add TLS support for public endpoint,MERGED,2019-07-10 16:33:34.000000000,2019-10-16 23:53:13.000000000,2019-10-16 23:52:07.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 23928}]","[{'number': 1, 'created': '2019-07-10 16:33:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5994f5210c07df7a365a67de10c6c1b434538135', 'message': 'Gnocchi: Add TLS support for public endpoint\n\nThis commit adds the capability for Gnocchi chart to\nsupport TLS on overriden fqdn for public endpoint.\n\nChange-Id: Ic008934641540968927f5961783ed45b835e4d34\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 2, 'created': '2019-08-29 05:45:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b9a1f428ac22aea43d7b82fab8182d15125d07fc', 'message': 'Gnocchi: Add TLS support for public endpoint\n\nThis commit adds the capability for Gnocchi chart to\nsupport TLS on overriden fqdn for public endpoint.\n\nChange-Id: Ic008934641540968927f5961783ed45b835e4d34\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 3, 'created': '2019-10-16 19:20:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/01144ddb39d213c9e5ad26ccc02c4d8d6e5f0784', 'message': 'Gnocchi: Add TLS support for public endpoint\n\nThis commit adds the capability for Gnocchi chart to\nsupport TLS on overriden fqdn for public endpoint.\n\nChange-Id: Ic008934641540968927f5961783ed45b835e4d34\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}, {'number': 4, 'created': '2019-10-16 21:48:19.000000000', 'files': ['gnocchi/values.yaml', 'gnocchi/templates/secret-ingress-tls.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9090278f469b2026be4ba690b9816094e1e89824', 'message': 'Gnocchi: Add TLS support for public endpoint\n\nThis commit adds the capability for Gnocchi chart to\nsupport TLS on overriden fqdn for public endpoint.\n\nChange-Id: Ic008934641540968927f5961783ed45b835e4d34\nSigned-off-by: Angie Wang <angie.wang@windriver.com>\n'}]",0,670123,9090278f469b2026be4ba690b9816094e1e89824,15,5,4,28435,,,0,"Gnocchi: Add TLS support for public endpoint

This commit adds the capability for Gnocchi chart to
support TLS on overriden fqdn for public endpoint.

Change-Id: Ic008934641540968927f5961783ed45b835e4d34
Signed-off-by: Angie Wang <angie.wang@windriver.com>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/23/670123/1 && git format-patch -1 --stdout FETCH_HEAD,"['gnocchi/values.yaml', 'gnocchi/templates/secret-ingress-tls.yaml']",2,5994f5210c07df7a365a67de10c6c1b434538135,,"{{/* Copyright 2019 Wind River Systems, Inc. Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License. */}} {{- if .Values.manifests.secret_ingress_tls }} {{- include ""helm-toolkit.manifests.secret_ingress_tls"" ( dict ""envAll"" . ""backendServiceType"" ""metric"" ) }} {{- end }} ",,31,0
openstack%2Fpython-novaclient~master~I11343ca265ab2b6b6f46877897d8223ef340c258,openstack/python-novaclient,master,I11343ca265ab2b6b6f46877897d8223ef340c258,Microversion 2.80: Add user_id/project_id to migration-list API,MERGED,2019-08-07 04:14:41.000000000,2019-10-16 23:52:34.000000000,2019-10-16 17:59:23.000000000,"[{'_account_id': 679}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2019-08-07 04:14:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fff7cc9e78989c44fb8d0238eb6c0d424f542dd0', 'message': 'Microversion 2.76: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 2, 'created': '2019-08-08 01:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/0ba016f491d9139f4c5eb673ced8e2a4842e30e2', 'message': 'Microversion 2.76: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 3, 'created': '2019-08-08 01:45:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f48a6270525a8f12a0e09ea448048236924193a2', 'message': 'Microversion 2.76: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 4, 'created': '2019-09-09 03:02:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/02f343254ee51f75d092cc678ed45023c5b85717', 'message': 'Microversion 2.81: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 5, 'created': '2019-09-09 03:21:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/24c85ff89355369e3d5116bc5b53b082b3a3f57b', 'message': 'Microversion 2.81: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 6, 'created': '2019-09-09 03:30:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/c584a25ca62835b793c112670ddac19a09e877e5', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 7, 'created': '2019-09-09 05:35:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/14c7103cdc101d8da3e829a64fd8d861191dff2c', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 8, 'created': '2019-09-09 22:20:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/6d8638dcbefa35760be11411e50b38192455bef5', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 9, 'created': '2019-09-10 09:34:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/fae9e7b42bb98f8d6e96db9199af757ce629cc66', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 10, 'created': '2019-09-10 09:38:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/1226c9dbcbabd7a4dca0b9247b0689c54ca49f6a', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 11, 'created': '2019-09-10 09:57:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/2736ec090725107cd632bf208e88393b852205dd', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 12, 'created': '2019-09-10 11:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/608d804dc0a981417edfa46c9344e5acf3b5cdea', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 13, 'created': '2019-10-15 05:57:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/f0ed6b6ae823e9ab9fae0ceffa126204d00cac0e', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nShowing the ``user_id`` and ``project_id`` when using api_version>=2.80\nwith the server-migration-list or server-migration-show APIs.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}, {'number': 14, 'created': '2019-10-16 14:07:54.000000000', 'files': ['novaclient/tests/unit/v2/test_migrations.py', 'novaclient/tests/unit/v2/fakes.py', 'novaclient/v2/shell.py', 'novaclient/__init__.py', 'releasenotes/notes/microversion-v2_80-c2394316f9212865.yaml', 'novaclient/v2/migrations.py', 'doc/source/cli/nova.rst', 'novaclient/tests/unit/v2/test_shell.py'], 'web_link': 'https://opendev.org/openstack/python-novaclient/commit/8744bea0e3ebe5bc4d0d899189bfa0bcdcb0a08f', 'message': 'Microversion 2.80: Add user_id/project_id to migration-list API\n\nAdd ``user_id`` and ``project_id`` to the ``GET /os-migrations``\nAPI, and it can called ``--user-id <user_id>`` and/or\n``--project-id <project_id>`` by ``nova migration-list`` CLI.\n\nShowing the ``user_id`` and ``project_id`` when using api_version>=2.80\nwith the server-migration-list or server-migration-show APIs.\n\nDepends-On: https://review.opendev.org/#/c/674243/\nPart of blueprint add-user-id-field-to-the-migrations-table\n\nChange-Id: I11343ca265ab2b6b6f46877897d8223ef340c258\n'}]",60,675023,8744bea0e3ebe5bc4d0d899189bfa0bcdcb0a08f,43,5,14,26458,,,0,"Microversion 2.80: Add user_id/project_id to migration-list API

Add ``user_id`` and ``project_id`` to the ``GET /os-migrations``
API, and it can called ``--user-id <user_id>`` and/or
``--project-id <project_id>`` by ``nova migration-list`` CLI.

Showing the ``user_id`` and ``project_id`` when using api_version>=2.80
with the server-migration-list or server-migration-show APIs.

Depends-On: https://review.opendev.org/#/c/674243/
Part of blueprint add-user-id-field-to-the-migrations-table

Change-Id: I11343ca265ab2b6b6f46877897d8223ef340c258
",git fetch https://review.opendev.org/openstack/python-novaclient refs/changes/23/675023/13 && git format-patch -1 --stdout FETCH_HEAD,"['novaclient/tests/unit/v2/test_migrations.py', 'novaclient/v2/shell.py', 'novaclient/__init__.py', 'releasenotes/notes/microversion-v2_76-c2394316f9212865.yaml', 'doc/source/cli/nova.rst', 'novaclient/v2/migrations.py', 'novaclient/tests/unit/v2/test_shell.py']",7,fff7cc9e78989c44fb8d0238eb6c0d424f542dd0,bp/add-user-id-field-to-the-migrations-table," def test_migration_list_with_user_id_v276(self): user_id = '13cc0930-d27c-4be0-acc1-4d7c47a3e1f7' self.run_command('migration-list --user-id %s' % user_id, api_version='2.76') self.assert_called('GET', '/os-migrations?user_id=%s' % user_id) def test_migration_list_with_project_id_v276(self): project_id = 'b59c18e5-fa28-4fd3-8498-7c5cb25a1853' self.run_command('migration-list --project-id %s' % project_id, api_version='2.76') self.assert_called('GET', '/os-migrations?project_id=%s' % project_id) def test_migration_list_with_user_and_project_id_v276(self): user_id = '13cc0930-d27c-4be0-acc1-4d7c47a3e1f7' project_id = 'b59c18e5-fa28-4fd3-8498-7c5cb25a1853' self.run_command('migration-list --project-id %(project_id)s ' '--user-id %(user_id)s' % {'user_id': user_id, 'project_id': project_id}, api_version='2.76') self.assert_called('GET', '/os-migrations?project_id=%s&user_id=%s' % (project_id, user_id)) def test_migration_list_with_user_id_pre_v266_not_allowed(self): user_id = '13cc0930-d27c-4be0-acc1-4d7c47a3e1f7' cmd = 'migration-list --user-id %s' % user_id self.assertRaises(SystemExit, self.run_command, cmd, api_version='2.75') def test_migration_list_with_project_id_pre_v266_not_allowed(self): project_id = 'b59c18e5-fa28-4fd3-8498-7c5cb25a1853' cmd = 'migration-list --project-id %s' % project_id self.assertRaises(SystemExit, self.run_command, cmd, api_version='2.75') 75, # There are no version-wrapped shell method changes for this.",,227,4
openstack%2Frequirements~master~Ia92faf4980b6bea02ad6ff990b681fbb3e02c3e9,openstack/requirements,master,Ia92faf4980b6bea02ad6ff990b681fbb3e02c3e9,update constraint for os-traits to new release 1.0.0,MERGED,2019-10-16 18:07:48.000000000,2019-10-16 23:43:31.000000000,2019-10-16 23:42:01.000000000,"[{'_account_id': 14070}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 18:07:48.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/84fd56448352a05851f8fa6090431e4655da7b07', 'message': 'update constraint for os-traits to new release 1.0.0\n\nChange-Id: Ia92faf4980b6bea02ad6ff990b681fbb3e02c3e9\nmeta:version: 1.0.0\nmeta:diff-start: -\nmeta:series: independent\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Eric Fried <openstack@fried.cc>\nmeta:release:Commit: Eric Fried <openstack@fried.cc>\nmeta:release:Change-Id: I7212a8e73a852bf89e6f8fb26edef4b91df8a31b\nmeta:release:Code-Review+1: Stephen Finucane <stephenfin@redhat.com>\nmeta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,688995,84fd56448352a05851f8fa6090431e4655da7b07,8,3,1,11131,,,0,"update constraint for os-traits to new release 1.0.0

Change-Id: Ia92faf4980b6bea02ad6ff990b681fbb3e02c3e9
meta:version: 1.0.0
meta:diff-start: -
meta:series: independent
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Eric Fried <openstack@fried.cc>
meta:release:Commit: Eric Fried <openstack@fried.cc>
meta:release:Change-Id: I7212a8e73a852bf89e6f8fb26edef4b91df8a31b
meta:release:Code-Review+1: Stephen Finucane <stephenfin@redhat.com>
meta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/95/688995/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,84fd56448352a05851f8fa6090431e4655da7b07,new-release,os-traits===1.0.0,os-traits===0.16.0,1,1
openstack%2Fnova~stable%2Ftrain~I285f68c81b0587c6a197d4791b09234a1697f5e7,openstack/nova,stable/train,I285f68c81b0587c6a197d4791b09234a1697f5e7,Fix unit of hw_rng:rate_period,MERGED,2019-10-11 09:03:57.000000000,2019-10-16 23:27:54.000000000,2019-10-16 23:24:45.000000000,"[{'_account_id': 6873}, {'_account_id': 22348}, {'_account_id': 26515}]","[{'number': 1, 'created': '2019-10-11 09:03:57.000000000', 'files': ['doc/source/user/flavors.rst'], 'web_link': 'https://opendev.org/openstack/nova/commit/875826df959bf953609aa66d793793afa5ad618a', 'message': 'Fix unit of hw_rng:rate_period\n\nReplace seconds with milliseconds\nin the description of hw_rng:rate_period.\n\n* https://libvirt.org/formatdomain.html#elementsRng\n\nChange-Id: I285f68c81b0587c6a197d4791b09234a1697f5e7\nCloses-Bug: #1843542\n(cherry picked from commit 976120cb20da46258df87b8fa43ba0f8ee6dc675)\n'}]",0,688083,875826df959bf953609aa66d793793afa5ad618a,11,3,1,7634,,,0,"Fix unit of hw_rng:rate_period

Replace seconds with milliseconds
in the description of hw_rng:rate_period.

* https://libvirt.org/formatdomain.html#elementsRng

Change-Id: I285f68c81b0587c6a197d4791b09234a1697f5e7
Closes-Bug: #1843542
(cherry picked from commit 976120cb20da46258df87b8fa43ba0f8ee6dc675)
",git fetch https://review.opendev.org/openstack/nova refs/changes/83/688083/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/flavors.rst'],1,875826df959bf953609aa66d793793afa5ad618a,bug/1843542, - RATE-PERIOD: (integer) Duration of the read period in milliseconds., - RATE-PERIOD: (integer) Duration of the read period in seconds.,1,1
openstack%2Frequirements~master~I932280e1d4d2e08d704d8e338ba57d6b94d9430b,openstack/requirements,master,I932280e1d4d2e08d704d8e338ba57d6b94d9430b,Updated from generate-constraints,MERGED,2019-10-16 06:16:02.000000000,2019-10-16 23:26:56.000000000,2019-10-16 23:24:41.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 06:16:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/9c801d105b429877acce36df3a579f601a574efa', 'message': 'Updated from generate-constraints\n\nChange-Id: I932280e1d4d2e08d704d8e338ba57d6b94d9430b\n'}, {'number': 2, 'created': '2019-10-16 15:12:10.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/f5da3afc2988c8d508fe2380fe21507414752d16', 'message': 'Updated from generate-constraints\n\nChange-Id: I932280e1d4d2e08d704d8e338ba57d6b94d9430b\n'}]",0,688857,f5da3afc2988c8d508fe2380fe21507414752d16,11,2,2,11131,,,0,"Updated from generate-constraints

Change-Id: I932280e1d4d2e08d704d8e338ba57d6b94d9430b
",git fetch https://review.opendev.org/openstack/requirements refs/changes/57/688857/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,9c801d105b429877acce36df3a579f601a574efa,openstack/requirements/constraints/noclob,amqp===2.5.2boto3===1.9.250tempest===22.1.0salt===2019.2.1botocore===1.12.250wsgi-intercept===1.9.0cffi===1.13.0,amqp===2.5.1boto3===1.9.249tempest===22.0.0salt===2019.2.0botocore===1.12.249wsgi-intercept===1.8.1cffi===1.12.3,7,7
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Id5f7bb2160215170561f39015ddfdb93cba904b5,openstack/tripleo-heat-templates,stable/queens,Id5f7bb2160215170561f39015ddfdb93cba904b5,Add new parameter options to Octavia service,MERGED,2019-09-27 14:23:08.000000000,2019-10-16 23:25:53.000000000,2019-10-16 23:24:28.000000000,"[{'_account_id': 6469}, {'_account_id': 7144}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-27 14:23:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/acad94084eb63aa5f060869f896da58c622e8925', 'message': 'Add new parameter options to Octavia service\n\nThis patch adds three new parameters:\n\n1. OctaviaConnectionMaxRetries\n2. OctaviaBuildActiveRetries\n3. OctaviaPortDetachTimeout\n\nThe default values are same as in octavia and puppet-octavia master\nbranches as of now.\n\nDepends-On: https://review.opendev.org/#/c/682636/\nChange-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5\n(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)\n(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)\n'}, {'number': 2, 'created': '2019-10-12 09:21:55.000000000', 'files': ['puppet/services/octavia-controller.yaml', 'releasenotes/notes/add-three-more-octavia-params-1e4a32f910e5f1fc.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/24f1ac96411c29aab78107cfcdad31d7ec614317', 'message': 'Add new parameter options to Octavia service\n\nThis patch adds three new parameters:\n\n1. OctaviaConnectionMaxRetries\n2. OctaviaBuildActiveRetries\n3. OctaviaPortDetachTimeout\n\nThe default values are same as in octavia and puppet-octavia master\nbranches as of now.\n\nDepends-On: https://review.opendev.org/#/c/682636/\nChange-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5\n(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)\n(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)\n(cherry picked from commit dd3356189ba67bbe01d6a94ae95133e32c0bce86)\n'}]",0,685363,24f1ac96411c29aab78107cfcdad31d7ec614317,16,4,2,6469,,,0,"Add new parameter options to Octavia service

This patch adds three new parameters:

1. OctaviaConnectionMaxRetries
2. OctaviaBuildActiveRetries
3. OctaviaPortDetachTimeout

The default values are same as in octavia and puppet-octavia master
branches as of now.

Depends-On: https://review.opendev.org/#/c/682636/
Change-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5
(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)
(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)
(cherry picked from commit dd3356189ba67bbe01d6a94ae95133e32c0bce86)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/63/685363/1 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/octavia-controller.yaml', 'releasenotes/notes/add-three-more-octavia-params-1e4a32f910e5f1fc.yaml']",2,acad94084eb63aa5f060869f896da58c622e8925,,"--- features: - | Three new parameter options are now added to Octavia service (OctaviaConnectionMaxRetries, OctaviaBuildActiveRetries, OctaviaPortDetachTimeout) ",,21,0
openstack%2Fneutron-tempest-plugin~master~I5b0d03fd0f8068ede749f416bec8d102d02308e7,openstack/neutron-tempest-plugin,master,I5b0d03fd0f8068ede749f416bec8d102d02308e7,Add stadium projects jobs to the gate queue,MERGED,2019-09-27 07:35:56.000000000,2019-10-16 23:24:42.000000000,2019-10-16 23:24:42.000000000,"[{'_account_id': 6547}, {'_account_id': 11975}, {'_account_id': 13252}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 17130}, {'_account_id': 17499}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 28543}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-09-27 07:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/198d0c19c2cbb611e40d63941876516aea52f50a', 'message': 'Remove stadium projects jobs from gate queue\n\nIt should be enough if we will run stadium projects jobs\nin check queue for neutron-tempest-plugin repo.\n\nChange-Id: I5b0d03fd0f8068ede749f416bec8d102d02308e7\n'}, {'number': 2, 'created': '2019-10-02 11:26:21.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/0a48f5149229964397cde769dc629bdf742ef546', 'message': 'Add stadium projects jobs to the gate queue\n\nWe should run stadium projects jobs in gate queue for\nneutron-tempest-plugin repo.\nJob for networking-sfc was missing from gate queue so this\npatch adds it there too.\n\nChange-Id: I5b0d03fd0f8068ede749f416bec8d102d02308e7\n'}]",0,685214,0a48f5149229964397cde769dc629bdf742ef546,40,11,2,11975,,,0,"Add stadium projects jobs to the gate queue

We should run stadium projects jobs in gate queue for
neutron-tempest-plugin repo.
Job for networking-sfc was missing from gate queue so this
patch adds it there too.

Change-Id: I5b0d03fd0f8068ede749f416bec8d102d02308e7
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/14/685214/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,198d0c19c2cbb611e40d63941876516aea52f50a,gating-stadium,, gate: jobs: - neutron-tempest-plugin-bgpvpn-bagpipe - neutron-tempest-plugin-fwaas,0,4
openstack%2Ftripleo-quickstart-extras~master~Ic4aa91f061d9918fa91a69cb4c38eb476521c3d0,openstack/tripleo-quickstart-extras,master,Ic4aa91f061d9918fa91a69cb4c38eb476521c3d0,Set force_periodic to true in periodic job,MERGED,2019-10-16 07:02:12.000000000,2019-10-16 23:24:27.000000000,2019-10-16 23:24:27.000000000,"[{'_account_id': 8175}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 07:02:12.000000000', 'files': ['roles/create-zuul-based-reproducer/templates/launcher-playbook.yaml.j2'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/8b6f71035bfad79dce41fe56e90592a671e179c4', 'message': 'Set force_periodic to true in periodic job\n\nCurrently in zuul based reproducer, for running periodic\njobs, we need to specifically set force_periodic to true\nin the launcher playbook manually. In order to fix that\nwe are enabling it based on job name.\n\nChange-Id: Ic4aa91f061d9918fa91a69cb4c38eb476521c3d0\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",0,688860,8b6f71035bfad79dce41fe56e90592a671e179c4,16,8,1,12393,,,0,"Set force_periodic to true in periodic job

Currently in zuul based reproducer, for running periodic
jobs, we need to specifically set force_periodic to true
in the launcher playbook manually. In order to fix that
we are enabling it based on job name.

Change-Id: Ic4aa91f061d9918fa91a69cb4c38eb476521c3d0
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/60/688860/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/create-zuul-based-reproducer/templates/launcher-playbook.yaml.j2'],1,8b6f71035bfad79dce41fe56e90592a671e179c4,reproducer, {% if 'periodic' in zuul.job -%} force_periodic: true {% endif %},,3,0
openstack%2Fnetworking-ovn~stable%2Fstein~I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8,openstack/networking-ovn,stable/stein,I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8,Disable ip_version checking while updating member without new ip,MERGED,2019-10-08 07:08:01.000000000,2019-10-16 23:14:16.000000000,2019-10-16 23:12:08.000000000,"[{'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-08 07:08:01.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3d1d6e2390e4517df079efcc9e8eb0cc80f4a0ca', 'message': ""Disable ip_version checking while updating member without new ip\n\nIf member gets updated with new data, but without IP version\nwe shouldn't be checking if ip_version differs from the listener.\n\nRelated-Bug: #1843553\n\nChange-Id: I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8\n(cherry picked from commit 7f802007843bc9177d7f6a3081045f444b9e5968)\n""}]",0,687220,3d1d6e2390e4517df079efcc9e8eb0cc80f4a0ca,14,4,1,24791,,,0,"Disable ip_version checking while updating member without new ip

If member gets updated with new data, but without IP version
we shouldn't be checking if ip_version differs from the listener.

Related-Bug: #1843553

Change-Id: I5edfc70efeaa0758373ecfb2fa12f4721c6fb1f8
(cherry picked from commit 7f802007843bc9177d7f6a3081045f444b9e5968)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/20/687220/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py']",2,3d1d6e2390e4517df079efcc9e8eb0cc80f4a0ca,ovn-provider-driver-stein-cherry-picks," @mock.patch.object(ovn_driver.OvnProviderDriver, '_ip_version_differs') def test_member_update_no_ip_addr(self, mock_ip_differs): self.update_member.address = None self.driver.member_update(self.ref_member, self.update_member) mock_ip_differs.assert_not_called() ",,8,2
openstack%2Fnetworking-ovn~stable%2Fstein~I6d4a4b396eaa0d4be2a2c7afeccdb336020a40b3,openstack/networking-ovn,stable/stein,I6d4a4b396eaa0d4be2a2c7afeccdb336020a40b3,Add _find_ovn_lb_by_id() in OvnProviderHelper,MERGED,2019-10-03 10:08:37.000000000,2019-10-16 23:13:20.000000000,2019-10-16 23:12:07.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-03 10:08:37.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/f545f516d5da62e2f1512096bd660af6c10bc615', 'message': 'Add _find_ovn_lb_by_id() in OvnProviderHelper\n\nThere were four code paths doing the same thing, created\na helper to lookup a loadbalancer given a pool id.\n\nChange-Id: I6d4a4b396eaa0d4be2a2c7afeccdb336020a40b3\n'}]",0,686372,f545f516d5da62e2f1512096bd660af6c10bc615,14,4,1,24791,,,0,"Add _find_ovn_lb_by_id() in OvnProviderHelper

There were four code paths doing the same thing, created
a helper to lookup a loadbalancer given a pool id.

Change-Id: I6d4a4b396eaa0d4be2a2c7afeccdb336020a40b3
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/72/686372/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/octavia/ovn_driver.py'],1,f545f516d5da62e2f1512096bd660af6c10bc615,ovn-provider-driver-stein-cherry-picks," def _find_ovn_lb_by_id(self, pool_id): pool_key = self._get_pool_key(pool_id) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(pool_id, is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) return pool_key, ovn_lb pool_key, ovn_lb = self._find_ovn_lb_by_id( member['pool_id']) pool_key, ovn_lb = self._find_ovn_lb_by_id( member['pool_id']) pool_key, ovn_lb = self._find_ovn_lb_by_id( member['pool_id']) pool_key, ovn_lb = self._find_ovn_lb_by_id(pool_id) if not ovn_lb: msg = _(""Loadbalancer with pool %s does not exist"") % pool_key raise driver_exceptions.DriverError(msg) _, ovn_lb = self._ovn_helper._find_ovn_lb_by_id(member.pool_id)"," pool_key = self._get_pool_key(member['pool_id']) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(member['pool_id'], is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) pool_key = self._get_pool_key(member['pool_id']) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(member['pool_id'], is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) pool_key = self._get_pool_key(member['pool_id']) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(member['pool_id'], is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) pool_key = self._get_pool_key(pool_id) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._get_pool_key(pool_id, is_enabled=False) ovn_lb = self._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: msg = _(""Loadbalancer with pool %s does not exist"") % pool_key raise driver_exceptions.DriverError(msg) pool_key = self._ovn_helper._get_pool_key(member.pool_id) ovn_lb = self._ovn_helper._find_ovn_lb_with_pool_key(pool_key) if not ovn_lb: pool_key = self._ovn_helper._get_pool_key(member.pool_id, is_enabled=False) ovn_lb = self._ovn_helper._find_ovn_lb_with_pool_key(pool_key)",18,32
openstack%2Fswift~master~I1bbdcaedd4c645a931ed618594c6511f221fcad4,openstack/swift,master,I1bbdcaedd4c645a931ed618594c6511f221fcad4,use the whichever version of nosetests is installed,NEW,2019-10-15 23:18:12.000000000,2019-10-16 22:42:35.000000000,,"[{'_account_id': 330}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 23:18:12.000000000', 'files': ['tools/playbooks/probetests/run.yaml', '.unittests', '.probetests', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/swift/commit/c3cfcf2e5a1a4e28a09a4f91af109a4796ee5208', 'message': 'use the whichever version of nosetests is installed\n\nChange-Id: I1bbdcaedd4c645a931ed618594c6511f221fcad4\n'}]",4,688834,c3cfcf2e5a1a4e28a09a4f91af109a4796ee5208,5,3,1,330,,,0,"use the whichever version of nosetests is installed

Change-Id: I1bbdcaedd4c645a931ed618594c6511f221fcad4
",git fetch https://review.opendev.org/openstack/swift refs/changes/34/688834/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/playbooks/probetests/run.yaml', '.unittests', '.probetests', 'tox.ini']",4,c3cfcf2e5a1a4e28a09a4f91af109a4796ee5208,noseknows, $(which nosetests || which nosetests3) {posargs:test/unit}, nosetests {posargs:test/unit},7,4
openstack%2Fproject-config~master~I88c28691cd20e23e31060296bb89c44141a056ca,openstack/project-config,master,I88c28691cd20e23e31060296bb89c44141a056ca,Add jgit to gerrit repo list,MERGED,2019-10-16 22:08:02.000000000,2019-10-16 22:41:25.000000000,2019-10-16 22:41:24.000000000,"[{'_account_id': 1}, {'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 22:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/49dcef3f99251ec7b557d03a0bc47eca158b801e', 'message': ""Add jgit to gerrit repo list\n\nFor buidling gerrit from master, we need jgit, since it's a submodule\nin gerrit master now.\n\nChange-Id: I88c28691cd20e23e31060296bb89c44141a056ca\n""}, {'number': 2, 'created': '2019-10-16 22:19:00.000000000', 'files': ['zuul/main.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/ce21e7850069e8fad0bf094f8e79317f09532668', 'message': ""Add jgit to gerrit repo list\n\nFor buidling gerrit from master, we need jgit, since it's a submodule\nin gerrit master now.\n\nChange-Id: I88c28691cd20e23e31060296bb89c44141a056ca\n""}]",0,689053,ce21e7850069e8fad0bf094f8e79317f09532668,11,4,2,2,,,0,"Add jgit to gerrit repo list

For buidling gerrit from master, we need jgit, since it's a submodule
in gerrit master now.

Change-Id: I88c28691cd20e23e31060296bb89c44141a056ca
",git fetch https://review.opendev.org/openstack/project-config refs/changes/53/689053/2 && git format-patch -1 --stdout FETCH_HEAD,['zuul/main.yaml'],1,49dcef3f99251ec7b557d03a0bc47eca158b801e,, - modules/jgit,,1,0
openstack%2Fpuppet-glance~master~I5962e42a8e2b56b987db3ddfa9093b67ec13c821,openstack/puppet-glance,master,I5962e42a8e2b56b987db3ddfa9093b67ec13c821,Update the constraints url,MERGED,2019-09-26 03:41:05.000000000,2019-10-16 22:11:27.000000000,2019-10-16 22:09:52.000000000,"[{'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-09-26 03:41:05.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/809ce20cbc36e55379f19dfb2897a2aba6603453', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I5962e42a8e2b56b987db3ddfa9093b67ec13c821\n'}]",0,684917,809ce20cbc36e55379f19dfb2897a2aba6603453,39,7,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I5962e42a8e2b56b987db3ddfa9093b67ec13c821
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/17/684917/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,809ce20cbc36e55379f19dfb2897a2aba6603453,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fopenstack-ansible-os_heat~stable%2Fstein~I533ab16557cb83e2791dbb7267a97fb0d44e9ba6,openstack/openstack-ansible-os_heat,stable/stein,I533ab16557cb83e2791dbb7267a97fb0d44e9ba6,Fix keystone endpoint for heat servers,MERGED,2019-10-16 10:24:35.000000000,2019-10-16 22:02:54.000000000,2019-10-16 22:01:14.000000000,"[{'_account_id': 22348}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-16 10:24:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/fff33bce6d79a12447bbf148cb4d3a8d8da550c3', 'message': 'Fix keystone endpoint for heat servers\n\nThis patch changes the heat config so that communication between\nthe heat service and the other internal parts of openstack occurs over\nthe internal API endpoint, but a new heat configuration option [1] is set\nwhich ensures that the keystone endpoint written into server configs\npoints to the external API endpoint.\n\nThis should address several long running SSL related failures when self\nsigned certificates are used, and allows heat to work correctly when the\ninternal and external endpoints are on different networks.\n\nChange-Id: I533ab16557cb83e2791dbb7267a97fb0d44e9ba6\nFixes-Bug: 1811086\nFixes-Bug: 1820591\nRelated-Bug: 1824646\nRelated-Bug: 1814909\nDepends-On: https://review.opendev.org/678062\n(cherry picked from commit 288634ce0bf042bed614b3f764753d7b65a7170f)\n'}, {'number': 2, 'created': '2019-10-16 10:25:19.000000000', 'files': ['templates/heat.conf.j2'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_heat/commit/eccb5c13fec9d9efcccb821dbcf0f344cd515eec', 'message': 'Fix keystone endpoint for heat servers\n\nThis patch changes the heat config so that communication between\nthe heat service and the other internal parts of openstack occurs over\nthe internal API endpoint, but a new heat configuration option [1] is set\nwhich ensures that the keystone endpoint written into server configs\npoints to the external API endpoint.\n\nThis should address several long running SSL related failures when self\nsigned certificates are used, and allows heat to work correctly when the\ninternal and external endpoints are on different networks.\n\nChange-Id: I533ab16557cb83e2791dbb7267a97fb0d44e9ba6\nFixes-Bug: 1811086\nFixes-Bug: 1820591\nRelated-Bug: 1824646\nRelated-Bug: 1814909\nDepends-On:  https://review.opendev.org/688894\n(cherry picked from commit 288634ce0bf042bed614b3f764753d7b65a7170f)\n'}]",0,688895,eccb5c13fec9d9efcccb821dbcf0f344cd515eec,9,3,2,25023,,,0,"Fix keystone endpoint for heat servers

This patch changes the heat config so that communication between
the heat service and the other internal parts of openstack occurs over
the internal API endpoint, but a new heat configuration option [1] is set
which ensures that the keystone endpoint written into server configs
points to the external API endpoint.

This should address several long running SSL related failures when self
signed certificates are used, and allows heat to work correctly when the
internal and external endpoints are on different networks.

Change-Id: I533ab16557cb83e2791dbb7267a97fb0d44e9ba6
Fixes-Bug: 1811086
Fixes-Bug: 1820591
Related-Bug: 1824646
Related-Bug: 1814909
Depends-On:  https://review.opendev.org/688894
(cherry picked from commit 288634ce0bf042bed614b3f764753d7b65a7170f)
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_heat refs/changes/95/688895/2 && git format-patch -1 --stdout FETCH_HEAD,['templates/heat.conf.j2'],1,fff33bce6d79a12447bbf148cb4d3a8d8da550c3,bug/1811086-stable/stein,server_keystone_endpoint_type = publicauth_uri = {{ keystone_service_internaluri }}auth_uri = {{ keystone_service_internaluri }}www_authenticate_uri = {{ keystone_service_internaluri }},auth_uri = {{ keystone_service_publicuri }}auth_uri = {{ keystone_service_publicuri }}www_authenticate_uri = {{ keystone_service_publicuri }},4,3
openstack%2Fvitrage~stable%2Ftrain~Iabd9df036fa02598ffa03086d15205482fa565a2,openstack/vitrage,stable/train,Iabd9df036fa02598ffa03086d15205482fa565a2,Fix sampling timestamp format of deduced alarms.,MERGED,2019-10-15 06:18:47.000000000,2019-10-16 21:35:37.000000000,2019-10-16 21:33:43.000000000,"[{'_account_id': 9029}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 06:18:47.000000000', 'files': ['vitrage/evaluator/actions/action_executor.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/29d402c934bbc65090a29f7e2bbcd5f0c5aac58d', 'message': 'Fix sampling timestamp format of deduced alarms.\n\nIt differs from the other entities.\n\nChange-Id: Iabd9df036fa02598ffa03086d15205482fa565a2\n(cherry picked from commit 95106757f366ef6a33e9f40b920f62b51bd81c47)\n'}]",0,688627,29d402c934bbc65090a29f7e2bbcd5f0c5aac58d,30,5,1,19134,,,0,"Fix sampling timestamp format of deduced alarms.

It differs from the other entities.

Change-Id: Iabd9df036fa02598ffa03086d15205482fa565a2
(cherry picked from commit 95106757f366ef6a33e9f40b920f62b51bd81c47)
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/27/688627/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/evaluator/actions/action_executor.py'],1,29d402c934bbc65090a29f7e2bbcd5f0c5aac58d,, event[VProps.VITRAGE_SAMPLE_TIMESTAMP] = datetime_utils.format_utcnow(), event[VProps.VITRAGE_SAMPLE_TIMESTAMP] = str(datetime_utils.utcnow()),1,1
openstack%2Fmanila~master~Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3,openstack/manila,master,Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3,Fix [Unity] verification and convert mgmt ipv6,MERGED,2019-09-24 06:38:57.000000000,2019-10-16 21:34:07.000000000,2019-09-26 16:56:16.000000000,"[{'_account_id': 9003}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 14624}, {'_account_id': 15386}, {'_account_id': 15831}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 29291}, {'_account_id': 29632}]","[{'number': 1, 'created': '2019-09-24 06:38:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/1f07a4e92c17b001ab87ff71ce57a6d089fca306', 'message': 'Fix [Unity] missing verification and convert server management IP in ipv6 format\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\n'}, {'number': 2, 'created': '2019-09-24 06:43:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/9089b23b3414861430e55c4919170c7d9008a125', 'message': 'Fix [Unity] missing verification and convert server management IP in ipv6 format\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\nCloses-bug: #1845135\n'}, {'number': 3, 'created': '2019-09-24 06:56:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/dbbb8a19af274e00deffba6b9d2daf90cd5575f2', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\nCloses-bug: #1845135\n'}, {'number': 4, 'created': '2019-09-24 09:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/ab17f19f7ed1d63740755c07a40418013a43c9f4', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\nCloses-bug: #1845135\n'}, {'number': 5, 'created': '2019-09-24 09:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila/commit/a6760c0e4e91c57c08da8978f9fdc9911b4e7ab4', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\nCloses-bug: #1845135\n'}, {'number': 6, 'created': '2019-09-24 10:17:43.000000000', 'files': ['manila/share/drivers/dell_emc/plugins/unity/connection.py'], 'web_link': 'https://opendev.org/openstack/manila/commit/923edff7264905e54a307e4fdf95273a6548bc29', 'message': 'Fix [Unity] verification and convert mgmt ipv6\n\nThe IPv6 format need change to [ipv6]\n\nChange-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3\nCloses-bug: #1845135\n'}]",0,684195,923edff7264905e54a307e4fdf95273a6548bc29,39,14,6,29291,,,0,"Fix [Unity] verification and convert mgmt ipv6

The IPv6 format need change to [ipv6]

Change-Id: Ic0fd36a4f6f71adbd16b54e074efcd3541ca5cf3
Closes-bug: #1845135
",git fetch https://review.opendev.org/openstack/manila refs/changes/95/684195/3 && git format-patch -1 --stdout FETCH_HEAD,['manila/share/drivers/dell_emc/plugins/unity/connection.py'],1,1f07a4e92c17b001ab87ff71ce57a6d089fca306,, storage_ip = enas_utils.convert_ipv6_format_if_needed(config.emc_nas_server), storage_ip = config.emc_nas_server,1,1
openstack%2Fopenstack-helm~master~I5a7e8197b84bc5f1ad94d5d6a1d0662257404994,openstack/openstack-helm,master,I5a7e8197b84bc5f1ad94d5d6a1d0662257404994,Add horizon ingress override,MERGED,2019-09-27 19:27:36.000000000,2019-10-16 21:22:13.000000000,2019-10-16 21:19:25.000000000,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 17499}, {'_account_id': 17591}, {'_account_id': 18236}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 24780}, {'_account_id': 28614}, {'_account_id': 28618}, {'_account_id': 28849}, {'_account_id': 28935}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-09-27 19:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3de725a24b4d518192fe7ae6ad8ea30dc951d4ff', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2019-09-28 00:21:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/60f765314f3f0255d515beb8066c3b50cacc33cd', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2019-09-28 02:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/365efc21c86d0e6f8d7cc5e9bbb55898fc14d1ac', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 4, 'created': '2019-09-28 05:33:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8e03d486c6c9d9f0c0b54740e2bfbe72ea4f784a', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 5, 'created': '2019-09-29 02:49:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/0521a5aa4b52a52b6f55d666aba17b3efb72dc91', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 6, 'created': '2019-09-30 15:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/8430711fafd1c00887f0a3d9d9824d5956ec2224', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 7, 'created': '2019-09-30 22:10:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/59c3df4ea2f38980c731d0808290c87d47a97399', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 8, 'created': '2019-10-01 01:20:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/3dec6153b0a22e73fdcfeb1d8b3b953e93d4c671', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 9, 'created': '2019-10-08 13:29:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/10a607fc853376063af1768e0bce6c4dd6c740b3', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 10, 'created': '2019-10-14 16:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/5a8c45f331e33b4a14a8e121cac43ae8f95f7cc8', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 11, 'created': '2019-10-15 20:34:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1bd816d772e0a0fe0cf1cb589c438e8499efc1ab', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 12, 'created': '2019-10-16 02:46:28.000000000', 'files': ['horizon/values_overrides/netpol.yaml', 'tools/deployment/common/test-networkpolicy.sh', 'zuul.d/jobs-openstack-helm.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/feb97a2dc3842f16ed4fb418ab5e788228b2a638', 'message': 'Add horizon ingress override\n\nThis patch set adds in default horizon ingress overrides.\n\nChange-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",2,685467,feb97a2dc3842f16ed4fb418ab5e788228b2a638,58,19,12,20466,,,0,"Add horizon ingress override

This patch set adds in default horizon ingress overrides.

Change-Id: I5a7e8197b84bc5f1ad94d5d6a1d0662257404994
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/67/685467/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/common/test-networkpolicy.sh', 'horizon/values.yaml']",2,3de725a24b4d518192fe7ae6ad8ea30dc951d4ff,netpol, - from: - podSelector: matchLabels: application: horizon - from: - podSelector: matchLabels: application: ingress ports: - port: 80 protocol: TCP - port: 443 protocol: TCP, - {},16,1
openstack%2Fopenstack-helm-addons~master~Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801,openstack/openstack-helm-addons,master,Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801,Fix indent,MERGED,2019-06-18 06:59:04.000000000,2019-10-16 21:18:33.000000000,2019-10-16 21:18:33.000000000,"[{'_account_id': 8749}, {'_account_id': 8898}, {'_account_id': 14525}, {'_account_id': 17499}, {'_account_id': 21420}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26297}, {'_account_id': 28543}, {'_account_id': 28614}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-06-18 06:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/b1551017cf27d778ad780ae1c66da6b85e771846', 'message': 'Fix indent\n\nPatch set to fix indentation problems in YAMLs after running yamllint\nfor the OpenStack-Helm-Addons project.\n\nTrivial fix\n\nChange-Id: Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 2, 'created': '2019-07-26 13:45:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/3a18be2ee386c804fcfc37b58bff3738bf8a690d', 'message': 'Fix indent\n\nPatch set to fix indentation problems in YAMLs after running yamllint\nfor the OpenStack-Helm-Addons project.\n\nTrivial fix\n\nChange-Id: Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}, {'number': 3, 'created': '2019-09-08 02:05:47.000000000', 'files': ['monasca/values.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/08c0d0819254b7291dfbb4fa68cf4b0810b4bef1', 'message': 'Fix indent\n\nPatch set to fix indentation problems in YAMLs after running yamllint\nfor the OpenStack-Helm-Addons project.\n\nTrivial fix\n\nChange-Id: Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801\nSigned-off-by: Tin Lam <tin@irrational.io>\n'}]",0,665888,08c0d0819254b7291dfbb4fa68cf4b0810b4bef1,21,12,3,20466,,,0,"Fix indent

Patch set to fix indentation problems in YAMLs after running yamllint
for the OpenStack-Helm-Addons project.

Trivial fix

Change-Id: Iaf2f1bfa70af95b86d2a7a6768d15d14f4a66801
Signed-off-by: Tin Lam <tin@irrational.io>
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/88/665888/3 && git format-patch -1 --stdout FETCH_HEAD,['monasca/values.yaml'],1,b1551017cf27d778ad780ae1c66da6b85e771846,fix/indent, definitions.yml.j2: | aggregation-specifications.yaml: |, definitions.yml.j2: | aggregation-specifications.yaml: |,2,2
openstack%2Fovsdbapp~stable%2Fqueens~Ic820ab3978a3b58a41762e6fca034f62d51a0243,openstack/ovsdbapp,stable/queens,Ic820ab3978a3b58a41762e6fca034f62d51a0243,Expand retry behavior to cover other python-ovs methods,MERGED,2019-10-08 17:30:27.000000000,2019-10-16 21:13:48.000000000,2019-10-16 21:13:48.000000000,"[{'_account_id': 5756}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-08 17:30:27.000000000', 'files': ['ovsdbapp/backend/ovs_idl/connection.py'], 'web_link': 'https://opendev.org/openstack/ovsdbapp/commit/f8776cfc9ef9a72be3b23c10e6afc47e1b4862fb', 'message': 'Expand retry behavior to cover other python-ovs methods\n\nIf there is a disconnect, it is possible that we could throw an\nexception if we call wait() while the stream is currently set to\nNone. Move the try: earlier so that if something weird happens, we\nat least retry before raising.\n\nChange-Id: Ic820ab3978a3b58a41762e6fca034f62d51a0243\n(cherry picked from commit 46e4323bed91b6b5eb2779ec62754d9486237590)\n'}]",0,687364,f8776cfc9ef9a72be3b23c10e6afc47e1b4862fb,8,2,1,5756,,,0,"Expand retry behavior to cover other python-ovs methods

If there is a disconnect, it is possible that we could throw an
exception if we call wait() while the stream is currently set to
None. Move the try: earlier so that if something weird happens, we
at least retry before raising.

Change-Id: Ic820ab3978a3b58a41762e6fca034f62d51a0243
(cherry picked from commit 46e4323bed91b6b5eb2779ec62754d9486237590)
",git fetch https://review.opendev.org/openstack/ovsdbapp refs/changes/64/687364/1 && git format-patch -1 --stdout FETCH_HEAD,['ovsdbapp/backend/ovs_idl/connection.py'],1,f8776cfc9ef9a72be3b23c10e6afc47e1b4862fb,," # If we fail in an Idl call, we could have missed an update self.idl.wait(self.poller) self.poller.fd_wait(self.txns.alert_fileno, poller.POLLIN) # TODO(jlibosva): Remove next line once losing connection to # ovsdb is solved. self.poller.timer_wait(self.timeout * 1000) self.poller.block()"," self.idl.wait(self.poller) self.poller.fd_wait(self.txns.alert_fileno, poller.POLLIN) # TODO(jlibosva): Remove next line once losing connection to ovsdb # is solved. self.poller.timer_wait(self.timeout * 1000) self.poller.block() # If we fail on a run() call, we could have missed an update",7,7
openstack%2Fcharm-guide~master~I9f05175038a56cac394f2b41324a148479061b95,openstack/charm-guide,master,I9f05175038a56cac394f2b41324a148479061b95,Add known issue 1790904 to release notes,MERGED,2019-10-16 20:49:15.000000000,2019-10-16 21:05:35.000000000,2019-10-16 21:04:16.000000000,"[{'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 20:49:15.000000000', 'files': ['doc/source/1910.rst'], 'web_link': 'https://opendev.org/openstack/charm-guide/commit/b1f6f7069fe031a3b736d3b480a837c989c498a1', 'message': 'Add known issue 1790904 to release notes\n\nChange-Id: I9f05175038a56cac394f2b41324a148479061b95\n'}]",0,689040,b1f6f7069fe031a3b736d3b480a837c989c498a1,7,2,1,30561,,,0,"Add known issue 1790904 to release notes

Change-Id: I9f05175038a56cac394f2b41324a148479061b95
",git fetch https://review.opendev.org/openstack/charm-guide refs/changes/40/689040/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/1910.rst'],1,b1f6f7069fe031a3b736d3b480a837c989c498a1,release-notes-1910-known-issue-1846070,"default. The 19.10 release ""flips the switch"" and enables this option byGlance Simplestreams Sync ~~~~~~~~~~~~~~~~~~~~~~~~~ When deploying the glance-simplestreams-sync charm on Bionic use `source=ppa:simplestreams-dev/trunk`. See bug `1790904 <https://bugs.launchpad.net/simplestreams/+bug/1790904>`. ","default. The 19.10 release ""flips the swtich"" and enables this option by",8,1
openstack%2Fansible-role-python_venv_build~master~Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e,openstack/ansible-role-python_venv_build,master,Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e,PDF Documentation Build tox target,MERGED,2019-10-15 19:39:08.000000000,2019-10-16 21:00:50.000000000,2019-10-16 20:59:02.000000000,"[{'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-10-15 19:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/b1e35cee1fc01e7c5a41b54d3c6e3082bdc6602f', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-16 09:18:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/0bc85f387a9c61030c16cc4e007550023927d83d', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-16 10:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/a2dd974d05a5b9560a776f50432b23fbb260fac7', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 4, 'created': '2019-10-16 11:25:03.000000000', 'files': ['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-role-python_venv_build/commit/8e13d0d0144cd5ad45b2ac4cd8381174be435d82', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}]",0,688795,8e13d0d0144cd5ad45b2ac4cd8381174be435d82,14,3,4,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e
Story: 2006105
",git fetch https://review.opendev.org/openstack/ansible-role-python_venv_build refs/changes/95/688795/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",4,b1e35cee1fc01e7c5a41b54d3c6e3082bdc6602f,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,4
openstack%2Fansible-config_template~master~Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e,openstack/ansible-config_template,master,Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e,PDF Documentation Build tox target,MERGED,2019-10-15 16:38:50.000000000,2019-10-16 20:54:40.000000000,2019-10-16 20:53:34.000000000,"[{'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-10-15 16:38:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/03b518032063d3f5559de0435dd23772809d8129', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-15 19:11:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/e390b9ecb83ed004707f505955b8055881b3d00c', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-15 19:37:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/d3772f393ed642eb0a0db467f36a9d9767be38f7', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 4, 'created': '2019-10-15 19:44:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/21c8ce1768a4391f3bd01b8ab6883e9d02da887d', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}, {'number': 5, 'created': '2019-10-15 20:29:15.000000000', 'files': ['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ansible-config_template/commit/faf60ddb53dd3d345ea3644f818805a3d356b104', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e\nStory: 2006105\n'}]",0,688753,faf60ddb53dd3d345ea3644f818805a3d356b104,15,3,5,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Ib0fc3cabe19771c3f569d22c8b09aa456f4caf6e
Story: 2006105
",git fetch https://review.opendev.org/openstack/ansible-config_template refs/changes/53/688753/3 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",3,03b518032063d3f5559de0435dd23772809d8129,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,31,25
openstack%2Ftraining-guides~master~Ib0cd022bf4b84d33ecc12a26154084d0be965e16,openstack/training-guides,master,Ib0cd022bf4b84d33ecc12a26154084d0be965e16,Reorder irc exercises,MERGED,2019-10-15 18:36:08.000000000,2019-10-16 20:50:28.000000000,2019-10-16 20:46:29.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 18:36:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/b17459085553081324d02f5e611c0598527898fc', 'message': 'Reorder irc exercises\n\nGiven the information being discovered in the exercises, I reordered\nthem to make the flow of discovery more logical.\n\nChange-Id: Ib0cd022bf4b84d33ecc12a26154084d0be965e16\n'}, {'number': 2, 'created': '2019-10-16 19:40:35.000000000', 'files': ['doc/upstream-training/source/slides/howitsmade-irc.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2ced4425e8c16a894943700e48f1fd0b7b4329aa', 'message': 'Reorder irc exercises\n\nGiven the information being discovered in the exercises, I reordered\nthem to make the flow of discovery more logical.\n\nChange-Id: Ib0cd022bf4b84d33ecc12a26154084d0be965e16\n'}]",1,688780,2ced4425e8c16a894943700e48f1fd0b7b4329aa,13,3,2,16708,,,0,"Reorder irc exercises

Given the information being discovered in the exercises, I reordered
them to make the flow of discovery more logical.

Change-Id: Ib0cd022bf4b84d33ecc12a26154084d0be965e16
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/80/688780/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/howitsmade-irc.rst'],1,b17459085553081324d02f5e611c0598527898fc,irc_exercises,* Where can you find a list of all of the OpenStack irc channels?* Find the logs from the most recent meeting * Who spoke the most during that meeting?,* Find the logs from the most recent meeting * Who spoke the most during that meeting?* Where can you find a list of all of the OpenStack irc channels? ,3,4
openstack%2Fopenstack-ansible-galera_client~master~Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12,openstack/openstack-ansible-galera_client,master,Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12,PDF Documentation Build tox target,MERGED,2019-10-15 20:01:24.000000000,2019-10-16 20:40:22.000000000,2019-10-16 20:39:07.000000000,"[{'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-10-15 20:01:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/560f0acb843f4c02407006587ad69f2b5018e343', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12\nStory: 2006105\n'}, {'number': 2, 'created': '2019-10-15 20:25:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/0e1a3d7d26fd0c0e2b5e4fbd98726e2d44d5fa90', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12\nStory: 2006105\n'}, {'number': 3, 'created': '2019-10-16 11:15:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/21462bec276ad20d5ccbd85a93735a58aef42324', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12\nStory: 2006105\n'}, {'number': 4, 'created': '2019-10-16 11:26:50.000000000', 'files': ['doc/source/_static/ .gitkeep', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-galera_client/commit/fda14fbe36830f1cafe352f800fa56b19842e56a', 'message': 'PDF Documentation Build tox target\n\nThis patch adds a `pdf-docs` tox target that will build\nPDF versions of our docs. As per the Train community goal:\n\n  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html\n\nAdd sphinxcontrib-svg2pdfconverter to doc/requirements.txt\nto convert our SVGs.\n\nChange-Id: Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12\nStory: 2006105\n'}]",0,688806,fda14fbe36830f1cafe352f800fa56b19842e56a,12,3,4,28619,,,0,"PDF Documentation Build tox target

This patch adds a `pdf-docs` tox target that will build
PDF versions of our docs. As per the Train community goal:

  https://governance.openstack.org/tc/goals/selected/train/pdf-doc-generation.html

Add sphinxcontrib-svg2pdfconverter to doc/requirements.txt
to convert our SVGs.

Change-Id: Ibed28b9dafee3bbba3dd7a2895f849ad2dde2f12
Story: 2006105
",git fetch https://review.opendev.org/openstack/openstack-ansible-galera_client refs/changes/06/688806/2 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",3,560f0acb843f4c02407006587ad69f2b5018e343,build-pdf-docs,commands =[testenv:pdf-docs] basepython = python3 deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,commands=,26,4
openstack%2Fopenstack-ansible~master~I760de564a352c73f3483f7606458c733a8cfbfaf,openstack/openstack-ansible,master,I760de564a352c73f3483f7606458c733a8cfbfaf,OpeStack replaces with OpenStack in line 441.,ABANDONED,2019-09-25 02:34:21.000000000,2019-10-16 20:27:56.000000000,,"[{'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-09-25 02:34:21.000000000', 'files': ['doc/source/locale/ru/LC_MESSAGES/doc-user.po'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/1af274e47a7b7bce8a378173e41be610c2991888', 'message': 'OpeStack replaces with OpenStack in line 441.\n\nChange-Id: I760de564a352c73f3483f7606458c733a8cfbfaf\n'}]",0,684445,1af274e47a7b7bce8a378173e41be610c2991888,6,4,1,30717,,,0,"OpeStack replaces with OpenStack in line 441.

Change-Id: I760de564a352c73f3483f7606458c733a8cfbfaf
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/45/684445/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/locale/ru/LC_MESSAGES/doc-user.po'],1,1af274e47a7b7bce8a378173e41be610c2991888,,"""SELinux на данный момент не поддерживается в OpenStack Ansible для CentOS/""","""SELinux на данный момент не поддерживается в OpeStack Ansible для CentOS/""",1,1
openstack%2Fopenstack-zuul-jobs~master~I8d4f7733fcba75a89d769bac60de00c9adc27cff,openstack/openstack-zuul-jobs,master,I8d4f7733fcba75a89d769bac60de00c9adc27cff,Remove legacy-puppet-syntax-centos job,MERGED,2019-10-15 09:48:35.000000000,2019-10-16 20:25:47.000000000,2019-10-16 20:22:22.000000000,"[{'_account_id': 1004}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 09:48:35.000000000', 'files': ['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/puppet-syntax-4-centos-7/run.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/face1af75f1ae804576345888bea80cf48ec4a5a', 'message': 'Remove legacy-puppet-syntax-centos job\n\nThis job is now unused, remove it.\n\nDepends-On: https://review.opendev.org/688664\nChange-Id: I8d4f7733fcba75a89d769bac60de00c9adc27cff\n'}]",0,688666,face1af75f1ae804576345888bea80cf48ec4a5a,10,4,1,6547,,,0,"Remove legacy-puppet-syntax-centos job

This job is now unused, remove it.

Depends-On: https://review.opendev.org/688664
Change-Id: I8d4f7733fcba75a89d769bac60de00c9adc27cff
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/66/688666/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/zuul-legacy-jobs.yaml', 'playbooks/legacy/puppet-syntax-4-centos-7/run.yaml']",2,face1af75f1ae804576345888bea80cf48ec4a5a,infra-centos-7,,"- hosts: all name: Autoconverted job legacy-puppet-syntax-4-centos-7 from old job gate-{name}-puppet-syntax-4-centos-7 roles: - bindep tasks: - name: Ensure legacy workspace directory file: path: '{{ ansible_user_dir }}/workspace' state: directory - shell: cmd: | set -e set -x CLONEMAP=`mktemp` function cleanup { # In cases where zuul-cloner is aborted during a git # clone operation, git will remove the git work tree in # its cleanup. The work tree in these jobs is the # workspace directory, which means that subsequent # jenkins post-build actions can not run because the # workspace has been removed. # To reduce the likelihood of this having an impact, # recreate the workspace directory if needed mkdir -p $WORKSPACE rm -f $CLONEMAP } trap cleanup EXIT cat > $CLONEMAP << EOF clonemap: - name: $ZUUL_PROJECT dest: . EOF /usr/zuul-env/bin/zuul-cloner -m $CLONEMAP --cache-dir /opt/git \ https://opendev.org $ZUUL_PROJECT executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -e set -x if [ -f /usr/bin/yum ]; then sudo yum -y remove rdo-release ""centos-release-openstack-*"" ""centos-release-ceph-*"" sudo yum -y install libxml2-devel libxslt-devel ruby-devel zlib-devel sudo yum -y groupinstall ""Development Tools"" # Uninstall python-requests from pip, since we install it in # system-config/install_puppet.sh sudo pip uninstall requests -y || true elif [ -f /usr/bin/apt-get ]; then sudo apt-get update sudo apt-get install -y libxml2-dev libxslt-dev ruby-dev zlib1g-dev fi executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | set -x sudo rm -f /etc/sudoers.d/zuul # Prove that general sudo access is actually revoked ! sudo -n true executable: /bin/bash chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' - shell: cmd: | export PUPPET_GEM_VERSION='~> 4' mkdir .bundled_gems export GEM_HOME=`pwd`/.bundled_gems gem install bundler --no-rdoc --no-ri --verbose --version '<2.0.0' $GEM_HOME/bin/bundle install --retry 3 # FUTURE_PARSER=yes is only supported by Puppet 3.x if [ ""4"" -lt ""4"" ]; then export FUTURE_PARSER=yes fi $GEM_HOME/bin/bundle exec rake syntax chdir: '{{ ansible_user_dir }}/workspace' environment: '{{ zuul | zuul_legacy_vars }}' ",0,91
openstack%2Fcharm-keystone-saml-mellon~master~I1099edb7df4eaaa2b3674f99902df6862bdc99c0,openstack/charm-keystone-saml-mellon,master,I1099edb7df4eaaa2b3674f99902df6862bdc99c0,"Sync charm/ceph helpers, tox, and requirements",MERGED,2019-09-30 22:08:29.000000000,2019-10-16 20:18:39.000000000,2019-10-16 20:18:38.000000000,"[{'_account_id': 12549}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-30 22:08:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/2ee51fd58bb3a09355c181d1d3b1176af25ad087', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nChange-Id: I1099edb7df4eaaa2b3674f99902df6862bdc99c0\n'}, {'number': 2, 'created': '2019-10-01 01:59:19.000000000', 'files': ['src/files/.gitkeep', 'requirements.txt', 'test-requirements.txt', 'src/tox.ini', 'src/test-requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-keystone-saml-mellon/commit/0947cb7f86be39943ded95eb203361012d6424db', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nChange-Id: I1099edb7df4eaaa2b3674f99902df6862bdc99c0\n'}]",0,685833,0947cb7f86be39943ded95eb203361012d6424db,26,5,2,20635,,,0,"Sync charm/ceph helpers, tox, and requirements

Change-Id: I1099edb7df4eaaa2b3674f99902df6862bdc99c0
",git fetch https://review.opendev.org/openstack/charm-keystone-saml-mellon refs/changes/33/685833/2 && git format-patch -1 --stdout FETCH_HEAD,"['requirements.txt', 'src/files/.gitkeep', 'test-requirements.txt', 'src/tox.ini', 'src/test-requirements.txt', 'tox.ini']",6,2ee51fd58bb3a09355c181d1d3b1176af25ad087,batch-update,"# within individual charm repos. See the 'global' dir contents for available # choices of tox.ini for OpenStack Charms: # https://github.com/openstack-charmers/release-tools # NOTE: Avoid build/test env pollution by not enabling sitepackages. sitepackages = False # NOTE: Avoid false positives by not skipping missing interpreters. skip_missing_interpreters = False LAYER_PATH={toxinidir}/layers INTERFACE_PATH={toxinidir}/interfacespassenv = http_proxy https_proxy INTERFACE_PATH LAYER_PATH JUJU_REPOSITORYcommands = stestr run --slowest {posargs}commands = stestr run --slowest {posargs}commands = stestr run --slowest {posargs}commands = stestr run --slowest {posargs}[testenv:cover] # Technique based heavily upon # https://github.com/openstack/nova/blob/master/tox.ini basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt setenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run --slowest {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report [coverage:run] branch = True concurrency = multiprocessing parallel = True source = . omit = .tox/* */charmhelpers/* unit_tests/* ignore = E402,W504",# within individual charm repos.passenv = http_proxy https_proxy INTERFACE_PATH LAYER_PATHcommands = stestr run {posargs}commands = stestr run {posargs}commands = stestr run {posargs}commands = stestr run {posargs}ignore = E402,93,34
openstack%2Foctavia-dashboard~master~I1290f1caa6d3098729c314ce17a0d0435e91ed99,openstack/octavia-dashboard,master,I1290f1caa6d3098729c314ce17a0d0435e91ed99,Update master for stable/train,MERGED,2019-09-26 19:52:08.000000000,2019-10-16 19:42:43.000000000,2019-10-16 19:41:07.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-26 19:52:08.000000000', 'files': ['releasenotes/source/train.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/octavia-dashboard/commit/0b1e89e2645297aa50d963b94f88efa67e1366c2', 'message': 'Update master for stable/train\n\nAdd file to the reno documentation build to show release notes for\nstable/train.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/train.\n\nChange-Id: I1290f1caa6d3098729c314ce17a0d0435e91ed99\nSem-Ver: feature\n'}]",0,685162,0b1e89e2645297aa50d963b94f88efa67e1366c2,8,3,1,22816,,,0,"Update master for stable/train

Add file to the reno documentation build to show release notes for
stable/train.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/train.

Change-Id: I1290f1caa6d3098729c314ce17a0d0435e91ed99
Sem-Ver: feature
",git fetch https://review.opendev.org/openstack/octavia-dashboard refs/changes/62/685162/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/train.rst', 'releasenotes/source/index.rst']",2,0b1e89e2645297aa50d963b94f88efa67e1366c2,reno-train, train,,7,0
openstack%2Fopenstack-helm-images~master~Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5,openstack/openstack-helm-images,master,Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5,(minimirror) Create Bionic based minimirror image,MERGED,2019-10-03 19:50:11.000000000,2019-10-16 19:32:21.000000000,2019-10-16 19:28:22.000000000,"[{'_account_id': 8898}, {'_account_id': 17499}, {'_account_id': 20466}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 26449}, {'_account_id': 26628}, {'_account_id': 27715}, {'_account_id': 28543}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-10-03 19:50:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/047b5a0cf7958efa2a9d2adb4e79060bb37a31f7', 'message': ""(minimirror) Create Bionic based minimirror image\n\n- aptly v0.9.7 switched to SHA256 package signatures, required\n  by 18.04 for trust. 18.04 uses aptly 1.2.x.\n\n- Remove dead code from Makefile that duplicated the build block\n  for 'ubuntu_bionic'\n\nChange-Id: Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5\n""}, {'number': 2, 'created': '2019-10-03 21:25:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/9c48612018527271b7972bddd4d696df438ad027', 'message': ""(minimirror) Create Bionic based minimirror image\n\n- aptly v0.9.7 switched to SHA256 package signatures, required\n  by 18.04 for trust. 18.04 uses aptly 1.2.x.\n\n- Remove dead code from Makefile that duplicated the build block\n  for 'ubuntu_bionic'\n\nChange-Id: Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5\n""}, {'number': 3, 'created': '2019-10-04 14:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/4eb7911f4bc500db8ae39aa715002729bd72a4d8', 'message': ""(minimirror) Create Bionic based minimirror image\n\n- aptly v0.9.7 switched to SHA256 package signatures, required\n  by 18.04 for trust. 18.04 uses aptly 1.2.x.\n\n- Remove dead code from Makefile that duplicated the build block\n  for 'ubuntu_bionic'\n\nChange-Id: Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5\n""}, {'number': 4, 'created': '2019-10-04 15:13:47.000000000', 'files': ['zuul.d/mini-mirror.yaml', 'Makefile', 'mini-mirror/Dockerfile.ubuntu_bionic'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/37f0185f6596661b225582e5761bac49b0e07b12', 'message': ""(minimirror) Create Bionic based minimirror image\n\n- aptly v0.9.7 switched to SHA256 package signatures, required\n  by 18.04 for trust. 18.04 uses aptly 1.2.x.\n\n- Remove dead code from Makefile that duplicated the build block\n  for 'ubuntu_bionic'\n\nChange-Id: Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5\n""}]",1,686475,37f0185f6596661b225582e5761bac49b0e07b12,25,11,4,26449,,,0,"(minimirror) Create Bionic based minimirror image

- aptly v0.9.7 switched to SHA256 package signatures, required
  by 18.04 for trust. 18.04 uses aptly 1.2.x.

- Remove dead code from Makefile that duplicated the build block
  for 'ubuntu_bionic'

Change-Id: Ib6290beac8110cc9b21fcaab6cfbdb331c3bb8c5
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/75/686475/1 && git format-patch -1 --stdout FETCH_HEAD,"['Makefile', 'mini-mirror/Dockerfile.ubuntu_bionic']",2,047b5a0cf7958efa2a9d2adb4e79060bb37a31f7,aptly-sha256,"# Copyright 2019, AT&T Intellectual Property # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. FROM ubuntu:18.04 as aptly ARG APTLY_CONFIG_PATH=etc/aptly.conf ARG MIRROR_SOURCE_DIR=sources ARG RELEASE_SIGN_KEY_PATH=etc ARG RELEASE_SIGN_KEY_PASSPHRASE COPY ""${APTLY_CONFIG_PATH}"" /etc/aptly.conf COPY ""${MIRROR_SOURCE_DIR}"" /opt/sources COPY ""${RELEASE_SIGN_KEY_PATH}"" /opt/release.gpg COPY tools/publish_snapshots.sh /opt/publish_snapshots.sh RUN apt-get update RUN apt-get install -y aptly wget RUN /opt/publish_snapshots.sh ""${RELEASE_SIGN_KEY_PASSPHRASE}"" FROM nginx ARG APTLY_SNAPSHOT_DIR=/srv # NOTE(drewwalters96): This must match the location provided in the NGINX # config file. COPY --from=aptly /opt/.aptly/public ""${APTLY_SNAPSHOT_DIR}"" ",,39,6
openstack%2Fopenstack-helm-infra~master~I6d539493a7388b250688dba780ff9351d99ad732,openstack/openstack-helm-infra,master,I6d539493a7388b250688dba780ff9351d99ad732,Blacklist sphinx 2.1.0 (autodoc bug),MERGED,2019-10-10 06:12:14.000000000,2019-10-16 19:27:29.000000000,2019-10-16 19:25:43.000000000,"[{'_account_id': 8898}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-10-10 06:12:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/defd25db1d99893589e1320742a491b65fd1969f', 'message': 'Sync Sphinx requirement\n\nSync sphinx dependency with global requirements. It caps python 2 since\nsphinx 2.0 no longer supports Python 2.7.\n\nChange-Id: I6d539493a7388b250688dba780ff9351d99ad732\n'}, {'number': 2, 'created': '2019-10-10 07:47:33.000000000', 'files': ['doc/requirements.txt'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/a9bebfce581939da2bc922d440a1bd5732b52deb', 'message': 'Blacklist sphinx 2.1.0 (autodoc bug)\n\nChange-Id: I6d539493a7388b250688dba780ff9351d99ad732\n'}]",1,687780,a9bebfce581939da2bc922d440a1bd5732b52deb,12,4,2,27822,,,0,"Blacklist sphinx 2.1.0 (autodoc bug)

Change-Id: I6d539493a7388b250688dba780ff9351d99ad732
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/80/687780/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/requirements.txt'],1,defd25db1d99893589e1320742a491b65fd1969f,sphinx,"sphinx!=1.6.6,!=1.6.7,>=1.6.2,<2.0.0;python_version=='2.7' # BSD sphinx!=1.6.6,!=1.6.7,!=2.1.0,>=1.6.2;python_version>='3.4' # BSD",sphinx>=1.6.2 # BSD,2,1
openstack%2Fopenstack-helm-infra~master~If5a62650c5679674dfe44bab2c50301d9386d947,openstack/openstack-helm-infra,master,If5a62650c5679674dfe44bab2c50301d9386d947,Gate: Fix Openstack support job,ABANDONED,2019-06-25 23:35:36.000000000,2019-10-16 19:21:48.000000000,,"[{'_account_id': 8749}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 28618}, {'_account_id': 28849}]","[{'number': 1, 'created': '2019-06-25 23:35:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/af54a0c39889f656af99201a997fbc48fcbffdd7', 'message': 'Gate: Fix Openstack support job\n\nThis PS provides a fix for the OpenStack support checks.\n\nChange-Id: If5a62650c5679674dfe44bab2c50301d9386d947\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 2, 'created': '2019-06-25 23:36:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/001badd6aaa72f6bb186ebeb942d9489c5bf18f6', 'message': 'Gate: Fix Openstack support job\n\nThis PS provides a fix for the OpenStack support checks.\n\nChange-Id: If5a62650c5679674dfe44bab2c50301d9386d947\nSigned-off-by: Pete Birley <pete@port.direct>\n'}, {'number': 3, 'created': '2019-07-17 13:45:27.000000000', 'files': ['zuul.d/project.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/48e0128ef718241ddaa1b704d7b02da471347d57', 'message': 'Gate: Fix Openstack support job\n\nThis PS provides a fix for the OpenStack support checks.\n\nChange-Id: If5a62650c5679674dfe44bab2c50301d9386d947\nSigned-off-by: Pete Birley <pete@port.direct>\n'}]",0,667481,48e0128ef718241ddaa1b704d7b02da471347d57,15,7,3,23928,,,0,"Gate: Fix Openstack support job

This PS provides a fix for the OpenStack support checks.

Change-Id: If5a62650c5679674dfe44bab2c50301d9386d947
Signed-off-by: Pete Birley <pete@port.direct>
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/81/667481/1 && git format-patch -1 --stdout FETCH_HEAD,['tools/deployment/keystone-auth/070-keystone.sh'],1,af54a0c39889f656af99201a997fbc48fcbffdd7,ci/keystone-auth-periodic, --values=${OSH_PATH}/keystone/values_overrides/ldap.yaml \, --values=${OSH_PATH}/tools/overrides/keystone/ldap_domain_config.yaml \,1,1
openstack%2Fneutron~master~I6b3881a77de0419e0c3612661bf60cc2e55da0a7,openstack/neutron,master,I6b3881a77de0419e0c3612661bf60cc2e55da0a7,switch to the newly created opensuse-15 nodeset,MERGED,2019-09-18 12:01:53.000000000,2019-10-16 19:16:07.000000000,2019-10-16 19:13:07.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-09-18 12:01:53.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/0528068a35b8ffecaf69d1cffb325604b97d30ed', 'message': 'switch to the newly created opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThis is the remaining work to be done after https://review.opendev.org/#/c/667539\ngot merged earlier\n\nChange-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7\nDepends-On: https://review.opendev.org/#/c/682843\n'}]",0,682879,0528068a35b8ffecaf69d1cffb325604b97d30ed,16,6,1,6593,,,0,"switch to the newly created opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

This is the remaining work to be done after https://review.opendev.org/#/c/667539
got merged earlier

Change-Id: I6b3881a77de0419e0c3612661bf60cc2e55da0a7
Depends-On: https://review.opendev.org/#/c/682843
",git fetch https://review.opendev.org/openstack/neutron refs/changes/79/682879/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0528068a35b8ffecaf69d1cffb325604b97d30ed,, - tempest-full-py3-opensuse15:, - tempest-full-py3-opensuse150:,1,1
openstack%2Fplacement~master~I1478e7a9c6ffc41f0a31bdab52a04123307708b6,openstack/placement,master,I1478e7a9c6ffc41f0a31bdab52a04123307708b6,api-ref: note GET /resource_providers?resources amount constraints,MERGED,2019-10-16 14:29:38.000000000,2019-10-16 19:16:03.000000000,2019-10-16 19:13:09.000000000,"[{'_account_id': 11564}, {'_account_id': 14070}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 14:29:38.000000000', 'files': ['api-ref/source/parameters.yaml'], 'web_link': 'https://opendev.org/openstack/placement/commit/0ed544e8ce1f1ba7dc9b2dfef695897e27d1024a', 'message': ""api-ref: note GET /resource_providers?resources amount constraints\n\nI was wondering if I could list only compute node resource providers\nby doing something like:\n\n  GET /resource_providers?resources=MEMORY_MB:0\n\nThe API reference does not explain the constraints on the resource\nclass amount value so I had to dig into the normalize_resources_qs_param\ncode to confirm that it must be an integer greater than 0, which is\nwhat I assumed but it was not mentioned in the docs, so I've added\nthat clarification here.\n\nChange-Id: I1478e7a9c6ffc41f0a31bdab52a04123307708b6\n""}]",1,688943,0ed544e8ce1f1ba7dc9b2dfef695897e27d1024a,8,3,1,6873,,,0,"api-ref: note GET /resource_providers?resources amount constraints

I was wondering if I could list only compute node resource providers
by doing something like:

  GET /resource_providers?resources=MEMORY_MB:0

The API reference does not explain the constraints on the resource
class amount value so I had to dig into the normalize_resources_qs_param
code to confirm that it must be an integer greater than 0, which is
what I assumed but it was not mentioned in the docs, so I've added
that clarification here.

Change-Id: I1478e7a9c6ffc41f0a31bdab52a04123307708b6
",git fetch https://review.opendev.org/openstack/placement refs/changes/43/688943/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/parameters.yaml'],1,0ed544e8ce1f1ba7dc9b2dfef695897e27d1024a,api-ref-list-providers-resources-amount, Note that the amount must be an integer greater than 0.,,2,0
openstack%2Fnetworking-ovn~stable%2Fstein~Id193385866cfb5f2490e3e322fc79a1fae81fd72,openstack/networking-ovn,stable/stein,Id193385866cfb5f2490e3e322fc79a1fae81fd72,Don't allow mixing IPv4/IPv6 configuration,MERGED,2019-10-03 10:08:37.000000000,2019-10-16 19:13:05.000000000,2019-10-16 19:11:32.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-03 10:08:37.000000000', 'files': ['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e5721859badac2ff3ffb83ef3e39d428771019a5', 'message': ""Don't allow mixing IPv4/IPv6 configuration\n\nOVN doesn't support members with different IP version\nthat loadalancer VIP. We should block such operations.\n\nChange-Id: Id193385866cfb5f2490e3e322fc79a1fae81fd72\nCloses-Bug: #1843553\n""}]",0,686371,e5721859badac2ff3ffb83ef3e39d428771019a5,13,4,1,24791,,,0,"Don't allow mixing IPv4/IPv6 configuration

OVN doesn't support members with different IP version
that loadalancer VIP. We should block such operations.

Change-Id: Id193385866cfb5f2490e3e322fc79a1fae81fd72
Closes-Bug: #1843553
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/71/686371/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/octavia/ovn_driver.py', 'networking_ovn/tests/unit/octavia/test_ovn_driver.py']",2,e5721859badac2ff3ffb83ef3e39d428771019a5,ovn-provider-driver-stein-cherry-picks," self.ovn_lb.external_ids = { ovn_driver.LB_EXT_IDS_VIP_KEY: '10.22.33.4'} self.mock_find_lb_pool_key = mock.patch.object( ovn_driver.OvnProviderHelper, '_find_ovn_lb_with_pool_key', return_value=self.ovn_lb).start() def test__ip_version_differs(self): self.assertFalse(self.driver._ip_version_differs(self.ref_member)) self.ref_member.address = 'fc00::1' self.assertTrue(self.driver._ip_version_differs(self.ref_member)) def test__ip_version_differs_pool_disabled(self): self.mock_find_lb_pool_key.side_effect = [None, self.ovn_lb] self.driver._ip_version_differs(self.ref_member) self.mock_find_lb_pool_key.assert_has_calls([ mock.call('pool_%s' % self.pool_id), mock.call('pool_%s:D' % self.pool_id)]) def test_member_create_different_ip_version(self): self.ref_member.address = 'fc00::1' self.assertRaises(exceptions.UnsupportedOptionError, self.driver.member_create, self.ref_member) def test_member_update_different_ip_version(self): self.ref_member.address = 'fc00::1' self.assertRaises(exceptions.UnsupportedOptionError, self.driver.member_update, self.ref_member, self.ref_member) "," mock.patch.object(ovn_driver.OvnProviderHelper, '_find_ovn_lb_with_pool_key', return_value=self.ovn_lb).start()",54,4
openstack%2Ftempest~master~I3c0e14c606c88b5deecfad71bc156e53335d543e,openstack/tempest,master,I3c0e14c606c88b5deecfad71bc156e53335d543e,switch to the newly created opensuse-15 nodeset,MERGED,2019-09-18 09:14:21.000000000,2019-10-16 19:06:04.000000000,2019-10-16 19:02:42.000000000,"[{'_account_id': 5689}, {'_account_id': 6547}, {'_account_id': 8556}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-09-18 09:14:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/a54c89d78ae507545a9ebba98f7528e980906a83', 'message': 'switch to the newly created opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThis is the remaining work to be done after https://review.opendev.org/#/c/667539\ngot merged earlier\n\nChange-Id: I3c0e14c606c88b5deecfad71bc156e53335d543e\n'}, {'number': 2, 'created': '2019-09-18 12:01:04.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/f352241b072302a6621762e0de65b2ffb79d7198', 'message': 'switch to the newly created opensuse-15 nodeset\n\nopensuse-150 nodeset is referring to openSUSE 15.0, which is still in\nmaintenance but openSUSE 15.1 has been released already. ""opensuse-15""\nis going to refer to the ""latest openSUSE 15.x"" build released and\nworking for OpenStack going forward, so add this nodeset and use\nit by default going forward.\n\nThis is the remaining work to be done after https://review.opendev.org/#/c/667539\ngot merged earlier\n\nChange-Id: I3c0e14c606c88b5deecfad71bc156e53335d543e\n'}]",2,682843,f352241b072302a6621762e0de65b2ffb79d7198,18,5,2,6593,,,0,"switch to the newly created opensuse-15 nodeset

opensuse-150 nodeset is referring to openSUSE 15.0, which is still in
maintenance but openSUSE 15.1 has been released already. ""opensuse-15""
is going to refer to the ""latest openSUSE 15.x"" build released and
working for OpenStack going forward, so add this nodeset and use
it by default going forward.

This is the remaining work to be done after https://review.opendev.org/#/c/667539
got merged earlier

Change-Id: I3c0e14c606c88b5deecfad71bc156e53335d543e
",git fetch https://review.opendev.org/openstack/tempest refs/changes/43/682843/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a54c89d78ae507545a9ebba98f7528e980906a83,, name: tempest-full-py3-opensuse15 nodeset: devstack-single-node-opensuse-15 on openSUSE Leap 15.x - tempest-full-py3-opensuse15:, name: tempest-full-py3-opensuse150 nodeset: devstack-single-node-opensuse-150 on openSUSE Leap 15.0 - tempest-full-py3-opensuse150:,4,4
openstack%2Fopenstack-helm-infra~master~I41f9e19dfa4b84ca0e45150362742297d78d9c42,openstack/openstack-helm-infra,master,I41f9e19dfa4b84ca0e45150362742297d78d9c42,Elasticsearch: fix Zuul gate scripts,ABANDONED,2019-10-15 20:02:19.000000000,2019-10-16 19:02:41.000000000,,"[{'_account_id': 22348}, {'_account_id': 28719}]","[{'number': 1, 'created': '2019-10-15 20:02:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8f0ce5e1c2b49f1e42d08d50e681347afbfc0b7a', 'message': 'Elasticsearch: fix Zuul gate scripts\n\nThe follow gates are failing because the elastic elasticsearch-curator\npods are getting stuck in Init:\n\n    openstack-helm-infra-aio-network-policy\n    openstack-helm-infra-apparmor\n\nThis is because the pods have a static dependency on this job that is\nnot being run:\n\n    elasticsearch-register-snapshot-repository\n\nThis change ensures that the job runs, and the pods can progress.\n\nChange-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42\n'}, {'number': 2, 'created': '2019-10-15 21:02:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b264625a2cb041fcc0c95b62c8d5fc53e95de57e', 'message': 'Elasticsearch: fix Zuul gate scripts\n\nThe follow gates are failing because the elastic elasticsearch-curator\npods are getting stuck in Init:\n\n    openstack-helm-infra-aio-network-policy\n    openstack-helm-infra-apparmor\n\nThis is because the pods have a static dependency on this job that is\nnot being run:\n\n    elasticsearch-register-snapshot-repository\n\nThis change ensures that the job runs, and the pods can progress.\n\nChange-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42\n'}, {'number': 3, 'created': '2019-10-15 21:17:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d96872364bf7d353412cabd33b73b521b8016b17', 'message': 'Elasticsearch: fix Zuul gate scripts\n\nThe follow gates may fail because the elastic elasticsearch-curator\npods are getting stuck in Init:\n\n    openstack-helm-infra-aio-network-policy\n    openstack-helm-infra-apparmor\n\nThis is because the pods have a static dependency on this job that is\nnot being run:\n\n    elasticsearch-register-snapshot-repository\n\nThis change ensures that the job runs, and the pods can progress.\n\nChange-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42\n'}, {'number': 4, 'created': '2019-10-15 21:17:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/da8f8490f0fff23673ead04e4b417bd1483ab045', 'message': 'Elasticsearch: fix Zuul gate scripts\n\nThe follow gates may fail because the elastic elasticsearch-curator\npods are getting stuck in Init:\n\n    openstack-helm-infra-aio-network-policy\n    openstack-helm-infra-apparmor\n\nThis is because the pods have a static dependency on this job that is\nnot being run:\n\n    elasticsearch-register-snapshot-repository\n\nThis change ensures that the job runs, and the pods can progress.\n\nChange-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42\n'}, {'number': 5, 'created': '2019-10-15 22:18:21.000000000', 'files': ['tools/deployment/apparmor/090-elasticsearch.sh', 'tools/deployment/network-policy/120-elasticsearch.sh'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/c78cbfdab94780927bd089ac4262e844f53d36d0', 'message': 'Elasticsearch: fix Zuul gate scripts\n\nThe follow gates may fail because the elastic elasticsearch-curator\npods are getting stuck in Init:\n\n    openstack-helm-infra-aio-network-policy\n    openstack-helm-infra-apparmor\n\nThis is because the pods have a static dependency on this job that is\nnot being run:\n\n    elasticsearch-register-snapshot-repository\n\nThis change ensures that the job runs, and the pods can progress.\n\nChange-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42\n'}]",0,688807,c78cbfdab94780927bd089ac4262e844f53d36d0,10,2,5,28719,,,0,"Elasticsearch: fix Zuul gate scripts

The follow gates may fail because the elastic elasticsearch-curator
pods are getting stuck in Init:

    openstack-helm-infra-aio-network-policy
    openstack-helm-infra-apparmor

This is because the pods have a static dependency on this job that is
not being run:

    elasticsearch-register-snapshot-repository

This change ensures that the job runs, and the pods can progress.

Change-Id: I41f9e19dfa4b84ca0e45150362742297d78d9c42
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/07/688807/5 && git format-patch -1 --stdout FETCH_HEAD,"['tools/deployment/apparmor/090-elasticsearch.sh', 'tools/deployment/network-policy/120-elasticsearch.sh']",2,8f0ce5e1c2b49f1e42d08d50e681347afbfc0b7a,,"jobs: verify_repositories: cron: ""*/3 * * * *""",,6,0
openstack%2Fneutron-lbaas~stable%2Fstein~I2c56542b667ad2747cbafb6da3e55788bc3b091e,openstack/neutron-lbaas,stable/stein,I2c56542b667ad2747cbafb6da3e55788bc3b091e,Fix lb stats model,MERGED,2019-10-14 11:52:36.000000000,2019-10-16 18:51:59.000000000,2019-10-16 18:51:59.000000000,"[{'_account_id': 841}, {'_account_id': 2245}, {'_account_id': 6469}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 11:52:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/afc9e4c425841e0873184328d9c565af783517fd', 'message': 'Fix lb stats model\n\nComparing int < str is always true in py2, but raises an exception in\npy3. So the validation was always broken, now we also fix the exceptions\noccurring in py3.\n\nTask: 37085\nChange-Id: I2c56542b667ad2747cbafb6da3e55788bc3b091e\n'}, {'number': 2, 'created': '2019-10-14 12:46:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/e9b09a663dde33564f3743ca21f91b2d15eb4859', 'message': 'Fix lb stats model\n\nComparing int < str is always true in py2, but raises an exception in\npy3. So the validation was always broken, now we also fix the exceptions\noccurring in py3.\n\nTask: 37085\nChange-Id: I2c56542b667ad2747cbafb6da3e55788bc3b091e\n'}, {'number': 3, 'created': '2019-10-16 11:05:25.000000000', 'files': ['releasenotes/notes/bug-lb-stats-validation-aa806817c16b22b1.yaml', 'neutron_lbaas/tests/unit/db/loadbalancer/test_models.py', 'neutron_lbaas/db/loadbalancer/models.py'], 'web_link': 'https://opendev.org/openstack/neutron-lbaas/commit/52adf0ac369839dda0ae90d6735bab5e6e62646b', 'message': 'Fix lb stats model\n\nComparing int < str is always true in py2, but raises an exception in\npy3. So the validation was always broken, now we also fix the exceptions\noccurring in py3.\n\nTask: 37085\nChange-Id: I2c56542b667ad2747cbafb6da3e55788bc3b091e\n'}]",1,688391,52adf0ac369839dda0ae90d6735bab5e6e62646b,17,5,3,13252,,,0,"Fix lb stats model

Comparing int < str is always true in py2, but raises an exception in
py3. So the validation was always broken, now we also fix the exceptions
occurring in py3.

Task: 37085
Change-Id: I2c56542b667ad2747cbafb6da3e55788bc3b091e
",git fetch https://review.opendev.org/openstack/neutron-lbaas refs/changes/91/688391/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_lbaas/tests/unit/db/loadbalancer/test_models.py', 'neutron_lbaas/db/loadbalancer/models.py']",2,afc9e4c425841e0873184328d9c565af783517fd,fix-stats-model-stein," if int(value) < 0: data = {'key': key, 'value': int(value)}"," if value < 0: data = {'key': key, 'value': value}",36,2
openstack%2Fnetworking-ovn~master~I3049dc69892bbab9bd6aa125d7008e0b688d675b,openstack/networking-ovn,master,I3049dc69892bbab9bd6aa125d7008e0b688d675b,Change playbooks to set python3 usage to True,ABANDONED,2019-10-14 19:38:14.000000000,2019-10-16 18:39:38.000000000,,"[{'_account_id': 1131}, {'_account_id': 8655}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 19:38:14.000000000', 'files': ['playbooks/legacy/networking-ovn-dsvm-functional/run.yaml', 'playbooks/legacy/grenade-dsvm-networking-ovn/run.yaml', 'playbooks/legacy/tempest-dsvm-networking-ovn-multinode/run.yaml'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/1c2af92c4c777f4b371a6490ac07e2d37947fd33', 'message': 'Change playbooks to set python3 usage to True\n\nSet DEVSTACK_GATE_USE_PYTHON3 to True so devstack will use\npython3 when setting-up the test environment. Follow-on to\nremoval of python2.\n\nChange-Id: I3049dc69892bbab9bd6aa125d7008e0b688d675b\n'}]",0,688547,1c2af92c4c777f4b371a6490ac07e2d37947fd33,5,3,1,1131,,,0,"Change playbooks to set python3 usage to True

Set DEVSTACK_GATE_USE_PYTHON3 to True so devstack will use
python3 when setting-up the test environment. Follow-on to
removal of python2.

Change-Id: I3049dc69892bbab9bd6aa125d7008e0b688d675b
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/47/688547/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/legacy/networking-ovn-dsvm-functional/run.yaml', 'playbooks/legacy/grenade-dsvm-networking-ovn/run.yaml', 'playbooks/legacy/tempest-dsvm-networking-ovn-multinode/run.yaml']",3,1c2af92c4c777f4b371a6490ac07e2d37947fd33,playbook-py3, export DEVSTACK_GATE_USE_PYTHON3=True,,3,0
openstack%2Fkolla-ansible~master~Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c,openstack/kolla-ansible,master,Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c,Implement IPv6 support in the control plane,MERGED,2019-09-11 18:48:06.000000000,2019-10-16 18:25:56.000000000,2019-10-16 18:22:23.000000000,"[{'_account_id': 14826}, {'_account_id': 19316}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 27781}, {'_account_id': 28614}, {'_account_id': 30491}, {'_account_id': 31073}]","[{'number': 1, 'created': '2019-09-11 18:48:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d32d8ff75458d1e38b780e73371154009c0763b2', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nCI tests for IPv6\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 2, 'created': '2019-09-11 18:50:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c29411ba5d94b2523514d1f7a105e1df153865e9', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nCI tests for IPv6\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 3, 'created': '2019-09-12 06:44:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5f261b4d217e537f152e4a0ae7aabbb52a693642', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nCI tests for IPv6\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 4, 'created': '2019-09-12 14:05:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/895630c4045850df51d0da36d8d2fea39193309d', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 5, 'created': '2019-09-12 14:13:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ad64fb608fbc01b45e7b9a96917db26217ccf9e4', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 6, 'created': '2019-09-12 15:22:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f8f088ff98318aeb712f6a6367ce179466d5426a', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nprechecks for rabbitmq and qdrouterd use ahostsv4\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 7, 'created': '2019-09-12 15:45:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/718f4f00fad3480208b7a07d3c23201bd1b04a48', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 8, 'created': '2019-09-12 16:04:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/51580179d9f8637eb6699815ba068e4d900b8bd2', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 9, 'created': '2019-09-12 17:31:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e59ee642f0a9de5380a83ce56299d962420fb95f', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 10, 'created': '2019-09-12 17:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fa6dcf400558a0d87012d21f31f47df8ce2a78b7', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 11, 'created': '2019-09-12 18:13:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1d20f08f4cdc3009508721722a0a9708f9c209bf', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 12, 'created': '2019-09-12 19:02:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e50808d82c7cd41256243aaf40808b15a7efb3c0', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 13, 'created': '2019-09-23 11:36:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4ba8adb51b4c2e855775a6069e22fc2f540abf51', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 14, 'created': '2019-09-23 11:37:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9d48403d00afa5521fb047c1b45b82d2074d6fa2', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 15, 'created': '2019-09-23 12:22:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ead2eba9e17216794766757318d7e9109c13e412', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 16, 'created': '2019-09-23 14:43:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4519259fc568fe03db5a93ad1629938cd895c85a', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 17, 'created': '2019-09-25 17:11:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/ff0d4d35db7346e572c29efada14c86312b7ab63', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 18, 'created': '2019-09-25 17:42:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/41c02cf44c600e105ea2f9150924d64edceb8520', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 19, 'created': '2019-09-25 18:26:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fda188abe98ef44478db4803ffaa3f713f6fa5e8', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 20, 'created': '2019-09-25 19:16:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5e750a0ee9a567d63100507f2879b73ccb131cbc', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 21, 'created': '2019-09-29 19:56:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/61f4132433dc43ba9761848ce93c3ceaecadc74a', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 22, 'created': '2019-09-30 06:47:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/af95b03165a21735aa2296e9978ce75fb9c2e3e2', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 23, 'created': '2019-09-30 10:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4866c440e5a113031a2c52ed04a72bf57a5122a5', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 24, 'created': '2019-09-30 11:58:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/84371cf388a3e0e72a5185bd4713f4a3a2e263ec', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 25, 'created': '2019-09-30 16:27:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/1b6f6ca3b8800f0edcfb94abfd03cb8495b4d779', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 26, 'created': '2019-09-30 16:30:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cb5e55d6b559f826ba6b74cdc91fb8bc691c9a31', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 27, 'created': '2019-09-30 17:55:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/819ad0f52cbbb0ac8f874d4b0bee3bd3d6dbd23f', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 28, 'created': '2019-09-30 18:50:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e4a37d1d6d0b3e3ee726460982eee493ccfa0e8b', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 29, 'created': '2019-10-01 08:47:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3d636a97babbe78d4be98ad0d24b720a8ca7aefe', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 30, 'created': '2019-10-01 10:15:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/23309a078a373ddf794816cfe9f40eaafda990a2', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 31, 'created': '2019-10-01 11:35:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c8879b06834cecda3bb19172f1a2eb66dce0f45d', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 32, 'created': '2019-10-01 17:08:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/409036f7babb62e02714503c353d2a26b88c11ab', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 33, 'created': '2019-10-02 06:34:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/12ff2b8c5c464ded32e5606691f8ea4c04baebbf', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 34, 'created': '2019-10-02 06:57:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/91b8240cc2bfd10f33f740ede9d5d56f124be477', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 35, 'created': '2019-10-02 10:06:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10f0d6dbfa7445b3863ac4dce6f025be79d3af9c', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 36, 'created': '2019-10-02 11:04:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/91ecdece2783157be78e1291c4d6a6ae1402302d', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 37, 'created': '2019-10-02 12:34:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/9076fd42ea5b9d801757e78ac336f0366be503ce', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 38, 'created': '2019-10-02 14:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cc41e8672436d7a48c91e022fa952a3ba561927d', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL syntax applied in some places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\ncheck if proper context applied everywhere\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 39, 'created': '2019-10-02 18:38:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/0b60f55c8c2875f8015f1a8b892b2c4d38d3c74e', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 40, 'created': '2019-10-03 06:54:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3f8ee4d15f981a5ebab5a2fba7ac89c27925b1b5', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 41, 'created': '2019-10-03 07:01:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d81edf405518bc27973aa2015c6cc92dfc6c58e1', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 42, 'created': '2019-10-03 09:41:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/048dedf9aa2b4ed4bda071b672f6a8444009686f', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 43, 'created': '2019-10-03 14:18:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/c1c9429ed0c5b53e4028d6f50eb63fe5f539e26a', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 44, 'created': '2019-10-03 16:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/af61d2763cc9dc329420fdf051ecd1fc02768da1', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 45, 'created': '2019-10-03 19:50:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5c0386ec6a3d9d8e9b49ace885d8b3c8df5df5f1', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 46, 'created': '2019-10-04 09:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7b3f6c6ad670e241f5230cdd4c78d68175078fcd', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemoved neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let\'s avoid any confusion)\nand could break setups without proper multicast routing\nif it started working\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 47, 'created': '2019-10-04 09:18:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/8aea2dc8100e58fcb8f5e2da5cf6c5790eb168c6', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemoved neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let\'s avoid any confusion)\nand could break setups without proper multicast routing\nif it started working\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 48, 'created': '2019-10-06 10:07:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/44943de95be1a09e4da3eb670baa8b3ce3e3d32f', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemoved neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let\'s avoid any confusion)\nand could break setups without proper multicast routing\nif it started working\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 49, 'created': '2019-10-06 11:06:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d100b0ac82210c5cba65ab1cf9864028adca7e4f', 'message': 'Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter for ""DRY and expand"".\n\nAdd AF config to vars.\n\nApply the following subs:\nhostvars\\[inventory_hostname\\]\\[\'ansible_\' *[+~] *([^\\]]+)_interface\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$1\' | kolla_address\nhostvars\\[([^\\]]+)\\]\\[\'ansible_\' *[+~] *hostvars\\[[^\\]]+\\]\\[\'([^\\]]+)_interface\'\\]\\]\\[\'ipv4\'\\]\\[\'address\'\\]\n\'$2\' | kolla_address($1)\n\nmemcache address syntax exception (inet6[...]) applied.\nURL address syntax exception ([...]) applied.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron\'s ml2 \'overlay_ip_version\' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemoved neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let\'s avoid any confusion)\nand could break setups without proper multicast routing\nif it started working\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}, {'number': 50, 'created': '2019-10-06 13:34:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6caaa445be3694ef3a4d7b794b1ae5a4937b9b42', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 51, 'created': '2019-10-06 14:58:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/58f2fbd3f9008ea3b4972200d864ce83b2e91288', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 52, 'created': '2019-10-06 16:29:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/503c3d0d8885dd28e47b37555551b9da32c9b8b8', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ will fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred and will fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 53, 'created': '2019-10-06 17:53:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/eccfb48fb6c12e18219222670008fb92c5ae168c', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 54, 'created': '2019-10-06 19:54:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/903531a89d96de85c7b412f01a043fac2ef3ff36', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 55, 'created': '2019-10-06 19:55:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/785c16d8f8cf2e9c59716c9ebf8d85619c022165', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 56, 'created': '2019-10-06 19:59:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2eebc7969320f05a03dab7c51c81cb5edc578c14', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 57, 'created': '2019-10-07 06:52:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bfae64910bcbceb33e548de283ec9d35ff4a84a0', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 58, 'created': '2019-10-07 09:32:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/56d5f7f45bc248e0d0ee3593ff32c15cbdaeb452', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nIPv6 internal VIP address used via FQDN in URLs needs some escaping\nworkaround: use real FQDN\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 59, 'created': '2019-10-07 16:43:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2ad031f4945b9743361bd4f93c4359b59c11ee6e', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 60, 'created': '2019-10-08 07:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/d0f6fa9fa2ef9e7292c22cc24402212c5d85a3b3', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 61, 'created': '2019-10-08 10:13:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/aabb14ce6aaaefbdf856028d1ce40ecabd2e0524', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nReplace IPv4 addresses and FQDNs usages in all places.\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nhaproxy upgrade checks for slaves based on ipv4 secondaries only\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 62, 'created': '2019-10-08 16:15:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/f80ffcae0373b58ad84dc108bf6ad66a542ea27f', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 63, 'created': '2019-10-08 16:18:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7d703af94d577612de74fd27a2287a12369eae16', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 64, 'created': '2019-10-08 16:56:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/49ff235a125516cd5897e609149f4ee99b624e4f', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic source CI jobs for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 65, 'created': '2019-10-08 17:17:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/a17990fb0f8535771d73cc2eea6be74957068e50', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 66, 'created': '2019-10-09 18:25:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/50e3c2bb0c935298330c0ec80fd98fb9400d7261', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nBifrost Train does not support IPv6 deployments.\nSee: https://storyboard.openstack.org/#!/story/2006689\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 67, 'created': '2019-10-10 10:43:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/96912ba04a17bc1ac21dc7fc08d6b6e22259b5de', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nBifrost Train does not support IPv6 deployments.\nSee: https://storyboard.openstack.org/#!/story/2006689\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 68, 'created': '2019-10-10 19:41:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/97325ea3075457835f7ee4d94302b56fe6a72ffe', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6:[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nBifrost Train does not support IPv6 deployments.\nSee: https://storyboard.openstack.org/#!/story/2006689\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 69, 'created': '2019-10-11 18:00:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/2983873f2f89b05eac824fa48dbaab8944dbd321', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6:[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\n\nml2 for xenapi\n\nrp_filter setting\n(? would require meddling with ip6tables, by default nothing is dropped)\n\nironic dnsmasq is configured IPv4-only\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nBifrost Train does not support IPv6 deployments.\nSee: https://storyboard.openstack.org/#!/story/2006689\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}, {'number': 70, 'created': '2019-10-16 08:44:03.000000000', 'files': ['ansible/roles/ceph/templates/ceph-osd.json.j2', 'ansible/roles/collectd/templates/collectd.conf.j2', 'ansible/roles/heat/defaults/main.yml', 'ansible/roles/ironic/templates/inspector.ipxe.j2', 'ansible/roles/vitrage/tasks/precheck.yml', 'ansible/roles/ceilometer/templates/ceilometer.conf.j2', 'ansible/roles/grafana/tasks/post_config.yml', 'ansible/roles/swift/templates/container.conf.j2', 'ansible/roles/prometheus/templates/prometheus-server.json.j2', 'ansible/roles/haproxy/tasks/precheck.yml', 'ansible/roles/cyborg/templates/cyborg.conf.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/qinling/defaults/main.yml', 'ansible/roles/memcached/defaults/main.yml', 'ansible/roles/skydive/templates/skydive-agent.json.j2', 'ansible/roles/cloudkitty/templates/wsgi-cloudkitty.conf.j2', 'ansible/roles/kibana/tasks/post_config.yml', 'ansible/roles/swift/templates/proxy-server.conf.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/roles/freezer/defaults/main.yml', 'ansible/roles/baremetal/tasks/pre-install.yml', 'ansible/roles/neutron/defaults/main.yml', 'ansible/roles/sahara/templates/sahara.conf.j2', 'ansible/roles/kafka/defaults/main.yml', 'ansible/roles/barbican/templates/barbican-api.ini.j2', 'ansible/roles/placement/templates/placement.conf.j2', 'ansible/roles/blazar/templates/blazar.conf.j2', 'ansible/roles/manila/defaults/main.yml', 'ansible/roles/mistral/templates/mistral.conf.j2', 'ansible/roles/ceph/templates/ceph-mon.json.j2', 'ansible/roles/horizon/templates/horizon.conf.j2', 'ansible/roles/karbor/templates/karbor.conf.j2', 'ansible/roles/designate/defaults/main.yml', 'tests/pre.yml', 'ansible/roles/monasca/templates/monasca-log-api/wsgi-log-api.conf.j2', 'ansible/roles/opendaylight/templates/akka.conf.j2', 'ansible/roles/masakari/defaults/main.yml', 'ansible/roles/octavia/defaults/main.yml', 'ansible/roles/panko/defaults/main.yml', 'doc/source/reference/compute/masakari-guide.rst', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/group_vars/all.yml', 'ansible/roles/swift/tasks/precheck.yml', 'ansible/roles/keystone/templates/keystone.conf.j2', 'ansible/roles/aodh/templates/aodh.conf.j2', 'ansible/roles/kibana/templates/kibana.yml.j2', 'ansible/roles/prometheus/templates/prometheus-alertmanager.yml.j2', 'ansible/roles/masakari/templates/masakari.conf.j2', 'ansible/roles/designate/templates/designate.conf.j2', 'ansible/roles/murano/tasks/import_library_packages.yml', 'ansible/roles/qinling/templates/qinling.conf.j2', 'ansible/roles/solum/templates/solum.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/iscsi/templates/tgtd.json.j2', 'ansible/roles/congress/defaults/main.yml', 'ansible/roles/blazar/defaults/main.yml', 'ansible/roles/ceph/defaults/main.yml', 'ansible/roles/aodh/templates/wsgi-aodh.conf.j2', 'ansible/roles/keystone/templates/fernet-push.sh.j2', 'ansible/roles/solum/defaults/main.yml', 'ansible/roles/monasca/templates/monasca-thresh/storm.yml.j2', 'ansible/roles/rabbitmq/templates/erl_inetrc.j2', 'ansible/roles/storm/defaults/main.yml', 'ansible/roles/designate/templates/pools.yaml.j2', 'etc/kolla/globals.yml', 'kolla_ansible/put_address_in_context.py', 'ansible/roles/skydive/templates/skydive-agent.conf.j2', 'ansible/roles/rabbitmq/templates/rabbitmq.json.j2', 'ansible/roles/vitrage/templates/vitrage.conf.j2', 'ansible/roles/etcd/defaults/main.yml', 'ansible/roles/sahara/defaults/main.yml', 'ansible/roles/zun/templates/wsgi-zun.conf.j2', 'ansible/roles/swift/templates/object.conf.j2', 'ansible/roles/trove/defaults/main.yml', 'ansible/roles/mariadb/templates/galera.cnf.j2', 'ansible/roles/octavia/templates/octavia.conf.j2', 'ansible/roles/nova/defaults/main.yml', 'ansible/roles/magnum/defaults/main.yml', 'ansible/roles/prometheus/tasks/precheck.yml', 'ansible/roles/zun/defaults/main.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_split.cfg.j2', 'ansible/roles/searchlight/templates/searchlight.conf.j2', 'ansible/roles/mistral/defaults/main.yml', 'ansible/roles/tacker/templates/tacker.conf.j2', 'ansible/roles/cinder/templates/cinder.conf.j2', 'ansible/roles/skydive/templates/skydive-analyzer.conf.j2', 'ansible/roles/cyborg/defaults/main.yml', 'ansible/roles/congress/templates/congress.conf.j2', 'ansible/roles/ironic/templates/pxelinux.default.j2', 'ansible/roles/influxdb/templates/influxdb.conf.j2', 'ansible/filter_plugins/address.py', 'ansible/roles/openvswitch/templates/start-ovs.j2', 'ansible/roles/freezer/templates/wsgi-freezer-api.conf.j2', 'ansible/roles/telegraf/templates/telegraf.conf.j2', 'ansible/roles/vitrage/defaults/main.yml', 'zuul.d/base.yaml', 'kolla_ansible/tests/unit/test_address_filters.py', 'ansible/roles/gnocchi/defaults/main.yml', 'ansible/roles/common/templates/conf/output/02-monasca.conf.j2', 'ansible/roles/prometheus/templates/prometheus-openstack-exporter.json.j2', 'zuul.d/project.yaml', 'ansible/roles/storm/templates/storm.yml.j2', 'ansible/roles/monasca/tasks/post_config.yml', 'ansible/roles/ironic/templates/ironic-dnsmasq.conf.j2', 'tests/get_logs.sh', 'ansible/roles/haproxy/templates/keepalived.conf.j2', 'ansible/roles/cloudkitty/defaults/main.yml', 'ansible/roles/prometheus/templates/prometheus-blackbox-exporter.json.j2', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/monasca/templates/monasca-grafana/grafana.ini.j2', 'ansible/roles/vitrage/templates/wsgi-vitrage.conf.j2', 'ansible/roles/murano/defaults/main.yml', 'ansible/roles/nova-hyperv/templates/nova_hyperv.conf.j2', 'ansible/roles/prometheus/templates/prometheus-memcached-exporter.json.j2', 'ansible/roles/monasca/templates/monasca-thresh/thresh-config.yml.j2', 'ansible/roles/opendaylight/defaults/main.yml', 'ansible/roles/prometheus/templates/prometheus-elasticsearch-exporter.json.j2', 'ansible/roles/magnum/templates/magnum.conf.j2', 'ansible/roles/neutron/templates/ml2_conf.ini.j2', 'ansible/roles/masakari/templates/masakari-monitors.conf.j2', 'ansible/roles/placement/templates/placement-api-wsgi.conf.j2', 'tools/validate-all-file.py', 'ansible/roles/ironic/defaults/main.yml', 'zuul.d/jobs.yaml', 'ansible/roles/rabbitmq/tasks/precheck.yml', 'ansible/roles/watcher/defaults/main.yml', 'ansible/roles/panko/templates/wsgi-panko.conf.j2', 'ansible/roles/elasticsearch/templates/elasticsearch.yml.j2', 'ansible/roles/heat/templates/heat.conf.j2', 'ansible/roles/kafka/templates/kafka.server.properties.j2', 'ansible/roles/common/templates/conf/output/00-local.conf.j2', 'ansible/roles/keystone/defaults/main.yml', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/monasca/defaults/main.yml', 'ansible/roles/rabbitmq/templates/rabbitmq-env.conf.j2', 'ansible/roles/swift/defaults/main.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_listen.cfg.j2', 'ansible/roles/qinling/templates/wsgi-qinling.conf.j2', 'ansible/roles/redis/templates/redis.conf.j2', 'ansible/roles/senlin/defaults/main.yml', 'ansible/roles/keystone/templates/wsgi-keystone.conf.j2', 'ansible/roles/ovs-dpdk/defaults/main.yml', 'ansible/roles/tacker/defaults/main.yml', 'ansible/roles/watcher/templates/watcher.conf.j2', 'ansible/roles/prometheus/templates/prometheus.yml.j2', 'ansible/roles/swift/templates/account.conf.j2', 'kolla_ansible/kolla_address.py', 'ansible/roles/horizon/templates/local_settings.j2', 'ansible/roles/zookeeper/templates/zookeeper.cfg.j2', 'ansible/roles/swift/templates/rsyncd.conf.j2', 'ansible/roles/manila/templates/manila.conf.j2', 'ansible/roles/masakari/templates/wsgi-masakari.conf.j2', 'ansible/roles/monasca/templates/monasca-api/wsgi-api.conf.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/gnocchi/templates/wsgi-gnocchi.conf.j2', 'ansible/roles/rally/defaults/main.yml', 'ansible/roles/horizon/defaults/main.yml', 'ansible/roles/elasticsearch/tasks/upgrade.yml', 'ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/designate/templates/rndc.conf.j2', 'ansible/roles/prechecks/tasks/port_checks.yml', 'ansible/roles/cinder/defaults/main.yml', 'ansible/roles/redis/templates/redis-sentinel.conf.j2', 'ansible/roles/senlin/templates/senlin.conf.j2', 'ansible/roles/haproxy/tasks/upgrade.yml', 'ansible/roles/searchlight/defaults/main.yml', 'ansible/roles/grafana/templates/prometheus.yaml.j2', 'ansible/roles/keystone/templates/fernet-node-sync.sh.j2', 'ansible/roles/mariadb/defaults/main.yml', 'ansible/roles/cinder/templates/cinder-wsgi.conf.j2', 'ansible/roles/qdrouterd/tasks/precheck.yml', 'ansible/roles/zun/templates/zun.conf.j2', 'ansible/roles/rabbitmq/tasks/config.yml', 'ansible/roles/grafana/defaults/main.yml', 'tests/templates/globals-default.j2', 'ansible/roles/barbican/defaults/main.yml', 'ansible/roles/kuryr/templates/kuryr.conf.j2', 'ansible/roles/nova/templates/nova.conf.d/libvirt.conf.j2', 'ansible/roles/prometheus/templates/clouds.yml.j2', 'ansible/roles/aodh/defaults/main.yml', 'ansible/roles/prometheus/templates/prometheus-haproxy-exporter.json.j2', 'ansible/roles/gnocchi/templates/gnocchi.conf.j2', 'ansible/roles/designate/tasks/precheck.yml', 'ansible/roles/designate/templates/named.conf.j2', 'ansible/roles/freezer/templates/freezer.conf.j2', 'ansible/roles/opendaylight/tasks/precheck.yml', 'ansible/roles/mongodb/handlers/main.yml', 'ansible/roles/skydive/templates/skydive-analyzer.json.j2', 'ansible/roles/ceph/templates/ceph.conf.j2', 'ansible/roles/placement/defaults/main.yml', 'ansible/roles/prometheus/defaults/main.yml', 'ansible/roles/panko/templates/panko.conf.j2', 'ansible/roles/monasca/templates/monasca-api/api.conf.j2', 'ansible/roles/murano/templates/murano.conf.j2', 'ansible/roles/rabbitmq/templates/rabbitmq.conf.j2', 'tests/run.yml', 'ansible/roles/prometheus/templates/prometheus-alertmanager.json.j2', 'ansible/roles/karbor/defaults/main.yml', 'ansible/roles/mongodb/templates/bootstrap_cluster.js.j2', 'ansible/roles/ironic/templates/ironic-ipxe-httpd.conf.j2', 'ansible/roles/kuryr/templates/kuryr.spec.j2', 'ansible/roles/ceph/tasks/upgrade.yml', 'ansible/roles/prometheus/templates/prometheus-node-exporter.json.j2', 'ansible/roles/cloudkitty/templates/cloudkitty.conf.j2', 'ansible/roles/opendaylight/templates/10-rest-connector.xml.j2', 'ansible/roles/prometheus/templates/prometheus-mysqld-exporter.json.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/bc053c09c180b21151da9312386c0d2fdc1a2700', 'message': ""Implement IPv6 support in the control plane\n\nIntroduce kolla_address filter.\nIntroduce put_address_in_context filter.\n\nAdd AF config to vars.\n\nAddress contexts:\n- raw (default): <ADDR>\n- memcache: inet6:[<ADDR>]\n- url: [<ADDR>]\n\nOther changes:\n\nglobals.yml - mention just IP in comment\n\nprechecks/port_checks (api_intf) - kolla_address handles validation\n\n3x interface conditional (swift configs: replication/storage)\n\n2x interface variable definition with hostname\n(haproxy listens; api intf)\n\n1x interface variable definition with hostname with bifrost exclusion\n(baremetal pre-install /etc/hosts; api intf)\n\nneutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network\n\nbasic multinode source CI job for IPv6\n\nprechecks for rabbitmq and qdrouterd use proper NSS database now\n\nMariaDB Galera Cluster WSREP SST mariabackup workaround\n(socat and IPv6)\n\nCeph naming workaround in CI\nTODO: probably needs documenting\n\nRabbitMQ IPv6-only proto_dist\n\nCeph ms switch to IPv6 mode\n\nRemove neutron-server ml2_type_vxlan/vxlan_group setting\nas it is not used (let's avoid any confusion)\nand could break setups without proper multicast routing\nif it started working (also IPv4-only)\n\nhaproxy upgrade checks for slaves based on ipv6 addresses\n\nTODO:\n\novs-dpdk grabs ipv4 network address (w/ prefix len / submask)\nnot supported, invalid by default because neutron_external has no address\nNo idea whether ovs-dpdk works at all atm.\n\nml2 for xenapi\nXen is not supported too well.\nThis would require working with XenAPI facts.\n\nrp_filter setting\nThis would require meddling with ip6tables (there is no sysctl param).\nBy default nothing is dropped.\nUnlikely we really need it.\n\nironic dnsmasq is configured IPv4-only\ndnsmasq needs DHCPv6 options and testing in vivo.\n\nKNOWN ISSUES (beyond us):\n\nOne cannot use IPv6 address to reference the image for docker like we\ncurrently do, see: https://github.com/moby/moby/issues/39033\n(docker_registry; docker API 400 - invalid reference format)\nworkaround: use hostname/FQDN\n\nRabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.\nThis is due to old RabbitMQ versions available in images.\nIPv4 is preferred by default and may fail in the IPv6-only scenario.\nThis should be no problem in real life as IPv6-only is indeed IPv6-only.\nAlso, when new RabbitMQ (3.7.16/3.8+) makes it into images, this will\nno longer be relevant as we supply all the necessary config.\nSee: https://github.com/rabbitmq/rabbitmq-server/pull/1982\n\nFor reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed\nto work well). Older Ansible versions are known to miss IPv6 addresses\nin interface facts. This may affect redeploys, reconfigures and\nupgrades which run after VIP address is assigned.\nSee: https://github.com/ansible/ansible/issues/63227\n\nBifrost Train does not support IPv6 deployments.\nSee: https://storyboard.openstack.org/#!/story/2006689\n\nChange-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c\nImplements: blueprint ipv6-control-plane\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n""}]",55,681573,bc053c09c180b21151da9312386c0d2fdc1a2700,213,10,70,30491,,,0,"Implement IPv6 support in the control plane

Introduce kolla_address filter.
Introduce put_address_in_context filter.

Add AF config to vars.

Address contexts:
- raw (default): <ADDR>
- memcache: inet6:[<ADDR>]
- url: [<ADDR>]

Other changes:

globals.yml - mention just IP in comment

prechecks/port_checks (api_intf) - kolla_address handles validation

3x interface conditional (swift configs: replication/storage)

2x interface variable definition with hostname
(haproxy listens; api intf)

1x interface variable definition with hostname with bifrost exclusion
(baremetal pre-install /etc/hosts; api intf)

neutron's ml2 'overlay_ip_version' set to 6 for IPv6 on tunnel network

basic multinode source CI job for IPv6

prechecks for rabbitmq and qdrouterd use proper NSS database now

MariaDB Galera Cluster WSREP SST mariabackup workaround
(socat and IPv6)

Ceph naming workaround in CI
TODO: probably needs documenting

RabbitMQ IPv6-only proto_dist

Ceph ms switch to IPv6 mode

Remove neutron-server ml2_type_vxlan/vxlan_group setting
as it is not used (let's avoid any confusion)
and could break setups without proper multicast routing
if it started working (also IPv4-only)

haproxy upgrade checks for slaves based on ipv6 addresses

TODO:

ovs-dpdk grabs ipv4 network address (w/ prefix len / submask)
not supported, invalid by default because neutron_external has no address
No idea whether ovs-dpdk works at all atm.

ml2 for xenapi
Xen is not supported too well.
This would require working with XenAPI facts.

rp_filter setting
This would require meddling with ip6tables (there is no sysctl param).
By default nothing is dropped.
Unlikely we really need it.

ironic dnsmasq is configured IPv4-only
dnsmasq needs DHCPv6 options and testing in vivo.

KNOWN ISSUES (beyond us):

One cannot use IPv6 address to reference the image for docker like we
currently do, see: https://github.com/moby/moby/issues/39033
(docker_registry; docker API 400 - invalid reference format)
workaround: use hostname/FQDN

RabbitMQ may fail to bind to IPv6 if hostname resolves also to IPv4.
This is due to old RabbitMQ versions available in images.
IPv4 is preferred by default and may fail in the IPv6-only scenario.
This should be no problem in real life as IPv6-only is indeed IPv6-only.
Also, when new RabbitMQ (3.7.16/3.8+) makes it into images, this will
no longer be relevant as we supply all the necessary config.
See: https://github.com/rabbitmq/rabbitmq-server/pull/1982

For reliable runs, at least Ansible 2.8 is required (2.8.5 confirmed
to work well). Older Ansible versions are known to miss IPv6 addresses
in interface facts. This may affect redeploys, reconfigures and
upgrades which run after VIP address is assigned.
See: https://github.com/ansible/ansible/issues/63227

Bifrost Train does not support IPv6 deployments.
See: https://storyboard.openstack.org/#!/story/2006689

Change-Id: Ia34e6916ea4f99e9522cd2ddde03a0a4776f7e2c
Implements: blueprint ipv6-control-plane
Signed-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/73/681573/70 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/ceph/templates/ceph-osd.json.j2', 'ansible/roles/collectd/templates/collectd.conf.j2', 'ansible/roles/storm/templates/storm.yml.j2', 'ansible/roles/vitrage/tasks/precheck.yml', 'ansible/roles/ceilometer/templates/ceilometer.conf.j2', 'ansible/roles/haproxy/templates/keepalived.conf.j2', 'ansible/roles/glance/templates/glance-api.conf.j2', 'ansible/roles/vitrage/templates/wsgi-vitrage.conf.j2', 'ansible/roles/swift/templates/container.conf.j2', 'ansible/roles/opendaylight/defaults/main.yml', 'ansible/roles/magnum/templates/magnum.conf.j2', 'ansible/roles/cyborg/templates/cyborg.conf.j2', 'ansible/roles/ironic/templates/ironic-inspector.conf.j2', 'ansible/roles/memcached/defaults/main.yml', 'ansible/roles/neutron/templates/ml2_conf.ini.j2', 'ansible/roles/masakari/templates/masakari-monitors.conf.j2', 'ansible/roles/rabbitmq/tasks/precheck.yml', 'ansible/roles/swift/templates/proxy-server.conf.j2', 'ansible/roles/elasticsearch/templates/elasticsearch.yml.j2', 'ansible/roles/ironic/templates/ironic.conf.j2', 'ansible/roles/baremetal/tasks/pre-install.yml', 'ansible/roles/sahara/templates/sahara.conf.j2', 'ansible/roles/heat/templates/heat.conf.j2', 'ansible/roles/kafka/defaults/main.yml', 'ansible/roles/placement/templates/placement.conf.j2', 'ansible/roles/blazar/templates/blazar.conf.j2', 'ansible/roles/mistral/templates/mistral.conf.j2', 'ansible/roles/glance/defaults/main.yml', 'ansible/roles/monasca/defaults/main.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_listen.cfg.j2', 'ansible/roles/karbor/templates/karbor.conf.j2', 'ansible/roles/redis/templates/redis.conf.j2', 'ansible/roles/ovs-dpdk/defaults/main.yml', 'ansible/roles/opendaylight/templates/akka.conf.j2', 'ansible/roles/watcher/templates/watcher.conf.j2', 'ansible/roles/prometheus/templates/prometheus.yml.j2', 'ansible/roles/swift/templates/account.conf.j2', 'ansible/roles/panko/defaults/main.yml', 'doc/source/reference/compute/masakari-guide.rst', 'ansible/roles/neutron/templates/neutron.conf.j2', 'ansible/roles/horizon/templates/local_settings.j2', 'ansible/roles/zookeeper/templates/zookeeper.cfg.j2', 'ansible/group_vars/all.yml', 'ansible/roles/swift/tasks/precheck.yml', 'ansible/roles/swift/templates/rsyncd.conf.j2', 'ansible/roles/manila/templates/manila.conf.j2', 'ansible/roles/barbican/templates/barbican.conf.j2', 'ansible/roles/keystone/templates/keystone.conf.j2', 'ansible/roles/manila/templates/manila-share.conf.j2', 'ansible/roles/aodh/templates/aodh.conf.j2', 'ansible/roles/designate/templates/rndc.conf.j2', 'ansible/roles/masakari/templates/masakari.conf.j2', 'ansible/roles/designate/templates/designate.conf.j2', 'ansible/roles/prechecks/tasks/port_checks.yml', 'ansible/roles/qinling/templates/qinling.conf.j2', 'ansible/roles/solum/templates/solum.conf.j2', 'ansible/roles/nova/templates/nova.conf.j2', 'ansible/roles/redis/templates/redis-sentinel.conf.j2', 'ansible/roles/senlin/templates/senlin.conf.j2', 'ansible/roles/keystone/templates/fernet-push.sh.j2', 'ansible/roles/monasca/templates/monasca-thresh/storm.yml.j2', 'ansible/roles/storm/defaults/main.yml', 'ansible/roles/designate/templates/pools.yaml.j2', 'ansible/roles/keystone/templates/fernet-node-sync.sh.j2', 'ansible/roles/mariadb/defaults/main.yml', 'etc/kolla/globals.yml', 'ansible/roles/qdrouterd/tasks/precheck.yml', 'ansible/roles/zun/templates/zun.conf.j2', 'ansible/roles/skydive/templates/skydive-agent.conf.j2', 'ansible/roles/vitrage/templates/vitrage.conf.j2', 'ansible/roles/etcd/defaults/main.yml', 'ansible/roles/swift/templates/object.conf.j2', 'ansible/filter_plugins/kolla_address.py', 'ansible/roles/mariadb/templates/galera.cnf.j2', 'ansible/roles/nova/templates/nova.conf.d/libvirt.conf.j2', 'ansible/roles/octavia/templates/octavia.conf.j2', 'ansible/roles/gnocchi/templates/gnocchi.conf.j2', 'ansible/roles/designate/tasks/precheck.yml', 'ansible/roles/prometheus/tasks/precheck.yml', 'ansible/roles/haproxy-config/templates/haproxy_single_service_split.cfg.j2', 'ansible/roles/searchlight/templates/searchlight.conf.j2', 'ansible/roles/tacker/templates/tacker.conf.j2', 'ansible/roles/designate/templates/named.conf.j2', 'ansible/roles/freezer/templates/freezer.conf.j2', 'ansible/roles/cinder/templates/cinder.conf.j2', 'ansible/roles/skydive/templates/skydive-analyzer.conf.j2', 'ansible/roles/opendaylight/tasks/precheck.yml', 'ansible/roles/congress/templates/congress.conf.j2', 'ansible/roles/mongodb/handlers/main.yml', 'ansible/roles/ceph/templates/ceph.conf.j2', 'ansible/roles/panko/templates/panko.conf.j2', 'ansible/roles/openvswitch/templates/start-ovs.j2', 'ansible/roles/murano/templates/murano.conf.j2', 'ansible/roles/telegraf/templates/telegraf.conf.j2', 'ansible/roles/prometheus/templates/prometheus-alertmanager.json.j2', 'ansible/roles/mongodb/templates/bootstrap_cluster.js.j2', 'ansible/roles/ceph/tasks/upgrade.yml', 'ansible/roles/cloudkitty/templates/cloudkitty.conf.j2', 'ansible/roles/opendaylight/templates/10-rest-connector.xml.j2']",99,d32d8ff75458d1e38b780e73371154009c0763b2,bp/ipv6-control-plane, <websocket-address>{{ 'api' | kolla_address(inventory_hostname) }}</websocket-address>, <websocket-address>{{ hostvars[inventory_hostname]['ansible_' + hostvars[inventory_hostname]['api_interface']]['ipv4']['address'] }}</websocket-address>,344,191
openstack%2Fpuppet-neutron~master~I258402e8033726aa9abf2dc5f801fdf724ab9e3a,openstack/puppet-neutron,master,I258402e8033726aa9abf2dc5f801fdf724ab9e3a,OVN: Add ovn_emit_need_to_frag configuration option,MERGED,2019-10-10 09:43:16.000000000,2019-10-16 18:17:35.000000000,2019-10-16 18:16:11.000000000,"[{'_account_id': 3153}, {'_account_id': 6469}, {'_account_id': 6681}, {'_account_id': 6773}, {'_account_id': 9414}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-10-10 09:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/c5cb8bf5bcd9958e72545cdfffd8911cd7536269', 'message': 'OVN: Add ovn_emit_need_to_frag configuration option\n\nThis patch is adding a new configuration option called\n""ovn_emit_need_to_frag"" to be set in the ""ovn"" section of\netc/neutron/plugins/ml2_conf.ini.\n\nWhen set to True the option tells ovn whether it should emit ""need to\nfrag"" packets in case of MTU mismatch. Before enabling this configuration\nmake sure that its supported by the host kernel (version >= 5.2) or by\nchecking the output of the following command: ovs-appctl -t ovs-vswitchd\ndpif/show-dp-features br-int | grep ""Check pkt length action"". Defaults\nto False.\n\nThis option was intruced by networking-ovn at:\nhttps://review.opendev.org/#/c/671766/\n\nChange-Id: I258402e8033726aa9abf2dc5f801fdf724ab9e3a\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}, {'number': 2, 'created': '2019-10-11 09:10:46.000000000', 'files': ['spec/classes/neutron_plugins_ml2_ovn_spec.rb', 'releasenotes/notes/ovn-emit-need-to-frag-config-option-89c716cd33592bea.yaml', 'manifests/plugins/ml2/ovn.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3478011d64fcf57fa8d034f10621ce48cb5aff88', 'message': 'OVN: Add ovn_emit_need_to_frag configuration option\n\nThis patch is adding a new configuration option called\n""ovn_emit_need_to_frag"" to be set in the ""ovn"" section of\netc/neutron/plugins/ml2_conf.ini.\n\nWhen set to True the option tells ovn whether it should emit ""need to\nfrag"" packets in case of MTU mismatch. Before enabling this configuration\nmake sure that its supported by the host kernel (version >= 5.2) or by\nchecking the output of the following command: ovs-appctl -t ovs-vswitchd\ndpif/show-dp-features br-int | grep ""Check pkt length action"". Defaults\nto False.\n\nThis option was intruced by networking-ovn at:\nhttps://review.opendev.org/#/c/671766/\n\nChange-Id: I258402e8033726aa9abf2dc5f801fdf724ab9e3a\nSigned-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>\n'}]",0,687845,3478011d64fcf57fa8d034f10621ce48cb5aff88,29,11,2,6773,,,0,"OVN: Add ovn_emit_need_to_frag configuration option

This patch is adding a new configuration option called
""ovn_emit_need_to_frag"" to be set in the ""ovn"" section of
etc/neutron/plugins/ml2_conf.ini.

When set to True the option tells ovn whether it should emit ""need to
frag"" packets in case of MTU mismatch. Before enabling this configuration
make sure that its supported by the host kernel (version >= 5.2) or by
checking the output of the following command: ovs-appctl -t ovs-vswitchd
dpif/show-dp-features br-int | grep ""Check pkt length action"". Defaults
to False.

This option was intruced by networking-ovn at:
https://review.opendev.org/#/c/671766/

Change-Id: I258402e8033726aa9abf2dc5f801fdf724ab9e3a
Signed-off-by: Lucas Alvares Gomes <lucasagomes@gmail.com>
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/45/687845/2 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_plugins_ml2_ovn_spec.rb', 'releasenotes/notes/ovn-emit-need-to-frag-config-option-89c716cd33592bea.yaml', 'manifests/plugins/ml2/ovn.pp']",3,c5cb8bf5bcd9958e72545cdfffd8911cd7536269,ovn-need-to-frag,"# # [*ovn_emit_need_to_frag*] # (optional) Configure OVN to emit ""need to frag"" packets in case # of MTU mismatch. Before enabling this configuration make # sure that its supported by the host kernel (version >= # 5.2) or by checking the output of the following command: # ovs-appctl -t ovs-vswitchd dpif/show-dp-features br-int | # grep ""Check pkt length action"". # Type: boolean # Defaults to $::os_service_default $ovn_emit_need_to_frag = $::os_service_default, 'ovn/ovn_emit_need_to_frag' : value => $ovn_emit_need_to_frag;",,25,0
openstack%2Fkeystone~stable%2Frocky~Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,openstack/keystone,stable/rocky,Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,Import LDAP job into project,MERGED,2019-10-15 17:25:50.000000000,2019-10-16 18:07:03.000000000,2019-10-16 18:07:03.000000000,"[{'_account_id': 5046}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:25:50.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/2f7155065456a3142ea05317dd82b370c70a7fdf', 'message': 'Import LDAP job into project\n\nImport the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the\nkeystone repo and convert it to be Zuulv3 native.\n\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver\n\nChange-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda\nNeeded-by: https://review.opendev.org/687444\n(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)\n(cherry picked from commit 0f6c6061b3026dc7a33bffad20848ebd3341af4b)\n(cherry picked from commit 429923fbb3be7229b0c6c1b6136b230d86672bcf)\n'}]",0,688757,2f7155065456a3142ea05317dd82b370c70a7fdf,7,3,1,8482,,,0,"Import LDAP job into project

Import the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the
keystone repo and convert it to be Zuulv3 native.

[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver

Change-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda
Needed-by: https://review.opendev.org/687444
(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)
(cherry picked from commit 0f6c6061b3026dc7a33bffad20848ebd3341af4b)
(cherry picked from commit 429923fbb3be7229b0c6c1b6136b230d86672bcf)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/57/688757/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,2f7155065456a3142ea05317dd82b370c70a7fdf,ldap-zuulv3-stable/rocky,- job: name: keystone-dsvm-ldap-domain-specific-driver parent: devstack-tempest vars: devstack_localrc: KEYSTONE_CLEAR_LDAP: 'yes' LDAP_PASSWORD: 'nomoresecret' USE_PYTHON3: True devstack_services: ldap: true - keystone-dsvm-ldap-domain-specific-driver:, - legacy-tempest-dsvm-ldap-domain-specific-driver:,12,1
openstack%2Fkeystone~stable%2Fstein~Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,openstack/keystone,stable/stein,Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,Import LDAP job into project,MERGED,2019-10-15 17:23:52.000000000,2019-10-16 18:04:34.000000000,2019-10-16 18:00:52.000000000,"[{'_account_id': 5046}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:23:52.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/429923fbb3be7229b0c6c1b6136b230d86672bcf', 'message': 'Import LDAP job into project\n\nImport the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the\nkeystone repo and convert it to be Zuulv3 native.\n\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver\n\nChange-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda\nNeeded-by: https://review.opendev.org/687444\n(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)\n(cherry picked from commit 0f6c6061b3026dc7a33bffad20848ebd3341af4b)\n'}]",0,688756,429923fbb3be7229b0c6c1b6136b230d86672bcf,8,3,1,8482,,,0,"Import LDAP job into project

Import the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the
keystone repo and convert it to be Zuulv3 native.

[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver

Change-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda
Needed-by: https://review.opendev.org/687444
(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)
(cherry picked from commit 0f6c6061b3026dc7a33bffad20848ebd3341af4b)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/56/688756/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,429923fbb3be7229b0c6c1b6136b230d86672bcf,ldap-zuulv3-stable/stein,- job: name: keystone-dsvm-ldap-domain-specific-driver parent: devstack-tempest vars: devstack_localrc: KEYSTONE_CLEAR_LDAP: 'yes' LDAP_PASSWORD: 'nomoresecret' USE_PYTHON3: True devstack_services: ldap: true - keystone-dsvm-ldap-domain-specific-driver:, - legacy-tempest-dsvm-ldap-domain-specific-driver:,12,1
openstack%2Freno~master~I0d74222f711724f3aaccc226a9ec4b5f31cf283e,openstack/reno,master,I0d74222f711724f3aaccc226a9ec4b5f31cf283e,Handle Windows compatibility,MERGED,2019-10-08 17:01:07.000000000,2019-10-16 18:04:04.000000000,2019-10-16 18:02:47.000000000,"[{'_account_id': 308}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-08 17:01:07.000000000', 'files': ['reno/scanner.py'], 'web_link': 'https://opendev.org/openstack/reno/commit/6d35f48c64b1f936be70d29a71300554550fac13', 'message': 'Handle Windows compatibility\n\nSome of the library functions we call for file path handling require the\ncalling code to handle the differences in path separators for Windows.\nThis adds special handling where this was found, though it is possible\nthere are some other code paths that have not been identified yet.\n\nStory: 2006549\nTask: 36632\n\nChange-Id: I0d74222f711724f3aaccc226a9ec4b5f31cf283e\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,687358,6d35f48c64b1f936be70d29a71300554550fac13,8,3,1,11904,,,0,"Handle Windows compatibility

Some of the library functions we call for file path handling require the
calling code to handle the differences in path separators for Windows.
This adds special handling where this was found, though it is possible
there are some other code paths that have not been identified yet.

Story: 2006549
Task: 36632

Change-Id: I0d74222f711724f3aaccc226a9ec4b5f31cf283e
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/reno refs/changes/58/687358/1 && git format-patch -1 --stdout FETCH_HEAD,['reno/scanner.py'],1,6d35f48c64b1f936be70d29a71300554550fac13,windows," if os.path.sep == '\\': subdir = subdir.replace('\\', '/') if os.path.sep == '\\': # Dulwich doesn't handle Windows paths, we need to take care of # it ourselves filename = filename.replace('\\', '/')",,7,0
openstack%2Fopenstack-helm-infra~master~Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce,openstack/openstack-helm-infra,master,Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce,Run mariadb ingress-error-pages container with the nobody user,ABANDONED,2019-04-26 16:35:48.000000000,2019-10-16 18:01:56.000000000,,"[{'_account_id': 7769}, {'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 17896}, {'_account_id': 20466}, {'_account_id': 22259}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22636}, {'_account_id': 23928}, {'_account_id': 24816}, {'_account_id': 26449}, {'_account_id': 28618}]","[{'number': 1, 'created': '2019-04-26 16:35:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e36b1f2294d56230be200e16bf9f937dbd1a188c', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}, {'number': 2, 'created': '2019-08-14 20:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8c5d079cf5e0a1f8bfb7236eabdc7305e648c3b8', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}, {'number': 3, 'created': '2019-08-15 15:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7ba56b2fd0f533d8e82ea6493b0988894bfb4c23', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}, {'number': 4, 'created': '2019-08-23 21:45:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/500c4e23a1042ef60f6631433d005023ae427fee', 'message': 'Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user, by running the\ncontainer with the error-page image [0], from [1] which already\nruns as nobody user.\n\n[0] Dockerfile.404-server-with-metrics\n[1] https://github.com/kubernetes/ingress-gce\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n'}, {'number': 5, 'created': '2019-08-26 21:53:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/8948e4b6b6dac2d1018d3f1524060ea4693f025d', 'message': 'Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user, by running the\ncontainer with the error-page image [0], from [1] which already\nruns as nobody user.\n\n[0] Dockerfile.404-server-with-metrics\n[1] https://github.com/kubernetes/ingress-gce\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n'}, {'number': 6, 'created': '2019-08-27 13:57:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/aa919e884f4ff46b0c2640cbb9938ca3713a8d2d', 'message': 'Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user, by running the\ncontainer with the error-page image [0], from [1] which already\nruns as nobody user.\n\n[0] Dockerfile.404-server-with-metrics\n[1] https://github.com/kubernetes/ingress-gce\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n'}, {'number': 7, 'created': '2019-09-11 19:09:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/7d47104005c99d7b27931ec9598875ac63f218b6', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}, {'number': 8, 'created': '2019-09-11 19:13:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/5e2d266b661c0e43b0f025e810ada484f433b6c3', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}, {'number': 9, 'created': '2019-09-25 16:19:49.000000000', 'files': ['mariadb/templates/bin/_perms_update.tpl', 'mariadb/values.yaml', 'mariadb/templates/configmap-bin.yaml', 'mariadb/templates/bin/_mariadb-ingress-error-pages.sh.tpl', 'mariadb/templates/deployment-error.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9e182d9222a25118585d053331b1740037a364a8', 'message': ""Run mariadb ingress-error-pages container with the nobody user\n\nThis change enables the mariadb ingress-error-pages container to run\nwith the nobody user instead of the root user. For this to be possible,\nthe 'server' file ownership is changed to nobody:nobody, otherwise\na permission denied error arises.\n\nA mariadb-ingress-error-pages-perms init container is used to change the\nownership of the 'server' file and additionally the 'server' file\nis copied into the mounted /tmp volume so that the file ownership\nchange is persisted.\n\nChange-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce\n""}]",14,655950,9e182d9222a25118585d053331b1740037a364a8,40,13,9,17896,,,0,"Run mariadb ingress-error-pages container with the nobody user

This change enables the mariadb ingress-error-pages container to run
with the nobody user instead of the root user. For this to be possible,
the 'server' file ownership is changed to nobody:nobody, otherwise
a permission denied error arises.

A mariadb-ingress-error-pages-perms init container is used to change the
ownership of the 'server' file and additionally the 'server' file
is copied into the mounted /tmp volume so that the file ownership
change is persisted.

Change-Id: Ic61cc04ad9eeb91168e0127db3bd18f8c105c4ce
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/50/655950/2 && git format-patch -1 --stdout FETCH_HEAD,"['mariadb/values.yaml', 'mariadb/templates/bin/_mariadb-ingress-error-pages.sh.tpl', 'mariadb/templates/deployment-error.yaml']",3,e36b1f2294d56230be200e16bf9f937dbd1a188c,mariadb_ingress_errors_non_root," - name: mariadb-ingress-error-pages-perms {{ tuple $envAll ""error_pages"" | include ""helm-toolkit.snippets.image"" | indent 10 }} {{ dict ""envAll"" $envAll ""application"" ""error_pages"" ""container"" ""ingress-error-pages-perms-init"" | include ""helm-toolkit.snippets.kubernetes_container_security_context"" | indent 10 }} {{ tuple $envAll $envAll.Values.pod.resources.error_pages | include ""helm-toolkit.snippets.kubernetes_resources"" | indent 10 }} command: [""/bin/sh"", ""-c""] args: - cp /server /tmp; chown nobody:nobody /tmp/server; volumeMounts: - name: pod-tmp mountPath: /tmp",,16,2
openstack%2Fironic-python-agent~stable%2Ftrain~I4d488e4a1ab680eb1353b158c3339cb30b056ada,openstack/ironic-python-agent,stable/train,I4d488e4a1ab680eb1353b158c3339cb30b056ada,Last resort fallback to find a partition,MERGED,2019-10-16 13:46:23.000000000,2019-10-16 17:58:36.000000000,2019-10-16 17:57:09.000000000,"[{'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-16 13:46:23.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_image.py', 'releasenotes/notes/fallback-to-findfs-59abde55221e1e84.yaml', 'ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7b17a29b6295a6e88c7fb552fcf40a0455f9217c', 'message': ""Last resort fallback to find a partition\n\nFalls back to attempt to use findfs to locate\na UUID or PARTUUID match as opposed to trying to\nlist and enumerate through lsblk output.\n\nCan confirm that tinycore 8.x's findfs binary works\nexpected.\n\nStory: 2006724\nTask: 37141\n\nChange-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada\n(cherry picked from commit 3ee17e86249b8ed6a6060ae4d6f225e85b456a13)\n""}]",0,688931,7b17a29b6295a6e88c7fb552fcf40a0455f9217c,8,4,1,10239,,,0,"Last resort fallback to find a partition

Falls back to attempt to use findfs to locate
a UUID or PARTUUID match as opposed to trying to
list and enumerate through lsblk output.

Can confirm that tinycore 8.x's findfs binary works
expected.

Story: 2006724
Task: 37141

Change-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada
(cherry picked from commit 3ee17e86249b8ed6a6060ae4d6f225e85b456a13)
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/31/688931/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/extensions/test_image.py', 'releasenotes/notes/fallback-to-findfs-59abde55221e1e84.yaml', 'ironic_python_agent/extensions/image.py']",3,7b17a29b6295a6e88c7fb552fcf40a0455f9217c,story/2006419-stable/train," # NOTE(TheJulia): This techincally creates an edge failure # case where a filesystem on a whole block device sans # partitioning would behave differently. # NOTE(TheJulia): We may want to consider moving towards using # findfs in the future, if we're comfortable with the execution # and interaction. There is value in either way though. try: findfs, stderr = utils.execute('findfs', 'UUID=%s' % uuid) return findfs.strip() except processutils.ProcessExecutionError as e: LOG.debug('First fallback detection attempt for locating ' 'partition via UUID %(uuid)s failed. ' 'Error: %(err)s', {'uuid': uuid, 'err': e}) try: findfs, stderr = utils.execute( 'findfs', 'PARTUUID=%s' % uuid) return findfs.strip() except processutils.ProcessExecutionError as e: LOG.debug('Secondary fallback detection attempt for ' 'locating partition via UUID %(uuid)s failed. ' 'Error: %(err)s', {'uuid': uuid, 'err': e})",,64,1
openstack%2Fmanila-ui~stable%2Frocky~I5fb9cef577b109530fde9a4bafe930ea05f3fed8,openstack/manila-ui,stable/rocky,I5fb9cef577b109530fde9a4bafe930ea05f3fed8,Updated to get quotas data for Modify Quotas dialog Share tab,MERGED,2019-10-15 20:23:26.000000000,2019-10-16 17:57:52.000000000,2019-10-16 17:56:26.000000000,"[{'_account_id': 1916}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 11880}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 20:23:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/5c00e9ca2fa536d0d6333e7a480f0158d3e62fc2', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n'}, {'number': 2, 'created': '2019-10-15 21:51:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/3dba20d5490b4f68b307adf235ee48e765623954', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit fb6daa507841b266df89b0261a73728c4fcd0917)\n'}, {'number': 3, 'created': '2019-10-15 21:58:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/fd60b968f2f8644b518f0e9271b36e2e7c65fc10', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)\n(cherry picked from commit fb6daa507841b266df89b0261a73728c4fcd0917)\n'}, {'number': 4, 'created': '2019-10-16 02:10:44.000000000', 'files': ['releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/tests/dashboards/identity/__init__.py', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/bfc45c381aebe6aaf83f0098a21a473a60134bf0', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)\n(cherry picked from commit cc52163a36cd4863ebe96bfef0a163b4190d01b2)\n'}]",1,688813,bfc45c381aebe6aaf83f0098a21a473a60134bf0,20,8,4,14892,,,0,"Updated to get quotas data for Modify Quotas dialog Share tab

Current Modfiy Quotas action of a project in Identity->Projects
for manila ui does not get quotas data for the project. If user
updated quotas for manila ui, the saved data will not be shown
in the Modify Quotas dialog Share tab.

This commit includes:
1) Added a call to get quotas data and also maps the data
fields retuned to the UI data fields.
2) Added unit tests.
3) Added a release note.

Change-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8
Closes-bug: #1842119
Depends-on: https://review.opendev.org/#/c/679513/
(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)
(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)
(cherry picked from commit cc52163a36cd4863ebe96bfef0a163b4190d01b2)
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/13/688813/4 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/tests/dashboards/identity/__init__.py', 'releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py']",7,5c00e9ca2fa536d0d6333e7a480f0158d3e62fc2,bug/1842119-stable/rocky,"import logging from horizon import exceptionsLOG = logging.getLogger(__name__) def prepare_action_context(self, request, context): try: quotas = api_manila.tenant_quota_get( request, context['project_id']) for field in api_manila.MANILA_QUOTA_FIELDS: # Resolve mismatch UI field names and data field names. data_field = api_manila.MANILA_QUOTA_FIELDS_DATA_MAP[field] context[field] = quotas.get(data_field).limit except Exception as ex: LOG.exception(ex) exceptions.handle(request, _('Unable to retrieve share quotas.')) return context ",,137,0
openstack%2Fpuppet-tripleo~stable%2Frocky~I30f03bc8eb81db0243c137d4af08924adeebc951,openstack/puppet-tripleo,stable/rocky,I30f03bc8eb81db0243c137d4af08924adeebc951,Deep merge hiera keys for mysqld_options,MERGED,2019-10-16 06:13:13.000000000,2019-10-16 17:57:16.000000000,2019-10-16 17:54:04.000000000,"[{'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 06:13:13.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/82e304a419698e1243765557b66ee2ebd83d03bc', 'message': ""Deep merge hiera keys for mysqld_options\n\nCurrently when adding some tuning options via hiera, galera won't start because\noverriding even a single mysql option will reset the whole key in the hash. So\nfor example, when adding:\n    tripleo::profile::base::database::mysql::mysql_server_options:\n      mysqld:\n        # MySQL InnoDB equally divided in 1GB instances\n        innodb_buffer_pool_instances: 2\n        # Query network write timeout raised to 120 seconds\n        net_write_timeout: 120\n        # Query network read timeout raised to 120 seconds\n        net_read_timeout: 120\n        # MySQL connection timeout set to 8 hours\n        connect_timeout: 28800\n\nThings will break because all the wsrep options that are set normally will be\noverridden and galera will refuse to start\n\nTested by passing the above hiera keys and observing the deploy complete\nsuccessfully and the settings correctly applied to galera/mysql on the overcloud.\n\nChange-Id: I30f03bc8eb81db0243c137d4af08924adeebc951\nCloses-Bug: #1848060\n(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)\n(cherry picked from commit d12fe87318264c9423e6bc0ac509fa2978261f1c)\n""}]",0,688856,82e304a419698e1243765557b66ee2ebd83d03bc,9,4,1,20172,,,0,"Deep merge hiera keys for mysqld_options

Currently when adding some tuning options via hiera, galera won't start because
overriding even a single mysql option will reset the whole key in the hash. So
for example, when adding:
    tripleo::profile::base::database::mysql::mysql_server_options:
      mysqld:
        # MySQL InnoDB equally divided in 1GB instances
        innodb_buffer_pool_instances: 2
        # Query network write timeout raised to 120 seconds
        net_write_timeout: 120
        # Query network read timeout raised to 120 seconds
        net_read_timeout: 120
        # MySQL connection timeout set to 8 hours
        connect_timeout: 28800

Things will break because all the wsrep options that are set normally will be
overridden and galera will refuse to start

Tested by passing the above hiera keys and observing the deploy complete
successfully and the settings correctly applied to galera/mysql on the overcloud.

Change-Id: I30f03bc8eb81db0243c137d4af08924adeebc951
Closes-Bug: #1848060
(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)
(cherry picked from commit d12fe87318264c9423e6bc0ac509fa2978261f1c)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/56/688856/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,82e304a419698e1243765557b66ee2ebd83d03bc,fix-stable/stein-stable/rocky," $mysqld_options = deep_merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)"," $mysqld_options = merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)",1,1
openstack%2Ftripleo-heat-templates~master~Ibba4273526392985ede6da2ef3fec66a61407777,openstack/tripleo-heat-templates,master,Ibba4273526392985ede6da2ef3fec66a61407777,Add ability to collocate pinned and unpinned instance on same host,MERGED,2019-09-10 10:35:30.000000000,2019-10-16 17:55:58.000000000,2019-10-16 17:54:07.000000000,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 15334}, {'_account_id': 17216}, {'_account_id': 17499}, {'_account_id': 18575}, {'_account_id': 20172}, {'_account_id': 20733}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30133}]","[{'number': 1, 'created': '2019-09-10 10:35:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/98ac1fd3a6aa4b6a1c251d9caa92b9f4b3593e42', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd role parameter `NovaComputeCpuDedicatedSet` which allows to set\n`compute/cpu_dedicated_set` parameter value to specify PCPU resources\nto use for virtual machine processes.\n\nAlso add `NovaSchedulerEnablePinningPolicyTranslation` parameter\nwhich allows to set `scheduler/enable_pinning_policy_translation`\nparamter to enable/disable this feature.\n\nFor new deployments this feature will be enabled by default.\nFor deployments upgrading from Stein, this will be disabled\nbefore upgrade and enabled once all compute nodes are upgraded.\n\nDepends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\nChange-Id: Ibba4273526392985ede6da2ef3fec66a61407777\n'}, {'number': 2, 'created': '2019-09-13 11:19:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/e1f286b769fa08edc37e48c4ac32cf6db73b6bcc', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd role parameter `NovaComputeCpuDedicatedSet` which allows\nto set `compute/cpu_dedicated_set` parameter value to specify\nlist or range of physical CPU cores to reserve for allocating\nPCPU resources to use for virtual machine processes.\n\nDeprecate `NovaVcpuPinSet` option as it is deprecated from config\noptions in nova [1] as well.\n[1] https://review.opendev.org/#/c/671793\n\nDepends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\nChange-Id: Ibba4273526392985ede6da2ef3fec66a61407777\n'}, {'number': 3, 'created': '2019-10-03 05:52:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc90ffe098cc4b80b23879728a02a7cf2de18ab5', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd role parameter `NovaComputeCpuDedicatedSet` which allows\nto set `compute/cpu_dedicated_set` parameter value to specify\nlist or range of physical CPU cores to reserve for allocating\nPCPU resources to use for virtual machine processes.\n\nDeprecate `NovaVcpuPinSet` option as it is deprecated from config\noptions in nova [1] as well.\n[1] https://review.opendev.org/#/c/671793\n\nDepends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\nChange-Id: Ibba4273526392985ede6da2ef3fec66a61407777\n'}, {'number': 4, 'created': '2019-10-03 07:38:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/64bc3cbabd8c861bd96c4f6d47de076fbd9c2266', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd role parameter `NovaComputeCpuDedicatedSet` which allows\nto set `compute/cpu_dedicated_set` parameter value to specify\nlist or range of physical CPU cores to reserve for allocating\nPCPU resources to use for virtual machine processes.\n\nDeprecate `NovaVcpuPinSet` option as it is deprecated from config\noptions in nova [1] as well.\n[1] https://review.opendev.org/#/c/671793\n\nDepends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\nChange-Id: Ibba4273526392985ede6da2ef3fec66a61407777\n'}, {'number': 5, 'created': '2019-10-04 07:55:05.000000000', 'files': ['releasenotes/notes/cpu-resources-f8b511d39c6e0cfe.yaml', 'deployment/nova/nova-compute-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d68e709b2ced797d068e1b1a76aabcf0ea210c3a', 'message': 'Add ability to collocate pinned and unpinned instance on same host\n\nAdd role parameter `NovaComputeCpuDedicatedSet` which allows\nto set `compute/cpu_dedicated_set` parameter value to specify\nlist or range of physical CPU cores to reserve for allocating\nPCPU resources to use for virtual machine processes.\n\nDeprecate `NovaVcpuPinSet` option as it is deprecated from config\noptions in nova [1] as well.\n[1] https://review.opendev.org/#/c/671793\n\nDepends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776\nChange-Id: Ibba4273526392985ede6da2ef3fec66a61407777\n'}]",8,681209,d68e709b2ced797d068e1b1a76aabcf0ea210c3a,44,15,5,20733,,,0,"Add ability to collocate pinned and unpinned instance on same host

Add role parameter `NovaComputeCpuDedicatedSet` which allows
to set `compute/cpu_dedicated_set` parameter value to specify
list or range of physical CPU cores to reserve for allocating
PCPU resources to use for virtual machine processes.

Deprecate `NovaVcpuPinSet` option as it is deprecated from config
options in nova [1] as well.
[1] https://review.opendev.org/#/c/671793

Depends-On: I40e0ed0bba93bfcdc4cf157195c3e9fbcfce0776
Change-Id: Ibba4273526392985ede6da2ef3fec66a61407777
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/09/681209/4 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/nova/nova-compute-container-puppet.yaml', 'environments/lifecycle/upgrade-converge.yaml', 'environments/lifecycle/upgrade-prepare.yaml', 'deployment/nova/nova-scheduler-container-puppet.yaml']",4,98ac1fd3a6aa4b6a1c251d9caa92b9f4b3593e42,bp/cpu-resources, NovaSchedulerEnablePinningPolicyTranslation: default: true description: To enable translation of legacy CPU pinning-related image metadata and flavor extra specs to their placement equivalent. type: boolean nova::scheduler::enable_pinning_policy_translation: {get_param: NovaSchedulerEnablePinningPolicyTranslation},,20,0
openstack%2Fpython-tripleoclient~master~I2dc2420cdf73f47a2a38398235d7297c2f99a8ce,openstack/python-tripleoclient,master,I2dc2420cdf73f47a2a38398235d7297c2f99a8ce,Update master for stable/train,MERGED,2019-10-15 16:19:06.000000000,2019-10-16 17:55:47.000000000,2019-10-16 17:54:10.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 16:19:06.000000000', 'files': ['releasenotes/source/train.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f75f41e968e28882077413cc15f910356edd04bc', 'message': 'Update master for stable/train\n\nAdd file to the reno documentation build to show release notes for\nstable/train.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/train.\n\nChange-Id: I2dc2420cdf73f47a2a38398235d7297c2f99a8ce\nSem-Ver: feature\n'}]",0,688750,f75f41e968e28882077413cc15f910356edd04bc,7,2,1,22816,,,0,"Update master for stable/train

Add file to the reno documentation build to show release notes for
stable/train.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/train.

Change-Id: I2dc2420cdf73f47a2a38398235d7297c2f99a8ce
Sem-Ver: feature
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/50/688750/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/train.rst', 'releasenotes/source/index.rst']",2,f75f41e968e28882077413cc15f910356edd04bc,reno-train, train,,7,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~I67e0a321fe2c77e54966cd9b70be56a489dd2007,openstack/tripleo-heat-templates,stable/rocky,I67e0a321fe2c77e54966cd9b70be56a489dd2007,Remove all old pcmklatest images,MERGED,2019-10-10 15:49:52.000000000,2019-10-16 17:54:05.000000000,2019-10-16 17:54:05.000000000,"[{'_account_id': 6816}, {'_account_id': 8042}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}, {'_account_id': 29222}]","[{'number': 1, 'created': '2019-10-10 15:49:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/b00c7a576caac928e80f1d93b488cf4bb8436761', 'message': 'Remove all old pcmklatest images\n\nAn operator may make a mistake when importing images, resulting\nin more than one image being present. This may happen, for example,\nif an image is imported from one source, then another.\n\nTo ensure that all old images are deleted, and to prevent a failure\nin the command executing the deletion if there is more than one\nresult when listing the images, we process the deletion in a loop\nper stdout line.\n\nCloses: rhbz#1727173\nChange-Id: I67e0a321fe2c77e54966cd9b70be56a489dd2007\n'}, {'number': 2, 'created': '2019-10-10 16:56:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3c675dafe31f4970424c4d430b079ae59f400759', 'message': 'Remove all old pcmklatest images\n\nAn operator may make a mistake when importing images, resulting\nin more than one image being present. This may happen, for example,\nif an image is imported from one source, then another.\n\nTo ensure that all old images are deleted, and to prevent a failure\nin the command executing the deletion if there is more than one\nresult when listing the images, we process the deletion in a loop\nper stdout line.\n\nNote:\nThis patch is not required in more recent branches due to other\nchanges in the process which have eliminated the possibility of\nthere being more than one image to delete.\n\nCloses: rhbz#1727173\nChange-Id: I67e0a321fe2c77e54966cd9b70be56a489dd2007\n'}, {'number': 3, 'created': '2019-10-11 11:16:31.000000000', 'files': ['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/notify-rabbitmq.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml', 'docker/services/pacemaker/ovn-dbs.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/818c7bb118cda9e242aad3bbeb75c02282d7a75d', 'message': 'Remove all old pcmklatest images\n\nAn operator may make a mistake when importing images, resulting\nin more than one image being present. This may happen, for example,\nif an image is imported from one source, then another.\n\nTo ensure that all old images are deleted, and to prevent a failure\nin the command executing the deletion if there is more than one\nresult when listing the images, we process the deletion in a loop\nper stdout line.\n\nNote:\nThis patch is not required in more recent branches due to other\nchanges in the process which have eliminated the possibility of\nthere being more than one image to delete.\n\nCloses: rhbz#1727173\nChange-Id: I67e0a321fe2c77e54966cd9b70be56a489dd2007\n'}]",2,687944,818c7bb118cda9e242aad3bbeb75c02282d7a75d,19,6,3,6816,,,0,"Remove all old pcmklatest images

An operator may make a mistake when importing images, resulting
in more than one image being present. This may happen, for example,
if an image is imported from one source, then another.

To ensure that all old images are deleted, and to prevent a failure
in the command executing the deletion if there is more than one
result when listing the images, we process the deletion in a loop
per stdout line.

Note:
This patch is not required in more recent branches due to other
changes in the process which have eliminated the possibility of
there being more than one image to delete.

Closes: rhbz#1727173
Change-Id: I67e0a321fe2c77e54966cd9b70be56a489dd2007
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/44/687944/3 && git format-patch -1 --stdout FETCH_HEAD,"['docker/services/pacemaker/rabbitmq.yaml', 'docker/services/pacemaker/cinder-volume.yaml', 'docker/services/pacemaker/database/mysql.yaml', 'docker/services/pacemaker/haproxy.yaml', 'docker/services/pacemaker/rpc-rabbitmq.yaml', 'docker/services/pacemaker/database/redis.yaml', 'docker/services/pacemaker/notify-rabbitmq.yaml', 'docker/services/pacemaker/cinder-backup.yaml', 'docker/services/pacemaker/manila-share.yaml', 'docker/services/pacemaker/ovn-dbs.yaml']",10,b00c7a576caac928e80f1d93b488cf4bb8436761,," shell: ""docker rmi -f {{ item }}"" with_items: ""{{ ovn_dbs_image_id.stdout_lines }}"""," shell: ""docker rmi -f {{ovn_dbs_image_id.stdout}}""",20,10
openstack%2Freleases~master~I7212a8e73a852bf89e6f8fb26edef4b91df8a31b,openstack/releases,master,I7212a8e73a852bf89e6f8fb26edef4b91df8a31b,Release os-traits 1.0.0,MERGED,2019-10-16 16:42:51.000000000,2019-10-16 17:52:40.000000000,2019-10-16 17:52:40.000000000,"[{'_account_id': 11564}, {'_account_id': 11904}, {'_account_id': 14070}, {'_account_id': 15334}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 16:42:51.000000000', 'files': ['deliverables/_independent/os-traits.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/adf7e5ef6c3fa4d2bf6ef64995938a6b37d5fa92', 'message': ""Release os-traits 1.0.0\n\nSince [1] made some (theoretically, not realistically) breaking changes,\ndo a major bump. As it happens, we hadn't had an official release of\nos-traits yet, but we're using it quite officially, so this does double\nduty.\n\n[1] https://review.opendev.org/#/c/687378/\n\nChange-Id: I7212a8e73a852bf89e6f8fb26edef4b91df8a31b\n""}]",4,688974,adf7e5ef6c3fa4d2bf6ef64995938a6b37d5fa92,10,5,1,14070,,,0,"Release os-traits 1.0.0

Since [1] made some (theoretically, not realistically) breaking changes,
do a major bump. As it happens, we hadn't had an official release of
os-traits yet, but we're using it quite officially, so this does double
duty.

[1] https://review.opendev.org/#/c/687378/

Change-Id: I7212a8e73a852bf89e6f8fb26edef4b91df8a31b
",git fetch https://review.opendev.org/openstack/releases refs/changes/74/688974/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/_independent/os-traits.yaml'],1,adf7e5ef6c3fa4d2bf6ef64995938a6b37d5fa92,os-traits-1.0.0, - version: 1.0.0 projects: - repo: openstack/os-traits hash: fc685f9e3b3572574d2d80a5efb3f1648ea0b4eb,,4,0
openstack%2Fkeystone~stable%2Ftrain~Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,openstack/keystone,stable/train,Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda,Import LDAP job into project,MERGED,2019-10-14 20:58:56.000000000,2019-10-16 17:43:04.000000000,2019-10-16 17:38:43.000000000,"[{'_account_id': 5046}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-10-14 20:58:56.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/keystone/commit/0f6c6061b3026dc7a33bffad20848ebd3341af4b', 'message': 'Import LDAP job into project\n\nImport the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the\nkeystone repo and convert it to be Zuulv3 native.\n\n[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver\n\nChange-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda\nNeeded-by: https://review.opendev.org/687444\n(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)\n'}]",0,688569,0f6c6061b3026dc7a33bffad20848ebd3341af4b,9,4,1,8482,,,0,"Import LDAP job into project

Import the legacy-tempest-dsvm-ldap-domain-specific-driver job[1] into the
keystone repo and convert it to be Zuulv3 native.

[1] https://opendev.org/openstack/openstack-zuul-jobs/src/branch/master/playbooks/legacy/tempest-dsvm-ldap-domain-specific-driver

Change-Id: Ie0b9f13d6fb06b776d6a58d5d1087c20df8a7cda
Needed-by: https://review.opendev.org/687444
(cherry picked from commit 52ab0cf579445190483f3a6f0e3aa5db0a9ebdef)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/69/688569/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,0f6c6061b3026dc7a33bffad20848ebd3341af4b,ldap-zuulv3-stable/train,- job: name: keystone-dsvm-ldap-domain-specific-driver parent: devstack-tempest vars: devstack_localrc: KEYSTONE_CLEAR_LDAP: 'yes' LDAP_PASSWORD: 'nomoresecret' USE_PYTHON3: True devstack_services: ldap: true - keystone-dsvm-ldap-domain-specific-driver:, - legacy-tempest-dsvm-ldap-domain-specific-driver:,12,1
openstack%2Fopenstack-helm-infra~master~I61071d19ec89f22d50417c80ceccb1be58f89e70,openstack/openstack-helm-infra,master,I61071d19ec89f22d50417c80ceccb1be58f89e70,[WIP] Remove code from Selenium Test Refactor,ABANDONED,2019-10-15 21:32:59.000000000,2019-10-16 17:34:09.000000000,,"[{'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 28849}, {'_account_id': 30777}]","[{'number': 1, 'created': '2019-10-15 21:32:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/9136e16ec2dcea72a929b16ebabdf7cfbacb4f0e', 'message': '[WIP] Remove code from Selenium Test Refactor\n\nThis change would further refactor the Selenium Tests\nin order to move boilerplate code to separate file.\n\nChange-Id: I61071d19ec89f22d50417c80ceccb1be58f89e70\n'}, {'number': 2, 'created': '2019-10-15 21:39:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/19679f54d3b93bcb267deb97b9364af6de3b332b', 'message': '[WIP] Remove code from Selenium Test Refactor\n\nThis change would further refactor the Selenium Tests\nin order to move boilerplate code to separate file.\n\nChange-Id: I61071d19ec89f22d50417c80ceccb1be58f89e70\n'}, {'number': 3, 'created': '2019-10-16 13:36:39.000000000', 'files': ['tools/gate/selenium/prometheusSelenium.py', 'tools/gate/selenium/nagiosSelenium.py', 'tools/gate/selenium/kibanaSelenium.py', 'tools/gate/selenium/seleniumtester.py', 'tools/gate/selenium/grafanaSelenium.py'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/e75fc609681bef8a10a3e992a6af0e0232e9267f', 'message': '[WIP] Remove code from Selenium Test Refactor\n\nThis change would further refactor the Selenium Tests\nin order to move boilerplate code to separate file.\n\nChange-Id: I61071d19ec89f22d50417c80ceccb1be58f89e70\n'}]",4,688819,e75fc609681bef8a10a3e992a6af0e0232e9267f,10,4,3,30777,,,0,"[WIP] Remove code from Selenium Test Refactor

This change would further refactor the Selenium Tests
in order to move boilerplate code to separate file.

Change-Id: I61071d19ec89f22d50417c80ceccb1be58f89e70
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/19/688819/2 && git format-patch -1 --stdout FETCH_HEAD,"['tools/gate/selenium/prometheusSelenium.py', 'tools/gate/selenium/kibanaSelenium.py', 'tools/gate/selenium/nagiosSelenium.py', 'tools/gate/selenium/seleniumtester.py', 'tools/gate/selenium/grafanaSelenium.py']",5,9136e16ec2dcea72a929b16ebabdf7cfbacb4f0e,selenium-refactor-refactor,"from seleniumtester import SeleniumTester st = SeleniumTester('Grafana') username = st.get_variable('GRAFANA_USER') password = st.get_variable('GRAFANA_PASSWORD') grafana_uri = st.get_variable('GRAFANA_URI') st.logger.info('Attempting to connect to Grafana') st.browser.get(grafana_url) el = WebDriverWait(st.browser, 15).until( st.logger.info('Connected to Grafana') except TimeoutException: st.logger.critical('Timed out waiting to connect to Grafana') st.browser.quit() st.logger.info('Attempting to login to Grafana') st.browser.find_element_by_name('username').send_keys(username) st.browser.find_element_by_name('password').send_keys(password) st.browser.find_element_by_css_selector( st.logger.info(""Successfully logged in to Grafana"") except NoSuchElementException: st.logger.error(""Failed to log in to Grafana"") st.browser.quit() st.logger.info('Attempting to visit Nodes dashboard') st.click_link_by_name('Home') st.click_link_by_name('Nodes') el = WebDriverWait(st.browser, 15).until( st.take_screenshot('Grafana Nodes') except TimeoutException: st.logger.error('Failed to load Nodes dashboard') st.browser.quit() st.logger.info('Attempting to visit Cluster Status dashboard') st.click_link_by_name('Nodes') st.click_link_by_name('Kubernetes Cluster Status') el = WebDriverWait(st.browser, 15).until( st.take_screenshot('Grafana Cluster Status') except TimeoutException: st.logger.error('Failed to load Cluster Status dashboard') st.browser.quit()st.browser.quit()","import logging import osfrom selenium import webdriverfrom selenium.webdriver.chrome.options import Optionsfrom selenium.common.exceptions import ScreenshotException # Create logger, console handler and formatter logger = logging.getLogger('Grafana Selenium Tests') logger.setLevel(logging.DEBUG) ch = logging.StreamHandler() ch.setLevel(logging.DEBUG) formatter = logging.Formatter( '%(asctime)s - %(name)s - %(levelname)s - %(message)s' ) # Set the formatter and add the handler ch.setFormatter(formatter) logger.addHandler(ch) def get_variable(env_var): if env_var in os.environ: logger.info('Found ""{}""'.format(env_var)) return os.environ[env_var] else: logger.critical('Variable ""{}"" is not defined!'.format(env_var)) sys.exit(1) def click_link_by_name(link_name): try: el = WebDriverWait(browser, 15).until( EC.presence_of_element_located((By.LINK_TEXT, link_name)) ) logger.info(""Clicking '{}' link"".format(link_name)) link = browser.find_element_by_link_text(link_name) link.click() except (TimeoutException, NoSuchElementException): logger.error(""Failed clicking '{}' link"".format(link_name)) browser.quit() sys.exit(1) def take_screenshot(page_name, artifacts_dir='/tmp/artifacts/'): file_name = page_name.replace(' ','_') try: el = WebDriverWait(browser, 15) browser.save_screenshot('{}{}.png'.format(artifacts_dir,file_name)) logger.info(""Successfully captured {} screenshot"".format(page_name)) except ScreenshotException: logger.error(""Failed to capture {} screenshot"".format(page_name)) browser.quit() sys.exit(1) artifacts_dir = get_variable('ARTIFACTS_DIR') if artifacts_dir and not os.path.exists(artifacts_dir): os.makedirs(artifacts_dir) logger.info('Created {} for test artifacts'.format(artifacts_dir)) chrome_driver = get_variable('CHROMEDRIVER') options = Options() options.add_argument('--headless') options.add_argument('--no-sandbox') options.add_argument('--window-size=1920x1080') browser = webdriver.Chrome(chrome_driver, chrome_options=options) username = get_variable('GRAFANA_USER') password = get_variable('GRAFANA_PASSWORD') grafana_uri = get_variable('GRAFANA_URI') logger.info('Attempting to connect to Grafana') browser.get(grafana_url) el = WebDriverWait(browser, 15).until( logger.info('Connected to Grafana') except TimeoutException: logger.critical('Timed out waiting to connect to Grafana') browser.quit() logger.info('Attempting to login to Grafana') browser.find_element_by_name('username').send_keys(username) browser.find_element_by_name('password').send_keys(password) browser.find_element_by_css_selector( logger.info(""Successfully logged in to Grafana"") except NoSuchElementException: logger.error(""Failed to log in to Grafana"") browser.quit() logger.info('Attempting to visit Nodes dashboard') click_link_by_name('Home') click_link_by_name('Nodes') el = WebDriverWait(browser, 15).until( take_screenshot('Grafana Nodes', artifacts_dir) except TimeoutException: logger.error('Failed to load Nodes dashboard') browser.quit() logger.info('Attempting to visit Cluster Status dashboard') click_link_by_name('Nodes') click_link_by_name('Kubernetes Cluster Status') el = WebDriverWait(browser, 15).until( take_screenshot('Grafana Cluster Status', artifacts_dir) except TimeoutException: logger.error('Failed to load Cluster Status dashboard') browser.quit()browser.quit()",205,337
openstack%2Fironic-python-agent-builder~master~Ia0e3897ba414827fb81ba7ca7367e86899ea455a,openstack/ironic-python-agent-builder,master,Ia0e3897ba414827fb81ba7ca7367e86899ea455a,Allow changing DIB_RELEASE and add a job with CentOS 8,MERGED,2019-10-15 09:33:45.000000000,2019-10-16 17:26:50.000000000,2019-10-16 17:23:37.000000000,"[{'_account_id': 10239}, {'_account_id': 11655}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-15 09:33:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/78fc49a53fc12a1b69401d50a868b1816afc3f99', 'message': 'Add a non-voting job with CentOS 8\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 2, 'created': '2019-10-15 09:57:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/d7dba6eb8d34fe967c9ec2afd58c2be8eb94ba71', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nAdds explicit DIB_RELEASE for CentOS 7, which is not strictly required,\nbut will simplify the switch to a generic centos element later on.\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 3, 'created': '2019-10-15 10:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/b00353231698d87d1ce47e7a468b7a99b7af2f65', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nAdds explicit DIB_RELEASE for CentOS 7, which is not strictly required,\nbut will simplify the switch to a generic centos element later on.\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 4, 'created': '2019-10-15 12:10:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/76c66f7eefcda44c1e137d02cd79aee734d54819', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nAdds explicit DIB_RELEASE for CentOS 7, which is not strictly required,\nbut will simplify the switch to a generic centos element later on.\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 5, 'created': '2019-10-15 12:13:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/875e928e543223c43ae84ebd63b72e8f4dbbf983', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nAdds explicit DIB_RELEASE for CentOS 7, which is not strictly required,\nbut will simplify the switch to a generic centos element later on.\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 6, 'created': '2019-10-15 13:17:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/5ef0042085c3744ec587453df8a00e3a2360d497', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 7, 'created': '2019-10-15 16:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/062b09674ee0c355602f0ecce9d94c664c91b7c3', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 8, 'created': '2019-10-16 09:20:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/b67924e2936791d7f0b00db841df46c31b090586', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}, {'number': 9, 'created': '2019-10-16 13:10:35.000000000', 'files': ['ironic_python_agent_builder/__init__.py', 'roles/ipa-build-dib-image/tasks/main.yaml', '.zuul.yaml', 'roles/ipa-build-dib-image/defaults/main.yaml', 'dib/ironic-python-agent-ramdisk/pkg-map'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/3be5066aa9441046ed3d0f94d2db1b61c08d02b4', 'message': 'Allow changing DIB_RELEASE and add a job with CentOS 8\n\nChange-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a\n'}]",3,688661,3be5066aa9441046ed3d0f94d2db1b61c08d02b4,23,4,9,10239,,,0,"Allow changing DIB_RELEASE and add a job with CentOS 8

Change-Id: Ia0e3897ba414827fb81ba7ca7367e86899ea455a
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/61/688661/9 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,78fc49a53fc12a1b69401d50a868b1816afc3f99,centos8, name: ironic-python-agent-check-image-dib-centos8 parent: ironic-python-agent-check-image-base required-projects: # NOTE(dtantsur): used for bindep only - openstack/diskimage-builder vars: image_type: 'dib' image_distro: 'centos8' - job: - ironic-python-agent-check-image-dib-centos8: voting: false,,12,0
openstack%2Frequirements~stable%2Ftrain~I8b2ffb22d937fb6f9b1209c92bfcd36ce8c543bf,openstack/requirements,stable/train,I8b2ffb22d937fb6f9b1209c92bfcd36ce8c543bf,update constraint for ceilometer to new release 13.0.0,MERGED,2019-10-16 12:51:28.000000000,2019-10-16 17:11:11.000000000,2019-10-16 17:11:10.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 12:51:28.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/5d2dc701ab2fe7e87d78e4d96eb444766eef6725', 'message': 'update constraint for ceilometer to new release 13.0.0\n\nChange-Id: I8b2ffb22d937fb6f9b1209c92bfcd36ce8c543bf\nmeta:version: 13.0.0\nmeta:diff-start: 12.0.0\nmeta:series: train\nmeta:release-type: release\nmeta:pypi: no\nmeta:first: yes\nmeta:release:Author: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Change-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834\nmeta:release:Code-Review+1: Andrey Pavlov <andrey.mp@gmail.com>\nmeta:release:Code-Review+1: Pierre Riteau <pierre@stackhpc.com>\nmeta:release:Code-Review+1: Eric Fried <openstack@fried.cc>\nmeta:release:Code-Review+1: Douglas Mendizábal <dmendiza@redhat.com>\nmeta:release:Code-Review+1: Lucian Petrut <lpetrut@cloudbasesolutions.com>\nmeta:release:Code-Review+1: Jay Bryant <jungleboyj@electronicjungle.net>\nmeta:release:Code-Review+1: Goutham Pacha Ravi <gouthampravi@gmail.com>\nmeta:release:Code-Review+1: Nicolas Bock <nicolasbock@gmail.com>\nmeta:release:Code-Review+1: Claudiu Belu <cbelu@cloudbasesolutions.com>\nmeta:release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>\nmeta:release:Code-Review+1: Michael Johnson <johnsomor@gmail.com>\nmeta:release:Code-Review+1: Jeremy Freudberg <jeremyfreudberg@gmail.com>\nmeta:release:Code-Review+1: Sundar Nadathur <sundar.nadathur@intel.com>\nmeta:release:Code-Review+1: Ivan Kolodyazhny <e0ne@e0ne.info>\nmeta:release:Code-Review+1: Colleen Murphy <colleen@gazlene.net>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Code-Review+1: licanwei <li.canwei2@zte.com.cn>\nmeta:release:Code-Review+1: Brin Zhang <zhangbailin@inspur.com>\nmeta:release:Code-Review+1: Slawek Kaplonski <skaplons@redhat.com>\nmeta:release:Code-Review+1: dharmendra kushwaha <dharmendra.kushwaha@gmail.com>\nmeta:release:Code-Review+1: Luka Peschke <luka.peschke@objectif-libre.com>\nmeta:release:Code-Review+1: Carlos Goncalves <cgoncalves@redhat.com>\nmeta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,688921,5d2dc701ab2fe7e87d78e4d96eb444766eef6725,6,2,1,11131,,,0,"update constraint for ceilometer to new release 13.0.0

Change-Id: I8b2ffb22d937fb6f9b1209c92bfcd36ce8c543bf
meta:version: 13.0.0
meta:diff-start: 12.0.0
meta:series: train
meta:release-type: release
meta:pypi: no
meta:first: yes
meta:release:Author: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Commit: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Change-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834
meta:release:Code-Review+1: Andrey Pavlov <andrey.mp@gmail.com>
meta:release:Code-Review+1: Pierre Riteau <pierre@stackhpc.com>
meta:release:Code-Review+1: Eric Fried <openstack@fried.cc>
meta:release:Code-Review+1: Douglas Mendizábal <dmendiza@redhat.com>
meta:release:Code-Review+1: Lucian Petrut <lpetrut@cloudbasesolutions.com>
meta:release:Code-Review+1: Jay Bryant <jungleboyj@electronicjungle.net>
meta:release:Code-Review+1: Goutham Pacha Ravi <gouthampravi@gmail.com>
meta:release:Code-Review+1: Nicolas Bock <nicolasbock@gmail.com>
meta:release:Code-Review+1: Claudiu Belu <cbelu@cloudbasesolutions.com>
meta:release:Code-Review+1: Akihiro Motoki <amotoki@gmail.com>
meta:release:Code-Review+1: Michael Johnson <johnsomor@gmail.com>
meta:release:Code-Review+1: Jeremy Freudberg <jeremyfreudberg@gmail.com>
meta:release:Code-Review+1: Sundar Nadathur <sundar.nadathur@intel.com>
meta:release:Code-Review+1: Ivan Kolodyazhny <e0ne@e0ne.info>
meta:release:Code-Review+1: Colleen Murphy <colleen@gazlene.net>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Code-Review+1: licanwei <li.canwei2@zte.com.cn>
meta:release:Code-Review+1: Brin Zhang <zhangbailin@inspur.com>
meta:release:Code-Review+1: Slawek Kaplonski <skaplons@redhat.com>
meta:release:Code-Review+1: dharmendra kushwaha <dharmendra.kushwaha@gmail.com>
meta:release:Code-Review+1: Luka Peschke <luka.peschke@objectif-libre.com>
meta:release:Code-Review+1: Carlos Goncalves <cgoncalves@redhat.com>
meta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta:release:Code-Review+1: Chris Dent <cdent@anticdent.org>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/21/688921/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,5d2dc701ab2fe7e87d78e4d96eb444766eef6725,new-release,ceilometer===13.0.0,ceilometer===13.0.0.0rc2,1,1
openstack%2Fpaunch~stable%2Fstein~I00d037100adbe1c052b64f244d852d46625aa9aa,openstack/paunch,stable/stein,I00d037100adbe1c052b64f244d852d46625aa9aa,Use k8s-file log driver with podman,MERGED,2019-10-15 13:06:28.000000000,2019-10-16 17:04:14.000000000,2019-10-16 17:03:12.000000000,"[{'_account_id': 3153}, {'_account_id': 8161}, {'_account_id': 8833}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-15 13:06:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/3e6090bdc04f6180272d22b554d847bf7f74f14d', 'message': 'Use k8s-file log driver with podman\n\nAs suggested in https://github.com/containers/libpod/issues/3363\n\nChange-Id: I00d037100adbe1c052b64f244d852d46625aa9aa\nDepends-On: https://review.opendev.org/666220\n'}, {'number': 2, 'created': '2019-10-15 13:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/paunch/commit/2dd68e5eb26fa8c2f44bb38ed13c17d912c18ad7', 'message': 'Use k8s-file log driver with podman\n\nAs suggested in https://github.com/containers/libpod/issues/3363\n\nChange-Id: I00d037100adbe1c052b64f244d852d46625aa9aa\nDepends-On: https://review.opendev.org/666220\n(cherry picked from commit 3e6090bdc04f6180272d22b554d847bf7f74f14d)\n'}, {'number': 3, 'created': '2019-10-15 13:47:12.000000000', 'files': ['paunch/builder/podman.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/faed0cf419dfdae485e17144512b6e62f7bf2251', 'message': 'Use k8s-file log driver with podman\n\nAs suggested in https://github.com/containers/libpod/issues/3363\n\nChange-Id: I00d037100adbe1c052b64f244d852d46625aa9aa\nDepends-On: https://review.opendev.org/666220\n(cherry picked from commit d1eef2930ea2ac3610c9c32d3ab172ddbecf665d)\n'}]",0,688705,faed0cf419dfdae485e17144512b6e62f7bf2251,16,6,3,28223,,,0,"Use k8s-file log driver with podman

As suggested in https://github.com/containers/libpod/issues/3363

Change-Id: I00d037100adbe1c052b64f244d852d46625aa9aa
Depends-On: https://review.opendev.org/666220
(cherry picked from commit d1eef2930ea2ac3610c9c32d3ab172ddbecf665d)
",git fetch https://review.opendev.org/openstack/paunch refs/changes/05/688705/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/builder/podman.py'],1,3e6090bdc04f6180272d22b554d847bf7f74f14d,," logging = ['--log-driver', 'k8s-file',"," logging = ['--log-driver', 'json-file',",1,1
openstack%2Ftripleo-heat-templates~stable%2Fstein~I3891da45e665727ab6d767514f9d24cb06da6b50,openstack/tripleo-heat-templates,stable/stein,I3891da45e665727ab6d767514f9d24cb06da6b50,Podman 1.4.1 drops json-file in favor of k8s-file,MERGED,2019-10-15 13:02:31.000000000,2019-10-16 17:03:13.000000000,2019-10-16 17:03:13.000000000,"[{'_account_id': 3153}, {'_account_id': 8161}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-15 13:02:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/3dfde2d28ccc99a78acd508285031dd97fc4e014', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/666223\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n(cherry picked from commit 55e1eac8920c8ecb987bcc6b6edeb723956fd40c)\n'}, {'number': 2, 'created': '2019-10-15 14:00:15.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/810fe0676490c7c5fb22926348427b01b6b1ce0e', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/688705\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n(cherry picked from commit 55e1eac8920c8ecb987bcc6b6edeb723956fd40c)\n'}]",0,688703,810fe0676490c7c5fb22926348427b01b6b1ce0e,12,5,2,28223,,,0,"Podman 1.4.1 drops json-file in favor of k8s-file

While this new name makes more sense than the ""json-file"" which wasn't a
json, it breaks podman invocations[0] in TripleO.

Also, moved the configuration snipped to the podman dedicated block,
since docker doesn't have that driver[1].

[0] https://github.com/containers/libpod/issues/3363
[1] https://docs.docker.com/config/containers/logging/configure/

Depends-On: https://review.opendev.org/688705
Change-Id: I3891da45e665727ab6d767514f9d24cb06da6b50
(cherry picked from commit 55e1eac8920c8ecb987bcc6b6edeb723956fd40c)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/03/688703/1 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,3dfde2d28ccc99a78acd508285031dd97fc4e014,container-puppet/logging-stable/stein," logging = ['--log-driver', 'k8s-file', '--log-opt',"," '--log-driver', 'json-file', logging = ['--log-opt',",2,2
openstack%2Ftripleo-heat-templates~master~I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f,openstack/tripleo-heat-templates,master,I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f,Add missing step tag in updates/upgrades/ffu tasks,MERGED,2019-10-11 09:48:52.000000000,2019-10-16 17:02:49.000000000,2019-10-16 17:02:49.000000000,"[{'_account_id': 7144}, {'_account_id': 8042}, {'_account_id': 11090}, {'_account_id': 11166}, {'_account_id': 20775}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26343}]","[{'number': 1, 'created': '2019-10-11 09:48:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0ecde007f5e93d917ef648fdff98886b661a1501', 'message': 'Add missing step tag in ffu tasks\n\nWe are missing some step tags in ffu tasks\nto make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n'}, {'number': 2, 'created': '2019-10-11 16:04:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6f7d5000b7248d9d26c360726878a31d7632c604', 'message': 'Add missing step tag in ffu tasks\n\nWe are missing some step tags in ffu tasks\nto make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n'}, {'number': 3, 'created': '2019-10-11 16:25:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/bb09cd2f2471f8fb1a0dc3b8b949102e208ee952', 'message': 'Add missing step tag in ffu tasks\n\nWe are missing some step tags in ffu tasks\nto make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n'}, {'number': 4, 'created': '2019-10-11 18:08:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/c7aa2f994f0cd1600257e5acaaf2a3a8f15a3381', 'message': 'Add missing step tag in ffu tasks\n\nWe are missing some step tags in ffu tasks\nto make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n'}, {'number': 5, 'created': '2019-10-14 14:48:38.000000000', 'files': ['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml', 'deployment/haproxy/haproxy-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/af1e393e07dc595db72c26b330955cc60a36f922', 'message': 'Add missing step tag in updates/upgrades/ffu tasks\n\nWe are missing some step tags in updates/upgrades/ffu\ntasks to make the Ansible lint check to work.\n\nChange-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f\n'}]",2,688092,af1e393e07dc595db72c26b330955cc60a36f922,21,8,5,20775,,,0,"Add missing step tag in updates/upgrades/ffu tasks

We are missing some step tags in updates/upgrades/ffu
tasks to make the Ansible lint check to work.

Change-Id: I7eb07d6b0b3738c63184ab5b900bbf1b2d62da8f
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/92/688092/4 && git format-patch -1 --stdout FETCH_HEAD,['deployment/tripleo-packages/tripleo-packages-baremetal-puppet.yaml'],1,0ecde007f5e93d917ef648fdff98886b661a1501,ansible-syntax-check, when: step|int == 3 when: step|int == 3 when: step|int == 3 - step|int == 3 - step|int == 3,,5,0
openstack%2Fproject-config~master~Icb9e9c6f9c61de406b9e010d66160a5c1d75b61b,openstack/project-config,master,Icb9e9c6f9c61de406b9e010d66160a5c1d75b61b,New charms & interfaces for MySQL8,MERGED,2019-10-11 21:40:46.000000000,2019-10-16 17:00:38.000000000,2019-10-16 17:00:38.000000000,"[{'_account_id': 1}, {'_account_id': 935}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 21:40:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/6d02c49656744833b7360b6a13be9fa673fef102', 'message': 'New charms & interfaces for MySQL8\n\nAdd mysql-router and mysql-innodb-cluster charms for clustering with\nMySQL 8. Also add interfaces for both charms.\n\nChange-Id: Icb9e9c6f9c61de406b9e010d66160a5c1d75b61b\n'}, {'number': 2, 'created': '2019-10-11 21:42:27.000000000', 'files': ['zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/595faee589283ab4c3bc5b6e40d833aa92e9ba65', 'message': 'New charms & interfaces for MySQL8\n\nAdd mysql-router and mysql-innodb-cluster charms for clustering with\nMySQL 8. Also add interfaces for both charms.\n\nNeeded-By: Id3e0516c838efd653834aeeed8fbe3a40dcaabc4\nChange-Id: Icb9e9c6f9c61de406b9e010d66160a5c1d75b61b\n'}]",0,688209,595faee589283ab4c3bc5b6e40d833aa92e9ba65,9,4,2,20805,,,0,"New charms & interfaces for MySQL8

Add mysql-router and mysql-innodb-cluster charms for clustering with
MySQL 8. Also add interfaces for both charms.

Needed-By: Id3e0516c838efd653834aeeed8fbe3a40dcaabc4
Change-Id: Icb9e9c6f9c61de406b9e010d66160a5c1d75b61b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/09/688209/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerrit/projects.yaml', 'zuul/main.yaml']",2,6d02c49656744833b7360b6a13be9fa673fef102,new-project, - openstack/charm-interface-mysql-innodb-cluster - openstack/charm-interface-mysql-router - openstack/charm-mysql-innodb-cluster - openstack/charm-mysql-router,,24,0
openstack%2Foctavia~master~If2a732d7b692f3cd6c422efbb1f71103ffecc4c9,openstack/octavia,master,If2a732d7b692f3cd6c422efbb1f71103ffecc4c9,Add backend re-encryption to the LB cookbook,MERGED,2019-10-15 22:01:11.000000000,2019-10-16 16:51:29.000000000,2019-10-16 16:49:13.000000000,"[{'_account_id': 6469}, {'_account_id': 10850}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 22:01:11.000000000', 'files': ['doc/source/user/guides/basic-cookbook.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/076c3adc36380113f16561280bcec6aed50a628a', 'message': 'Add backend re-encryption to the LB cookbook\n\nThis patch adds a cookbook section for creating backend re-encryption\npools with optional client authentication.\n\nChange-Id: If2a732d7b692f3cd6c422efbb1f71103ffecc4c9\n'}]",0,688824,076c3adc36380113f16561280bcec6aed50a628a,8,3,1,11628,,,0,"Add backend re-encryption to the LB cookbook

This patch adds a cookbook section for creating backend re-encryption
pools with optional client authentication.

Change-Id: If2a732d7b692f3cd6c422efbb1f71103ffecc4c9
",git fetch https://review.opendev.org/openstack/octavia refs/changes/24/688824/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/guides/basic-cookbook.rst'],1,076c3adc36380113f16561280bcec6aed50a628a,,"Deploy a load balancer with backend re-encryption ------------------------------------------------- This example will demostrate how to enable TLS encryption from the load balancer to the backend member servers. Typically this is used with TLS termination enabled on the listener, but, to simplify the example, we are going to use an unencrypted HTTP listener. For information on setting up a TLS terminated listener, see the above section :ref:`basic-tls-terminated-listener`. **Scenario description**: * Back-end servers 192.0.2.10 and 192.0.2.11 on subnet *private-subnet* have been configured with an HTTPS application on TCP port 443. * A Certificate Authority (CA) certificate chain and optional Certificate Revocation List (CRL) have been obtained from an external certificate authority to authenticate member server certificates against. * Subnet *public-subnet* is a shared external subnet created by the cloud operator which is reachable from the internet. * We want to configure a basic load balancer that is accessible from the internet, which distributes web requests to the back-end servers. **Solution**: 1. Create a barbican *secret* resource for the member CA certificate. We will call this *member_ca_cert*. 2. Optionally create a barbican *secret* for the CRL file. We will call this *member_ca_crl*. 3. Create load balancer *lb1* on subnet *public-subnet*. 4. Create listener *listener1*. 5. Create pool *pool1* as *listener1*'s default pool, that is TLS enabled, with a Certificate Authority (CA) certificate chain *member_ca_cert* to validate the member server certificate, and a Certificate Revocation List (CRL) *member_ca_crl* to check the member server certificate against. 6. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*. **CLI commands**: :: openstack secret store --name='member_ca_cert' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < member_ca.pem)"" openstack secret store --name='member_ca_crl' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < member_ca.crl)"" openstack loadbalancer create --name lb1 --vip-subnet-id public-subnet # Re-run the following until lb1 shows ACTIVE and ONLINE statuses: openstack loadbalancer show lb1 openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1 openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP --enable-tls --ca-tls-container-ref $(openstack secret list | awk '/ member_ca_cert / {print $2}') --crl-container-ref $(openstack secret list | awk '/ member_ca_crl / {print $2}') openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.10 --protocol-port 443 pool1 openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.11 --protocol-port 443 pool1 Deploy a load balancer with backend re-encryption and client authentication --------------------------------------------------------------------------- This example will demostrate how to enable TLS encryption from the load balancer to the backend member servers with the load balancer being authenticated using TLS client authentication. Typically this is used with TLS termination enabled on the listener, but, to simplify the example, we are going to use an unencrypted HTTP listener. For information on setting up a TLS terminated listener, see the above section :ref:`basic-tls-terminated-listener`. **Scenario description**: * Back-end servers 192.0.2.10 and 192.0.2.11 on subnet *private-subnet* have been configured with an HTTPS application on TCP port 443. * A Certificate Authority (CA) certificate chain and optional Certificate Revocation List (CRL) have been obtained from an external certificate authority to authenticate member server certificates against. * A TLS certificate and key have been obtained from an external Certificate Authority (CA). The now exist in the files member.crt and member.key. The key and certificate are PEM-encoded and the key is not encrypted with a passphrase (for this example). * Subnet *public-subnet* is a shared external subnet created by the cloud operator which is reachable from the internet. * We want to configure a basic load balancer that is accessible from the internet, which distributes web requests to the back-end servers. **Solution**: 1. Combine the member client authentication certificate and key to a single PKCS12 file. 2. Create a barbican *secret* resource for the PKCS12 file. We will call this *member_secret1*. 3. Create a barbican *secret* resource for the member CA certificate. We will call this *member_ca_cert*. 4. Optionally create a barbican *secret* for the CRL file. We will call this *member_ca_crl*. 5. Create load balancer *lb1* on subnet *public-subnet*. 6. Create listener *listener1*. 7. Create pool *pool1* as *listener1*'s default pool, that is TLS enabled, with a TLS container reference for the member client authentication key and certificate pkcs12, also with a Certificate Authority (CA) certificate chain *member_ca_cert* to validate the member server certificate, and a Certificate Revocation List (CRL) *member_ca_crl* to check the member server certificate against. 8. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*. **CLI commands**: :: openssl pkcs12 -export -inkey member.key -in member.crt -passout pass: -out member.p12 openstack secret store --name='member_secret1' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < member.p12)"" openstack secret store --name='member_ca_cert' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < member_ca.pem)"" openstack secret store --name='member_ca_crl' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < member_ca.crl)"" openstack loadbalancer create --name lb1 --vip-subnet-id public-subnet # Re-run the following until lb1 shows ACTIVE and ONLINE statuses: openstack loadbalancer show lb1 openstack loadbalancer listener create --name listener1 --protocol HTTP --protocol-port 80 lb1 openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP --enable-tls --ca-tls-container-ref $(openstack secret list | awk '/ member_ca_cert / {print $2}') --crl-container-ref $(openstack secret list | awk '/ member_ca_crl / {print $2}') --tls-container-ref $(openstack secret list | awk '/ member_secret1 / {print $2}') openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.10 --protocol-port 443 pool1 openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.11 --protocol-port 443 pool1",,110,0
openstack%2Fkolla~stable%2Fstein~I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,openstack/kolla,stable/stein,I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,CI: pep8: Fix yamllint error on .yamllint,MERGED,2019-10-16 08:05:57.000000000,2019-10-16 16:50:58.000000000,2019-10-16 16:49:04.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 08:05:57.000000000', 'files': ['.yamllint'], 'web_link': 'https://opendev.org/openstack/kolla/commit/dabf34c9901b7e213621e3e7adf9296ed38f9142', 'message': 'CI: pep8: Fix yamllint error on .yamllint\n\nChange-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n(cherry picked from commit 88d26e52d350683f4407191ccb196a203167e756)\n'}]",0,688871,dabf34c9901b7e213621e3e7adf9296ed38f9142,8,3,1,14826,,,0,"CI: pep8: Fix yamllint error on .yamllint

Change-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486
Signed-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>
(cherry picked from commit 88d26e52d350683f4407191ccb196a203167e756)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/71/688871/1 && git format-patch -1 --stdout FETCH_HEAD,['.yamllint'],1,dabf34c9901b7e213621e3e7adf9296ed38f9142,,---,,1,0
openstack%2Fkolla~master~If63fb782c3b3da8301610e80bd3b2cfeadc301cc,openstack/kolla,master,If63fb782c3b3da8301610e80bd3b2cfeadc301cc,Fix source link.,MERGED,2019-10-16 14:08:01.000000000,2019-10-16 16:50:57.000000000,2019-10-16 16:49:06.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 14:08:01.000000000', 'files': ['doc/source/contributor/release-management.rst'], 'web_link': 'https://opendev.org/openstack/kolla/commit/fd5bff9cf1d9eac371cf481d2888771666eba359', 'message': 'Fix source link.\n\nChange-Id: If63fb782c3b3da8301610e80bd3b2cfeadc301cc\n'}]",0,688938,fd5bff9cf1d9eac371cf481d2888771666eba359,8,3,1,30717,,,0,"Fix source link.

Change-Id: If63fb782c3b3da8301610e80bd3b2cfeadc301cc
",git fetch https://review.opendev.org/openstack/kolla refs/changes/38/688938/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/release-management.rst'],1,fd5bff9cf1d9eac371cf481d2888771666eba359,, * example (kolla): https://review.opendev.org/647819 * example (kolla): https://review.opendev.org/650419, * example (kolla): https://review.openstack.org/647819 * example (kolla): https://review.openstack.org/650419,2,2
openstack%2Foctavia~master~Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567,openstack/octavia,master,Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567,Add client authentication to the LB cookbook,MERGED,2019-10-15 18:11:11.000000000,2019-10-16 16:49:55.000000000,2019-10-16 16:47:02.000000000,"[{'_account_id': 1131}, {'_account_id': 6469}, {'_account_id': 10850}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28502}]","[{'number': 1, 'created': '2019-10-15 18:11:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/65cbd58b16f108737bf4534dcef4a420a4fede20', 'message': 'Add client authentication to the LB cookbook\n\nThis patch adds a cookbook section for creating client authentication\nenabled listeners.\n\nIt also removes two references to granting access to secrets in\nbarbican that are no longer required.\n\nChange-Id: Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567\n'}, {'number': 2, 'created': '2019-10-15 18:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f88315ccdbc9cbcbd1934664d39b8c246f72c7f2', 'message': 'Add client authentication to the LB cookbook\n\nThis patch adds a cookbook section for creating client authentication\nenabled listeners.\n\nIt also removes two references to granting access to secrets in\nbarbican that are no longer required.\n\nChange-Id: Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567\n'}, {'number': 3, 'created': '2019-10-15 18:24:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/6606ff7610260b9f7a1fd345a48d372931ed8dc8', 'message': 'Add client authentication to the LB cookbook\n\nThis patch adds a cookbook section for creating client authentication\nenabled listeners.\n\nIt also removes two references to granting access to secrets in\nbarbican that are no longer required.\n\nChange-Id: Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567\n'}, {'number': 4, 'created': '2019-10-15 20:46:02.000000000', 'files': ['doc/source/user/guides/basic-cookbook.rst'], 'web_link': 'https://opendev.org/openstack/octavia/commit/4b4638e67d0a324839fabf1524a8f0a1e0c1dc31', 'message': 'Add client authentication to the LB cookbook\n\nThis patch adds a cookbook section for creating client authentication\nenabled listeners.\n\nIt also removes two references to granting access to secrets in\nbarbican that are no longer required.\n\nChange-Id: Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567\n'}]",3,688776,4b4638e67d0a324839fabf1524a8f0a1e0c1dc31,17,6,4,11628,,,0,"Add client authentication to the LB cookbook

This patch adds a cookbook section for creating client authentication
enabled listeners.

It also removes two references to granting access to secrets in
barbican that are no longer required.

Change-Id: Iaada1b5d519bfc57528aa15bae8c0ee2b55f0567
",git fetch https://review.opendev.org/openstack/octavia refs/changes/76/688776/4 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/user/guides/basic-cookbook.rst'],1,65cbd58b16f108737bf4534dcef4a420a4fede20,," Copyright 2019 Red Hat, Inc. All rights reserved.3. Create load balancer *lb1* on subnet *public-subnet*. 4. Create listener *listener1* as a TERMINATED_HTTPS listener referencing5. Create pool *pool1* as *listener1*'s default pool. 6. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*.3. Create load balancer *lb1* on subnet *public-subnet*. 4. Create listener *listener1* as a TERMINATED_HTTPS listener referencing5. Create pool *pool1* as *listener1*'s default pool. 6. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*.Deploy a TLS-terminated HTTPS load balancer with client authentication ---------------------------------------------------------------------- With a TLS-terminated HTTPS load balancer, web clients communicate with the load balancer over TLS protocols. The load balancer terminates the TLS session and forwards the decrypted requests to the back-end servers. By terminating the TLS session on the load balancer, we offload the CPU-intensive encryption work to the load balancer, and enable the possibility of using advanced load balancer features, like Layer 7 features and header manipulation. Adding client authentication allows users to authenticate users connecting to the VIP using certificates. This is also known as two-way TLS authentication. **Scenario description**: * Back-end servers 192.0.2.10 and 192.0.2.11 on subnet *private-subnet* have been configured with regular HTTP application on TCP port 80. * Subnet *public-subnet* is a shared external subnet created by the cloud operator which is reachable from the internet. * A TLS certificate, key, and intermediate certificate chain for www.example.com have been obtained from an external certificate authority. These now exist in the files server.crt, server.key, and ca-chain.crt in the current directory. The key and certificate are PEM-encoded, and the intermediate certificate chain is multiple PEM-encoded certs concatenated together. The key is not encrypted with a passphrase. * A Certificate Authority (CA) certificate chain and optional Certificate Revocation List (CRL) have been obtained from an external certificate authority to authenticate client certificates against. * We want to configure a TLS-terminated HTTPS load balancer that is accessible from the internet using the key and certificate mentioned above, which distributes requests to the back-end servers over the non-encrypted HTTP protocol. * Octavia is configured to use barbican for key management. **Solution**: 1. Combine the individual cert/key/intermediates to a single PKCS12 file. 2. Create a barbican *secret* resource for the PKCS12 file. We will call this *tls_secret1*. 3. Create a barbican *secret* resource for the client CA certificate. We will call this *client_ca_cert*. 4. Optionally create a barbican *secret* for the CRL file. We will call this *client_ca_crl*. 5. Create load balancer *lb1* on subnet *public-subnet*. 6. Create listener *listener1* as a TERMINATED_HTTPS listener referencing *tls_secret1* as its default TLS container, client authentication enabled, *client_ca_cert* as the client CA tls container reference, and *client_ca_crl* as the client CRL container reference. 6. Create pool *pool1* as *listener1*'s default pool. 7. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*. **CLI commands**: :: openssl pkcs12 -export -inkey server.key -in server.crt -certfile ca-chain.crt -passout pass: -out server.p12 openstack secret store --name='tls_secret1' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < server.p12)"" openstack secret store --name='client_ca_cert' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < client_ca.pem)"" openstack secret store --name='client_ca_crl' -t 'application/octet-stream' -e 'base64' --payload=""$(base64 < client_ca.crl)"" openstack loadbalancer create --name lb1 --vip-subnet-id public-subnet # Re-run the following until lb1 shows ACTIVE and ONLINE statuses: openstack loadbalancer show lb1 openstack loadbalancer listener create --protocol-port 443 --protocol TERMINATED_HTTPS --name listener1 --default-tls-container=$(openstack secret list | awk '/ tls_secret1 / {print $2}') --client-authentication=MANDATORY --client-ca-tls-container-ref=$(openstack secret list | awk '/ client_ca_cert / {print $2}') --client-crl-container=$(openstack secret list | awk '/ client_ca_crl / {print $2}') lb1 openstack loadbalancer pool create --name pool1 --lb-algorithm ROUND_ROBIN --listener listener1 --protocol HTTP openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.10 --protocol-port 80 pool1 openstack loadbalancer member create --subnet-id private-subnet --address 192.0.2.11 --protocol-port 80 pool1",3. Grant the *admin* user access to the *tls_secret1* barbican resource. 4. Create load balancer *lb1* on subnet *public-subnet*. 5. Create listener *listener1* as a TERMINATED_HTTPS listener referencing6. Create pool *pool1* as *listener1*'s default pool. 7. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*.3. Grant the *admin* user access to both *tls_secret* barbican resources. 4. Create load balancer *lb1* on subnet *public-subnet*. 5. Create listener *listener1* as a TERMINATED_HTTPS listener referencing6. Create pool *pool1* as *listener1*'s default pool. 7. Add members 192.0.2.10 and 192.0.2.11 on *private-subnet* to *pool1*.,74,10
openstack%2Fkolla~stable%2Frocky~I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,openstack/kolla,stable/rocky,I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,CI: pep8: Fix yamllint error on .yamllint,MERGED,2019-10-16 08:06:12.000000000,2019-10-16 16:49:05.000000000,2019-10-16 16:49:05.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 08:06:12.000000000', 'files': ['.yamllint'], 'web_link': 'https://opendev.org/openstack/kolla/commit/350873a00c03599aab4010dbaeef5b52db9ba632', 'message': 'CI: pep8: Fix yamllint error on .yamllint\n\nChange-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n(cherry picked from commit 88d26e52d350683f4407191ccb196a203167e756)\n'}]",0,688872,350873a00c03599aab4010dbaeef5b52db9ba632,7,3,1,14826,,,0,"CI: pep8: Fix yamllint error on .yamllint

Change-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486
Signed-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>
(cherry picked from commit 88d26e52d350683f4407191ccb196a203167e756)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/72/688872/1 && git format-patch -1 --stdout FETCH_HEAD,['.yamllint'],1,350873a00c03599aab4010dbaeef5b52db9ba632,,---,,1,0
openstack%2Ftripleo-ci~master~I1ff20467bb2222336a0e2e307cff3380e3761122,openstack/tripleo-ci,master,I1ff20467bb2222336a0e2e307cff3380e3761122,Attempt to fix slow cleanup of cached files,MERGED,2019-10-14 19:49:49.000000000,2019-10-16 16:32:24.000000000,2019-10-15 10:08:24.000000000,"[{'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-14 19:49:49.000000000', 'files': ['toci_gate_test.sh'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/39bb0d6250d008b889b9925776b77e95c1df8bc7', 'message': 'Attempt to fix slow cleanup of cached files\n\nAs part of the cleanup we remove cached repos in /opt/git. This\ncausing some transient timeouts, as rm -rf spawns a new process\nfor every file that matches in the pattern. And this results in\nvery long execution due to I/O degradation.\n\nChange-Id: I1ff20467bb2222336a0e2e307cff3380e3761122\nCloses-Bug: #1847814\n'}]",3,688549,39bb0d6250d008b889b9925776b77e95c1df8bc7,12,4,1,8175,,,0,"Attempt to fix slow cleanup of cached files

As part of the cleanup we remove cached repos in /opt/git. This
causing some transient timeouts, as rm -rf spawns a new process
for every file that matches in the pattern. And this results in
very long execution due to I/O degradation.

Change-Id: I1ff20467bb2222336a0e2e307cff3380e3761122
Closes-Bug: #1847814
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/49/688549/1 && git format-patch -1 --stdout FETCH_HEAD,['toci_gate_test.sh'],1,39bb0d6250d008b889b9925776b77e95c1df8bc7,lp/1847814," # rm -rf spawns a separate process for each file, lets use find -delete sudo find /opt/git -delete", sudo rm -rf /opt/git,2,1
openstack%2Fmagnum~master~Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff,openstack/magnum,master,Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff,ng-13: Support nodegroup upgrade,MERGED,2019-10-04 14:22:55.000000000,2019-10-16 16:14:27.000000000,2019-10-16 16:10:32.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28022}, {'_account_id': 28614}]","[{'number': 1, 'created': '2019-10-04 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/426a477fe92c20b498299f04bde5891cd41aa56c', 'message': '[WIP] ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}, {'number': 2, 'created': '2019-10-10 12:14:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0e540b4a9ec484f802d09a8d3e76d3e7eb5d9a79', 'message': 'ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster. The\nonly label that gets upgraded for now is kube_tag. All other labels\nin the new cluster_template are ignored.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}, {'number': 3, 'created': '2019-10-10 13:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/342449f7011334ef747c0391b63c67d5001c4d56', 'message': 'ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster. The\nonly label that gets upgraded for now is kube_tag. All other labels\nin the new cluster_template are ignored.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}, {'number': 4, 'created': '2019-10-11 13:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cc64a9c070afd3b9229367fddeabc1aaaba7b037', 'message': 'ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster. The\nonly label that gets upgraded for now is kube_tag. All other labels\nin the new cluster_template are ignored.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}, {'number': 5, 'created': '2019-10-14 09:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d8c37136a4d7ae508b2f390df809d8bf1b276a80', 'message': 'ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster. The\nonly label that gets upgraded for now is kube_tag. All other labels\nin the new cluster_template are ignored.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}, {'number': 6, 'created': '2019-10-16 11:57:52.000000000', 'files': ['magnum/tests/unit/api/controllers/v1/test_cluster_actions.py', 'magnum/tests/unit/drivers/test_k8s_fedora_atomic_v1_driver.py', 'releasenotes/notes/upgrade_api-1fecc206e5b0ef99.yaml', 'magnum/api/controllers/v1/cluster_actions.py', 'magnum/conductor/handlers/cluster_conductor.py', 'magnum/tests/unit/db/utils.py', 'magnum/drivers/heat/driver.py', 'magnum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/0ac4db955f6a63a977bea6c2d8946fa46e14b6a2', 'message': 'ng-13: Support nodegroup upgrade\n\nAdds support for upgrading nodegroups. All non-default nodegroups,\nare allowed to be upgraded using the CT set in the cluster. The\nonly label that gets upgraded for now is kube_tag. All other labels\nin the new cluster_template are ignored.\n\nChange-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff\n'}]",2,686733,0ac4db955f6a63a977bea6c2d8946fa46e14b6a2,22,5,6,27057,,,0,"ng-13: Support nodegroup upgrade

Adds support for upgrading nodegroups. All non-default nodegroups,
are allowed to be upgraded using the CT set in the cluster. The
only label that gets upgraded for now is kube_tag. All other labels
in the new cluster_template are ignored.

Change-Id: Icade1a70f160d5ec1c0e6f06ee642e29fe9b02ff
",git fetch https://review.opendev.org/openstack/magnum refs/changes/33/686733/6 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/tests/unit/api/controllers/v1/test_cluster_actions.py', 'magnum/tests/unit/drivers/test_k8s_fedora_atomic_v1_driver.py', 'magnum/drivers/k8s_fedora_atomic_v1/driver.py', 'magnum/api/controllers/v1/cluster_actions.py', 'magnum/conductor/handlers/cluster_conductor.py', 'magnum/tests/unit/db/utils.py', 'magnum/common/exception.py']",7,426a477fe92c20b498299f04bde5891cd41aa56c,magnum_nodegroups," class InvalidClusterTemplateForNGUpgrade(Conflict): message = _(""Nodegroup %(ng_name)s can be upgraded only to match "" ""cluster's template (%(ct_name)s)."")",,274,12
openstack%2Fmagnum~master~Ic410a059b19a1252cdf6eed786964c5c7b03d01c,openstack/magnum,master,Ic410a059b19a1252cdf6eed786964c5c7b03d01c,ng-12: Label nodegroup nodes,MERGED,2019-10-03 09:17:40.000000000,2019-10-16 16:12:13.000000000,2019-10-16 16:10:31.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2019-10-03 09:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b44d9e1f22e2e22598271b49551c3421663d4d03', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}, {'number': 2, 'created': '2019-10-04 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/db1269e6fe37a016f667c9e31f0daaff765b1c54', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\n* magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}, {'number': 3, 'created': '2019-10-10 13:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/9151fd8fbeb3c24c253dff0fa1d57338d80eb311', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\n* magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}, {'number': 4, 'created': '2019-10-11 13:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/c59a43134375015c66aa7b9ba2f4e1632e14e57a', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\n* --node-labels=magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}, {'number': 5, 'created': '2019-10-14 09:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6475d9f9e08a71a020ff9003e88faaa93a834ad9', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\n* --node-labels=magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}, {'number': 6, 'created': '2019-10-16 11:57:52.000000000', 'files': ['magnum/drivers/k8s_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py', 'magnum/drivers/heat/k8s_template_def.py', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubecluster.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/113fdc44b26b27fb4248e8535e46cb7512207cc4', 'message': 'ng-12: Label nodegroup nodes\n\nWith this change each node will be labeled with the following:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\n* --node-labels=magnum.openstack.org/nodegroup=${NODEGROUP_NAME}\n\nChange-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c\n'}]",0,686362,113fdc44b26b27fb4248e8535e46cb7512207cc4,21,6,6,27057,,,0,"ng-12: Label nodegroup nodes

With this change each node will be labeled with the following:
* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}
* --node-labels=magnum.openstack.org/nodegroup=${NODEGROUP_NAME}

Change-Id: Ic410a059b19a1252cdf6eed786964c5c7b03d01c
",git fetch https://review.opendev.org/openstack/magnum refs/changes/62/686362/2 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/heat/k8s_template_def.py', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params.sh', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubecluster.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/write-heat-params-master.sh', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py']",11,b44d9e1f22e2e22598271b49551c3421663d4d03,magnum_nodegroups," 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng', 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng', 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng', 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng', 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng', 'master_nodegroup_name': 'master_ng', 'worker_nodegroup_name': 'worker_ng',",,60,0
openstack%2Foctavia~master~I6570f9f82173a1258da76899de8f1410ff5fc52a,openstack/octavia,master,I6570f9f82173a1258da76899de8f1410ff5fc52a,[Jobboard] Importable flow functions,ABANDONED,2019-05-16 11:52:09.000000000,2019-10-16 16:11:14.000000000,,"[{'_account_id': 7249}, {'_account_id': 10273}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-16 11:52:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/db340b799c008d7e298332fa1b0591bc866687ab', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 2, 'created': '2019-05-22 08:09:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/65e7137b3cce289b0f0134c29ace84d6c4972125', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 3, 'created': '2019-05-22 08:35:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/0dd43ba3ddf9fb36f0521b0ef222b252427a42ff', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 4, 'created': '2019-05-23 10:32:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/f6793be3aa105dbbf5745664e412bd2aa051a420', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 5, 'created': '2019-06-06 13:11:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d0febe3c40627574911d112ef0023d02d06d1dea', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 6, 'created': '2019-07-17 14:26:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/bcb6a0a5d906b6ecd5fa61ff95e9dbd0ca0eaf76', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}, {'number': 7, 'created': '2019-08-06 10:12:43.000000000', 'files': ['octavia/controller/worker/v2/flows/flow_utils.py', 'octavia/tests/unit/controller/worker/v2/test_controller_worker.py', 'octavia/controller/worker/v2/controller_worker.py', 'octavia/controller/worker/v2/flows/amphora_flows.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/086516818cc77dbab89427ba4a5c85fe7d549422', 'message': '[Jobboard] Importable flow functions\n\nPart of required refactor for implementation of taskflow jobboard\nbased controller is creation of importable flow functions.\n\nChange-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a\nStory: 2005072\nTask: 30816\n'}]",0,659538,086516818cc77dbab89427ba4a5c85fe7d549422,28,3,7,7249,,,0,"[Jobboard] Importable flow functions

Part of required refactor for implementation of taskflow jobboard
based controller is creation of importable flow functions.

Change-Id: I6570f9f82173a1258da76899de8f1410ff5fc52a
Story: 2005072
Task: 30816
",git fetch https://review.opendev.org/openstack/octavia refs/changes/38/659538/3 && git format-patch -1 --stdout FETCH_HEAD,['octavia/controller/worker/flows/flow_utils.py'],1,db340b799c008d7e298332fa1b0591bc866687ab,jobboard,"# Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. from octavia.controller.worker.flows import amphora_flows from octavia.controller.worker.flows import health_monitor_flows from octavia.controller.worker.flows import l7policy_flows from octavia.controller.worker.flows import l7rule_flows from octavia.controller.worker.flows import listener_flows from octavia.controller.worker.flows import load_balancer_flows from octavia.controller.worker.flows import member_flows from octavia.controller.worker.flows import pool_flows LB_FLOWS = load_balancer_flows.LoadBalancerFlows() AMP_FLOWS = amphora_flows.AmphoraFlows() HM_FLOWS = health_monitor_flows.HealthMonitorFlows() L7_POLICY_FLOWS = l7policy_flows.L7PolicyFlows() L7_RULES_FLOWS = l7rule_flows.L7RuleFlows() LISTENER_FLOWS = listener_flows.ListenerFlows() M_FLOWS = member_flows.MemberFlows() P_FLOWS = pool_flows.PoolFlows() def get_create_load_balancer_flow(topology, listeners=None): return LB_FLOWS.get_create_load_balancer_flow(topology, listeners=listeners) def get_delete_load_balancer_flow(lb): return LB_FLOWS.get_delete_load_balancer_flow(lb) def get_cascade_delete_load_balancer_flow(lb): return LB_FLOWS.get_cascade_delete_load_balancer_flow(lb) def get_update_load_balancer_flow(): return LB_FLOWS.get_update_load_balancer_flow() def get_create_amphora_flow(): return AMP_FLOWS.get_create_amphora_flow() def get_delete_amphora_flow(): return AMP_FLOWS.get_delete_amphora_flow() def get_failover_flow(): return AMP_FLOWS.get_failover_flow() def cert_rotate_amphora_flow(): return AMP_FLOWS.cert_rotate_amphora_flow() def update_amphora_config_flow(): return AMP_FLOWS.update_amphora_config_flow() def get_create_health_monitor_flow(): return HM_FLOWS.get_create_health_monitor_flow() def get_delete_health_monitor_flow(): return HM_FLOWS.get_delete_health_monitor_flow() def get_update_health_monitor_flow(): return HM_FLOWS.get_update_health_monitor_flow() def get_create_l7policy_flow(): return L7_POLICY_FLOWS.get_create_l7policy_flow() def get_delete_l7policy_flow(): return L7_POLICY_FLOWS.get_delete_l7policy_flow() def get_update_l7policy_flow(): return L7_POLICY_FLOWS.get_update_l7policy_flow() def get_create_l7rule_flow(): return L7_RULES_FLOWS.get_create_l7rule_flow() def get_delete_l7rule_flow(): return L7_RULES_FLOWS.get_delete_l7rule_flow() def get_update_l7rule_flow(): return L7_RULES_FLOWS.get_update_l7rule_flow() def get_create_listener_flow(): return LISTENER_FLOWS.get_create_listener_flow() def get_create_all_listeners_flow(): return LISTENER_FLOWS.get_create_all_listeners_flow() def get_delete_listener_flow(): return LISTENER_FLOWS.get_delete_listener_flow() def get_update_listener_flow(): return LISTENER_FLOWS.get_update_listener_flow() def get_create_member_flow(): return M_FLOWS.get_create_member_flow() def get_delete_member_flow(): return M_FLOWS.get_delete_member_flow() def get_update_member_flow(): return M_FLOWS.get_update_member_flow() def get_batch_update_members_flow(old_members, new_members, updated_members): return M_FLOWS.get_batch_update_members_flow(old_members, new_members, updated_members) def get_create_pool_flow(): return P_FLOWS.get_create_pool_flow() def get_delete_pool_flow(): return P_FLOWS.get_delete_pool_flow() def get_update_pool_flow(): return P_FLOWS.get_update_pool_flow() ",,148,0
openstack%2Fmagnum~master~I020940e1495f481c840c691cbe9770d14dc050ec,openstack/magnum,master,I020940e1495f481c840c691cbe9770d14dc050ec,ng-11: API microversion 1.9,MERGED,2019-10-02 06:54:38.000000000,2019-10-16 16:02:43.000000000,2019-10-16 16:00:50.000000000,"[{'_account_id': 6484}, {'_account_id': 17499}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28022}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-10-02 06:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a27c1562597a8b36930aab3ad7f56e3116a31a96', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 2, 'created': '2019-10-02 08:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d674de19bbb8eff993a7b0a54ab6d416e8ba221d', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 3, 'created': '2019-10-03 09:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4f92960c08a708aaf8d950042222a29f37cc27bb', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 4, 'created': '2019-10-04 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a94e232c8af5beba2e86c98696077a62d7b6a127', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 5, 'created': '2019-10-10 13:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7e193d6f7d469ee40cd58e8bececa2ac33c44ea5', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 6, 'created': '2019-10-11 13:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dab94a1d4e14c3f98c5318d240551179263d4d68', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 7, 'created': '2019-10-14 09:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a1363931edfbf5fb99eb9fc5a00810088daddb54', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}, {'number': 8, 'created': '2019-10-16 11:57:52.000000000', 'files': ['magnum/api/controllers/versions.py', 'magnum/api/controllers/v1/nodegroup.py', 'magnum/tests/unit/api/controllers/test_root.py', 'magnum/tests/unit/api/controllers/v1/test_nodegroup.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/f14c50011a1168a92d29c82a6bc7feaff8d2d3b7', 'message': 'ng-11: API microversion 1.9\n\nThis change bumps the API microversion from 1.8 to 1.9.\n\nChange-Id: I020940e1495f481c840c691cbe9770d14dc050ec\n'}]",0,686089,f14c50011a1168a92d29c82a6bc7feaff8d2d3b7,25,7,8,27057,,,0,"ng-11: API microversion 1.9

This change bumps the API microversion from 1.8 to 1.9.

Change-Id: I020940e1495f481c840c691cbe9770d14dc050ec
",git fetch https://review.opendev.org/openstack/magnum refs/changes/89/686089/8 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/api/controllers/versions.py', 'magnum/api/controllers/v1/nodegroup.py', 'magnum/tests/unit/api/controllers/test_root.py', 'magnum/tests/unit/api/controllers/v1/test_nodegroup.py']",4,a27c1562597a8b36930aab3ad7f56e3116a31a96,magnum_nodegroups,"class NodeGroupControllerTest(api_base.FunctionalTest): headers = {""Openstack-Api-Version"": ""container-infra latest""} def _add_headers(self, kwargs): if 'headers' not in kwargs: kwargs['headers'] = self.headers def get_json(self, *args, **kwargs): self._add_headers(kwargs) return super(NodeGroupControllerTest, self).get_json(*args, **kwargs) def post_json(self, *args, **kwargs): self._add_headers(kwargs) return super(NodeGroupControllerTest, self).post_json(*args, **kwargs) def delete(self, *args, **kwargs): self._add_headers(kwargs) return super(NodeGroupControllerTest, self).delete(*args, **kwargs) def patch_json(self, *args, **kwargs): self._add_headers(kwargs) return super(NodeGroupControllerTest, self).patch_json(*args, **kwargs) class TestListNodegroups(NodeGroupControllerTest): def test_get_one_wrong_microversion(self): headers = {""Openstack-Api-Version"": ""container-infra 1.8""} worker = self.cluster.default_ng_worker url = '/clusters/%s/nodegroups/%s' % (self.cluster.uuid, worker.uuid) response = self.get_json(url, headers=headers, expect_errors=True) self.assertEqual(406, response.status_code) def test_get_all_wrong_microversion(self): headers = {""Openstack-Api-Version"": ""container-infra 1.8""} url = '/clusters/%s/nodegroups/' % (self.cluster.uuid) response = self.get_json(url, headers=headers, expect_errors=True) self.assertEqual(406, response.status_code) class TestPost(NodeGroupControllerTest): @mock.patch('oslo_utils.timeutils.utcnow') def test_create_ng_wrong_microversion(self, mock_utcnow): headers = {""Openstack-Api-Version"": ""container-infra 1.8""} ng_dict = apiutils.nodegroup_post_data(name=""new_ng"") response = self.post_json(self.url, ng_dict, headers=headers, expect_errors=True) self.assertEqual('application/json', response.content_type) self.assertEqual(406, response.status_int) class TestDelete(NodeGroupControllerTest): def test_delete_wrong_microversion(self): headers = {""Openstack-Api-Version"": ""container-infra 1.8""} response = self.delete(self.url + self.nodegroup.uuid, headers=headers, expect_errors=True) self.assertEqual(406, response.status_int) class TestPatch(NodeGroupControllerTest): def test_replace_wrong_microversion(self): headers = {""Openstack-Api-Version"": ""container-infra 1.8""} response = self.patch_json(self.url + self.nodegroup.name, [{'path': '/max_node_count', 'value': 4, 'op': 'replace'}], headers=headers, expect_errors=True) self.assertEqual(406, response.status_code) class TestNodeGroupPolicyEnforcement(NodeGroupControllerTest):",class TestListNodegroups(api_base.FunctionalTest): class TestPost(api_base.FunctionalTest): class TestDelete(api_base.FunctionalTest): class TestPatch(api_base.FunctionalTest): class TestNodeGroupPolicyEnforcement(api_base.FunctionalTest):,74,7
openstack%2Fpuppet-neutron~stable%2Ftrain~I930582694aabc9f6c800cca9cf528259e1d29198,openstack/puppet-neutron,stable/train,I930582694aabc9f6c800cca9cf528259e1d29198,Switch to Train,MERGED,2019-10-09 23:10:13.000000000,2019-10-16 16:00:50.000000000,2019-10-16 16:00:49.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 23:10:13.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/3dc0585e05e79bafb4beaa66d16d251e22fb05f5', 'message': 'Switch to Train\n\nChange-Id: I930582694aabc9f6c800cca9cf528259e1d29198\n'}]",0,687717,3dc0585e05e79bafb4beaa66d16d251e22fb05f5,28,5,1,16137,,,0,"Switch to Train

Change-Id: I930582694aabc9f6c800cca9cf528259e1d29198
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/17/687717/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,3dc0585e05e79bafb4beaa66d16d251e22fb05f5,," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper', :branch => 'stable/train',"," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper',",2,1
openstack%2Fcharm-keystone~master~I8cbc3d890e1fbeb05e2eef0354cdb60d849f20b4,openstack/charm-keystone,master,I8cbc3d890e1fbeb05e2eef0354cdb60d849f20b4,Enable functional tests for train,MERGED,2019-10-16 13:26:16.000000000,2019-10-16 15:58:48.000000000,2019-10-16 15:58:48.000000000,"[{'_account_id': 7730}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 13:26:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/8bb02a585c3fd7fa9873e87183254d7b44f7adaf', 'message': 'Enable functional tests for train\n\nThis patch also updates the smoke test to run train.\n\nDepends-On: https://review.opendev.org/#/c/680227\nChange-Id: I8cbc3d890e1fbeb05e2eef0354cdb60d849f20b4\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@canonical.com>\n'}, {'number': 2, 'created': '2019-10-16 15:31:57.000000000', 'files': ['tests/bundles/bionic-train.yaml', 'tests/tests.yaml'], 'web_link': 'https://opendev.org/openstack/charm-keystone/commit/af06e0d3560cd13bf38166f3a6e88d306400cbff', 'message': 'Enable functional tests for train\n\nThis patch also updates the smoke test to run train.\n\nChange-Id: I8cbc3d890e1fbeb05e2eef0354cdb60d849f20b4\nSigned-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@canonical.com>\n'}]",0,688927,af06e0d3560cd13bf38166f3a6e88d306400cbff,13,4,2,7730,,,0,"Enable functional tests for train

This patch also updates the smoke test to run train.

Change-Id: I8cbc3d890e1fbeb05e2eef0354cdb60d849f20b4
Signed-off-by: Sahid Orentino Ferdjaoui <sahid.ferdjaoui@canonical.com>
",git fetch https://review.opendev.org/openstack/charm-keystone refs/changes/27/688927/2 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/bionic-train.yaml', 'tests/tests.yaml']",2,8bb02a585c3fd7fa9873e87183254d7b44f7adaf,charms-train-function-test,- bionic-train gate_bundles: - bionic-train,- bionic-stein gate_bundles:,43,1
openstack%2Fmagnum~master~Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5,openstack/magnum,master,Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5,ng-10: Fix cluster template conditions,MERGED,2019-09-29 16:49:39.000000000,2019-10-16 15:56:18.000000000,2019-10-16 15:54:53.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27057}, {'_account_id': 27781}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-09-29 16:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/bc56097fb47922265ad41a8f1655a72cc9dc1424', 'message': 'Fix cluster template conditions\n\nThe new worker_only condition should be true for all roles except for\nmaster. Also this adds the new params in the cluster templates of all\nthe coes.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 2, 'created': '2019-09-30 12:32:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/2918b4d71e9c5f6996ff364d92afab919daa7265', 'message': '[ng-10] Fix cluster template conditions\n\nThe new worker_only condition should be true for all roles except for\nmaster. Also this adds the new params in the cluster templates of all\nthe coes.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 3, 'created': '2019-10-01 13:28:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/01f69e388ecc91063682e8170a225704b082bc26', 'message': '[ng-10] Fix cluster template conditions\n\nThe new worker_only condition should be true for all roles except for\nmaster. Also this adds the new params in the cluster templates of all\nthe coes.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 4, 'created': '2019-10-02 06:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/374212405b63eeb63905bf5241381d9d5a629e2a', 'message': 'ng-10: Fix cluster template conditions\n\nThe new worker_only condition should be true for all roles except for\nmaster. Also this adds the new params in the cluster templates of all\nthe coes.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 5, 'created': '2019-10-03 09:17:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/dba173b74ca8057e9213ee0ec9f8b742dbff27b8', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nOn k8s we label the nodes of each nodegroup with the role of the\nnodegroup where they belong in the following way:\n* --node-labels=magnum.openstack.org/role=${NODEGROUP_ROLE}\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 6, 'created': '2019-10-04 14:22:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fdc3651dd81bbbc19333f3703db49e661533a632', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 7, 'created': '2019-10-10 13:49:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/69c10d91c1d75c5225e30df97833d80f5685e606', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 8, 'created': '2019-10-11 13:02:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/ef8c210c7ce08390fda093aa2a1932a26fcf4d4e', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 9, 'created': '2019-10-14 09:10:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/662b95af8ac245573d598e45d749c2132f7e5fae', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}, {'number': 10, 'created': '2019-10-16 11:57:52.000000000', 'files': ['magnum/drivers/heat/template_def.py', 'magnum/drivers/swarm_fedora_atomic_v1/templates/cluster.yaml', 'magnum/tests/unit/conductor/handlers/test_swarm_cluster_conductor.py', 'magnum/drivers/k8s_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/swarm_fedora_atomic_v2/templates/swarmcluster.yaml', 'magnum/drivers/mesos_ubuntu_v1/templates/mesoscluster.yaml', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py', 'magnum/drivers/heat/k8s_template_def.py', 'magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubecluster.yaml', 'magnum/tests/unit/conductor/handlers/test_mesos_cluster_conductor.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/44631afbbfa662ecd9b37c30e450f191d2178978', 'message': 'ng-10: Fix cluster template conditions\n\nRemoves the role heat param from all templates. Instead and only for\nk8s templates adds the master_role and worker_role params. The new\nworker_only condition should be true for all roles except for master.\nFinally, adds the missing is_cluster_stack param to all templates.\n\nChange-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5\n'}]",5,685620,44631afbbfa662ecd9b37c30e450f191d2178978,38,6,10,27057,,,0,"ng-10: Fix cluster template conditions

Removes the role heat param from all templates. Instead and only for
k8s templates adds the master_role and worker_role params. The new
worker_only condition should be true for all roles except for master.
Finally, adds the missing is_cluster_stack param to all templates.

Change-Id: Ie0799373fe492c2e0a0cad903ed6e8c93e6266b5
",git fetch https://review.opendev.org/openstack/magnum refs/changes/20/685620/10 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_atomic_v1/templates/kubecluster.yaml', 'magnum/drivers/swarm_fedora_atomic_v1/templates/cluster.yaml', 'magnum/drivers/k8s_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/swarm_fedora_atomic_v2/templates/swarmcluster.yaml', 'magnum/drivers/k8s_fedora_ironic_v1/templates/kubecluster.yaml', 'magnum/drivers/mesos_ubuntu_v1/templates/mesoscluster.yaml']",6,bc56097fb47922265ad41a8f1655a72cc9dc1424,magnum_nodegroups," is_cluster_stack: type: boolean default: false role: type: string default: """" ",,61,18
openstack%2Fmanila~stable%2Frocky~Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f,openstack/manila,stable/rocky,Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f,Remove backend spec from share type while creating replica,MERGED,2019-10-13 23:36:39.000000000,2019-10-16 15:51:32.000000000,2019-10-16 15:50:01.000000000,"[{'_account_id': 9003}, {'_account_id': 16643}, {'_account_id': 21863}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-10-13 23:36:39.000000000', 'files': ['manila/tests/scheduler/drivers/test_filter.py', 'manila/scheduler/drivers/filter.py', 'releasenotes/notes/bug-1634734-fix-backend-extraspec-for-replication-d611d2227997ae3e.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/bffeef11b4aea4a9e718fb7814336149b1d2abfd', 'message': 'Remove backend spec from share type while creating replica\n\nIf a share type includes the share_backend_name spec,\nthe scheduler may fail to schedule share replicas unless\nall backends in a replication domain share the same\nvalue for the capability ""share_backend_name"". Having\nthe same ""share_backend_name"" isn\'t desirable all the\ntime.\n\nIgnore the share_backend_name spec from share type\nwhile creating replica, so the scheduler will filter\na available backend according to the selection policy.\n\nChange-Id: Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f\nCloses-Bug: #1634734\n(cherry picked from commit 700c1a02f0a357312df8f47932f83e86a3d2dc86)\n(cherry picked from commit 19c4869a3f004e4ec699412c1831765b714aa93b)\n(cherry picked from commit e2fe03e25363a35bd07895505c18d349e4a330e7)\n'}]",0,688314,bffeef11b4aea4a9e718fb7814336149b1d2abfd,12,6,1,16643,,,0,"Remove backend spec from share type while creating replica

If a share type includes the share_backend_name spec,
the scheduler may fail to schedule share replicas unless
all backends in a replication domain share the same
value for the capability ""share_backend_name"". Having
the same ""share_backend_name"" isn't desirable all the
time.

Ignore the share_backend_name spec from share type
while creating replica, so the scheduler will filter
a available backend according to the selection policy.

Change-Id: Ic8f7e6230298c222cc6cb5e4e4e8189524aaa81f
Closes-Bug: #1634734
(cherry picked from commit 700c1a02f0a357312df8f47932f83e86a3d2dc86)
(cherry picked from commit 19c4869a3f004e4ec699412c1831765b714aa93b)
(cherry picked from commit e2fe03e25363a35bd07895505c18d349e4a330e7)
",git fetch https://review.opendev.org/openstack/manila refs/changes/14/688314/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila/tests/scheduler/drivers/test_filter.py', 'manila/scheduler/drivers/filter.py', 'releasenotes/notes/bug-1634734-fix-backend-extraspec-for-replication-d611d2227997ae3e.yaml']",3,bffeef11b4aea4a9e718fb7814336149b1d2abfd,bug/1634734-stable/train-stable/stein-stable/rocky,--- fixes: - | Share type extra-specification ``share_backend_name`` is now ignored when creating share replicas. This ensures that backends in the same replication domain need not have the same value of ``share_backend_name``. See `launchpad bug #1634734 <https://bugs.launchpad.net/manila/+bug/1634734>`_ for details. ,,42,0
openstack%2Fpython-tripleoclient~stable%2Ftrain~Ifae2ec26e9ccf125ba84d3b20795b3912d756811,openstack/python-tripleoclient,stable/train,Ifae2ec26e9ccf125ba84d3b20795b3912d756811,Update .gitreview for stable/train,ABANDONED,2019-10-15 16:19:01.000000000,2019-10-16 15:51:09.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 16:19:01.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5e274776fc919cfda121582b81908159dee1aa26', 'message': 'Update .gitreview for stable/train\n\nChange-Id: Ifae2ec26e9ccf125ba84d3b20795b3912d756811\n'}]",0,688748,5e274776fc919cfda121582b81908159dee1aa26,4,2,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: Ifae2ec26e9ccf125ba84d3b20795b3912d756811
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/48/688748/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,5e274776fc919cfda121582b81908159dee1aa26,create-train,defaultbranch=stable/train,,1,0
openstack%2Freleases~master~Iabb57b47a5ec37248733526c709d7011636df414,openstack/releases,master,Iabb57b47a5ec37248733526c709d7011636df414,Update release process for R-1 and R+0,MERGED,2019-10-10 09:30:47.000000000,2019-10-16 15:43:57.000000000,2019-10-16 15:43:57.000000000,"[{'_account_id': 11904}, {'_account_id': 16708}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-10-10 09:30:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/e251194a113962b2e8cd661e2a0a1f4e92644ba2', 'message': 'Update release process for R-1 and R+0\n\nRefine process based on what happened in R-1 for Train,\nand adjust process based on what is planned for R+0\n\nInclude the template for the R+0 release weekly email.\n\nChange-Id: Iabb57b47a5ec37248733526c709d7011636df414\n'}, {'number': 2, 'created': '2019-10-10 10:40:13.000000000', 'files': ['doc/source/reference/process.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/58be9736696a76133e30547be12a8e614057adce', 'message': 'Update release process for R-1 and R+0\n\nRefine process based on what happened in R-1 for Train,\nand adjust process based on what is planned for R+0\n\nInclude the template for the R+0 release weekly email.\n\nChange-Id: Iabb57b47a5ec37248733526c709d7011636df414\n'}]",2,687840,58be9736696a76133e30547be12a8e614057adce,12,5,2,308,,,0,"Update release process for R-1 and R+0

Refine process based on what happened in R-1 for Train,
and adjust process based on what is planned for R+0

Include the template for the R+0 release weekly email.

Change-Id: Iabb57b47a5ec37248733526c709d7011636df414
",git fetch https://review.opendev.org/openstack/releases refs/changes/40/687840/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/process.rst'],1,e251194a113962b2e8cd661e2a0a1f4e92644ba2,detailed-process,"#. Test the release process using the ``openstack/release-test`` repository to ensure our machinery is functional. #. On the day before the deadline for final release candidates, propose last-minute RCs where needed: - Check the list of unreleased changes for cycle-with-rc projects, by running the following command in the releases repo working directory:: $ ./tools/list_rc_updates.sh - Propose patches creating a new RC for those that have unreleased bugfixes or updated translations - Patches that get a +1 from PTL or release liaison should be approved. A -1 will mean that the PTL prefers to wait for a post-release stable update. Patches that get no feedback by the deadline should be abandoned. #. At the end of the week, send weekly email content preparing for R-0 week:: Development Focus ----------------- We will be releasing the coordinated OpenStack $series release next week, on $release-date. Thanks to everyone involved in the $series cycle! We are now in pre-release freeze, so no new deliverable will be created until final release, unless a release-critical regression is spotted. Otherwise, teams attending the PTG in $ptg-location should start to plan what they will be discussing there, by creating and filling team etherpads: $link-to-list General Information ------------------- On release day, the release team will produce final versions of deliverables following the cycle-with-rc release model, by re-tagging the commit used for the last RC. A patch doing just that will be proposed. PTLs and release liaisons should watch for that final release patch from the release team. While not required, we would appreciate having an ack from each team before we approve it on the 16th, so that their approval is included in the metadata that goes onto the signed tag. Upcoming Deadlines & Dates -------------------------- Final Train release: $release-date $other-upcoming-event #. After the email is sent, use ``propose-final-releases`` to tag the existing most recent release candidates as the final release for projects using the cycle-with-rc model. #. We are in pre-release freeze. Only release-critical regressions, or legal compliance issues, or bugs making it otherwise impossible to install and use the software on release day, should be considered by the release management team for a pre-release freeze exception. If approved, release freeze exceptions should trigger the production of a new RC (or cycle-with-intermediary release) and (if needed) a regeneration of the final release patch. #. On release day, approve the final release patch created earlier.#. Once the final patch is proceesed, run the ``missing-releases`` script to check for missing tarballs on the release page before the announcement::","#. On the morning of the deadline for final release candidates, check the list of unreleased changes for cycle-with-rc projects and verify with the PTLs and liaisons that they are planning a release or that they do not need one. In the releases repository working directory, run:: $ ./tools/list_rc_updates.sh #. As soon as the last release candidate is tagged and the freeze period is entered, use ``propose-final-releases`` to tag the existing most recent release candidates as the final release for projects using the cycle-with-rc model. #. Ask liaisons and PTLs of milestone-based projects to review and +1 the final release proposal from the previous step so their approval is included in the metadata that goes onto the signed tag. #. Test the release process using the ``openstack/release-test`` repository to ensure our machinery is functional. #. Approve the final release patch created earlier.#. Run the ``missing-releases`` script to check for missing tarballs on the release page before the announcement::",68,24
openstack%2Freleases~master~I118760bc31440457a415f5c8248f6ff94493255f,openstack/releases,master,I118760bc31440457a415f5c8248f6ff94493255f,"Update process for R-3, R-2 and R-1 weeks",MERGED,2019-10-02 14:10:22.000000000,2019-10-16 15:41:49.000000000,2019-10-16 15:41:49.000000000,"[{'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-02 14:10:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/1b60553efa604716d27591a287d573b47ebea60d', 'message': 'Update process for R-3, R-2 and R-1 weeks\n\nFurther refine release process tasks for R-3, R-2 and R-1 weeks.\n\nChange-Id: I118760bc31440457a415f5c8248f6ff94493255f\n'}, {'number': 2, 'created': '2019-10-03 07:58:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/cab4b8f8fb0fa9924d43bae8b80c9ddb73030e2e', 'message': 'Update process for R-3, R-2 and R-1 weeks\n\nFurther refine release process tasks for R-3, R-2 and R-1 weeks.\n\nChange-Id: I118760bc31440457a415f5c8248f6ff94493255f\n'}, {'number': 3, 'created': '2019-10-08 12:11:27.000000000', 'files': ['doc/source/reference/process.rst'], 'web_link': 'https://opendev.org/openstack/releases/commit/2e661ef351e8e8cee4ee060cd6c0fbf221c8beb5', 'message': 'Update process for R-3, R-2 and R-1 weeks\n\nFurther refine release process tasks for R-3, R-2 and R-1 weeks.\n\nChange-Id: I118760bc31440457a415f5c8248f6ff94493255f\n'}]",0,686169,2e661ef351e8e8cee4ee060cd6c0fbf221c8beb5,13,3,3,308,,,0,"Update process for R-3, R-2 and R-1 weeks

Further refine release process tasks for R-3, R-2 and R-1 weeks.

Change-Id: I118760bc31440457a415f5c8248f6ff94493255f
",git fetch https://review.opendev.org/openstack/releases refs/changes/69/686169/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/reference/process.rst'],1,1b60553efa604716d27591a287d573b47ebea60d,detailed-process,"#. At the end of the week, send weekly email content preparing for R-2 week:: Development Focus ----------------- At this point we should have release candidates (RC1 or recent intermediary release) for all the $series deliverables. Teams should be working on any release-critical bugs that would require another RC or intermediary release before the final release. Actions ------- Early in the week, the release team will be proposing stable/$series branch creation for all deliverables that have not branched yet, using the latest available $series release as the branch point. If your team is ready to go for creating that branch, please let us know by leaving a +1 on these patches. If you would like to wait for another release before branching, you can -1 the patch and update it later in the week with the new release you would like to use. By the end of the week the release team will merge those patches though, unless an exception is granted. Once stable/$series branches are created, if a release-critical bug is detected, you will need to fix the issue in the master branch first, then backport the fix to the stable/$series branch before releasing out of the stable/$series branch. After all of the cycle-with-rc projects have branched we will branch devstack, grenade, and the requirements repos. This will effectively open them up for $next-series development, though the focus should still be on finishing up $series until the final release. For projects with translations, watch for any translation patches coming through and merge them quickly. A new release should be produced so that translations are included in the final $series release. Finally, now is a good time to finalize release notes. In particular, consider adding any relevant ""prelude"" content. Release notes are targetted for the downstream consumers of your project, so it would be great to include any useful information for those that are going to pick up and use or deploy the $series version of your project. Upcoming Deadlines & Dates -------------------------- Final RC deadline: $final-rc-deadline (R-1 week) Final Train release: $release-date $other-upcoming-event are still missing one. - You can list those using:: - Those patches will be used as a base to communicate with the team: if a team wants to wait and make another release before the branch is cut, someone from the team can -1 the patch to have it held, or update that patch to include another release and stable branch point. - Between Tuesday and Thursday, merge as soon as possible the patches that get +1 from the PTL or the release liaison. - On the Friday, merge patches that did not get any feedback from PTL or release liaison. Discuss standing -1s to see if they should be granted an exception and wait until next week.#. Ensure that all projects that are publishing release notes have the notes link included in their deliverable file. See tools/add_release_note_links.sh. #. At the end of the week, send weekly email content preparing for R-1 week:: Development Focus ----------------- We are on the final mile of the $series development cycle! Remember that the $series final release will include the latest release candidate (for cycle-with-rc deliverables) or the latest intermediary release (for cycle-with-intermediary deliverables) available. $final-rc-deadline is the deadline for final $series release candidates as well as any last cycle-with-intermediary deliverables. We will then enter a quiet period until we tag the final release on $release-date. Teams should be prioritizing fixing release-critical bugs, before that deadline. Otherwise it's time to start planning the $next-series development cycle, including discussing Forum and PTG sessions content, in preparation of $other-upcoming-event. Actions ------- Watch for any translation patches coming through on the stable/$series branch and merge them quickly. If you discover a release-critical issue, please make sure to fix it on the master branch first, then backport the bugfix to the stable/$series branch before triggering a new release. Please drop by #openstack-release with any questions or concerns about the upcoming release ! Upcoming Deadlines & Dates -------------------------- Final Train release: $release-date $other-upcoming-event #. Process any remaining stable branching exception."," are still missing one. You can list those using::#. Those patches will be used as a base to communicate with the team: if a team wants to wait and make another release before the branch is cut, someone from the team can -1 the patch to have it held, or update that patch to include another release and stable branch point. #. Between Tuesday and Thursday, merge as soon as possible the patches that get +1 from the PTL or the release liaison. #. On the Friday, merge patches that did not get any feedback from PTL or release liaison. Discuss standing -1s to see if they should be granted an exception and wait until next week.#. In the countdown email, remind everyone that the latest RC (for cycle-with-rc deliverables) or the latest intermediary release (for cycle-with-intermediary deliverables) will automatically be used as the final $series release on release day. #. Ensure that all projects that are publishing release notes have the notes link included in their deliverable file. See ``tools/add_release_note_links.sh``. #. Encourage liaisons to merge all translation patches. #. When all translations and bug fixes are merged for a project, prepare a new release candidate.",106,23
openstack%2Fcharm-placement~master~I118f10529f9c6bf91dce14f10feda828526df57a,openstack/charm-placement,master,I118f10529f9c6bf91dce14f10feda828526df57a,Initial Commit,MERGED,2019-10-10 14:33:43.000000000,2019-10-16 15:35:16.000000000,2019-10-16 15:35:16.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-10-10 14:33:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/ca4fd65c825d98ba3fe64613c7c6cc6dc9818d10', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\n'}, {'number': 2, 'created': '2019-10-10 19:54:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/c4d7884a5f0f75d159d72ea6b7476adeefa7e490', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\n'}, {'number': 3, 'created': '2019-10-10 20:02:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/31bd0598c6a0e7d7fa2995a3b754d7b057642fa7', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\n'}, {'number': 4, 'created': '2019-10-10 20:07:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/41de725b2f8dba7a0af2e4e8a2dd1f27424472ea', 'message': 'Initial Commit\n\nDepends-On: https://review.opendev.org/#/c/687911/\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\n'}, {'number': 5, 'created': '2019-10-10 20:15:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/7763985d1f45ac9ce770bedb5afeed5c19c358b5', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\nDepends-On: https://review.opendev.org/#/c/687911/\nDepends-On: https://review.opendev.org/#/c/686177/\n'}, {'number': 6, 'created': '2019-10-10 20:31:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/faf88bdb9e0f9e6ecc1e3b053384e33da184bcfa', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\nDepends-On: https://review.opendev.org/#/c/687911/\nDepends-On: https://review.opendev.org/#/c/686177/\nDepends-On: https://review.opendev.org/#/c/681343/\n'}, {'number': 7, 'created': '2019-10-15 17:59:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/facf8ceab2cd7eaf36fe26bdf5f545d2304ef9c2', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\nDepends-On: https://review.opendev.org/#/c/687911/\nDepends-On: https://review.opendev.org/#/c/686177/\nDepends-On: https://review.opendev.org/#/c/681343/\n'}, {'number': 8, 'created': '2019-10-15 18:13:57.000000000', 'files': ['.gitignore', 'test-requirements.txt', 'src/tox.ini', 'unit_tests/test_lib_charm_openstack_placement.py', 'src/metadata.yaml', 'src/test-requirements.txt', 'src/templates/train/placement.conf', 'src/layer.yaml', 'src/lib/charm/openstack/placement.py', 'requirements.txt', 'LICENSE', '.stestr.conf', 'src/reactive/placement_handlers.py', 'rebuild', 'src/lib/charm/openstack/__init__.py', 'unit_tests/test_placement_handlers.py', 'src/templates/train/placement-api.conf', '.zuul.yaml', 'unit_tests/__init__.py', 'src/reactive/__init__.py', 'src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml', 'src/README.md', 'src/lib/__init__.py', 'src/copyright', 'src/templates/train/migrate-db.rc', 'src/HACKING.md', 'tox.ini', 'src/lib/charm/__init__.py'], 'web_link': 'https://opendev.org/openstack/charm-placement/commit/170dd3310cac9817d132dbeedc70926e674f406e', 'message': 'Initial Commit\n\nChange-Id: I118f10529f9c6bf91dce14f10feda828526df57a\nDepends-On: https://review.opendev.org/#/c/687911/\nDepends-On: https://review.opendev.org/#/c/686177/\nDepends-On: https://review.opendev.org/#/c/681343/\n'}]",0,687915,170dd3310cac9817d132dbeedc70926e674f406e,46,5,8,11805,,,0,"Initial Commit

Change-Id: I118f10529f9c6bf91dce14f10feda828526df57a
Depends-On: https://review.opendev.org/#/c/687911/
Depends-On: https://review.opendev.org/#/c/686177/
Depends-On: https://review.opendev.org/#/c/681343/
",git fetch https://review.opendev.org/openstack/charm-placement refs/changes/15/687915/8 && git format-patch -1 --stdout FETCH_HEAD,"['.gitignore', 'test-requirements.txt', 'src/tox.ini', 'unit_tests/test_lib_charm_openstack_placement.py', 'src/metadata.yaml', 'src/test-requirements.txt', 'src/templates/train/placement.conf', 'src/layer.yaml', 'src/lib/charm/openstack/placement.py', 'requirements.txt', 'LICENSE', '.stestr.conf', 'src/reactive/placement_handlers.py', 'rebuild', 'src/lib/charm/openstack/__init__.py', 'unit_tests/test_placement_handlers.py', 'src/templates/train/placement-api.conf', '.zuul.yaml', 'unit_tests/__init__.py', 'src/reactive/__init__.py', 'src/tests/tests.yaml', 'src/tests/bundles/bionic-train.yaml', 'src/README.md', 'src/lib/__init__.py', 'src/copyright', 'src/templates/train/migrate-db.rc', 'src/wheelhouse.txt', 'src/HACKING.md', 'tox.ini', 'src/lib/charm/__init__.py']",30,ca4fd65c825d98ba3fe64613c7c6cc6dc9818d10,charms-train-placement,"# Copyright 2019 Canonical Ltd # # Licensed under the Apache License, Version 2.0 (the ""License""); # you may not use this file except in compliance with the License. # You may obtain a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. # See the License for the specific language governing permissions and # limitations under the License. ",,1055,0
openstack%2Fnova~master~I49196e16819abd1a4ac94619a2909ee523b14215,openstack/nova,master,I49196e16819abd1a4ac94619a2909ee523b14215,Update compute rpc version alias for train,MERGED,2019-10-14 14:58:36.000000000,2019-10-16 15:32:23.000000000,2019-10-16 06:30:49.000000000,"[{'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-14 14:58:36.000000000', 'files': ['nova/compute/rpcapi.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/de373c700748df31ee460f469fa00b48d5eab243', 'message': 'Update compute rpc version alias for train\n\nThis adds a compute rpc version alias for the named release train.\n\nChange-Id: I49196e16819abd1a4ac94619a2909ee523b14215\n'}]",1,688418,de373c700748df31ee460f469fa00b48d5eab243,35,11,1,4393,,,0,"Update compute rpc version alias for train

This adds a compute rpc version alias for the named release train.

Change-Id: I49196e16819abd1a4ac94619a2909ee523b14215
",git fetch https://review.opendev.org/openstack/nova refs/changes/18/688418/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/compute/rpcapi.py'],1,de373c700748df31ee460f469fa00b48d5eab243,train-rpc-alias," 'train': '5.3',",,1,0
openstack%2Fswift~feature%2Flosf~Ib20c0c6b984bc8f4598ffc387b66540ea93bd97f,openstack/swift,feature/losf,Ib20c0c6b984bc8f4598ffc387b66540ea93bd97f,EC frags are the ones with the #,MERGED,2019-10-04 22:16:25.000000000,2019-10-16 15:26:58.000000000,2019-10-16 15:25:21.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 25251}]","[{'number': 1, 'created': '2019-10-04 22:16:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/2c0cb657cf63bf7e0c881704ccab237256b6a137', 'message': 'EC frags are the ones with the #\n\nChange-Id: Ib20c0c6b984bc8f4598ffc387b66540ea93bd97f\n'}, {'number': 2, 'created': '2019-10-16 13:00:03.000000000', 'files': ['requirements.txt', 'swift/obj/vfile.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/a1d5a4f05796245b935056c36fb8d10e8e99ac7f', 'message': 'EC frags are the ones with the #\n\nChange-Id: Ib20c0c6b984bc8f4598ffc387b66540ea93bd97f\n'}]",0,686846,a1d5a4f05796245b935056c36fb8d10e8e99ac7f,24,3,2,15343,,,0,"EC frags are the ones with the #

Change-Id: Ib20c0c6b984bc8f4598ffc387b66540ea93bd97f
",git fetch https://review.opendev.org/openstack/swift refs/changes/46/686846/2 && git format-patch -1 --stdout FETCH_HEAD,['swift/obj/vfile.py'],1,2c0cb657cf63bf7e0c881704ccab237256b6a137,alecuyer/protobufVersion, else: sort_f = lambda x: utils.Timestamp(os.path.splitext(x)[0]), sort_f = lambda x: utils.Timestamp(os.path.splitext(x)[0]) else:,2,2
openstack%2Fkeystone~stable%2Frocky~If0eb5fe8eddc5ee32395fb34a7896efdcf0aaea3,openstack/keystone,stable/rocky,If0eb5fe8eddc5ee32395fb34a7896efdcf0aaea3,Update broken links to dogpile.cache docs,MERGED,2019-09-23 12:35:37.000000000,2019-10-16 15:25:23.000000000,2019-10-16 15:25:23.000000000,"[{'_account_id': 4}, {'_account_id': 5046}, {'_account_id': 6873}, {'_account_id': 8482}, {'_account_id': 17068}, {'_account_id': 21420}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-23 12:35:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone/commit/f51676cedd1ed3a65b70866b826f807e7253840d', 'message': 'Update broken links to dogpile.cache docs\n\nChange-Id: If0eb5fe8eddc5ee32395fb34a7896efdcf0aaea3\n'}, {'number': 2, 'created': '2019-09-23 12:37:48.000000000', 'files': ['doc/source/admin/identity-caching-layer.rst'], 'web_link': 'https://opendev.org/openstack/keystone/commit/11b2665ef8c4bfa4872a86ca8c4a00037277374e', 'message': 'Update broken links to dogpile.cache docs\n\nChange-Id: If0eb5fe8eddc5ee32395fb34a7896efdcf0aaea3\n(cherry picked from commit 3b0b392972bed152ac7170e0def0968ae1c21bdf)\n'}]",0,683945,11b2665ef8c4bfa4872a86ca8c4a00037277374e,12,7,2,10607,,,0,"Update broken links to dogpile.cache docs

Change-Id: If0eb5fe8eddc5ee32395fb34a7896efdcf0aaea3
(cherry picked from commit 3b0b392972bed152ac7170e0def0968ae1c21bdf)
",git fetch https://review.opendev.org/openstack/keystone refs/changes/45/683945/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/identity-caching-layer.rst'],1,f51676cedd1ed3a65b70866b826f807e7253840d,fix-url-404,- `dogpile.cache.memory <https://dogpilecache.sqlalchemy.org/en/latest/api.html#memory-backends>`__ - `dogpile.cache.memcached <https://dogpilecache.sqlalchemy.org/en/latest/api.html#memcached-backends>`__- `dogpile.cache.redis <https://dogpilecache.sqlalchemy.org/en/latest/api.html#redis-backends>`__ - `dogpile.cache.dbm <https://dogpilecache.sqlalchemy.org/en/latest/api.html#file-backends>`__,- `dogpile.cache.memory <https://dogpilecache.readthedocs.io/en/latest/api.html#memory-backends>`__ - `dogpile.cache.memcached <https://dogpilecache.readthedocs.io/en/latest/api.html#memcached-backends>`__- `dogpile.cache.redis <https://dogpilecache.readthedocs.io/en/latest/api.html#redis-backends>`__ - `dogpile.cache.dbm <https://dogpilecache.readthedocs.io/en/latest/api.html#file-backends>`__,4,4
openstack%2Fnova~master~Ia27ba0be6c0f5b1d936c0aa95ade3c6e6f84308e,openstack/nova,master,Ia27ba0be6c0f5b1d936c0aa95ade3c6e6f84308e,Fix misspell word,ABANDONED,2019-10-16 11:07:22.000000000,2019-10-16 15:23:07.000000000,,"[{'_account_id': 9732}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-16 11:07:22.000000000', 'files': ['nova/network/linux_net.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/2fb22aa1bc460a2ad4bf79a9c2539da690c5a033', 'message': 'Fix misspell word\n\nChange-Id: Ia27ba0be6c0f5b1d936c0aa95ade3c6e6f84308e\n'}]",0,688901,2fb22aa1bc460a2ad4bf79a9c2539da690c5a033,9,6,1,30717,,,0,"Fix misspell word

Change-Id: Ia27ba0be6c0f5b1d936c0aa95ade3c6e6f84308e
",git fetch https://review.opendev.org/openstack/nova refs/changes/01/688901/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/network/linux_net.py'],1,2fb22aa1bc460a2ad4bf79a9c2539da690c5a033,, # .. and make sure iptables won't forward it as well., # .. and make sure iptbles won't forward it as well.,1,1
openstack%2Fironic-inspector~master~I367ccfbfaf8c6cfb9be4c2cd1a56e74a400ed20f,openstack/ironic-inspector,master,I367ccfbfaf8c6cfb9be4c2cd1a56e74a400ed20f,Ignore long lines when checking docs,ABANDONED,2019-10-04 10:22:43.000000000,2019-10-16 15:23:05.000000000,,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-10-04 10:22:43.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/d951954b2b07daf1356022cb30cf41789853ddf6', 'message': 'Ignore long lines when checking docs\n\nIgnoring long lines errors when checking docs.\nThis is helpful for example when dealing with long urls.\n\nChange-Id: I367ccfbfaf8c6cfb9be4c2cd1a56e74a400ed20f\n'}]",0,686564,d951954b2b07daf1356022cb30cf41789853ddf6,8,4,1,23851,,,0,"Ignore long lines when checking docs

Ignoring long lines errors when checking docs.
This is helpful for example when dealing with long urls.

Change-Id: I367ccfbfaf8c6cfb9be4c2cd1a56e74a400ed20f
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/64/686564/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,d951954b2b07daf1356022cb30cf41789853ddf6,doc-check-ignore-long-lines, # Check the *.rst files but ignore long lines doc8 README.rst CONTRIBUTING.rst doc/source --ignore D001, doc8 README.rst CONTRIBUTING.rst doc/source,2,1
openstack%2Fopenstack-ansible~master~I24880ab92f89ca02f6b09a63da9f03dd5b230083,openstack/openstack-ansible,master,I24880ab92f89ca02f6b09a63da9f03dd5b230083,Add unified linters check,MERGED,2019-08-28 16:56:13.000000000,2019-10-16 15:20:41.000000000,2019-10-16 15:16:09.000000000,"[{'_account_id': 17068}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}, {'_account_id': 28543}, {'_account_id': 28619}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-08-28 16:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/3f8ac784723022f9154853d51f7cb432c21e0fb9', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nFor for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 2, 'created': '2019-08-28 17:13:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/26d29bbeb7cd9d813881b187f316a6891990b6da', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 3, 'created': '2019-08-28 17:42:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/94cda3c73b7283620dba517dfd74f6fd8fefc22c', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 4, 'created': '2019-08-28 19:02:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/9e587f3a33d086b9d374f2daf5de5d3411c04531', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 5, 'created': '2019-08-29 10:24:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c0f43400dbd1ff12b85d32ae58d897d7e7a8a674', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 6, 'created': '2019-08-29 10:45:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0c44824b2e01bcac3552e9fbdb1ea4f86e4ab715', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 7, 'created': '2019-08-29 12:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/6161673d6c044239c566c27c4c761a557d89388d', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 8, 'created': '2019-08-29 12:35:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/93b2b4b705aa3d6fd553fdb7215919b450befdd4', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-check which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 9, 'created': '2019-08-29 13:23:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4c3ffd87ca3e658ed3f6195d5244669bd928e2de', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 10, 'created': '2019-08-29 13:51:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0608e83de4ed16cf6dda898a8ca462fd78c588c8', 'message': ""[WIP] Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 11, 'created': '2019-08-29 14:58:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/4dda59a7b48e20e9c8f9049a0ae43b624957754a', 'message': ""[WIP] Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 12, 'created': '2019-08-29 15:57:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/0bcb8985052780a64c685cbc12bc6a99263f7031', 'message': ""[WIP] Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 13, 'created': '2019-09-02 10:00:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5ee598d65eff7890b8837cb10ea5a39c0a90816a', 'message': ""[WIP] Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 14, 'created': '2019-09-02 11:11:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/261609b828d6d0737ae637e72c6d150ebac496ad', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 15, 'created': '2019-09-09 15:25:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2519d0797e66946290a4c9c6259db1125f441ac5', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 16, 'created': '2019-09-10 12:03:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/5f45ffa6114efd6e12afc644656377e08b5686b9', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 17, 'created': '2019-10-11 20:31:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/7f854615ccb6f1a42041f557ce53e0495a961d30', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 18, 'created': '2019-10-15 10:19:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/65a3b5df9051e033f53f607fb772bc972373fcda', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}, {'number': 19, 'created': '2019-10-15 11:11:18.000000000', 'files': ['zuul.d/project-templates.yaml', 'test-requirements.txt', 'scripts/gate-check-commit.sh', 'zuul.d/playbooks/pre-gate-scenario.yml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/94e8518f682c2f5d7c78f5c0ebef62b233627b58', 'message': ""Add unified linters check\n\nSince now linters check are provided by openstack-ansible-tests repo\nwhich we're trying to get rid of, this patch implements new job template\nopenstack-ansible-linters-jobs which aims to cover linters checks, that\nwill be runned by gate-check-commit script. It provides next checks:\n- ansible-lint\n- ansible syntax-check\n- bashate\n- flake8\n\nRole for the check will be selected based on the zuul.project.short_name\nand passed as a scenario, while provided action is linters.\n\nWe can't use this check for openstack-ansible repo itself, since we have\na lot of linters debt, so we need to fix things inside roles first.\n\nDepends-On: https://review.opendev.org/679238\nDepends-On: https://review.opendev.org/679105\nChange-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083\n""}]",2,679101,94e8518f682c2f5d7c78f5c0ebef62b233627b58,68,8,19,28619,,,0,"Add unified linters check

Since now linters check are provided by openstack-ansible-tests repo
which we're trying to get rid of, this patch implements new job template
openstack-ansible-linters-jobs which aims to cover linters checks, that
will be runned by gate-check-commit script. It provides next checks:
- ansible-lint
- ansible syntax-check
- bashate
- flake8

Role for the check will be selected based on the zuul.project.short_name
and passed as a scenario, while provided action is linters.

We can't use this check for openstack-ansible repo itself, since we have
a lot of linters debt, so we need to fix things inside roles first.

Depends-On: https://review.opendev.org/679238
Depends-On: https://review.opendev.org/679105
Change-Id: I24880ab92f89ca02f6b09a63da9f03dd5b230083
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/01/679101/6 && git format-patch -1 --stdout FETCH_HEAD,"['test-requirements.txt', 'scripts/gate-check-commit.sh', 'zuul.d/playbooks/pre-gate-scenario.yml', 'zuul.d/jobs.yaml']",4,3f8ac784723022f9154853d51f7cb432c21e0fb9,linter_check,# Running linters check - job: name: openstack-ansible-linters-check parent: openstack-ansible-deploy-aio nodeset: ubuntu-bionic ,,63,1
openstack%2Fkolla~master~Id9312830fb9961927ac8d317c432f52a4ad7af24,openstack/kolla,master,Id9312830fb9961927ac8d317c432f52a4ad7af24,CI: increase both limits to 3h,MERGED,2019-10-04 09:41:19.000000000,2019-10-16 15:08:02.000000000,2019-10-04 13:41:53.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-04 09:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7170de7b6bdb45ae5bac0be1b37e3d24872c6468', 'message': 'CI: increase both limits to 3h\n\nChange-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24\n'}, {'number': 2, 'created': '2019-10-04 09:45:50.000000000', 'files': ['.zuul.d/base.yaml'], 'web_link': 'https://opendev.org/openstack/kolla/commit/7e1d3eba928ec54899f90368b0235b6737fda3b0', 'message': 'CI: increase both limits to 3h\n\nOur publishing job is barely managing to fit in 2h time so let add\nanother one.\n\nChange-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24\n'}]",0,686561,7e1d3eba928ec54899f90368b0235b6737fda3b0,11,3,2,24072,,,0,"CI: increase both limits to 3h

Our publishing job is barely managing to fit in 2h time so let add
another one.

Change-Id: Id9312830fb9961927ac8d317c432f52a4ad7af24
",git fetch https://review.opendev.org/openstack/kolla refs/changes/61/686561/2 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.d/base.yaml'],1,7170de7b6bdb45ae5bac0be1b37e3d24872c6468,686134, timeout: 10800 post-timeout: 10800, timeout: 10200 post-timeout: 7200,2,2
openstack%2Fgoal-tools~master~Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55,openstack/goal-tools,master,Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55,Add python3-train support,NEW,2019-06-21 21:28:24.000000000,2019-10-16 15:00:40.000000000,,"[{'_account_id': 8099}, {'_account_id': 11805}, {'_account_id': 11904}, {'_account_id': 18955}, {'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-06-21 21:28:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/223e0aa7205510c0b82b6aea41f0da3afcf2b6e4', 'message': 'Add python3-train support\n\nAdd patch generation scripts for the following goal:\nhttps://governance.openstack.org/tc/goals/train/python3-updates.html\n\nChange-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55\n'}, {'number': 2, 'created': '2019-06-22 17:51:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/8e452d2dcdb72e05265ab9bf136c9b1e34d6f52d', 'message': 'Add python3-train support\n\nAdd patch generation scripts for the following goal:\nhttps://governance.openstack.org/tc/goals/train/python3-updates.html\n\nChange-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55\n'}, {'number': 3, 'created': '2019-06-24 13:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/c30d0dbb0eb93c904dc3147ffdb9020dfebc7709', 'message': 'Add python3-train support\n\nAdd patch generation scripts for the following goal:\nhttps://governance.openstack.org/tc/goals/train/python3-updates.html\n\nChange-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55\n'}, {'number': 4, 'created': '2019-06-27 00:26:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/27b85e453ac081801b8abf5fff1a51eac3afa56f', 'message': 'Add python3-train support\n\nAdd patch generation scripts for the following goal:\nhttps://governance.openstack.org/tc/goals/train/python3-updates.html\n\nChange-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55\n'}, {'number': 5, 'created': '2019-09-16 13:10:17.000000000', 'files': ['tools/python3-train/functions', 'goal_tools/python3_train/repos.py', 'goal_tools/python3_train/jobs.py', 'README.rst', 'tools/python3-train/add_py3_train_job.sh', 'tools/python3-train/taskids.txt', 'tools/python3-train/do_team.sh', 'goal_tools/python3_train/__init__.py', 'goal_tools/python3_train/main.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/goal-tools/commit/efb8b18b938cb5b2d8dd5c57882122a60d027391', 'message': 'Add python3-train support\n\nAdd patch generation scripts for the following goal:\nhttps://governance.openstack.org/tc/goals/train/python3-updates.html\n\nChange-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55\n'}]",4,666934,efb8b18b938cb5b2d8dd5c57882122a60d027391,17,6,5,11805,,,0,"Add python3-train support

Add patch generation scripts for the following goal:
https://governance.openstack.org/tc/goals/train/python3-updates.html

Change-Id: Ie92629a4ba76bddd41d0d9f7a824e5f1145e3c55
",git fetch https://review.opendev.org/openstack/goal-tools refs/changes/34/666934/1 && git format-patch -1 --stdout FETCH_HEAD,"['tools/python3-train/functions', 'goal_tools/python3_train/repos.py', 'goal_tools/python3_train/jobs.py', 'README.rst', 'tools/python3-train/add_py3_train_job.sh', 'tools/python3-train/taskids.txt', 'tools/python3-train/do_team.sh', 'goal_tools/python3_train/__init__.py', 'goal_tools/python3_train/main.py', 'setup.cfg']",10,223e0aa7205510c0b82b6aea41f0da3afcf2b6e4,python3-train, python3-train = goal_tools.python3_train.main:mainpython3_train = jobs add py3 train = goal_tools.python3_train.jobs:JobsAddPy3Train repos clone = goal_tools.python3_train.repos:ReposClone repos list = goal_tools.python3_train.repos:ReposList ,,744,0
openstack%2Ftripleo-quickstart~master~I21aa1679045a41751b57d96027d24444ec8bcb62,openstack/tripleo-quickstart,master,I21aa1679045a41751b57d96027d24444ec8bcb62,Move featureset 020 tempest_workers to 2 to improve performance,ABANDONED,2019-10-15 12:53:30.000000000,2019-10-16 15:00:31.000000000,,"[{'_account_id': 8175}, {'_account_id': 8367}, {'_account_id': 8449}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 12:53:30.000000000', 'files': ['config/general_config/featureset020.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart/commit/574e23b74b82c530f9a0565fc99c6edd7369b4ab', 'message': 'Move featureset 020 tempest_workers to 2 to improve performance\n\nHoping this will help with the related bug - 3 workers may be\noverloading\n\nChange-Id: I21aa1679045a41751b57d96027d24444ec8bcb62\nRelated-bug: 1847585\n'}]",1,688701,574e23b74b82c530f9a0565fc99c6edd7369b4ab,7,7,1,8449,,,0,"Move featureset 020 tempest_workers to 2 to improve performance

Hoping this will help with the related bug - 3 workers may be
overloading

Change-Id: I21aa1679045a41751b57d96027d24444ec8bcb62
Related-bug: 1847585
",git fetch https://review.opendev.org/openstack/tripleo-quickstart refs/changes/01/688701/1 && git format-patch -1 --stdout FETCH_HEAD,['config/general_config/featureset020.yml'],1,574e23b74b82c530f9a0565fc99c6edd7369b4ab,,tempest_workers: 2,tempest_workers: 3,1,1
openstack%2Ftripleo-common~stable%2Fqueens~Ic7705efb47b1cbce1b486aff9bc40e41166ff253,openstack/tripleo-common,stable/queens,Ic7705efb47b1cbce1b486aff9bc40e41166ff253,"Revert ""Stop sending execution object via Zaqar message""",ABANDONED,2019-10-16 14:16:45.000000000,2019-10-16 14:52:40.000000000,,"[{'_account_id': 3153}, {'_account_id': 8833}, {'_account_id': 15895}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-16 14:16:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/aca369c459af8f3a4a94a8f231c07d7068814dbf', 'message': 'Revert ""Stop sending execution object via Zaqar message""\n\nAs commented on the backport this change doesn\'t seem to be inline with stable policy and I can\'t find where it is needed. It also seems to break the deploy command which looks for the execution object in queens tripleoclient.\n\nThis reverts commit 78419bcb54c578f1fdfa3cf912133cfa1d3cca11.\n\nChange-Id: Ic7705efb47b1cbce1b486aff9bc40e41166ff253\n'}, {'number': 2, 'created': '2019-10-16 14:30:49.000000000', 'files': ['workbooks/messaging.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/369bbbbbfa70c3056291db7159459c5f92d402f9', 'message': 'Revert ""Stop sending execution object via Zaqar message""\n\nAs commented on the backport this change doesn\'t seem to be inline with stable policy and I can\'t find where it is needed. It also seems to break the deploy command which looks for the execution object in queens tripleoclient.\n\nThis reverts commit 78419bcb54c578f1fdfa3cf912133cfa1d3cca11.\n\nChange-Id: Ic7705efb47b1cbce1b486aff9bc40e41166ff253\n'}]",0,688940,369bbbbbfa70c3056291db7159459c5f92d402f9,5,5,2,9712,,,0,"Revert ""Stop sending execution object via Zaqar message""

As commented on the backport this change doesn't seem to be inline with stable policy and I can't find where it is needed. It also seems to break the deploy command which looks for the execution object in queens tripleoclient.

This reverts commit 78419bcb54c578f1fdfa3cf912133cfa1d3cca11.

Change-Id: Ic7705efb47b1cbce1b486aff9bc40e41166ff253
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/40/688940/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/messaging.yaml'],1,aca369c459af8f3a4a94a8f231c07d7068814dbf,zaqar_message_too_large-stable/queens," execution: {execution details}, # Deprecated and will be removed in the future. payload: <% {status => $.status, message => $.message, execution => $.execution, execution_id => $.execution.id, plan_name => $.plan_name, deployment_status => $.deployment_status} + $.payload %>"," root_execution_id: 'UUID of the root execution', payload: <% {status => $.status, message => $.message, root_execution_id => $.execution.root_execution_id, execution_id => $.execution.id, plan_name => $.plan_name, deployment_status => $.deployment_status} + $.payload %>",2,2
openstack%2Fnova~master~I282888a74ee75c18170ddf3ea436d89b95f39074,openstack/nova,master,I282888a74ee75c18170ddf3ea436d89b95f39074,fixd notes: neuton is replaced with neutron in line 756.,ABANDONED,2019-09-28 00:00:26.000000000,2019-10-16 14:50:45.000000000,,"[{'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-09-28 00:00:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2f84dc02b0fb3d4f7a232662d4a3f0de82bb0d3b', 'message': 'fixd notes: neuton is replayced with neutron in line 756.\n\nChange-Id: I282888a74ee75c18170ddf3ea436d89b95f39074\n'}, {'number': 2, 'created': '2019-09-30 07:29:36.000000000', 'files': ['nova/virt/libvirt/vif.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/32839756f7af44daaa5b2892c2be7c5377fc0562', 'message': 'fixd notes: neuton is replaced with neutron in line 756.\n\nChange-Id: I282888a74ee75c18170ddf3ea436d89b95f39074\n'}]",1,685509,32839756f7af44daaa5b2892c2be7c5377fc0562,28,14,2,30717,,,0,"fixd notes: neuton is replaced with neutron in line 756.

Change-Id: I282888a74ee75c18170ddf3ea436d89b95f39074
",git fetch https://review.opendev.org/openstack/nova refs/changes/09/685509/2 && git format-patch -1 --stdout FETCH_HEAD,['nova/virt/libvirt/vif.py'],1,2f84dc02b0fb3d4f7a232662d4a3f0de82bb0d3b,, # a network partition in the event a vm is migrated or the neutron, # a network partition in the event a vm is migrated or the neuton,1,1
openstack%2Fnova~master~Ic38a152480b69376e17e9b320c55f4aee935ec52,openstack/nova,master,Ic38a152480b69376e17e9b320c55f4aee935ec52,first modify,ABANDONED,2019-10-16 09:13:11.000000000,2019-10-16 14:48:51.000000000,,"[{'_account_id': 9732}, {'_account_id': 10068}, {'_account_id': 14070}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-10-16 09:13:11.000000000', 'files': ['nova/api/openstack/compute/routes.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/5f17a9dc825fb4222a30b30bc7c7080c89de0e31', 'message': 'first modify\n\nChange-Id: Ic38a152480b69376e17e9b320c55f4aee935ec52\n'}]",0,688884,5f17a9dc825fb4222a30b30bc7c7080c89de0e31,10,8,1,31017,,,0,"first modify

Change-Id: Ic38a152480b69376e17e9b320c55f4aee935ec52
",git fetch https://review.opendev.org/openstack/nova refs/changes/84/688884/1 && git format-patch -1 --stdout FETCH_HEAD,['nova/api/openstack/compute/routes.py'],1,5f17a9dc825fb4222a30b30bc7c7080c89de0e31,vm-query-notsameproject, ,,2,0
openstack%2Ftripleo-quickstart-extras~master~I8c5a316145dda6497971be46f75370511a8f2103,openstack/tripleo-quickstart-extras,master,I8c5a316145dda6497971be46f75370511a8f2103,Skip dns related tests,MERGED,2019-06-10 09:29:00.000000000,2019-10-16 14:36:56.000000000,2019-06-12 12:55:26.000000000,"[{'_account_id': 5756}, {'_account_id': 8449}, {'_account_id': 9592}, {'_account_id': 9976}, {'_account_id': 10022}, {'_account_id': 10969}, {'_account_id': 11082}, {'_account_id': 12393}, {'_account_id': 13861}, {'_account_id': 18846}, {'_account_id': 22318}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24162}]","[{'number': 1, 'created': '2019-06-10 09:29:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/a514bc83870c5bd957617e5a6f98f2c21626e20b', 'message': 'Skip dns related tests\n\nIn ovn recently dns dependent tests were enabled.\nFor some of them we need to add additional configuration\nand for another one we are waiting for OVS 2.12 to be\nreleased.\n\nChange-Id: I8c5a316145dda6497971be46f75370511a8f2103\nPartial-Bug: #1832166\n'}, {'number': 2, 'created': '2019-06-10 09:49:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/c3690582378fae9184e3b5ce693e4146c07e68eb', 'message': 'Skip dns related tests\n\nIn ovn recently dns dependent tests were enabled.\nFor some of them we need to add additional configuration\nand for another one we are waiting for OVS 2.12 to be\nreleased.\n\nChange-Id: I8c5a316145dda6497971be46f75370511a8f2103\nPartial-Bug: #1832166\n'}, {'number': 3, 'created': '2019-06-10 15:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/7faee47870fb4b4f84ab876591759bcf3ff4920f', 'message': 'Skip dns related tests\n\nIn ovn recently dns dependent tests were enabled.\nFor some of them we need to add additional configuration\nand for another one we are waiting for OVS 2.12 to be\nreleased.\n\nChange-Id: I8c5a316145dda6497971be46f75370511a8f2103\nPartial-Bug: #1832166\n'}, {'number': 4, 'created': '2019-06-11 09:58:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/ab098adddad3ab7b14038314b278b6846df49562', 'message': 'Skip dns related tests\n\nIn ovn recently dns dependent tests were enabled.\nFor some of them we need to add additional configuration\nand for another one we are waiting for OVS 2.12 to be\nreleased.\n\nChange-Id: I8c5a316145dda6497971be46f75370511a8f2103\nPartial-Bug: #1832166\n'}, {'number': 5, 'created': '2019-06-11 17:56:21.000000000', 'files': ['roles/validate-tempest/vars/tempest_skip_master.yml'], 'web_link': 'https://opendev.org/openstack/tripleo-quickstart-extras/commit/26f3127b2e6c710750a70048074126cfaca7ddd1', 'message': 'Skip dns related tests\n\nIn ovn recently dns dependent tests were enabled.\nFor some of them we need to add additional configuration\nand for another one we are waiting for OVS 2.12 to be\nreleased.\n\nChange-Id: I8c5a316145dda6497971be46f75370511a8f2103\nPartial-Bug: #1832166\n'}]",1,664233,26f3127b2e6c710750a70048074126cfaca7ddd1,45,14,5,11082,,,0,"Skip dns related tests

In ovn recently dns dependent tests were enabled.
For some of them we need to add additional configuration
and for another one we are waiting for OVS 2.12 to be
released.

Change-Id: I8c5a316145dda6497971be46f75370511a8f2103
Partial-Bug: #1832166
",git fetch https://review.opendev.org/openstack/tripleo-quickstart-extras refs/changes/33/664233/4 && git format-patch -1 --stdout FETCH_HEAD,['roles/validate-tempest/vars/tempest_skip_master.yml'],1,a514bc83870c5bd957617e5a6f98f2c21626e20b,bug/1832166," - test: 'neutron_tempest_plugin.scenario.test_dns_integration.DNSIntegrationTests' reason: 'Remove this blacklist when OVS 2.12 will be released and https://patchwork.ozlabs.org/patch/1102717/ merged.' - test: 'neutron_tempest_plugin.api.test_revisions.TestRevisions.test_update_dns_domain_bumps_revision' reason: 'This test was enabled recently on ovn and we miss configuration in tripleo jobs, for sake of CI we will skip them for a now, but we will enabled them as fast as possible' lp: 'https://bugs.launchpad.net/tripleo/+bug/1832166' - test: 'neutron_tempest_plugin.scenario.test_internal_dns.InternalDNSTest.test_dns_domain_and_name' reason: 'This test was enabled recently on ovn and we miss configuration in tripleo jobs, for sake of CI we will skip them for a now, but we will enabled them as fast as possible' lp: 'https://bugs.launchpad.net/tripleo/+bug/1832166'",,8,0
openstack%2Fopenstack-manuals~master~Ib1b5794fb1d4d86c5ab388008c75f48ffd805347,openstack/openstack-manuals,master,Ib1b5794fb1d4d86c5ab388008c75f48ffd805347,Update stein index,MERGED,2019-10-15 19:48:14.000000000,2019-10-16 14:36:33.000000000,2019-10-16 13:40:09.000000000,"[{'_account_id': 10607}, {'_account_id': 22348}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-10-15 19:48:14.000000000', 'files': ['www/project-data/stein.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/30b37cf08a4547e3cac156657566d5bf5d6ef42e', 'message': 'Update stein index\n\nRemove repos that do not have stein branches or only publish from\nmaster, enable muranoclient.\n\nChange-Id: Ib1b5794fb1d4d86c5ab388008c75f48ffd805347\n'}]",0,688797,30b37cf08a4547e3cac156657566d5bf5d6ef42e,9,3,1,6547,,,0,"Update stein index

Remove repos that do not have stein branches or only publish from
master, enable muranoclient.

Change-Id: Ib1b5794fb1d4d86c5ab388008c75f48ffd805347
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/97/688797/1 && git format-patch -1 --stdout FETCH_HEAD,['www/project-data/stein.yaml'],1,30b37cf08a4547e3cac156657566d5bf5d6ef42e,stein-index,- name: python-muranoclient service: Application Catalog service Python Bindings type: service-client description: murano client,# - name: requirements # service: Global requirements for OpenStack # type: tool # - name: python-muranoclient # service: Application Catalog service Python Bindings # type: service-client # description: murano client# - name: renderspec # service: RPM .spec template renderer # type: tool # - name: tripleo-docs # type: deployment # service: Deploying OpenStack with TripleO # has_install_guide: true # - name: puppet-openstack-guide # type: deployment # service: Puppet modules for deployment # has_install_guide: true,4,20
openstack%2Ftripleo-common~stable%2Fqueens~I010ea5d732aba97a554e868f62a19e6fdaee8889,openstack/tripleo-common,stable/queens,I010ea5d732aba97a554e868f62a19e6fdaee8889,Stop sending execution object via Zaqar message,MERGED,2019-09-06 13:38:15.000000000,2019-10-16 14:16:45.000000000,2019-09-09 15:47:22.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-06 13:38:15.000000000', 'files': ['workbooks/messaging.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/78419bcb54c578f1fdfa3cf912133cfa1d3cca11', 'message': ""Stop sending execution object via Zaqar message\n\nExecution object can be quite large which is not suitable\nfor sending via Zaqar messages. Instead we're sending\nexecution_id and root_execution_id which can be used by the client\nto retrieve execution details\n\nDepends-On: Ia6c954e688589f69a7463f1b8e02244d029e8b7a\nChange-Id: I010ea5d732aba97a554e868f62a19e6fdaee8889\n(cherry picked from commit 37fc8e31717e60bf6f2e125384b095fc514ac038)\n""}]",0,680688,78419bcb54c578f1fdfa3cf912133cfa1d3cca11,10,3,1,15895,,,0,"Stop sending execution object via Zaqar message

Execution object can be quite large which is not suitable
for sending via Zaqar messages. Instead we're sending
execution_id and root_execution_id which can be used by the client
to retrieve execution details

Depends-On: Ia6c954e688589f69a7463f1b8e02244d029e8b7a
Change-Id: I010ea5d732aba97a554e868f62a19e6fdaee8889
(cherry picked from commit 37fc8e31717e60bf6f2e125384b095fc514ac038)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/88/680688/1 && git format-patch -1 --stdout FETCH_HEAD,['workbooks/messaging.yaml'],1,78419bcb54c578f1fdfa3cf912133cfa1d3cca11,zaqar_message_too_large-stable/queens," root_execution_id: 'UUID of the root execution', payload: <% {status => $.status, message => $.message, root_execution_id => $.execution.root_execution_id, execution_id => $.execution.id, plan_name => $.plan_name, deployment_status => $.deployment_status} + $.payload %>"," execution: {execution details}, # Deprecated and will be removed in the future. payload: <% {status => $.status, message => $.message, execution => $.execution, execution_id => $.execution.id, plan_name => $.plan_name, deployment_status => $.deployment_status} + $.payload %>",2,2
openstack%2Fcharm-specs~master~I3b8f22946479428f1de6108af834c0cb901cf23b,openstack/charm-specs,master,I3b8f22946479428f1de6108af834c0cb901cf23b,MySQL 8 InnoDB Cluster and MySQL Router,MERGED,2019-09-26 22:03:45.000000000,2019-10-16 14:15:26.000000000,2019-10-16 14:14:03.000000000,"[{'_account_id': 935}, {'_account_id': 10058}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-09-26 22:03:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/a005417a40e31d2c06509245986a89da3c1bc659', 'message': 'MySQL 8 InnoDB Cluster and MySQL Router\n\nChange-Id: I3b8f22946479428f1de6108af834c0cb901cf23b\n'}, {'number': 2, 'created': '2019-10-15 22:36:51.000000000', 'files': ['specs/train/approved/mysql8.rst'], 'web_link': 'https://opendev.org/openstack/charm-specs/commit/3ad31ac3e6c340e47f4d3d1991676d46a4b3c941', 'message': 'MySQL 8 InnoDB Cluster and MySQL Router\n\nChange-Id: I3b8f22946479428f1de6108af834c0cb901cf23b\n'}]",5,685182,3ad31ac3e6c340e47f4d3d1991676d46a4b3c941,14,4,2,20805,,,0,"MySQL 8 InnoDB Cluster and MySQL Router

Change-Id: I3b8f22946479428f1de6108af834c0cb901cf23b
",git fetch https://review.opendev.org/openstack/charm-specs refs/changes/82/685182/1 && git format-patch -1 --stdout FETCH_HEAD,['specs/train/approved/mysql8.rst'],1,a005417a40e31d2c06509245986a89da3c1bc659,mysql8,".. Copyright 2019 Canonical Ltd. This work is licensed under a Creative Commons Attribution 3.0 Unported License. http://creativecommons.org/licenses/by/3.0/legalcode .. This template should be in ReSTructured text. Please do not delete any of the sections in this template. If you have nothing to say for a whole section, just write: ""None"". For help with syntax, see http://sphinx-doc.org/rest.html To test out your formatting, see http://www.tele3.cz/jbar/rest/rest.html ======= MySQL 8 ======= Introduce charmed and enterprise grade MySQL 8 + InnoDB + MySQL Router as a database solution for OpenStack models with the intention of making it the default as of Ubuntu 20.04. Problem Description =================== Percona XtraDB Cluster is in Universe, has failed a Main Inclusion Request process, and will not be carried into the next LTS relative to Charmed OpenStack deployments. Proposed Change =============== These will be wholly new charms, not based in any way on existing MySQL or Percona-Cluster charms, and without a charm upgrade path. The migration story will be to get off of Percona-Cluster and onto MySQL8 while on Ubuntu 18.04 LTS, and before moving to Ubuntu 20.04 LTS. The approach for doing that is most likely to stand up a new database cluster on 20.04 alongside the old dbs, migrate data, and cut over. Details to be further specified and documented. The charms will be promulgated to the following locations: - cs:mysql-innodb-cluster - cs:mysql-router What versions of the operating system are affected or required? 19.10 (Eaon) and 20.04 What versions of OpenStack are affected or required? Train and above What version of Juju is required? Juju 2.7+ Alternatives ------------ The alternative is to bring percona-cluster into main for 20.04. Implementation ============== Assignee(s) ----------- Primary assignee: thedac Gerrit Topic ------------ Use Gerrit topic ""mysql8"" for all patches related to this spec. .. code-block:: bash git-review -t mysql8 Work Items ---------- The implementation consists of the following charms: - mysql-innodb-cluster The primary charm that will handle the mysql implementation. - Install MySQL 8 - Handle InnoDB clustering - interface-mysql-innodb-cluster The peer relationship for mysql-innodb-cluster - interface-mysql-shared provides The interface mysql-shared provides side - mysql-router The subordinate charm that will relate to the application charm and to mysql-innodb-cluster. - Proxies DB requests and responses - interface-mysql-router The interface between the application and mysql-router - mysqlsh snap The mysqlsh tool that manages the mysql innodb cluster - snapped from upstream source Repositories ------------ - charm-mysql-innodb-cluster - charm-interface-mysql-innodb-cluster - charm-mysql-router - charm-interface-mysql-router - mysqlsh-snap Documentation ------------- Each charm and interface will contain a README with instructions on deploying and relating the charm. Potentially an OpenStack deployment guide appendix to discuss clustering and cluster management. Security -------- MySQL 8 will now be in main with security auditing which percona-cluster never had. The code reviews of the work items should include a security conscious review approach. Testing ------- Unit tests for each repository. Zaza functional tests for each charm. This will include end to end testing with applications, mysql-router and mysql-inndob-cluster. Dependencies ============ - Eoan+ mysql8 packaging - MySQL shell ",,175,0
openstack%2Fos-brick~master~I51a30825da5e7378ebc1d6f4a12645d73d7feb19,openstack/os-brick,master,I51a30825da5e7378ebc1d6f4a12645d73d7feb19,nvmeof: Use subnqn to disconnect a volume,MERGED,2019-09-23 10:48:53.000000000,2019-10-16 14:10:44.000000000,2019-10-16 14:09:13.000000000,"[{'_account_id': 7198}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 14384}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 16898}, {'_account_id': 17130}, {'_account_id': 18051}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 27710}, {'_account_id': 28050}, {'_account_id': 31019}]","[{'number': 1, 'created': '2019-09-23 10:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/40a4fd6d08a67d6563bac91309a24a758118f3ea', 'message': ""nvmeof: Use subnqn to disconnect a volume\n\nnvme-cli no longer allows to use a path to nvme block device\n(e.g. /dev/nvme0n1) as an argument to nvme disconnect command.\nFor more details, please see:\nhttps://github.com/linux-nvme/nvme-cli/issues/563\n\nTo address this issue, change the command that is executed to\ndisconnect a volume from:\n\n$ nvme disconnect -d <device>\n\nto:\n\n$ nvme disconnect -n <subnqn>\n\nThis patch also fixes broken nvmeof UTs. A few tests\ncalled 'asert_called_once_with' method on mock object,\ninstead of calling 'assert_called_once_with'.\nThe mistake went undetected, because mock objects\nwere not configured to use auto-speccing.\nTo avoid the same problem in the future, configure all\nmocks to use autospec.\n\nChange-Id: I51a30825da5e7378ebc1d6f4a12645d73d7feb19\nCloses-Bug: #1843431\nSigned-off-by: Szczerbik, Przemyslaw <przemyslawx.szczerbik@intel.com>\n""}, {'number': 2, 'created': '2019-09-23 13:24:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6deb82bfee1e3b00fcbc0319161c797df7201fd5', 'message': ""nvmeof: Use subnqn to disconnect a volume\n\nnvme-cli no longer allows to use a path to nvme block device\n(e.g. /dev/nvme0n1) as an argument to nvme disconnect command.\nFor more details, please see:\nhttps://github.com/linux-nvme/nvme-cli/issues/563\n\nTo address this issue, change the command that is executed to\ndisconnect a volume from:\n\n$ nvme disconnect -d <device>\n\nto:\n\n$ nvme disconnect -n <subnqn>\n\nThis patch also fixes broken nvmeof UTs. A few tests\ncalled 'asert_called_once_with' method on mock object,\ninstead of calling 'assert_called_once_with'.\nThe mistake went undetected, because mock objects\nwere not configured to use auto-speccing.\nTo avoid the same problem in the future, configure all\nmocks to use autospec.\n\nChange-Id: I51a30825da5e7378ebc1d6f4a12645d73d7feb19\nCloses-Bug: #1843431\nSigned-off-by: Szczerbik, Przemyslaw <przemyslawx.szczerbik@intel.com>\n""}, {'number': 3, 'created': '2019-09-24 09:58:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/os-brick/commit/db4ce9e5b490cb32fdbb5b41b857bd308023c706', 'message': 'nvmeof: Use subnqn to disconnect a volume\n\nnvme-cli no longer allows to use a path to nvme block device\n(e.g. /dev/nvme0n1) as an argument to nvme disconnect command.\nFor more details, please see:\nhttps://github.com/linux-nvme/nvme-cli/issues/563\n\nTo address this issue, change the command that is executed to\ndisconnect a volume from:\n\n$ nvme disconnect -d <device>\n\nto:\n\n$ nvme disconnect -n <subnqn>\n\nChange-Id: I51a30825da5e7378ebc1d6f4a12645d73d7feb19\nCloses-Bug: #1843431\nSigned-off-by: Szczerbik, Przemyslaw <przemyslawx.szczerbik@intel.com>\n'}, {'number': 4, 'created': '2019-10-09 17:06:43.000000000', 'files': ['os_brick/initiator/connectors/nvmeof.py'], 'web_link': 'https://opendev.org/openstack/os-brick/commit/6ea276c22e204531653110089759d800fd4f7bbf', 'message': 'nvmeof: Use subnqn to disconnect a volume\n\nnvme-cli no longer allows to use a path to nvme block device\n(e.g. /dev/nvme0n1) as an argument to nvme disconnect command.\nFor more details, please see:\nhttps://github.com/linux-nvme/nvme-cli/issues/563\n\nTo address this issue, change the command that is executed to\ndisconnect a volume from:\n\n$ nvme disconnect -d <device>\n\nto:\n\n$ nvme disconnect -n <subnqn>\n\nChange-Id: I51a30825da5e7378ebc1d6f4a12645d73d7feb19\nCloses-Bug: #1843431\nSigned-off-by: Szczerbik, Przemyslaw <przemyslawx.szczerbik@intel.com>\n'}]",1,683917,6ea276c22e204531653110089759d800fd4f7bbf,72,23,4,31019,,,0,"nvmeof: Use subnqn to disconnect a volume

nvme-cli no longer allows to use a path to nvme block device
(e.g. /dev/nvme0n1) as an argument to nvme disconnect command.
For more details, please see:
https://github.com/linux-nvme/nvme-cli/issues/563

To address this issue, change the command that is executed to
disconnect a volume from:

$ nvme disconnect -d <device>

to:

$ nvme disconnect -n <subnqn>

Change-Id: I51a30825da5e7378ebc1d6f4a12645d73d7feb19
Closes-Bug: #1843431
Signed-off-by: Szczerbik, Przemyslaw <przemyslawx.szczerbik@intel.com>
",git fetch https://review.opendev.org/openstack/os-brick refs/changes/17/683917/4 && git format-patch -1 --stdout FETCH_HEAD,"['os_brick/tests/initiator/connectors/test_nvmeof.py', 'os_brick/initiator/connectors/nvmeof.py']",2,40a4fd6d08a67d6563bac91309a24a758118f3ea,nvmeof," LOG.warning(""Trying to disconnect device %(device_path)s with "" "" subnqn %(conn_nqn)s that is not connected."", {'device_path': device_path, 'conn_nqn': conn_nqn}) ""Trying to disconnect from device %(device_path)s with "" ""subnqn %(conn_nqn)s"", {'device_path': device_path, 'conn_nqn': conn_nqn}) '-n', conn_nqn]"," LOG.warning(""Trying to disconnect device %(device_path)s that "" ""is not connected."", {'device_path': device_path}) ""Trying to disconnect from NVMe nqn "" ""%(conn_nqn)s with device_path %(device_path)s"", {'conn_nqn': conn_nqn, 'device_path': device_path}) '-d', device_path]",63,49
openstack%2Fkolla-ansible~stable%2Fstein~I3dd5f5d2ba73d491366791986fdbdf16b75538ef,openstack/kolla-ansible,stable/stein,I3dd5f5d2ba73d491366791986fdbdf16b75538ef,Fixes glance image cache deployment.,MERGED,2019-10-16 09:57:16.000000000,2019-10-16 14:09:02.000000000,2019-10-16 14:07:43.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 09:57:16.000000000', 'files': ['ansible/roles/glance/templates/glance-cache.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/fdc41e3399ae2f08b10161691de3a2db3147b134', 'message': 'Fixes glance image cache deployment.\n\nDeployment fails because the variable ""glance_registry_port"" in\n""ansible/roles/glance/templates/glance-cache.conf.j2"" hasn\'t been configured\nanywhere.\n\nAlso, ""registry_host"" and ""registry_port"" were deprecated since Queens[1], so\nthey should be removed.\n\n[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html\n\nCloses-Bug: #1848146\n\nChange-Id: I3dd5f5d2ba73d491366791986fdbdf16b75538ef\n(cherry picked from commit cf1b3a73aee1889bc9865275bbf2a6062293e751)\n'}]",0,688891,fdc41e3399ae2f08b10161691de3a2db3147b134,9,3,1,30523,,,0,"Fixes glance image cache deployment.

Deployment fails because the variable ""glance_registry_port"" in
""ansible/roles/glance/templates/glance-cache.conf.j2"" hasn't been configured
anywhere.

Also, ""registry_host"" and ""registry_port"" were deprecated since Queens[1], so
they should be removed.

[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html

Closes-Bug: #1848146

Change-Id: I3dd5f5d2ba73d491366791986fdbdf16b75538ef
(cherry picked from commit cf1b3a73aee1889bc9865275bbf2a6062293e751)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/91/688891/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/glance/templates/glance-cache.conf.j2'],1,fdc41e3399ae2f08b10161691de3a2db3147b134,,,registry_host = {{ api_interface_address }} registry_port = {{ glance_registry_port }} ,0,3
openstack%2Fpuppet-barbican~master~I985341ca95807763b4ddd6653dbfcfdc87fb903a,openstack/puppet-barbican,master,I985341ca95807763b4ddd6653dbfcfdc87fb903a,Update the constraints url,MERGED,2019-10-11 00:54:50.000000000,2019-10-16 14:05:31.000000000,2019-10-16 14:03:28.000000000,"[{'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 00:54:50.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/puppet-barbican/commit/a4b07dd193d125967bfdfee5cf7177bc98916ef5', 'message': 'Update the constraints url\n\nChange-Id: I985341ca95807763b4ddd6653dbfcfdc87fb903a\n'}]",0,688014,a4b07dd193d125967bfdfee5cf7177bc98916ef5,9,2,1,23312,,,0,"Update the constraints url

Change-Id: I985341ca95807763b4ddd6653dbfcfdc87fb903a
",git fetch https://review.opendev.org/openstack/puppet-barbican refs/changes/14/688014/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,a4b07dd193d125967bfdfee5cf7177bc98916ef5,,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fopenstack-manuals~master~I816c29f1a591b7778573088ba766239037dd466a,openstack/openstack-manuals,master,I816c29f1a591b7778573088ba766239037dd466a,[www] Update settings for train/master,MERGED,2019-10-16 11:19:57.000000000,2019-10-16 14:05:01.000000000,2019-10-16 13:40:07.000000000,"[{'_account_id': 10607}, {'_account_id': 22348}, {'_account_id': 28743}]","[{'number': 1, 'created': '2019-10-16 11:19:57.000000000', 'files': ['www/project-data/train.yaml', 'www/project-data/latest.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/ceda86b9f26814b03e6cba7c9b44d9f509bbc593', 'message': '[www] Update settings for train/master\n\nSome guides have additional documents, add them.\n\nChange-Id: I816c29f1a591b7778573088ba766239037dd466a\n'}]",0,688903,ceda86b9f26814b03e6cba7c9b44d9f509bbc593,9,3,1,6547,,,0,"[www] Update settings for train/master

Some guides have additional documents, add them.

Change-Id: I816c29f1a591b7778573088ba766239037dd466a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/03/688903/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/project-data/train.yaml', 'www/project-data/latest.yaml']",2,ceda86b9f26814b03e6cba7c9b44d9f509bbc593,train, has_admin_guide: true has_user_guide: true has_user_guide: true has_user_guide: true has_user_guide: true has_config_ref: true has_install_guide: true has_admin_guide: true, has_user_guide: false,14,2
openstack%2Freleases~master~I93747459c5e4555ea3e97a02bb49a2f3e400d6d1,openstack/releases,master,I93747459c5e4555ea3e97a02bb49a2f3e400d6d1,Mark Train as released,MERGED,2019-10-10 22:06:36.000000000,2019-10-16 14:00:30.000000000,2019-10-16 14:00:30.000000000,"[{'_account_id': 308}, {'_account_id': 1736}, {'_account_id': 5263}, {'_account_id': 11904}, {'_account_id': 22348}, {'_account_id': 26458}]","[{'number': 1, 'created': '2019-10-10 22:06:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/007fea60c0ce07f9b57dc92a05690874b58c9b4a', 'message': 'Mark Train as released\n\nThe train has entered the station.\n\nChange-Id: I93747459c5e4555ea3e97a02bb49a2f3e400d6d1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 2, 'created': '2019-10-15 07:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b1803ebf7c02562be625f137c089bc018fc0f4e4', 'message': 'Mark Train as released\n\nThe train has entered the station.\n\nChange-Id: I93747459c5e4555ea3e97a02bb49a2f3e400d6d1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}, {'number': 3, 'created': '2019-10-15 13:43:41.000000000', 'files': ['openstack_releases/defaults.py', 'doc/source/train/index.rst', 'data/series_status.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/807813eda8f873052177c8b65724b1fa3926957b', 'message': 'Mark Train as released\n\nThe train has entered the station.\n\nChange-Id: I93747459c5e4555ea3e97a02bb49a2f3e400d6d1\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,687992,807813eda8f873052177c8b65724b1fa3926957b,15,6,3,11904,,,0,"Mark Train as released

The train has entered the station.

Change-Id: I93747459c5e4555ea3e97a02bb49a2f3e400d6d1
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/92/687992/1 && git format-patch -1 --stdout FETCH_HEAD,"['openstack_releases/defaults.py', 'doc/source/train/index.rst', 'data/series_status.yaml']",3,007fea60c0ce07f9b57dc92a05690874b58c9b4a,train-final, status: development status: maintained status: extended maintenance, status: future status: development status: maintained,5,5
openstack%2Fcharm-neutron-api~master~I355a136a0ced7367d69ee9fb8c3b493ddae5e087,openstack/charm-neutron-api,master,I355a136a0ced7367d69ee9fb8c3b493ddae5e087,Misc updates for OpenStack Train,MERGED,2019-10-16 08:13:08.000000000,2019-10-16 13:53:07.000000000,2019-10-16 13:53:07.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 08:13:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/920722214f31641614ff856def1a5cac6e50520b', 'message': 'Misc updates for OpenStack Train\n\nDrop install on python3-neutron-lbaas as this package has been\ndropped from the UCA at Train.\n\nAdd test bundle for train; make smoke to validate changes.\n\nChange-Id: I355a136a0ced7367d69ee9fb8c3b493ddae5e087\n'}, {'number': 2, 'created': '2019-10-16 08:13:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/f9493b5b35f59ef2375134fdc63ac1a0f5b053f3', 'message': 'Misc updates for OpenStack Train\n\nDrop install of python3-neutron-lbaas as this package has been\ndropped from the UCA at Train.\n\nAdd test bundle for train; make smoke to validate changes.\n\nChange-Id: I355a136a0ced7367d69ee9fb8c3b493ddae5e087\n'}, {'number': 3, 'created': '2019-10-16 08:28:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/0e2b05fdc216416a3f4ed6bd4b89766a22a080ac', 'message': 'Misc updates for OpenStack Train\n\nDrop install of python3-neutron-lbaas as this package has been\ndropped from the UCA at Train.\n\nAdd test bundle for train; make smoke to validate changes.\n\nChange-Id: I355a136a0ced7367d69ee9fb8c3b493ddae5e087\n'}, {'number': 4, 'created': '2019-10-16 12:52:57.000000000', 'files': ['tests/bundles/bionic-train.yaml', 'tests/tests.yaml', 'hooks/neutron_api_context.py', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/fc2a172b9b03b157e4890cb142998f30e837bac0', 'message': 'Misc updates for OpenStack Train\n\nDrop install of python3-neutron-lbaas as this package has been\ndropped from the UCA at Train.\n\nAdd test bundle for train; make smoke to validate changes.\n\nChange-Id: I355a136a0ced7367d69ee9fb8c3b493ddae5e087\n'}]",0,688874,fc2a172b9b03b157e4890cb142998f30e837bac0,20,4,4,935,,,0,"Misc updates for OpenStack Train

Drop install of python3-neutron-lbaas as this package has been
dropped from the UCA at Train.

Add test bundle for train; make smoke to validate changes.

Change-Id: I355a136a0ced7367d69ee9fb8c3b493ddae5e087
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/74/688874/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/bundles/bionic-train.yaml', 'tests/tests.yaml', 'hooks/neutron_api_utils.py', 'unit_tests/test_neutron_api_utils.py']",4,920722214f31641614ff856def1a5cac6e50520b,charms-train-function-test," def test_determine_packages_train(self): self.os_release.return_value = 'train' self.get_os_codename_install_source.return_value = 'train' pkg_list = nutils.determine_packages() expect = deepcopy(nutils.BASE_PACKAGES) expect.extend([ 'memcached', 'neutron-server', 'neutron-plugin-ml2', 'python-networking-hyperv' ]) expect.extend(nutils.KILO_PACKAGES) expect = [p for p in expect if not p.startswith('python-')] expect.extend(nutils.PY3_PACKAGES) expect.remove('python3-neutron-lbaas') self.assertEqual(sorted(pkg_list), sorted(expect)) ",,152,1
openstack%2Fironic-python-agent~master~I93d57303ac1094fc797b0197eb015d0514be8a5d,openstack/ironic-python-agent,master,I93d57303ac1094fc797b0197eb015d0514be8a5d,[WIP] Use blkid to find the target partition,ABANDONED,2019-09-27 11:34:17.000000000,2019-10-16 13:49:21.000000000,,"[{'_account_id': 11292}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-27 11:34:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/daf070a3c1fd4e8173a4e61515f9e6dd78df97fc', 'message': '[WIP] Try calling partprobe before installing bootloader\n\nChange-Id: I93d57303ac1094fc797b0197eb015d0514be8a5d\n'}, {'number': 2, 'created': '2019-10-09 14:55:00.000000000', 'files': ['ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/1788668dfa3abfc391cd7b1d3a8b1c03c093e91d', 'message': '[WIP] Use blkid to find the target partition\n\nChange-Id: I93d57303ac1094fc797b0197eb015d0514be8a5d\n'}]",0,685324,1788668dfa3abfc391cd7b1d3a8b1c03c093e91d,7,3,2,10239,,,0,"[WIP] Use blkid to find the target partition

Change-Id: I93d57303ac1094fc797b0197eb015d0514be8a5d
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/24/685324/1 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent/extensions/image.py'],1,daf070a3c1fd4e8173a4e61515f9e6dd78df97fc,partprobe,"from oslo_config import cfgCONF = cfg.CONF try: # Ensure we re-read the partition table before we try to list # partitions utils.execute('partprobe', device, run_as_root=True, attempts=CONF.disk_utils.partprobe_attempts) except (processutils.UnknownArgumentError, processutils.ProcessExecutionError, OSError) as e: LOG.warning(""Unable to probe for partitions on device %(device)s "" ""after writing the image, the partitioning table may "" ""be broken. Error: %(error)s"", {'device': device, 'error': e})",,13,0
openstack%2Fironic-python-agent~master~I4d488e4a1ab680eb1353b158c3339cb30b056ada,openstack/ironic-python-agent,master,I4d488e4a1ab680eb1353b158c3339cb30b056ada,Last resort fallback to find a partition,MERGED,2019-10-14 21:31:17.000000000,2019-10-16 13:46:23.000000000,2019-10-16 13:44:19.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-14 21:31:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/7ad0d2ad2968c8b8426561b1486b3d395afdd2ec', 'message': ""Last resort fallback to find a partition\n\nFalls back to attempt to use findfs to locate\na UUID or PARTUUID match as opposed to trying to\nlist and enumerate through lsblk output.\n\nCan confirm that tinycore 8.x's findfs binary works\nexpected.\n\nChange-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada\n""}, {'number': 2, 'created': '2019-10-15 16:24:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/5e189dd53c48e6d3ddd6235ea4342957dfabfc92', 'message': ""Last resort fallback to find a partition\n\nFalls back to attempt to use findfs to locate\na UUID or PARTUUID match as opposed to trying to\nlist and enumerate through lsblk output.\n\nCan confirm that tinycore 8.x's findfs binary works\nexpected.\n\nChange-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada\n""}, {'number': 3, 'created': '2019-10-15 16:35:19.000000000', 'files': ['ironic_python_agent/tests/unit/extensions/test_image.py', 'releasenotes/notes/fallback-to-findfs-59abde55221e1e84.yaml', 'ironic_python_agent/extensions/image.py'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent/commit/3ee17e86249b8ed6a6060ae4d6f225e85b456a13', 'message': ""Last resort fallback to find a partition\n\nFalls back to attempt to use findfs to locate\na UUID or PARTUUID match as opposed to trying to\nlist and enumerate through lsblk output.\n\nCan confirm that tinycore 8.x's findfs binary works\nexpected.\n\nStory: 2006724\nTask: 37141\n\nChange-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada\n""}]",4,688575,3ee17e86249b8ed6a6060ae4d6f225e85b456a13,18,4,3,11655,,,0,"Last resort fallback to find a partition

Falls back to attempt to use findfs to locate
a UUID or PARTUUID match as opposed to trying to
list and enumerate through lsblk output.

Can confirm that tinycore 8.x's findfs binary works
expected.

Story: 2006724
Task: 37141

Change-Id: I4d488e4a1ab680eb1353b158c3339cb30b056ada
",git fetch https://review.opendev.org/openstack/ironic-python-agent refs/changes/75/688575/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic_python_agent/tests/unit/extensions/test_image.py', 'ironic_python_agent/extensions/image.py']",2,7ad0d2ad2968c8b8426561b1486b3d395afdd2ec,story/2006419," try: findfs = utils.execute('findfs', 'UUID=%s' % uuid) return findfs except OSError: try: findfs = utils.execute('findfs', 'PARTUUID=%s' % uuid) return findfs except OSError: # Well, This din't work, so it is time to error. pass",,12,1
openstack%2Fironic-inspector~master~If954bc5e1b89a968bb8281ab6e2e12e8da6939ca,openstack/ironic-inspector,master,If954bc5e1b89a968bb8281ab6e2e12e8da6939ca,update source link in readme,MERGED,2019-10-15 11:08:42.000000000,2019-10-16 13:45:53.000000000,2019-10-16 13:44:22.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-15 11:08:42.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/ironic-inspector/commit/a380fe330f154c6d3fa6278fc3b227772536242c', 'message': 'update source link in readme\n\nChange-Id: If954bc5e1b89a968bb8281ab6e2e12e8da6939ca\n'}]",0,688678,a380fe330f154c6d3fa6278fc3b227772536242c,9,3,1,30384,,,0,"update source link in readme

Change-Id: If954bc5e1b89a968bb8281ab6e2e12e8da6939ca
",git fetch https://review.opendev.org/openstack/ironic-inspector refs/changes/78/688678/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,a380fe330f154c6d3fa6278fc3b227772536242c,,* Source: https://opendev.org/openstack/ironic-inspector/,* Source: https://git.openstack.org/cgit/openstack/ironic-inspector,1,1
openstack%2Fmistral~master~I02401b3e0471a4e29b2292da842115946867cf8e,openstack/mistral,master,I02401b3e0471a4e29b2292da842115946867cf8e,Add missing :param statement in doc string,MERGED,2019-10-15 15:07:08.000000000,2019-10-16 13:31:19.000000000,2019-10-16 13:29:44.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}, {'_account_id': 26693}]","[{'number': 1, 'created': '2019-10-15 15:07:08.000000000', 'files': ['mistral/utils/javascript.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/6284c9dcd339cee5ae8a23282527ad83f2df8886', 'message': 'Add missing :param statement in doc string\n\nChange-Id: I02401b3e0471a4e29b2292da842115946867cf8e\n'}]",0,688729,6284c9dcd339cee5ae8a23282527ad83f2df8886,13,3,1,26693,,,0,"Add missing :param statement in doc string

Change-Id: I02401b3e0471a4e29b2292da842115946867cf8e
",git fetch https://review.opendev.org/openstack/mistral refs/changes/29/688729/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/utils/javascript.py'],1,6284c9dcd339cee5ae8a23282527ad83f2df8886,missing-param, :param context: This object will be assigned to the $ javascript, context: This object will be assigned to the $ javascript,1,1
openstack%2Fironic~stable%2Ftrain~Ibeae18798a25e33fa070f1120ce0cc0981f66850,openstack/ironic,stable/train,Ibeae18798a25e33fa070f1120ce0cc0981f66850,DRAC: Fix a bug for clear_job_queue clean step with non-BIOS pending job,MERGED,2019-10-14 05:49:17.000000000,2019-10-16 13:26:11.000000000,2019-10-16 11:38:22.000000000,"[{'_account_id': 6618}, {'_account_id': 7160}, {'_account_id': 8580}, {'_account_id': 10250}, {'_account_id': 10379}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 17130}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-14 05:49:17.000000000', 'files': ['ironic/drivers/modules/drac/management.py', 'ironic/tests/unit/drivers/modules/drac/test_management.py', 'releasenotes/notes/fix_pending_non_bios_job_execution-4b22e168ac915f4f.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/006970fe86bc3f04019de9e2b557e78883450343', 'message': 'DRAC: Fix a bug for clear_job_queue clean step with non-BIOS pending job\n\nIf we create pending non-bios config job(E.g create/delete virtual disk)\nwith ""At next reboot"" option and execute ""clear_job_queue"" clean step,\nthen that job gets deleted after job execution instead of getting\ndeleted before job execution.\n\nChange-Id: Ibeae18798a25e33fa070f1120ce0cc0981f66850\nStory: #2006580\nTask: #36695\n(cherry picked from commit 4be3fcef26e63aafcefa49c8e8611bb405d0e372)\n'}]",0,688330,006970fe86bc3f04019de9e2b557e78883450343,15,11,1,29834,,,0,"DRAC: Fix a bug for clear_job_queue clean step with non-BIOS pending job

If we create pending non-bios config job(E.g create/delete virtual disk)
with ""At next reboot"" option and execute ""clear_job_queue"" clean step,
then that job gets deleted after job execution instead of getting
deleted before job execution.

Change-Id: Ibeae18798a25e33fa070f1120ce0cc0981f66850
Story: #2006580
Task: #36695
(cherry picked from commit 4be3fcef26e63aafcefa49c8e8611bb405d0e372)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/30/688330/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/drivers/modules/drac/management.py', 'ironic/tests/unit/drivers/modules/drac/test_management.py', 'releasenotes/notes/fix_pending_non_bios_job_execution-4b22e168ac915f4f.yaml']",3,006970fe86bc3f04019de9e2b557e78883450343,bug_fix_non_bios_config_job-stable/train,"--- fixes: - | Fixes a bug in the ``idrac`` hardware type where executing the ``clear_job_queue`` clean step, pending non-BIOS config jobs (E.g. create/delete virtual disk) were not being deleted before job execution. See bug `2006580 https://storyboard.openstack.org/#!/story/2006580` for details ",,156,22
openstack%2Fkolla~master~Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,openstack/kolla,master,Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48,Add disk dev name check function,MERGED,2019-10-14 05:32:16.000000000,2019-10-16 13:23:27.000000000,2019-10-16 10:11:50.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}, {'_account_id': 30687}]","[{'number': 1, 'created': '2019-10-14 05:32:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/26164ae8ab543e05161ec0020415db0a81a6a631', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n'}, {'number': 2, 'created': '2019-10-14 05:39:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f9ef1ba7632399131784dbd95f705f3dfbff07e6', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n'}, {'number': 3, 'created': '2019-10-14 10:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/2c9534181c9567734245c551610a432f6587c988', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n'}, {'number': 4, 'created': '2019-10-14 11:01:35.000000000', 'files': ['docker/ceph/ceph-osd/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/1d5f753fb13bcc3659b4abd1bb768de8550a6dc4', 'message': 'Add disk dev name check function\n\nThis patch will add new function in extend_start.sh for OSD\ncreation. Not only support loop device but also others that\ndisk dev layout is end with numbers.\n\nChange-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48\nCloses-Bug: #1847014\n'}]",0,688328,1d5f753fb13bcc3659b4abd1bb768de8550a6dc4,25,6,4,30687,,,0,"Add disk dev name check function

This patch will add new function in extend_start.sh for OSD
creation. Not only support loop device but also others that
disk dev layout is end with numbers.

Change-Id: Iee5f8b8581d70166de6eba1bdc9e42766fe8cb48
Closes-Bug: #1847014
",git fetch https://review.opendev.org/openstack/kolla refs/changes/28/688328/3 && git format-patch -1 --stdout FETCH_HEAD,['docker/ceph/ceph-osd/extend_start.sh'],1,26164ae8ab543e05161ec0020415db0a81a6a631,bug/1847014,"# Few storage device like loop or NVMe, wiil add ""p"" between disk & partition # name if disk layout is end with number. This function will fix to correct format. function part_name_checker { if [[ $1 =~ .*[0-9] ]]; then echo ${1}p${2} else echo ${1}${2} fi } sgdisk --zap-all -- $(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM) sgdisk --zap-all -- ""$(part_name_checker ${OSD_BS_BLK_DEV} ${OSD_BS_BLK_PARTNUM})"" wait_partition_appear ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DEV 2)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_WAL_DEV $OSD_BS_WAL_PARTNUM)"" sgdisk --zap-all -- ""$(part_name_checker $OSD_BS_DB_DEV $OSD_BS_DB_PARTNUM)"" mkfs.xfs -f ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" mount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" ""${OSD_DIR}"" umount ""$(part_name_checker $OSD_BS_DEV $OSD_BS_PARTNUM)"" "," if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi if [[ ""${OSD_BS_BLK_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""p${OSD_BS_BLK_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_BLK_DEV}""""${OSD_BS_BLK_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then wait_partition_appear ""${OSD_BS_DEV}""p2 sgdisk --zap-all -- ""${OSD_BS_DEV}""p2 else wait_partition_appear ""${OSD_BS_DEV}""2 sgdisk --zap-all -- ""${OSD_BS_DEV}""2 fi if [[ ""${OSD_BS_WAL_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""p${OSD_BS_WAL_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_WAL_DEV}""""${OSD_BS_WAL_PARTNUM}"" fi if [[ ""${OSD_BS_DB_DEV}"" =~ ""/dev/loop"" ]]; then sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""p${OSD_BS_DB_PARTNUM}"" else sgdisk --zap-all -- ""${OSD_BS_DB_DEV}""""${OSD_BS_DB_PARTNUM}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then mkfs.xfs -f ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" else mkfs.xfs -f ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" mount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" ""${OSD_DIR}"" fi if [[ ""${OSD_BS_DEV}"" =~ ""/dev/loop"" ]]; then umount ""${OSD_BS_DEV}""""p${OSD_BS_PARTNUM}"" else umount ""${OSD_BS_DEV}""""${OSD_BS_PARTNUM}"" fi",20,39
openstack%2Ftripleo-common~master~I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec,openstack/tripleo-common,master,I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec,"Revert ""Use tenancity to backoff when layer is locked""",ABANDONED,2019-10-14 15:02:21.000000000,2019-10-16 13:15:20.000000000,,"[{'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 9712}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-14 15:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/738fff8eb26d3e51bbf2080b096f93edbbd1c81f', 'message': 'Revert ""Use tenancity to backoff when layer is locked""\n\nMake it really ""keep retrying until we no longer have collisions"".\nThis fixes the introduced regression where tenacity might\nstop retrying after some limit values, and the originally coded exit condition would be violated then to exit before we actually no longer can have colliding locks.\n\nCloses-Bug: #1819175\n\nThis reverts commit 98f2d962f955fd57085f6c2a9fcc3882f9eaae38.\n\nChange-Id: I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec\n'}, {'number': 2, 'created': '2019-10-14 15:08:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/978b89d73611c938a39eff1b5bdc7a40142c4081', 'message': 'Revert ""Use tenancity to backoff when layer is locked""\n\nMake it really ""keep retrying until we no longer have collisions"".\nThis fixes the introduced regression where tenacity might\nstop retrying after some limit values, and the originally coded exit condition would be violated then to exit before we actually no longer can have colliding locks.\n\nCloses-Bug: #1819175\n\nThis reverts commit 98f2d962f955fd57085f6c2a9fcc3882f9eaae38.\n\nChange-Id: I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec\n'}, {'number': 3, 'created': '2019-10-15 15:20:41.000000000', 'files': ['tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c3cf93627c688c29c9fd600ed1c8b89c56c526d4', 'message': 'Revert ""Use tenancity to backoff when layer is locked""\n\nMake it really ""keep retrying until we no longer have collisions"".\nThis fixes the introduced regression where tenacity might\nstop retrying after some limit values, and the originally coded exit condition would be violated then to exit before we actually no longer can have colliding locks.\n\nCloses-Bug: #1819175\n\nThis reverts commit 98f2d962f955fd57085f6c2a9fcc3882f9eaae38.\n\nChange-Id: I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec\n'}]",0,688421,c3cf93627c688c29c9fd600ed1c8b89c56c526d4,12,7,3,6926,,,0,"Revert ""Use tenancity to backoff when layer is locked""

Make it really ""keep retrying until we no longer have collisions"".
This fixes the introduced regression where tenacity might
stop retrying after some limit values, and the originally coded exit condition would be violated then to exit before we actually no longer can have colliding locks.

Closes-Bug: #1819175

This reverts commit 98f2d962f955fd57085f6c2a9fcc3882f9eaae38.

Change-Id: I87f5b73fdd77c94ebfe0d3c5a8c06a81b8f2e3ec
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/21/688421/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_common/image/image_uploader.py'],1,738fff8eb26d3e51bbf2080b096f93edbbd1c81f,bug/1847225,import time while layer in cls.uploader_lock_info: LOG.debug('[%s] Layer is being fetched by another thread' % layer) time.sleep(0.5), if layer in cls.uploader_lock_info: LOG.debug('[%s] Layer is being fetched by another thread' % layer) raise ImageUploaderThreadException('layer being fetched'),4,3
openstack%2Fironic-python-agent-builder~master~Idb7819b1d783f4f5f390cc7621019d3be2fa576f,openstack/ironic-python-agent-builder,master,Idb7819b1d783f4f5f390cc7621019d3be2fa576f,Slim down the pre-built DIB IPA images,MERGED,2019-09-26 13:39:26.000000000,2019-10-16 13:13:15.000000000,2019-10-16 13:08:19.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-09-26 13:39:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/d786ac336c334e00e793008d45228c9df395ed23', 'message': 'Slim down the pre-built DIB IPA images\n\n* Avoid updating pip and virtualenv from source\n* Remove gcc in post-install\n* Exclude more locale files from the image\n* Exclude the content of /var/log\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n'}, {'number': 2, 'created': '2019-09-30 10:10:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/7ca8e1ffba5efb3fcff8eec502c0ddf1eaa8041d', 'message': 'WIP Slim down the pre-built DIB IPA images\n\n* Avoid updating pip and virtualenv from source\n* Move remove-extra-packages to post-install since finalise.d\n  is running on the final image and the DIB documentation\n  recommends avoiding unnecessary actions there.\n* Remove gcc and a few packages that used to be removed only\n  for Fedora\n* Exclude more locale files from the image\n* Exclude the content of /var/log\n\nAdd CI jobs that ensure we can build images with Ubuntu, Debian and Fedora.\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n'}, {'number': 3, 'created': '2019-09-30 11:44:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/56d0d049d138727d778fbcd4080834a035daa596', 'message': ""Slim down the pre-built DIB IPA images\n\n* Avoid updating pip and virtualenv from source.\n* Move remove-extra-packages to post-install since finalise.d\n  is running on the final image and the DIB documentation\n  recommends avoiding unnecessary actions there.\n* Remove a few packages that used to be removed only for Fedora;\n  do not try to remove those that aren't on the cloud image.\n* Do all uninstallations in pre-install phase, so that it doesn't try\n  to remove dependencies of already installed packages.\n* Exclude more locale files from the image.\n* Exclude the content of /var/log.\n\nAdd CI jobs that ensure we can build images with Ubuntu, Debian and Fedora.\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n""}, {'number': 4, 'created': '2019-09-30 12:15:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/97e49d101cede14890ece6db58a7344ca76ca11d', 'message': ""Slim down the pre-built DIB IPA images\n\n* Move remove-extra-packages to post-install since finalise.d\n  is running on the final image and the DIB documentation\n  recommends avoiding unnecessary actions there.\n* Remove a few packages that used to be removed only for Fedora;\n  do not try to remove those that aren't on the cloud image.\n* Do all uninstallations in pre-install phase, so that it doesn't try\n  to remove dependencies of already installed packages.\n* Exclude more locale files from the image.\n* Exclude the content of /var/log.\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n""}, {'number': 5, 'created': '2019-09-30 12:49:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/59c8cd9d4aec7d0f8c289aaf518ea1ba6c9ba5a5', 'message': ""Slim down the pre-built DIB IPA images\n\n* Move remove-extra-packages to post-install since finalise.d\n  is running on the final image and the DIB documentation\n  recommends avoiding unnecessary actions there.\n* Remove a few packages that used to be removed only for Fedora;\n  do not try to remove those that aren't on the cloud image.\n* Do all uninstallations in pre-install phase, so that it doesn't try\n  to remove dependencies of already installed packages.\n* Exclude more locale files from the image.\n* Exclude the content of /var/log.\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n""}, {'number': 6, 'created': '2019-10-09 09:32:34.000000000', 'files': ['dib/ironic-python-agent-ramdisk/package-installs.yaml', 'dib/ironic-python-agent-ramdisk/environment.d/20-ipa-distro-family.bash', 'dib/ironic-python-agent-ramdisk/finalise.d/99-remove-extra-packages', 'dib/ironic-python-agent-ramdisk/cleanup.d/99-ramdisk-create', 'dib/ironic-python-agent-ramdisk/post-install.d/99-remove-extra-packages', 'dib/ironic-python-agent-ramdisk/post-install.d/80-ironic-python-agent-ramdisk'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/f45996c192d3abfd6658b0e0ee24643de3de75fd', 'message': ""Slim down the pre-built DIB IPA images\n\n* Move remove-extra-packages to post-install since finalise.d\n  is running on the final image and the DIB documentation\n  recommends avoiding unnecessary actions there.\n* Remove a few packages that used to be removed only for Fedora;\n  do not try to remove those that aren't on the cloud image.\n* Do all uninstallations in pre-install phase, so that it doesn't try\n  to remove dependencies of already installed packages.\n* Exclude more locale files from the image.\n* Exclude the content of /var/log.\n\nChange-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f\n""}]",0,685075,f45996c192d3abfd6658b0e0ee24643de3de75fd,23,4,6,10239,,,0,"Slim down the pre-built DIB IPA images

* Move remove-extra-packages to post-install since finalise.d
  is running on the final image and the DIB documentation
  recommends avoiding unnecessary actions there.
* Remove a few packages that used to be removed only for Fedora;
  do not try to remove those that aren't on the cloud image.
* Do all uninstallations in pre-install phase, so that it doesn't try
  to remove dependencies of already installed packages.
* Exclude more locale files from the image.
* Exclude the content of /var/log.

Change-Id: Idb7819b1d783f4f5f390cc7621019d3be2fa576f
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/75/685075/6 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ipa-build-dib-image/tasks/main.yaml', 'dib/ironic-python-agent-ramdisk/cleanup.d/99-ramdisk-create', 'dib/ironic-python-agent-ramdisk/post-install.d/80-ironic-python-agent-ramdisk']",3,d786ac336c334e00e793008d45228c9df395ed23,diet,install-packages -e cloud-init gcc,install-packages -e cloud-init,6,1
openstack%2Fironic-lib~master~I2241bfd11c66fb84b8840ab76563af52fe93e5ad,openstack/ironic-lib,master,I2241bfd11c66fb84b8840ab76563af52fe93e5ad,Move ironic-lib.filters to etc/ironic/rootwrap.d,MERGED,2019-09-25 15:01:28.000000000,2019-10-16 13:11:22.000000000,2019-09-27 09:04:42.000000000,"[{'_account_id': 6618}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-09-25 15:01:28.000000000', 'files': ['etc/ironic/rootwrap.d/ironic-lib.filters'], 'web_link': 'https://opendev.org/openstack/ironic-lib/commit/c4d1162f19b2db4d3c89a5ee4acd828644d5ee8e', 'message': 'Move ironic-lib.filters to etc/ironic/rootwrap.d\n\nThis is the path where ironic searches for rootwrap filter files by\ndefault.\nThis is important because ironic itself is going to remove [1] its\ncopy of the ironic-lib.filters file.\n\n[1] https://review.opendev.org/#/c/684270\n\nChange-Id: I2241bfd11c66fb84b8840ab76563af52fe93e5ad\n'}]",0,684771,c4d1162f19b2db4d3c89a5ee4acd828644d5ee8e,12,3,1,7102,,,0,"Move ironic-lib.filters to etc/ironic/rootwrap.d

This is the path where ironic searches for rootwrap filter files by
default.
This is important because ironic itself is going to remove [1] its
copy of the ironic-lib.filters file.

[1] https://review.opendev.org/#/c/684270

Change-Id: I2241bfd11c66fb84b8840ab76563af52fe93e5ad
",git fetch https://review.opendev.org/openstack/ironic-lib refs/changes/71/684771/1 && git format-patch -1 --stdout FETCH_HEAD,['etc/ironic/rootwrap.d/ironic-lib.filters'],1,c4d1162f19b2db4d3c89a5ee4acd828644d5ee8e,,,,0,0
openstack%2Fironic-python-agent-builder~master~Ife73d59b8e5c4454634d0e6c4f23daaf7cc9fb66,openstack/ironic-python-agent-builder,master,Ife73d59b8e5c4454634d0e6c4f23daaf7cc9fb66,DIB: allow disabling rescue mode,MERGED,2019-09-30 08:58:04.000000000,2019-10-16 13:10:35.000000000,2019-10-16 13:08:19.000000000,"[{'_account_id': 10239}, {'_account_id': 15064}, {'_account_id': 15519}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-09-30 08:58:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/cab661a4be2a8d80a04545100aae30defaaebd0d', 'message': 'DIB: allow disabling rescue mode\n\nChange-Id: Ife73d59b8e5c4454634d0e6c4f23daaf7cc9fb66\n'}, {'number': 2, 'created': '2019-10-09 09:32:04.000000000', 'files': ['doc/source/admin/dib.rst', 'dib/ironic-python-agent-ramdisk/README.rst', 'dib/ironic-python-agent-ramdisk/post-install.d/80-ironic-python-agent-ramdisk'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/cecbc860dd2d161ac663ee3ee6db00984a533260', 'message': 'DIB: allow disabling rescue mode\n\nChange-Id: Ife73d59b8e5c4454634d0e6c4f23daaf7cc9fb66\n'}]",0,685662,cecbc860dd2d161ac663ee3ee6db00984a533260,28,6,2,10239,,,0,"DIB: allow disabling rescue mode

Change-Id: Ife73d59b8e5c4454634d0e6c4f23daaf7cc9fb66
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/62/685662/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/admin/dib.rst', 'dib/ironic-python-agent-ramdisk/README.rst', 'dib/ironic-python-agent-ramdisk/post-install.d/80-ironic-python-agent-ramdisk']",3,cab661a4be2a8d80a04545100aae30defaaebd0d,rescue,DIB_IPA_ENABLE_RESCUE=${DIB_IPA_ENABLE_RESCUE:-true} if $DIB_IPA_ENABLE_RESCUE; then # Make sure rescue works mkdir -p /etc/ipa-rescue-config fi if $DIB_IPA_ENABLE_RESCUE; then systemctl enable ironic-agent-create-rescue-user.path fi,# Make sure rescue works mkdir -p /etc/ipa-rescue-config systemctl enable ironic-agent-create-rescue-user.path,21,6
openstack%2Fpython-magnumclient~stable%2Ftrain~I98b662b5a95f16d80852e3b30683c75e78acb3e5,openstack/python-magnumclient,stable/train,I98b662b5a95f16d80852e3b30683c75e78acb3e5,Add nodegroup CRUD commands,MERGED,2019-10-16 08:08:14.000000000,2019-10-16 13:01:31.000000000,2019-10-16 13:00:21.000000000,"[{'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27057}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-10-16 08:08:14.000000000', 'files': ['magnumclient/tests/osc/unit/v1/test_nodegroups.py', 'magnumclient/tests/v1/test_nodegroups.py', 'magnumclient/tests/osc/unit/v1/fakes.py', 'setup.cfg', 'magnumclient/osc/v1/nodegroups.py', 'magnumclient/v1/nodegroups.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/8106c5ff0020aefd755af66cdf8f2c49bb68f969', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n(cherry picked from commit 934cf548540086268991dab47b5bcb85f65b693f)\n'}]",0,688873,8106c5ff0020aefd755af66cdf8f2c49bb68f969,8,4,1,20498,,,0,"Add nodegroup CRUD commands

The commands added are:

* openstack coe nodegroup create <params> <cluster> <nodegroup>
* openstack coe nodegroup delete <cluster> <nodegroup>
* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>

Depends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c
Change-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5
(cherry picked from commit 934cf548540086268991dab47b5bcb85f65b693f)
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/73/688873/1 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/tests/osc/unit/v1/test_nodegroups.py', 'magnumclient/tests/v1/test_nodegroups.py', 'magnumclient/tests/osc/unit/v1/fakes.py', 'setup.cfg', 'magnumclient/osc/v1/nodegroups.py', 'magnumclient/v1/nodegroups.py']",6,8106c5ff0020aefd755af66cdf8f2c49bb68f969,magnum_nodegroups-stable/train,"from magnumclient import exceptions def create(self, cluster_id, **kwargs): new = {} for (key, value) in kwargs.items(): if key in CREATION_ATTRIBUTES: new[key] = value else: raise exceptions.InvalidAttribute( ""Key must be in %s"" % "","".join(CREATION_ATTRIBUTES)) return self._create(self._path(cluster_id), new) def delete(self, cluster_id, id): return self._delete(self._path(cluster_id, id=id)) def update(self, cluster_id, id, patch): return self._update(self._path(cluster_id, id=id), patch)",,483,5
openstack%2Fcharm-neutron-api~master~Ia7e3b95d234a449606a3707809810a9ace27bbdc,openstack/charm-neutron-api,master,Ia7e3b95d234a449606a3707809810a9ace27bbdc,Enable functional tests for train,ABANDONED,2019-09-09 20:38:06.000000000,2019-10-16 12:55:19.000000000,,"[{'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-09 20:38:06.000000000', 'files': ['tests/tests.yaml', 'tests/bionic-train.yaml', 'tests/bionic-train-dvr-snat.yaml', 'tests/bionic-train-dvr.yaml'], 'web_link': 'https://opendev.org/openstack/charm-neutron-api/commit/1e1b36808729495aadcf9ad0137ac0c1919bcdb9', 'message': 'Enable functional tests for train\n\nThis patch also updates the smoke test to run train.\n\nDepends-On: https://review.opendev.org/#/c/678219/\nChange-Id: Ia7e3b95d234a449606a3707809810a9ace27bbdc\n'}]",0,681118,1e1b36808729495aadcf9ad0137ac0c1919bcdb9,5,2,1,11805,,,0,"Enable functional tests for train

This patch also updates the smoke test to run train.

Depends-On: https://review.opendev.org/#/c/678219/
Change-Id: Ia7e3b95d234a449606a3707809810a9ace27bbdc
",git fetch https://review.opendev.org/openstack/charm-neutron-api refs/changes/18/681118/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/tests.yaml', 'tests/bionic-train.yaml', 'tests/bionic-train-dvr-snat.yaml', 'tests/bionic-train-dvr.yaml']",4,1e1b36808729495aadcf9ad0137ac0c1919bcdb9,charms-train-function-test,"variables: openstack-origin: &openstack-origin cloud:bionic-train series: &series bionic machines: 0: constraints: ""mem=3072M"" 1: {} 2: {} 3: {} 4: {} 5: {} 6: {} 7: constraints: ""root-disk=20G mem=4G"" 8: constraints: ""root-disk=20G mem=4G"" # We specify machine placements for these to improve iteration # time, given that machine ""0"" comes up way before machine ""7"" applications: percona-cluster: charm: cs:~openstack-charmers-next/percona-cluster num_units: 1 options: source: *openstack-origin to: - '0' rabbitmq-server: charm: cs:~openstack-charmers-next/rabbitmq-server num_units: 1 options: source: *openstack-origin to: - '1' neutron-api: charm: ../../../neutron-api series: *series num_units: 1 options: overlay-network-type: 'vxlan' l2-population: True flat-network-providers: physnet1 neutron-security-groups: true openstack-origin: *openstack-origin enable-dvr: True to: - '2' keystone: charm: cs:~openstack-charmers-next/keystone num_units: 1 options: openstack-origin: *openstack-origin to: - '3' glance: charm: cs:~openstack-charmers-next/glance num_units: 1 options: openstack-origin: *openstack-origin to: - '4' neutron-openvswitch: charm: cs:~openstack-charmers-next/neutron-openvswitch options: enable-local-dhcp-and-metadata: True bridge-mappings: physnet1:br-ex neutron-gateway: charm: cs:~openstack-charmers-next/neutron-gateway num_units: 1 options: bridge-mappings: physnet1:br-ex openstack-origin: *openstack-origin to: - '5' nova-cloud-controller: charm: cs:~openstack-charmers-next/nova-cloud-controller num_units: 1 options: network-manager: Neutron openstack-origin: *openstack-origin to: - '6' nova-compute: charm: cs:~openstack-charmers-next/nova-compute num_units: 2 options: config-flags: default_ephemeral_format=ext4 enable-live-migration: true enable-resize: true migration-auth-type: ssh openstack-origin: *openstack-origin to: - '7' - '8' relations: - - 'neutron-api:shared-db' - 'percona-cluster:shared-db' - - 'neutron-api:amqp' - 'rabbitmq-server:amqp' - - 'neutron-api:neutron-api' - 'nova-cloud-controller:neutron-api' - - 'neutron-api:neutron-plugin-api' - 'neutron-gateway:neutron-plugin-api' - - 'neutron-api:identity-service' - 'keystone:identity-service' - - 'keystone:shared-db' - 'percona-cluster:shared-db' - - 'nova-compute:neutron-plugin' - 'neutron-openvswitch:neutron-plugin' - - 'neutron-api:neutron-plugin-api' - 'neutron-openvswitch:neutron-plugin-api' - - 'nova-cloud-controller:shared-db' - 'percona-cluster:shared-db' - - 'neutron-gateway:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:amqp' - 'rabbitmq-server:amqp' - - 'neutron-openvswitch:amqp' - 'rabbitmq-server:amqp' - - 'nova-cloud-controller:identity-service' - 'keystone:identity-service' - - 'nova-cloud-controller:cloud-compute' - 'nova-compute:cloud-compute' - - 'glance:identity-service' - 'keystone:identity-service' - - 'glance:shared-db' - 'percona-cluster:shared-db' - - 'glance:amqp' - 'rabbitmq-server:amqp' - - 'nova-compute:image-service' - 'glance:image-service' - - 'nova-cloud-controller:image-service' - 'glance:image-service' - - 'nova-cloud-controller:quantum-network-service' - 'neutron-gateway:quantum-network-service' ",,399,1
openstack%2Fpuppet-neutron~stable%2Fstein~I8248ad80e6ff88aec252919fa687018bda78a60b,openstack/puppet-neutron,stable/stein,I8248ad80e6ff88aec252919fa687018bda78a60b,Ensure tunnel types are absent if not configured,MERGED,2019-06-19 17:07:39.000000000,2019-10-16 12:50:45.000000000,2019-10-16 12:50:44.000000000,"[{'_account_id': 6681}, {'_account_id': 9414}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-19 17:07:39.000000000', 'files': ['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp'], 'web_link': 'https://opendev.org/openstack/puppet-neutron/commit/5c261512c50da865efbceaa74e370cbe96fb7215', 'message': ""Ensure tunnel types are absent if not configured\n\nThis patch fixes a bug where updating a configuration wouldn't remove\nagent/tunnel_types configuration when required.\n\nChange-Id: I8248ad80e6ff88aec252919fa687018bda78a60b\nCloses-Bug: #1832251\n(cherry picked from commit 6c34ce2a42ae8c445a1fbe14ab18d4ee59e09c9b)\n""}]",0,666403,5c261512c50da865efbceaa74e370cbe96fb7215,12,5,1,6681,,,0,"Ensure tunnel types are absent if not configured

This patch fixes a bug where updating a configuration wouldn't remove
agent/tunnel_types configuration when required.

Change-Id: I8248ad80e6ff88aec252919fa687018bda78a60b
Closes-Bug: #1832251
(cherry picked from commit 6c34ce2a42ae8c445a1fbe14ab18d4ee59e09c9b)
",git fetch https://review.opendev.org/openstack/puppet-neutron refs/changes/03/666403/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/classes/neutron_agents_ml2_ovs_spec.rb', 'manifests/agents/ml2/ovs.pp']",2,5c261512c50da865efbceaa74e370cbe96fb7215,bug/1832251, 'agent/tunnel_types': ensure => absent;,,2,0
openstack%2Fopenstack-helm~master~Id546c113b2d3c42591a0326ee8cd442cccc73578,openstack/openstack-helm,master,Id546c113b2d3c42591a0326ee8cd442cccc73578,Remove need to configure VF during DPDK deployment,MERGED,2019-10-02 08:41:11.000000000,2019-10-16 12:50:00.000000000,2019-10-16 12:48:04.000000000,"[{'_account_id': 8898}, {'_account_id': 16353}, {'_account_id': 18250}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 27589}, {'_account_id': 30220}]","[{'number': 1, 'created': '2019-10-02 08:41:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/24be081719535bd7cd6b1ed98b732eaa806c97ec', 'message': 'Remove need to configure VF during DPDK deployment\n\nThe current configuration expects VF & bonding info by default. This patch\nset removes the need to configure them for every deployment.\n\nChange-Id: Id546c113b2d3c42591a0326ee8cd442cccc73578\n'}, {'number': 2, 'created': '2019-10-02 12:05:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/d5850183e37a24f4f2ef2e0b91178f2aaed2eb0e', 'message': 'Remove need to configure VF during DPDK deployment\n\nThe current configuration expects VF & bonding info by default. This patch\nset removes the need to configure them for every deployment.\n\nChange-Id: Id546c113b2d3c42591a0326ee8cd442cccc73578\n'}, {'number': 3, 'created': '2019-10-09 09:40:16.000000000', 'files': ['neutron/values_overrides/dpdk.yaml', 'neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/05bff26162cc05286ba563d6e8cec82a36031b7d', 'message': 'Remove need to configure VF during DPDK deployment\n\nThe current configuration expects VF & bonding info by default. This patch\nset removes the need to configure them for every deployment.\n\nChange-Id: Id546c113b2d3c42591a0326ee8cd442cccc73578\n'}]",3,686107,05bff26162cc05286ba563d6e8cec82a36031b7d,21,7,3,30220,,,0,"Remove need to configure VF during DPDK deployment

The current configuration expects VF & bonding info by default. This patch
set removes the need to configure them for every deployment.

Change-Id: Id546c113b2d3c42591a0326ee8cd442cccc73578
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/07/686107/1 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/values_overrides/dpdk.yaml', 'neutron/templates/bin/_neutron-openvswitch-agent-init.sh.tpl']",2,24be081719535bd7cd6b1ed98b732eaa806c97ec,ovsdpdk," ip link set ${iface} promisc on ip link set ${iface} ${vf_string} trust on ip link set ${iface} ${vf_string} spoofchk off if [ -n ""${iface}"" ]; then ip link set ${iface} promisc on if [ -n ""${vf_index}"" ]; then vf_string=""vf ${vf_index}"" ip link set ${iface} ${vf_string} trust on ip link set ${iface} ${vf_string} spoofchk off fi"," ip link set ${iface} promisc on ip link set ${iface} ${vf_string} trust on ip link set ${iface} ${vf_string} spoofchk off if [ -n ""${vf_index}"" ]; then vf_string=""vf ${vf_index}"" ip link set ${iface} promisc on ip link set ${iface} ${vf_string} trust on ip link set ${iface} ${vf_string} spoofchk off ",12,10
openstack%2Ftripleo-common~master~I1e1621537ed040548456a1699b972add1636e6ec,openstack/tripleo-common,master,I1e1621537ed040548456a1699b972add1636e6ec,Never block or wait when workers upload images,ABANDONED,2019-10-04 15:59:30.000000000,2019-10-16 12:45:32.000000000,,"[{'_account_id': 4571}, {'_account_id': 6926}, {'_account_id': 9712}, {'_account_id': 11082}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-04 15:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6a7184ecdfc38418f6cb1f97956b7209e2d5a294', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do not block\non locked layers. If layers locked, workers firstly will look for a free\nlayers, or free images. If there is no more retries in the budget, workers will\nre-enter in the boring mode and will wait for the layer locks to release\nmeanwhile doing nothing useful.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the locks-free\nand non-blocking way, but also keeping the possibility to finish the undone\nthings using the traditional locks.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-10-04 16:08:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/e59ebe1c79f4607f7c51912f250500d733ef857b', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do not block\non locked layers. If layers locked, workers firstly will look for a free\nlayers, or free images. If there is no more retries in the budget, workers will\nre-enter in the boring mode and will wait for the layer locks to release\nmeanwhile doing nothing useful.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the locks-free\nand non-blocking way, but also keeping the possibility to finish the undone\nthings using the traditional locks.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2019-10-04 16:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6886cd642b7644eedb4cbaf45b161ceee4267c89', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do not block\non locked layers. If layers locked, workers firstly will look for a free\nlayers, or free images. If there is no more retries in the budget, workers will\nre-enter in the boring mode and will wait for the layer locks to release\nmeanwhile doing nothing useful.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the locks-free\nand non-blocking way, but also keeping the possibility to finish the undone\nthings using the traditional locks.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 4, 'created': '2019-10-04 16:44:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/ca96ba625f72d92b157bf1c923bfdb60cc5260bb', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do not block\non locked layers. If layers locked, workers firstly will look for a free\nlayers, or free images. If there is no more retries in the budget, workers will\nre-enter in the boring mode and will wait for the layer locks to release\nmeanwhile doing nothing useful.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the locks-free\nand non-blocking way, but also keeping the possibility to finish the undone\nthings using the traditional locks.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 5, 'created': '2019-10-07 14:59:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/66548ceae7a891972f57cb611d0d9684828ed468', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do not block\non locked layers. If layers locked, workers firstly will look for a free\nlayers, or free images. If there is no more retries in the budget, workers will\nre-enter in the boring mode and will wait for the layer locks to release\nmeanwhile doing nothing useful.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the locks-free\nand non-blocking way, but also keeping the possibility to finish the undone\nthings using the traditional locks.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 6, 'created': '2019-10-07 15:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/b63ce7612e169104b99e6daef183fa4eea6206a6', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do\nnot block on locked layers. If layers locked, workers firstly will look\nfor a free layers, or free images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* In the creative workers mode, increase minimum numbers of workers\n  to a 4 and do not process the first image as a separate.\n  Layers/images locking ensures no data races, when picking several\n  images for concurrent processing.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 7, 'created': '2019-10-07 16:31:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/a06edfe677c97f98ad181dbec5e7135eae40be7c', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do\nnot block on locked layers. If layers locked, workers firstly will look\nfor a free layers, or free images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* In the creative workers mode, increase minimum numbers of workers\n  to a 4 and do not process the first image as a separate.\n  Layers/images locking ensures no data races, when picking several\n  images for concurrent processing.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 8, 'created': '2019-10-07 16:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/4687a44af62fbc6b4673b2611a8b7bbbf344dd7b', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do\nnot block on locked layers. If layers locked, workers firstly will look\nfor a free layers, or free images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* In the creative workers mode, increase minimum numbers of workers\n  to a 4 and do not process the first image as a separate.\n  Layers/images locking ensures no data races, when picking several\n  images for concurrent processing.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 9, 'created': '2019-10-07 16:46:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/8fee6457077ef7857dab8aec1884a4cb38a5c0c4', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do\nnot block on locked layers. If layers locked, workers firstly will look\nfor a free layers, or free images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* In the creative workers mode, increase minimum numbers of workers\n  to a 4 and do not process the first image as a separate.\n  Layers/images locking ensures no data races, when picking several\n  images for concurrent processing.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 10, 'created': '2019-10-07 16:49:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fbef9987c6e98459a36351cdd9f082d04a026102', 'message': 'WIP Be creative workers when uploading images\n\nMultiple workers start in the creative mode and will cooperate and do\nnot block on locked layers. If layers locked, workers firstly will look\nfor a free layers, or free images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* In the creative workers mode, increase minimum numbers of workers\n  to a 4 and do not process the first image as a separate.\n  Layers/images locking ensures no data races, when picking several\n  images for concurrent processing.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 11, 'created': '2019-10-08 08:20:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/41f910f31d39862bf0a98fee65293a27597571b4', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Extend layers locks management for images uploading as well\n* Move locks management and the upload tasks function to the base image\n  uploader class as the requirement of the former\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 12, 'created': '2019-10-08 13:17:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/82c7b8c7c3fde9ac737dca64ed20c4b43421b83b', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 13, 'created': '2019-10-08 13:35:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/713237aec39bfee111cf09641ff8e3c221bd6312', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 14, 'created': '2019-10-08 14:08:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fdf6995152580d6730160d8c62f81e00d71d762c', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 15, 'created': '2019-10-09 12:28:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/709e538c6db870e966b9c15b61bda9b969052eb2', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 16, 'created': '2019-10-09 15:11:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7908ce002a88a8bda51fd5f8af458dc44f3a47b3', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 17, 'created': '2019-10-09 15:14:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/92f6f99201fae53379fa0f75b5f0a98f1340df86', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 18, 'created': '2019-10-09 15:58:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/fdb09088497c960db93f1b56b77a6bd2e0f7870b', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 19, 'created': '2019-10-10 10:05:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/3456b12916827bf7ae7f8f26dbd7ce157c67c1ec', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 20, 'created': '2019-10-10 13:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/172b3a1132a68ebf8e511910f8573ca620948c9d', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 21, 'created': '2019-10-10 13:44:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/6ba34ea67c1d5452f057290f5c1f23a8c707a349', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}, {'number': 22, 'created': '2019-10-10 14:57:02.000000000', 'files': ['tripleo_common/image/exception.py', 'tripleo_common/image/image_uploader.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/f5c7ce999e57c89ed9181cd788a32abadbff8f5f', 'message': ""Never block or wait when workers upload images\n\nMultiple workers will not block on locked layers. If layers locked,\nworkers firstly will look for a free (unlocked) layers of the image\nbeing processed, or another (unlocked) images.\n\nThis reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the\nlocks-free and non-blocking way. Locking both images and its layers\ntogether with emoving exp-backoff sleeping of workers, when there is\ncollisions happen on layers allows running more concurrent workers\nin the more efficient way (each worker always does some job and never\nsleeps or blocks on something). Additionally that allows omitting\npulling the first image in a single worker mode, which also somewhat\nspeeds up the process. That is mainly because layers & images global\npool of locks ensures no data races, when picking several images for\nconcurrent processing, so a pair of workers will never end up pulling\nthe same layer, even it's contained by different images under\nprocessing.\n\nLower level changes explained:\n* Drop tenacity retrying on the collisions detected for layers/images\n  as we do not need that any more and just raise for the worker to pick\n  another layer or image to process\n* Increase minimum numbers of workers to a 4 and do not process the\n  first image as a separate.\n\nRelated-Bug: #1844446\nDepends-on: https://review.opendev.org/687294\nChange-Id: I1e1621537ed040548456a1699b972add1636e6ec\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n""}]",12,686756,f5c7ce999e57c89ed9181cd788a32abadbff8f5f,78,7,22,6926,,,0,"Never block or wait when workers upload images

Multiple workers will not block on locked layers. If layers locked,
workers firstly will look for a free (unlocked) layers of the image
being processed, or another (unlocked) images.

This reimplements I477219b7dca1e6cfa02a278c55a0cc1a9833d007 in the
locks-free and non-blocking way. Locking both images and its layers
together with emoving exp-backoff sleeping of workers, when there is
collisions happen on layers allows running more concurrent workers
in the more efficient way (each worker always does some job and never
sleeps or blocks on something). Additionally that allows omitting
pulling the first image in a single worker mode, which also somewhat
speeds up the process. That is mainly because layers & images global
pool of locks ensures no data races, when picking several images for
concurrent processing, so a pair of workers will never end up pulling
the same layer, even it's contained by different images under
processing.

Lower level changes explained:
* Drop tenacity retrying on the collisions detected for layers/images
  as we do not need that any more and just raise for the worker to pick
  another layer or image to process
* Increase minimum numbers of workers to a 4 and do not process the
  first image as a separate.

Related-Bug: #1844446
Depends-on: https://review.opendev.org/687294
Change-Id: I1e1621537ed040548456a1699b972add1636e6ec
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/56/686756/20 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/image/exception.py', 'tripleo_common/image/image_uploader.py']",2,6a7184ecdfc38418f6cb1f97956b7209e2d5a294,bug/1844446,"from tripleo_common.image.exception import ImageUploaderImageSkippedException from tripleo_common.image.exception import ImageUploaderLayerSkippedException# How much times try finding an unlocked layer for a free worker, before # dropping image on floor and taking the next one RETRY_LAYERS_BEFORE_NEXT_IMAGE = 10 # Time to wait (sec) before starting looking for another layer of # an image to be picked by a free worker WAIT_FOR_NEXT_LAYER_ATTEMPT = 5 # How much times trying to fing a new image for a free worker in non-blocking # (creative) mode, before give up and re-enter it in the ""boring"" blocking # mode. RETRY_IMAGES_BEFORE_GIVE_UP = 42 Multiple workers start in the creative mode and will cooperate and do not block on locked layers. If layers locked, workers firstly will look for a free layers, or free images. If there is no more retries in the budget, workers will re-enter in the boring mode and will wait for the layer locks to release meanwhile doing nothing useful. """"""Start the upload process."""""" try: # NOTE(bogdando): creative workers may never be blocked and # (almost) never sleep. They constantly look for free layers # if failing to acquire a lock for the wanted layer. Or they # look for picking another task to process (next image in the # tasks list). If that strategy fails, start it all over # again (but omitting the finished tasks) in the boring mode # with workers always waiting to acquire their locks. uploader.run_tasks(workers_mode='creative') except ImageUploaderImageSkippedException: # TODO(bogdando): Find the better way of retrying, but # idempotency works here good as well LOG.warning('Some of the image uploads will be retried by ' 'the workers running in the blocking mode') uploader.run_tasks(workers_mode='boring') @tenacity.retry( # Retry a few times or drop it (reraise) and take next reraise=True, def upload_image(self, task, workers_mode='creative'): uploading a local image as well. Multiple workers, if in the creative mode will cooperate and never block on locked layers. While in the boring mode, it will wait for the layer lock to release and do nothing. :param: workers_mode: A mode in which workers should start LOG.info('[%s] Starting upload image process with %s ' 'workers' % (t.image_name, workers_mode)) multi_arch=t.multi_arch, workers_mode=workers_mode except ImageUploaderLayerSkippedException: # No more tries left for seeking unlocked layers, # re-raise it to start working on the next image LOG.error('[%s] Failed uploading image, picking ' 'another one' % t.target_image) source_session.close() target_session.close() raise ImageUploaderImageSkippedException # unlock it and retry with tenacity, if IOError'ed, # or leave it for another worker and another time LOG.warning('[%s] Couldnot copy layer to registry' % digest) @tenacity.retry( # Retry processing layers if budget allows reraise=True, retry=tenacity.retry_if_exception_type( ImageUploaderLayerSkippedException), wait=wait_fixed(WAIT_FOR_NEXT_LAYER_ATTEMPT) stop=tenacity.stop_after_attempt(RETRY_LAYERS_BEFORE_NEXT_IMAGE) ) multi_arch=False, workers_mode='creative'): LOG.debug('[%s] Waiting for %i jobs to be finished by %s ' 'workers' % (image, jobs_count, workers_mode)) if (e and isinstance(e, ImageUploaderLayerSkippedException) and workers_mode='creative'): LOG.error('[%s] Failed uploading layer %s, picking ' 'another one' % (image, layer)) raise e if e and isinstance(e, requests.exceptions.RequestException): LOG.error('[%s] Retrying uploading layer %s' % (image, layer)) raise e if e: LOG.error('[%s] Error uploading layer %s' % (image, layer)) @tenacity.retry( # Freely retry processing images untill become blocking reraise=True, retry=tenacity.retry_if_exception_type( ImageUploaderImageSkippedException), wait=wait_fixed(0.5), stop=tenacity.stop_after_attempt(RETRY_IMAGES_BEFORE_GIVE_UP) ) def run_tasks(self, workers_mode='creative'): for result in p.map(upload_task, self.upload_tasks, workers_mode): LOG.info('results of the %s work %s' % (local_images, workers_mode)) uploader, task, workers_mode = args return uploader.upload_image(task, workers_mode)"," """"""Start the upload process"""""" uploader.run_tasks() @tenacity.retry( # Retry until we no longer have collisions def upload_image(self, task): uploading a local image as well. LOG.info('[%s] Starting upload image process' % t.image_name) multi_arch=t.multi_arch multi_arch=False): LOG.debug('[%s] Waiting for %i jobs to finish' % (image, jobs_count)) if e: def run_tasks(self): for result in p.map(upload_task, self.upload_tasks): LOG.info('result %s' % local_images) uploader, task = args return uploader.upload_image(task)",100,15
openstack%2Fironic-python-agent-builder~master~I0cc0af440f954007f01bae4508f6853e1529913d,openstack/ironic-python-agent-builder,master,I0cc0af440f954007f01bae4508f6853e1529913d,Increase the DIB DHCP timeout to 60,MERGED,2019-09-25 14:54:59.000000000,2019-10-16 12:33:30.000000000,2019-10-16 12:32:08.000000000,"[{'_account_id': 10239}, {'_account_id': 12860}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-09-25 14:54:59.000000000', 'files': ['roles/ipa-build-dib-image/tasks/main.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/cd76a4c752e07c5b296bd872a08126770c1cc85a', 'message': 'Increase the DIB DHCP timeout to 60\n\nWe seem to be hitting occasional failures to DHCP in time, although\nDHCP itself seems working. Try increasing timeout from 30 to 60.\n\nChange-Id: I0cc0af440f954007f01bae4508f6853e1529913d\nDepends-On: https://review.opendev.org/684765\n'}]",1,684767,cd76a4c752e07c5b296bd872a08126770c1cc85a,30,7,1,10239,,,0,"Increase the DIB DHCP timeout to 60

We seem to be hitting occasional failures to DHCP in time, although
DHCP itself seems working. Try increasing timeout from 30 to 60.

Change-Id: I0cc0af440f954007f01bae4508f6853e1529913d
Depends-On: https://review.opendev.org/684765
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/67/684767/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ipa-build-dib-image/tasks/main.yaml'],1,cd76a4c752e07c5b296bd872a08126770c1cc85a,dib, # Increase from the default value of 30 DIB_DHCP_TIMEOUT: 60,,2,0
openstack%2Fkolla~master~Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196,openstack/kolla,master,Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196,handle push error properly,MERGED,2019-10-14 11:46:42.000000000,2019-10-16 12:33:15.000000000,2019-10-16 10:27:34.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-14 11:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/69cd3d16480c1a5dc5556e1ec1e8021250a0f251', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n'}, {'number': 2, 'created': '2019-10-14 12:02:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/efc3344dd3105becde84b8a12efb247812703d41', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 3, 'created': '2019-10-14 12:53:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/107f27f777761bd9397c801099bd592c66b04107', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 4, 'created': '2019-10-14 13:27:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/0e4fc9070ec575ed4f43221b72687a28129c10eb', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 5, 'created': '2019-10-15 11:04:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/4971fd8b1b5d85519ad18129d895c1cf36a1cf80', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 6, 'created': '2019-10-15 11:29:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6a3c1eb70b40b2d620de370c8a7530cb75b91cfe', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 7, 'created': '2019-10-15 12:58:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/7cae6535901e7bf32fdde795813a6ea7c395658a', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 8, 'created': '2019-10-15 13:33:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b520a28a574e580c57487d45d6f052d72f33ec47', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 9, 'created': '2019-10-15 16:00:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/8a590e609222d70d136eb7723b410cd89c0e55ff', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 10, 'created': '2019-10-15 16:18:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/dd57559ff5c425c583fc9ff72bf557ec5f5fd5cf', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}, {'number': 11, 'created': '2019-10-16 05:02:16.000000000', 'files': ['kolla/image/build.py', 'kolla/tests/test_build.py'], 'web_link': 'https://opendev.org/openstack/kolla/commit/52cac09d3d0b8dcdbc8d68a0bcc8092008220309', 'message': 'handle push error properly\n\nIf there was some error during pushing then Kolla was greeting with ""all went\nfine"" message anyway:\n\nINFO:kolla.common.utils.aodh-api:Trying to push the image\nERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host\nINFO:kolla.common.utils.aodh-api:Pushed successfully\n\nThis patch changes that. Now if there is an error during push then proper\nexception is raised to PushTask and image is marked with PUSH_ERROR status.\n\nThis way at the end of build it is easy to spot which images did not got\npushed to registry:\n\nINFO:kolla.common.utils:===========================\nINFO:kolla.common.utils:Images that failed to build\nINFO:kolla.common.utils:===========================\nERROR:kolla.common.utils:base Failed with status: push_error\nERROR:kolla.common.utils:nova-api Failed with status: push_error\nERROR:kolla.common.utils:nova-base Failed with status: push_error\nERROR:kolla.common.utils:nova-compute Failed with status: push_error\nERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error\nERROR:kolla.common.utils:nova-conductor Failed with status: push_error\n\nCloses-Bug: #1848019\nChange-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196\n'}]",23,688390,52cac09d3d0b8dcdbc8d68a0bcc8092008220309,52,6,11,24072,,,0,"handle push error properly

If there was some error during pushing then Kolla was greeting with ""all went
fine"" message anyway:

INFO:kolla.common.utils.aodh-api:Trying to push the image
ERROR:kolla.common.utils.aodh-api:Get http://10.101.16.1:5000/v2/: dial tcp 10.101.16.1:5000: connect: no route to host
INFO:kolla.common.utils.aodh-api:Pushed successfully

This patch changes that. Now if there is an error during push then proper
exception is raised to PushTask and image is marked with PUSH_ERROR status.

This way at the end of build it is easy to spot which images did not got
pushed to registry:

INFO:kolla.common.utils:===========================
INFO:kolla.common.utils:Images that failed to build
INFO:kolla.common.utils:===========================
ERROR:kolla.common.utils:base Failed with status: push_error
ERROR:kolla.common.utils:nova-api Failed with status: push_error
ERROR:kolla.common.utils:nova-base Failed with status: push_error
ERROR:kolla.common.utils:nova-compute Failed with status: push_error
ERROR:kolla.common.utils:nova-compute-ironic Failed with status: push_error
ERROR:kolla.common.utils:nova-conductor Failed with status: push_error

Closes-Bug: #1848019
Change-Id: Id2ab97bf4c0dc3423268a0ea435b56f4a65f7196
",git fetch https://review.opendev.org/openstack/kolla refs/changes/90/688390/11 && git format-patch -1 --stdout FETCH_HEAD,"['kolla/image/build.py', 'kolla/tests/test_build.py']",2,69cd3d16480c1a5dc5556e1ec1e8021250a0f251,686963,," @mock.patch('docker.version', '3.0.0') @mock.patch.dict(os.environ, clear=True) @mock.patch('docker.APIClient') def test_push_image_failure_retry(self, mock_client): self.dc = mock_client mock_client().push.side_effect = [Exception, []] pusher = build.PushTask(self.conf, self.image) pusher.run() mock_client().push.assert_called_once_with( self.image.canonical_name, decode=True, stream=True) self.assertFalse(pusher.success) self.assertEqual(build.STATUS_PUSH_ERROR, self.image.status) # Try again, this time without exception. pusher.reset() pusher.run() self.assertEqual(2, mock_client().push.call_count) self.assertTrue(pusher.success) self.assertEqual(build.STATUS_BUILT, self.image.status) ",9,25
openstack%2Freleases~master~Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834,openstack/releases,master,Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834,Train final releases for cycle-with-rc projects,MERGED,2019-10-10 22:03:47.000000000,2019-10-16 12:28:59.000000000,2019-10-16 12:28:59.000000000,"[{'_account_id': 308}, {'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 4608}, {'_account_id': 5202}, {'_account_id': 5314}, {'_account_id': 6469}, {'_account_id': 6484}, {'_account_id': 6732}, {'_account_id': 7198}, {'_account_id': 7973}, {'_account_id': 8099}, {'_account_id': 8213}, {'_account_id': 8246}, {'_account_id': 8482}, {'_account_id': 8543}, {'_account_id': 8716}, {'_account_id': 8731}, {'_account_id': 8932}, {'_account_id': 9003}, {'_account_id': 9303}, {'_account_id': 10234}, {'_account_id': 10273}, {'_account_id': 11536}, {'_account_id': 11561}, {'_account_id': 11564}, {'_account_id': 11600}, {'_account_id': 11628}, {'_account_id': 11904}, {'_account_id': 11975}, {'_account_id': 12076}, {'_account_id': 12404}, {'_account_id': 13154}, {'_account_id': 13629}, {'_account_id': 13861}, {'_account_id': 14070}, {'_account_id': 14107}, {'_account_id': 15197}, {'_account_id': 15312}, {'_account_id': 16312}, {'_account_id': 16465}, {'_account_id': 16643}, {'_account_id': 18591}, {'_account_id': 18955}, {'_account_id': 19298}, {'_account_id': 20498}, {'_account_id': 21672}, {'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 22998}, {'_account_id': 23060}, {'_account_id': 23078}, {'_account_id': 23365}, {'_account_id': 25625}, {'_account_id': 26458}, {'_account_id': 27068}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-10-10 22:03:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/b49733a34f89d6e0b64c07fccf1e05dc900af266', 'message': ""Train final releases for cycle-with-rc projects\n\nThese are the final release taggings for all cycle-with-rc projects.\nWhile not required, having PTLs ack this patch would be nice to include\nthat record in the merged metadata.\n\nSince it always comes up - yes, the diff-start is right. That's the\ncalculated starting point where the last stable branch was created.\n\nChange-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}, {'number': 2, 'created': '2019-10-11 16:22:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/64521b4e428400ec684c08f85938531874fef58e', 'message': ""Train final releases for cycle-with-rc projects\n\nThese are the final release taggings for all cycle-with-rc projects.\nWhile not required, having PTLs ack this patch would be nice to include\nthat record in the merged metadata.\n\nSince it always comes up - yes, the diff-start is right. That's the\ncalculated starting point where the last stable branch was created.\n\nChange-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}, {'number': 3, 'created': '2019-10-15 07:15:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/fdb4b2cc9dbf99caea8df295ad66ecd7cfe424cf', 'message': ""Train final releases for cycle-with-rc projects\n\nThese are the final release taggings for all cycle-with-rc projects.\nWhile not required, having PTLs ack this patch would be nice to include\nthat record in the merged metadata.\n\nSince it always comes up - yes, the diff-start is right. That's the\ncalculated starting point where the last stable branch was created.\n\nChange-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}, {'number': 4, 'created': '2019-10-15 13:43:41.000000000', 'files': ['deliverables/train/sahara-dashboard.yaml', 'deliverables/train/neutron.yaml', 'deliverables/train/watcher.yaml', 'deliverables/train/ceilometer.yaml', 'deliverables/train/masakari-dashboard.yaml', 'deliverables/train/magnum.yaml', 'deliverables/train/heat.yaml', 'deliverables/train/tacker.yaml', 'deliverables/train/sahara-image-elements.yaml', 'deliverables/train/sahara-plugin-spark.yaml', 'deliverables/train/storlets.yaml', 'deliverables/train/masakari.yaml', 'deliverables/train/murano-dashboard.yaml', 'deliverables/train/barbican.yaml', 'deliverables/train/masakari-monitors.yaml', 'deliverables/train/nova-powervm.yaml', 'deliverables/train/sahara-extra.yaml', 'deliverables/train/trove.yaml', 'deliverables/train/solum.yaml', 'deliverables/train/manila.yaml', 'deliverables/train/blazar.yaml', 'deliverables/train/tricircle.yaml', 'deliverables/train/networking-sfc.yaml', 'deliverables/train/zun-ui.yaml', 'deliverables/train/cloudkitty-dashboard.yaml', 'deliverables/train/neutron-vpnaas.yaml', 'deliverables/train/cinder.yaml', 'deliverables/train/heat-dashboard.yaml', 'deliverables/train/sahara.yaml', 'deliverables/train/murano.yaml', 'deliverables/train/sahara-plugin-cdh.yaml', 'deliverables/train/designate.yaml', 'deliverables/train/networking-bagpipe.yaml', 'deliverables/train/octavia-dashboard.yaml', 'deliverables/train/compute-hyperv.yaml', 'deliverables/train/zaqar.yaml', 'deliverables/train/ceilometer-powervm.yaml', 'deliverables/train/qinling-dashboard.yaml', 'deliverables/train/blazar-dashboard.yaml', 'deliverables/train/murano-agent.yaml', 'deliverables/train/searchlight-ui.yaml', 'deliverables/train/ec2-api.yaml', 'deliverables/train/watcher-dashboard.yaml', 'deliverables/train/zun.yaml', 'deliverables/train/senlin.yaml', 'deliverables/train/sahara-plugin-storm.yaml', 'deliverables/train/trove-dashboard.yaml', 'deliverables/train/keystone.yaml', 'deliverables/train/zaqar-ui.yaml', 'deliverables/train/networking-midonet.yaml', 'deliverables/train/networking-bgpvpn.yaml', 'deliverables/train/neutron-fwaas.yaml', 'deliverables/train/glance.yaml', 'deliverables/train/sahara-plugin-vanilla.yaml', 'deliverables/train/horizon.yaml', 'deliverables/train/mistral.yaml', 'deliverables/train/congress.yaml', 'deliverables/train/placement.yaml', 'deliverables/train/searchlight.yaml', 'deliverables/train/congress-dashboard.yaml', 'deliverables/train/solum-dashboard.yaml', 'deliverables/train/cyborg.yaml', 'deliverables/train/networking-ovn.yaml', 'deliverables/train/networking-powervm.yaml', 'deliverables/train/designate-dashboard.yaml', 'deliverables/train/nova.yaml', 'deliverables/train/aodh.yaml', 'deliverables/train/sahara-plugin-ambari.yaml', 'deliverables/train/octavia.yaml', 'deliverables/train/qinling.yaml', 'deliverables/train/kuryr-libnetwork.yaml', 'deliverables/train/neutron-dynamic-routing.yaml', 'deliverables/train/sahara-plugin-mapr.yaml', 'deliverables/train/networking-odl.yaml', 'deliverables/train/panko.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/86a537ba238364e07e43b04a5ccfbea323c29868', 'message': ""Train final releases for cycle-with-rc projects\n\nThese are the final release taggings for all cycle-with-rc projects.\nWhile not required, having PTLs ack this patch would be nice to include\nthat record in the merged metadata.\n\nSince it always comes up - yes, the diff-start is right. That's the\ncalculated starting point where the last stable branch was created.\n\nChange-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834\nSigned-off-by: Sean McGinnis <sean.mcginnis@gmail.com>\n""}]",8,687991,86a537ba238364e07e43b04a5ccfbea323c29868,86,57,4,11904,,,0,"Train final releases for cycle-with-rc projects

These are the final release taggings for all cycle-with-rc projects.
While not required, having PTLs ack this patch would be nice to include
that record in the merged metadata.

Since it always comes up - yes, the diff-start is right. That's the
calculated starting point where the last stable branch was created.

Change-Id: Icd4d3e6bc2bdd23b7073c38ea1a2e9100e679834
Signed-off-by: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/releases refs/changes/91/687991/1 && git format-patch -1 --stdout FETCH_HEAD,"['deliverables/train/sahara-dashboard.yaml', 'deliverables/train/neutron.yaml', 'deliverables/train/watcher.yaml', 'deliverables/train/ceilometer.yaml', 'deliverables/train/masakari-dashboard.yaml', 'deliverables/train/magnum.yaml', 'deliverables/train/heat.yaml', 'deliverables/train/tacker.yaml', 'deliverables/train/sahara-image-elements.yaml', 'deliverables/train/sahara-plugin-spark.yaml', 'deliverables/train/storlets.yaml', 'deliverables/train/masakari.yaml', 'deliverables/train/murano-dashboard.yaml', 'deliverables/train/barbican.yaml', 'deliverables/train/masakari-monitors.yaml', 'deliverables/train/nova-powervm.yaml', 'deliverables/train/sahara-extra.yaml', 'deliverables/train/trove.yaml', 'deliverables/train/solum.yaml', 'deliverables/train/manila.yaml', 'deliverables/train/blazar.yaml', 'deliverables/train/tricircle.yaml', 'deliverables/train/networking-sfc.yaml', 'deliverables/train/zun-ui.yaml', 'deliverables/train/cloudkitty-dashboard.yaml', 'deliverables/train/neutron-vpnaas.yaml', 'deliverables/train/cinder.yaml', 'deliverables/train/heat-dashboard.yaml', 'deliverables/train/sahara.yaml', 'deliverables/train/murano.yaml', 'deliverables/train/sahara-plugin-cdh.yaml', 'deliverables/train/designate.yaml', 'deliverables/train/networking-bagpipe.yaml', 'deliverables/train/octavia-dashboard.yaml', 'deliverables/train/compute-hyperv.yaml', 'deliverables/train/zaqar.yaml', 'deliverables/train/ceilometer-powervm.yaml', 'deliverables/train/qinling-dashboard.yaml', 'deliverables/train/blazar-dashboard.yaml', 'deliverables/train/murano-agent.yaml', 'deliverables/train/searchlight-ui.yaml', 'deliverables/train/ec2-api.yaml', 'deliverables/train/watcher-dashboard.yaml', 'deliverables/train/zun.yaml', 'deliverables/train/senlin.yaml', 'deliverables/train/sahara-plugin-storm.yaml', 'deliverables/train/trove-dashboard.yaml', 'deliverables/train/keystone.yaml', 'deliverables/train/zaqar-ui.yaml', 'deliverables/train/networking-midonet.yaml', 'deliverables/train/networking-bgpvpn.yaml', 'deliverables/train/neutron-fwaas.yaml', 'deliverables/train/glance.yaml', 'deliverables/train/sahara-plugin-vanilla.yaml', 'deliverables/train/horizon.yaml', 'deliverables/train/mistral.yaml', 'deliverables/train/congress.yaml', 'deliverables/train/placement.yaml', 'deliverables/train/searchlight.yaml', 'deliverables/train/congress-dashboard.yaml', 'deliverables/train/solum-dashboard.yaml', 'deliverables/train/cyborg.yaml', 'deliverables/train/networking-ovn.yaml', 'deliverables/train/networking-powervm.yaml', 'deliverables/train/designate-dashboard.yaml', 'deliverables/train/nova.yaml', 'deliverables/train/aodh.yaml', 'deliverables/train/sahara-plugin-ambari.yaml', 'deliverables/train/octavia.yaml', 'deliverables/train/qinling.yaml', 'deliverables/train/kuryr-libnetwork.yaml', 'deliverables/train/neutron-dynamic-routing.yaml', 'deliverables/train/sahara-plugin-mapr.yaml', 'deliverables/train/networking-odl.yaml', 'deliverables/train/panko.yaml']",75,b49733a34f89d6e0b64c07fccf1e05dc900af266,train-final, - version: 7.0.0 projects: - repo: openstack/panko hash: 92a0a825e5771a03c81069c5a19a6fc8adfbec15 diff-start: 6.0.0,,386,7
openstack%2Fkolla~master~I3b17bfdbc68a9a227bb22dc05a02ed6da607a114,openstack/kolla,master,I3b17bfdbc68a9a227bb22dc05a02ed6da607a114,Neutron: add support to use legacy iptables,MERGED,2019-09-20 18:14:28.000000000,2019-10-16 12:27:42.000000000,2019-10-16 12:22:13.000000000,"[{'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24072}, {'_account_id': 26768}, {'_account_id': 28374}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-09-20 18:14:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6a2dd78ffae1a2410a84baa3d2d34c98d9212f6e', 'message': 'Neutron: use iptables-legacy\n\nUse iptables-legacy if KOLLA_LEGACY_IPTABLES=yes is set.\nForces usage of legacy iptables binary (some kernels have issues\nwith nftables).\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 2, 'created': '2019-09-24 15:56:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/95170cec480268822a4c629ab11ca13cb4564e37', 'message': 'Neutron: use iptables-legacy\n\nUse iptables-legacy if KOLLA_LEGACY_IPTABLES=yes is set.\nForces usage of legacy iptables binary (some kernels have issues\nwith nftables).\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 3, 'created': '2019-09-27 17:36:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/be225eae06c19cfce3d692e2c16cf1c2c2df2221', 'message': 'Neutron: use iptables-legacy\n\nUse iptables-legacy if KOLLA_LEGACY_IPTABLES=yes is set.\nForces usage of legacy iptables binary (some kernels have issues\nwith nftables).\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 4, 'created': '2019-09-27 17:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/f8d43b84dd7729fd765d0bfd722c894faf22e989', 'message': 'Neutron: use iptables-legacy\n\nForces usage of legacy iptables binary (some kernels have issues\nwith nftables). \nWe enountered the problem while upgrading deployment with host system \nUbuntu 16.04 Xenial from Queens debian kolla images (based on stretch) \nto Stein. \nThis causes problems when using a hybrid security group driver since\nBuster is using iptables-nft by default and Xenial kernel has no support\nfor it resulting in port binding failure.\nSo basically this issue occurs ""only"" when upgrading kolla deployment \nwithout upgrading the host OS.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 5, 'created': '2019-09-27 17:46:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/b1dcbb6985f6c7af49d22935e37ff7a9882f1926', 'message': 'Neutron: use iptables-legacy\n\nForces usage of legacy iptables binary (some kernels have issues\nwith nftables). \nWe enountered the problem while upgrading deployment with host system \nUbuntu 16.04 Xenial from Queens debian kolla images (based on stretch) \nto Stein. \nThis causes problems when using a hybrid security group driver since\nBuster is using iptables-nft by default and Xenial kernel has no support\nfor it resulting in port binding failure.\nSo basically this issue occurs ""only"" when upgrading kolla deployment \nwithout upgrading the host OS.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 6, 'created': '2019-09-27 19:16:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/ab86dad6dabcc20b2d4d188e2b8579d7fc5a6b79', 'message': 'Neutron: use iptables-legacy\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 7, 'created': '2019-09-28 17:45:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/340306f483dbac1e3df1865472f114d1b784516c', 'message': 'Neutron: use iptables-legacy\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 8, 'created': '2019-09-29 13:58:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/1deee09ae4e1c9ff595b92597bc7f474998cb318', 'message': 'Neutron: use iptables-legacy\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 9, 'created': '2019-10-01 06:49:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/9e02cdaa591b7dbe352865b44e0c7e8ad789a4f9', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 10, 'created': '2019-10-01 13:26:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/5e8ce6518aa999c8f5ec6fd6df8b8737d8b95f95', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nDepends-On: https://review.opendev.org/685967\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 11, 'created': '2019-10-01 15:10:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/11033fa82b68b94a8d3c8d910d0b1906f0826dd8', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nDepends-On: https://review.opendev.org/685967\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 12, 'created': '2019-10-02 20:16:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/fa511d87a6f9169cbbef624de0b96052c034bda8', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting \niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 13, 'created': '2019-10-11 18:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/6fb4d076391c8ca5447c6ede6f99ff830b9a54ff', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 14, 'created': '2019-10-11 18:45:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/452f3ed3baef54babe4c77773702a21b81210d80', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 15, 'created': '2019-10-11 18:45:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/58f094432af277fcb8a428d78577865da8afdb62', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 16, 'created': '2019-10-12 15:37:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/df56d5ad9ee44a73c201caf59fa7cb63abd625b5', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 17, 'created': '2019-10-12 18:53:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/a4ce044707579f5e781eaa703299119302971d84', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}, {'number': 18, 'created': '2019-10-12 19:02:18.000000000', 'files': ['docker/neutron/neutron-base/neutron_sudoers', 'docker/neutron/neutron-base/extend_start.sh'], 'web_link': 'https://opendev.org/openstack/kolla/commit/e8289ff6df6b305a2f154a4aa6210c5d0bbb006f', 'message': 'Neutron: add support to use legacy iptables\n\nSetting legacy iptables for host system kernels not supporting\niptables-nft.\n\nChange-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114\n'}]",3,683679,e8289ff6df6b305a2f154a4aa6210c5d0bbb006f,86,6,18,28374,,,0,"Neutron: add support to use legacy iptables

Setting legacy iptables for host system kernels not supporting
iptables-nft.

Change-Id: I3b17bfdbc68a9a227bb22dc05a02ed6da607a114
",git fetch https://review.opendev.org/openstack/kolla refs/changes/79/683679/13 && git format-patch -1 --stdout FETCH_HEAD,"['docker/neutron/neutron-base/neutron_sudoers', 'docker/neutron/neutron-base/extend_start.sh']",2,6a2dd78ffae1a2410a84baa3d2d34c98d9212f6e,680447,"if [[ ${KOLLA_LEGACY_IPTABLES} == ""yes"" && -x /usr/sbin/iptables ]]; then sudo /usr/bin/update-alternatives --set iptables /usr/sbin/iptables-legacy sudo /usr/bin/update-alternatives --set iptables /usr/sbin/ip6tables-legacy fi ",,7,0
openstack%2Fironic~stable%2Ftrain~I18aa79774c0b562bf1e8b973db3d7860a01367e7,openstack/ironic,stable/train,I18aa79774c0b562bf1e8b973db3d7860a01367e7,DRAC: Fix a bug for delete_config with multiple controllers,MERGED,2019-10-14 12:19:02.000000000,2019-10-16 12:15:36.000000000,2019-10-16 11:38:18.000000000,"[{'_account_id': 10250}, {'_account_id': 10379}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23851}]","[{'number': 1, 'created': '2019-10-14 12:19:02.000000000', 'files': ['ironic/tests/unit/drivers/modules/drac/test_raid.py', 'ironic/drivers/modules/drac/raid.py', 'releasenotes/notes/fix-delete_configuration-with-multiple-controllers-06fc3fca94ba870f.yaml'], 'web_link': 'https://opendev.org/openstack/ironic/commit/4568cc625040cda2dd28edce0f1acb3a595158a1', 'message': 'DRAC: Fix a bug for delete_config with multiple controllers\n\nThis fix a bug where a race condition can occur on a host that\nhas a mix of controllers where some supports realtime mode and\nsome do not. The approach is to use only realtime mode if all\ncontrollers supports realtime. This removes the race condition.\n\nStory: #2006502\nTask: #36480\n\nChange-Id: I18aa79774c0b562bf1e8b973db3d7860a01367e7\n(cherry picked from commit e4f3b7b813007b90a579b7d3f6c4990a6affeb39)\n'}]",0,688394,4568cc625040cda2dd28edce0f1acb3a595158a1,12,7,1,29405,,,0,"DRAC: Fix a bug for delete_config with multiple controllers

This fix a bug where a race condition can occur on a host that
has a mix of controllers where some supports realtime mode and
some do not. The approach is to use only realtime mode if all
controllers supports realtime. This removes the race condition.

Story: #2006502
Task: #36480

Change-Id: I18aa79774c0b562bf1e8b973db3d7860a01367e7
(cherry picked from commit e4f3b7b813007b90a579b7d3f6c4990a6affeb39)
",git fetch https://review.opendev.org/openstack/ironic refs/changes/94/688394/1 && git format-patch -1 --stdout FETCH_HEAD,"['ironic/tests/unit/drivers/modules/drac/test_raid.py', 'ironic/drivers/modules/drac/raid.py', 'releasenotes/notes/fix-delete_configuration-with-multiple-controllers-06fc3fca94ba870f.yaml']",3,4568cc625040cda2dd28edce0f1acb3a595158a1,sort_controllers-stable/train,fixes: - | Fixes a bug in the ``idrac`` hardware type where a race condition can occur on a host that has a mix of controllers where some support realtime mode and some do not. The approach is to use only realtime mode if all controllers support realtime. This removes the race condition. See bug `2006502 https://storyboard.openstack.org/#!/story/2006502` for details ,,132,39
openstack%2Fpuppet-openstack_extras~master~I8dd2b19fd1f2db72cb1c61aa0c5047c3a8c1c1c7,openstack/puppet-openstack_extras,master,I8dd2b19fd1f2db72cb1c61aa0c5047c3a8c1c1c7,Update the constraints url,MERGED,2019-09-26 03:28:31.000000000,2019-10-16 12:13:02.000000000,2019-10-16 12:11:50.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-09-26 03:28:31.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_extras/commit/237c0c04cbfbaf3156af5b63bd9714a8ebb1f306', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: I8dd2b19fd1f2db72cb1c61aa0c5047c3a8c1c1c7\n'}]",0,684909,237c0c04cbfbaf3156af5b63bd9714a8ebb1f306,22,6,1,27822,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: I8dd2b19fd1f2db72cb1c61aa0c5047c3a8c1c1c7
",git fetch https://review.opendev.org/openstack/puppet-openstack_extras refs/changes/09/684909/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,237c0c04cbfbaf3156af5b63bd9714a8ebb1f306,constraints,install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master} {opts} {packages},install_command = pip install -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt} {opts} {packages},1,1
openstack%2Fopenstack-manuals~master~I71746e0508b00f26ec7fc4e82552d2f89d0b7626,openstack/openstack-manuals,master,I71746e0508b00f26ec7fc4e82552d2f89d0b7626,Update for Train release,MERGED,2019-10-15 19:39:31.000000000,2019-10-16 12:09:15.000000000,2019-10-16 11:46:36.000000000,"[{'_account_id': 2472}, {'_account_id': 6547}, {'_account_id': 10607}, {'_account_id': 11904}, {'_account_id': 14482}, {'_account_id': 15334}, {'_account_id': 17765}, {'_account_id': 19779}, {'_account_id': 20156}, {'_account_id': 22165}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:39:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/8fb2378f3f7f06f536c3a00f6743283e3ed915e8', 'message': 'Update for Train release\n\nCreate ussuri files and train data for release of OpenStack Train.\n\nChange-Id: I71746e0508b00f26ec7fc4e82552d2f89d0b7626\n'}, {'number': 2, 'created': '2019-10-16 10:40:50.000000000', 'files': ['www/project-data/train.yaml', 'www/ussuri/install/index.html', 'www/ussuri/deploy/index.html', 'www/ussuri/configuration/index.html', 'www/ussuri/projects.html', 'www/ussuri/user/index.html', 'tools/www-generator.py', 'www/ussuri/admin/index.html', 'www/ussuri/index.html', 'www/ussuri/language-bindings.html', 'www/ussuri/api/index.html'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/94f57d55d8c01d9ac2b547a883e84e061dd633ab', 'message': 'Update for Train release\n\nCreate ussuri files and train data for release of OpenStack Train.\n\nChange-Id: I71746e0508b00f26ec7fc4e82552d2f89d0b7626\n'}]",0,688796,94f57d55d8c01d9ac2b547a883e84e061dd633ab,11,11,2,6547,,,0,"Update for Train release

Create ussuri files and train data for release of OpenStack Train.

Change-Id: I71746e0508b00f26ec7fc4e82552d2f89d0b7626
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/96/688796/1 && git format-patch -1 --stdout FETCH_HEAD,"['www/project-data/train.yaml', 'www/ussuri/install/index.html', 'www/ussuri/deploy/index.html', 'www/ussuri/configuration/index.html', 'www/ussuri/projects.html', 'www/ussuri/user/index.html', 'tools/www-generator.py', 'www/ussuri/admin/index.html', 'www/ussuri/index.html', 'www/ussuri/language-bindings.html', 'www/ussuri/api/index.html']",11,8fb2378f3f7f06f536c3a00f6743283e3ed915e8,train,"{% set projects = PROJECT_DATA[SERIES] %} {% extends ""templates/base.tmpl"" %} {% block pagetitle %}{{SERIES_TITLE}} API references{% endblock %} {% block title %}API references{% endblock %} {% block header %} {% endblock header %} {% block content %} <!-- Begin Page Content --> <div class=""top-docs-wrapper""> <div class=""container""> <div class=""row""> <div class=""col-lg-8 col-md-8 col-sm-8""> <h1>OpenStack {{SERIES_TITLE}} API Reference Documentation</h1> <p> This page contains documentation about the OpenStack API and how to use it. </p> </div> </div> </div> <div class=""mid-docs-wrapper"" id=""docs-main-body""> <div class=""container""> <div class=""row""> <div class=""col-lg-12""> </div> </div> <div class=""row docs-toc""> <div class=""col-lg-6 col-md-6 col-sm-6""> <div class=""docs-link-sections""> <h3><i class=""fa fa-book""></i>API References</h3> {% for project in projects|sort(attribute='service') %} {% if project.has_api_ref or project.has_api_guide or project.has_in_tree_api_docs %} {{project.service}} ({{project.name}}): {% if project.has_api_ref %} <a href=""https://docs.openstack.org/api-ref/{{project.service_type}}/""> API Reference</a> {% endif %} {% if project.has_in_tree_api_docs %} <a href=""/{{project.name}}/{{SERIES}}/api/""> API Documentation</a> {% endif %} {% if project.has_api_guide %} <a href=""https://docs.openstack.org/api-guide/{{project.service_type}}/""> API Guide</a> {% endif %} <br/> {% endif %} {% endfor %} </div> </div> <div class=""col-lg-6 col-md-6 col-sm-6""> <div class=""docs-link-sections""> <h3><i class=""fa fa-cloud""></i>User Guides</h3> <a href=""/api-quick-start/"">API Guide</a><br/> <a href=""../user/"">OpenStack End User Guides (includes Python SDK)</a><br/> <a href=""https://developer.openstack.org"">Open source software for application development</a><br/> </div> </div> </div> <div class=""row docs-contribute-wrapper""> <div class=""col-lg-12""> <p>Documentation treated like code, powered by the community - interested?</p> <a href=""/doc-contrib-guide/"" class=""overview-btn contribute-btn"">How To Contribute <i class=""fa fa-chevron-right""></i></a> </div> </div> </div> </div> <!-- End Page Content --> {% endblock content %} ",,1451,1
openstack%2Fmistral~master~I714962c91fdf4638dd2e04a8d1618df2245eaeb6,openstack/mistral,master,I714962c91fdf4638dd2e04a8d1618df2245eaeb6,Adjust doc string to correct param,MERGED,2019-10-15 14:50:59.000000000,2019-10-16 11:55:42.000000000,2019-10-16 11:53:50.000000000,"[{'_account_id': 8731}, {'_account_id': 22348}, {'_account_id': 26693}]","[{'number': 1, 'created': '2019-10-15 14:50:59.000000000', 'files': ['mistral/rpc/clients.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/10fe69e147e4cc5e18a702658287f75d93c53243', 'message': 'Adjust doc string to correct param\n\nThe doc string for action_ex_id has been used twice and the doc string\nfor state param was missing. This commit corrects this.\n\nChange-Id: I714962c91fdf4638dd2e04a8d1618df2245eaeb6\n'}]",0,688726,10fe69e147e4cc5e18a702658287f75d93c53243,11,3,1,26693,,,0,"Adjust doc string to correct param

The doc string for action_ex_id has been used twice and the doc string
for state param was missing. This commit corrects this.

Change-Id: I714962c91fdf4638dd2e04a8d1618df2245eaeb6
",git fetch https://review.opendev.org/openstack/mistral refs/changes/26/688726/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/rpc/clients.py'],1,10fe69e147e4cc5e18a702658287f75d93c53243,fix-docstring, :param state: Updated state., :param action_ex_id: Updated state.,1,1
openstack%2Fmonasca-ui~master~Ie6a63d939165e52afa7f15091a226dcb525a31d8,openstack/monasca-ui,master,Ie6a63d939165e52afa7f15091a226dcb525a31d8,Update the constraints url,MERGED,2019-10-09 17:20:04.000000000,2019-10-16 11:55:35.000000000,2019-10-16 11:55:35.000000000,"[{'_account_id': 16222}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 17:20:04.000000000', 'files': ['tox.ini'], 'web_link': 'https://opendev.org/openstack/monasca-ui/commit/b95f0873d859b8755728e7314a6062c6fb0f74f9', 'message': 'Update the constraints url\n\nFor more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html\n\nChange-Id: Ie6a63d939165e52afa7f15091a226dcb525a31d8\n'}]",0,687629,b95f0873d859b8755728e7314a6062c6fb0f74f9,6,2,1,29313,,,0,"Update the constraints url

For more detail, see http://lists.openstack.org/pipermail/openstack-discuss/2019-May/006478.html

Change-Id: Ie6a63d939165e52afa7f15091a226dcb525a31d8
",git fetch https://review.opendev.org/openstack/monasca-ui refs/changes/29/687629/1 && git format-patch -1 --stdout FETCH_HEAD,['tox.ini'],1,b95f0873d859b8755728e7314a6062c6fb0f74f9,,deps = -c{env:UPPER_CONSTRAINTS_FILE:https://releases.openstack.org/constraints/upper/master},deps = -c{env:UPPER_CONSTRAINTS_FILE:https://opendev.org/openstack/requirements/raw/branch/master/upper-constraints.txt},1,1
openstack%2Fmagnum~master~Iffcaa68d385b1b829b577ebce2df465073dfb5a1,openstack/magnum,master,Iffcaa68d385b1b829b577ebce2df465073dfb5a1,Support Fedora CoreOS 30,MERGED,2019-08-26 03:46:27.000000000,2019-10-16 11:52:08.000000000,2019-10-16 11:50:43.000000000,"[{'_account_id': 4571}, {'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27057}, {'_account_id': 28022}]","[{'number': 1, 'created': '2019-08-26 03:46:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a272423b1a88099a2080ea7f5dc9d655b37217e8', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 2, 'created': '2019-08-29 09:09:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/6243d8d1b05802588d326477155c5e665d4d4f20', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 3, 'created': '2019-08-30 03:47:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/30685a2d2284e74fe787e2e4c2f0d976f15b768a', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 4, 'created': '2019-09-23 02:26:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/198a99bef6026cc45953e40dbbe9e262e0ce7c74', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 5, 'created': '2019-09-24 04:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fc551101159351f06aab105dd6de1b1cb2bd97d4', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 6, 'created': '2019-09-26 03:14:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3a45710dad76216f376bfb3853edbc74db23d5a7', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 7, 'created': '2019-10-07 12:54:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/922a3f52fa5f6ea87c7e79797927404e571eb443', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 8, 'created': '2019-10-08 14:59:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/20e0803ddf6edb4f7b7419b0cf7d12e5e6614b8b', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 9, 'created': '2019-10-09 15:29:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/73e777adb00afbc5d041266a77b5aab01e8ed18b', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 10, 'created': '2019-10-09 19:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a5fdf94d0be328e5a438049d466cebb130e8c334', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 11, 'created': '2019-10-10 08:45:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a6d98815cd5f52283d5f31de7854460ae5882acb', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 12, 'created': '2019-10-10 10:04:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5d268ca22aa737170e40d7fc0a988f373ee84143', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 13, 'created': '2019-10-10 10:32:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/4a1e7a1899418671819265b6b5d1889003d3fc43', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 14, 'created': '2019-10-10 14:36:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a5c07a29147b32cd575d0054e95b49eb09991ef7', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 15, 'created': '2019-10-11 09:13:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/fc4d4665aa4c834c7b89f0398b486a3f6d8774ff', 'message': '[WIP] Support Fedora CoreOS 30\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 16, 'created': '2019-10-11 12:32:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/cb13dda4ef115e97cb7393c30b0ed0ff0bdf9cd6', 'message': 'Support Fedora CoreOS 30\n\nAdd fedora coreos driver. To deploy clusters with fedora coreos operators\nor users need to add os_distro=fedora-coreos to the image. The scripts\nto deploy kubernetes on top are the same with fedora atomic. Note that\nthis driver has selinux enabled.\n\nThe startup of the heat-container-agent uses a workaround to copy the\nsoftwareDeployment credentials to /var/lib/cloud/data/cfn-init-data.\nThe fedora coreos driver requires heat train to support ignition.\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 17, 'created': '2019-10-14 07:12:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e8c2950bd0fd5dce3e845df0d54f02220f8447be', 'message': 'Support Fedora CoreOS 30\n\nAdd fedora coreos driver. To deploy clusters with fedora coreos operators\nor users need to add os_distro=fedora-coreos to the image. The scripts\nto deploy kubernetes on top are the same with fedora atomic. Note that\nthis driver has selinux enabled.\n\nThe startup of the heat-container-agent uses a workaround to copy the\nSoftwareDeployment credentials to /var/lib/cloud/data/cfn-init-data.\nThe fedora coreos driver requires heat train to support ignition.\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 18, 'created': '2019-10-15 15:20:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8ca9263900b6ef03b1cffa8aeff1476a3ddf1681', 'message': 'Support Fedora CoreOS 30\n\nAdd fedora coreos driver. To deploy clusters with fedora coreos operators\nor users need to add os_distro=fedora-coreos to the image. The scripts\nto deploy kubernetes on top are the same with fedora atomic. Note that\nthis driver has selinux enabled.\n\nThe startup of the heat-container-agent uses a workaround to copy the\nSoftwareDeployment credentials to /var/lib/cloud/data/cfn-init-data.\nThe fedora coreos driver requires heat train to support ignition.\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}, {'number': 19, 'created': '2019-10-16 09:44:26.000000000', 'files': ['magnum/drivers/k8s_fedora_coreos_v1/templates/user_data.json', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/common/templates/kubernetes/fragments/flannel-service.sh', 'magnum/drivers/k8s_fedora_atomic_v1/driver.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/version.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/COPYING', 'magnum/drivers/k8s_fedora_coreos_v1/template_def.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/heat/driver.py', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-minion.sh', 'magnum/drivers/k8s_fedora_coreos_v1/__init__.py', 'magnum/drivers/common/templates/kubernetes/fragments/configure-kubernetes-master.sh', 'releasenotes/notes/fedora_coreos-e66b44d86dea380f.yaml', 'setup.cfg', 'magnum/drivers/k8s_fedora_coreos_v1/driver.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/73dc57c319b815badba177c0ab06a4ddc69b4e01', 'message': 'Support Fedora CoreOS 30\n\nAdd fedora coreos driver. To deploy clusters with fedora coreos operators\nor users need to add os_distro=fedora-coreos to the image. The scripts\nto deploy kubernetes on top are the same with fedora atomic. Note that\nthis driver has selinux enabled.\n\nThe startup of the heat-container-agent uses a workaround to copy the\nSoftwareDeployment credentials to /var/lib/cloud/data/cfn-init-data.\nThe fedora coreos driver requires heat train to support ignition.\n\nTask: 29968\nStory: 2005201\n\nSigned-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>\n\nChange-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1\n'}]",33,678458,73dc57c319b815badba177c0ab06a4ddc69b4e01,78,6,19,6484,,,0,"Support Fedora CoreOS 30

Add fedora coreos driver. To deploy clusters with fedora coreos operators
or users need to add os_distro=fedora-coreos to the image. The scripts
to deploy kubernetes on top are the same with fedora atomic. Note that
this driver has selinux enabled.

The startup of the heat-container-agent uses a workaround to copy the
SoftwareDeployment credentials to /var/lib/cloud/data/cfn-init-data.
The fedora coreos driver requires heat train to support ignition.

Task: 29968
Story: 2005201

Signed-off-by: Spyros Trigazis <spyridon.trigazis@cern.ch>

Change-Id: Iffcaa68d385b1b829b577ebce2df465073dfb5a1
",git fetch https://review.opendev.org/openstack/magnum refs/changes/58/678458/16 && git format-patch -1 --stdout FETCH_HEAD,"['magnum/drivers/k8s_fedora_coreos_v1/templates/kubecluster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/version.py', 'magnum/drivers/k8s_fedora_coreos_v1/template_def.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-apiserver.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-proxy-minion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-coredns.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/configure-docker.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kubelet-minion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/wc-notify.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-controller-manager.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-network-service.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/add-ext-ca-certs.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/create-kube-namespace.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/driver.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/write-kubeconfig.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubeminion.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kubelet-master.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/COPYING', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/make-cert-client.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/make-cert.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/write-heat-params-master.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/write-network-config.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/kubemaster.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/configure-etcd.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/add-proxy.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-dashboard.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-network-service-client.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/__init__.py', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-proxy-master.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/write-heat-params.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-docker-mount.yaml', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/enable-kube-scheduler.yaml', 'setup.cfg', 'magnum/drivers/k8s_fedora_coreos_v1/templates/fragments/write-master-kubeconfig.yaml']",34,a272423b1a88099a2080ea7f5dc9d655b37217e8,fcos,"#cloud-config merge_how: dict(recurse_array)+list(append) write_files: - path: /etc/kubernetes/master-kubeconfig.yaml owner: ""root:root"" permissions: ""0644"" content: | apiVersion: v1 kind: Config clusters: - name: local cluster: server: http://127.0.0.1:8080 users: - name: kubelet contexts: - context: cluster: local user: kubelet name: kubelet-context current-context: kubelet-context ",,4283,0
openstack%2Frally-openstack~master~I80637622d1e9987da60e207a55839b5df0df9a44,openstack/rally-openstack,master,I80637622d1e9987da60e207a55839b5df0df9a44,`uptime hypervisor` would be failed  if some hosts downed,MERGED,2019-10-14 09:05:18.000000000,2019-10-16 11:24:20.000000000,2019-10-16 11:24:20.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 09:05:18.000000000', 'files': ['rally_openstack/scenarios/nova/hypervisors.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/e74eeef83b4b31054d7834ebfaf830c5387ab560', 'message': '`uptime hypervisor` would be failed  if some hosts downed\n\nChange-Id: I80637622d1e9987da60e207a55839b5df0df9a44\n'}]",0,688356,e74eeef83b4b31054d7834ebfaf830c5387ab560,6,2,1,21528,,,0,"`uptime hypervisor` would be failed  if some hosts downed

Change-Id: I80637622d1e9987da60e207a55839b5df0df9a44
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/56/688356/1 && git format-patch -1 --stdout FETCH_HEAD,['rally_openstack/scenarios/nova/hypervisors.py'],1,e74eeef83b4b31054d7834ebfaf830c5387ab560,uptime," if hypervisor.state == ""up"": self._uptime_hypervisor(hypervisor)", self._uptime_hypervisor(hypervisor),2,1
openstack%2Fironic-python-agent-builder~master~I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d,openstack/ironic-python-agent-builder,master,I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d,DIB: default to installing pip and virtualenv from packages,MERGED,2019-09-30 12:15:33.000000000,2019-10-16 11:13:57.000000000,2019-10-16 11:12:06.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-09-30 12:15:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/af7072f02e0e034ca86199b92c63d6144acee15d', 'message': ""DIB: default to installing pip and virtualenv from packages\n\nThis reduces the size of the image slightly. We don't need latest\nversions since we update pip in our venv anyway.\n\nChange-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d\n""}, {'number': 2, 'created': '2019-09-30 12:16:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/e55df1ea853f1575e35291ebefec765d2cf5f354', 'message': ""DIB: default to installing pip and virtualenv from packages\n\nThis reduces the size of the image slightly. We don't need latest\nversions since we update pip in our venv anyway.\n\nChange-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d\n""}, {'number': 3, 'created': '2019-09-30 12:51:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/9479c991875ac072827a51f4cbc61ab8864f23d7', 'message': ""DIB: default to installing pip and virtualenv from packages\n\nThis reduces the size of the image slightly. We don't need latest\nversions since we update pip in our venv anyway.\n\nChange-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d\n""}, {'number': 4, 'created': '2019-09-30 17:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/30afd5eae6d06cb0f7c341fda2dface2df13f5ca', 'message': ""DIB: default to installing pip and virtualenv from packages\n\nThis reduces the size of the image slightly. We don't need latest\nversions since we update pip in our venv anyway.\n\nChange-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d\n""}, {'number': 5, 'created': '2019-10-09 07:50:20.000000000', 'files': ['ironic_python_agent_builder/__init__.py', 'dib/ironic-python-agent-ramdisk/install.d/ironic-python-agent-ramdisk-source-install/60-ironic-python-agent-ramdisk-install'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/eaaa1118ad6e8204f9d276b868e06ffc53bb5864', 'message': ""DIB: default to installing pip and virtualenv from packages\n\nThis reduces the size of the image slightly. We don't need latest\nversions since we update pip in our venv anyway.\n\nChange-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d\n""}]",0,685697,eaaa1118ad6e8204f9d276b868e06ffc53bb5864,18,4,5,10239,,,0,"DIB: default to installing pip and virtualenv from packages

This reduces the size of the image slightly. We don't need latest
versions since we update pip in our venv anyway.

Change-Id: I7729b8c286c641a7b70a775ffe73f9f1c9dbff2d
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/97/685697/2 && git format-patch -1 --stdout FETCH_HEAD,['ironic_python_agent_builder/__init__.py'],1,af7072f02e0e034ca86199b92c63d6144acee15d,venv-installtype," if not os.environ.get('DIB_INSTALLTYPE_pip_and_virtualenv'): # DIB updates these to latest versions from source. However, we do the # same in our virtualenv, so it's not needed and just increases the # size of the image. os.environ['DIB_INSTALLTYPE_pip_and_virtualenv'] = 'package'",,5,0
openstack%2Frally-openstack~master~Iaebde73c46b688ba4ac37ef1160dfa703dbc030d,openstack/rally-openstack,master,Iaebde73c46b688ba4ac37ef1160dfa703dbc030d,update source link in readme,MERGED,2019-10-15 10:59:27.000000000,2019-10-16 11:13:18.000000000,2019-10-16 11:13:18.000000000,"[{'_account_id': 9545}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 10:59:27.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/1067caae5b6099bf1bc1394f59d030fa98b7ab90', 'message': 'update source link in readme\n\nChange-Id: Iaebde73c46b688ba4ac37ef1160dfa703dbc030d\n'}]",0,688675,1067caae5b6099bf1bc1394f59d030fa98b7ab90,6,2,1,30384,,,0,"update source link in readme

Change-Id: Iaebde73c46b688ba4ac37ef1160dfa703dbc030d
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/75/688675/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,1067caae5b6099bf1bc1394f59d030fa98b7ab90,,* Source: https://opendev.org/openstack/rally-openstack/,* Source: https://git.openstack.org/cgit/openstack/rally-openstack,1,1
openstack%2Frally-openstack~master~Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95,openstack/rally-openstack,master,Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95,Support to boot server with net name,MERGED,2019-10-08 09:01:49.000000000,2019-10-16 11:13:18.000000000,2019-10-16 11:13:18.000000000,"[{'_account_id': 9545}, {'_account_id': 21528}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-08 09:01:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/6dcc35f3a885668bbae437c9e4255621395b1bfb', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}, {'number': 2, 'created': '2019-10-08 09:02:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/afed8ec6c39775b9e2678e1687e1c6206bdecdc1', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}, {'number': 3, 'created': '2019-10-09 02:08:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/8a6389d312e8f0f74568bd97797441adc35e3343', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}, {'number': 4, 'created': '2019-10-09 02:08:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/3fc992e3c80829898757dacb34872713acc23417', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}, {'number': 5, 'created': '2019-10-09 02:11:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/fc84fc9a916c86d15987f5c0764381603cfe75cc', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}, {'number': 6, 'created': '2019-10-09 12:22:23.000000000', 'files': ['tests/unit/scenarios/nova/test_utils.py', 'rally_openstack/scenarios/nova/utils.py'], 'web_link': 'https://opendev.org/openstack/rally-openstack/commit/b093524d6be09aa1a67604d8ed2840826db4850f', 'message': 'Support to boot server with net name\n\nit can not specify the net id while creating net in neturon,\nso we may be known the net name but not net id.\nAlso, if we want to trend the reports, it is hard to keep the\nsame net id.\n\nChange-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95\n'}]",3,687251,b093524d6be09aa1a67604d8ed2840826db4850f,18,3,6,21528,,,0,"Support to boot server with net name

it can not specify the net id while creating net in neturon,
so we may be known the net name but not net id.
Also, if we want to trend the reports, it is hard to keep the
same net id.

Change-Id: Ibeda5db86dcd0cb1c71569c1d7280227de1f8b95
",git fetch https://review.opendev.org/openstack/rally-openstack refs/changes/51/687251/1 && git format-patch -1 --stdout FETCH_HEAD,"['tests/unit/scenarios/nova/test_utils.py', 'rally_openstack/scenarios/nova/utils.py']",2,6dcc35f3a885668bbae437c9e4255621395b1bfb,boot_server,"from rally_openstack.scenarios.neutron import utils as neutron_utils for nic in kwargs.get(""nics"", []): if nic.get(""net-name""): neutron = neutron_utils.NeutronScenario(self.context) nic[""net-id""] = neutron._get_network_id(nic[""net-name""]) for nic in kwargs.get(""nics"", []): if nic.get(""net-name""): neutron = neutron_utils.NeutronScenario(self.context) nic[""net-id""] = neutron._get_network_id(nic[""net-name""]) ",,29,5
openstack%2Fpython-tripleoclient~master~Iab755744e305c07b548f808f9d4d9e01db0cfe7a,openstack/python-tripleoclient,master,Iab755744e305c07b548f808f9d4d9e01db0cfe7a,[WiP] Add brackets to container registry addresses,ABANDONED,2019-07-10 13:18:53.000000000,2019-10-16 11:09:06.000000000,,"[{'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-07-10 13:18:53.000000000', 'files': ['tripleoclient/v1/undercloud_config.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1239de0addc0fc2805df0840caeded749a11949a', 'message': '[WiP] Add brackets to container registry addresses\n\nIf the container registry addresses, i.e CONF.local_ip\nCONF.undercloud_admin_host is an IPv6 address add\nbrackets.\n\nChange-Id: Iab755744e305c07b548f808f9d4d9e01db0cfe7a\n'}]",0,670055,1239de0addc0fc2805df0840caeded749a11949a,4,2,1,24245,,,0,"[WiP] Add brackets to container registry addresses

If the container registry addresses, i.e CONF.local_ip
CONF.undercloud_admin_host is an IPv6 address add
brackets.

Change-Id: Iab755744e305c07b548f808f9d4d9e01db0cfe7a
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/55/670055/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/v1/undercloud_config.py'],1,1239de0addc0fc2805df0840caeded749a11949a,ipv6-support, utils.bracket_ipv6(CONF['local_ip'].split('/')[0])] utils.bracket_ipv6(CONF['undercloud_admin_host'])) '%s:8787' % utils.bracket_ipv6(CONF['local_ip'].split('/')[0])] '%s:8787' % utils.bracket_ipv6(CONF['undercloud_admin_host'])) [utils.bracket_ipv6(x) for x in CONF['container_insecure_registries']]) env_data['LocalContainerRegistry'] = utils.bracket_ipv6( CONF['local_ip'].split('/')[0]), CONF['local_ip'].split('/')[0]] CONF['undercloud_admin_host']) '%s:8787' % CONF['local_ip'].split('/')[0]] '%s:8787' % CONF['undercloud_admin_host']) CONF['container_insecure_registries']) env_data['LocalContainerRegistry'] = CONF['local_ip'].split('/')[0],7,6
openstack%2Fcharm-neutron-gateway~master~I103c809f5f67ee797cc767bd58236601c16aeca5,openstack/charm-neutron-gateway,master,I103c809f5f67ee797cc767bd58236601c16aeca5,Further changes for OpenStack Train,MERGED,2019-10-16 09:44:25.000000000,2019-10-16 10:59:37.000000000,2019-10-16 10:59:37.000000000,"[{'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 09:44:25.000000000', 'files': ['unit_tests/test_neutron_utils.py', 'hooks/neutron_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/776979801e777d7e54cf00462e3dd364b8abeafb', 'message': 'Further changes for OpenStack Train\n\nDrop installation and configuration of neutron-lbaasv2-agent for\nTrain.\n\nChange-Id: I103c809f5f67ee797cc767bd58236601c16aeca5\n'}]",0,688889,776979801e777d7e54cf00462e3dd364b8abeafb,7,3,1,935,,,0,"Further changes for OpenStack Train

Drop installation and configuration of neutron-lbaasv2-agent for
Train.

Change-Id: I103c809f5f67ee797cc767bd58236601c16aeca5
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/89/688889/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_neutron_utils.py', 'hooks/neutron_utils.py']",2,776979801e777d7e54cf00462e3dd364b8abeafb,train," if cmp_os_source >= 'train': # LBaaS v2 dropped in train packages.remove('neutron-lbaasv2-agent') # Drop lbaasv2 at train if cmp_os_release >= 'train': drop_config.extend([ NEUTRON_LBAASV2_AA_PROFILE_PATH, NEUTRON_LBAAS_AGENT_CONF, ]) cmp_release = CompareOpenStackReleases(release) if cmp_release >= 'newton' and 'neutron-lbaas-agent' in svcs: if cmp_release >= 'train' and 'neutron-lbaasv2-agent' in svcs: svcs.remove('neutron-lbaasv2-agent') if cmp_os_source >= 'train': profiles.remove(NEUTRON_LBAASV2_AA_PROFILE)", if (CompareOpenStackReleases(release) >= 'newton' and 'neutron-lbaas-agent' in svcs):,58,2
openstack%2Fmagnum~master~Iecbae5866278afe1687a4533b71af60fce537a4a,openstack/magnum,master,Iecbae5866278afe1687a4533b71af60fce537a4a,Build cluster autoscaler container images,MERGED,2019-10-15 08:12:15.000000000,2019-10-16 10:48:58.000000000,2019-10-16 10:46:18.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 30262}]","[{'number': 1, 'created': '2019-10-15 08:12:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/30ea4d29cbff4986cf6dc4813bc5b4d242dbeafa', 'message': 'Build cluster autoscaler container images\n\nAdd Dockerfile and CI config for building cluster autoscaler\ncontainer images specifically for magnum.\nThe autoscaler is built with the build tag ""magnum"" so that\nonly the magnum provider is included in the binary. This cuts\nthe size of the image in half compared to building with all\ncloud providers.\n\nChange-Id: Iecbae5866278afe1687a4533b71af60fce537a4a\n'}, {'number': 2, 'created': '2019-10-15 08:16:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/52cc2466bb1d7e1b83da10094a832e839c72b1ff', 'message': 'Build cluster autoscaler container images\n\nAdd Dockerfile and CI config for building cluster autoscaler\ncontainer images specifically for magnum.\nThe autoscaler is built with the build tag ""magnum"" so that\nonly the magnum provider is included in the binary. This cuts\nthe size of the image in half compared to building with all\ncloud providers.\n\nChange-Id: Iecbae5866278afe1687a4533b71af60fce537a4a\n'}, {'number': 3, 'created': '2019-10-15 08:18:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/d95e2bd96fac1540b7027bc123d4ab9f433056aa', 'message': 'Build cluster autoscaler container images\n\nAdd Dockerfile and CI config for building cluster autoscaler\ncontainer images specifically for magnum.\nThe autoscaler is built with the build tag ""magnum"" so that\nonly the magnum provider is included in the binary. This cuts\nthe size of the image in half compared to building with all\ncloud providers.\n\nChange-Id: Iecbae5866278afe1687a4533b71af60fce537a4a\n'}, {'number': 4, 'created': '2019-10-15 09:41:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/0dab902f11cc8cdca8a2629b3ce71b3015aa1b53', 'message': 'Build cluster autoscaler container images\n\nAdd Dockerfile and CI config for building cluster autoscaler\ncontainer images specifically for magnum.\nThe autoscaler is built with the build tag ""magnum"" so that\nonly the magnum provider is included in the binary. This cuts\nthe size of the image in half compared to building with all\ncloud providers.\nThe container-build job in .zuul.yaml has to have its timeout\nincreased, as the build time was already close to the timeout.\n\nChange-Id: Iecbae5866278afe1687a4533b71af60fce537a4a\n'}, {'number': 5, 'created': '2019-10-16 08:05:23.000000000', 'files': ['.zuul.yaml', 'playbooks/container-builder-vars.yaml', 'playbooks/container-builder.yaml', 'dockerfiles/cluster-autoscaler/Dockerfile', 'playbooks/container-publish.yaml'], 'web_link': 'https://opendev.org/openstack/magnum/commit/25c0f461695470183418b77f02ab12a09bf8d53d', 'message': 'Build cluster autoscaler container images\n\nAdd Dockerfile and CI config for building cluster autoscaler\ncontainer images specifically for magnum.\nThe autoscaler is built with the build tag ""magnum"" so that\nonly the magnum provider is included in the binary. This cuts\nthe size of the image in half compared to building with all\ncloud providers.\nThe container-build job in .zuul.yaml has to have its timeout\nincreased, as the build time was already close to the timeout.\n\nChange-Id: Iecbae5866278afe1687a4533b71af60fce537a4a\n'}]",0,688648,25c0f461695470183418b77f02ab12a09bf8d53d,19,4,5,30262,,,0,"Build cluster autoscaler container images

Add Dockerfile and CI config for building cluster autoscaler
container images specifically for magnum.
The autoscaler is built with the build tag ""magnum"" so that
only the magnum provider is included in the binary. This cuts
the size of the image in half compared to building with all
cloud providers.
The container-build job in .zuul.yaml has to have its timeout
increased, as the build time was already close to the timeout.

Change-Id: Iecbae5866278afe1687a4533b71af60fce537a4a
",git fetch https://review.opendev.org/openstack/magnum refs/changes/48/688648/4 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/container-builder-vars.yaml', 'playbooks/container-builder.yaml', 'dockerfiles/cluster-autoscaler/Dockerfile', 'playbooks/container-publish.yaml']",4,30ea4d29cbff4986cf6dc4813bc5b4d242dbeafa,autoscaler-builder," - command: docker push {{magnum_respository }}/cluster-autoscaler:v{{ item.version }} with_items: ""{{ cluster_autoscaler_versions }}"" retries: 10",,36,0
openstack%2Ftripleo-ci~master~I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5,openstack/tripleo-ci,master,I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5,DNM: Test multi-arch support for build-containers role,ABANDONED,2019-08-22 16:38:22.000000000,2019-10-16 10:45:59.000000000,,"[{'_account_id': 8175}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-08-22 16:38:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ba60ac1bbff93dce696b783c7d17e9f86696a577', 'message': 'DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n'}, {'number': 2, 'created': '2019-08-22 16:56:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bbdc54f94d9255cb1106cc8063ac09eae38303f3', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 3, 'created': '2019-08-22 18:55:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e0b44d4bdb89a86179b953bdea0a9de1d9f7adc6', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 4, 'created': '2019-08-22 21:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6497e69e22bbc30ba0a4d98eaa9fb90ad173c593', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 5, 'created': '2019-08-23 10:59:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/3a7272c995d7455d75031a80dc4580f13c503508', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 6, 'created': '2019-08-23 12:22:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/e7c1a5d2cc979b07a9c60fa7039261818dd4ec96', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 7, 'created': '2019-08-23 13:29:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9844616dc3f58b574d277b2b4babab8d611aa872', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 8, 'created': '2019-08-23 17:18:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f6815c11b4202db87d2d45cc3fd4f357ab1f091a', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 9, 'created': '2019-08-23 17:20:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/046e1cc26eece55758de7262c7dccdc3af122962', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 10, 'created': '2019-08-23 17:45:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/ee84a51b3b90a151f4eb595a7c40ce9f3961dd78', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 11, 'created': '2019-08-23 19:32:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/6e8b4b16644bcded9b3f05b7c07ee98d79933144', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 12, 'created': '2019-08-23 19:43:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/d444f8818a1b5c3881af10f16eee0d8cc117a796', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 13, 'created': '2019-08-23 22:41:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/173728f13fe7c6b137ff8257259a5603fe89b251', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 14, 'created': '2019-08-24 14:15:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b5743462285ff734986897ef37fe321321943564', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 15, 'created': '2019-08-24 17:44:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/694a90653f96ba236abbf5b3dabfffdd0f3bcd31', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 16, 'created': '2019-08-24 22:09:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/9381e90cac0ce199f5602a4ae4f3de0fc76a4d0b', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 17, 'created': '2019-08-25 00:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/8037777370b929d4ffb5a06a337752fe713739c0', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 18, 'created': '2019-08-25 04:36:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/119fec71c5b8e152ae73fd107796e9b29c4ca08c', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 19, 'created': '2019-08-25 13:27:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/73880d59ebdd773f3c3575ac17aebb8fcc1380fd', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 20, 'created': '2019-08-25 16:21:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/b7020c282cc94401d1e879d612259486f35c93c6', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 21, 'created': '2019-08-25 16:28:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/f64457e503bce4c2482122317022f7b92cc3d8c1', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 22, 'created': '2019-08-25 16:28:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7fddfbb4d20d98afeb473e1eccee85003c168353', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 23, 'created': '2019-08-26 00:09:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/65f7c8fc22536457e60382192892fb9a73626a6f', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 24, 'created': '2019-08-26 02:01:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/75e17d2148a7134eb2b93d3b7c6af2f366aa3e65', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 25, 'created': '2019-08-26 12:17:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7917ad44033135f2e8a9a98f98e9998827c2cc47', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 26, 'created': '2019-08-26 15:10:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/82ecfb35df4d46cb7e9746653190d98ca65371cc', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 27, 'created': '2019-08-26 15:14:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/bc632ea96de6342cad4a3ca2888e0f017cb6965e', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 28, 'created': '2019-08-27 13:59:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/85152781bade1aaabd2c4d0790606230bc24fa19', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}, {'number': 29, 'created': '2019-08-27 17:00:40.000000000', 'files': ['zuul.d/build-containers.yaml', 'zuul.d/layout.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-ci/commit/7d54a61d4f7abc691080a8c91889c3750b691f28', 'message': ""DNM: Test multi-arch support for build-containers role\n\nTest multi-arch tagging in https://review.opendev.org/#/c/663977.\nRun container build jobs only to make sure we don't break anything.\n\nChange-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5\nStory: https://tree.taiga.io/project/tripleo-ci-board/us/1220\n""}]",0,678058,7d54a61d4f7abc691080a8c91889c3750b691f28,69,3,29,8175,,,0,"DNM: Test multi-arch support for build-containers role

Test multi-arch tagging in https://review.opendev.org/#/c/663977.
Run container build jobs only to make sure we don't break anything.

Change-Id: I582c7d5ca4d395ee60cbdcf2abdf83a7b77906c5
Story: https://tree.taiga.io/project/tripleo-ci-board/us/1220
",git fetch https://review.opendev.org/openstack/tripleo-ci refs/changes/58/678058/25 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/build-containers.yaml', 'zuul.d/layout.yaml']",2,ba60ac1bbff93dce696b783c7d17e9f86696a577,multi-arch-tagging,, - tripleo-multinode-baremetal-full - tripleo-multinode-branchful - tripleo-multinode-container-full - tripleo-multinode-experimental - tripleo-standalone-scenarios-full - tripleo-undercloud-jobs - tripleo-periodic - tripleo-tox-molecule - tripleo-buildimage-overcloud-full-centos-7: files: &build_images_files - ^playbooks/tripleo-buildimages/.*$ - ^roles/oooci-build-images/.*$ - tripleo-buildimage-ironic-python-agent-centos-7: files: *build_images_files - tripleo-buildimage-overcloud-hardened-full-centos-7: files: *build_images_files - tripleo-ci-centos-7-scenario001-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario002-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario003-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario004-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario007-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario009-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-scenario012-multinode-oooq-container: files: - ^playbooks/tripleo-ci/.*$ - tripleo-ci-centos-7-standalone-upgrade-stein: branches: master - tripleo-ci-centos-7-containers-undercloud-minion: files: - ^zuul.d/multinode-jobs.yaml$ ,4,43
openstack%2Fkolla~stable%2Fqueens~Ibd3bc04f3cedbcf3e029579877f60e90eb7081e1,openstack/kolla,stable/queens,Ibd3bc04f3cedbcf3e029579877f60e90eb7081e1,Service assurance plugins and write_prometheus,MERGED,2019-10-16 06:10:50.000000000,2019-10-16 10:27:36.000000000,2019-10-16 10:27:35.000000000,"[{'_account_id': 4264}, {'_account_id': 10061}, {'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 06:10:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla/commit/cc6fe496d3613956993975b92a5351888ed8bb40', 'message': 'Service assurance plugins and write_prometheus\n\nThis enables to send metrics and events to AMQP 1.0.\nwrite_prometheus provides an exporter to be scraped by\nprometheus.\nThis also moves turbostat to x86 plugins\n\nChange-Id: Ibd3bc04f3cedbcf3e029579877f60e90eb7081e1\n(cherry picked from commit 706b70d4bd25b93b0c6c0d6150124a2d7cf81055)\n(cherry picked from commit 9bde747dab92e04e4be37d1104446f2573a06ba5)\n(cherry picked from commit 31a7792cbb40cbf9fcaf0bb6fbe8829513370e8c)\n(cherry picked from commit 3f8db42f1fdd1cb392a021bfa3850300cefc41df)\n'}, {'number': 2, 'created': '2019-10-16 06:36:20.000000000', 'files': ['docker/collectd/Dockerfile.j2'], 'web_link': 'https://opendev.org/openstack/kolla/commit/87486e72f58def28805f9e9bbe125f77b7e76149', 'message': 'Service assurance plugins and write_prometheus\n\nThis enables to send metrics and events to AMQP 1.0.\nwrite_prometheus provides an exporter to be scraped by\nprometheus.\n\nThis also moves turbostat to x86 plugins\n\nChange-Id: Ibd3bc04f3cedbcf3e029579877f60e90eb7081e1\n(cherry picked from commit 706b70d4bd25b93b0c6c0d6150124a2d7cf81055)\n(cherry picked from commit 9bde747dab92e04e4be37d1104446f2573a06ba5)\n(cherry picked from commit 31a7792cbb40cbf9fcaf0bb6fbe8829513370e8c)\n(cherry picked from commit 3f8db42f1fdd1cb392a021bfa3850300cefc41df)\n'}]",0,688855,87486e72f58def28805f9e9bbe125f77b7e76149,12,5,2,4264,,,0,"Service assurance plugins and write_prometheus

This enables to send metrics and events to AMQP 1.0.
write_prometheus provides an exporter to be scraped by
prometheus.

This also moves turbostat to x86 plugins

Change-Id: Ibd3bc04f3cedbcf3e029579877f60e90eb7081e1
(cherry picked from commit 706b70d4bd25b93b0c6c0d6150124a2d7cf81055)
(cherry picked from commit 9bde747dab92e04e4be37d1104446f2573a06ba5)
(cherry picked from commit 31a7792cbb40cbf9fcaf0bb6fbe8829513370e8c)
(cherry picked from commit 3f8db42f1fdd1cb392a021bfa3850300cefc41df)
",git fetch https://review.opendev.org/openstack/kolla refs/changes/55/688855/1 && git format-patch -1 --stdout FETCH_HEAD,['docker/collectd/Dockerfile.j2'],1,cc6fe496d3613956993975b92a5351888ed8bb40,collectd_queens_backports," 'collectd-amqp1', 'collectd-connectivity', 'collectd-mysql', 'collectd-ping', 'collectd-procevent', 'collectd-snmp-agent', 'collectd-snmp-agent', 'collectd-sysevent', 'collectd-write_prometheus',",,9,0
openstack%2Fmistral~stable%2Frocky~I793fbfec03032d9ff7137c11becb6d1c18ec54bc,openstack/mistral,stable/rocky,I793fbfec03032d9ff7137c11becb6d1c18ec54bc,Fix error validate token when run cron trigger,MERGED,2019-10-10 15:12:59.000000000,2019-10-16 10:09:54.000000000,2019-10-16 10:09:54.000000000,"[{'_account_id': 8731}, {'_account_id': 10068}, {'_account_id': 21032}, {'_account_id': 22348}, {'_account_id': 28691}, {'_account_id': 31093}]","[{'number': 1, 'created': '2019-10-10 15:12:59.000000000', 'files': ['mistral/utils/openstack/keystone.py'], 'web_link': 'https://opendev.org/openstack/mistral/commit/d1b8dd1635aa45d3d644b356f883484997f31ca7', 'message': ""Fix error validate token when run cron trigger\n\nA trust client can't do validate token when run cron trigger\nThis patch will fix that.\n\nChange-Id: I793fbfec03032d9ff7137c11becb6d1c18ec54bc\nCloses-Bug: #1843175\n(cherry picked from commit 51b7dd0c6d5c4d0de354719765968ca883b9f8fb)\n""}]",0,687933,d1b8dd1635aa45d3d644b356f883484997f31ca7,19,6,1,31093,,,0,"Fix error validate token when run cron trigger

A trust client can't do validate token when run cron trigger
This patch will fix that.

Change-Id: I793fbfec03032d9ff7137c11becb6d1c18ec54bc
Closes-Bug: #1843175
(cherry picked from commit 51b7dd0c6d5c4d0de354719765968ca883b9f8fb)
",git fetch https://review.opendev.org/openstack/mistral refs/changes/33/687933/1 && git format-patch -1 --stdout FETCH_HEAD,['mistral/utils/openstack/keystone.py'],1,d1b8dd1635aa45d3d644b356f883484997f31ca7,bug/1843175-stable/rocky," # trust_client = client_for_trusts(ctx.trust_id) # Using trust client, it can't validate token # when cron trigger running because keystone policy # don't allow do this. So we need use admin client to # get token data token_data = _admin_client().tokens.get_token_data(", trust_client = client_for_trusts(ctx.trust_id) token_data = trust_client.tokens.get_token_data(,6,2
openstack%2Ftacker-horizon~stable%2Ftrain~I5cb05e40c6672dbe2673b4f7ce2a4bdc93a7ef47,openstack/tacker-horizon,stable/train,I5cb05e40c6672dbe2673b4f7ce2a4bdc93a7ef47,Update .gitreview for stable/train,MERGED,2019-10-04 09:17:19.000000000,2019-10-16 10:07:53.000000000,2019-10-16 10:05:39.000000000,"[{'_account_id': 18955}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-04 09:17:19.000000000', 'files': ['.gitreview'], 'web_link': 'https://opendev.org/openstack/tacker-horizon/commit/c82bf027a1590d0591c69fa2f98473df2baf5186', 'message': 'Update .gitreview for stable/train\n\nChange-Id: I5cb05e40c6672dbe2673b4f7ce2a4bdc93a7ef47\n'}]",0,686555,c82bf027a1590d0591c69fa2f98473df2baf5186,7,2,1,22816,,,0,"Update .gitreview for stable/train

Change-Id: I5cb05e40c6672dbe2673b4f7ce2a4bdc93a7ef47
",git fetch https://review.opendev.org/openstack/tacker-horizon refs/changes/55/686555/1 && git format-patch -1 --stdout FETCH_HEAD,['.gitreview'],1,c82bf027a1590d0591c69fa2f98473df2baf5186,create-train,defaultbranch=stable/train,,1,0
openstack%2Fkolla-ansible~master~I3dd5f5d2ba73d491366791986fdbdf16b75538ef,openstack/kolla-ansible,master,I3dd5f5d2ba73d491366791986fdbdf16b75538ef,Fixes glance image cache deployment.,MERGED,2019-10-15 08:39:09.000000000,2019-10-16 09:57:16.000000000,2019-10-16 09:54:07.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2019-10-15 08:39:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/10e78a8969523d7529043439294d778d3877da83', 'message': 'Fixes glance image cache deployment.\n\nDeployment fails because the variable ""glance_registry_port"" in\n""ansible/roles/glance/templates/glance-cache.conf.j2"" hasn\'t been configured\nanywhere.\n\nAlso, ""registry_host"" and ""registry_port"" were deprecated since Queens[1], so\nthey should be removed.\n\n[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html\n\nChange-Id: I3dd5f5d2ba73d491366791986fdbdf16b75538ef\n'}, {'number': 2, 'created': '2019-10-15 08:40:29.000000000', 'files': ['ansible/roles/glance/templates/glance-cache.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/cf1b3a73aee1889bc9865275bbf2a6062293e751', 'message': 'Fixes glance image cache deployment.\n\nDeployment fails because the variable ""glance_registry_port"" in\n""ansible/roles/glance/templates/glance-cache.conf.j2"" hasn\'t been configured\nanywhere.\n\nAlso, ""registry_host"" and ""registry_port"" were deprecated since Queens[1], so\nthey should be removed.\n\n[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html\n\nCloses-Bug: #1848146\n\nChange-Id: I3dd5f5d2ba73d491366791986fdbdf16b75538ef\n'}]",0,688653,cf1b3a73aee1889bc9865275bbf2a6062293e751,14,4,2,30523,,,0,"Fixes glance image cache deployment.

Deployment fails because the variable ""glance_registry_port"" in
""ansible/roles/glance/templates/glance-cache.conf.j2"" hasn't been configured
anywhere.

Also, ""registry_host"" and ""registry_port"" were deprecated since Queens[1], so
they should be removed.

[1] https://specs.openstack.org/openstack/glance-specs/specs/queens/approved/glance/deprecate-registry.html

Closes-Bug: #1848146

Change-Id: I3dd5f5d2ba73d491366791986fdbdf16b75538ef
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/53/688653/1 && git format-patch -1 --stdout FETCH_HEAD,['ansible/roles/glance/templates/glance-cache.conf.j2'],1,10e78a8969523d7529043439294d778d3877da83,,,registry_host = {{ api_interface_address }} registry_port = {{ glance_registry_port }} ,0,3
openstack%2Fkolla-ansible~stable%2Fstein~I5ded328485855f3f3d4390282040b0d89d08d997,openstack/kolla-ansible,stable/stein,I5ded328485855f3f3d4390282040b0d89d08d997,HAProxy backend connection limits,MERGED,2019-10-15 08:15:56.000000000,2019-10-16 09:54:44.000000000,2019-10-16 09:53:07.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 29543}, {'_account_id': 30491}, {'_account_id': 30523}]","[{'number': 1, 'created': '2019-10-15 08:15:56.000000000', 'files': ['releasenotes/notes/increase-haproxy-max-connections-df6aff5c82fdef24.yaml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e729a15105f6b9826ba60605ae9354acc1aa8ce8', 'message': ""HAProxy backend connection limits\n\nThe default connection limits for backends is 2000\nhowever, mariadb defaults to a max of 10000 conections,\ntherefore changing this limit to match the mariadb limit.\n\n'haproxy_max_connections' also needs to be bumped\nfor this to work.\n\nChange-Id: I5ded328485855f3f3d4390282040b0d89d08d997\n(cherry picked from commit 46f9ad3a96d9a30a6741781cb0b47550cdb23e4f)\n""}]",0,688649,e729a15105f6b9826ba60605ae9354acc1aa8ce8,14,5,1,30523,,,0,"HAProxy backend connection limits

The default connection limits for backends is 2000
however, mariadb defaults to a max of 10000 conections,
therefore changing this limit to match the mariadb limit.

'haproxy_max_connections' also needs to be bumped
for this to work.

Change-Id: I5ded328485855f3f3d4390282040b0d89d08d997
(cherry picked from commit 46f9ad3a96d9a30a6741781cb0b47550cdb23e4f)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/49/688649/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/increase-haproxy-max-connections-df6aff5c82fdef24.yaml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml']",3,e729a15105f6b9826ba60605ae9354acc1aa8ce8,bump-haproxy-max-connections-stable/stein,haproxy_max_connections: 40000# Matches the mariadb 10000 max connections limit haproxy_defaults_max_connections: 10000,haproxy_max_connections: 4000,13,1
openstack%2Fcinder~master~I5e399624e7586db3444b38eeaccd5efa28ecb9c8,openstack/cinder,master,I5e399624e7586db3444b38eeaccd5efa28ecb9c8,Change the log level from info to error,ABANDONED,2018-09-30 03:17:57.000000000,2019-10-16 09:46:01.000000000,,"[{'_account_id': 9008}, {'_account_id': 10058}, {'_account_id': 11611}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 12822}, {'_account_id': 14384}, {'_account_id': 15670}, {'_account_id': 15941}, {'_account_id': 18883}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 22510}, {'_account_id': 23613}, {'_account_id': 24230}, {'_account_id': 24236}, {'_account_id': 24496}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24863}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 28801}]","[{'number': 1, 'created': '2018-09-30 03:17:57.000000000', 'files': ['cinder/volume/api.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/dd7afc2ec41d34b91448e3802cacfff3c58f0771', 'message': 'Change the log level from info to error\n\nChange the log level from info to error.\n\nChange-Id: I5e399624e7586db3444b38eeaccd5efa28ecb9c8\n'}]",1,606770,dd7afc2ec41d34b91448e3802cacfff3c58f0771,35,31,1,28706,,,0,"Change the log level from info to error

Change the log level from info to error.

Change-Id: I5e399624e7586db3444b38eeaccd5efa28ecb9c8
",git fetch https://review.opendev.org/openstack/cinder refs/changes/70/606770/1 && git format-patch -1 --stdout FETCH_HEAD,['cinder/volume/api.py'],1,dd7afc2ec41d34b91448e3802cacfff3c58f0771,trivialfix_log, LOG.error(msg), LOG.info(msg),1,1
openstack%2Fcharm-neutron-gateway~master~I5dc373608d56f2fbb9f21a51f73a0da13c3b1611,openstack/charm-neutron-gateway,master,I5dc373608d56f2fbb9f21a51f73a0da13c3b1611,Misc updates for OpenStack Train,MERGED,2019-10-16 08:59:30.000000000,2019-10-16 09:39:36.000000000,2019-10-16 09:39:36.000000000,"[{'_account_id': 13686}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 08:59:30.000000000', 'files': ['unit_tests/test_neutron_utils.py', 'hooks/neutron_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-neutron-gateway/commit/75c4fac21879b84ba3173c93b0f52e2795432150', 'message': 'Misc updates for OpenStack Train\n\nDrop installation of python3-neutron-lbaas as this package has\nbeen dropped from the Train UCA.\n\nChange-Id: I5dc373608d56f2fbb9f21a51f73a0da13c3b1611\n'}]",0,688881,75c4fac21879b84ba3173c93b0f52e2795432150,7,3,1,935,,,0,"Misc updates for OpenStack Train

Drop installation of python3-neutron-lbaas as this package has
been dropped from the Train UCA.

Change-Id: I5dc373608d56f2fbb9f21a51f73a0da13c3b1611
",git fetch https://review.opendev.org/openstack/charm-neutron-gateway refs/changes/81/688881/1 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_neutron_utils.py', 'hooks/neutron_utils.py']",2,75c4fac21879b84ba3173c93b0f52e2795432150,train, if cmp_os_source >= 'train': packages.remove('python3-neutron-lbaas'),,15,0
openstack%2Fneutron-fwaas~stable%2Frocky~If5fde4fc9475f468860b0c1fb29db66f1c44f74e,openstack/neutron-fwaas,stable/rocky,If5fde4fc9475f468860b0c1fb29db66f1c44f74e,Fix AttributeError with third-party L3 service plugins,MERGED,2019-10-07 15:50:18.000000000,2019-10-16 09:36:58.000000000,2019-10-16 09:36:58.000000000,"[{'_account_id': 1131}, {'_account_id': 4187}, {'_account_id': 6854}, {'_account_id': 7016}, {'_account_id': 11975}, {'_account_id': 13995}, {'_account_id': 14892}, {'_account_id': 21798}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-10-07 15:50:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/37a09d83a7f89681c69b4c3cd7bd5579850ced02', 'message': 'Fix AttributeError with third-party L3 service plugins\n\nThis changes fixes an issue where in the course of sending\nfirewall update notifications to the appropriate agents an\nAttributeError is encountered due to unsafe assumption of the\navailability of DVR on the l3_plugin. This change puts protections\nin place to avoid this issue.\n\nChange-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e\nCloses-Bug: #1847019\n'}, {'number': 2, 'created': '2019-10-07 21:37:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/d79c0f0cc07468a00ed5ded650dff891040c440e', 'message': 'Fix AttributeError with third-party L3 service plugins\n\nThis change fixes an issue where in the course of sending\nfirewall update notifications to the appropriate agents an\nAttributeError is encountered due to unsafe assumption of the\navailability of DVR on the l3_plugin.\n\nThis change puts protections in place to avoid this issue.\n\nChange-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e\nCloses-Bug: #1847019\n'}, {'number': 3, 'created': '2019-10-07 21:40:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/0137fec51fcc0c055fa2ebd39b40fa98b05ae3af', 'message': 'Fix AttributeError with third-party L3 service plugins\n\nThis change fixes an issue where in the course of sending\nfirewall update notifications to the appropriate agents an\nAttributeError is encountered due to unsafe assumption of the\navailability of DVR on the l3_plugin.\n\nThis change puts protections in place to avoid this issue.\n\nChange-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e\nCloses-Bug: #1847019\n'}, {'number': 4, 'created': '2019-10-10 17:49:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/c9c232cb589328114779771fbfafac9f6a5d9e28', 'message': 'Fix AttributeError with third-party L3 service plugins\n\nA recent patch fix from commit 20fd02611674da5365e93d06f330d1f76fd71e3e\nhave introduced an AttributeError on Third Party Plugins that does not\nimplement certain extensions.\nThis is just related to FWaaSv1 and only applicable to Rocky and below\nreleases.\nThis change fixes an issue where in the course of sending firewall\nupdate notifications to the appropriate agents an AttributeError\nis encountered due to unsafe assumption of the availability of L3\nextensions on the l3_plugin.\n\nThis change puts protections in place to avoid this issue.\n\nChange-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e\nCloses-Bug: #1847019\n'}, {'number': 5, 'created': '2019-10-10 18:33:25.000000000', 'files': ['neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/services/firewall/fwaas_plugin.py'], 'web_link': 'https://opendev.org/openstack/neutron-fwaas/commit/fc59b08ff78456c98fee0cc187f8888bc99c333e', 'message': 'Fix AttributeError with third-party L3 service plugins\n\nA recent patch fix for the Rocky branch from\ncommit 20fd02611674da5365e93d06f330d1f76fd71e3e have introduced an\nAttributeError on Third Party Plugins that does not implement\ncertain extensions.\n\nThis is just related to FWaaSv1 and only applicable to Rocky and below\nreleases.\n\nThis change fixes an issue where in the course of sending firewall\nupdate notifications to the appropriate agents an AttributeError\nis encountered due to unsafe assumption of the availability of L3\nextensions on the l3_plugin.\n\nThis change puts protections in place to avoid this issue.\n\nChange-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e\nCloses-Bug: #1847019\n'}]",6,687085,fc59b08ff78456c98fee0cc187f8888bc99c333e,30,12,5,4187,,,0,"Fix AttributeError with third-party L3 service plugins

A recent patch fix for the Rocky branch from
commit 20fd02611674da5365e93d06f330d1f76fd71e3e have introduced an
AttributeError on Third Party Plugins that does not implement
certain extensions.

This is just related to FWaaSv1 and only applicable to Rocky and below
releases.

This change fixes an issue where in the course of sending firewall
update notifications to the appropriate agents an AttributeError
is encountered due to unsafe assumption of the availability of L3
extensions on the l3_plugin.

This change puts protections in place to avoid this issue.

Change-Id: If5fde4fc9475f468860b0c1fb29db66f1c44f74e
Closes-Bug: #1847019
",git fetch https://review.opendev.org/openstack/neutron-fwaas refs/changes/85/687085/3 && git format-patch -1 --stdout FETCH_HEAD,"['neutron_fwaas/tests/unit/services/firewall/test_fwaas_plugin.py', 'neutron_fwaas/services/firewall/fwaas_plugin.py']",2,37a09d83a7f89681c69b4c3cd7bd5579850ced02,687085," scheduled_hosts = set([a.host for a in agents]) if getattr(l3_plugin, ""get_hosts_to_notify"", None): unscheduled_dvr_hosts = set() for router_id in router_ids: hosts = set(l3_plugin.get_hosts_to_notify( context, router_id)) unscheduled_dvr_hosts |= hosts scheduled_hosts = scheduled_hosts.union(unscheduled_dvr_hosts) return scheduled_hosts"," scheduled_rtr_hosts = set([a.host for a in agents]) unscheduled_dvr_hosts = set() for router_id in router_ids: hosts = set(l3_plugin._get_dvr_hosts_for_router( context, router_id)) unscheduled_dvr_hosts |= hosts total_hosts = scheduled_rtr_hosts.union(unscheduled_dvr_hosts) return total_hosts",10,9
openstack%2Fkolla-ansible~master~I99275d5338c54bfc85d0471156173be4d2f6f688,openstack/kolla-ansible,master,I99275d5338c54bfc85d0471156173be4d2f6f688,Add haproxy stats listening on external network,ABANDONED,2019-10-16 02:23:19.000000000,2019-10-16 09:25:55.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28367}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-16 02:23:19.000000000', 'files': ['ansible/group_vars/all.yml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/96d2d0016acb4e42103f36e6ad8233ecab7e2bca', 'message': 'Add haproxy stats listening on external network\n\nNormally, the default route is on network_interface. If you do not add\nexternal listeners, it is difficult for the client to access the internal\nlistening address.\n\nChange-Id: I99275d5338c54bfc85d0471156173be4d2f6f688\nSigned-off-by: ZijianGuo <guozijn@gmail.com>\n'}]",2,688844,96d2d0016acb4e42103f36e6ad8233ecab7e2bca,8,4,1,28367,,,0,"Add haproxy stats listening on external network

Normally, the default route is on network_interface. If you do not add
external listeners, it is difficult for the client to access the internal
listening address.

Change-Id: I99275d5338c54bfc85d0471156173be4d2f6f688
Signed-off-by: ZijianGuo <guozijn@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/44/688844/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/group_vars/all.yml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml']",3,96d2d0016acb4e42103f36e6ad8233ecab7e2bca,external_haproxy_stats, enable_external_haproxy_stats: false,,6,0
openstack%2Fvitrage~stable%2Ftrain~I4e782cb6f24f55aa0f93de91a202131918e10bf4,openstack/vitrage,stable/train,I4e782cb6f24f55aa0f93de91a202131918e10bf4,Fix index in counter,MERGED,2019-10-16 06:10:43.000000000,2019-10-16 09:19:14.000000000,2019-10-16 09:17:38.000000000,"[{'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 06:10:43.000000000', 'files': ['vitrage/entity_graph/graph_init.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/8d5254a4609b6c1dbaff5134821348725c2f75af', 'message': 'Fix index in counter\n\nshould start from 1 so when logging\nit will show the correct number\n\nChange-Id: I4e782cb6f24f55aa0f93de91a202131918e10bf4\n(cherry picked from commit 6ff29e73356388ee04dd17dad4ba769c3ce03f97)\n'}]",0,688854,8d5254a4609b6c1dbaff5134821348725c2f75af,8,3,1,19134,,,0,"Fix index in counter

should start from 1 so when logging
it will show the correct number

Change-Id: I4e782cb6f24f55aa0f93de91a202131918e10bf4
(cherry picked from commit 6ff29e73356388ee04dd17dad4ba769c3ce03f97)
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/54/688854/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/graph_init.py'],1,8d5254a4609b6c1dbaff5134821348725c2f75af,eyalb/logging-stable/train," for index, e in enumerate(events, 1):"," for index, e in enumerate(events):",1,1
openstack%2Fneutron~master~Ib8e0dda5ecc668ad936155df101dc696141f8d60,openstack/neutron,master,Ib8e0dda5ecc668ad936155df101dc696141f8d60,[doc][IPv6] make kernel config addr_gen_mode clear,MERGED,2019-10-11 12:45:19.000000000,2019-10-16 09:18:33.000000000,2019-10-16 09:16:49.000000000,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22348}, {'_account_id': 26622}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-10-11 12:45:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/eb5cc6edee80427a39d89d57bc1090b0f8b71092', 'message': '[doc][IPv6] make kernel config addr_gen_mode clear\n\n1. There is no such config ``net.ipv6.conf.*.addr_gen_mode``\n   for some kernel version, for instance:\n   3.10.0-862.14.4.el7.x86_64\n2. According to the commit [1], this config is used for\n   link-local and autoconf addresses.\n\n[1] https://github.com/torvalds/linux/commit/d35a00b8e33dab7385f724e713ae71c8be0a49f4\n\nChange-Id: Ib8e0dda5ecc668ad936155df101dc696141f8d60\n'}, {'number': 2, 'created': '2019-10-11 16:11:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/8b30be088bbc365bebfb35989cee66d0b47b4aaa', 'message': '[doc][IPv6] make kernel config addr_gen_mode clear\n\n1. There is no such config ``net.ipv6.conf.*.addr_gen_mode``\n   for some kernel version, for instance:\n   3.10.0-862.14.4.el7.x86_64\n2. According to the commit [1], this config is used for\n   link-local and autoconf addresses.\n\n[1] https://github.com/torvalds/linux/commit/d35a00b8e33dab7385f724e713ae71c8be0a49f4\n\nChange-Id: Ib8e0dda5ecc668ad936155df101dc696141f8d60\n'}, {'number': 3, 'created': '2019-10-15 12:12:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2bcdd67d6b4d9acdca479909b68ea100b222deca', 'message': '[doc][IPv6] make kernel config addr_gen_mode clear\n\n1. There is no such config ``net.ipv6.conf.*.addr_gen_mode``\n   for some kernel version, for instance:\n   3.10.0-862.14.4.el7.x86_64\n2. According to the commit [1], this config is used for\n   link-local and autoconf addresses.\n\n[1] https://github.com/torvalds/linux/commit/d35a00b8e33dab7385f724e713ae71c8be0a49f4\n\nChange-Id: Ib8e0dda5ecc668ad936155df101dc696141f8d60\n'}, {'number': 4, 'created': '2019-10-15 19:27:10.000000000', 'files': ['doc/source/admin/config-ipv6.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/3fe4df00e3c03889d55a9a36fcd3348ad90fb04a', 'message': '[doc][IPv6] make kernel config addr_gen_mode clear\n\n1. There is no such config ``net.ipv6.conf.*.addr_gen_mode``\n   for some kernel version, for instance:\n   3.10.0-862.14.4.el7.x86_64\n2. According to the commit [1], this config is used for\n   link-local and autoconf addresses.\n\n[1] https://github.com/torvalds/linux/commit/d35a00b8e33dab7385f724e713ae71c8be0a49f4\n\nChange-Id: Ib8e0dda5ecc668ad936155df101dc696141f8d60\n'}]",14,688117,3fe4df00e3c03889d55a9a36fcd3348ad90fb04a,27,7,4,9531,,,0,"[doc][IPv6] make kernel config addr_gen_mode clear

1. There is no such config ``net.ipv6.conf.*.addr_gen_mode``
   for some kernel version, for instance:
   3.10.0-862.14.4.el7.x86_64
2. According to the commit [1], this config is used for
   link-local and autoconf addresses.

[1] https://github.com/torvalds/linux/commit/d35a00b8e33dab7385f724e713ae71c8be0a49f4

Change-Id: Ib8e0dda5ecc668ad936155df101dc696141f8d60
",git fetch https://review.opendev.org/openstack/neutron refs/changes/17/688117/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/config-ipv6.rst'],1,eb5cc6edee80427a39d89d57bc1090b0f8b71092,no_such_config," This should be disabled (zero means disable Privacy Extensions) to allow autoconf can generated right address by EUI64. The ``addr_gen_mode`` config defines how link-local and autoconf addresses are generated: - ``net.ipv6.conf.*.addr_gen_mode`` Value 0 means generate address based on EUI64 (default). .. note:: For some older kernel version, this is no such ``addr_gen_mode`` config. The first support version is v4.11. ",- ``net.ipv6.conf.*.addr_gen_mode`` (link-local and autoconf address generation) Both of these settings should be disabled (zero).,13,2
openstack%2Frequirements~master~Ief46647ce27adb698befe1fd2eb7641841b9bc94,openstack/requirements,master,Ief46647ce27adb698befe1fd2eb7641841b9bc94,update constraint for tempest to new release 22.1.0,MERGED,2019-10-15 23:16:40.000000000,2019-10-16 09:18:17.000000000,2019-10-16 09:16:47.000000000,"[{'_account_id': 11131}, {'_account_id': 11904}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 23:16:40.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/34df3d30c290d1617ee1fc53e146c49195fe2ceb', 'message': 'update constraint for tempest to new release 22.1.0\n\nmeta:version: 22.1.0\nmeta:diff-start: -\nmeta:series: train\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Ghanshyam Mann <gmann@ghanshyammann.com>\nmeta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>\nmeta:release:Change-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541\nmeta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n(cherry picked from commit 7790dc55d28cd3e1cb3c9d42d0e7c91b581a742a)\n\nChange-Id: Ief46647ce27adb698befe1fd2eb7641841b9bc94\n'}]",0,688833,34df3d30c290d1617ee1fc53e146c49195fe2ceb,14,4,1,14288,,,0,"update constraint for tempest to new release 22.1.0

meta:version: 22.1.0
meta:diff-start: -
meta:series: train
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Ghanshyam Mann <gmann@ghanshyammann.com>
meta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>
meta:release:Change-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541
meta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
(cherry picked from commit 7790dc55d28cd3e1cb3c9d42d0e7c91b581a742a)

Change-Id: Ief46647ce27adb698befe1fd2eb7641841b9bc94
",git fetch https://review.opendev.org/openstack/requirements refs/changes/33/688833/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,34df3d30c290d1617ee1fc53e146c49195fe2ceb,,tempest===22.1.0,tempest===22.0.0,1,1
openstack%2Fironic-python-agent-builder~master~I827a72a40c14bf439168aff86d4a5a493dc491a7,openstack/ironic-python-agent-builder,master,I827a72a40c14bf439168aff86d4a5a493dc491a7,Temporary raise diskimage-builder to the latest version,MERGED,2019-10-15 13:24:44.000000000,2019-10-16 09:17:17.000000000,2019-10-16 02:59:59.000000000,"[{'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 24828}]","[{'number': 1, 'created': '2019-10-15 13:24:44.000000000', 'files': ['roles/ipa-build-dib-image/tasks/install.yaml'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/aafcdd263d9e2361bd2378941ed53357e6cf164f', 'message': 'Temporary raise diskimage-builder to the latest version\n\nThe one in upper-constraints is breaking us.\n\nChange-Id: I827a72a40c14bf439168aff86d4a5a493dc491a7\n'}]",0,688708,aafcdd263d9e2361bd2378941ed53357e6cf164f,11,4,1,10239,,,0,"Temporary raise diskimage-builder to the latest version

The one in upper-constraints is breaking us.

Change-Id: I827a72a40c14bf439168aff86d4a5a493dc491a7
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/08/688708/1 && git format-patch -1 --stdout FETCH_HEAD,['roles/ipa-build-dib-image/tasks/install.yaml'],1,aafcdd263d9e2361bd2378941ed53357e6cf164f,gate, - name: FIXME temporary raise diskimage-builder pip: name: diskimage-builder>=2.28.2 become: true,,5,0
openstack%2Fnetworking-ovn~stable%2Fqueens~I020ba64618b2eb76c627632b0575896e88d1fcf8,openstack/networking-ovn,stable/queens,I020ba64618b2eb76c627632b0575896e88d1fcf8,Set binding profile directly from OVNTrunkDriver,ABANDONED,2019-09-17 10:46:21.000000000,2019-10-16 08:58:44.000000000,,"[{'_account_id': 11952}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-09-17 10:46:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/e6a7d411f0fb81fc377098700aa06765937d1712', 'message': 'Set binding profile directly from OVNTrunkDriver\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 19.7 for 95%ile\nfrom 99 sec to 14.9 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nCloses-Bug: #1834637\n\nChange-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8\n(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)\n'}, {'number': 2, 'created': '2019-09-17 10:46:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/85cbd29cb22e0a3c271343d6f7223be6c6db645c', 'message': 'Set binding profile directly from OVNTrunkDriver\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 19.7 for 95%ile\nfrom 99 sec to 14.9 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nCloses-Bug: #1834637\n\nChange-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8\n(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)\n'}, {'number': 3, 'created': '2019-09-17 15:24:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/3653629fe5607f6518b00e521201e8e868deb236', 'message': 'Set binding profile directly from OVNTrunkDriver\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 19.7 for 95%ile\nfrom 99 sec to 14.9 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nCloses-Bug: #1834637\n\nChange-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8\n(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)\n'}, {'number': 4, 'created': '2019-09-18 06:12:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/64ca89b6b0a9a96538d53d682bbdbf6fe2bafe8a', 'message': 'Set binding profile directly from OVNTrunkDriver\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 19.7 for 95%ile\nfrom 99 sec to 14.9 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nCloses-Bug: #1834637\n\nChange-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8\n(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)\n'}, {'number': 5, 'created': '2019-09-20 13:46:25.000000000', 'files': ['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/5daf9d6d7b52d118fe1e3ca4a3bffe36b921bc51', 'message': 'Set binding profile directly from OVNTrunkDriver\n\nSetting binding profile for Trunk subports takes\ntime - for 125 subports rally CreateAndListTrunks\nscenario [0] takes about 150 seconds. We need to\nbump up the perfomance because large number of\nsubports is widly used in Kuryr deployments.\n\nTo achieve that I changed setting the binding\nprofile to be saved directly to the neutron DB.\nInstead calling port_update I update only related\nfields in OVN NorthBound DB rows. That gave performance\nimprovement in trunk port creation:\n\nfrom 101 sec to 19.7 for 95%ile\nfrom 99 sec to 14.9 for 50%ile\n\nThe same thing has been done for Trunk deletion.\n\n[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37\n\nCloses-Bug: #1834637\n\nChange-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8\n(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)\n'}]",0,682606,5daf9d6d7b52d118fe1e3ca4a3bffe36b921bc51,20,5,5,23804,,,0,"Set binding profile directly from OVNTrunkDriver

Setting binding profile for Trunk subports takes
time - for 125 subports rally CreateAndListTrunks
scenario [0] takes about 150 seconds. We need to
bump up the perfomance because large number of
subports is widly used in Kuryr deployments.

To achieve that I changed setting the binding
profile to be saved directly to the neutron DB.
Instead calling port_update I update only related
fields in OVN NorthBound DB rows. That gave performance
improvement in trunk port creation:

from 101 sec to 19.7 for 95%ile
from 99 sec to 14.9 for 50%ile

The same thing has been done for Trunk deletion.

[0] https://github.com/openstack/rally-openstack/blob/master/rally_openstack/scenarios/neutron/trunk.py#L37

Closes-Bug: #1834637

Change-Id: I020ba64618b2eb76c627632b0575896e88d1fcf8
(cherry picked from commit 739316f2be8d456e43276b891b6b8b79ec8715a7)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/06/682606/4 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/unit/ml2/test_trunk_driver.py', 'networking_ovn/ml2/trunk_driver.py']",2,e6a7d411f0fb81fc377098700aa06765937d1712,bug/1834637,"from neutron.objects import ports as port_obj self.context = n_context.get_admin_context() txn = self.plugin_driver._nb_ovn.transaction with self.context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._set_binding_profile(port, parent_port, ovn_txn) txn = self.plugin_driver._nb_ovn.transaction with self.context.session.begin(subtransactions=True), ( txn(check_error=True)) as ovn_txn: for port in subports: self._unset_binding_profile(port, ovn_txn) def _set_binding_profile(self, subport, parent_port, ovn_txn): db_port = port_obj.Port.get_object(self.context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.update({ 'parent_name': parent_port, 'tag': subport.segmentation_id}) # host + port_id is primary key port_obj.PortBinding.update_object( self.context, {'profile': binding.profile}, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to set "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=parent_port, tag=subport.segmentation_id)) def _unset_binding_profile(self, subport, ovn_txn): db_port = port_obj.Port.get_object(self.context, id=subport.port_id) if not db_port: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return try: for binding in db_port.bindings: binding.profile.pop('tag', None) binding.profile.pop('parent_name', None) # host + port_id is primary key port_obj.PortBinding.update_object( self.context, {'profile': binding.profile, 'vif_type': portbindings.VIF_TYPE_UNBOUND, 'vif_details': '', 'host': ''}, port_id=subport.port_id, host=binding.host) port_obj.PortBindingLevel.delete_objects( self.context, port_id=subport.port_id, host=binding.host) except n_exc.ObjectNotFound: LOG.debug(""Port not found while trying to unset "" ""binding_profile: %s"", subport.port_id) return ovn_txn.add(self.plugin_driver._nb_ovn.set_lswitch_port( lport_name=subport.port_id, parent_name=[], up=False, tag=[])) if trunk.sub_ports: self._set_sub_ports(trunk.port_id, trunk.sub_ports) if trunk.sub_ports: self._unset_sub_ports(trunk.sub_ports) if subports: self._set_sub_ports(trunk.port_id, subports) if subports: self._unset_sub_ports(subports)","from oslo_db import exception as os_db_exc def _set_binding_profile(self, port_id, parent_port, tag=None): context = n_context.get_admin_context() binding_profile = {} if parent_port and tag: binding_profile = {'parent_name': parent_port, 'tag': tag} port = {'port': {'binding:profile': binding_profile}} if not tag: port['port']['binding:host_id'] = None try: self.plugin_driver._plugin.update_port(context, port_id, port) except (os_db_exc.DBReferenceError, n_exc.PortNotFound): LOG.debug(""Port not found trying to set binding_profile: %s"", port_id) for port in subports: self._set_binding_profile(port.port_id, parent_port, tag=port.segmentation_id) for port in subports: self._set_binding_profile(port.port_id, None) self._set_sub_ports(trunk.port_id, trunk.sub_ports) self._unset_sub_ports(trunk.sub_ports) self._set_sub_ports(trunk.port_id, subports) self._unset_sub_ports(subports)",272,106
openstack%2Fnetworking-odl~stable%2Fstein~I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa,openstack/networking-odl,stable/stein,I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa,[stein-only] Constrain l2gw to Stein version,MERGED,2019-10-11 16:44:48.000000000,2019-10-16 08:35:02.000000000,2019-10-16 08:33:10.000000000,"[{'_account_id': 1131}, {'_account_id': 4694}, {'_account_id': 8313}, {'_account_id': 11975}, {'_account_id': 17685}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 16:44:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/12b1a17cdd82d88b7f35b79f3ba8689c9bd0026c', 'message': ""[stein-only] Constrain l2gw to Stein version\n\nSince Train version of l2gw (15.0.0) was released, which requires newer\nneuton-lib (1.29.0) than the version in upper-constaints.txt (1.25.0)\nin stein, the CI jobs started to fail with:\n\nChange-Id: I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa\nContextualVersionConflict: (neutron-lib 1.25.0 (/home/zuul/src/opendev.org/openstack/networking-odl/.tox/py27/lib/python2.7/site-packages), Requirement.parse('neutron-lib>=1.29.0'), set(['networking-l2gw']))\n""}, {'number': 2, 'created': '2019-10-11 16:47:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/ebfe7c7a26778b990d8331605283503519a167a0', 'message': ""[stein-only] Constrain l2gw to Stein version\n\nSince Train version of l2gw (15.0.0) was released, which requires newer\nneuton-lib (1.29.0) than the version in upper-constaints.txt (1.25.0)\nin stein, the CI jobs started to fail with:\n\nContextualVersionConflict: (neutron-lib 1.25.0 (/home/zuul/src/opendev.org/openstack/networking-odl/.tox/py27/lib/python2.7/site-packages), Requirement.parse('neutron-lib>=1.29.0'), set(['networking-l2gw']))\n\nChange-Id: I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa\n""}, {'number': 3, 'created': '2019-10-14 14:53:05.000000000', 'files': ['requirements.txt'], 'web_link': 'https://opendev.org/openstack/networking-odl/commit/5b062f03e795809760b706d7700b53c8ef038a7f', 'message': ""[stein-only] Constrain l2gw to Stein version\n\nSince Train version of l2gw (15.0.0) was released, which requires newer\nneutron-lib (1.29.0) than the version in upper-constraints.txt (1.25.0)\nin stein, the CI jobs started to fail with:\n\nContextualVersionConflict: (neutron-lib 1.25.0 (/home/zuul/src/opendev.org/openstack/networking-odl/.tox/py27/lib/python2.7/site-packages), Requirement.parse('neutron-lib>=1.29.0'), set(['networking-l2gw']))\n\nChange-Id: I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa\n""}]",6,688168,5b062f03e795809760b706d7700b53c8ef038a7f,27,7,3,17685,,,0,"[stein-only] Constrain l2gw to Stein version

Since Train version of l2gw (15.0.0) was released, which requires newer
neutron-lib (1.29.0) than the version in upper-constraints.txt (1.25.0)
in stein, the CI jobs started to fail with:

ContextualVersionConflict: (neutron-lib 1.25.0 (/home/zuul/src/opendev.org/openstack/networking-odl/.tox/py27/lib/python2.7/site-packages), Requirement.parse('neutron-lib>=1.29.0'), set(['networking-l2gw']))

Change-Id: I7dc6d466e7d4fc82e1da27cb7fa5b53e72acf5aa
",git fetch https://review.opendev.org/openstack/networking-odl refs/changes/68/688168/1 && git format-patch -1 --stdout FETCH_HEAD,['requirements.txt'],1,12b1a17cdd82d88b7f35b79f3ba8689c9bd0026c,,"networking-l2gw>=12.0.0,<15.0.0 # Apache-2.0",networking-l2gw>=12.0.0 # Apache-2.0,1,1
openstack%2Fproject-config~master~Ic48d7db4c6b7b1dd2589118c630f45deee19730f,openstack/project-config,master,Ic48d7db4c6b7b1dd2589118c630f45deee19730f,Remove opensuse-423 from nodepool,MERGED,2019-10-14 16:20:44.000000000,2019-10-16 08:30:47.000000000,2019-10-16 08:30:47.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 16:20:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/53774614a983b0699149286abeff43b68c628850', 'message': 'Remove opensuse-423 from nodepool\n\nThis label/image is no longer supported.\n\nChange-Id: Ic48d7db4c6b7b1dd2589118c630f45deee19730f\n'}, {'number': 2, 'created': '2019-10-16 05:50:29.000000000', 'files': ['nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/19380c9b599e5c3e970627c84790ea148cbb9a2c', 'message': 'Remove opensuse-423 from nodepool\n\nThis label/image is no longer supported.\n\nChange-Id: Ic48d7db4c6b7b1dd2589118c630f45deee19730f\n'}]",2,688444,19380c9b599e5c3e970627c84790ea148cbb9a2c,16,6,2,1,,,0,"Remove opensuse-423 from nodepool

This label/image is no longer supported.

Change-Id: Ic48d7db4c6b7b1dd2589118c630f45deee19730f
",git fetch https://review.opendev.org/openstack/project-config refs/changes/44/688444/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml']",5,53774614a983b0699149286abeff43b68c628850,opensuse-423,, - name: opensuse-423 min-ready: 1 - name: opensuse-423 config-drive: true - name: opensuse-423 min-ram: 8000 flavor-name: 'Performance' diskimage: opensuse-423 key-name: infra-root-keys-2018-06-15 - name: opensuse-423,0,66
openstack%2Fpuppet-gnocchi~stable%2Ftrain~I65ed470a1f585ed4704057a71511451c8db44f8c,openstack/puppet-gnocchi,stable/train,I65ed470a1f585ed4704057a71511451c8db44f8c,Configure s3_secret_access_key as secret,MERGED,2019-10-16 00:41:36.000000000,2019-10-16 08:27:10.000000000,2019-10-16 08:27:10.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 00:41:36.000000000', 'files': ['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/b4623024bcc4b0b3737efa481f9fb6349a5d0cf9', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/688319\n(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)\n'}]",0,688841,b4623024bcc4b0b3737efa481f9fb6349a5d0cf9,6,2,1,9414,,,0,"Configure s3_secret_access_key as secret

Parameter s3_secret_access_key should be configured as a secret.

Change-Id: I65ed470a1f585ed4704057a71511451c8db44f8c
Closes-Bug: #1847941
Depends-On: https://review.opendev.org/688319
(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/41/688841/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb']",2,b4623024bcc4b0b3737efa481f9fb6349a5d0cf9,bug/1847941-stable/train, is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz').with_secret(true), is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz'),2,2
openstack%2Fpuppet-gnocchi~stable%2Frocky~I65ed470a1f585ed4704057a71511451c8db44f8c,openstack/puppet-gnocchi,stable/rocky,I65ed470a1f585ed4704057a71511451c8db44f8c,Configure s3_secret_access_key as secret,MERGED,2019-10-16 00:41:20.000000000,2019-10-16 08:27:10.000000000,2019-10-16 08:27:10.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 00:41:20.000000000', 'files': ['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/4bfed23cfb24a32ee5fe160527e0fbfa12d3e938', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/688319\n(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)\n'}]",0,688839,4bfed23cfb24a32ee5fe160527e0fbfa12d3e938,6,2,1,9414,,,0,"Configure s3_secret_access_key as secret

Parameter s3_secret_access_key should be configured as a secret.

Change-Id: I65ed470a1f585ed4704057a71511451c8db44f8c
Closes-Bug: #1847941
Depends-On: https://review.opendev.org/688319
(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/39/688839/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb']",2,4bfed23cfb24a32ee5fe160527e0fbfa12d3e938,bug/1847941-stable/rocky, is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz').with_secret(true), is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz'),2,2
openstack%2Fmagnum~master~Idda0267c5396f0406c5d71bfd97bcfb9905e8bb7,openstack/magnum,master,Idda0267c5396f0406c5d71bfd97bcfb9905e8bb7,update api-ref for clustertemplate,MERGED,2019-09-02 11:19:16.000000000,2019-10-16 08:24:14.000000000,2019-10-16 08:22:38.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 28614}]","[{'number': 1, 'created': '2019-09-02 11:19:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/12c7aeaaaa8c8d036f5cc37f4c3b0a4df2c4c5eb', 'message': ""update api-ref for clustertemplate\n\nadd param 'hidden' in clustertemplate api-ref,and add param 'floating_ip_enabled' in create clustertemplate request\n\nChange-Id: Idda0267c5396f0406c5d71bfd97bcfb9905e8bb7\n""}, {'number': 2, 'created': '2019-10-16 07:58:40.000000000', 'files': ['api-ref/source/parameters.yaml', 'api-ref/source/clustertemplates.inc'], 'web_link': 'https://opendev.org/openstack/magnum/commit/25496654b14d30113fd68ec74422498fc5eb08c6', 'message': ""update api-ref for clustertemplate\n\nadd param 'hidden' in clustertemplate api-ref,and add param 'floating_ip_enabled' in create clustertemplate request\n\nChange-Id: Idda0267c5396f0406c5d71bfd97bcfb9905e8bb7\n""}]",0,679624,25496654b14d30113fd68ec74422498fc5eb08c6,13,4,2,30814,,,0,"update api-ref for clustertemplate

add param 'hidden' in clustertemplate api-ref,and add param 'floating_ip_enabled' in create clustertemplate request

Change-Id: Idda0267c5396f0406c5d71bfd97bcfb9905e8bb7
",git fetch https://review.opendev.org/openstack/magnum refs/changes/24/679624/2 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'api-ref/source/clustertemplates.inc']",2,12c7aeaaaa8c8d036f5cc37f4c3b0a4df2c4c5eb,update api-ref, - floating_ip_enabled: floating_ip_enabled - hidden: hidden - hidden: hidden - hidden: hidden - hidden: hidden - hidden: hidden,,13,0
openstack%2Fopenstack-manuals~master~Iacc7d1d76b3aab6f120bac8b543fd8c3d009b42a,openstack/openstack-manuals,master,Iacc7d1d76b3aab6f120bac8b543fd8c3d009b42a,Imported Translations from Zanata,MERGED,2019-10-16 07:06:29.000000000,2019-10-16 08:08:55.000000000,2019-10-16 07:40:43.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 07:06:29.000000000', 'files': ['doc/install-guide/source/locale/ru/LC_MESSAGES/install-guide.po'], 'web_link': 'https://opendev.org/openstack/openstack-manuals/commit/6b9b6ffd3c8ece1df3f9a0613ea2c71d564a463a', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: Iacc7d1d76b3aab6f120bac8b543fd8c3d009b42a\n'}]",0,688861,6b9b6ffd3c8ece1df3f9a0613ea2c71d564a463a,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: Iacc7d1d76b3aab6f120bac8b543fd8c3d009b42a
",git fetch https://review.opendev.org/openstack/openstack-manuals refs/changes/61/688861/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/install-guide/source/locale/ru/LC_MESSAGES/install-guide.po'],1,6b9b6ffd3c8ece1df3f9a0613ea2c71d564a463a,zanata/translations,"# Ilya Alekseyev <ilyaalekseyev@acm.org>, 2019. #zanata""Project-Id-Version: Installation Guide\n""""POT-Creation-Date: 2019-10-15 06:44+0000\n""""PO-Revision-Date: 2019-10-15 09:23+0000\n""""As of Ubuntu 18.04, the ``etcd`` package is no longer available from the "" ""default repository. To install successfully, enable the ``Universe`` "" ""repository on Ubuntu."" msgstr """" ""Для Ubuntu 18.04, пакет ``etcd`` больше недоступен в репозитории по "" ""умолчанию. Для установки разрешите репозиторий ``Universe``."" msgid """"msgid ""Change the existing line ``MEMCACHED_PARAMS=\""-l 127.0.0.1\""``."" msgstr ""Замените имеющуюся строку ``MEMCACHED_PARAMS=\""-l 127.0.0.1\""``."" ""Configure the service to use the management IP address of the controller "" ""node. This is to enable access by other nodes via the management network:"" msgstr """" ""Сконфигурируйте сервис на использование IP адреса менеджмент сети ноды "" ""контроллера. Это позволит другим нодам получить доступ через менеджмент сеть:"" msgid """"""Create and edit the ``/etc/etcd/etcd.conf.yml`` file and set the ``initial-"" ""cluster``, ``initial-advertise-peer-urls``, ``advertise-client-urls``, "" ""``listen-client-urls`` to the management IP address of the controller node "" ""to enable access by other nodes via the management network:"" msgstr """" ""Создайте и отредактируйте файл ``/etc/etcd/etcd.conf.yml`` задав опции "" ""``initial-cluster``, ``initial-advertise-peer-urls``, ``advertise-client-"" ""urls``, ``listen-client-urls`` как IP адресс менеджмент сети ноды "" ""контроллера чтобы обеспечить доступ других нод по менеджмент сети:"" msgid """"msgid ""Create and edit the ``/usr/lib/systemd/system/etcd.service`` file:"" msgstr """" ""Создайте и отредактируйте файл ``/usr/lib/systemd/system/etcd.service``:"" msgid ""Create etcd user:"" msgstr ""Создайте пользователя etcd:"" msgid ""Create the necessary directories:"" msgstr ""Создайте необходимые директории:"" msgid ""Determine your system architecture:"" msgstr ""Определите архитектуру вашей системы:"" msgid ""Download and install the etcd tarball for x86_64/amd64:"" msgstr ""Скачайте tar архив и установите etcd для x86_64/amd64:"" msgid """" ""Edit the ``/etc/default/etcd`` file and set the ``ETCD_INITIAL_CLUSTER``, "" ""``ETCD_INITIAL_ADVERTISE_PEER_URLS``, ``ETCD_ADVERTISE_CLIENT_URLS``, "" ""``ETCD_LISTEN_CLIENT_URLS`` to the management IP address of the controller "" ""node to enable access by other nodes via the management network:"" msgstr """" ""Отредактируйте файл ``/etc/default/etcd`` и установите параметры "" ""``ETCD_INITIAL_CLUSTER``, ``ETCD_INITIAL_ADVERTISE_PEER_URLS``, "" ""``ETCD_ADVERTISE_CLIENT_URLS``, ``ETCD_LISTEN_CLIENT_URLS`` как IP адрес "" ""ноды контроллера в менеджмент сети , чтобы обеспечить доступ других нод "" ""через менеджмент сеть:"" msgid """" ""Edit the ``/etc/etcd/etcd.conf`` file and set the ``ETCD_INITIAL_CLUSTER``, "" ""``ETCD_INITIAL_ADVERTISE_PEER_URLS``, ``ETCD_ADVERTISE_CLIENT_URLS``, "" ""``ETCD_LISTEN_CLIENT_URLS`` to the management IP address of the controller "" ""node to enable access by other nodes via the management network:"" msgstr """" ""Отредактируйте файл ``/etc/etcd/etcd.conf`` и установите параметры "" ""``ETCD_INITIAL_CLUSTER``, ``ETCD_INITIAL_ADVERTISE_PEER_URLS``, "" ""``ETCD_ADVERTISE_CLIENT_URLS``, ``ETCD_LISTEN_CLIENT_URLS`` как IP адрес "" ""ноды контроллера в менеджмент сети , чтобы обеспечить доступ других нод "" ""через менеджмент сеть:"" ""Edit the ``/etc/sysconfig/memcached`` file and complete the following "" ""actions:"" msgstr """" ""Отредактируйте файл ``/etc/sysconfig/memcached`` и выполните следующие "" ""действия:"" msgid """"msgid ""Enable and restart the etcd service:"" msgstr ""Разрешите и запустите сервис etcd:"" msgid ""Enable and start the etcd service:"" msgstr ""Разрешите и запустите сервис etcd:"" msgid ""Etcd"" msgstr ""Etcd"" msgid ""Etcd for RHEL and CentOS"" msgstr ""Etcd для RHEL и CentOS"" msgid ""Etcd for Ubuntu"" msgstr ""Etcd для Ubuntu"" msgid ""Install the ``etcd`` package:"" msgstr ""Установите пакет ``etcd``:"" msgid ""Memcached for RHEL and CentOS"" msgstr ""Memcached для RHEL и CentOS"" msgid ""Memcached for SUSE"" msgstr ""Memcached для SUSE"" msgstr ""Вариант сети 1: Провайдерские Сети""""OpenStack services may use Etcd, a distributed reliable key-value store for "" ""distributed key locking, storing configuration, keeping track of service "" ""live-ness and other scenarios."" msgstr """" ""Сервисы OpenStack могут использовать Etcd, распределенное надежное хранилище "" ""данных типа ключ-значение для распределенной блокировки ключа, хранения "" ""конфигурации, отслеживания работоспособности сервисов и для других сценариев."" msgid """"msgid ""Or download and install the etcd tarball for arm64:"" msgstr ""Или скачайте tar архив и установите etcd для arm64:"" msgid ""Reload systemd service files with:"" msgstr ""Перезагрузите файлы конфигурации сервиса systemd:"" msgid """" ""Right now, there is no distro package available for etcd3. This guide uses "" ""the tarball installation as a workaround until proper distro packages are "" ""available."" msgstr """" ""В текущий момент пакет для etcd3 в дистрибутиве недоступен. В этом "" ""руководстве мы используем инсталляцию из tar архива, как временный вариант, "" ""пока в дистрибутиве не появится пакет."" msgid ""The etcd service runs on the controller node."" msgstr ""Сервис etcd работает на ноде контроллера."" ","""Project-Id-Version: openstackinstallguide\n""""POT-Creation-Date: 2018-10-26 01:42+0000\n""""PO-Revision-Date: 2018-10-26 12:49+0000\n""msgstr ""Вариант сети 2: Провайдерские Сети""",132,4
openstack%2Fpython-magnumclient~master~I98b662b5a95f16d80852e3b30683c75e78acb3e5,openstack/python-magnumclient,master,I98b662b5a95f16d80852e3b30683c75e78acb3e5,Add nodegroup CRUD commands,MERGED,2019-03-26 16:09:05.000000000,2019-10-16 08:08:14.000000000,2019-09-27 08:20:24.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27057}, {'_account_id': 28022}, {'_account_id': 29425}]","[{'number': 1, 'created': '2019-03-26 16:09:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/c0779113e3154b91fc3004db02356960dc1eeeb6', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe node-group create <params> <cluster> <nodegroup>\n* openstack coe node-group delete <cluster> <nodegroup>\n* openstack coe node-group update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 2, 'created': '2019-03-26 16:42:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/b97dbe1d490f5efa4aca3e80f28d9f7168e7c97e', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe node-group create <params> <cluster> <nodegroup>\n* openstack coe node-group delete <cluster> <nodegroup>\n* openstack coe node-group update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 3, 'created': '2019-03-27 16:28:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/3efdd680c15a88cfa7f980d7e8d8cf7b4dc19f42', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 4, 'created': '2019-06-24 13:21:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/27faf468082e40cec7e90ed80ab9de559f124062', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 5, 'created': '2019-09-06 15:11:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/2103ec682932733078557101372ae5087994270c', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 6, 'created': '2019-09-11 09:00:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/ef644241d5c981aa0f264f01282915317a06b0a7', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 7, 'created': '2019-09-12 16:00:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/4a90385b61eb04ef37bb6db6c91f9898fc8d72c8', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 8, 'created': '2019-09-20 08:55:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/0f0c9567bd4753492ffcd20476ee16063f64fb65', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 9, 'created': '2019-09-25 14:58:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/c248a8a6bd5fa573a2fdf9bdeb6aeb7edcb1cf69', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}, {'number': 10, 'created': '2019-09-26 08:16:32.000000000', 'files': ['magnumclient/tests/osc/unit/v1/test_nodegroups.py', 'magnumclient/tests/v1/test_nodegroups.py', 'magnumclient/tests/osc/unit/v1/fakes.py', 'setup.cfg', 'magnumclient/osc/v1/nodegroups.py', 'magnumclient/v1/nodegroups.py'], 'web_link': 'https://opendev.org/openstack/python-magnumclient/commit/934cf548540086268991dab47b5bcb85f65b693f', 'message': 'Add nodegroup CRUD commands\n\nThe commands added are:\n\n* openstack coe nodegroup create <params> <cluster> <nodegroup>\n* openstack coe nodegroup delete <cluster> <nodegroup>\n* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>\n\nDepends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c\nChange-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5\n'}]",2,647793,934cf548540086268991dab47b5bcb85f65b693f,41,6,10,27057,,,0,"Add nodegroup CRUD commands

The commands added are:

* openstack coe nodegroup create <params> <cluster> <nodegroup>
* openstack coe nodegroup delete <cluster> <nodegroup>
* openstack coe nodegroup update <op> <params> <cluster> <nodegroup>

Depends-On: I4ad60994ad6b4cb9cac18129557e1e87e61ae98c
Change-Id: I98b662b5a95f16d80852e3b30683c75e78acb3e5
",git fetch https://review.opendev.org/openstack/python-magnumclient refs/changes/93/647793/5 && git format-patch -1 --stdout FETCH_HEAD,"['magnumclient/tests/osc/unit/v1/test_nodegroups.py', 'magnumclient/tests/v1/test_nodegroups.py', 'setup.cfg', 'magnumclient/osc/v1/nodegroups.py', 'magnumclient/v1/nodegroups.py']",5,c0779113e3154b91fc3004db02356960dc1eeeb6,magnum_nodegroups,"from magnumclient import exceptions def create(self, cluster_id, **kwargs): new = {} for (key, value) in kwargs.items(): if key in CREATION_ATTRIBUTES: new[key] = value else: raise exceptions.InvalidAttribute( ""Key must be in %s"" % "","".join(CREATION_ATTRIBUTES)) return self._create(self._path(cluster_id), new) def delete(self, cluster_id, id): return self._delete(self._path(cluster_id, id=id)) def update(self, cluster_id, id, patch): return self._update(self._path(cluster_id, id=id), patch)",,461,1
openstack%2Fkolla~master~I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,openstack/kolla,master,I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486,CI: pep8: Fix yamllint error on .yamllint,MERGED,2019-10-15 15:30:12.000000000,2019-10-16 08:06:12.000000000,2019-10-15 22:01:07.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-15 15:30:12.000000000', 'files': ['.yamllint'], 'web_link': 'https://opendev.org/openstack/kolla/commit/88d26e52d350683f4407191ccb196a203167e756', 'message': 'CI: pep8: Fix yamllint error on .yamllint\n\nChange-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486\nSigned-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>\n'}]",0,688735,88d26e52d350683f4407191ccb196a203167e756,15,5,1,30491,,,0,"CI: pep8: Fix yamllint error on .yamllint

Change-Id: I0ffa25a4bdc7b7966b986e1718b4bb8ce02d2486
Signed-off-by: Radosław Piliszek <radoslaw.piliszek@gmail.com>
",git fetch https://review.opendev.org/openstack/kolla refs/changes/35/688735/1 && git format-patch -1 --stdout FETCH_HEAD,['.yamllint'],1,88d26e52d350683f4407191ccb196a203167e756,,---,,1,0
openstack%2Fvitrage~stable%2Ftrain~Icd99bf6abf51b99290578f236e27f5aaceeeae60,openstack/vitrage,stable/train,Icd99bf6abf51b99290578f236e27f5aaceeeae60,Add database migrations release note,MERGED,2019-10-15 06:22:47.000000000,2019-10-16 07:47:12.000000000,2019-10-16 07:45:38.000000000,"[{'_account_id': 1736}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 06:22:47.000000000', 'files': ['releasenotes/notes/database-migrations-ffca2f9f3283f2a2.yaml'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/3a2639a0acbd265a6afd047cea40aab1acae61e3', 'message': 'Add database migrations release note\n\nChange-Id: Icd99bf6abf51b99290578f236e27f5aaceeeae60\n(cherry picked from commit cc46fdb49773e26e96d4833926c7ddc2e58dd410)\n'}]",0,688630,3a2639a0acbd265a6afd047cea40aab1acae61e3,8,4,1,19134,,,0,"Add database migrations release note

Change-Id: Icd99bf6abf51b99290578f236e27f5aaceeeae60
(cherry picked from commit cc46fdb49773e26e96d4833926c7ddc2e58dd410)
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/30/688630/1 && git format-patch -1 --stdout FETCH_HEAD,['releasenotes/notes/database-migrations-ffca2f9f3283f2a2.yaml'],1,3a2639a0acbd265a6afd047cea40aab1acae61e3,db-migrations-release-notes-stable/train,--- features: - | Starting with Train release Vitrage supports database migrations. It means that starting U release you will be able to upgrade Vitrage from the previous release. ,,6,0
openstack%2Fpuppet-tripleo~master~I394f56ba9b213c75378bdf21999d23509632523c,openstack/puppet-tripleo,master,I394f56ba9b213c75378bdf21999d23509632523c,Fix missing PXE directories for Conductor,MERGED,2019-09-25 10:26:57.000000000,2019-10-16 07:39:06.000000000,2019-10-04 08:10:39.000000000,"[{'_account_id': 6926}, {'_account_id': 7144}, {'_account_id': 10239}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 24245}]","[{'number': 1, 'created': '2019-09-25 10:26:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2d611c12406d902f123df0ce0629a348cadf71cd', 'message': 'Fix missing PXE directories for Conductor\n\nWhen Ironic Conductor class is called, it expects the\nPXE directories exist. That is only the case for the step 4.\nWhile there is also a case when the conductor class invoked\nfor the step 3 & db sync case. For that case also inlcude\nthe missing ironic::pxe class to ensure the PXE directories\ncreated.\n\nCloses-Bug: #1845222\n\nChange-Id: I394f56ba9b213c75378bdf21999d23509632523c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 2, 'created': '2019-09-26 09:20:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f60f954c14cc85193c89cf2e674b6b29c122bad0', 'message': 'Fix missing PXE directories for Conductor\n\nWhen Ironic Conductor class is called, it expects the\nPXE directories exist. That is only the case for the step 4.\nWhile there is also a case when the conductor class invoked\nfor the step 3 & db sync case. For that case also inlcude\nthe missing ironic::pxe class to ensure the PXE directories\ncreated.\n\nCloses-Bug: #1845222\n\nChange-Id: I394f56ba9b213c75378bdf21999d23509632523c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}, {'number': 3, 'created': '2019-10-03 07:48:05.000000000', 'files': ['manifests/profile/base/ironic/conductor.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/2f69faf666bcb574d59f7c087ac9bcee98693365', 'message': 'Fix missing PXE directories for Conductor\n\nWhen Ironic Conductor class is called, it expects the\nPXE directories exist. That is only the case for the step 4.\nWhile there is also a case when the conductor class invoked\nfor the step 3 & db sync case. For that case also inlcude\nthe missing ironic::pxe class to ensure the PXE directories\ncreated.\n\nCloses-Bug: #1845222\n\nChange-Id: I394f56ba9b213c75378bdf21999d23509632523c\nSigned-off-by: Bogdan Dobrelya <bdobreli@redhat.com>\n'}]",2,684689,2f69faf666bcb574d59f7c087ac9bcee98693365,33,6,3,6926,,,0,"Fix missing PXE directories for Conductor

When Ironic Conductor class is called, it expects the
PXE directories exist. That is only the case for the step 4.
While there is also a case when the conductor class invoked
for the step 3 & db sync case. For that case also inlcude
the missing ironic::pxe class to ensure the PXE directories
created.

Closes-Bug: #1845222

Change-Id: I394f56ba9b213c75378bdf21999d23509632523c
Signed-off-by: Bogdan Dobrelya <bdobreli@redhat.com>
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/89/684689/3 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/ironic/conductor.pp'],1,2d611c12406d902f123df0ce0629a348cadf71cd,bug/1845222, # Ironic conductor class expects PXE directories exist if ($step >= 3 and $sync_db) and $manage_pxe { include ::ironic::pxe } ,,5,0
openstack%2Fvitrage~stable%2Ftrain~I50eae6ae50a924ce5b325fc6637404902c035f7f,openstack/vitrage,stable/train,I50eae6ae50a924ce5b325fc6637404902c035f7f,Add ability to upgrade db,MERGED,2019-10-15 06:22:03.000000000,2019-10-16 07:29:11.000000000,2019-10-16 07:27:55.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19159}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 06:22:03.000000000', 'files': ['vitrage/storage/sqlalchemy/migration/__init__.py', 'vitrage/storage/base.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/versions/4e44c9414dff_initial_migration.py', 'vitrage/storage/sqlalchemy/migration/alembic.ini', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/env.py', 'vitrage/storage/sqlalchemy/models.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/README', 'vitrage/tests/unit/storage/test_migrations.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/versions/__init__.py', 'vitrage/storage/impl_sqlalchemy.py', 'requirements.txt', 'vitrage/tests/unit/storage/__init__.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/script.py.mako', 'vitrage/cli/storage.py', 'setup.cfg', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/__init__.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/e0cf274da278a71e4e89cd5fb72b6a8ab0c722ec', 'message': 'Add ability to upgrade db\n\nThis commit adds support for database migrations via alembic.\n\nFirst revision corresponds to Train release.\n\nCo-Authored-By: Oleksiy Petrenko <opetrenko@mirantis.com>\nChange-Id: I50eae6ae50a924ce5b325fc6637404902c035f7f\nImplements: blueprint db-upgrade\n(cherry picked from commit abb6164722902f6bbe0dc6b534aaf66dbd7ae8d9)\n'}]",0,688629,e0cf274da278a71e4e89cd5fb72b6a8ab0c722ec,10,5,1,19134,,,0,"Add ability to upgrade db

This commit adds support for database migrations via alembic.

First revision corresponds to Train release.

Co-Authored-By: Oleksiy Petrenko <opetrenko@mirantis.com>
Change-Id: I50eae6ae50a924ce5b325fc6637404902c035f7f
Implements: blueprint db-upgrade
(cherry picked from commit abb6164722902f6bbe0dc6b534aaf66dbd7ae8d9)
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/29/688629/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/storage/sqlalchemy/migration/__init__.py', 'vitrage/storage/base.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/versions/4e44c9414dff_initial_migration.py', 'vitrage/storage/sqlalchemy/migration/alembic.ini', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/env.py', 'vitrage/storage/sqlalchemy/models.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/README', 'vitrage/tests/unit/storage/test_migrations.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/versions/__init__.py', 'vitrage/storage/impl_sqlalchemy.py', 'requirements.txt', 'vitrage/tests/unit/storage/__init__.py', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/script.py.mako', 'vitrage/cli/storage.py', 'setup.cfg', 'vitrage/storage/sqlalchemy/migration/alembic_migrations/__init__.py']",16,e0cf274da278a71e4e89cd5fb72b6a8ab0c722ec,bp/db-upgrade-stable/train,,,697,33
openstack%2Fswift~master~I97beace3094f11286730b99653dc1e8f699c5aec,openstack/swift,master,I97beace3094f11286730b99653dc1e8f699c5aec,tests: Stop invoking python just to get the real source directory,MERGED,2019-10-15 22:09:26.000000000,2019-10-16 07:16:11.000000000,2019-10-16 07:14:25.000000000,"[{'_account_id': 330}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 22:09:26.000000000', 'files': ['.functests', '.unittests', '.alltests', '.probetests'], 'web_link': 'https://opendev.org/openstack/swift/commit/86952dd3edf4ca45f8df7440cb8b6d31d9e415d7', 'message': ""tests: Stop invoking python just to get the real source directory\n\nWhile we're at it, stop checking for a seven-year-old version of nose --\nwe already list a newer version in test-requirements.txt anyway.\n\nChange-Id: I97beace3094f11286730b99653dc1e8f699c5aec\n""}]",0,688826,86952dd3edf4ca45f8df7440cb8b6d31d9e415d7,11,3,1,15343,,,0,"tests: Stop invoking python just to get the real source directory

While we're at it, stop checking for a seven-year-old version of nose --
we already list a newer version in test-requirements.txt anyway.

Change-Id: I97beace3094f11286730b99653dc1e8f699c5aec
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/688826/1 && git format-patch -1 --stdout FETCH_HEAD,"['.functests', '.alltests', '.unittests', '.probetests']",4,86952dd3edf4ca45f8df7440cb8b6d31d9e415d7,,"SRC_DIR=$(dirname $(realpath ""$0""))","SRC_DIR=$(python -c ""import os; print(os.path.dirname(os.path.realpath('$0')))"")",5,13
openstack%2Fpuppet-gnocchi~stable%2Fqueens~I65ed470a1f585ed4704057a71511451c8db44f8c,openstack/puppet-gnocchi,stable/queens,I65ed470a1f585ed4704057a71511451c8db44f8c,Configure s3_secret_access_key as secret,MERGED,2019-10-16 00:41:11.000000000,2019-10-16 07:07:18.000000000,2019-10-16 07:07:17.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 00:41:11.000000000', 'files': ['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/0a165cb4fef34d8432a04456de1575d021cd677b', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/688319\n(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)\n'}]",0,688838,0a165cb4fef34d8432a04456de1575d021cd677b,6,2,1,9414,,,0,"Configure s3_secret_access_key as secret

Parameter s3_secret_access_key should be configured as a secret.

Change-Id: I65ed470a1f585ed4704057a71511451c8db44f8c
Closes-Bug: #1847941
Depends-On: https://review.opendev.org/688319
(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/38/688838/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb']",2,0a165cb4fef34d8432a04456de1575d021cd677b,bug/1847941-stable/queens, is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz').with_secret(true), is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz'),2,2
openstack%2Fpuppet-gnocchi~stable%2Fstein~I65ed470a1f585ed4704057a71511451c8db44f8c,openstack/puppet-gnocchi,stable/stein,I65ed470a1f585ed4704057a71511451c8db44f8c,Configure s3_secret_access_key as secret,MERGED,2019-10-16 00:41:30.000000000,2019-10-16 06:42:36.000000000,2019-10-16 06:42:35.000000000,"[{'_account_id': 9414}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 00:41:30.000000000', 'files': ['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/3ee8cb69e1845a0f6739c51516b809b432f121f7', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/688319\n(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)\n'}]",0,688840,3ee8cb69e1845a0f6739c51516b809b432f121f7,6,2,1,9414,,,0,"Configure s3_secret_access_key as secret

Parameter s3_secret_access_key should be configured as a secret.

Change-Id: I65ed470a1f585ed4704057a71511451c8db44f8c
Closes-Bug: #1847941
Depends-On: https://review.opendev.org/688319
(cherry picked from commit 05ee0bb4339b98ab67e4bedc192748905afe0aba)
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/40/688840/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb']",2,3ee8cb69e1845a0f6739c51516b809b432f121f7,bug/1847941-stable/stein, is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz').with_secret(true), is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz'),2,2
openstack%2Fopenstack-zuul-jobs~master~I254a7e6ee6b7c835eb22efbd83f4ec3735fc6eeb,openstack/openstack-zuul-jobs,master,I254a7e6ee6b7c835eb22efbd83f4ec3735fc6eeb,Stop running legacy puppet4 centos-7 jobs,MERGED,2019-10-14 20:56:11.000000000,2019-10-16 06:36:51.000000000,2019-10-16 06:34:40.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:56:11.000000000', 'files': ['zuul.d/zuul-legacy-project-templates.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/aba5a1adc07fd7d2ddded078ed3ca6c41e4791d3', 'message': ""Stop running legacy puppet4 centos-7 jobs\n\nInfra doesn't have any centos-7 nodes anymore.\n\nChange-Id: I254a7e6ee6b7c835eb22efbd83f4ec3735fc6eeb\n""}]",0,688567,aba5a1adc07fd7d2ddded078ed3ca6c41e4791d3,14,3,1,2,,,0,"Stop running legacy puppet4 centos-7 jobs

Infra doesn't have any centos-7 nodes anymore.

Change-Id: I254a7e6ee6b7c835eb22efbd83f4ec3735fc6eeb
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/67/688567/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/zuul-legacy-project-templates.yaml'],1,aba5a1adc07fd7d2ddded078ed3ca6c41e4791d3,infra-centos-7,, - legacy-puppet-syntax-4-centos-7 - legacy-puppet-syntax-4-centos-7,0,2
openstack%2Fkolla-ansible~master~Iff372025566f37f1c1ce093f39c93e083dec1c8f,openstack/kolla-ansible,master,Iff372025566f37f1c1ce093f39c93e083dec1c8f,Zun: disable image validation,ABANDONED,2019-10-03 01:49:20.000000000,2019-10-16 06:32:48.000000000,,"[{'_account_id': 11536}, {'_account_id': 22348}, {'_account_id': 30356}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-03 01:49:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6969a18f0dee9be0f8de1da67dd8712d684b597f', 'message': ""Zun: disable image validation\n\nThere are several reports [1][2] that image validation doesn't\nwork well. Let's disable it in Kolla.\n\n[1] https://bugs.launchpad.net/zun/+bug/1840629\n[2] https://bugs.launchpad.net/zun/+bug/1845650\n\nChange-Id: Iff372025566f37f1c1ce093f39c93e083dec1c8f\n""}, {'number': 2, 'created': '2019-10-05 02:18:34.000000000', 'files': ['ansible/roles/zun/templates/zun.conf.j2'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/7bef845ed9db57a5ec621b0be6a3f4f769052a70', 'message': ""Zun: disable image validation\n\nThere are several reports [1][2] that image validation doesn't\nwork well. Let's disable it in Kolla.\n\n[1] https://bugs.launchpad.net/zun/+bug/1840629\n[2] https://bugs.launchpad.net/zun/+bug/1845650\n\nChange-Id: Iff372025566f37f1c1ce093f39c93e083dec1c8f\n""}]",7,686320,7bef845ed9db57a5ec621b0be6a3f4f769052a70,15,4,2,11536,,,0,"Zun: disable image validation

There are several reports [1][2] that image validation doesn't
work well. Let's disable it in Kolla.

[1] https://bugs.launchpad.net/zun/+bug/1840629
[2] https://bugs.launchpad.net/zun/+bug/1845650

Change-Id: Iff372025566f37f1c1ce093f39c93e083dec1c8f
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/20/686320/2 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/zun/templates/zun.conf.j2', 'ansible/roles/zun/defaults/main.yml']",2,6969a18f0dee9be0f8de1da67dd8712d684b597f,, #################### # Zun #################### zun_enable_image_validation: false,,6,0
openstack%2Fhorizon~master~If7007e9d5b912b48d6bf3e4fac5decc53cd8388b,openstack/horizon,master,If7007e9d5b912b48d6bf3e4fac5decc53cd8388b,Assume features from N-4 release instead of N-3,MERGED,2019-10-15 06:19:59.000000000,2019-10-16 06:21:45.000000000,2019-10-16 06:20:08.000000000,"[{'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-10-15 06:19:59.000000000', 'files': ['doc/source/contributor/policy.rst'], 'web_link': 'https://opendev.org/openstack/horizon/commit/882b5f0582d68c5526690e9bbaacd212dee7aab5', 'message': 'Assume features from N-4 release instead of N-3\n\nCurretnly, features from N-3 release are assumed as a baseline\nin the horizon development policy document.\nLTS of Ubuntu Cloud Archive supports upgrade from N-4 to N.\nIf we assume a case where horizon is upgraded first, N release of\nhorizon needs to be able to run with N-4 release of back-end services.\nThe difference of N-3 and N-4 would be small, so it sounds reasonable\nto assume features from N-4 release.\n\nN-4 is chosen considering LTS support in the major OpenStack distributions:\n* Red Hat OpenStack Platform (RHOSP): X -> X+3\n  https://access.redhat.com/support/policy/updates/openstack/platform/\n* SuSE OpenStack Cloud (SOC): X -> X+2\n  https://www.suse.com/releasenotes/x86_64/SUSE-OPENSTACK-CLOUD/8/#Upgrade\n* Ubuntu Cloud Archive: X -> X+4\n  https://www.ubuntu.com/about/release-cycle\n\nChange-Id: If7007e9d5b912b48d6bf3e4fac5decc53cd8388b\n'}]",0,688628,882b5f0582d68c5526690e9bbaacd212dee7aab5,8,3,1,841,,,0,"Assume features from N-4 release instead of N-3

Curretnly, features from N-3 release are assumed as a baseline
in the horizon development policy document.
LTS of Ubuntu Cloud Archive supports upgrade from N-4 to N.
If we assume a case where horizon is upgraded first, N release of
horizon needs to be able to run with N-4 release of back-end services.
The difference of N-3 and N-4 would be small, so it sounds reasonable
to assume features from N-4 release.

N-4 is chosen considering LTS support in the major OpenStack distributions:
* Red Hat OpenStack Platform (RHOSP): X -> X+3
  https://access.redhat.com/support/policy/updates/openstack/platform/
* SuSE OpenStack Cloud (SOC): X -> X+2
  https://www.suse.com/releasenotes/x86_64/SUSE-OPENSTACK-CLOUD/8/#Upgrade
* Ubuntu Cloud Archive: X -> X+4
  https://www.ubuntu.com/about/release-cycle

Change-Id: If7007e9d5b912b48d6bf3e4fac5decc53cd8388b
",git fetch https://review.opendev.org/openstack/horizon refs/changes/28/688628/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/contributor/policy.rst'],1,882b5f0582d68c5526690e9bbaacd212dee7aab5,doc-policy,"* Related to the previous item, features available in ``N-4`` releases","* Related to the previous item, features available in ``N-3`` releases",1,1
openstack%2Fpuppet-tripleo~stable%2Fstein~I30f03bc8eb81db0243c137d4af08924adeebc951,openstack/puppet-tripleo,stable/stein,I30f03bc8eb81db0243c137d4af08924adeebc951,Deep merge hiera keys for mysqld_options,MERGED,2019-10-15 06:55:35.000000000,2019-10-16 06:13:13.000000000,2019-10-15 14:45:08.000000000,"[{'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 06:55:35.000000000', 'files': ['manifests/profile/pacemaker/database/mysql_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/d12fe87318264c9423e6bc0ac509fa2978261f1c', 'message': ""Deep merge hiera keys for mysqld_options\n\nCurrently when adding some tuning options via hiera, galera won't start because\noverriding even a single mysql option will reset the whole key in the hash. So\nfor example, when adding:\n    tripleo::profile::base::database::mysql::mysql_server_options:\n      mysqld:\n        # MySQL InnoDB equally divided in 1GB instances\n        innodb_buffer_pool_instances: 2\n        # Query network write timeout raised to 120 seconds\n        net_write_timeout: 120\n        # Query network read timeout raised to 120 seconds\n        net_read_timeout: 120\n        # MySQL connection timeout set to 8 hours\n        connect_timeout: 28800\n\nThings will break because all the wsrep options that are set normally will be\noverridden and galera will refuse to start\n\nTested by passing the above hiera keys and observing the deploy complete\nsuccessfully and the settings correctly applied to galera/mysql on the overcloud.\n\nChange-Id: I30f03bc8eb81db0243c137d4af08924adeebc951\nCloses-Bug: #1848060\n(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)\n""}]",0,688634,d12fe87318264c9423e6bc0ac509fa2978261f1c,9,4,1,20172,,,0,"Deep merge hiera keys for mysqld_options

Currently when adding some tuning options via hiera, galera won't start because
overriding even a single mysql option will reset the whole key in the hash. So
for example, when adding:
    tripleo::profile::base::database::mysql::mysql_server_options:
      mysqld:
        # MySQL InnoDB equally divided in 1GB instances
        innodb_buffer_pool_instances: 2
        # Query network write timeout raised to 120 seconds
        net_write_timeout: 120
        # Query network read timeout raised to 120 seconds
        net_read_timeout: 120
        # MySQL connection timeout set to 8 hours
        connect_timeout: 28800

Things will break because all the wsrep options that are set normally will be
overridden and galera will refuse to start

Tested by passing the above hiera keys and observing the deploy complete
successfully and the settings correctly applied to galera/mysql on the overcloud.

Change-Id: I30f03bc8eb81db0243c137d4af08924adeebc951
Closes-Bug: #1848060
(cherry picked from commit 7e78ebdc0f3678afddea3bdab2007c7b6ac92776)
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/34/688634/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/pacemaker/database/mysql_bundle.pp'],1,d12fe87318264c9423e6bc0ac509fa2978261f1c,fix-stable/stein," $mysqld_options = deep_merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)"," $mysqld_options = merge($mysqld_options_mysqld, $mysqld_options_sst, $mysql_server_options)",1,1
openstack%2Fvitrage~master~I4e782cb6f24f55aa0f93de91a202131918e10bf4,openstack/vitrage,master,I4e782cb6f24f55aa0f93de91a202131918e10bf4,Fix index in counter,MERGED,2019-09-01 13:26:41.000000000,2019-10-16 06:10:43.000000000,2019-09-03 06:33:26.000000000,"[{'_account_id': 1736}, {'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-01 13:26:41.000000000', 'files': ['vitrage/entity_graph/graph_init.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/6ff29e73356388ee04dd17dad4ba769c3ce03f97', 'message': 'Fix index in counter\n\nshould start from 1 so when logging\nit will show the correct number\n\nChange-Id: I4e782cb6f24f55aa0f93de91a202131918e10bf4\n'}]",0,679567,6ff29e73356388ee04dd17dad4ba769c3ce03f97,20,4,1,19134,,,0,"Fix index in counter

should start from 1 so when logging
it will show the correct number

Change-Id: I4e782cb6f24f55aa0f93de91a202131918e10bf4
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/67/679567/1 && git format-patch -1 --stdout FETCH_HEAD,['vitrage/entity_graph/graph_init.py'],1,6ff29e73356388ee04dd17dad4ba769c3ce03f97,eyalb/logging," for index, e in enumerate(events, 1):"," for index, e in enumerate(events):",1,1
openstack%2Fpuppet-tripleo~master~I2af70755746f3fc3eb10eba2188ad2772704d988,openstack/puppet-tripleo,master,I2af70755746f3fc3eb10eba2188ad2772704d988,"Revert ""Add support to configure token caching in keystone""",MERGED,2019-10-15 17:51:56.000000000,2019-10-16 05:43:11.000000000,2019-10-16 05:42:02.000000000,"[{'_account_id': 3153}, {'_account_id': 5046}, {'_account_id': 6926}, {'_account_id': 9592}, {'_account_id': 9816}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 20172}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 17:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/c29a476b831f5053d60bc9d2ab570f61a5436f08', 'message': 'Revert ""Add support to configure token caching in keystone""\n\nChanging cache/enabled=False by default has dropped performance. keystone local cache also got disabled with\nthis.\n\nDepends-On: https://review.opendev.org/#/c/688770/\nCloses-Bug: #1847585\nThis reverts commit 469d432195d1f5b5e15ce72ce1624d4ed4447e4e.\n\nChange-Id: I2af70755746f3fc3eb10eba2188ad2772704d988\n'}, {'number': 2, 'created': '2019-10-15 17:53:45.000000000', 'files': ['releasenotes/notes/keystone-token-caching-9b65cb169fe65f01.yaml', 'manifests/profile/base/keystone.pp', 'spec/classes/tripleo_profile_base_keystone_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/63dd90aacc84545d9f171ee163b7e97452d0a537', 'message': 'Revert ""Add support to configure token caching in keystone""\n\nChanging cache/enabled=False by default has dropped performance.\nkeystone local cache also got disabled with this.\n\nThis reverts commit 469d432195d1f5b5e15ce72ce1624d4ed4447e4e.\n\n\nDepends-On: https://review.opendev.org/#/c/688770/\nCloses-Bug: #1847585\nChange-Id: I2af70755746f3fc3eb10eba2188ad2772704d988\n'}]",2,688771,63dd90aacc84545d9f171ee163b7e97452d0a537,14,11,2,13861,,,0,"Revert ""Add support to configure token caching in keystone""

Changing cache/enabled=False by default has dropped performance.
keystone local cache also got disabled with this.

This reverts commit 469d432195d1f5b5e15ce72ce1624d4ed4447e4e.


Depends-On: https://review.opendev.org/#/c/688770/
Closes-Bug: #1847585
Change-Id: I2af70755746f3fc3eb10eba2188ad2772704d988
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/71/688771/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/keystone-token-caching-9b65cb169fe65f01.yaml', 'manifests/profile/base/keystone.pp', 'spec/classes/tripleo_profile_base_keystone_spec.rb']",3,c29a476b831f5053d60bc9d2ab570f61a5436f08,token-cache, :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0' :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0' :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0'," :memcached_ips => [ '192.168.0.3', '192.168.0.4', '192.168.0.5' ] :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0', :cache_enabled => false, :cache_memcache_servers => [ '192.168.0.3:11211', '192.168.0.4:11211', '192.168.0.5:11211' ], :cache_backend => 'oslo_cache.memcache_pool', :token_caching => false :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0', :cache_enabled => false, :cache_memcache_servers => [ '192.168.0.3:11211', '192.168.0.4:11211', '192.168.0.5:11211' ], :cache_backend => 'oslo_cache.memcache_pool', :token_caching => false :notification_transport_url => 'rabbit://keystone2:baa@192.168.0.2:5678/?ssl=0', :cache_enabled => false, :cache_memcache_servers => [ '192.168.0.3:11211', '192.168.0.4:11211', '192.168.0.5:11211' ], :cache_backend => 'oslo_cache.memcache_pool', :token_caching => false context 'with step 4 and token_caching eabled' do before do params.merge!( { :step => 4, :bootstrap_node => 'other.example.com', :enable_token_caching => true } ) end it 'should trigger token_caching configuration' do is_expected.to contain_class('keystone').with( :cache_enabled => true, :token_caching => true ) end end ",7,56
openstack%2Fpuppet-glance~stable%2Ftrain~I02039d0ef308638f074ede5c0ef3bfc315eb0f7b,openstack/puppet-glance,stable/train,I02039d0ef308638f074ede5c0ef3bfc315eb0f7b,Switch to Train,MERGED,2019-10-09 23:03:50.000000000,2019-10-16 05:16:20.000000000,2019-10-16 05:16:20.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-09 23:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/0c83e6ce8f4257e37cefa5b13f5a79591a54b43f', 'message': 'Switch to Train\n\nChange-Id: I02039d0ef308638f074ede5c0ef3bfc315eb0f7b\n'}, {'number': 2, 'created': '2019-10-11 14:24:33.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9439d5662282099a859bacfcd16e42f99e0add2f', 'message': 'Switch to Train\n\nChange-Id: I02039d0ef308638f074ede5c0ef3bfc315eb0f7b\n'}]",0,687705,9439d5662282099a859bacfcd16e42f99e0add2f,21,4,2,16137,,,0,"Switch to Train

Change-Id: I02039d0ef308638f074ede5c0ef3bfc315eb0f7b
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/05/687705/2 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,0c83e6ce8f4257e37cefa5b13f5a79591a54b43f,," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper', :branch => 'stable/train',"," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper',",2,1
openstack%2Ftripleo-heat-templates~master~I24a387c50fd2357ef226b3678c3c02ee1e4c691b,openstack/tripleo-heat-templates,master,I24a387c50fd2357ef226b3678c3c02ee1e4c691b,"Revert ""Add support to configure token caching""",MERGED,2019-10-15 17:49:26.000000000,2019-10-16 05:01:08.000000000,2019-10-16 04:59:53.000000000,"[{'_account_id': 3153}, {'_account_id': 9592}, {'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 17:49:26.000000000', 'files': ['releasenotes/notes/keystone_token_caching-ce02411398a40420.yaml', 'deployment/keystone/keystone-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/79ec11227700b10f60fcbfa42bf984169fff0085', 'message': 'Revert ""Add support to configure token caching""\n\nChanging cache/enabled=False by default has dropped\nperformance.\n\nRelated-Bug: #1847585\nThis reverts commit db35747962ff8d00ac903cd1e153f5b25a78e33a.\n\nChange-Id: I24a387c50fd2357ef226b3678c3c02ee1e4c691b\n'}]",0,688770,79ec11227700b10f60fcbfa42bf984169fff0085,11,7,1,13861,,,0,"Revert ""Add support to configure token caching""

Changing cache/enabled=False by default has dropped
performance.

Related-Bug: #1847585
This reverts commit db35747962ff8d00ac903cd1e153f5b25a78e33a.

Change-Id: I24a387c50fd2357ef226b3678c3c02ee1e4c691b
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/70/688770/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/keystone_token_caching-ce02411398a40420.yaml', 'deployment/keystone/keystone-container-puppet.yaml']",2,79ec11227700b10f60fcbfa42bf984169fff0085,token-cache,, KeystoneEnableTokenCaching: type: boolean default: false description: >- Enable token caching tripleo::profile::base::keystone::enable_token_caching: {get_param: KeystoneEnableTokenCaching},0,11
openstack%2Fproject-config~master~I5ac0f5ee7b8f18acfd9726e0fcec1c67bedde32d,openstack/project-config,master,I5ac0f5ee7b8f18acfd9726e0fcec1c67bedde32d,Remove references to OpenSUSE 423,MERGED,2019-10-14 16:20:44.000000000,2019-10-16 04:56:39.000000000,2019-10-16 04:56:38.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 16:20:44.000000000', 'files': ['nodepool/elements/bindep-fallback.txt', 'grafana/tempest.yaml', 'grafana/nodepool-dib.base.template', 'grafana/openstack-ansible.yaml', 'grafana/create-nodepool-dib.sh', 'grafana/nodepool-dib.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/d1a1fe920370f553d7551d325e2ff21a437767ac', 'message': 'Remove references to OpenSUSE 423\n\nThis nodeset is no longer in use, remove references to it.\n\nChange-Id: I5ac0f5ee7b8f18acfd9726e0fcec1c67bedde32d\n'}]",0,688443,d1a1fe920370f553d7551d325e2ff21a437767ac,8,3,1,1,,,0,"Remove references to OpenSUSE 423

This nodeset is no longer in use, remove references to it.

Change-Id: I5ac0f5ee7b8f18acfd9726e0fcec1c67bedde32d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/43/688443/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/elements/bindep-fallback.txt', 'grafana/tempest.yaml', 'grafana/nodepool-dib.base.template', 'grafana/openstack-ansible.yaml', 'grafana/create-nodepool-dib.sh', 'grafana/nodepool-dib.yaml']",6,d1a1fe920370f553d7551d325e2ff21a437767ac,opensuse-423,# NOTE: This file is autogenerated. Use ./create-nodepool-dib.sh to,"# NOTE: This file is autogenerated. Use ./create-dib.sh to# AUTOGENERATED : openSUSE 42.3 - title: openSUSE 42.3 showTitle: true height: 200px panels: - title: Build status colorBackground: true type: singlestat valueName: current valueMaps: - value: 0 text: ""OK"" - value: 1 text: ""FAILED"" thresholds: 0.1,0.9 span: 2 targets: - target: ""stats.gauges.nodepool.dib_image_build.opensuse-423.qcow2.rc"" valueFontSize: ""50%"" - title: Image size type: graph span: 3 yaxes: - format: decbytes min: 0 - format: decbytes min: 0 targets: - target: aliasByNode(stats.gauges.nodepool.dib_image_build.opensuse-423.*.size, 5) refId: A - title: Build duration type: graph span: 3 yaxes: - format: ms min: 0 - format: ms min: 0 targets: - target: alias(keepLastValue(stats.timers.nodepool.dib_image_build.opensuse-423.qcow2.duration.mean, 'None'), ""Time"") refId: A",3,62
openstack%2Ftripleo-heat-templates~master~I8f71bf83ddafca167deae1a38ca819f7d930fb80,openstack/tripleo-heat-templates,master,I8f71bf83ddafca167deae1a38ca819f7d930fb80,Workaround ovn cluster failure during update when schema change.,MERGED,2019-10-11 21:47:01.000000000,2019-10-16 04:43:03.000000000,2019-10-16 03:29:09.000000000,"[{'_account_id': 7144}, {'_account_id': 8297}, {'_account_id': 10237}, {'_account_id': 17823}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-10-11 21:47:01.000000000', 'files': ['deployment/ovn/ovn-dbs-pacemaker-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/751b3fc09632cf184bf947be8f74d771554a23d0', 'message': ""Workaround ovn cluster failure during update when schema change.\n\nDuring update the ovndb server can have a schema change. The problem\nis that an updated slave ovndb wouldn't connect to a master which\nstill has the old db schema.  At some point (200000ms) pacemaker put\nthe resource in error Time Out.  Then it will wait for the operator to\ncleanup the resource.  Meaning that the update can goes like this:\n\n - Original state: (Master, Slave, Failed): nothing updated\n   - ctl0-M-old\n   - ctl1-S-old\n   - ctl2-S-old\n - First state: after update of ctl0\n   - ctl0-F-new\n   - ctl1-M-old\n   - ctl2-S-old\n - Second state: after update of ctl1\n   - ctl0-F-new\n   - ctl1-F-new\n   - ctl2-M-old\n - Third and final state: after update of ctl2\n   - ctl0-F-new\n   - ctl1-F-new\n   - ctl2-M-new\n\nDuring the third state we have a cut in the control plane as ctl2 is\nthe master and there is no slave to fall back to. Then we end up\nloosing HA as only one node is active.  The error persists after\nreboot.  Only a pcs resource cleanup will bring the cluster online.\n\nThe real solution will come from ovndb and the associated ocf agent,\nbut in the meantime, we workaround it by:\n - cleanup\n - ban the resource;\nin step 1 and:\n - cleanup\n - unban the resource\nin step 5.\n\nThis has the net effect of preventing the cut in the control plane for\nthe last node as we move master to the updated controller which will\nform a cluster of one master and one slave (as two are updated).  The\nlast one will happily join then when it will be updated.\n\nThat means:\n - we always have either 1 or 2 nodes working;\n - we end the update with the cluster converged back to a stable\n state.\n\nThe problems are :\n - we could hide a real ovndb cluster issue;\n- if the update break in-between we could have a leftover ban on one\n of the node;\n\nBut, all things considered, this looks like the best compromise for\nthe time being.\n\nChange-Id: I8f71bf83ddafca167deae1a38ca819f7d930fb80\nCloses-Bug: #1847780\n""}]",5,688212,751b3fc09632cf184bf947be8f74d771554a23d0,20,8,1,8297,,,0,"Workaround ovn cluster failure during update when schema change.

During update the ovndb server can have a schema change. The problem
is that an updated slave ovndb wouldn't connect to a master which
still has the old db schema.  At some point (200000ms) pacemaker put
the resource in error Time Out.  Then it will wait for the operator to
cleanup the resource.  Meaning that the update can goes like this:

 - Original state: (Master, Slave, Failed): nothing updated
   - ctl0-M-old
   - ctl1-S-old
   - ctl2-S-old
 - First state: after update of ctl0
   - ctl0-F-new
   - ctl1-M-old
   - ctl2-S-old
 - Second state: after update of ctl1
   - ctl0-F-new
   - ctl1-F-new
   - ctl2-M-old
 - Third and final state: after update of ctl2
   - ctl0-F-new
   - ctl1-F-new
   - ctl2-M-new

During the third state we have a cut in the control plane as ctl2 is
the master and there is no slave to fall back to. Then we end up
loosing HA as only one node is active.  The error persists after
reboot.  Only a pcs resource cleanup will bring the cluster online.

The real solution will come from ovndb and the associated ocf agent,
but in the meantime, we workaround it by:
 - cleanup
 - ban the resource;
in step 1 and:
 - cleanup
 - unban the resource
in step 5.

This has the net effect of preventing the cut in the control plane for
the last node as we move master to the updated controller which will
form a cluster of one master and one slave (as two are updated).  The
last one will happily join then when it will be updated.

That means:
 - we always have either 1 or 2 nodes working;
 - we end the update with the cluster converged back to a stable
 state.

The problems are :
 - we could hide a real ovndb cluster issue;
- if the update break in-between we could have a leftover ban on one
 of the node;

But, all things considered, this looks like the best compromise for
the time being.

Change-Id: I8f71bf83ddafca167deae1a38ca819f7d930fb80
Closes-Bug: #1847780
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/688212/1 && git format-patch -1 --stdout FETCH_HEAD,['deployment/ovn/ovn-dbs-pacemaker-puppet.yaml'],1,751b3fc09632cf184bf947be8f74d771554a23d0,bug/1847780," # When a schema change happens, the newer slaves don't connect # back to the older master and end up timing out. So we clean # up the error here until we get a fix for # https://bugzilla.redhat.com/show_bug.cgi?id=1759974 - name: Clear ovndb cluster pacemaker error shell: ""pcs resource cleanup ovn-dbs-bundle"" when: - step|int == 1 # Then we ban the resource for this node. It has no effect on # the first two controllers, but when we reach the last one, # it avoids a cut in the control plane as master get chosen in # one of the updated Stopped ovn. They are in error, that why # we need the cleanup just before. - name: Ban ovndb resource on the current node. shell: ""pcs resource ban ovn-dbs-bundle $(hostname | cut -d. -f1)"" when: - step|int == 1 # We remove any leftover error and remove the ban. - name: Ensure the cluster converge back even in case of schema change shell: ""pcs resource cleanup ovn-dbs-bundle"" when: - step|int == 5 - name: Remove the ban shell: ""pcs resource clear ovn-dbs-bundle"" when: - step|int == 5",,26,0
openstack%2Fswift~master~I37f78d5993082ac29b001e9563aa4b24fd009a27,openstack/swift,master,I37f78d5993082ac29b001e9563aa4b24fd009a27,swift-account-audit: clean up some error formatting,MERGED,2019-10-14 18:21:26.000000000,2019-10-16 04:05:36.000000000,2019-10-16 04:03:02.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 18:21:26.000000000', 'files': ['bin/swift-account-audit'], 'web_link': 'https://opendev.org/openstack/swift/commit/3e90ddb37d1d13977b69ae01117f50bab3495266', 'message': 'swift-account-audit: clean up some error formatting\n\n""127.0.0.1s:sdas"" is confusing at best.\n\nChange-Id: I37f78d5993082ac29b001e9563aa4b24fd009a27\n'}]",0,688529,3e90ddb37d1d13977b69ae01117f50bab3495266,19,3,1,15343,,,0,"swift-account-audit: clean up some error formatting

""127.0.0.1s:sdas"" is confusing at best.

Change-Id: I37f78d5993082ac29b001e9563aa4b24fd009a27
",git fetch https://review.opendev.org/openstack/swift refs/changes/29/688529/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-account-audit'],1,3e90ddb37d1d13977b69ae01117f50bab3495266,," "" from %s:%s"" % print("" Exception GETting account '%s' on %s:%s"" %"," "" from %ss:%ss"" % print("" Exception GETting account '%s' on %ss:%ss"" %",2,2
openstack%2Fswift~master~I7ae0d7e47ae44286564f8ab7126e8ff131bc0de6,openstack/swift,master,I7ae0d7e47ae44286564f8ab7126e8ff131bc0de6,py38: Provide readinto() interface for RingReader,MERGED,2019-10-15 01:00:18.000000000,2019-10-16 04:04:33.000000000,2019-10-16 04:03:00.000000000,"[{'_account_id': 597}, {'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 01:00:18.000000000', 'files': ['swift/common/ring/ring.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/8efaa3556fdb21f741ff897dac4730c3c3654421', 'message': ""py38: Provide readinto() interface for RingReader\n\nOtherwise pickle complains\n\n   TypeError: file must have 'read', 'readinto' and 'readline' attributes\n\nChange-Id: I7ae0d7e47ae44286564f8ab7126e8ff131bc0de6\n""}]",1,688591,8efaa3556fdb21f741ff897dac4730c3c3654421,19,4,1,15343,,,0,"py38: Provide readinto() interface for RingReader

Otherwise pickle complains

   TypeError: file must have 'read', 'readinto' and 'readline' attributes

Change-Id: I7ae0d7e47ae44286564f8ab7126e8ff131bc0de6
",git fetch https://review.opendev.org/openstack/swift refs/changes/91/688591/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/ring/ring.py'],1,8efaa3556fdb21f741ff897dac4730c3c3654421,," def readinto(self, buffer): chunk = self.read(len(buffer)) buffer[:len(chunk)] = chunk return len(chunk) ",,5,0
openstack%2Frequirements~master~Ib66385229b097f50a1582706649a1e26e9141a52,openstack/requirements,master,Ib66385229b097f50a1582706649a1e26e9141a52,Updated from generate-constraints,MERGED,2019-10-15 06:17:27.000000000,2019-10-16 04:04:19.000000000,2019-10-16 04:02:59.000000000,"[{'_account_id': 10239}, {'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 06:17:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/requirements/commit/73d3c1418787990fb203bd166070f3cbdfd866c8', 'message': 'Updated from generate-constraints\n\nChange-Id: Ib66385229b097f50a1582706649a1e26e9141a52\n'}, {'number': 2, 'created': '2019-10-15 15:27:11.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/3ce56912ffa4b3c6a1a89a903e2d60c162e6ab31', 'message': 'Updated from generate-constraints\n\nChange-Id: Ib66385229b097f50a1582706649a1e26e9141a52\n'}]",0,688624,3ce56912ffa4b3c6a1a89a903e2d60c162e6ab31,15,3,2,11131,,,0,"Updated from generate-constraints

Change-Id: Ib66385229b097f50a1582706649a1e26e9141a52
",git fetch https://review.opendev.org/openstack/requirements refs/changes/24/688624/2 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,73d3c1418787990fb203bd166070f3cbdfd866c8,openstack/requirements/constraints/noclob,enum-compat===0.0.3;python_version=='2.7'attrs===19.3.0pyroute2===0.5.7amqp===2.5.2boto3===1.9.249Faker===2.0.3salt===2019.2.1botocore===1.12.249Paste===3.2.2diskimage-builder===2.28.2,enum-compat===0.0.2;python_version=='2.7'attrs===19.2.0pyroute2===0.5.6amqp===2.5.1boto3===1.9.248Faker===2.0.2salt===2019.2.0botocore===1.12.248Paste===3.2.1diskimage-builder===2.28.1,10,10
openstack%2Fpython-freezerclient~master~I05fd9111663512ef2169036c637c330df1c5f740,openstack/python-freezerclient,master,I05fd9111663512ef2169036c637c330df1c5f740,result is different from comments,MERGED,2019-10-11 03:56:37.000000000,2019-10-16 03:36:55.000000000,2019-10-16 03:35:52.000000000,"[{'_account_id': 21069}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 03:56:37.000000000', 'files': ['freezerclient/v2/managers/jobs.py', 'freezerclient/v1/managers/jobs.py'], 'web_link': 'https://opendev.org/openstack/python-freezerclient/commit/de0f67c6f5de97ad9321f2ee31aa710ffbe34d84', 'message': 'result is different from comments\n\nChange-Id: I05fd9111663512ef2169036c637c330df1c5f740\n'}]",0,688030,de0f67c6f5de97ad9321f2ee31aa710ffbe34d84,7,2,1,19098,,,0,"result is different from comments

Change-Id: I05fd9111663512ef2169036c637c330df1c5f740
",git fetch https://review.opendev.org/openstack/python-freezerclient refs/changes/30/688030/1 && git format-patch -1 --stdout FETCH_HEAD,"['freezerclient/v2/managers/jobs.py', 'freezerclient/v1/managers/jobs.py']",2,de0f67c6f5de97ad9321f2ee31aa710ffbe34d84,, result: string 'success' or 'start already requested' result: string 'success' or 'stop already requested' result: string 'success' or 'abort already requested', result: string 'success' or 'already started' result: string 'success' or 'already stopped' result: string 'success' or 'already stopped',6,6
openstack%2Fopenstack-helm-images~master~I99aa8ab2aa66947ac0568432dbf9eb37ccc70215,openstack/openstack-helm-images,master,I99aa8ab2aa66947ac0568432dbf9eb37ccc70215,Build placement in OSH-images,MERGED,2019-07-25 09:55:56.000000000,2019-10-16 02:56:08.000000000,2019-09-24 11:47:55.000000000,"[{'_account_id': 12281}, {'_account_id': 14525}, {'_account_id': 17068}, {'_account_id': 17966}, {'_account_id': 20466}, {'_account_id': 21420}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 28208}, {'_account_id': 28570}]","[{'number': 1, 'created': '2019-07-25 09:55:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/8fd70548aba70ff413afef25fcf5689c084a09fd', 'message': 'Build placement in OSH-images\n\nThis will use LOCI to build placement. Without this patch, it\nwill be impossible to have separated placement chart.\n\nChange-Id: I99aa8ab2aa66947ac0568432dbf9eb37ccc70215\n'}, {'number': 2, 'created': '2019-08-20 02:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/7953e32de8e41437825def2a254a735f76049682', 'message': 'Build placement in OSH-images\n\nThis will use LOCI to build placement. Without this patch, it\nwill be impossible to have separated placement chart.\n\nChange-Id: I99aa8ab2aa66947ac0568432dbf9eb37ccc70215\n'}, {'number': 3, 'created': '2019-09-03 14:35:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/9dd9a7c0a460bd2d78eda80a96e7609aaa65f7c0', 'message': 'Build placement in OSH-images\n\nThis will use LOCI to build placement. Without this patch, it\nwill be impossible to have separated placement chart.\n\nChange-Id: I99aa8ab2aa66947ac0568432dbf9eb37ccc70215\n'}, {'number': 4, 'created': '2019-09-05 16:43:43.000000000', 'files': ['zuul.d/openstack-loci.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-images/commit/d0fded66ab7f8c583786d97cf134dbba68c4ec2c', 'message': 'Build placement in OSH-images\n\nThis will use LOCI to build placement. Without this patch, it\nwill be impossible to have separated placement chart.\n\nChange-Id: I99aa8ab2aa66947ac0568432dbf9eb37ccc70215\n'}]",0,672678,d0fded66ab7f8c583786d97cf134dbba68c4ec2c,77,10,4,17068,,,0,"Build placement in OSH-images

This will use LOCI to build placement. Without this patch, it
will be impossible to have separated placement chart.

Change-Id: I99aa8ab2aa66947ac0568432dbf9eb37ccc70215
",git fetch https://review.opendev.org/openstack/openstack-helm-images refs/changes/78/672678/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/openstack-loci.yaml'],1,8fd70548aba70ff413afef25fcf5689c084a09fd,add-placement," - &placement_project context: ""."" repository: openstackhelm/placement build_args: - ""FROM='{{ from }}'"" - ""PYTHON3={{ python3 }}"" - ""PROJECT='placement'"" - ""PROJECT_REF={{ branchname }}"" - ""PROFILES='apache'"" - ""PIP_PACKAGES='httplib2 pycrypto'"" - ""WHEELS='{{ wheels_location }}'"" tags: *imagetag - <<: *placement_project",,14,0
openstack%2Fironic~master~I416019fc1ed3ab2a3a3dbc4443571123ef90e327,openstack/ironic,master,I416019fc1ed3ab2a3a3dbc4443571123ef90e327,Add Redfish vmedia boot interface to idrac HW type,MERGED,2019-07-24 10:51:01.000000000,2019-10-16 02:55:53.000000000,2019-10-14 12:57:53.000000000,"[{'_account_id': 7160}, {'_account_id': 10118}, {'_account_id': 10239}, {'_account_id': 10250}, {'_account_id': 10379}, {'_account_id': 11076}, {'_account_id': 11655}, {'_account_id': 14629}, {'_account_id': 19339}, {'_account_id': 22348}, {'_account_id': 23847}, {'_account_id': 26340}, {'_account_id': 28128}, {'_account_id': 28533}, {'_account_id': 31089}]","[{'number': 1, 'created': '2019-07-24 10:51:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c3217f345667145d60fe43c6a4612ec36cf4d31e', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 2, 'created': '2019-07-24 18:14:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/5070bdecd74e5e880884a1c73aa440894617d4f4', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 3, 'created': '2019-07-24 18:19:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3decf29161c9996cacd8ec1146fbe6dd54ced938', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 4, 'created': '2019-07-26 13:51:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/49e313303a377a33f290a86d8e8fe222f77517fe', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 5, 'created': '2019-07-30 14:24:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c0f3112fc22716ff26749456286b12d7168083ef', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 6, 'created': '2019-07-30 14:55:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/3975739fe01dbf523cda491def0f418e8070a5dc', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 7, 'created': '2019-08-09 14:40:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/b516a89dddd1a695214261187e1d110b9e67261a', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 8, 'created': '2019-08-12 19:38:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/124ceb696b458812adc8914fa5f195671c7100bb', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 9, 'created': '2019-08-14 11:35:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/73a330f4e062ee1dbbe4b0a7ce97ec827a40a347', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 10, 'created': '2019-08-14 12:21:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/02aaf93988f7d2bbb8be2ad1a9a9cc31612dcad4', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nThis patch is not functional yet because of the missing dependencies:\n\n1. Dell OEM extension needs to be implemented as a discoverable Python\n   entry point\n2. Redfish TaskService needs to be implemented in sushy library\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 11, 'created': '2019-08-16 16:35:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/ce1a3c87b2038177d958c0205ba20fce170ae35b', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 12, 'created': '2019-09-10 14:47:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/8749dd57ff7cdb137baaed3caf1fb8d7b0af209d', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 13, 'created': '2019-09-13 11:42:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/6b70f087f7d7211bcb83ac6cb76e67e303392090', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 14, 'created': '2019-09-16 09:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/a618b39e96a9bb02b445000a7c78f7c9b4f54c1d', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 15, 'created': '2019-09-17 17:33:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/89fda0f3071303a48af956f93a8ad3d9dd45609c', 'message': ""[WIP] Add iDRAC boot interface\n\nImplements Redfish boot interface for `drac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `drac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 16, 'created': '2019-09-18 12:26:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/1e5bf7f5abb1426fdf8f18fa6c69f815b02ca6b8', 'message': ""Add boot interface to ``idrac`` hw type\n\nImplements Redfish boot interface for `idrac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `idrac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\nStory: 2006570\nTask: 36675\n""}, {'number': 17, 'created': '2019-09-18 12:53:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/d5544799e8350af7d774fbd17cd8575632f0a647', 'message': ""Add boot interface to ``idrac`` hw type\n\nImplements Redfish boot interface for `idrac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `idrac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\nStory: 2006570\nTask: 36675\n""}, {'number': 18, 'created': '2019-09-18 12:59:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/06bc0be19553d0c23392b7554ada968079c6a1e8', 'message': ""Add boot interface to ``idrac`` hw type\n\nImplements Redfish boot interface for `idrac` hardware type.\n\nDell iDRAC BMC largely supports Redfish, but not entirely. One of\nthe missing bits is iDRAC's ability to set node to boot from\nvirtual media via standard Redfish means. That needs to be done via\nan OEM extension.\n\nTo circumvent the above problem, `idrac` hardware type implements\nironic boot interface by inheriting from standard `redfish` boot\ninterface replacing boot device set operation to run the OEM\nworkflow.\n\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\nStory: 2006570\nTask: 36675\n""}, {'number': 19, 'created': '2019-09-23 05:41:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/19e8ce90fd56a692ab8c011558f997447ca2bf4a', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\nOEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 20, 'created': '2019-09-23 06:04:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/4da7cc8efc268b343840498427394180fe93e5fe', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\nOEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 21, 'created': '2019-09-24 03:15:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/bd440a8f27c1b2cbf672ae2df307e7cec65d1c3e', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\naforementioned iDRAC Redfish Service OEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nA new idrac hardware type Python package dependency is introduced. It is\non 'sushy-oem-idrac'.\n\n[1] https://pypi.org/project/sushy-oem-idrac/\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 22, 'created': '2019-10-07 22:37:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/c51d6247842c0456478875386d5d7706b299f2bd', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\naforementioned iDRAC Redfish Service OEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nA new idrac hardware type Python package dependency is introduced. It is\non 'sushy-oem-idrac'.\n\n[1] https://pypi.org/project/sushy-oem-idrac/\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 23, 'created': '2019-10-08 05:01:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ironic/commit/edad9363cfc9c2109180a8ae528ab39c3897c15a', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\naforementioned iDRAC Redfish Service OEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nA new idrac hardware type Python package dependency is introduced. It is\non 'sushy-oem-idrac'.\n\n[1] https://pypi.org/project/sushy-oem-idrac/\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}, {'number': 24, 'created': '2019-10-12 00:01:56.000000000', 'files': ['ironic/tests/unit/drivers/modules/drac/utils.py', 'ironic/drivers/modules/drac/boot.py', 'releasenotes/notes/idrac-add-redfish-boot-support-036396b48d3f71f4.yaml', 'ironic/tests/unit/drivers/modules/drac/test_boot.py', 'ironic/drivers/drac.py', 'ironic/tests/unit/drivers/third_party_driver_mocks.py', 'driver-requirements.txt', 'ironic/tests/unit/drivers/test_drac.py', 'setup.cfg'], 'web_link': 'https://opendev.org/openstack/ironic/commit/0ad6f8758747cf0d0796c89e0e8f8bdbf6f0421d', 'message': ""Add Redfish vmedia boot interface to idrac HW type\n\nThis change adds idrac hardware type support of a virtual media boot\ninterface implementation that utilizes the Redfish out-of-band (OOB)\nmanagement protocol and is compatible with the integrated Dell Remote\nAccess Controller (iDRAC) baseboard management controller (BMC). It is\nnamed 'idrac-redfish-virtual-media'.\n\nThe iDRAC Redfish Service almost entirely interoperates with the virtual\nmedia boot workflow suggested by the Redfish standard. The only\ndifference is configuring the system to boot from the inserted virtual\nmedia. The standard workflow expects it to be referred to as a CD-ROM or\nfloppy disk drive boot source, no different from their physical\ncounterparts. However, the iDRAC refers to them as virtual boot sources,\ndistinct from their physical counterparts. Presently, the standard does\nnot define virtual CD-ROM nor virtual floppy disk drive boot sources.\nHowever, the iDRAC provides a Redfish OEM extension for setting the\nsystem to boot from one of those virtual boot sources.\n\nTo circumvent the above issue, the Python class which implements\n'idrac-redfish-virtual-media' is derived from the class which implements\nthe generic, vendor-independent 'redfish-virtual-media' interface. It\noverrides the method which sets the boot device to facilitate use of the\naforementioned iDRAC Redfish Service OEM extension.\n\nThe idrac hardware type declares support for that new interface\nimplementation, in addition to all boot interface implementations it has\nbeen supporting. The priority order is retained by assigning the new\n'idrac-redfish-virtual-media' the lowest priority.\n\nA new idrac hardware type Python package dependency is introduced. It is\non 'sushy-oem-idrac'.\n\n[1] https://pypi.org/project/sushy-oem-idrac/\n\nCo-Authored-By: Richard G. Pioso <richard.pioso@dell.com>\nStory: 2006570\nTask: 36675\nChange-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327\n""}]",94,672498,0ad6f8758747cf0d0796c89e0e8f8bdbf6f0421d,134,15,24,26340,,,0,"Add Redfish vmedia boot interface to idrac HW type

This change adds idrac hardware type support of a virtual media boot
interface implementation that utilizes the Redfish out-of-band (OOB)
management protocol and is compatible with the integrated Dell Remote
Access Controller (iDRAC) baseboard management controller (BMC). It is
named 'idrac-redfish-virtual-media'.

The iDRAC Redfish Service almost entirely interoperates with the virtual
media boot workflow suggested by the Redfish standard. The only
difference is configuring the system to boot from the inserted virtual
media. The standard workflow expects it to be referred to as a CD-ROM or
floppy disk drive boot source, no different from their physical
counterparts. However, the iDRAC refers to them as virtual boot sources,
distinct from their physical counterparts. Presently, the standard does
not define virtual CD-ROM nor virtual floppy disk drive boot sources.
However, the iDRAC provides a Redfish OEM extension for setting the
system to boot from one of those virtual boot sources.

To circumvent the above issue, the Python class which implements
'idrac-redfish-virtual-media' is derived from the class which implements
the generic, vendor-independent 'redfish-virtual-media' interface. It
overrides the method which sets the boot device to facilitate use of the
aforementioned iDRAC Redfish Service OEM extension.

The idrac hardware type declares support for that new interface
implementation, in addition to all boot interface implementations it has
been supporting. The priority order is retained by assigning the new
'idrac-redfish-virtual-media' the lowest priority.

A new idrac hardware type Python package dependency is introduced. It is
on 'sushy-oem-idrac'.

[1] https://pypi.org/project/sushy-oem-idrac/

Co-Authored-By: Richard G. Pioso <richard.pioso@dell.com>
Story: 2006570
Task: 36675
Change-Id: I416019fc1ed3ab2a3a3dbc4443571123ef90e327
",git fetch https://review.opendev.org/openstack/ironic refs/changes/98/672498/9 && git format-patch -1 --stdout FETCH_HEAD,['ironic/drivers/modules/drac/boot.py'],1,c3217f345667145d60fe43c6a4612ec36cf4d31e,02-add-drac-boot-interface,"# Copyright 2019 Red Hat, Inc. # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import eventlet from oslo_log import log from oslo_utils import importutils from ironic.common import exception from ironic.common.i18n import _ from ironic.drivers.modules.redfish import boot as redfish_boot from ironic.drivers.modules.redfish import utils as redfish_utils LOG = log.getLogger(__name__) sushy = importutils.try_import('sushy') class DracVirtualMediaBoot(redfish_boot.RedfishVirtualMediaBoot): """"""iDRAC virtual media boot interface over Redfish. Virtual Media allows booting the system from ""virtual"" CD/DVD drive containing user image that BMC ""inserts"" into the drive. The CD/DVD images must be in ISO format and (depending on BMC implementation) could be pulled over HTTP, served as iSCSI targets or NFS volumes. The baseline boot workflow looks like this: 1. Pull kernel, ramdisk and ESP if UEFI boot is requested (FAT partition image with EFI boot loader) images 2. Create bootable ISO out of images (#1), push it to Glance and pass to the BMC as Swift temporary URL 3. Optionally create floppy image with desired system configuration data, push it to Glance and pass to the BMC as Swift temporary URL 4. Insert CD/DVD and (optionally) floppy images and set proper boot mode For building deploy or rescue ISO, redfish boot interface uses `deploy_kernel`/`deploy_ramdisk` or `rescue_kernel`/`rescue_ramdisk` properties from `[instance_info]` or `[driver_info]`. For building boot (user) ISO, redfish boot interface seeks `kernel_id` and `ramdisk_id` properties in the Glance image metadata found in `[instance_info]image_source` node property. """""" capabilities = ['iscsi_volume_boot', 'ramdisk_boot'] MAGIC_CD_SAUCE = """"""\ <SystemConfiguration>\ <Component FQDD=""iDRAC.Embedded.1"">\ <Attribute Name=""ServerBoot.1#BootOnce"">\ Enabled\ </Attribute>\ <Attribute Name=""ServerBoot.1#FirstBootDevice"">\ VCD-DVD\ </Attribute>\ </Component>\ </SystemConfiguration>\ """""" MAGIC_FLOPPY_SAUCE = """"""\ <SystemConfiguration>\ <Component FQDD=""iDRAC.Embedded.1"">\ <Attribute Name=""ServerBoot.1#BootOnce"">\ Enabled\ </Attribute>\ <Attribute Name=""ServerBoot.1#FirstBootDevice"">\ VFDD\ </Attribute>\ </Component>\ </SystemConfiguration>\ """""" if sushy: MAGIC_SAUCER = { sushy.VIRTUAL_MEDIA_FLOPPY: MAGIC_FLOPPY_SAUCE, sushy.VIRTUAL_MEDIA_CD: MAGIC_CD_SAUCE } @classmethod def _set_boot_device(cls, task, device, persistent=False): """"""Set boot device for a node. Dell iDRAC Redfish implementation does not support setting boot device to virtual media via standard Redfish means. However, this still can be done via an OEM extension. :param task: a TaskManager instance. :param device: Boot device. Values are vendor-specific. :param persistent: Whether to set next-boot, or make the change permanent. Default: False. :raises: InvalidParameterValue if the validation of the ManagementInterface fails. """""" try: magic_saucer = cls.MAGIC_SAUCER[device] except KeyError: super(DracVirtualMediaBoot, cls)._set_boot_device( task, device, persistent) return system = redfish_utils.get_system(task.node) for manager in system.managers: try: # TODO(etingof): the exact sushy call may be different eid_674_manager = manager.oem.eid_674_manager except AttributeError: continue eid_674_manager.import_system_configuration( shared_configuration={'Target': 'ALL'}, import_buffer=magic_saucer) LOG.info(""Set node %(node) boot device to %(device) via "" ""OEM magic"", {'node': task.node.uuid, 'device': device}) break else: raise exception.InvalidParameterValue( driver='redfish', reason=_('Unable to find Dell sushy library OEM extension ' '(eid_674_manager)')) # TODO(etingof): we need to poll Redfish TaskService instead, # but that's not yet implemented in sushy eventlet.sleep(30) ",,144,0
openstack%2Ftempest-lib~master~I4c07da5550220c310a08bc566c0dcf067bd72af2,openstack/tempest-lib,master,I4c07da5550220c310a08bc566c0dcf067bd72af2,update source link in readme,ABANDONED,2019-10-16 00:46:37.000000000,2019-10-16 02:49:23.000000000,,"[{'_account_id': 5689}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-16 00:46:37.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/cd497e452e53b8b8691555b27f89beda52424284', 'message': 'update source link in readme\n\nChange-Id: I4c07da5550220c310a08bc566c0dcf067bd72af2\n'}]",1,688842,cd497e452e53b8b8691555b27f89beda52424284,4,2,1,30384,,,0,"update source link in readme

Change-Id: I4c07da5550220c310a08bc566c0dcf067bd72af2
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/42/688842/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,cd497e452e53b8b8691555b27f89beda52424284,,* Source: http://opendev.org/openstack/tempest-lib/,* Source: http://git.openstack.org/cgit/openstack/tempest-lib,1,1
openstack%2Ftempest-lib~master~Id1ebcc5f7e9f76c14d3a4debefdbb939914aa7c6,openstack/tempest-lib,master,Id1ebcc5f7e9f76c14d3a4debefdbb939914aa7c6,Fix author-email in setup.cfg,ABANDONED,2019-01-24 03:34:56.000000000,2019-10-16 02:49:08.000000000,,"[{'_account_id': 8556}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-01-24 03:34:56.000000000', 'files': ['setup.cfg'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/ba09b78ad18bb8f2d26a1af29c2c269e23b8bc6b', 'message': 'Fix author-email in setup.cfg\n\nChange-Id: Id1ebcc5f7e9f76c14d3a4debefdbb939914aa7c6\n'}]",0,632911,ba09b78ad18bb8f2d26a1af29c2c269e23b8bc6b,4,2,1,29423,,,0,"Fix author-email in setup.cfg

Change-Id: Id1ebcc5f7e9f76c14d3a4debefdbb939914aa7c6
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/11/632911/1 && git format-patch -1 --stdout FETCH_HEAD,['setup.cfg'],1,ba09b78ad18bb8f2d26a1af29c2c269e23b8bc6b,,author-email = openstack-discuss@lists.openstack.org,author-email = openstack-dev@lists.openstack.org,1,1
openstack%2Ftempest-lib~master~I8ef3e8c5b135d5761ba4e39f69cec1d2036dbe33,openstack/tempest-lib,master,I8ef3e8c5b135d5761ba4e39f69cec1d2036dbe33,Replacing the link in HACKING.rst,ABANDONED,2018-11-16 01:36:36.000000000,2019-10-16 02:49:03.000000000,,"[{'_account_id': 8556}, {'_account_id': 17887}, {'_account_id': 22348}]","[{'number': 1, 'created': '2018-11-16 01:36:36.000000000', 'files': ['HACKING.rst'], 'web_link': 'https://opendev.org/openstack/tempest-lib/commit/a07ff1821b76b9f0df7651c0bb90f200562d30fc', 'message': 'Replacing the link in HACKING.rst\n\nChange-Id: I8ef3e8c5b135d5761ba4e39f69cec1d2036dbe33\n'}]",0,618361,a07ff1821b76b9f0df7651c0bb90f200562d30fc,6,3,1,29423,,,0,"Replacing the link in HACKING.rst

Change-Id: I8ef3e8c5b135d5761ba4e39f69cec1d2036dbe33
",git fetch https://review.opendev.org/openstack/tempest-lib refs/changes/61/618361/1 && git format-patch -1 --stdout FETCH_HEAD,['HACKING.rst'],1,a07ff1821b76b9f0df7651c0bb90f200562d30fc,,Read the OpenStack Style Commandments https://docs.openstack.org/hacking/latest/,Read the OpenStack Style Commandments http://docs.openstack.org/developer/hacking/,1,1
openstack%2Fpaunch~master~I98c75e03d78885173d829fa850f35c52c625e6bb,openstack/paunch,master,I98c75e03d78885173d829fa850f35c52c625e6bb,list_or_dict_arg: fix the else condition,MERGED,2019-10-15 14:23:33.000000000,2019-10-16 02:45:08.000000000,2019-10-16 02:44:10.000000000,"[{'_account_id': 9592}, {'_account_id': 10969}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 14:23:33.000000000', 'files': ['paunch/builder/base.py'], 'web_link': 'https://opendev.org/openstack/paunch/commit/b9b3e32b4ed6647e2992466354b70afcedd5e8f2', 'message': 'list_or_dict_arg: fix the else condition\n\nThe ""else"" was wrong, if the key was empty with no value, it would try\nto iterate on something that might not be a list. Let\'s be sure the\ninstance is a list.\n\nChange-Id: I98c75e03d78885173d829fa850f35c52c625e6bb\n'}]",0,688721,b9b3e32b4ed6647e2992466354b70afcedd5e8f2,13,4,1,3153,,,0,"list_or_dict_arg: fix the else condition

The ""else"" was wrong, if the key was empty with no value, it would try
to iterate on something that might not be a list. Let's be sure the
instance is a list.

Change-Id: I98c75e03d78885173d829fa850f35c52c625e6bb
",git fetch https://review.opendev.org/openstack/paunch refs/changes/21/688721/1 && git format-patch -1 --stdout FETCH_HEAD,['paunch/builder/base.py'],1,b9b3e32b4ed6647e2992466354b70afcedd5e8f2,dict," elif isinstance(value, list):", else:,1,1
openstack%2Ftosca-parser~master~I81b5d4ac06776450149124f555f92fd350f0629a,openstack/tosca-parser,master,I81b5d4ac06776450149124f555f92fd350f0629a,Add initialization process for main_template_file_name,ABANDONED,2019-10-10 02:27:38.000000000,2019-10-16 02:42:48.000000000,,"[{'_account_id': 16511}, {'_account_id': 22348}, {'_account_id': 26588}, {'_account_id': 27180}]","[{'number': 1, 'created': '2019-10-10 02:27:38.000000000', 'files': ['toscaparser/tests/data/CSAR/csar_metadata_invalid_yaml.zip', 'toscaparser/tests/test_prereq.py', 'toscaparser/imports.py', 'toscaparser/prereq/csar.py'], 'web_link': 'https://opendev.org/openstack/tosca-parser/commit/e0f0f889b52fe21de9dbba64d30717b715319178', 'message': 'Add initialization process for main_template_file_name\n\n  * Add initialization process for main_template_file_name to fix that\n    invalid csar metafile cannot be loaded.\n\n  * Add assert function for csar.validate() to check the return value.\n\n  Story: #2006688\n  Task: #36980\n\nChange-Id: I81b5d4ac06776450149124f555f92fd350f0629a\n'}]",4,687767,e0f0f889b52fe21de9dbba64d30717b715319178,5,4,1,27180,,,0,"Add initialization process for main_template_file_name

  * Add initialization process for main_template_file_name to fix that
    invalid csar metafile cannot be loaded.

  * Add assert function for csar.validate() to check the return value.

  Story: #2006688
  Task: #36980

Change-Id: I81b5d4ac06776450149124f555f92fd350f0629a
",git fetch https://review.opendev.org/openstack/tosca-parser refs/changes/67/687767/1 && git format-patch -1 --stdout FETCH_HEAD,"['toscaparser/tests/data/CSAR/csar_metadata_invalid_yaml.zip', 'toscaparser/tests/test_prereq.py', 'toscaparser/imports.py', 'toscaparser/prereq/csar.py']",4,e0f0f889b52fe21de9dbba64d30717b715319178,bug/2006688, self.metadata = None return self.metadata.get(key) if self.metadata else None if custom_service.error_caught: self.error_caught = True self.error_caught = True self.error_caught = True, return self.metadata.get(key),146,69
openstack%2Fwatcher~stable%2Frocky~I896a7c49eea1b267099fc90d837458ec7bb7853d,openstack/watcher,stable/rocky,I896a7c49eea1b267099fc90d837458ec7bb7853d,Fix issues on stable/rocky,MERGED,2019-10-02 08:57:08.000000000,2019-10-16 02:33:40.000000000,2019-10-16 02:33:39.000000000,"[{'_account_id': 21692}, {'_account_id': 22348}, {'_account_id': 28014}, {'_account_id': 28748}, {'_account_id': 29911}, {'_account_id': 30442}]","[{'number': 1, 'created': '2019-10-02 08:57:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/bc88890e93d551f3312b33a854682a1f5feef6f0', 'message': 'Fix issues on stable/rocky\n\nThis patch fixes issues present to stable/rocky branch. Due to heavy\nrefactoring in later branches backporting is no possible.\n\nChange-Id: I896a7c49eea1b267099fc90d837458ec7bb7853d\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}, {'number': 2, 'created': '2019-10-08 12:39:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/watcher/commit/419d87b0b2a0dbfb7ed9892d5d6ff913f8b61d78', 'message': 'Fix issues on stable/rocky\n\nThis patch fixes issues present to stable/rocky branch. Due to heavy\nrefactoring in later branches backporting is no possible.\n\nChange-Id: I896a7c49eea1b267099fc90d837458ec7bb7853d\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}, {'number': 3, 'created': '2019-10-09 07:32:20.000000000', 'files': ['watcher/datasource/gnocchi.py', 'watcher/datasource/manager.py', 'doc/source/configuration/configuring.rst', 'watcher/common/service.py'], 'web_link': 'https://opendev.org/openstack/watcher/commit/6a4a9af53817300013951707213662569c641119', 'message': 'Fix issues on stable/rocky\n\nThis patch fixes issues present to stable/rocky branch. Due to heavy\nrefactoring in later branches backporting is no possible.\n\nChange-Id: I896a7c49eea1b267099fc90d837458ec7bb7853d\nSigned-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>\n'}]",5,686110,6a4a9af53817300013951707213662569c641119,16,6,3,28014,,,0,"Fix issues on stable/rocky

This patch fixes issues present to stable/rocky branch. Due to heavy
refactoring in later branches backporting is no possible.

Change-Id: I896a7c49eea1b267099fc90d837458ec7bb7853d
Signed-off-by: Stamatis Katsaounis <skatsaounis@admin.grnet.gr>
",git fetch https://review.opendev.org/openstack/watcher refs/changes/10/686110/1 && git format-patch -1 --stdout FETCH_HEAD,"['watcher/common/nova_helper.py', 'watcher/datasource/gnocchi.py', 'watcher/datasource/manager.py']",3,bc88890e93d551f3312b33a854682a1f5feef6f0,," if hasattr(self.config, 'datasources'): self.datasources = self.config.datasources elif hasattr(self.config, 'datasource'): self.datasources = [self.config.datasource] else: self.datasources = []", self.datasources = self.config.datasources,10,4
openstack%2Fnova~master~I3a6e55b771d7324fb0809059813e7553562c21c4,openstack/nova,master,I3a6e55b771d7324fb0809059813e7553562c21c4,Fix legacy issues in filter migrations by user_id/project_id,MERGED,2019-09-14 07:05:20.000000000,2019-10-16 02:13:36.000000000,2019-10-15 22:56:48.000000000,"[{'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 9008}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 28543}, {'_account_id': 28935}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-09-14 07:05:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3244fa9bdaf9811a6657e8940704fb6af148a8e6', 'message': 'Fix legacy issues in Filter migrations by user_id/project_id\n\nFix some issue in https://review.opendev.org/#/c/679413 and\nhttps://review.opendev.org/#/c/674243/ from Matt.\n\nMainly showing the base (2.1) and latest version of the response\nin the api-ref.\n\nChange-Id: I3a6e55b771d7324fb0809059813e7553562c21c4\n'}, {'number': 2, 'created': '2019-10-11 04:37:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/42f165f7202dd3f1e58d6cf3be56c9be2d0e36be', 'message': 'Fix legacy issues in Filter migrations by user_id/project_id\n\nFix some issue in https://review.opendev.org/#/c/679413 and\nhttps://review.opendev.org/#/c/674243/ from Matt.\n\nMainly showing the base (2.1) and latest version of the response\nin the api-ref.\n\nChange-Id: I3a6e55b771d7324fb0809059813e7553562c21c4\n'}, {'number': 3, 'created': '2019-10-11 04:38:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/15f15252443106f4390a7f0aff6bca06c197bf7a', 'message': 'Fix legacy issues in filter migrations by user_id/project_id\n\nFix some issue in https://review.opendev.org/#/c/679413.\n\nChange-Id: I3a6e55b771d7324fb0809059813e7553562c21c4\n'}, {'number': 4, 'created': '2019-10-14 18:49:19.000000000', 'files': ['nova/tests/unit/objects/test_migration.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/355570962b5e0f9dfa38dbb09e20066870a0d5bf', 'message': 'Fix legacy issues in filter migrations by user_id/project_id\n\nFix some issue in https://review.opendev.org/#/c/679413.\n\nChange-Id: I3a6e55b771d7324fb0809059813e7553562c21c4\n'}]",1,682198,355570962b5e0f9dfa38dbb09e20066870a0d5bf,59,16,4,26458,,,0,"Fix legacy issues in filter migrations by user_id/project_id

Fix some issue in https://review.opendev.org/#/c/679413.

Change-Id: I3a6e55b771d7324fb0809059813e7553562c21c4
",git fetch https://review.opendev.org/openstack/nova refs/changes/98/682198/1 && git format-patch -1 --stdout FETCH_HEAD,"['nova/tests/unit/objects/test_migration.py', 'api-ref/source/os-migrations.inc', 'api-ref/source/server-migrations.inc']",3,3244fa9bdaf9811a6657e8940704fb6af148a8e6,bp/add-user-id-field-to-the-migrations-table,,**Example List Migrations (2.59)** .. literalinclude:: ../../doc/api_samples/server-migrations/v2.59/migrations-index.json :language: javascript **Example Show Migration Details (2.59)** .. literalinclude:: ../../doc/api_samples/server-migrations/v2.59/migrations-get.json :language: javascript ,2,22
openstack%2Fnova~master~I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c,openstack/nova,master,I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c,Filter migrations by user_id/project_id,MERGED,2019-08-02 09:39:37.000000000,2019-10-16 02:05:51.000000000,2019-10-15 18:34:32.000000000,"[{'_account_id': 4393}, {'_account_id': 4690}, {'_account_id': 5754}, {'_account_id': 6873}, {'_account_id': 7634}, {'_account_id': 9008}, {'_account_id': 9732}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 14595}, {'_account_id': 15751}, {'_account_id': 15941}, {'_account_id': 16128}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 20722}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26458}, {'_account_id': 26515}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-08-02 09:39:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ea283f884447757b25817dc27f7d03ad8a7bc89c', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 2, 'created': '2019-08-03 08:49:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/836b0ccc99088b5f88382ade32ac0718ac2b80df', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 3, 'created': '2019-08-03 09:59:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/7324a10faa7d7cdc3acea442d7fb6ddf011561f3', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 4, 'created': '2019-08-03 10:12:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/439b9915a93cb33f5da4848f566dd99c0977a47e', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 5, 'created': '2019-08-03 10:17:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4d67d7b2a34568d18ff91df8acb7526cf8b322c9', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 6, 'created': '2019-08-04 05:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ceea421b422435fc8756aa90e54557889d7948e1', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 7, 'created': '2019-08-04 06:09:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/0abe41fdf9b37ea4f2b464b33a18041ff5e374fa', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 8, 'created': '2019-08-05 00:59:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/d35653446b463c9bb994d73f3b948f79bfe9b8c2', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 9, 'created': '2019-08-05 12:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a4c3a5a4a5cd5447256a339480b05981df52df59', 'message': 'WIP: Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 10, 'created': '2019-08-06 08:53:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1737efc31ef90a252575838025410264a1439df0', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 11, 'created': '2019-08-06 09:36:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/fd53acf32aa3cca9e1a1120d80fbd4602f5a4c9c', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 12, 'created': '2019-08-06 15:04:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/912d0f3d871c40ebc637e6198fc28874528f24c8', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 13, 'created': '2019-08-13 06:16:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/913d21deffbb531c53f628f309ce5367baa7565c', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.76, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 14, 'created': '2019-08-22 09:26:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/6a555bef4cdd9781321ae15fedd99554cdc34d13', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.77, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 15, 'created': '2019-08-29 07:49:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/b601f8355a76d8f11a45e225ea90a4eeade1dffa', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 16, 'created': '2019-08-29 11:00:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2e78412dd6e8ec4298727e272656d26ca4eeb61a', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nAdd ``user_id`` and ``project_id`` to the migrations, to record who\noperators *that* instance. Mainly at ``POST Migrate/Live-Migrate\nServer`` APIs.\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 17, 'created': '2019-08-30 10:45:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e942bfe18d7b38a844930d20822f29fe491a4ca8', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 18, 'created': '2019-08-30 10:50:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/e7acc21012b00c3bf2f2a054bde18e07608609d7', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 19, 'created': '2019-08-30 10:50:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/540d06ae6285fe8fbe8becd2e395505c1bf00e42', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 20, 'created': '2019-08-30 11:05:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/67920d6df40043d24b8d7d4d664b35c84dbafcb5', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.78, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 21, 'created': '2019-09-05 14:22:07.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/28b2462b6463823aa4d483a1c4273ef92570a9e9', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.79, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 22, 'created': '2019-09-06 11:19:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/af7d35d2ea21371c12c3b1c8b1753c158172279c', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 23, 'created': '2019-09-09 02:32:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/1bb70792455904926ec5abd8e435c1ee5b01f192', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 24, 'created': '2019-09-09 06:52:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/2a24f2d7bbf9f7754a555b2391c9d91d4bfa58ad', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 25, 'created': '2019-09-09 09:47:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cd9fe3bc91f4e3b1d9c49f3a09eb05e2efb80e8d', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 26, 'created': '2019-09-11 08:21:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/dd33510d2168749cdf9545be8d05ca5f6156a43c', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 27, 'created': '2019-09-11 08:23:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/9e050b8cb14bed5350b9d50a0c4489ef119aa56e', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 28, 'created': '2019-09-12 07:30:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/ca4f6af76b9413fdbf55815a1caccd55894a113a', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 29, 'created': '2019-09-12 16:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/aecfaf5b7e00019cf4f9455d60eb7376ea49af10', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 30, 'created': '2019-09-26 02:12:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/a46df3527ae464fce2e52ed58d5444854793f07a', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project::\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 31, 'created': '2019-10-11 04:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/4691aa88328ef919ae5cace7d1629a76f8ee60ec', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project:\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 32, 'created': '2019-10-11 04:36:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/309b175299866c38efacf9c046c8449bfd5ad3d6', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project:\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}, {'number': 33, 'created': '2019-10-14 18:35:31.000000000', 'files': ['api-ref/source/parameters.yaml', 'doc/api_samples/server-migrations/v2.80/migrations-index.json', 'nova/api/openstack/compute/migrations.py', 'api-ref/source/server-migrations.inc', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get.json.tpl', 'nova/tests/functional/api_sample_tests/test_migrations.py', 'doc/api_samples/os-migrations/v2.80/migrations-get-with-changes-before.json', 'doc/api_samples/versions/versions-get-resp.json', 'nova/api/openstack/api_version_request.py', 'nova/tests/functional/api_sample_tests/api_samples/server-migrations/v2.80/live-migrate-server.json.tpl', 'doc/api_samples/server-migrations/v2.80/live-migrate-server.json', 'releasenotes/notes/bp-add-user-id-field-to-the-migrations-table-af5989e74634b9c4.yaml', 'api-ref/source/os-migrations.inc', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get-with-limit.json.tpl', 'doc/api_samples/versions/v21-version-get-resp.json', 'doc/api_samples/os-migrations/v2.80/migrations-get-with-limit.json', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get-with-changes-before.json.tpl', 'nova/api/openstack/compute/rest_api_version_history.rst', 'doc/api_samples/os-migrations/v2.80/migrations-get-with-changes-since.json', 'nova/tests/unit/api/openstack/compute/test_server_migrations.py', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get-with-marker.json.tpl', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get-with-changes-since.json.tpl', 'nova/tests/functional/api/client.py', 'nova/api/openstack/compute/server_migrations.py', 'doc/api_samples/os-migrations/v2.80/migrations-get-with-marker.json', 'nova/tests/functional/api_sample_tests/api_samples/server-migrations/v2.80/migrations-get.json.tpl', 'nova/tests/functional/api_sample_tests/test_server_migrations.py', 'doc/api_samples/server-migrations/v2.80/migrations-get.json', 'nova/api/openstack/compute/schemas/migrations.py', 'nova/tests/unit/api/openstack/compute/test_migrations.py', 'nova/tests/functional/api_sample_tests/api_samples/os-migrations/v2.80/migrations-get-with-user-or-project-id.json.tpl', 'doc/api_samples/os-migrations/v2.80/migrations-get.json', 'doc/api_samples/os-migrations/v2.80/migrations-get-with-user-or-project-id.json', 'nova/tests/functional/test_servers.py', 'nova/tests/functional/api_sample_tests/api_samples/server-migrations/v2.80/migrations-index.json.tpl'], 'web_link': 'https://opendev.org/openstack/nova/commit/ac165112b7918e5aaaa80819e37b223edf86bb06', 'message': 'Filter migrations by user_id/project_id\n\nIn microversion 2.80, the ``GET /os-migrations`` API will have\noptional ``user_id`` and ``project_id`` query parameters for\nfiltering migrations by user and/or project:\n\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394\n* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54\n\nAnd expose the ``user_id`` and ``project_id`` fields in the following APIs:\n\n* GET /os-migrations\n* GET /servers/{server_id}/migrations\n* GET /servers/{server_id}/migrations/{migration_id}\n\nCo-Authored-By: Qiu Fossen <qiujunting>\nPart of blueprint add-user-id-field-to-the-migrations-table\nChange-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c\n'}]",180,674243,ac165112b7918e5aaaa80819e37b223edf86bb06,335,22,33,26458,,,0,"Filter migrations by user_id/project_id

In microversion 2.80, the ``GET /os-migrations`` API will have
optional ``user_id`` and ``project_id`` query parameters for
filtering migrations by user and/or project:

* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394
* GET /os-migrations?project_id=011ee9f4-8f16-4c38-8633-a254d420fd54
* GET /os-migrations?user_id=ef9d34b4-45d0-4530-871b-3fb535988394&project_id=011ee9f4-8f16-4c38-8633-a254d420fd54

And expose the ``user_id`` and ``project_id`` fields in the following APIs:

* GET /os-migrations
* GET /servers/{server_id}/migrations
* GET /servers/{server_id}/migrations/{migration_id}

Co-Authored-By: Qiu Fossen <qiujunting>
Part of blueprint add-user-id-field-to-the-migrations-table
Change-Id: I7313d6cde1a5e1dc7dd6f3c0dff9f30bbf4bee2c
",git fetch https://review.opendev.org/openstack/nova refs/changes/43/674243/33 && git format-patch -1 --stdout FETCH_HEAD,"['api-ref/source/parameters.yaml', 'releasenotes/notes/bp-add-user-id-field-to-the-migrations-table-af5989e74634b9c4.yaml', 'nova/tests/unit/api/openstack/compute/test_migrations.py', 'api-ref/source/os-migrations.inc', 'nova/api/openstack/compute/migrations.py', 'nova/api/openstack/compute/schemas/migrations.py']",6,ea283f884447757b25817dc27f7d03ad8a7bc89c,bp/add-user-id-field-to-the-migrations-table," list_query_params_v276 = copy.deepcopy(list_query_params_v266) list_query_params_v276['properties'].update({ # The 2.76 microversion added support filtering migrations # by user_id and project_id 'user_id': parameter_types.common_query_param, 'project_id': parameter_types.common_query_param, })",,112,2
openstack%2Fpython-tripleoclient~stable%2Fqueens~I344a4e660d29d73058623a7856e5835aa2b7c82d,openstack/python-tripleoclient,stable/queens,I344a4e660d29d73058623a7856e5835aa2b7c82d,Fixup hard-coded hw_architecture in unittest,MERGED,2018-08-02 03:11:55.000000000,2019-10-16 01:31:09.000000000,2019-10-16 01:31:09.000000000,"[{'_account_id': 7144}, {'_account_id': 10806}, {'_account_id': 11082}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 16282}, {'_account_id': 17130}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}]","[{'number': 1, 'created': '2018-08-02 03:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/c0f61ed890bb94569c5f9c304724f730700d3360', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 2, 'created': '2019-07-08 16:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/98649e621288feecfdc4b7863040c5340e380a83', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 3, 'created': '2019-07-08 17:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/bb573c716d40b148cd73d61ea658d2754975da62', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 4, 'created': '2019-07-08 18:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/728cc982420c13edbffd9a807da1e69c753a29be', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 5, 'created': '2019-07-09 16:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/56a54d004f79abd840d35141c88ceb6fb9e39a1c', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 6, 'created': '2019-07-16 00:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/77af4b4f8c6ed838bbb10d7a8444734bea72c486', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 7, 'created': '2019-08-01 15:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/850eba56fe285443b64e9edaa0981794d03145c4', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 8, 'created': '2019-09-09 17:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/53c2845a274c020a280878f748c060f3c50ca184', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}, {'number': 9, 'created': '2019-09-10 01:43:55.000000000', 'files': ['tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1945c289cfbc0bf43c1cb84cd9d77ce18a0e543b', 'message': 'Fixup hard-coded hw_architecture in unittest\n\nCloses-Bug: #1784662\nChange-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d\n(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)\n'}]",0,588128,1945c289cfbc0bf43c1cb84cd9d77ce18a0e543b,44,10,9,12898,,,0,"Fixup hard-coded hw_architecture in unittest

Closes-Bug: #1784662
Change-Id: I344a4e660d29d73058623a7856e5835aa2b7c82d
(cherry picked from commit 58888f23984c5cc4028b11d2b69284b4a2da5b48)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/28/588128/4 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'],1,c0f61ed890bb94569c5f9c304724f730700d3360,queens/multiarch-support," mock.call(mock.ANY, hw_architecture=self._arch), mock.call(mock.ANY, hw_architecture=self._arch), mock.call(mock.ANY, hw_architecture=self._arch),"," mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'),",3,3
openstack%2Fpython-tripleoclient~stable%2Fqueens~I082dfe34cf192f76f87e348aecb67e984e0c8ae9,openstack/python-tripleoclient,stable/queens,I082dfe34cf192f76f87e348aecb67e984e0c8ae9,Always set a hardware architecture on uploaded images,MERGED,2018-07-31 07:21:08.000000000,2019-10-16 01:31:08.000000000,2019-10-16 01:31:08.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10806}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2018-07-31 07:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/44465787865e1a03c25276548596ae5f4b8ee1a1', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 2, 'created': '2018-08-02 03:11:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/003ae4192249fa411f8ba8cd5b3c619917779b06', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 3, 'created': '2019-07-08 16:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0ec0b80e6aee78d2f54b33c3f854551b1a7bd338', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 4, 'created': '2019-07-08 17:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/edc283ea5da2a396164e7a0f2b5339cf5a46e37d', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 5, 'created': '2019-07-08 18:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/fff9200b9e6bb88047eed25fdaa03daa12477f29', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 6, 'created': '2019-07-09 16:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/aab9c2e1abff3f471b074c10ae3fa896eb7a1806', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 7, 'created': '2019-07-16 00:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/7bcb1d4c8c1b4965ea69a39b98cd18ec9a61c951', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 8, 'created': '2019-08-01 15:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2e68d1e0345f9b79b1f26932c0756824be55d84b', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 9, 'created': '2019-09-09 17:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/078beffc1df3b549d02faa38130982a2d47e5ccc', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}, {'number': 10, 'created': '2019-09-10 01:43:55.000000000', 'files': ['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3b6d2ca211c64ddea98cc7b2dac0aba00126a6b4', 'message': ""Always set a hardware architecture on uploaded images\n\nIn a multiarch environment if we have an image that doesn't have an\nhw_architecture it can be scheduled on any node registered with ironic.\nSo this means that nova could schedule an x86_64 image on a ppc64le node\n(clearly a bad thing).\n\nAvoid that by always setting a hw_architecture image property matching\nthe kernel of the running system.  This is safe as in a single arch\nenvironment, by definition all nodes are the same ;P and in a multiarch\nwe're being explict, which may result in NoValidHost exceptions which is\na much clearer error case than scheduling wrong ISA images.\n\nBlueprint: multiarch-support\nChange-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9\n(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)\n""}]",1,587312,3b6d2ca211c64ddea98cc7b2dac0aba00126a6b4,48,7,10,12898,,,0,"Always set a hardware architecture on uploaded images

In a multiarch environment if we have an image that doesn't have an
hw_architecture it can be scheduled on any node registered with ironic.
So this means that nova could schedule an x86_64 image on a ppc64le node
(clearly a bad thing).

Avoid that by always setting a hw_architecture image property matching
the kernel of the running system.  This is safe as in a single arch
environment, by definition all nodes are the same ;P and in a multiarch
we're being explict, which may result in NoValidHost exceptions which is
a much clearer error case than scheduling wrong ISA images.

Blueprint: multiarch-support
Change-Id: I082dfe34cf192f76f87e348aecb67e984e0c8ae9
(cherry picked from commit 879db352773c9d17fdf6895865e84cbeb2bbbbec)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/12/587312/1 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/v1/overcloud_image.py', 'tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py']",2,44465787865e1a03c25276548596ae5f4b8ee1a1,queens/multiarch-support,"import tripleo_common.arch self._arch = tripleo_common.arch.kernel_arch() mock.Mock(id=10, name='imgname', properties={'kernel_id': 10, 'ramdisk_id': 10, 'hw_architecture': self._arch}, mock.call(properties={'hw_architecture': self._arch}, mock.call(properties={'hw_architecture': self._arch}, mock.call(properties={'kernel_id': 10, 'ramdisk_id': 10, 'hw_architecture': self._arch}, mock.call(properties={'hw_architecture': self._arch}, mock.call(properties={'hw_architecture': self._arch}, 10, # 5 for new uploads, 5 updating the existsing self._arch = tripleo_common.arch.kernel_arch() mock.Mock(id=10, name='imgname', properties={'hw_architecture': self._arch}, # properties are set by updating the image self.app.client_manager.image.images.update.assert_has_calls([ mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), ]) properties={'hw_architecture': self._arch}) properties={'hw_architecture': self._arch}, 6, # update 3 images *and* add properties to 3 images"," mock.Mock(id=10, name='imgname', properties={'kernel_id': 10, 'ramdisk_id': 10}, mock.call(properties={}, mock.call(properties={}, mock.call(properties={'kernel_id': 10, 'ramdisk_id': 10}, mock.call(properties={}, mock.call(properties={}, 6, mock.Mock(id=10, name='imgname', properties={}, properties={}) properties={}, 3,",27,12
openstack%2Fpython-tripleoclient~stable%2Fqueens~I996248f06ff47a7e20398848ae047eb4c2227dec,openstack/python-tripleoclient,stable/queens,I996248f06ff47a7e20398848ae047eb4c2227dec,Switch to using assert_has_calls() instead of assertEqual(),MERGED,2018-07-31 07:21:08.000000000,2019-10-16 01:31:07.000000000,2019-10-16 01:31:07.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10806}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2018-07-31 07:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/806ed89f06dbaf1cceb506498f04aa662b179ec9', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 2, 'created': '2019-07-08 16:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/22b066cd666e9f1cab263523561a8bcfe8538828', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 3, 'created': '2019-07-08 17:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/52882d5ba803efc22be6ac67d5607fbd3f338f4f', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 4, 'created': '2019-07-08 18:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/579601b8d2777d72893201a92331f787973984d6', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 5, 'created': '2019-07-09 16:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/1c19dfa34e1bdbb34202529b2d4b234d6a3db6df', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 6, 'created': '2019-07-16 00:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/5d93b4d37272aad6da22bae60849f1e8dc067ea9', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 7, 'created': '2019-08-01 15:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/62a0d3b114ff5dcd289d5a5dd02800cf5274ba9a', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 8, 'created': '2019-09-09 17:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/2e61b2a5718a4115ec37f40bfa71ad35a276ff94', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}, {'number': 9, 'created': '2019-09-10 01:43:55.000000000', 'files': ['tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/3c3d813cf523db0b96bae09d8f502df8f9beaa20', 'message': ""Switch to using assert_has_calls() instead of assertEqual()\n\nWhile adding multiarch support I noticed that some tests I was copying\nhad switched the values of actual and reference.  While this doesn't\nalter the correctness of the tests it is somewhat strange when the tests\nfail and a human is looking at the output.\n\nAlso during review Steve Baker noted we could use assert_has_calls() so\navoid confusing humans by switching :)\n\nChange-Id: I996248f06ff47a7e20398848ae047eb4c2227dec\n(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)\n""}]",0,587311,3c3d813cf523db0b96bae09d8f502df8f9beaa20,46,8,9,12898,,,0,"Switch to using assert_has_calls() instead of assertEqual()

While adding multiarch support I noticed that some tests I was copying
had switched the values of actual and reference.  While this doesn't
alter the correctness of the tests it is somewhat strange when the tests
fail and a human is looking at the output.

Also during review Steve Baker noted we could use assert_has_calls() so
avoid confusing humans by switching :)

Change-Id: I996248f06ff47a7e20398848ae047eb4c2227dec
(cherry picked from commit 351633e4a396e38accdbcc99db1e82ba36f2f537)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/11/587311/8 && git format-patch -1 --stdout FETCH_HEAD,['tripleoclient/tests/v1/overcloud_image/test_overcloud_image.py'],1,806ed89f06dbaf1cceb506498f04aa662b179ec9,queens/multiarch-support," self.app.client_manager.image.images.create.assert_has_calls([ mock.call(name='overcloud-full-vmlinuz', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='overcloud-full-initrd', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ]) mock_subprocess_call.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(properties={}, data=b'IMGDATA', name='overcloud-full-vmlinuz', disk_format='aki', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='overcloud-full-initrd', disk_format='ari', is_public=True), mock.call(properties={'kernel_id': 10, 'ramdisk_id': 10}, name='overcloud-full', data=b'IMGDATA', container_format='bare', disk_format='qcow2', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='bm-deploy-kernel', disk_format='aki', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='bm-deploy-ramdisk', disk_format='ari', is_public=True) ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-overcloud-full-vmlinuz', disk_format='aki', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-overcloud-full-initrd', disk_format='ari', is_public=True), mock.call(properties={'hw_architecture': 'x86_64', 'kernel_id': 10, 'ramdisk_id': 10}, name='x86_64-overcloud-full', data=b'IMGDATA', container_format='bare', disk_format='qcow2', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-bm-deploy-kernel', disk_format='aki', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-bm-deploy-ramdisk', disk_format='ari', is_public=True) ]) mock_subprocess_call.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.cmd._image_try_update.assert_has_calls([ ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ]) mock_subprocess_call.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(name='x86_64-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='x86_64-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='x86_64-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ]) self.app.client_manager.image.images.update.assert_has_calls([ mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), ]) mock_subprocess_call.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ]) self.app.client_manager.image.images.update.assert_has_calls([ mock.call(13, hw_architecture='ppc64le'), mock.call(14, hw_architecture='ppc64le'), mock.call(15, hw_architecture='ppc64le'), ]) mock_subprocess_call.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/ppc64le/agent.ramdisk""', shell=True), ]) self.app.client_manager.image.images.create.assert_has_calls([ mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ]) self.app.client_manager.image.images.update.assert_has_calls([ mock.call(13, hw_architecture='ppc64le'), mock.call(14, hw_architecture='ppc64le'), mock.call(15, hw_architecture='ppc64le'), mock.call(16, hw_architecture='ppc64le', tripleo_platform='p9'), mock.call(17, hw_architecture='ppc64le', tripleo_platform='p9'), mock.call(18, hw_architecture='ppc64le', tripleo_platform='p9'), ]) mock_subprocess.assert_has_calls([ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/ppc64le/agent.ramdisk""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/p9-ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/p9-ppc64le/agent.ramdisk""', shell=True), ])"," self.assertEqual( [mock.call(name='overcloud-full-vmlinuz', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='overcloud-full-initrd', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( mock_subprocess_call.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.assertEqual( [mock.call(properties={}, data=b'IMGDATA', name='overcloud-full-vmlinuz', disk_format='aki', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='overcloud-full-initrd', disk_format='ari', is_public=True), mock.call(properties={'kernel_id': 10, 'ramdisk_id': 10}, name='overcloud-full', data=b'IMGDATA', container_format='bare', disk_format='qcow2', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='bm-deploy-kernel', disk_format='aki', is_public=True), mock.call(properties={}, data=b'IMGDATA', name='bm-deploy-ramdisk', disk_format='ari', is_public=True) ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( [mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-overcloud-full-vmlinuz', disk_format='aki', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-overcloud-full-initrd', disk_format='ari', is_public=True), mock.call(properties={'hw_architecture': 'x86_64', 'kernel_id': 10, 'ramdisk_id': 10}, name='x86_64-overcloud-full', data=b'IMGDATA', container_format='bare', disk_format='qcow2', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-bm-deploy-kernel', disk_format='aki', is_public=True), mock.call(properties={'hw_architecture': 'x86_64'}, data=b'IMGDATA', name='x86_64-bm-deploy-ramdisk', disk_format='ari', is_public=True) ], self.app.client_manager.image.images.create.call_args_list ) # FIXME(tonyb): this is the wrong way around self.assertEqual( mock_subprocess_call.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) expected = [ ] self.assertEqual(expected, self.cmd._image_try_update.mock_calls) self.assertEqual( [mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( mock_subprocess_call.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.assertEqual( [mock.call(name='x86_64-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='x86_64-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='x86_64-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( [mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), mock.call(mock.ANY, hw_architecture='x86_64'), ], self.app.client_manager.image.images.update.call_args_list ) self.assertEqual( mock_subprocess_call.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True) ]) self.assertEqual( [mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( [mock.call(13, hw_architecture='ppc64le'), mock.call(14, hw_architecture='ppc64le'), mock.call(15, hw_architecture='ppc64le'), ], self.app.client_manager.image.images.update.call_args_list ) # FIXME(tonyb): this is the wrong way around self.assertEqual( mock_subprocess_call.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/ppc64le/agent.ramdisk""', shell=True), ]) self.assertEqual( [mock.call(name='overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-overcloud-full', disk_format='qcow2', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-bm-deploy-kernel', disk_format='aki', container_format='bare', visibility='public'), mock.call(name='p9-ppc64le-bm-deploy-ramdisk', disk_format='ari', container_format='bare', visibility='public') ], self.app.client_manager.image.images.create.call_args_list ) self.assertEqual( [mock.call(13, hw_architecture='ppc64le'), mock.call(14, hw_architecture='ppc64le'), mock.call(15, hw_architecture='ppc64le'), mock.call(16, hw_architecture='ppc64le', tripleo_platform='p9'), mock.call(17, hw_architecture='ppc64le', tripleo_platform='p9'), mock.call(18, hw_architecture='ppc64le', tripleo_platform='p9'), ], self.app.client_manager.image.images.update.call_args_list ) # FIXME(tonyb): this is the wrong way around self.assertEqual( mock_subprocess.call_args_list, [ mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/agent.ramdisk""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/ppc64le/agent.ramdisk""', shell=True), # FIXME(tonyb): wrong mock.call('sudo cp -f ""./ironic-python-agent.kernel"" ' '""/httpboot/p9-ppc64le/agent.kernel""', shell=True), mock.call('sudo cp -f ""./ironic-python-agent.initramfs"" ' '""/httpboot/p9-ppc64le/agent.ramdisk""', shell=True), ])",239,260
openstack%2Fpython-tripleoclient~stable%2Fqueens~I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13,openstack/python-tripleoclient,stable/queens,I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13,Actually use the arch and platform to select appropriate images,MERGED,2018-07-31 07:21:08.000000000,2019-10-16 01:31:06.000000000,2019-10-16 01:31:06.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 10806}, {'_account_id': 12898}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2018-07-31 07:21:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/d72e5e0be12ef6361d145f836be7613f7e6f87c9', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: Id82de41e7a49c2d8124fc74125ed51031579aa80\nDepends-On: Idaf05b8efce28cd0cbf339cf693db4f55a693d9b\nDepends-On: I41dce6e25766562db4366021309b8c2b74a8ab80\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 2, 'created': '2019-07-08 16:48:53.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/152469155af7722cd9b2ddf47f9cacd77d1f6841', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: Id82de41e7a49c2d8124fc74125ed51031579aa80\nDepends-On: Idaf05b8efce28cd0cbf339cf693db4f55a693d9b\nDepends-On: I41dce6e25766562db4366021309b8c2b74a8ab80\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 3, 'created': '2019-07-08 17:44:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/ee94d163ed3ee186f3a03c6b4cbd3b6789a17c9b', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: Id82de41e7a49c2d8124fc74125ed51031579aa80\nDepends-On: Idaf05b8efce28cd0cbf339cf693db4f55a693d9b\nDepends-On: I41dce6e25766562db4366021309b8c2b74a8ab80\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 4, 'created': '2019-07-08 18:20:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/86d5cd0407ae4fa0e6870665c3f2321e991d59f0', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: Id82de41e7a49c2d8124fc74125ed51031579aa80\nDepends-On: Idaf05b8efce28cd0cbf339cf693db4f55a693d9b\nDepends-On: I41dce6e25766562db4366021309b8c2b74a8ab80\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 5, 'created': '2019-07-09 16:34:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/6a8120fab14abaa864bd307f115054154b958b25', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: Id82de41e7a49c2d8124fc74125ed51031579aa80\nDepends-On: Idaf05b8efce28cd0cbf339cf693db4f55a693d9b\nDepends-On: I41dce6e25766562db4366021309b8c2b74a8ab80\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 6, 'created': '2019-07-16 00:37:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/b9e5a0ade013e411eaf5ab5de45722022e1f934f', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: https://review.opendev.org/#/c/587329\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 7, 'created': '2019-08-01 15:49:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/f72381dd42e7a4f9beed47324df9bc44943d7cec', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: https://review.opendev.org/#/c/587329\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 8, 'created': '2019-09-09 17:15:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/9f3c8784d31fdf415d6c8050b4dfc5559375e7fb', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: https://review.opendev.org/#/c/587329\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}, {'number': 9, 'created': '2019-09-10 01:43:55.000000000', 'files': ['tripleoclient/utils.py', 'tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/v1/overcloud_node.py'], 'web_link': 'https://opendev.org/openstack/python-tripleoclient/commit/0e0a3abaffea7cbdc4242913f704dac57a8104e7', 'message': ""Actually use the arch and platform to select appropriate images\n\nThe prior changes in this series enabled uploading of images tagged in\nsuch a way that they could be used with multiple architectures, this\nchange uses the data from instckenv.json to select appropriate deploy\nimages for each node as it's registered to ironic.\n\nBlueprint: multiarch-support\nDepends-On: https://review.opendev.org/#/c/587329\nChange-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13\n(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)\n""}]",0,587310,0e0a3abaffea7cbdc4242913f704dac57a8104e7,61,8,9,12898,,,0,"Actually use the arch and platform to select appropriate images

The prior changes in this series enabled uploading of images tagged in
such a way that they could be used with multiple architectures, this
change uses the data from instckenv.json to select appropriate deploy
images for each node as it's registered to ironic.

Blueprint: multiarch-support
Depends-On: https://review.opendev.org/#/c/587329
Change-Id: I7c84f3035853d8ee7b8d45895e7acce8e9dd3d13
(cherry picked from commit 560b79cb1b1739747f6a81ace390b63d63cdf3c0)
",git fetch https://review.opendev.org/openstack/python-tripleoclient refs/changes/10/587310/8 && git format-patch -1 --stdout FETCH_HEAD,"['tripleoclient/tests/v1/overcloud_node/test_overcloud_node.py', 'tripleoclient/utils.py', 'tripleoclient/v1/overcloud_node.py']",3,d72e5e0be12ef6361d145f836be7613f7e6f87c9,queens/multiarch-support," deploy_kernel = oooutils.deploy_kernel()[0] deploy_ramdisk = oooutils.deploy_ramdisk()[0] # Look for *specific* deploy images and update the node data if # one is found. oooutils.update_nodes_deploy_data(self.app.client_manager.image, nodes_config) # FIXME(tonyb): This is not multi-arch safe :(", deploy_kernel = 'bm-deploy-kernel' deploy_ramdisk = 'bm-deploy-ramdisk' ,209,3
openstack%2Fopenstack-helm-addons~master~Ic429f709f7e6442b560c2c05de9ea51bc8870a1a,openstack/openstack-helm-addons,master,Ic429f709f7e6442b560c2c05de9ea51bc8870a1a,Make ranger tempest test py3 compatible,ABANDONED,2019-10-15 03:32:27.000000000,2019-10-16 00:58:26.000000000,,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 28719}]","[{'number': 1, 'created': '2019-10-15 03:32:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/140deaeb615ed05898501ac1c69a0ab5a6420401', 'message': 'Add ranger tempest tests py3 compatible\n\nChange-Id: Ic429f709f7e6442b560c2c05de9ea51bc8870a1a\n'}, {'number': 2, 'created': '2019-10-15 14:21:40.000000000', 'files': ['ranger-agent/templates/bin/_ranger-agent-test.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/c690f660a8a03fea6fed95beb648878cf454b7a2', 'message': 'Make ranger tempest test py3 compatible\n\nChange-Id: Ic429f709f7e6442b560c2c05de9ea51bc8870a1a\n'}]",0,688609,c690f660a8a03fea6fed95beb648878cf454b7a2,8,7,2,8863,,,0,"Make ranger tempest test py3 compatible

Change-Id: Ic429f709f7e6442b560c2c05de9ea51bc8870a1a
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/09/688609/1 && git format-patch -1 --stdout FETCH_HEAD,['ranger-agent/templates/bin/_ranger-agent-test.sh.tpl'],1,140deaeb615ed05898501ac1c69a0ab5a6420401,,UUID=$(python -c 'import uuid; print(uuid.uuid1())'),UUID=$(python -c 'import uuid; print uuid.uuid1()'),1,1
openstack%2Freleases~master~If24156c42be607c37983b1701ea2bd4630e5d561,openstack/releases,master,If24156c42be607c37983b1701ea2bd4630e5d561,Small update to make-tracking-pad,ABANDONED,2019-04-12 01:45:57.000000000,2019-10-16 00:53:53.000000000,,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-04-12 01:45:57.000000000', 'files': ['openstack_releases/cmds/make_tracking_pad.py'], 'web_link': 'https://opendev.org/openstack/releases/commit/793a7f0733c502b3ea87993ba2092a7e9348b5d0', 'message': 'Small update to make-tracking-pad\n\n* Use the new opendev URL\n* Add place-holders for the meeting information and review days\n\nChange-Id: If24156c42be607c37983b1701ea2bd4630e5d561\n'}]",4,651951,793a7f0733c502b3ea87993ba2092a7e9348b5d0,8,4,1,12898,,,0,"Small update to make-tracking-pad

* Use the new opendev URL
* Add place-holders for the meeting information and review days

Change-Id: If24156c42be607c37983b1701ea2bd4630e5d561
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/651951/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack_releases/cmds/make_tracking_pad.py'],1,793a7f0733c502b3ea87993ba2092a7e9348b5d0,,process_url = 'http://git.openstack.org/cgit/openstack/releases/tree/PROCESS.rst' # noqa print('Review dashboard: http://tiny.cc/ReleaseInbox') print('Planning document: https://etherpad.openstack.org/p/{}-relmgt-plan'.format(series)) # noqa print('Process document: {}'.format(process_url)) print('Storyboard: https://storyboard.openstack.org/#!/board/64') print('First apply \'Heading 3\' formatting to all week titles. ' 'Then apply list') print('Meeting info') print('<Which Day> at <What time> UTC in #openstack-release') print('Meeting stanza: #startmeeting releaseteam') print('Ping list: <Copy from previous pad>') print() print('Review Days') print('Mon:') print('Tue:') print('Wed:') print('Thu:') print('Fri:') print(), print('Review dashboard: http://bit.ly/ocata-relmgt-dashboard') print('Planning document: https://etherpad.openstack.org/p/{}-relmgt-plan'.format(series)) print('Process document: http://git.openstack.org/cgit/openstack/releases/tree/PROCESS.rst') print('First apply title formatting to all week titles. Then apply list'),21,4
openstack%2Fpuppet-gnocchi~master~I65ed470a1f585ed4704057a71511451c8db44f8c,openstack/puppet-gnocchi,master,I65ed470a1f585ed4704057a71511451c8db44f8c,Configure s3_secret_access_key as secret,MERGED,2019-10-14 00:53:25.000000000,2019-10-16 00:41:36.000000000,2019-10-15 14:54:23.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 00:53:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/b0e614d31b7b50539f9db92bde8fc6200ec24f60', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\n'}, {'number': 2, 'created': '2019-10-14 03:12:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/b07639672cb2867a53efd62a40ea0a3269da293f', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/#/c/688319\n'}, {'number': 3, 'created': '2019-10-14 03:15:07.000000000', 'files': ['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-gnocchi/commit/05ee0bb4339b98ab67e4bedc192748905afe0aba', 'message': 'Configure s3_secret_access_key as secret\n\nParameter s3_secret_access_key should be configured as a secret.\n\nChange-Id: I65ed470a1f585ed4704057a71511451c8db44f8c\nCloses-Bug: #1847941\nDepends-On: https://review.opendev.org/688319\n'}]",0,688316,05ee0bb4339b98ab67e4bedc192748905afe0aba,18,4,3,9414,,,0,"Configure s3_secret_access_key as secret

Parameter s3_secret_access_key should be configured as a secret.

Change-Id: I65ed470a1f585ed4704057a71511451c8db44f8c
Closes-Bug: #1847941
Depends-On: https://review.opendev.org/688319
",git fetch https://review.opendev.org/openstack/puppet-gnocchi refs/changes/16/688316/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/storage/s3.pp', 'spec/classes/gnocchi_storage_s3_spec.rb']",2,b0e614d31b7b50539f9db92bde8fc6200ec24f60,bug/1847941, is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz').with_secret(true), is_expected.to contain_gnocchi_config('storage/s3_secret_access_key').with_value('secret-xyz'),2,2
openstack%2Fopenstack-helm-infra~master~If9e9ffaf1a2610f86356e02f5f12cb691e66c756,openstack/openstack-helm-infra,master,If9e9ffaf1a2610f86356e02f5f12cb691e66c756,[ceph-osd] fix partprobe issue after deleing the partitions,MERGED,2019-10-15 15:12:32.000000000,2019-10-16 00:15:23.000000000,2019-10-16 00:14:18.000000000,"[{'_account_id': 8898}, {'_account_id': 17591}, {'_account_id': 20469}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 29974}]","[{'number': 1, 'created': '2019-10-15 15:12:32.000000000', 'files': ['ceph-osd/templates/bin/osd/_common.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/6a7ba1cef1d9fb92e1b32f46754665af7b1ef4c2', 'message': '[ceph-osd] fix partprobe issue after deleing the partitions\n\nThis is to fix partprobe issues after deleing the repsective partitions.\n\nChange-Id: If9e9ffaf1a2610f86356e02f5f12cb691e66c756\n'}]",0,688733,6a7ba1cef1d9fb92e1b32f46754665af7b1ef4c2,9,7,1,28372,,,0,"[ceph-osd] fix partprobe issue after deleing the partitions

This is to fix partprobe issues after deleing the repsective partitions.

Change-Id: If9e9ffaf1a2610f86356e02f5f12cb691e66c756
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/33/688733/1 && git format-patch -1 --stdout FETCH_HEAD,['ceph-osd/templates/bin/osd/_common.sh.tpl'],1,6a7ba1cef1d9fb92e1b32f46754665af7b1ef4c2,, /sbin/udevadm settle --timeout=600 /usr/bin/flock -s ${journal_disk} /sbin/partprobe ${journal_disk} /sbin/udevadm settle --timeout=600 /sbin/udevadm settle --timeout=600 /usr/bin/flock -s ${block_db_disk} /sbin/partprobe ${block_db_disk} /sbin/udevadm settle --timeout=600 /sbin/udevadm settle --timeout=600 /usr/bin/flock -s ${block_wal_disk} /sbin/partprobe ${block_wal_disk} /sbin/udevadm settle --timeout=600,,9,0
openstack%2Fvitrage~stable%2Ftrain~Idc2c6ecd713cdea3986009bdc50e85a9c88d57b9,openstack/vitrage,stable/train,Idc2c6ecd713cdea3986009bdc50e85a9c88d57b9,Run vertices cleanup at the end of get_all,MERGED,2019-10-15 06:17:51.000000000,2019-10-15 23:18:42.000000000,2019-10-15 23:17:31.000000000,"[{'_account_id': 9029}, {'_account_id': 19134}, {'_account_id': 19184}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 06:17:51.000000000', 'files': ['vitrage/entity_graph/graph_init.py', 'vitrage/entity_graph/driver_exec.py', 'vitrage/datasources/driver_base.py'], 'web_link': 'https://opendev.org/openstack/vitrage/commit/f33fc74fc7e2e8b968a8f69f6e4f4a1ee70d0c15', 'message': 'Run vertices cleanup at the end of get_all\n\nChange-Id: Idc2c6ecd713cdea3986009bdc50e85a9c88d57b9\n(cherry picked from commit 6f271598f8eeac631bbf151ee9e7a34484ad88ad)\n'}]",0,688625,f33fc74fc7e2e8b968a8f69f6e4f4a1ee70d0c15,30,4,1,19134,,,0,"Run vertices cleanup at the end of get_all

Change-Id: Idc2c6ecd713cdea3986009bdc50e85a9c88d57b9
(cherry picked from commit 6f271598f8eeac631bbf151ee9e7a34484ad88ad)
",git fetch https://review.opendev.org/openstack/vitrage refs/changes/25/688625/1 && git format-patch -1 --stdout FETCH_HEAD,"['vitrage/entity_graph/graph_init.py', 'vitrage/entity_graph/driver_exec.py', 'vitrage/datasources/driver_base.py']",3,f33fc74fc7e2e8b968a8f69f6e4f4a1ee70d0c15,eyalb/consistency-stable/train, entity[VProps.VITRAGE_DATASOURCE_NAME] = cls._datasource_name,,51,2
openstack%2Fswift~stable%2Ftrain~I5d9f86784a3e39577ab010d29d8d03b26ffda357,openstack/swift,stable/train,I5d9f86784a3e39577ab010d29d8d03b26ffda357,py3: fix swift-account-audit,MERGED,2019-10-15 20:04:40.000000000,2019-10-15 23:08:43.000000000,2019-10-15 23:07:18.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 20:04:40.000000000', 'files': ['bin/swift-account-audit'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd9f5747c9db7b4b28e778547852c58d866e0ca4', 'message': ""py3: fix swift-account-audit\n\nPreviously, we'd get a KeyError trying to read headers.\n\nChange-Id: I5d9f86784a3e39577ab010d29d8d03b26ffda357\n(cherry picked from commit 2f4fe56ca484c0efc11736aa323b2e63199e3513)\n""}]",0,688808,dd9f5747c9db7b4b28e778547852c58d866e0ca4,7,2,1,15343,,,0,"py3: fix swift-account-audit

Previously, we'd get a KeyError trying to read headers.

Change-Id: I5d9f86784a3e39577ab010d29d8d03b26ffda357
(cherry picked from commit 2f4fe56ca484c0efc11736aa323b2e63199e3513)
",git fetch https://review.opendev.org/openstack/swift refs/changes/08/688808/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-account-audit'],1,dd9f5747c9db7b4b28e778547852c58d866e0ca4,," responses[node['id']] = { h.lower(): v for h, v in resp.getheaders()} responses[node_id] = [ {h.lower(): v for h, v in resp.getheaders()}, []]"," responses[node['id']] = dict(resp.getheaders()) responses[node_id] = [dict(resp.getheaders()), []]",4,2
openstack%2Fswift~stable%2Ftrain~I1fbeb873d180891757db88a59bbb2db6bb547276,openstack/swift,stable/train,I1fbeb873d180891757db88a59bbb2db6bb547276,Imported Translations from Zanata,MERGED,2019-10-15 09:53:24.000000000,2019-10-15 22:59:20.000000000,2019-10-15 22:56:55.000000000,"[{'_account_id': 6547}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 09:53:24.000000000', 'files': ['swift/locale/ko_KR/LC_MESSAGES/swift.po'], 'web_link': 'https://opendev.org/openstack/swift/commit/59f580fa6762e714f9d5aaed0dcfb6f31e2603c2', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I1fbeb873d180891757db88a59bbb2db6bb547276\n'}]",0,688667,59f580fa6762e714f9d5aaed0dcfb6f31e2603c2,9,3,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I1fbeb873d180891757db88a59bbb2db6bb547276
",git fetch https://review.opendev.org/openstack/swift refs/changes/67/688667/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/locale/ko_KR/LC_MESSAGES/swift.po'],1,59f580fa6762e714f9d5aaed0dcfb6f31e2603c2,zanata/translations,"# SeongSoo Cho <ppiyakk2@printf.kr>, 2019. #zanata""POT-Creation-Date: 2019-10-05 19:15+0000\n""""PO-Revision-Date: 2019-10-14 12:04+0000\n"" ""Last-Translator: SeongSoo Cho <ppiyakk2@printf.kr>\n""msgid ""%(server)s #%(number)d not running (%(conf)s)"" msgstr ""%(server)s #%(number)d가 실행 중이 아님 (%(conf)s)"" #, python-format msgid ""%(server)s (%(pid)s) appears to have stopped"" msgstr ""%(server)s (%(pid)s) 이(가) 중지됨"" #, python-format msgid ""%(server)s running (%(pid)s - %(conf)s)"" msgstr ""%(server)s 실행 중 (%(pid)s - %(conf)s)"" #, python-format msgid ""%(server)s running (%(pid)s - %(pid_file)s)"" msgstr ""%(server)s 실행 중 (%(pid)s - %(pid_file)s)"" #, python-formatmsgid ""%(type)s: %(value)s"" msgstr ""%(type)s: %(value)s"" #, python-formatmsgid ""Audit Failed for %(path)s: %(err)s"" msgstr ""%(path)s 검사 실패: %(err)s"" #, python-format msgid ""Audit passed for %s"" msgstr ""%s 검사 완료"" #, python-formatmsgid ""Connection reset"" msgstr ""Connection reset"" msgid ""Could not load %(conf)r: %(error)s"" msgstr ""%(conf)r를 로드할 수 없음: %(error)s"" #, python-formatmsgid """" ""ERROR There are not enough handoff nodes to reach replica count for "" ""partition %s"" msgstr """" ""오류 - 파티션 %s 의 복제 수 만큼 충분한 handoff 노드가 존재하지 않습니다"" #, python-format#, python-format msgid ""Error in %(conf)r with mtime_check_interval: %(error)s"" msgstr ""%(conf)r에서 mtime_check_interval 오류 발생: %(error)s"" #, python-format msgid ""Error sending UDP message to %(target)r: %(err)s"" msgstr ""%(target)r에 UDP 메시지 전송 중 에러 발생: %(err)s"" msgid ""Invalid swift_bytes"" msgstr ""swift_bytes 가 유효하지 않습니다."" msgid ""More than one part in a single-part response?"" msgstr ""단일 파트에서 하나 이상의 응답이 존재 합니까?"" msgid ""Network unreachable"" msgstr ""Network unreachable"" msgid ""No cluster endpoint for %(realm)r %(cluster)r"" msgstr ""%(realm)r %(cluster)r 에 대한 클러스터 엔드포인트가 없음"" #, python-formatmsgid ""Quarantined %(db_dir)s to %(quar_path)s due to %(reason)s"" msgstr ""%(db_dir)s을 %(quar_path)s로 격리합니다. 이유: %(reason)s"" #, python-formatmsgid ""Signal %(server)s pid: %(pid)s signal: %(signal)s"" msgstr ""Signal %(server)s pid: %(pid)s signal: %(signal)s"" #, python-formatmsgid ""Skipping %(datadir)s because %(err)s"" msgstr ""%(datadir)s 을 건너 뜀: %(err)s"" #, python-formatmsgid ""Unable to find %(section)s config section in %(conf)s"" msgstr ""%(conf)s 에서 %(section)s 설정 섹션을 찾을 수 없음"" #, python-format#, python-format msgid ""Unable to locate config number %(number)s for %(server)s"" msgstr ""%(server)s 의 구성 번호 %(number)s를 찾을 수 없음"" msgid ""Unable to perform fsync() on directory %(dir)s: %(err)s"" msgstr ""디렉토리에서 fsync() 를 수행할 수 없음 %(dir)s: %(err)s"" #, python-formatmsgid """" ""WARNING: object-expirer.conf is deprecated. Move object-expirers' "" ""configuration into object-server.conf."" msgstr """" ""주의 - object-expirer.conf는 deprecate 되었습니다. object-expirer 설정을 "" ""object-server.conf 로 옮겨주시기 바랍니다."" #, python-format msgid ""Waited %(kill_wait)s seconds for %(server)s to die; giving up"" msgstr ""%(kill_wait)s초 동안 %(server)s의 종료를 대기함, 포기하는 중"" #, python-format msgid ""Waited %(kill_wait)s seconds for %(server)s to die; killing"" msgstr ""%(kill_wait)s초 동안 %(server)s을(를) 대기합니다, 강제 종료 중"" ","""POT-Creation-Date: 2019-10-03 19:48+0000\n""""PO-Revision-Date: 2016-04-12 06:43+0000\n"" ""Last-Translator: Copied by Zanata <copied-by-zanata@zanata.org>\n""",106,3
openstack%2Fswift~master~I799e288f66230a7847a13b7f303e4cd8e63eea59,openstack/swift,master,I799e288f66230a7847a13b7f303e4cd8e63eea59,"Use `==` to compare against the empty string, not `is`",MERGED,2019-10-15 00:49:53.000000000,2019-10-15 22:58:28.000000000,2019-10-15 22:56:44.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 00:49:53.000000000', 'files': ['swift/common/daemon.py', 'swift/common/middleware/acl.py', 'test/unit/common/middleware/s3api/test_s3request.py', 'test/unit/common/test_wsgi.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/3bd5653873bbb0ddc154481c3804ce6d801664b3', 'message': 'Use `==` to compare against the empty string, not `is`\n\npy38 will start complaining like\n\n   SyntaxWarning: ""is"" with a literal. Did you mean ""==""?\n\nChange-Id: I799e288f66230a7847a13b7f303e4cd8e63eea59\n'}]",0,688589,3bd5653873bbb0ddc154481c3804ce6d801664b3,14,3,1,15343,,,0,"Use `==` to compare against the empty string, not `is`

py38 will start complaining like

   SyntaxWarning: ""is"" with a literal. Did you mean ""==""?

Change-Id: I799e288f66230a7847a13b7f303e4cd8e63eea59
",git fetch https://review.opendev.org/openstack/swift refs/changes/89/688589/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/daemon.py', 'swift/common/middleware/acl.py', 'test/unit/common/middleware/s3api/test_s3request.py', 'test/unit/common/test_wsgi.py']",4,3bd5653873bbb0ddc154481c3804ce6d801664b3,," self.assertNotEqual(os.environ['TZ'], '')", self.assertTrue(os.environ['TZ'] is not ''),4,4
openstack%2Fswift~stable%2Ftrain~I6da047716c05e4f2a9e1e74ca19afb62e812d172,openstack/swift,stable/train,I6da047716c05e4f2a9e1e74ca19afb62e812d172,Fix kms_keymaster under Python 3,MERGED,2019-10-15 17:45:33.000000000,2019-10-15 22:58:17.000000000,2019-10-15 22:56:37.000000000,"[{'_account_id': 6476}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:45:33.000000000', 'files': ['swift/common/middleware/crypto/keymaster.py', 'swift/common/middleware/crypto/kms_keymaster.py', 'test/unit/common/middleware/crypto/test_kms_keymaster.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/dd51658949ca937abd9d87a5184704cd48135682', 'message': ""Fix kms_keymaster under Python 3\n\nDepending on how the key was stored in Barbican, it may come out of\nCastellan as a native string, which would not be suitable on Python 3.\nNow, check that the secret is a byte string, and if it isn't, encode as\nUTF-8 (to match Barbican's internal encoding).\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n(cherry picked from commit 85d3658d6297efbe9a588d1b4364a2a68f9e5bb7)\n""}]",0,688767,dd51658949ca937abd9d87a5184704cd48135682,7,3,1,15343,,,0,"Fix kms_keymaster under Python 3

Depending on how the key was stored in Barbican, it may come out of
Castellan as a native string, which would not be suitable on Python 3.
Now, check that the secret is a byte string, and if it isn't, encode as
UTF-8 (to match Barbican's internal encoding).

Change-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172
Closes-Bug: #1847755
(cherry picked from commit 85d3658d6297efbe9a588d1b4364a2a68f9e5bb7)
",git fetch https://review.opendev.org/openstack/swift refs/changes/67/688767/1 && git format-patch -1 --stdout FETCH_HEAD,"['swift/common/middleware/crypto/keymaster.py', 'swift/common/middleware/crypto/kms_keymaster.py', 'test/unit/common/middleware/crypto/test_kms_keymaster.py']",3,dd51658949ca937abd9d87a5184704cd48135682,bug/1847755-stable/train," if 'unicode' in key_id: key_str = key_id[0] * 32 else: key_str = (str(key_id[0]) * 32).encode('utf8') 'key_id_baz': 'zz-valid_unicode_kms_key_id-123456', 'key_id_non_ascii': u'\N{SNOWMAN}_unicode_key_id', 'bar': b'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb', 'baz': b'zzzzzzzzzzzzzzzzzzzzzzzzzzzzzzzz', 'non_ascii': b'\xe2\x98\x83' * 32}", key_str = (str(key_id[0]) * 32).encode('utf8') 'bar': b'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'},17,3
openstack%2Frequirements~stable%2Ftrain~I11388348d82e3be3bfe96d9d3b655e16a8b97bbf,openstack/requirements,stable/train,I11388348d82e3be3bfe96d9d3b655e16a8b97bbf,update constraint for tempest to new release 22.1.0,MERGED,2019-10-15 16:35:23.000000000,2019-10-15 22:56:53.000000000,2019-10-15 22:56:53.000000000,"[{'_account_id': 14288}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 16:35:23.000000000', 'files': ['upper-constraints.txt'], 'web_link': 'https://opendev.org/openstack/requirements/commit/7790dc55d28cd3e1cb3c9d42d0e7c91b581a742a', 'message': 'update constraint for tempest to new release 22.1.0\n\nChange-Id: I11388348d82e3be3bfe96d9d3b655e16a8b97bbf\nmeta:version: 22.1.0\nmeta:diff-start: -\nmeta:series: train\nmeta:release-type: release\nmeta:pypi: yes\nmeta:first: no\nmeta:release:Author: Ghanshyam Mann <gmann@ghanshyammann.com>\nmeta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>\nmeta:release:Change-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541\nmeta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>\nmeta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>\nmeta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>\n'}]",0,688752,7790dc55d28cd3e1cb3c9d42d0e7c91b581a742a,7,2,1,11131,,,0,"update constraint for tempest to new release 22.1.0

Change-Id: I11388348d82e3be3bfe96d9d3b655e16a8b97bbf
meta:version: 22.1.0
meta:diff-start: -
meta:series: train
meta:release-type: release
meta:pypi: yes
meta:first: no
meta:release:Author: Ghanshyam Mann <gmann@ghanshyammann.com>
meta:release:Commit: Ghanshyam Mann <gmann@ghanshyammann.com>
meta:release:Change-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541
meta:release:Code-Review+2: Thierry Carrez <thierry@openstack.org>
meta:release:Code-Review+2: Sean McGinnis <sean.mcginnis@gmail.com>
meta:release:Workflow+1: Sean McGinnis <sean.mcginnis@gmail.com>
",git fetch https://review.opendev.org/openstack/requirements refs/changes/52/688752/1 && git format-patch -1 --stdout FETCH_HEAD,['upper-constraints.txt'],1,7790dc55d28cd3e1cb3c9d42d0e7c91b581a742a,new-release,tempest===22.1.0,tempest===22.0.0,1,1
openstack%2Fswift~stable%2Ftrain~I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81,openstack/swift,stable/train,I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81,py3: fix swift-dispersion-populate,MERGED,2019-10-15 17:45:41.000000000,2019-10-15 22:56:42.000000000,2019-10-15 22:56:41.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:45:41.000000000', 'files': ['bin/swift-dispersion-populate'], 'web_link': 'https://opendev.org/openstack/swift/commit/203f13163a0d92b5a67decb7334face3353867a5', 'message': 'py3: fix swift-dispersion-populate\n\nChange-Id: I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81\n(cherry picked from commit 4c66596e630ee63cf2cd54d216c8e443203e59fe)\n'}]",0,688768,203f13163a0d92b5a67decb7334face3353867a5,6,2,1,15343,,,0,"py3: fix swift-dispersion-populate

Change-Id: I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81
(cherry picked from commit 4c66596e630ee63cf2cd54d216c8e443203e59fe)
",git fetch https://review.opendev.org/openstack/swift refs/changes/68/688768/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-dispersion-populate'],1,203f13163a0d92b5a67decb7334face3353867a5,,"import ioimport six data = io.BytesIO(obj if six.PY2 else obj.encode('utf8')) conn.put_object(container, obj, data,","from six.moves import cStringIO as StringIO conn.put_object(container, obj, StringIO(obj),",4,2
openstack%2Fswift~stable%2Ftrain~I82edbf1ddcc28f86e97405d21db0b96249412eac,openstack/swift,stable/train,I82edbf1ddcc28f86e97405d21db0b96249412eac,py3: Fix swift-recon,MERGED,2019-10-15 17:45:48.000000000,2019-10-15 22:56:40.000000000,2019-10-15 22:56:40.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:45:48.000000000', 'files': ['swift/cli/recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/c48f33f2f0f297e2181e14c386041176f9c7c958', 'message': ""py3: Fix swift-recon\n\nAvoid things like\n\n    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n\nChange-Id: I82edbf1ddcc28f86e97405d21db0b96249412eac\n(cherry picked from commit 2edcd0b7b9dd02a041fd1452ea17efda5f27f21c)\n""}]",0,688769,c48f33f2f0f297e2181e14c386041176f9c7c958,7,3,1,15343,,,0,"py3: Fix swift-recon

Avoid things like

    TypeError: '<' not supported between instances of 'NoneType' and 'int'

Change-Id: I82edbf1ddcc28f86e97405d21db0b96249412eac
(cherry picked from commit 2edcd0b7b9dd02a041fd1452ea17efda5f27f21c)
",git fetch https://review.opendev.org/openstack/swift refs/changes/69/688769/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/recon.py'],1,c48f33f2f0f297e2181e14c386041176f9c7c958,, if last is None: continue,,2,0
openstack%2Fswift~stable%2Ftrain~Iae332bb58388b5521445e75beba6ee2e9f06bfa6,openstack/swift,stable/train,Iae332bb58388b5521445e75beba6ee2e9f06bfa6,py3: Fix swift-drive-audit,MERGED,2019-10-15 17:45:23.000000000,2019-10-15 22:56:38.000000000,2019-10-15 22:56:38.000000000,"[{'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:45:23.000000000', 'files': ['bin/swift-drive-audit', 'etc/drive-audit.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/bcb2016673434e720e92fe4e75969c3b518a92c8', 'message': 'py3: Fix swift-drive-audit\n\nWalking through the kernel logs backwards requires that we open them\nin binary mode. Add a new option to allow users to specify which\nencoding should be used to interpret those logs; default to the same\nencoding that open() uses for its default.\n\nChange-Id: Iae332bb58388b5521445e75beba6ee2e9f06bfa6\nCloses-Bug: #1847955\n(cherry picked from commit 405a2b2a55866b74f196ad81eaafedeee4615fa8)\n'}]",0,688766,bcb2016673434e720e92fe4e75969c3b518a92c8,6,2,1,15343,,,0,"py3: Fix swift-drive-audit

Walking through the kernel logs backwards requires that we open them
in binary mode. Add a new option to allow users to specify which
encoding should be used to interpret those logs; default to the same
encoding that open() uses for its default.

Change-Id: Iae332bb58388b5521445e75beba6ee2e9f06bfa6
Closes-Bug: #1847955
(cherry picked from commit 405a2b2a55866b74f196ad81eaafedeee4615fa8)
",git fetch https://review.opendev.org/openstack/swift refs/changes/66/688766/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-drive-audit', 'etc/drive-audit.conf-sample']",2,bcb2016673434e720e92fe4e75969c3b518a92c8,bug/1847955-stable/train,"# On Python 3, the encoding to use when reading the log file. Defaults # to the result of locale.getpreferredencoding(), like Python's open(). # log_file_encoding = auto #",,17,4
openstack%2Fmanila-ui~stable%2Fstein~I5fb9cef577b109530fde9a4bafe930ea05f3fed8,openstack/manila-ui,stable/stein,I5fb9cef577b109530fde9a4bafe930ea05f3fed8,Updated to get quotas data for Modify Quotas dialog Share tab,MERGED,2019-10-15 19:59:22.000000000,2019-10-15 22:55:49.000000000,2019-10-15 22:54:32.000000000,"[{'_account_id': 1916}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 11880}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:59:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/c4e4ac61ffc6fe53c35b1c60c528a2838e9da814', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n'}, {'number': 2, 'created': '2019-10-15 20:51:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/fb6daa507841b266df89b0261a73728c4fcd0917', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)\n'}, {'number': 3, 'created': '2019-10-15 21:55:58.000000000', 'files': ['releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/tests/dashboards/identity/__init__.py', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/cc52163a36cd4863ebe96bfef0a163b4190d01b2', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)\n'}]",1,688804,cc52163a36cd4863ebe96bfef0a163b4190d01b2,17,8,3,14892,,,0,"Updated to get quotas data for Modify Quotas dialog Share tab

Current Modfiy Quotas action of a project in Identity->Projects
for manila ui does not get quotas data for the project. If user
updated quotas for manila ui, the saved data will not be shown
in the Modify Quotas dialog Share tab.

This commit includes:
1) Added a call to get quotas data and also maps the data
fields retuned to the UI data fields.
2) Added unit tests.
3) Added a release note.

Change-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8
Closes-bug: #1842119
Depends-on: https://review.opendev.org/#/c/679513/
(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)
(cherry picked from commit 7f0c6ad276d42289c61761e9cdcaa3720f7be764)
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/04/688804/2 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/tests/dashboards/identity/__init__.py', 'releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py']",7,c4e4ac61ffc6fe53c35b1c60c528a2838e9da814,bug/1842119-stable/stein,"import logging from horizon import exceptionsLOG = logging.getLogger(__name__) def prepare_action_context(self, request, context): try: quotas = api_manila.tenant_quota_get( request, context['project_id']) for field in api_manila.MANILA_QUOTA_FIELDS: # Resolve mismatch UI field names and data field names. data_field = api_manila.MANILA_QUOTA_FIELDS_DATA_MAP[field] context[field] = quotas.get(data_field).limit except Exception as ex: LOG.exception(ex) exceptions.handle(request, _('Unable to retrieve share quotas.')) return context ",,137,0
openstack%2Fkolla-ansible~stable%2Fstein~Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,openstack/kolla-ansible,stable/stein,Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,Fix CI failures,MERGED,2019-10-15 15:58:28.000000000,2019-10-15 22:12:07.000000000,2019-10-15 22:10:49.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-15 15:58:28.000000000', 'files': ['.yamllint', 'tests/pre.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/28da853830f2107808b537167a95bd89acf2254e', 'message': 'Fix CI failures\n\n1. Fix yamllint errors in .yamllint file(!)\n\nYAML lint is currently failling on its own configuration file,\n.yamllint. This change fixes the issues.\n\n2. Run bindep role in Zuul jobs\n\nThis fixes an issue where libffi is not available.\n\nChange-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f\n(cherry picked from commit e3e5f7f20f4b067142ffecacbe47789eed1d0e3b)\n'}]",0,688744,28da853830f2107808b537167a95bd89acf2254e,9,3,1,14826,,,0,"Fix CI failures

1. Fix yamllint errors in .yamllint file(!)

YAML lint is currently failling on its own configuration file,
.yamllint. This change fixes the issues.

2. Run bindep role in Zuul jobs

This fixes an issue where libffi is not available.

Change-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f
(cherry picked from commit e3e5f7f20f4b067142ffecacbe47789eed1d0e3b)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/44/688744/1 && git format-patch -1 --stdout FETCH_HEAD,"['.yamllint', 'tests/pre.yml']",2,28da853830f2107808b537167a95bd89acf2254e,, roles: - bindep - multi-node-firewall, roles: - multi-node-firewall,7,5
openstack%2Fkolla-ansible~stable%2Frocky~Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,openstack/kolla-ansible,stable/rocky,Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,Fix CI failures,MERGED,2019-10-15 16:00:33.000000000,2019-10-15 22:02:26.000000000,2019-10-15 22:01:08.000000000,"[{'_account_id': 22348}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-15 16:00:33.000000000', 'files': ['.yamllint', 'tests/pre.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/5dc2ebd7851135ef972b320d8946c0cc04474a50', 'message': 'Fix CI failures\n\n1. Fix yamllint errors in .yamllint file(!)\n\nYAML lint is currently failling on its own configuration file,\n.yamllint. This change fixes the issues.\n\n2. Run bindep role in Zuul jobs\n\nThis fixes an issue where libffi is not available.\n\nChange-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f\n(cherry picked from commit e3e5f7f20f4b067142ffecacbe47789eed1d0e3b)\n'}]",0,688745,5dc2ebd7851135ef972b320d8946c0cc04474a50,9,3,1,14826,,,0,"Fix CI failures

1. Fix yamllint errors in .yamllint file(!)

YAML lint is currently failling on its own configuration file,
.yamllint. This change fixes the issues.

2. Run bindep role in Zuul jobs

This fixes an issue where libffi is not available.

Change-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f
(cherry picked from commit e3e5f7f20f4b067142ffecacbe47789eed1d0e3b)
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/45/688745/1 && git format-patch -1 --stdout FETCH_HEAD,"['.yamllint', 'tests/pre.yml']",2,5dc2ebd7851135ef972b320d8946c0cc04474a50,, roles: - bindep - multi-node-firewall, roles: - multi-node-firewall,7,5
openstack%2Fproject-config~master~Ifdc3501b498c34db492bd6d752f1d078bc4d046b,openstack/project-config,master,Ifdc3501b498c34db492bd6d752f1d078bc4d046b,Remove opensuse-423 from nodepool's config,ABANDONED,2019-10-15 21:33:20.000000000,2019-10-15 21:37:19.000000000,,[],"[{'number': 1, 'created': '2019-10-15 21:33:20.000000000', 'files': ['nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/48b0b7311d6938fd431c2f41150847459c4ec38e', 'message': ""Remove opensuse-423 from nodepool's config\n\nOpenSuse 42.3 has been EOL since June. We've cleaned up consumers of\nthis image in the Zuul config and now we can remove it from nodepool.\n\nDepends-On: https://review.opendev.org/#/c/688442/\nChange-Id: Ifdc3501b498c34db492bd6d752f1d078bc4d046b\n""}]",0,688820,48b0b7311d6938fd431c2f41150847459c4ec38e,2,0,1,4146,,,0,"Remove opensuse-423 from nodepool's config

OpenSuse 42.3 has been EOL since June. We've cleaned up consumers of
this image in the Zuul config and now we can remove it from nodepool.

Depends-On: https://review.opendev.org/#/c/688442/
Change-Id: Ifdc3501b498c34db492bd6d752f1d078bc4d046b
",git fetch https://review.opendev.org/openstack/project-config refs/changes/20/688820/1 && git format-patch -1 --stdout FETCH_HEAD,"['nodepool/nl04.openstack.org.yaml', 'nodepool/nodepool.yaml', 'nodepool/nl03.openstack.org.yaml', 'nodepool/nl02.openstack.org.yaml', 'nodepool/nl01.openstack.org.yaml']",5,48b0b7311d6938fd431c2f41150847459c4ec38e,remove-opensuse-423,, - name: opensuse-423 min-ready: 1 - name: opensuse-423 config-drive: true - name: opensuse-423 min-ram: 8000 flavor-name: 'Performance' diskimage: opensuse-423 key-name: infra-root-keys-2018-06-15 - name: opensuse-423,0,89
openstack%2Fmanila-ui~stable%2Ftrain~I5fb9cef577b109530fde9a4bafe930ea05f3fed8,openstack/manila-ui,stable/train,I5fb9cef577b109530fde9a4bafe930ea05f3fed8,Updated to get quotas data for Modify Quotas dialog Share tab,MERGED,2019-10-15 19:33:08.000000000,2019-10-15 21:37:08.000000000,2019-10-15 21:35:32.000000000,"[{'_account_id': 1916}, {'_account_id': 7102}, {'_account_id': 11880}, {'_account_id': 12156}, {'_account_id': 16643}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 19:33:08.000000000', 'files': ['releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/tests/dashboards/identity/__init__.py', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/7f0c6ad276d42289c61761e9cdcaa3720f7be764', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)\n'}]",0,688792,7f0c6ad276d42289c61761e9cdcaa3720f7be764,9,6,1,14892,,,0,"Updated to get quotas data for Modify Quotas dialog Share tab

Current Modfiy Quotas action of a project in Identity->Projects
for manila ui does not get quotas data for the project. If user
updated quotas for manila ui, the saved data will not be shown
in the Modify Quotas dialog Share tab.

This commit includes:
1) Added a call to get quotas data and also maps the data
fields retuned to the UI data fields.
2) Added unit tests.
3) Added a release note.

Change-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8
Closes-bug: #1842119
Depends-on: https://review.opendev.org/#/c/679513/
(cherry picked from commit c763ebe6cd89657aa820ea14774fa3c95e4d0a6b)
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/92/688792/1 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/tests/dashboards/identity/__init__.py', 'releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py']",7,7f0c6ad276d42289c61761e9cdcaa3720f7be764,bug/1842119-stable/train,"import logging from horizon import exceptionsLOG = logging.getLogger(__name__) def prepare_action_context(self, request, context): try: quotas = api_manila.tenant_quota_get( request, context['project_id']) for field in api_manila.MANILA_QUOTA_FIELDS: # Resolve mismatch UI field names and data field names. data_field = api_manila.MANILA_QUOTA_FIELDS_DATA_MAP[field] context[field] = quotas.get(data_field).limit except Exception as ex: LOG.exception(ex) exceptions.handle(request, _('Unable to retrieve share quotas.')) return context ",,137,0
openstack%2Fdevstack~stable%2Frocky~I8c41325189f7b9e7a90d51d014bdbfc7b58371e8,openstack/devstack,stable/rocky,I8c41325189f7b9e7a90d51d014bdbfc7b58371e8,Remove openSUSE Leap 42.3 jobs,MERGED,2019-10-15 05:44:42.000000000,2019-10-15 21:11:35.000000000,2019-10-15 21:11:35.000000000,"[{'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 7118}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 05:44:42.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/devstack/commit/a855618447fb29cf4399f5e918120f265ed11b60', 'message': ""Remove openSUSE Leap 42.3 jobs\n\nopenSUSE Leap 42.3 is EOL since June 2019, let's remove remaining jobs\nso that we can remove Leap 42.3 from Opendev infrastructure.\n\nChange-Id: I8c41325189f7b9e7a90d51d014bdbfc7b58371e8\n""}]",0,688619,a855618447fb29cf4399f5e918120f265ed11b60,15,5,1,6547,,,0,"Remove openSUSE Leap 42.3 jobs

openSUSE Leap 42.3 is EOL since June 2019, let's remove remaining jobs
so that we can remove Leap 42.3 from Opendev infrastructure.

Change-Id: I8c41325189f7b9e7a90d51d014bdbfc7b58371e8
",git fetch https://review.opendev.org/openstack/devstack refs/changes/19/688619/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,a855618447fb29cf4399f5e918120f265ed11b60,goodbye_42.3,, name: devstack-single-node-opensuse-423 nodes: - name: controller label: opensuse-423 groups: - name: tempest nodes: - controller - nodeset: name: devstack-platform-opensuse-423 parent: tempest-full description: openSUSE 43.2 platform test nodeset: devstack-single-node-opensuse-423 voting: false - job: - devstack-platform-opensuse-423,0,18
openstack%2Ftripleo-heat-templates~master~Iec607ab6a5ba5b5156009073a264fa88ac59331e,openstack/tripleo-heat-templates,master,Iec607ab6a5ba5b5156009073a264fa88ac59331e,Deprecate kubespray kubernetes install,MERGED,2019-10-10 20:06:56.000000000,2019-10-15 21:09:14.000000000,2019-10-15 21:06:29.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-10 20:06:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dc6a138b2dedfed06de31c2b94e1bc99b5f6ffb7', 'message': ""Deprecate kubespray kubernetes install\n\nWe haven't tested this in many cycles and is not currently being\npersued as a supported service to install via TripleO.\n\nChange-Id: Iec607ab6a5ba5b5156009073a264fa88ac59331e\n""}, {'number': 2, 'created': '2019-10-10 22:08:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ce6227e59b2887eb4526cd6863160b7e01caf90f', 'message': ""Deprecate kubespray kubernetes install\n\nWe haven't tested this in many cycles and is not currently being\npersued as a supported service to install via TripleO.\n\nChange-Id: Iec607ab6a5ba5b5156009073a264fa88ac59331e\n""}, {'number': 3, 'created': '2019-10-15 12:16:42.000000000', 'files': ['releasenotes/notes/deprecate-kubernetes-services-69ca5ec733d24644.yaml', 'environments/kubernetes.yaml', 'overcloud-resource-registry-puppet.j2.yaml', 'zuul.d/layout.yaml', 'deployment/deprecated/kubernetes/kubernetes-worker-baremetal-ansible.yaml', 'deployment/deprecated/kubernetes/kubernetes-master-baremetal-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4b352b4ca483762c0532ba7c98a0af0397212aaf', 'message': ""Deprecate kubespray kubernetes install\n\nWe haven't tested this in many cycles and is not currently being\npersued as a supported service to install via TripleO.\n\nChange-Id: Iec607ab6a5ba5b5156009073a264fa88ac59331e\n""}]",0,687974,4b352b4ca483762c0532ba7c98a0af0397212aaf,16,3,3,14985,,,0,"Deprecate kubespray kubernetes install

We haven't tested this in many cycles and is not currently being
persued as a supported service to install via TripleO.

Change-Id: Iec607ab6a5ba5b5156009073a264fa88ac59331e
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/74/687974/3 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/deprecate-kubernetes-services-69ca5ec733d24644.yaml', 'environments/kubernetes.yaml', 'zuul.d/layout.yaml', 'deployment/deprecated/kubernetes/kubernetes-worker-baremetal-ansible.yaml', 'deployment/deprecated/kubernetes/kubernetes-master-baremetal-ansible.yaml']",5,dc6a138b2dedfed06de31c2b94e1bc99b5f6ffb7,deprecate-k8s,,,7,3
openstack%2Fheat~stable%2Fstein~I6de88e687ff95432ddbd0547a7f5759e18d7749e,openstack/heat,stable/stein,I6de88e687ff95432ddbd0547a7f5759e18d7749e,Fix the wrong time unit for OS::Octavia::HealthMonitor,MERGED,2019-09-30 03:34:25.000000000,2019-10-15 21:03:18.000000000,2019-10-15 21:00:09.000000000,"[{'_account_id': 4257}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-30 03:34:25.000000000', 'files': ['heat/engine/resources/openstack/octavia/health_monitor.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/e109d6d4968bde151cbcaddf31be8d11ead2f492', 'message': ""Fix the wrong time unit for OS::Octavia::HealthMonitor\n\nUnit of both 'delay' and 'timeout' should be seconds based on Octavia\nAPI doc\nhttps://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=create-health-monitor-detail#id105\n\nChange-Id: I6de88e687ff95432ddbd0547a7f5759e18d7749e\nStory: 2006637\nTask: 36852\n(cherry picked from commit ad841b4483eeba9dfd0ccd8f8b4c5d5fd3e15cc1)\n""}]",0,685637,e109d6d4968bde151cbcaddf31be8d11ead2f492,8,2,1,12404,,,0,"Fix the wrong time unit for OS::Octavia::HealthMonitor

Unit of both 'delay' and 'timeout' should be seconds based on Octavia
API doc
https://docs.openstack.org/api-ref/load-balancer/v2/index.html?expanded=create-health-monitor-detail#id105

Change-Id: I6de88e687ff95432ddbd0547a7f5759e18d7749e
Story: 2006637
Task: 36852
(cherry picked from commit ad841b4483eeba9dfd0ccd8f8b4c5d5fd3e15cc1)
",git fetch https://review.opendev.org/openstack/heat refs/changes/37/685637/1 && git format-patch -1 --stdout FETCH_HEAD,['heat/engine/resources/openstack/octavia/health_monitor.py'],1,e109d6d4968bde151cbcaddf31be8d11ead2f492,fix-unit-stable/stein, _('The minimum time in seconds between regular connections ' _('Maximum number of seconds for a monitor to wait for a ', _('The minimum time in milliseconds between regular connections ' _('Maximum number of milliseconds for a monitor to wait for a ',2,2
openstack%2Fheat~stable%2Fstein~I5d8fc5977014b196c34f4a59a30a7525bc778359,openstack/heat,stable/stein,I5d8fc5977014b196c34f4a59a30a7525bc778359,Add dedicated auth endpoint config for servers,MERGED,2019-08-23 06:46:34.000000000,2019-10-15 21:01:58.000000000,2019-10-15 21:00:01.000000000,"[{'_account_id': 4257}, {'_account_id': 6873}, {'_account_id': 8833}, {'_account_id': 11904}, {'_account_id': 12404}, {'_account_id': 12898}, {'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 27427}, {'_account_id': 28008}, {'_account_id': 28619}, {'_account_id': 29865}]","[{'number': 1, 'created': '2019-08-23 06:46:34.000000000', 'files': ['heat/engine/resources/signal_responder.py', 'heat/engine/clients/os/keystone/fake_keystoneclient.py', 'heat/tests/clients/test_heat_client.py', 'heat/engine/resources/server_base.py', 'releasenotes/notes/add-dedicated-auth-endpoint-config-for-servers-b20f7eb351f619d0.yaml', 'heat/common/config.py', 'heat/engine/clients/os/keystone/heat_keystoneclient.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/35ef93d037baf4e704f23ee20f58d11b1d4ccbe7', 'message': 'Add dedicated auth endpoint config for servers\n\nAdded a new config option to specify the keystone authentication\nendpoint to pass into cloud-init data.\n\nHeat code currently has several different methods of retrieving the\nkeystone endpoint to embed into cloud-init data for created\nservers. This data is currently read from several different parts\nof the heat config file rather than the service catalog which results\nin URLs being passed which are appropriate for the heat service rather\nthan the server. In particular there can be misconfiguration of\nservers due to deployments which separate the internal and\nexternal API endpoints.\n\nThis patch introduces a new config variable\nserver_keystone_endpoint_type which if set\nreads the keystone endpoint directly from the service catalog,\nif it is unset the original behavior is unchanged.\n\nstory: 2004808\ntask:  28967\nstory: 2004524\nChange-Id: I5d8fc5977014b196c34f4a59a30a7525bc778359\n(cherry picked from commit 5ba3b608741a0f00744c87b016185a6d845a34b9)\n'}]",1,678162,35ef93d037baf4e704f23ee20f58d11b1d4ccbe7,15,12,1,25023,,,0,"Add dedicated auth endpoint config for servers

Added a new config option to specify the keystone authentication
endpoint to pass into cloud-init data.

Heat code currently has several different methods of retrieving the
keystone endpoint to embed into cloud-init data for created
servers. This data is currently read from several different parts
of the heat config file rather than the service catalog which results
in URLs being passed which are appropriate for the heat service rather
than the server. In particular there can be misconfiguration of
servers due to deployments which separate the internal and
external API endpoints.

This patch introduces a new config variable
server_keystone_endpoint_type which if set
reads the keystone endpoint directly from the service catalog,
if it is unset the original behavior is unchanged.

story: 2004808
task:  28967
story: 2004524
Change-Id: I5d8fc5977014b196c34f4a59a30a7525bc778359
(cherry picked from commit 5ba3b608741a0f00744c87b016185a6d845a34b9)
",git fetch https://review.opendev.org/openstack/heat refs/changes/62/678162/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/resources/signal_responder.py', 'heat/engine/clients/os/keystone/fake_keystoneclient.py', 'heat/tests/clients/test_heat_client.py', 'heat/engine/resources/server_base.py', 'releasenotes/notes/add-dedicated-auth-endpoint-config-for-servers-b20f7eb351f619d0.yaml', 'heat/common/config.py', 'heat/engine/clients/os/keystone/heat_keystoneclient.py']",7,35ef93d037baf4e704f23ee20f58d11b1d4ccbe7,add-public-auth-uri-stable/stein," def server_keystone_endpoint_url(self, fallback_endpoint): ks_endpoint_type = cfg.CONF.server_keystone_endpoint_type if ((ks_endpoint_type == 'public') or ( ks_endpoint_type == 'internal') or (ks_endpoint_type == 'admin')): if (hasattr(self.context, 'auth_plugin') and hasattr(self.context.auth_plugin, 'get_access')): try: auth_ref = self.context.auth_plugin.get_access( self.session) if hasattr(auth_ref, ""service_catalog""): unversioned_sc_auth_uri = ( auth_ref.service_catalog.get_urls( service_type='identity', interface=ks_endpoint_type)) if len(unversioned_sc_auth_uri) > 0: sc_auth_uri = ( unversioned_sc_auth_uri[0] + ""/v3"") return sc_auth_uri except ks_exception.Unauthorized: LOG.error(""Keystone client authentication failed"") return fallback_endpoint ",,102,4
openstack%2Fheat~stable%2Fqueens~Ic526c8039c91353e772eee7b55f1d263470c86bb,openstack/heat,stable/queens,Ic526c8039c91353e772eee7b55f1d263470c86bb,Use connect_retries when creating clients,MERGED,2019-08-24 10:41:37.000000000,2019-10-15 21:00:14.000000000,2019-10-15 21:00:13.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-08-24 10:41:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/84bdde4775d48df9c49f227e10f7ac1780274ab6', 'message': ""Use connect_retries when creating clients\n\nWhen creating session clients we should use 'connect_retries'\nfor clients that use Adapter interface. This will\nallow retries when we get ConnectTimeout errors.\n\nTask: 36331\nChange-Id: Ic526c8039c91353e772eee7b55f1d263470c86bb\n(cherry picked from commit 364716725a4767f8d9e3e5e1c76ecf4f969a6613)\n""}, {'number': 2, 'created': '2019-08-28 07:05:36.000000000', 'files': ['heat/engine/clients/os/heat_plugin.py', 'heat/engine/clients/os/manila.py', 'heat/engine/clients/os/keystone/heat_keystoneclient.py', 'heat/engine/clients/os/glance.py', 'heat/engine/clients/os/cinder.py', 'heat/tests/clients/test_heat_client.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/barbican.py', 'heat/engine/clients/os/aodh.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/engine/clients/os/magnum.py', 'heat/engine/clients/os/sahara.py', 'heat/engine/clients/os/trove.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/87cd9e59ddeeed536cd0d736f36e2eaaf9b47b90', 'message': ""Use connect_retries when creating clients\n\nWhen creating session clients we should use 'connect_retries'\nfor clients that use Adapter interface. This will\nallow retries when we get ConnectTimeout errors.\n\nTask: 36331\nChange-Id: Ic526c8039c91353e772eee7b55f1d263470c86bb\n(cherry picked from commit 364716725a4767f8d9e3e5e1c76ecf4f969a6613\n and c7cc740f307ce8ffdf36c29094c9cbce5a6c8d14)\n""}]",0,678345,87cd9e59ddeeed536cd0d736f36e2eaaf9b47b90,11,5,2,8833,,,0,"Use connect_retries when creating clients

When creating session clients we should use 'connect_retries'
for clients that use Adapter interface. This will
allow retries when we get ConnectTimeout errors.

Task: 36331
Change-Id: Ic526c8039c91353e772eee7b55f1d263470c86bb
(cherry picked from commit 364716725a4767f8d9e3e5e1c76ecf4f969a6613
 and c7cc740f307ce8ffdf36c29094c9cbce5a6c8d14)
",git fetch https://review.opendev.org/openstack/heat refs/changes/45/678345/1 && git format-patch -1 --stdout FETCH_HEAD,"['heat/engine/clients/os/heat_plugin.py', 'heat/engine/clients/os/manila.py', 'heat/engine/clients/os/keystone/heat_keystoneclient.py', 'heat/engine/clients/os/glance.py', 'heat/engine/clients/os/cinder.py', 'heat/tests/clients/test_heat_client.py', 'heat/engine/clients/os/nova.py', 'heat/engine/clients/os/barbican.py', 'heat/engine/clients/os/aodh.py', 'heat/engine/clients/os/neutron/__init__.py', 'heat/engine/clients/os/magnum.py', 'heat/engine/clients/os/sahara.py', 'heat/engine/clients/os/trove.py']",13,84bdde4775d48df9c49f227e10f7ac1780274ab6,,"from oslo_config import cfg 'connect_retries': cfg.CONF.client_retry_limit,",,23,1
openstack%2Fheat~stable%2Fqueens~Iad2e71819f4847f47dd17d3cd4afa78e6b3f52a7,openstack/heat,stable/queens,Iad2e71819f4847f47dd17d3cd4afa78e6b3f52a7,Add entry_point for oslo policy scripts,MERGED,2019-04-23 11:40:25.000000000,2019-10-15 20:42:08.000000000,2019-10-15 20:42:08.000000000,"[{'_account_id': 4257}, {'_account_id': 8833}, {'_account_id': 12404}, {'_account_id': 17685}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-04-23 11:40:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/heat/commit/04660eaa00a750d14fdde419bed1d08b87784cb4', 'message': 'Add entry_point for oslo policy scripts\n\nWith the setup.cfg entry it can  be called directly from\noslo.policy.\n\n$oslopolicy-policy-generator --namespace heat\n\nThis will get the effective policy that’s being executed.\n\nChange-Id: Iad2e71819f4847f47dd17d3cd4afa78e6b3f52a7\nStory: #2005055\nTask: 29573\n(cherry picked from commit 5bdcaeff018782a956fd8228e04ddd2169c353c6)\n'}, {'number': 2, 'created': '2019-09-26 07:18:01.000000000', 'files': ['setup.cfg', 'heat/common/policy.py'], 'web_link': 'https://opendev.org/openstack/heat/commit/d19a7c05b2246e9256fb72fb4feb3ab999cfb21d', 'message': 'Add entry_point for oslo policy scripts\n\nWith the setup.cfg entry it can  be called directly from\noslo.policy.\n\n$oslopolicy-policy-generator --namespace heat\n\nThis will get the effective policy that’s being executed.\n\nChange-Id: Iad2e71819f4847f47dd17d3cd4afa78e6b3f52a7\nStory: #2005055\nTask: 29573\n(cherry picked from commit 5bdcaeff018782a956fd8228e04ddd2169c353c6)\n'}]",0,655079,d19a7c05b2246e9256fb72fb4feb3ab999cfb21d,12,5,2,8833,,,0,"Add entry_point for oslo policy scripts

With the setup.cfg entry it can  be called directly from
oslo.policy.

$oslopolicy-policy-generator --namespace heat

This will get the effective policy that’s being executed.

Change-Id: Iad2e71819f4847f47dd17d3cd4afa78e6b3f52a7
Story: #2005055
Task: 29573
(cherry picked from commit 5bdcaeff018782a956fd8228e04ddd2169c353c6)
",git fetch https://review.opendev.org/openstack/heat refs/changes/79/655079/2 && git format-patch -1 --stdout FETCH_HEAD,"['setup.cfg', 'heat/common/policy.py']",2,04660eaa00a750d14fdde419bed1d08b87784cb4,," self.file_rules = self.enforcer.file_rules self.registered_rules = self.enforcer.registered_rulesdef get_policy_enforcer(): # This method is used by oslopolicy CLI scripts to generate policy # files from overrides on disk and defaults in code. CONF([], project='heat') return get_enforcer() ",,12,0
openstack%2Fmanila-ui~master~I5fb9cef577b109530fde9a4bafe930ea05f3fed8,openstack/manila-ui,master,I5fb9cef577b109530fde9a4bafe930ea05f3fed8,Updated to get quotas data for Modify Quotas dialog Share tab,MERGED,2019-09-04 04:21:13.000000000,2019-10-15 20:23:26.000000000,2019-10-15 19:04:07.000000000,"[{'_account_id': 2417}, {'_account_id': 6413}, {'_account_id': 6491}, {'_account_id': 6825}, {'_account_id': 7102}, {'_account_id': 9003}, {'_account_id': 11880}, {'_account_id': 12156}, {'_account_id': 14892}, {'_account_id': 16643}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 26968}, {'_account_id': 27897}, {'_account_id': 28543}, {'_account_id': 28935}, {'_account_id': 29632}, {'_account_id': 30002}]","[{'number': 1, 'created': '2019-09-04 04:21:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/8f61991626abf3378771ac0c074769d43efcd914', 'message': 'Updated to get quota data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit adds a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\n'}, {'number': 2, 'created': '2019-09-07 05:49:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/9962e5bc3dee2151d574e285ef997bab815796cf', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\n'}, {'number': 3, 'created': '2019-09-09 16:54:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/f518729eae7eed4e6c488ab8b16b6e2b9c4d22ca', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\n'}, {'number': 4, 'created': '2019-09-09 17:07:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/6be4ab5c64439d949948d663c76cab069332c9a2', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\n'}, {'number': 5, 'created': '2019-09-10 04:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/52f4aabfb8b6ae63cf86683146e208230449be50', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\n'}, {'number': 6, 'created': '2019-09-13 19:02:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/f3c309a279294ce8b3b3ed68a763478f7f47e337', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n'}, {'number': 7, 'created': '2019-09-13 22:15:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/75d9dccffeaf7f5022bc404ff80064e429778acf', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n'}, {'number': 8, 'created': '2019-09-13 22:16:12.000000000', 'files': ['releasenotes/notes/bug-1842119-fix-get-quotas-for-update-quotas-share-7f229e4e011004cd.yaml', 'manila_ui/tests/dashboards/identity/__init__.py', 'manila_ui/api/manila.py', 'manila_ui/tests/dashboards/identity/projects/__init__.py', 'manila_ui/tests/api/test_manila.py', 'manila_ui/tests/dashboards/identity/projects/tests.py', 'manila_ui/dashboards/identity/projects/workflows.py'], 'web_link': 'https://opendev.org/openstack/manila-ui/commit/c763ebe6cd89657aa820ea14774fa3c95e4d0a6b', 'message': 'Updated to get quotas data for Modify Quotas dialog Share tab\n\nCurrent Modfiy Quotas action of a project in Identity->Projects\nfor manila ui does not get quotas data for the project. If user\nupdated quotas for manila ui, the saved data will not be shown\nin the Modify Quotas dialog Share tab.\n\nThis commit includes:\n1) Added a call to get quotas data and also maps the data\nfields retuned to the UI data fields.\n2) Added unit tests.\n3) Added a release note.\n\nChange-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8\nCloses-bug: #1842119\nDepends-on: https://review.opendev.org/#/c/679513/\n'}]",4,679897,c763ebe6cd89657aa820ea14774fa3c95e4d0a6b,45,18,8,11880,,,0,"Updated to get quotas data for Modify Quotas dialog Share tab

Current Modfiy Quotas action of a project in Identity->Projects
for manila ui does not get quotas data for the project. If user
updated quotas for manila ui, the saved data will not be shown
in the Modify Quotas dialog Share tab.

This commit includes:
1) Added a call to get quotas data and also maps the data
fields retuned to the UI data fields.
2) Added unit tests.
3) Added a release note.

Change-Id: I5fb9cef577b109530fde9a4bafe930ea05f3fed8
Closes-bug: #1842119
Depends-on: https://review.opendev.org/#/c/679513/
",git fetch https://review.opendev.org/openstack/manila-ui refs/changes/97/679897/8 && git format-patch -1 --stdout FETCH_HEAD,"['manila_ui/api/manila.py', 'manila_ui/dashboards/identity/projects/workflows.py']",2,8f61991626abf3378771ac0c074769d43efcd914,bug/1842119,"import logging from horizon import exceptionsLOG = logging.getLogger(__name__) def prepare_action_context(self, request, context): try: quotas = api_manila.tenant_quota_get( request, context['project_id']) for field in api_manila.MANILA_QUOTA_FIELDS: # Resolve mismatch UI field names and data field names. data_field = api_manila.MANILA_QUOTA_FIELDS_DATA_MAP[field] context[field] = quotas.get(data_field).limit except Exception as ex: LOG.exception(ex) exceptions.handle(request, _('Unable to retrieve share quotas.')) return context ",,28,0
openstack%2Fnetworking-bagpipe~master~Ia3df29060a6dfeb0f7b10769e8016762148a0a5b,openstack/networking-bagpipe,master,Ia3df29060a6dfeb0f7b10769e8016762148a0a5b,"Force copy of dict items in ""for"" loop",MERGED,2019-10-07 09:41:30.000000000,2019-10-15 20:18:54.000000000,2019-10-08 16:37:36.000000000,"[{'_account_id': 841}, {'_account_id': 13995}, {'_account_id': 16688}, {'_account_id': 18051}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-07 09:41:30.000000000', 'files': ['networking_bagpipe/bagpipe_bgp/common/dataplane_utils.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/359b901a2f4d8e8f61bb59903395e2004c44f000', 'message': 'Force copy of dict items in ""for"" loop\n\nIn module bagpipe_bgp.common.dataplane_utils in\nObjectLifecycleManager.clear_objects() method there is for loop\nwhich iterates over items from dict.\nTo avoid changes of dict during iterations this patch forces always\nto create list which is copy of items from dict.\n\nChange-Id: Ia3df29060a6dfeb0f7b10769e8016762148a0a5b\nCloses-Bug: #1846767\n'}]",0,686990,359b901a2f4d8e8f61bb59903395e2004c44f000,13,6,1,11975,,,0,"Force copy of dict items in ""for"" loop

In module bagpipe_bgp.common.dataplane_utils in
ObjectLifecycleManager.clear_objects() method there is for loop
which iterates over items from dict.
To avoid changes of dict during iterations this patch forces always
to create list which is copy of items from dict.

Change-Id: Ia3df29060a6dfeb0f7b10769e8016762148a0a5b
Closes-Bug: #1846767
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/90/686990/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/bagpipe_bgp/common/dataplane_utils.py'],1,359b901a2f4d8e8f61bb59903395e2004c44f000,bug/1846767," for object_key, users in list(self.object_used_for.items()):"," for object_key, users in self.object_used_for.items():",1,1
openstack%2Fnetworking-bagpipe~master~I39233176ab9a3fd221fdd3f1871d5b1fe0ca601d,openstack/networking-bagpipe,master,I39233176ab9a3fd221fdd3f1871d5b1fe0ca601d,Fix TypeError when calling join on bytes sequence,MERGED,2019-10-03 20:24:44.000000000,2019-10-15 20:17:40.000000000,2019-10-07 16:45:19.000000000,"[{'_account_id': 4694}, {'_account_id': 11975}, {'_account_id': 12021}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-03 20:24:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/63d1f338d43edd5f9bf5bc28e1cd3081785f61bd', 'message': 'Fix TypeError when calling join on bytes sequence\n\nIn bagpipe_bgp.common.run_command module output of command\nis used to be called as argument of join() method.\nBut this output variable has type ""byte"" instead of string\nand that cause failures when it\'s running on Python 3.\n\nSo this patch fixes it by converting output variable always to\nstring.\n\nChange-Id: I39233176ab9a3fd221fdd3f1871d5b1fe0ca601d\nCloses-Bug: #1846601\n'}, {'number': 2, 'created': '2019-10-04 08:22:02.000000000', 'files': ['networking_bagpipe/bagpipe_bgp/common/run_command.py'], 'web_link': 'https://opendev.org/openstack/networking-bagpipe/commit/996ea4530433039ef41a3dcd82c48bba905480ad', 'message': 'Fix TypeError when calling join on bytes sequence\n\nIn bagpipe_bgp.common.run_command module output and error\nof command are of type ""bytes"" instead of ""string"".\nThat causes some issues when it\'s running on Python 3.\n\nSo this patch fixes it by converting those variables always to\nthe string type.\n\nChange-Id: I39233176ab9a3fd221fdd3f1871d5b1fe0ca601d\nCloses-Bug: #1846601\n'}]",0,686489,996ea4530433039ef41a3dcd82c48bba905480ad,14,4,2,11975,,,0,"Fix TypeError when calling join on bytes sequence

In bagpipe_bgp.common.run_command module output and error
of command are of type ""bytes"" instead of ""string"".
That causes some issues when it's running on Python 3.

So this patch fixes it by converting those variables always to
the string type.

Change-Id: I39233176ab9a3fd221fdd3f1871d5b1fe0ca601d
Closes-Bug: #1846601
",git fetch https://review.opendev.org/openstack/networking-bagpipe refs/changes/89/686489/1 && git format-patch -1 --stdout FETCH_HEAD,['networking_bagpipe/bagpipe_bgp/common/run_command.py'],1,63d1f338d43edd5f9bf5bc28e1cd3081785f61bd,bug/1846601," log_fn("" run_command stdout: %s"", ""\n "".join(str(output))) if error: log_fn("" run_command stderr: %s"", ""\n"".join(str(error)))"," log_fn("" run_command stdout: %s"", ""\n "".join(output)) if error: log_fn("" run_command stderr: %s"", ""\n"".join(error))",2,2
openstack%2Fpython-heatclient~stable%2Ftrain~I6c980b68023b33dc318c5d9506c2cac5866c4924,openstack/python-heatclient,stable/train,I6c980b68023b33dc318c5d9506c2cac5866c4924,Ignore not found when delete in test,MERGED,2019-09-20 19:36:27.000000000,2019-10-15 20:07:13.000000000,2019-10-15 20:06:08.000000000,"[{'_account_id': 4257}, {'_account_id': 12404}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-20 19:36:27.000000000', 'files': ['heatclient/tests/functional/osc/v1/base.py'], 'web_link': 'https://opendev.org/openstack/python-heatclient/commit/dd6560f9618662198e25b298804742177db70e13', 'message': 'Ignore not found when delete in test\n\nIgnore not found when delete stack or stack snapshot in tests.\nStory: #1737100\nTask: #19354\n\nChange-Id: I6c980b68023b33dc318c5d9506c2cac5866c4924\n(cherry picked from commit 3b74f2ddd1cb624b98264426509200da00ea3745)\n'}]",0,683705,dd6560f9618662198e25b298804742177db70e13,7,3,1,11904,,,0,"Ignore not found when delete in test

Ignore not found when delete stack or stack snapshot in tests.
Story: #1737100
Task: #19354

Change-Id: I6c980b68023b33dc318c5d9506c2cac5866c4924
(cherry picked from commit 3b74f2ddd1cb624b98264426509200da00ea3745)
",git fetch https://review.opendev.org/openstack/python-heatclient refs/changes/05/683705/1 && git format-patch -1 --stdout FETCH_HEAD,['heatclient/tests/functional/osc/v1/base.py'],1,dd6560f9618662198e25b298804742177db70e13,story/1737100-stable/train,"from tempest.lib import exceptions as tempest_exc try: self.openstack(cmd) except tempest_exc.CommandFailed as e: msg = ""Stack not found: %s"" % id if msg in six.text_type(e.stdout): return raise", self.openstack(cmd),8,1
openstack%2Fswift~master~I5d9f86784a3e39577ab010d29d8d03b26ffda357,openstack/swift,master,I5d9f86784a3e39577ab010d29d8d03b26ffda357,py3: fix swift-account-audit,MERGED,2019-10-14 18:21:16.000000000,2019-10-15 20:04:40.000000000,2019-10-15 20:01:24.000000000,"[{'_account_id': 597}, {'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 18:21:16.000000000', 'files': ['bin/swift-account-audit'], 'web_link': 'https://opendev.org/openstack/swift/commit/2f4fe56ca484c0efc11736aa323b2e63199e3513', 'message': ""py3: fix swift-account-audit\n\nPreviously, we'd get a KeyError trying to read headers.\n\nChange-Id: I5d9f86784a3e39577ab010d29d8d03b26ffda357\n""}]",0,688528,2f4fe56ca484c0efc11736aa323b2e63199e3513,13,4,1,15343,,,0,"py3: fix swift-account-audit

Previously, we'd get a KeyError trying to read headers.

Change-Id: I5d9f86784a3e39577ab010d29d8d03b26ffda357
",git fetch https://review.opendev.org/openstack/swift refs/changes/28/688528/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-account-audit'],1,2f4fe56ca484c0efc11736aa323b2e63199e3513,," responses[node['id']] = { h.lower(): v for h, v in resp.getheaders()} responses[node_id] = [ {h.lower(): v for h, v in resp.getheaders()}, []]"," responses[node['id']] = dict(resp.getheaders()) responses[node_id] = [dict(resp.getheaders()), []]",4,2
openstack%2Ftraining-guides~master~I4e8742b62fc11b514b26baf2461a560d8ba88e8a,openstack/training-guides,master,I4e8742b62fc11b514b26baf2461a560d8ba88e8a,Tweak Events Exercise Phrasing,MERGED,2019-10-15 18:39:12.000000000,2019-10-15 19:34:43.000000000,2019-10-15 19:32:26.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 18:39:12.000000000', 'files': ['doc/upstream-training/source/slides/howitsmade-events.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/2ede05a1bb91719c38d7de70fc70e886bd3011ab', 'message': 'Tweak Events Exercise Phrasing\n\nWe should encourage students to lookup meetup groups as a backup\nto an OpenStack Day event.\n\nChange-Id: I4e8742b62fc11b514b26baf2461a560d8ba88e8a\n'}]",0,688781,2ede05a1bb91719c38d7de70fc70e886bd3011ab,8,3,1,16708,,,0,"Tweak Events Exercise Phrasing

We should encourage students to lookup meetup groups as a backup
to an OpenStack Day event.

Change-Id: I4e8742b62fc11b514b26baf2461a560d8ba88e8a
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/81/688781/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/howitsmade-events.rst'],1,2ede05a1bb91719c38d7de70fc70e886bd3011ab,events_exercises,"- Look up an OpenStack (or OpenInfra) Days event close to where you live that you would be interested in attending - If there are no events planned, is there a meetup group?","- Look up an OpenStack Days event close to where you live that you would be interested in attending - In case there are no events planned, how about organizing one in your area? ",3,4
openstack%2Fopenstack-zuul-jobs~master~I462f6c269bf2dd2d7abf1c7d15e4478d6a18bb0e,openstack/openstack-zuul-jobs,master,I462f6c269bf2dd2d7abf1c7d15e4478d6a18bb0e,Remove puppet-yum,MERGED,2019-10-15 18:57:20.000000000,2019-10-15 19:19:32.000000000,2019-10-15 19:16:29.000000000,"[{'_account_id': 2}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 18:57:20.000000000', 'files': ['zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-zuul-jobs/commit/7ae82e20ac0949ee9f1a0cae1c3e7442dff8bf94', 'message': 'Remove puppet-yum\n\npuppet-yum is retired, remove it from required-projects.\n\nChange-Id: I462f6c269bf2dd2d7abf1c7d15e4478d6a18bb0e\n'}]",0,688785,7ae82e20ac0949ee9f1a0cae1c3e7442dff8bf94,8,3,1,6547,,,0,"Remove puppet-yum

puppet-yum is retired, remove it from required-projects.

Change-Id: I462f6c269bf2dd2d7abf1c7d15e4478d6a18bb0e
",git fetch https://review.opendev.org/openstack/openstack-zuul-jobs refs/changes/85/688785/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/jobs.yaml'],1,7ae82e20ac0949ee9f1a0cae1c3e7442dff8bf94,puppet-yum,, - opendev/puppet-yum,0,1
openstack%2Ftraining-guides~master~Ie1fc88d31a46c650f875b94b0f5bd950c24e6c9c,openstack/training-guides,master,Ie1fc88d31a46c650f875b94b0f5bd950c24e6c9c,Tweak Governance Exercises,MERGED,2019-10-15 17:56:49.000000000,2019-10-15 18:52:43.000000000,2019-10-15 18:47:57.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 15993}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 17:56:49.000000000', 'files': ['doc/upstream-training/source/slides/howitsmade-governance.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/8e9155b012e1cab60be8eb856c92378d49cbbb84', 'message': ""Tweak Governance Exercises\n\nWe don't always ask just these questions so this patch makes the\nphrasing more in line with the information we want students to have\nand know.\n\nChange-Id: Ie1fc88d31a46c650f875b94b0f5bd950c24e6c9c\n""}]",0,688772,8e9155b012e1cab60be8eb856c92378d49cbbb84,9,4,1,16708,,,0,"Tweak Governance Exercises

We don't always ask just these questions so this patch makes the
phrasing more in line with the information we want students to have
and know.

Change-Id: Ie1fc88d31a46c650f875b94b0f5bd950c24e6c9c
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/72/688772/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/howitsmade-governance.rst'],1,8e9155b012e1cab60be8eb856c92378d49cbbb84,governance_exercises,- Find the current members of the TC and UC- Why do we care about APC status? - Name one activity you can do to get AUC status,- Find the latest election results for the TC and UC.,3,1
openstack%2Ftraining-guides~master~I8eba155304c05e61466b8885bde2bc2777ca6dff,openstack/training-guides,master,I8eba155304c05e61466b8885bde2bc2777ca6dff,Update Task Tracking Exercises,MERGED,2019-10-15 02:43:34.000000000,2019-10-15 18:51:09.000000000,2019-10-15 18:47:56.000000000,"[{'_account_id': 6547}, {'_account_id': 9562}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 02:43:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/training-guides/commit/10713ab9240594cc8b9f8e42ffbd7d900f9a5849', 'message': 'Update Task Tracking Exercises\n\nWe still occasionally hit the race condition where when a story is\ncreated with multiple tasks there is a deadlock. To avoid hitting this\nin the upstream training, let us have the students make stories with\none task.\n\nThis patch also adds clarifying phrasing to the other exercies in the\ntask tracking section.\n\nChange-Id: I8eba155304c05e61466b8885bde2bc2777ca6dff\n'}, {'number': 2, 'created': '2019-10-15 15:38:09.000000000', 'files': ['doc/upstream-training/source/slides/workflow-task-tracking.rst'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/49d4861081e720328dab44a1f80da95c19b0858d', 'message': 'Update Task Tracking Exercises\n\nWe still occasionally hit the race condition where when a story is\ncreated with multiple tasks there is a deadlock. To avoid hitting this\nin the upstream training, let us have the students make stories with\none task.\n\nThis patch also adds clarifying phrasing to the other exercies in the\ntask tracking section.\n\nChange-Id: I8eba155304c05e61466b8885bde2bc2777ca6dff\n'}]",1,688604,49d4861081e720328dab44a1f80da95c19b0858d,11,3,2,16708,,,0,"Update Task Tracking Exercises

We still occasionally hit the race condition where when a story is
created with multiple tasks there is a deadlock. To avoid hitting this
in the upstream training, let us have the students make stories with
one task.

This patch also adds clarifying phrasing to the other exercies in the
task tracking section.

Change-Id: I8eba155304c05e61466b8885bde2bc2777ca6dff
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/04/688604/2 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/slides/workflow-task-tracking.rst'],1,10713ab9240594cc8b9f8e42ffbd7d900f9a5849,update_exercises,"assign it to yourself. You will use this later when we practice writing commit messages and pushing patches to the sandbox repo so make it interesting!Include a description and assign yourself. You will use this later when we practice writing commit messages and pushing patches to the sandbox repo so make it interesting!for organizing stories you are going to create in the next exercise. For the automatic worklist, give at least two criteria for the items that will go into the worklist. These criteria can be matching a project-group, story tag, etc.Each story must have a task that is named differently than the story name. You will use these stories later when we practice writing commit messages and pushing patches to the sandbox repo so make them interesting!Share your board with your group. Assign yourself to two tasks on","assign it to yourself.Include a description and assign yourself.for organizing tasks you are going to create. For the automatic worklist, give at least two criteria for the items that will go into the worklist.Each story must have a minimum of two tasks that are named differently than the story name.Share your board with your group. Assign yourself to three tasks on",16,7
openstack%2Fsenlin~master~Id7b4181b919d630047708f726f7af86e0086ecb7,openstack/senlin,master,Id7b4181b919d630047708f726f7af86e0086ecb7,Use inbuilt threadgroup,ABANDONED,2019-10-12 05:59:23.000000000,2019-10-15 18:49:18.000000000,,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-10-12 05:59:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6256c0ea2d4c1d9a4861283bd21ee2be346dd584', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 2, 'created': '2019-10-12 06:03:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/44f1688332f9b98f8a4d9bd9846c91429dd5f868', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 3, 'created': '2019-10-12 06:23:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/6e159026bdffb2ccdbb4fb842d104f5825d87328', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 4, 'created': '2019-10-12 23:03:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/3fdcbb1911d5637d78ba37453fd85cb012298d8d', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 5, 'created': '2019-10-12 23:06:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/368605cd93cb972e69ec0d84a6a2ce9ec0346b3e', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 6, 'created': '2019-10-13 00:01:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/f10a18b8caecf6fc223d5674c162548c6993663f', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nThis also allows us to remove some custom code that\nis already handled in oslo_service, e.g. the custom\nstop logic is already handled in oslo_service when\nperforming a graceful shutdown.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}, {'number': 7, 'created': '2019-10-13 00:03:41.000000000', 'files': ['senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/engine/scheduler.py', 'senlin/tests/unit/engine/test_engine_startstop.py', 'senlin/tests/unit/engine/test_scheduler.py', 'senlin/tests/unit/engine/test_dispatcher.py', 'senlin/tests/unit/engine/test_health_manager.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/fcbc29813986750e19611445d099537b8edfb46e', 'message': 'Use inbuilt threadgroup\n\nWe are creating our own threadgroup instead of using\nthe one provided by oslo_service. This patch changes\nthat and also makes it more obvious when we are using\nthe custom thread manager group.\n\nThis also allows us to remove some custom code that\nis already handled in oslo_service, e.g. the custom\nstop logic is already handled in oslo_service when\nperforming a graceful shutdown.\n\nChange-Id: Id7b4181b919d630047708f726f7af86e0086ecb7\n'}]",1,688230,fcbc29813986750e19611445d099537b8edfb46e,15,3,7,22623,,,0,"Use inbuilt threadgroup

We are creating our own threadgroup instead of using
the one provided by oslo_service. This patch changes
that and also makes it more obvious when we are using
the custom thread manager group.

This also allows us to remove some custom code that
is already handled in oslo_service, e.g. the custom
stop logic is already handled in oslo_service when
performing a graceful shutdown.

Change-Id: Id7b4181b919d630047708f726f7af86e0086ecb7
",git fetch https://review.opendev.org/openstack/senlin refs/changes/30/688230/1 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'senlin/engine/service.py', 'senlin/engine/scheduler.py', 'senlin/tests/unit/engine/test_engine_startstop.py', 'senlin/tests/unit/engine/test_scheduler.py', 'senlin/tests/unit/engine/test_dispatcher.py', 'senlin/tests/unit/engine/test_health_manager.py']",8,6256c0ea2d4c1d9a4861283bd21ee2be346dd584,," self.assertIsNotNone(self.hm.tg) self.hm.tg = mock.Mock() mock_add_timer = self.patchobject(self.hm.tg, 'add_dynamic_timer', self.hm.tg = mock.Mock() self.hm.tg.stop.assert_called_once()"," self.assertIsNotNone(self.hm.TG) self.hm.TG = mock.Mock() mock_add_timer = self.patchobject(self.hm.TG, 'add_dynamic_timer', self.hm.TG = mock.Mock() self.hm.TG.stop_timers.assert_called_once_with()",80,98
openstack%2Fsenlin~master~I3a8c0f776bf00d2f8250c133941ae45e6fb4965f,openstack/senlin,master,I3a8c0f776bf00d2f8250c133941ae45e6fb4965f,Split engine service,ABANDONED,2019-10-13 02:07:18.000000000,2019-10-15 18:49:10.000000000,,"[{'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 22998}, {'_account_id': 27224}]","[{'number': 1, 'created': '2019-10-13 02:07:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/4e1f1286065fe522a13123af804048c60798404e', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 2, 'created': '2019-10-13 03:08:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/9f16a1585b7278721a7b831c305e3d455a2f1816', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 3, 'created': '2019-10-13 03:13:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/77860690f10cfa6e615ab5e74321a70f1f22c47a', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 4, 'created': '2019-10-13 03:34:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/579dbc627a2c6db8556a1c68b401d06255e80746', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 5, 'created': '2019-10-13 04:18:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/5325638f23cd7150d6cc717cc90aca9cd3a665ba', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 6, 'created': '2019-10-13 05:23:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/419e19e67fa6eacc5c92446aa2fc87d05e60799e', 'message': '[DNM][WIP] Test test\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 7, 'created': '2019-10-13 12:39:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/b646e08de4af0003f02018aa014a972d638d1727', 'message': '[DNM][WIP] Split engine service\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 8, 'created': '2019-10-13 12:52:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/de524b3b04c06828072dc38d87c4cc6b540198cd', 'message': '[DNM][WIP] Split engine service\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 9, 'created': '2019-10-13 13:01:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/79691fcccb5137f1ced8a8986876d7b1a8cf4267', 'message': '[DNM][WIP] Split engine service\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 10, 'created': '2019-10-13 15:52:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/43777c8477935476ea09aa4cc5fd0e719fc6ee18', 'message': '[DNM][WIP] Split engine service\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 11, 'created': '2019-10-13 21:07:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/senlin/commit/1d098527d9f4265db37701ebe2b0b4e1068a94a5', 'message': 'Split engine service\n\nThis patch splits the engine into 3 services,\ndispatcher, engine and health-manager.\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}, {'number': 12, 'created': '2019-10-15 07:31:47.000000000', 'files': ['senlin/health_manager/__init__.py', 'senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'senlin/tests/unit/engine/service/test_cluster_policies.py', 'senlin/engine/scheduler.py', 'senlin/common/config.py', 'devstack/lib/senlin', 'senlin/tests/unit/engine/test_health_manager.py', 'devstack/settings', 'senlin/cmd/health_manager.py', 'senlin/tests/unit/engine/service/test_actions.py', 'senlin/dispatcher/__init__.py', 'senlin/engine/service.py', 'senlin/health_manager/service.py', 'senlin/tests/unit/engine/test_engine_startstop.py', 'senlin/tests/unit/engine/test_scheduler.py', 'senlin/dispatcher/service.py', 'senlin/tests/unit/engine/test_dispatcher.py', 'setup.cfg', 'senlin/cmd/dispatcher.py'], 'web_link': 'https://opendev.org/openstack/senlin/commit/8d6cb536a955a3fd728f9f9d85aa51b47a54abde', 'message': 'Split engine service\n\nThis patch splits the engine into 3 services,\ndispatcher, engine and health-manager.\n\nChange-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f\n'}]",0,688288,8d6cb536a955a3fd728f9f9d85aa51b47a54abde,25,4,12,22623,,,0,"Split engine service

This patch splits the engine into 3 services,
dispatcher, engine and health-manager.

Change-Id: I3a8c0f776bf00d2f8250c133941ae45e6fb4965f
",git fetch https://review.opendev.org/openstack/senlin refs/changes/88/688288/8 && git format-patch -1 --stdout FETCH_HEAD,"['senlin/health_manager/__init__.py', 'senlin/engine/dispatcher.py', 'senlin/engine/health_manager.py', 'devstack/lib/senlin', 'senlin/tests/unit/engine/test_health_manager.py', 'senlin/cmd/health_manager.py', 'senlin/dispatcher/__init__.py', 'senlin/engine/service.py', 'senlin/health_manager/service.py', 'senlin/dispatcher/service.py', 'setup.cfg', 'senlin/cmd/dispatcher.py']",12,4e1f1286065fe522a13123af804048c60798404e,split_service,"#!/usr/bin/env python # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. """""" Senlin Engine Server. """""" from oslo_config import cfg from oslo_log import log as logging from oslo_reports import guru_meditation_report as gmr from oslo_service import service from senlin.common import messaging from senlin.common import profiler from senlin import objects from senlin import version def main(): logging.register_options(cfg.CONF) cfg.CONF(project='senlin', prog='senlin-dispatcher') logging.setup(cfg.CONF, 'senlin-dispatcher') logging.set_defaults() gmr.TextGuruMeditation.setup_autorun(version) objects.register_all() messaging.setup() from senlin.dispatcher import service as dispatcher profiler.setup('senlin-dispatcher', cfg.CONF.host) srv = dispatcher.DispatcherService(cfg.CONF.host) launcher = service.launch(cfg.CONF, srv, workers=cfg.CONF.num_engine_workers, restart_method='mutate') launcher.wait() ",,289,40
openstack%2Fnetworking-ovn~stable%2Ftrain~I8c1174df562a7164d4a96ce2e733279723827dcd,openstack/networking-ovn,stable/train,I8c1174df562a7164d4a96ce2e733279723827dcd,Avoid port group creation race,MERGED,2019-10-09 13:54:55.000000000,2019-10-15 18:35:17.000000000,2019-10-15 18:33:57.000000000,"[{'_account_id': 1131}, {'_account_id': 5756}, {'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 24791}]","[{'number': 1, 'created': '2019-10-09 13:54:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/41339ffcaae2ae53cb1d72609bc348bec61ec3c2', 'message': ""Avoid port group creation race\n\nThe neutron_pg_drop Porg Group is created with some ACLs to drop\nall the traffic by default. This group doesn't match any Neutron\nresource and it's created once the first Neutron port with\nport_security enabled gets created.\n\nA race condition exists whn the first two ports get created\nsimultaneously by different works as both may attempt to create\nthis Port Group. The result is that one of the port creations will\nfail. Setting may_exist=True should avoid this race\n\nCo-authored-by: Daniel Alvarez <dalvarez@redhat.com>\nCloses-Bug: 1838969\nChange-Id: I8c1174df562a7164d4a96ce2e733279723827dcd\n(cherry picked from commit e946836b208a5ddc3a17f2dba53658c4b9a3f8f7)\n""}, {'number': 2, 'created': '2019-10-14 10:24:13.000000000', 'files': ['networking_ovn/common/ovn_client.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/4b1c92c8bf09c86763ee1244f66953b6d4193484', 'message': ""Avoid port group creation race\n\nThe neutron_pg_drop Porg Group is created with some ACLs to drop\nall the traffic by default. This group doesn't match any Neutron\nresource and it's created once the first Neutron port with\nport_security enabled gets created.\n\nA race condition exists whn the first two ports get created\nsimultaneously by different works as both may attempt to create\nthis Port Group. The result is that one of the port creations will\nfail. Setting may_exist=True should avoid this race\n\nCo-authored-by: Daniel Alvarez <dalvarez@redhat.com>\nCloses-Bug: 1838969\nChange-Id: I8c1174df562a7164d4a96ce2e733279723827dcd\n(cherry picked from commit e946836b208a5ddc3a17f2dba53658c4b9a3f8f7)\n""}]",0,687566,4b1c92c8bf09c86763ee1244f66953b6d4193484,16,6,2,24791,,,0,"Avoid port group creation race

The neutron_pg_drop Porg Group is created with some ACLs to drop
all the traffic by default. This group doesn't match any Neutron
resource and it's created once the first Neutron port with
port_security enabled gets created.

A race condition exists whn the first two ports get created
simultaneously by different works as both may attempt to create
this Port Group. The result is that one of the port creations will
fail. Setting may_exist=True should avoid this race

Co-authored-by: Daniel Alvarez <dalvarez@redhat.com>
Closes-Bug: 1838969
Change-Id: I8c1174df562a7164d4a96ce2e733279723827dcd
(cherry picked from commit e946836b208a5ddc3a17f2dba53658c4b9a3f8f7)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/66/687566/2 && git format-patch -1 --stdout FETCH_HEAD,['networking_ovn/common/ovn_client.py'],1,41339ffcaae2ae53cb1d72609bc348bec61ec3c2,," txn.add(self._nb_idl.pg_add(pg_name, acls=[], may_exist=True)) txn.add(self._nb_idl.pg_acl_add(may_exist=True, **acl))"," txn.add(self._nb_idl.pg_add(pg_name, acls=[])) txn.add(self._nb_idl.pg_acl_add(**acl))",2,2
openstack%2Fkeystone-tempest-plugin~master~Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf,openstack/keystone-tempest-plugin,master,Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf,Follow the PTI for docs,MERGED,2019-09-27 09:09:59.000000000,2019-10-15 18:34:37.000000000,2019-10-15 18:34:37.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-27 09:09:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/f9f051fe6ef9b039a23d5bbfef7a65369d1c2578', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nThis requires using the sphinxcontrib-apidoc plugin rather than the\nautodoc pbr extention. Also fixes the header formatting for the index page,\nas the headers weren't rendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf\n""}, {'number': 2, 'created': '2019-09-27 09:40:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/a8f3e4820d6f468dcafe05f49754764b71ee0d55', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nThis requires using the sphinxcontrib-apidoc plugin rather than the\nautodoc pbr extention. Also fixes the header formatting for the index page,\nas the headers weren't rendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf\n""}, {'number': 3, 'created': '2019-09-27 16:40:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/15bef540be06da7baf9d35d3498d17a7612df7fa', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nThis requires using the sphinxcontrib-apidoc plugin rather than the\nautodoc pbr extention. Also fixes the header formatting for the index page,\nas the headers weren't rendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf\n""}, {'number': 4, 'created': '2019-10-09 09:08:13.000000000', 'files': ['doc/source/index.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/keystone-tempest-plugin/commit/30b20b6e048aa0879e2116d17542cde8949219f4', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nIt fixes the header formatting for the index page, as the headers weren't\nrendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf\n""}]",2,685260,30b20b6e048aa0879e2116d17542cde8949219f4,14,4,4,27621,,,0,"Follow the PTI for docs

Use sphinx-build instead of the pbr sphinx extention for building docs
as instructed by the PTI[1].

It fixes the header formatting for the index page, as the headers weren't
rendering at all.

[1] https://governance.openstack.org/tc/reference/pti/python.html

Change-Id: Ibac2b45ecfab4a7e575d097ecb9fc2c5e57b81cf
",git fetch https://review.opendev.org/openstack/keystone-tempest-plugin refs/changes/60/685260/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/conf.py', 'tox.ini']",3,f9f051fe6ef9b039a23d5bbfef7a65369d1c2578,685260,commands = sphinx-build -W -b html -d doc/buld/doctrees doc/source doc/build/html,commands = python setup.py build_sphinx,14,3
openstack%2Foctavia~stable%2Frocky~If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0,openstack/octavia,stable/rocky,If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0,loadbalancer vip-network-id IP availability check,MERGED,2019-09-27 17:54:15.000000000,2019-10-15 18:32:30.000000000,2019-10-15 18:31:01.000000000,"[{'_account_id': 6469}, {'_account_id': 11628}, {'_account_id': 22348}, {'_account_id': 28258}]","[{'number': 1, 'created': '2019-09-27 17:54:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/d6fbb63018e2f7322f791212f3b0d1de4b790440', 'message': 'loadbalancer vip-network-id IP availability check\n\nThe existing code selects the first IPv4 subnet in the network without\nany consideration of ip availability.  If not enough IPs are available,\nthe loadbalancer creations fails.  This patch uses neutron ip\navailability API to check the quantity of free IPs when creating\nloadbalancer with vip-network-id and skips subnets that do not have\nenough IPs for a loadbalancer on multi subnet networks.\n\nChange-Id: If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0\nTask: 36004\nStory: 2006293\n(cherry picked from commit cf901539677d24cac0d9541752b4b3c74c2a1635)\n'}, {'number': 2, 'created': '2019-09-30 23:00:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/octavia/commit/82e7a92bcca86bde3b0b60810f4e6b9dfecbf7a6', 'message': 'loadbalancer vip-network-id IP availability check\n\nThe existing code selects the first IPv4 subnet in the network without\nany consideration of ip availability.  If not enough IPs are available,\nthe loadbalancer creations fails.  This patch uses neutron ip\navailability API to check the quantity of free IPs when creating\nloadbalancer with vip-network-id and skips subnets that do not have\nenough IPs for a loadbalancer on multi subnet networks.\n\nChange-Id: If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0\nTask: 36004\nStory: 2006293\n'}, {'number': 3, 'created': '2019-10-01 06:56:24.000000000', 'files': ['octavia/common/utils.py', 'octavia/network/drivers/neutron/utils.py', 'octavia/tests/unit/network/drivers/neutron/test_base.py', 'octavia/api/v2/controllers/load_balancer.py', 'releasenotes/notes/fix-vip-network-ip-availability-2e924f32abf01052.yaml', 'octavia/network/drivers/neutron/base.py', 'octavia/network/base.py', 'octavia/network/data_models.py', 'octavia/network/drivers/noop_driver/driver.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/unit/network/drivers/neutron/test_utils.py', 'octavia/tests/common/constants.py'], 'web_link': 'https://opendev.org/openstack/octavia/commit/8faa42204ef1da2facca2221a649fad303caf548', 'message': 'loadbalancer vip-network-id IP availability check\n\nThe existing code selects the first IPv4 subnet in the network without\nany consideration of ip availability.  If not enough IPs are available,\nthe loadbalancer creations fails.  This patch uses neutron ip\navailability API to check the quantity of free IPs when creating\nloadbalancer with vip-network-id and skips subnets that do not have\nenough IPs for a loadbalancer on multi subnet networks.\n\nChange-Id: If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0\nTask: 36004\nStory: 2006293\n'}]",0,685447,8faa42204ef1da2facca2221a649fad303caf548,23,4,3,28258,,,0,"loadbalancer vip-network-id IP availability check

The existing code selects the first IPv4 subnet in the network without
any consideration of ip availability.  If not enough IPs are available,
the loadbalancer creations fails.  This patch uses neutron ip
availability API to check the quantity of free IPs when creating
loadbalancer with vip-network-id and skips subnets that do not have
enough IPs for a loadbalancer on multi subnet networks.

Change-Id: If3c3cf9be085bb95b4ebbaf71e24f92d42b8d6e0
Task: 36004
Story: 2006293
",git fetch https://review.opendev.org/openstack/octavia refs/changes/47/685447/3 && git format-patch -1 --stdout FETCH_HEAD,"['octavia/common/utils.py', 'octavia/network/drivers/neutron/utils.py', 'octavia/tests/unit/network/drivers/neutron/test_base.py', 'octavia/api/v2/controllers/load_balancer.py', 'releasenotes/notes/fix-vip-network-ip-availability-2e924f32abf01052.yaml', 'octavia/network/drivers/neutron/base.py', 'octavia/network/base.py', 'octavia/network/data_models.py', 'octavia/network/drivers/noop_driver/driver.py', 'octavia/tests/functional/api/v2/test_load_balancer.py', 'octavia/tests/unit/network/drivers/neutron/test_utils.py', 'octavia/tests/common/constants.py']",12,d6fbb63018e2f7322f791212f3b0d1de4b790440,2006293-fix-stable/rocky," MOCK_NETWORK_TOTAL_IPS = 254 MOCK_NETWORK_USED_IPS = 0 MOCK_SUBNET_TOTAL_IPS = 254 MOCK_SUBNET_USED_IPS = 0 MOCK_SUBNET_IP_AVAILABILITY = [{'used_ips': MOCK_SUBNET_USED_IPS, 'subnet_id': MOCK_SUBNET_ID, 'total_ips': MOCK_SUBNET_TOTAL_IPS}] MOCK_NETWORK_IP_AVAILABILITY = {'network_ip_availability': ( {'network_id': MOCK_NETWORK_ID, 'tenant_id': MOCK_PROJECT_ID, 'network_name': MOCK_NETWORK_NAME, 'total_ips': MOCK_NETWORK_TOTAL_IPS, 'used_ips': MOCK_NETWORK_USED_IPS, 'subnet_ip_availability': MOCK_SUBNET_IP_AVAILABILITY})}",,218,7
openstack%2Fopenstack-ansible-os_horizon~master~I11c3edec6d58e39da8de5e214fab9731eb5df9e2,openstack/openstack-ansible-os_horizon,master,I11c3edec6d58e39da8de5e214fab9731eb5df9e2,Allow to configure horizon bind address,MERGED,2019-09-12 11:15:09.000000000,2019-10-15 18:28:05.000000000,2019-10-15 18:25:05.000000000,"[{'_account_id': 22348}, {'_account_id': 25023}, {'_account_id': 28008}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-09-12 11:15:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/61e13e8fa2f39feaa060bc9f92e7e1b3b174fef7', 'message': ""Resolve metal conflict with haproxy\n\nAs for container deployments it's actually doesn't matter on what ports\napache will listen for horizon, and metal deployments are not functional\nwe can easily change ports for horizon\n\nAs an addition, horizon_listen_ports variable was converted to dict()\nfor affecting apache vhost.\n\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n""}, {'number': 2, 'created': '2019-09-12 11:37:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/96330607c61bd5bccd80b2f4732103d95865ae23', 'message': ""Resolve metal conflict with haproxy\n\nAs for container deployments it's actually doesn't matter on what ports\napache will listen for horizon, and metal deployments are not functional\nwe can easily change ports for horizon\n\nAs an addition, horizon_listen_ports variable was converted to dict()\nfor affecting apache vhost.\n\nDepends-On: https://review.opendev.org/681722\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n""}, {'number': 3, 'created': '2019-09-12 13:41:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/e1eeb8bf8e663d4f183013617e1c7a708c6899a4', 'message': ""Resolve metal conflict with haproxy\n\nAs for container deployments it's actually doesn't matter on what ports\napache will listen for horizon, and metal deployments are not functional\nwe can easily change ports for horizon\n\nAs an addition, horizon_listen_ports variable was converted to dict()\nfor affecting apache vhost.\n\nDepends-On: https://review.opendev.org/681722\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n""}, {'number': 4, 'created': '2019-09-13 10:38:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/512301ebd49d47c0071e27f2752a1bb004e50b26', 'message': ""Resolve metal conflict with haproxy\n\nAs for container deployments it's actually doesn't matter on what ports\napache will listen for horizon, and metal deployments are not functional\nwe can easily change ports for horizon\n\nAs an addition, horizon_listen_ports variable was converted to dict()\nfor affecting apache vhost.\n\nDepends-On: https://review.opendev.org/681722\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n""}, {'number': 5, 'created': '2019-09-18 19:47:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/2a9fa7cb264f6e9da3b167737e4d9f0088307ce2', 'message': 'Allow to configure horizon bind address\n\nAdded variable horizon_bind_address which allows to define address\non which horizon will be listening.\n\nhorizon_listen_ports variable was converted to dict()\nand used in apache vhost template.\n\nAs an addition metal jobs were added for horizon CI.\n\nDepends-On: https://review.opendev.org/681722\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n'}, {'number': 6, 'created': '2019-09-19 09:32:14.000000000', 'files': ['releasenotes/notes/horizon_haproxy_conflict-27955d6b7c1a6d30.yaml', 'templates/horizon_apache_ports.conf.j2', 'templates/openstack_dashboard.conf.j2', 'vars/debian.yml', 'zuul.d/project.yaml', 'defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_horizon/commit/9f9b66a985a44caef36e7af6695a2a6e25460a16', 'message': 'Allow to configure horizon bind address\n\nAdded variable horizon_bind_address which allows to define address\non which horizon will be listening.\n\nhorizon_listen_ports variable was converted to dict()\nand used in apache vhost template.\n\nAs an addition metal jobs were added for horizon CI.\n\nDepends-On: https://review.opendev.org/681722\nChange-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2\n'}]",0,681718,9f9b66a985a44caef36e7af6695a2a6e25460a16,21,4,6,28619,,,0,"Allow to configure horizon bind address

Added variable horizon_bind_address which allows to define address
on which horizon will be listening.

horizon_listen_ports variable was converted to dict()
and used in apache vhost template.

As an addition metal jobs were added for horizon CI.

Depends-On: https://review.opendev.org/681722
Change-Id: I11c3edec6d58e39da8de5e214fab9731eb5df9e2
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_horizon refs/changes/18/681718/4 && git format-patch -1 --stdout FETCH_HEAD,"['templates/horizon_apache_ports.conf.j2', 'templates/openstack_dashboard.conf.j2', 'defaults/main.yml']",3,61e13e8fa2f39feaa060bc9f92e7e1b3b174fef7,bind-to-mgmt," http: ""8080"" https: ""8443"""," - ""80"" - ""443""",5,5
openstack%2Fproject-config~master~Ia62cc8abbd64117d4939d560a0ee998a1f184b8d,openstack/project-config,master,Ia62cc8abbd64117d4939d560a0ee998a1f184b8d,Remove legacy-puppet4-centos-7,MERGED,2019-10-15 09:45:40.000000000,2019-10-15 18:01:26.000000000,2019-10-15 18:01:26.000000000,"[{'_account_id': 4146}, {'_account_id': 5263}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 09:45:40.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/bff94ee8648a57b2462f4a01e984976ea3ea0cdc', 'message': 'Remove legacy-puppet4-centos-7\n\nThe fuel repos are dead, we can remove the job usage so that we\ncan remove the job completely.\n\nChange-Id: Ia62cc8abbd64117d4939d560a0ee998a1f184b8d\n'}]",0,688664,bff94ee8648a57b2462f4a01e984976ea3ea0cdc,7,3,1,6547,,,0,"Remove legacy-puppet4-centos-7

The fuel repos are dead, we can remove the job usage so that we
can remove the job completely.

Change-Id: Ia62cc8abbd64117d4939d560a0ee998a1f184b8d
",git fetch https://review.opendev.org/openstack/project-config refs/changes/64/688664/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,bff94ee8648a57b2462f4a01e984976ea3ea0cdc,legacy-puppet-syntax-4-centos-7,, - legacy-puppet-syntax-4-centos-7: branches: ^(?!stable/8\.0).*$ - legacy-puppet-syntax-4-centos-7: branches: ^(?!stable/8\.0).*$ - legacy-puppet-syntax-4-centos-7: branches: ^(?!stable/8\.0).*$ - legacy-puppet-syntax-4-centos-7: branches: ^(?!stable/8\.0).*$,0,8
openstack%2Fopenstacksdk~master~Ib4c5120c3e7a95f8784bdef3003ae1b037b141cc,openstack/openstacksdk,master,Ib4c5120c3e7a95f8784bdef3003ae1b037b141cc,Use 'name' param if not UUID like,ABANDONED,2019-10-15 17:57:17.000000000,2019-10-15 18:01:22.000000000,,[],"[{'number': 1, 'created': '2019-10-15 17:57:17.000000000', 'files': ['openstack/cloud/_identity.py'], 'web_link': 'https://opendev.org/openstack/openstacksdk/commit/0eba00c98c29a3c7a2b0c1110747f8ab05cd56b9', 'message': ""Use 'name' param if not UUID like\n\nCloses-Bug: 2006720\n\nTested against both devstack and a dev env with ldap and pages\n\nChange-Id: Ib4c5120c3e7a95f8784bdef3003ae1b037b141cc\n""}]",0,688773,0eba00c98c29a3c7a2b0c1110747f8ab05cd56b9,2,0,1,31103,,,0,"Use 'name' param if not UUID like

Closes-Bug: 2006720

Tested against both devstack and a dev env with ldap and pages

Change-Id: Ib4c5120c3e7a95f8784bdef3003ae1b037b141cc
",git fetch https://review.opendev.org/openstack/openstacksdk refs/changes/73/688773/1 && git format-patch -1 --stdout FETCH_HEAD,['openstack/cloud/_identity.py'],1,0eba00c98c29a3c7a2b0c1110747f8ab05cd56b9,bug/2006720, # NOTE(jdwidari) if name_or_id isn't UUID like then make use of server- # side filter for user name https://bit.ly/2qh0Ijk # especially important when using LDAP and using page to limit results if name_or_id and not _utils._is_uuid_like(name_or_id): kwargs['name'] = name_or_id if not _utils._is_uuid_like(name_or_id): kwargs['name'] = name_or_id , kwargs['name'] = name_or_id,9,1
openstack%2Ftripleo-heat-templates~master~Id8b33837eebbe18417d4c349e73817aa8f660091,openstack/tripleo-heat-templates,master,Id8b33837eebbe18417d4c349e73817aa8f660091,Add support to configure token caching,MERGED,2019-09-19 00:51:56.000000000,2019-10-15 17:49:26.000000000,2019-10-08 17:33:17.000000000,"[{'_account_id': 9816}, {'_account_id': 14985}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-19 00:51:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/499aea0b8c1b493ae4fc628a663b9dfb77f86f72', 'message': 'WIP: Enable token caching\n\nDepends-on: https://review.opendev.org/#/c/683010\nChange-Id: Id8b33837eebbe18417d4c349e73817aa8f660091\n'}, {'number': 2, 'created': '2019-09-19 14:38:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/835836892042a8f2116ace0128ebd895a8c461b5', 'message': 'Add support to configure token caching\n\nAdd a new parameter named KeystoneEnableTokenCaching to enable\ncaching for keystone token to improve performance related to\ntoken management.\n\nDepends-on: https://review.opendev.org/#/c/683010\nChange-Id: Id8b33837eebbe18417d4c349e73817aa8f660091\n'}, {'number': 3, 'created': '2019-09-27 12:46:10.000000000', 'files': ['releasenotes/notes/keystone_token_caching-ce02411398a40420.yaml', 'deployment/keystone/keystone-container-puppet.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/db35747962ff8d00ac903cd1e153f5b25a78e33a', 'message': 'Add support to configure token caching\n\nAdd a new parameter named KeystoneEnableTokenCaching to enable\ncaching for keystone token to improve performance related to\ntoken management.\n\nDepends-on: https://review.opendev.org/#/c/683010\nChange-Id: Id8b33837eebbe18417d4c349e73817aa8f660091\n'}]",0,683012,db35747962ff8d00ac903cd1e153f5b25a78e33a,42,5,3,9816,,,0,"Add support to configure token caching

Add a new parameter named KeystoneEnableTokenCaching to enable
caching for keystone token to improve performance related to
token management.

Depends-on: https://review.opendev.org/#/c/683010
Change-Id: Id8b33837eebbe18417d4c349e73817aa8f660091
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/12/683012/3 && git format-patch -1 --stdout FETCH_HEAD,['deployment/keystone/keystone-container-puppet.yaml'],1,499aea0b8c1b493ae4fc628a663b9dfb77f86f72,token-cache, KeystoneEnableTokenCaching: type: boolean default: true description: >- Enable token caching tripleo::profile::base::keystone::enable_token_caching: {get_param: KeystoneEnableTokenCaching},,6,0
openstack%2Fswift~master~I82edbf1ddcc28f86e97405d21db0b96249412eac,openstack/swift,master,I82edbf1ddcc28f86e97405d21db0b96249412eac,py3: Fix swift-recon,MERGED,2019-10-14 18:40:46.000000000,2019-10-15 17:45:48.000000000,2019-10-15 02:20:56.000000000,"[{'_account_id': 597}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 18:40:46.000000000', 'files': ['swift/cli/recon.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/2edcd0b7b9dd02a041fd1452ea17efda5f27f21c', 'message': ""py3: Fix swift-recon\n\nAvoid things like\n\n    TypeError: '<' not supported between instances of 'NoneType' and 'int'\n\nChange-Id: I82edbf1ddcc28f86e97405d21db0b96249412eac\n""}]",0,688533,2edcd0b7b9dd02a041fd1452ea17efda5f27f21c,12,3,1,15343,,,0,"py3: Fix swift-recon

Avoid things like

    TypeError: '<' not supported between instances of 'NoneType' and 'int'

Change-Id: I82edbf1ddcc28f86e97405d21db0b96249412eac
",git fetch https://review.opendev.org/openstack/swift refs/changes/33/688533/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/cli/recon.py'],1,2edcd0b7b9dd02a041fd1452ea17efda5f27f21c,, if last is None: continue,,2,0
openstack%2Fswift~master~I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81,openstack/swift,master,I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81,py3: fix swift-dispersion-populate,MERGED,2019-10-14 18:34:38.000000000,2019-10-15 17:45:41.000000000,2019-10-15 14:54:03.000000000,"[{'_account_id': 9625}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 18:34:38.000000000', 'files': ['bin/swift-dispersion-populate'], 'web_link': 'https://opendev.org/openstack/swift/commit/4c66596e630ee63cf2cd54d216c8e443203e59fe', 'message': 'py3: fix swift-dispersion-populate\n\nChange-Id: I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81\n'}]",0,688531,4c66596e630ee63cf2cd54d216c8e443203e59fe,10,3,1,15343,,,0,"py3: fix swift-dispersion-populate

Change-Id: I1f140ae00cbd25b23c9a40ee91dccee8c7c15d81
",git fetch https://review.opendev.org/openstack/swift refs/changes/31/688531/1 && git format-patch -1 --stdout FETCH_HEAD,['bin/swift-dispersion-populate'],1,4c66596e630ee63cf2cd54d216c8e443203e59fe,,"import ioimport six data = io.BytesIO(obj if six.PY2 else obj.encode('utf8')) conn.put_object(container, obj, data,","from six.moves import cStringIO as StringIO conn.put_object(container, obj, StringIO(obj),",4,2
openstack%2Fswift~master~I6da047716c05e4f2a9e1e74ca19afb62e812d172,openstack/swift,master,I6da047716c05e4f2a9e1e74ca19afb62e812d172,Fix kms_keymaster under Python 3,MERGED,2019-10-11 12:13:57.000000000,2019-10-15 17:45:33.000000000,2019-10-15 14:54:04.000000000,"[{'_account_id': 597}, {'_account_id': 6476}, {'_account_id': 15343}, {'_account_id': 22348}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-10-11 12:13:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/1e81a78da81a4c03bdc773ce8a11ba25e4996952', 'message': ""Fix on-disk encryption under Python 3\n\nWhen using encryption with Python 3, we get:\nTypeError: key: expected bytes or bytearray,\nbut got 'str' (txn: tx2b59918356794c709b34b-005da06b77)\n\nThis patch fixes it by converting the key into a bytearay.\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n""}, {'number': 2, 'created': '2019-10-11 12:46:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/d1f0c674c0429eca2aa15a569a129830a3399b34', 'message': ""Fix on-disk encryption under Python 3\n\nWhen using encryption with Python 3, we get:\nTypeError: key: expected bytes or bytearray,\nbut got 'str' (txn: tx2b59918356794c709b34b-005da06b77)\n\nThis patch fixes it by converting the key into a bytearay.\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n""}, {'number': 3, 'created': '2019-10-11 16:33:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ac7970c6489aca64973816c4235f5b570f716d9b', 'message': ""Fix on-disk encryption under Python 3\n\nWhen using encryption with Python 3, we get:\nTypeError: key: expected bytes or bytearray,\nbut got 'str' (txn: tx2b59918356794c709b34b-005da06b77)\n\nThis patch fixes it by converting the key into a bytearay.\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n""}, {'number': 4, 'created': '2019-10-13 06:06:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/ad8a21628717fd3ba9eaaa54537ab8349a0353d8', 'message': ""Fix kms_keymaster under Python 3\n\nDepending on how the key was stored in Barbican, it may come out of\nCastellan as a native string, which would not be suitable on Python 3.\nNow, check that the secret is a byte string, and if it isn't, encode as\nUTF-8 (to match Barbican's internal encoding).\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n""}, {'number': 5, 'created': '2019-10-14 04:59:02.000000000', 'files': ['swift/common/middleware/crypto/keymaster.py', 'swift/common/middleware/crypto/kms_keymaster.py', 'test/unit/common/middleware/crypto/test_kms_keymaster.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/85d3658d6297efbe9a588d1b4364a2a68f9e5bb7', 'message': ""Fix kms_keymaster under Python 3\n\nDepending on how the key was stored in Barbican, it may come out of\nCastellan as a native string, which would not be suitable on Python 3.\nNow, check that the secret is a byte string, and if it isn't, encode as\nUTF-8 (to match Barbican's internal encoding).\n\nChange-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172\nCloses-Bug: #1847755\n""}]",4,688113,85d3658d6297efbe9a588d1b4364a2a68f9e5bb7,25,5,5,6476,,,0,"Fix kms_keymaster under Python 3

Depending on how the key was stored in Barbican, it may come out of
Castellan as a native string, which would not be suitable on Python 3.
Now, check that the secret is a byte string, and if it isn't, encode as
UTF-8 (to match Barbican's internal encoding).

Change-Id: I6da047716c05e4f2a9e1e74ca19afb62e812d172
Closes-Bug: #1847755
",git fetch https://review.opendev.org/openstack/swift refs/changes/13/688113/1 && git format-patch -1 --stdout FETCH_HEAD,['swift/common/middleware/crypto/keymaster.py'],1,1e81a78da81a4c03bdc773ce8a11ba25e4996952,bug/1847755," return hmac.new( bytes(key, 'latin-1'), wsgi_to_bytes(path),"," return hmac.new(key, wsgi_to_bytes(path),",1,1
openstack%2Fswift~master~Iae332bb58388b5521445e75beba6ee2e9f06bfa6,openstack/swift,master,Iae332bb58388b5521445e75beba6ee2e9f06bfa6,py3: Fix swift-drive-audit,MERGED,2019-10-14 04:57:22.000000000,2019-10-15 17:45:23.000000000,2019-10-14 20:57:15.000000000,"[{'_account_id': 1179}, {'_account_id': 15343}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 04:57:22.000000000', 'files': ['bin/swift-drive-audit', 'etc/drive-audit.conf-sample'], 'web_link': 'https://opendev.org/openstack/swift/commit/405a2b2a55866b74f196ad81eaafedeee4615fa8', 'message': 'py3: Fix swift-drive-audit\n\nWalking through the kernel logs backwards requires that we open them\nin binary mode. Add a new option to allow users to specify which\nencoding should be used to interpret those logs; default to the same\nencoding that open() uses for its default.\n\nChange-Id: Iae332bb58388b5521445e75beba6ee2e9f06bfa6\nCloses-Bug: #1847955\n'}]",0,688326,405a2b2a55866b74f196ad81eaafedeee4615fa8,10,3,1,15343,,,0,"py3: Fix swift-drive-audit

Walking through the kernel logs backwards requires that we open them
in binary mode. Add a new option to allow users to specify which
encoding should be used to interpret those logs; default to the same
encoding that open() uses for its default.

Change-Id: Iae332bb58388b5521445e75beba6ee2e9f06bfa6
Closes-Bug: #1847955
",git fetch https://review.opendev.org/openstack/swift refs/changes/26/688326/1 && git format-patch -1 --stdout FETCH_HEAD,"['bin/swift-drive-audit', 'etc/drive-audit.conf-sample']",2,405a2b2a55866b74f196ad81eaafedeee4615fa8,bug/1847955,"# On Python 3, the encoding to use when reading the log file. Defaults # to the result of locale.getpreferredencoding(), like Python's open(). # log_file_encoding = auto #",,17,4
openstack%2Fproject-config~master~I882147fc55aca3453e38fe526e9dcd3b688b1f27,openstack/project-config,master,I882147fc55aca3453e38fe526e9dcd3b688b1f27,Finish retiring puppet-yum,MERGED,2019-10-14 20:54:23.000000000,2019-10-15 17:43:19.000000000,2019-10-15 17:43:19.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:54:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/project-config/commit/ad4aee0d301583292166fb937da21cc206f0fec1', 'message': 'Finish retiring puppet-yum\n\nDepends-On: https://review.opendev.org/688565\nChange-Id: I882147fc55aca3453e38fe526e9dcd3b688b1f27\n'}, {'number': 2, 'created': '2019-10-14 22:32:13.000000000', 'files': ['gerritbot/channels.yaml', 'gerrit/acls/opendev/puppet-yum.config', 'zuul.d/projects.yaml', 'zuul/main.yaml', 'gerrit/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/0372cb0b14807914e3c6ff07f52b46568f5d4c99', 'message': 'Finish retiring puppet-yum\n\nDepends-On: https://review.opendev.org/688565\nChange-Id: I882147fc55aca3453e38fe526e9dcd3b688b1f27\n'}]",1,688566,0372cb0b14807914e3c6ff07f52b46568f5d4c99,13,4,2,2,,,0,"Finish retiring puppet-yum

Depends-On: https://review.opendev.org/688565
Change-Id: I882147fc55aca3453e38fe526e9dcd3b688b1f27
",git fetch https://review.opendev.org/openstack/project-config refs/changes/66/688566/1 && git format-patch -1 --stdout FETCH_HEAD,"['gerritbot/channels.yaml', 'gerrit/acls/opendev/puppet-yum.config', 'gerrit/projects.yaml', 'zuul.d/projects.yaml', 'zuul/main.yaml']",5,ad4aee0d301583292166fb937da21cc206f0fec1,infra-centos-7,, - opendev/puppet-yum,1,26
openstack%2Ftripleo-heat-templates~master~I2349e93251b3433c868d7790ba9f915f86d85143,openstack/tripleo-heat-templates,master,I2349e93251b3433c868d7790ba9f915f86d85143,"Add compute role ""ComputeSriovIB"" for infiniband deployments",MERGED,2019-10-14 09:12:34.000000000,2019-10-15 17:41:13.000000000,2019-10-15 17:39:54.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 12171}, {'_account_id': 14985}, {'_account_id': 16690}, {'_account_id': 18575}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25241}]","[{'number': 1, 'created': '2019-10-14 09:12:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/476fb3ff1243fa2cda9ae6b2d7c17cb28521f26f', 'message': 'Add compute role ""ComputeSriovIB"" for infiniband deployments\n\nAdd role ""ComputeSriovIB"" that contains the required services for IB\ndeployment (Mellanox agent, eSwitchd).\n\nChange-Id: I2349e93251b3433c868d7790ba9f915f86d85143\n'}, {'number': 2, 'created': '2019-10-14 09:15:13.000000000', 'files': ['releasenotes/notes/add-compute-sriov-ib-role-15baefb0dadfcbac.yaml', 'roles/ComputeSriov.yaml', 'roles/ComputeSriovIB.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/ebaf1852b957e4366d30174540659a4ad6bf3f25', 'message': 'Add compute role ""ComputeSriovIB"" for infiniband deployments\n\nAdd role ""ComputeSriovIB"" that contains the required services for IB\ndeployment (Mellanox agent, eSwitchd).\n\nChange-Id: I2349e93251b3433c868d7790ba9f915f86d85143\n'}]",0,688358,ebaf1852b957e4366d30174540659a4ad6bf3f25,11,9,2,22948,,,0,"Add compute role ""ComputeSriovIB"" for infiniband deployments

Add role ""ComputeSriovIB"" that contains the required services for IB
deployment (Mellanox agent, eSwitchd).

Change-Id: I2349e93251b3433c868d7790ba9f915f86d85143
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/58/688358/2 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/notes/add-compute-sriov-ib-role-15baefb0dadfcbac.yaml', 'roles/ComputeSriov.yaml', 'roles/ComputeSriovIB.yaml']",3,476fb3ff1243fa2cda9ae6b2d7c17cb28521f26f,,"############################################################################### # Role: ComputeSriov # ############################################################################### - name: ComputeSriov description: | Compute SR-IOV Role CountDefault: 1 networks: InternalApi: subnet: internal_api_subnet Tenant: subnet: tenant_subnet Storage: subnet: storage_subnet RoleParametersDefault: TunedProfileName: ""cpu-partitioning"" update_serial: 25 ServicesDefault: - OS::TripleO::Services::Aide - OS::TripleO::Services::AuditD - OS::TripleO::Services::BootParams - OS::TripleO::Services::CACerts - OS::TripleO::Services::CephClient - OS::TripleO::Services::CephExternal - OS::TripleO::Services::CertmongerUser - OS::TripleO::Services::Collectd - OS::TripleO::Services::ComputeCeilometerAgent - OS::TripleO::Services::ComputeNeutronCorePlugin - OS::TripleO::Services::ComputeNeutronL3Agent - OS::TripleO::Services::ComputeNeutronMetadataAgent - OS::TripleO::Services::ComputeNeutronOvsAgent - OS::TripleO::Services::Docker - OS::TripleO::Services::IpaClient - OS::TripleO::Services::Ipsec - OS::TripleO::Services::Iscsid - OS::TripleO::Services::Kernel - OS::TripleO::Services::LoginDefs - OS::TripleO::Services::MetricsQdr - OS::TripleO::Services::Multipathd - OS::TripleO::Services::MySQLClient - OS::TripleO::Services::NeutronBgpVpnBagpipe - OS::TripleO::Services::NeutronSriovAgent - OS::TripleO::Services::NeutronSriovHostConfig - OS::TripleO::Services::NeutronMlnxAgent - OS::TripleO::Services::NeutronVppAgent - OS::TripleO::Services::NovaCompute - OS::TripleO::Services::NovaLibvirt - OS::TripleO::Services::NovaLibvirtGuests - OS::TripleO::Services::NovaMigrationTarget - OS::TripleO::Services::ContainersLogrotateCrond - OS::TripleO::Services::OpenDaylightOvs - OS::TripleO::Services::Podman - OS::TripleO::Services::Rhsm - OS::TripleO::Services::Rsyslog - OS::TripleO::Services::RsyslogSidecar - OS::TripleO::Services::Securetty - OS::TripleO::Services::SensuClient - OS::TripleO::Services::SkydiveAgent - OS::TripleO::Services::Snmp - OS::TripleO::Services::Sshd - OS::TripleO::Services::Timesync - OS::TripleO::Services::Timezone - OS::TripleO::Services::TripleoFirewall - OS::TripleO::Services::TripleoPackages - OS::TripleO::Services::Vpp - OS::TripleO::Services::OVNController - OS::TripleO::Services::OVNMetadataAgent ",,72,1
openstack%2Fdesignate~master~I7ebc7991bd4f59579195d337f1787fd8abefbe90,openstack/designate,master,I7ebc7991bd4f59579195d337f1787fd8abefbe90,Don't install v1 dashboard panel,MERGED,2019-10-15 13:10:25.000000000,2019-10-15 17:22:20.000000000,2019-10-15 17:20:27.000000000,"[{'_account_id': 8099}, {'_account_id': 19298}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 13:10:25.000000000', 'files': ['devstack/plugin.sh'], 'web_link': 'https://opendev.org/openstack/designate/commit/b9e6549ad30b2b06ef6ca409a3a89e1c68ad6a47', 'message': ""Don't install v1 dashboard panel\n\nThe panel _1720_project_dns_panel.py has been removed in [0], stop\ntrying to install it in our devstack plugin.\n\n[0] Iabf7d396ea6feb0cd7de1c5408a81a7a3ce1efbf\n\nChange-Id: I7ebc7991bd4f59579195d337f1787fd8abefbe90\n""}]",0,688706,b9e6549ad30b2b06ef6ca409a3a89e1c68ad6a47,8,3,1,13252,,,0,"Don't install v1 dashboard panel

The panel _1720_project_dns_panel.py has been removed in [0], stop
trying to install it in our devstack plugin.

[0] Iabf7d396ea6feb0cd7de1c5408a81a7a3ce1efbf

Change-Id: I7ebc7991bd4f59579195d337f1787fd8abefbe90
",git fetch https://review.opendev.org/openstack/designate refs/changes/06/688706/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack/plugin.sh'],1,b9e6549ad30b2b06ef6ca409a3a89e1c68ad6a47,fix-dashboard,, _1720_project_dns_panel.py \,0,1
openstack%2Ftripleo-ansible~master~I5fc0f3d726b4735ae0e38bd6d5332ad7c1ea4d4f,openstack/tripleo-ansible,master,I5fc0f3d726b4735ae0e38bd6d5332ad7c1ea4d4f,Fix booleans settings in podman_container,MERGED,2019-10-14 19:14:18.000000000,2019-10-15 16:58:15.000000000,2019-10-15 16:58:14.000000000,"[{'_account_id': 3153}, {'_account_id': 7353}, {'_account_id': 9592}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-14 19:14:18.000000000', 'files': ['tripleo_ansible/ansible_plugins/modules/podman_container.py'], 'web_link': 'https://opendev.org/openstack/tripleo-ansible/commit/18ece9fd5ff721765947181ccb5c74e3c5d6fccb', 'message': 'Fix booleans settings in podman_container\n\nBoolean arguments should be passed as ""--key=True|False"".\n\nChange-Id: I5fc0f3d726b4735ae0e38bd6d5332ad7c1ea4d4f\n'}]",0,688540,18ece9fd5ff721765947181ccb5c74e3c5d6fccb,7,5,1,10969,,,0,"Fix booleans settings in podman_container

Boolean arguments should be passed as ""--key=True|False"".

Change-Id: I5fc0f3d726b4735ae0e38bd6d5332ad7c1ea4d4f
",git fetch https://review.opendev.org/openstack/tripleo-ansible refs/changes/40/688540/1 && git format-patch -1 --stdout FETCH_HEAD,['tripleo_ansible/ansible_plugins/modules/podman_container.py'],1,18ece9fd5ff721765947181ccb5c74e3c5d6fccb,bools, return c + ['--detach=%s' % self.params['detach']] return c + ['--http-proxy=%s' % self.params['http_proxy']] return c + ['--interactive=%s' % self.params['interactive']] return c + ['--no-hosts=%s' % self.params['no_hosts']] return c + ['--oom-kill-disable=%s' % self.params['oom_kill_disable']] return c + ['--privileged=%s' % self.params['privileged']] return c + ['--publish-all=%s' % self.params['publish_all']] return c + ['--read-only=%s' % self.params['read_only']] return c + ['--read-only-tmpfs=%s' % self.params['read_only_tmpfs']] return c + ['--rm=%s' % self.params['rm']] return c + ['--rootfs=%s' % self.params['rootfs']] return c + ['--sig-proxy=%s' % self.params['sig_proxy']] return c + ['--systemd=%s' % self.params['systemd']] return c + ['--tty=%s' % self.params['tty']]," return c + ['--detach'] if self.params['detach'] else c return c + ['--http-proxy', self.params['http_proxy']] return c + ['--interactive'] if self.params['interactive'] else c return c + ['--no-hosts', self.params['no_hosts']] return c + ['--oom-kill-disable', self.params['oom_kill_disable']] return c + ['--privileged'] if self.params['privileged'] else c return c + ['--publish-all', self.params['publish_all']] return c + ['--read-only', self.params['read_only']] return c + ['--read-only-tmpfs', self.params['read_only_tmpfs']] return c + ['--rm'] if self.params['rm'] else c return c + ['--rootfs'] if self.params['rootfs'] else c return c + ['--sig-proxy', self.params['sig_proxy']] return c + ['--systemd', self.params['systemd']] return c + ['--tty'] if self.params['tty'] else c",14,14
openstack%2Fpuppet-glance~stable%2Ftrain~I1829c7e59058fa72690dc08b3e2f65afcad7ea46,openstack/puppet-glance,stable/train,I1829c7e59058fa72690dc08b3e2f65afcad7ea46,Fix properties in glance_image provider for osc >= 4.0.0,MERGED,2019-10-11 05:36:53.000000000,2019-10-15 16:49:12.000000000,2019-10-15 16:49:12.000000000,"[{'_account_id': 3153}, {'_account_id': 13861}, {'_account_id': 14985}, {'_account_id': 16137}, {'_account_id': 21129}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-11 05:36:53.000000000', 'files': ['spec/unit/provider/glance_image_spec.rb', 'lib/puppet/provider/glance_image/openstack.rb', 'spec/acceptance/basic_glance_spec.rb'], 'web_link': 'https://opendev.org/openstack/puppet-glance/commit/9baa3816535a43787b978389d41a9e04064513fa', 'message': 'Fix properties in glance_image provider for osc >= 4.0.0\n\nSimilar to I6a68505d15473b140c85a199a09d2fee45864800\n\nOpenstackclient 4.0.0 changed the way some properties are displayed\non screen.\n\nOld:\n...,""Properties""\n...,""foo=\'bar\'""\n\nNew:\n...,""Properties""\n...,""{u\'foo\': u\'bar\'}""\nor\n...,""{\'foo\': \'bar\'}""\n\nThis is breaking idempotency on the glance_image provider, since it\ndoes not detect them correctly. This patch aims at fixing this, by\ntrying to detect the new format, and using JSON parsing in that case.\n\nChange-Id: I1829c7e59058fa72690dc08b3e2f65afcad7ea46\n(cherry picked from commit 13653589788c6ebe4f0d129968161216fd53f161)\n'}]",0,688035,9baa3816535a43787b978389d41a9e04064513fa,14,6,1,13861,,,0,"Fix properties in glance_image provider for osc >= 4.0.0

Similar to I6a68505d15473b140c85a199a09d2fee45864800

Openstackclient 4.0.0 changed the way some properties are displayed
on screen.

Old:
...,""Properties""
...,""foo='bar'""

New:
...,""Properties""
...,""{u'foo': u'bar'}""
or
...,""{'foo': 'bar'}""

This is breaking idempotency on the glance_image provider, since it
does not detect them correctly. This patch aims at fixing this, by
trying to detect the new format, and using JSON parsing in that case.

Change-Id: I1829c7e59058fa72690dc08b3e2f65afcad7ea46
(cherry picked from commit 13653589788c6ebe4f0d129968161216fd53f161)
",git fetch https://review.opendev.org/openstack/puppet-glance refs/changes/35/688035/1 && git format-patch -1 --stdout FETCH_HEAD,"['spec/unit/provider/glance_image_spec.rb', 'lib/puppet/provider/glance_image/openstack.rb', 'spec/acceptance/basic_glance_spec.rb']",3,9baa3816535a43787b978389d41a9e04064513fa,osc_train-stable/train, expect(r.stdout).to match(/properties=.*icanhaz.*cheezburger/)," expect(r.stdout).to include('properties=""icanhaz=\'cheezburger\'')",49,2
openstack%2Ftripleo-heat-templates~stable%2Frocky~Id5f7bb2160215170561f39015ddfdb93cba904b5,openstack/tripleo-heat-templates,stable/rocky,Id5f7bb2160215170561f39015ddfdb93cba904b5,Add new parameter options to Octavia service,MERGED,2019-09-27 14:22:49.000000000,2019-10-15 16:48:21.000000000,2019-10-15 16:46:27.000000000,"[{'_account_id': 3153}, {'_account_id': 7144}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-09-27 14:22:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0f9063479ce80b759a64be2a386d7a0c16a57c3f', 'message': 'Add new parameter options to Octavia service\n\nThis patch adds three new parameters:\n\n1. OctaviaConnectionMaxRetries\n2. OctaviaBuildActiveRetries\n3. OctaviaPortDetachTimeout\n\nThe default values are same as in octavia and puppet-octavia master\nbranches as of now.\n\nDepends-On: https://review.opendev.org/#/c/682636/\nChange-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5\n(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)\n(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)\n'}, {'number': 2, 'created': '2019-10-12 09:21:14.000000000', 'files': ['puppet/services/octavia-controller.yaml', 'releasenotes/notes/add-three-more-octavia-params-1e4a32f910e5f1fc.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/dd3356189ba67bbe01d6a94ae95133e32c0bce86', 'message': 'Add new parameter options to Octavia service\n\nThis patch adds three new parameters:\n\n1. OctaviaConnectionMaxRetries\n2. OctaviaBuildActiveRetries\n3. OctaviaPortDetachTimeout\n\nThe default values are same as in octavia and puppet-octavia master\nbranches as of now.\n\nDepends-On: https://review.opendev.org/#/c/682636/\nChange-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5\n(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)\n(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)\n'}]",0,685362,dd3356189ba67bbe01d6a94ae95133e32c0bce86,16,5,2,6469,,,0,"Add new parameter options to Octavia service

This patch adds three new parameters:

1. OctaviaConnectionMaxRetries
2. OctaviaBuildActiveRetries
3. OctaviaPortDetachTimeout

The default values are same as in octavia and puppet-octavia master
branches as of now.

Depends-On: https://review.opendev.org/#/c/682636/
Change-Id: Id5f7bb2160215170561f39015ddfdb93cba904b5
(cherry picked from commit f924a35d70270a96104a7381a32a6982d3678903)
(cherry picked from commit e90b0d898e72c60f34755f212a2cf669d82f26ae)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/62/685362/2 && git format-patch -1 --stdout FETCH_HEAD,"['puppet/services/octavia-controller.yaml', 'releasenotes/notes/add-three-more-octavia-params-1e4a32f910e5f1fc.yaml']",2,0f9063479ce80b759a64be2a386d7a0c16a57c3f,,"--- features: - | Three new parameter options are now added to Octavia service (OctaviaConnectionMaxRetries, OctaviaBuildActiveRetries, OctaviaPortDetachTimeout) ",,21,0
openstack%2Ftripleo-heat-templates~stable%2Fqueens~Ic84cc8864c799eaa4273c022b07445ec997a7fc9,openstack/tripleo-heat-templates,stable/queens,Ic84cc8864c799eaa4273c022b07445ec997a7fc9,Add posibilities to configure OVNNorthboundServerPort in split stacks,MERGED,2019-10-15 08:19:22.000000000,2019-10-15 16:46:29.000000000,2019-10-15 16:46:29.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 08:19:22.000000000', 'files': ['puppet/services/neutron-plugin-ml2-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/6a5cab4bf2c06f76a3c6a05b40c7ad481ebd2773', 'message': 'Add posibilities to configure OVNNorthboundServerPort in split stacks\n\nThis changes is need by split stacks when ovn dbs are not colocated\nwith neutron-server to configure correctly OVNNorthboundServerPort.\nWhen neutron api is deployed with ovn dbs on the same node,\novn dbs template set this port. But in other cases when\nthey are not colocated we need to set this port in neutron\nplugin template.\n\nChange-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9\nSigned-off-by: Kamil Sambor <ksambor@redhat.com>\n(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)\n(cherry picked from commit 4eed337552f030892aa837568c723e7130ae93f9)\n(cherry picked from commit 2a26c01b2270075e7450c3b750a7c79ab8d7f334)\n'}]",0,688650,6a5cab4bf2c06f76a3c6a05b40c7ad481ebd2773,6,4,1,11082,,,0,"Add posibilities to configure OVNNorthboundServerPort in split stacks

This changes is need by split stacks when ovn dbs are not colocated
with neutron-server to configure correctly OVNNorthboundServerPort.
When neutron api is deployed with ovn dbs on the same node,
ovn dbs template set this port. But in other cases when
they are not colocated we need to set this port in neutron
plugin template.

Change-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9
Signed-off-by: Kamil Sambor <ksambor@redhat.com>
(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)
(cherry picked from commit 4eed337552f030892aa837568c723e7130ae93f9)
(cherry picked from commit 2a26c01b2270075e7450c3b750a7c79ab8d7f334)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/50/688650/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/neutron-plugin-ml2-ovn.yaml'],1,6a5cab4bf2c06f76a3c6a05b40c7ad481ebd2773,, OVNNorthboundServerPort: description: Port of the OVN Northbound DB server type: number default: 6641 ovn::northbound::port: {get_param: OVNNorthboundServerPort},,5,0
openstack%2Ftripleo-heat-templates~stable%2Frocky~I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79,openstack/tripleo-heat-templates,stable/rocky,I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79,Fix placement of Octavia services in roles,MERGED,2019-10-08 07:48:20.000000000,2019-10-15 16:46:26.000000000,2019-10-15 16:46:25.000000000,"[{'_account_id': 3153}, {'_account_id': 11491}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-08 07:48:20.000000000', 'files': ['roles/ControllerAllNovaStandalone.yaml', 'roles/ControllerNovaStandalone.yaml', 'roles/Networker.yaml', 'roles/ControllerOpenstack.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/58ae272d24e0c3a548a7b6afebddf4115c3d17df', 'message': 'Fix placement of Octavia services in roles\n\nOctavia health manager, worker and housekeeping services belong to\nnetworker nodes.\n\nChange-Id: I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79\n(cherry picked from commit 3fca17839c1840df04f584eb7217fbbe18e386e4)\n'}]",0,687227,58ae272d24e0c3a548a7b6afebddf4115c3d17df,9,4,1,6469,,,0,"Fix placement of Octavia services in roles

Octavia health manager, worker and housekeeping services belong to
networker nodes.

Change-Id: I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79
(cherry picked from commit 3fca17839c1840df04f584eb7217fbbe18e386e4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/27/687227/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ControllerAllNovaStandalone.yaml', 'roles/ControllerNovaStandalone.yaml', 'roles/Networker.yaml', 'roles/ControllerOpenstack.yaml']",4,58ae272d24e0c3a548a7b6afebddf4115c3d17df,,, - OS::TripleO::Services::OctaviaHealthManager - OS::TripleO::Services::OctaviaHousekeeping - OS::TripleO::Services::OctaviaWorker,6,6
openstack%2Ftripleo-common~stable%2Frocky~I6afe5078bd285374b3a9311a066ba10883c2ff66,openstack/tripleo-common,stable/rocky,I6afe5078bd285374b3a9311a066ba10883c2ff66,Handle empty cert related hostvar info,MERGED,2019-10-10 19:38:59.000000000,2019-10-15 16:46:24.000000000,2019-10-15 16:46:24.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25877}]","[{'number': 1, 'created': '2019-10-10 19:38:59.000000000', 'files': ['playbooks/octavia-files.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/97f3b8b010e7f63925b47af6b262038983763f01', 'message': 'Handle empty cert related hostvar info\n\nWhen certificates are neither generated nor provided (e.g. on update)\nrelated variables would be empty or undefined and need to be handled\naccordingly.\n\nNote: this file has been relocated to triple-ansible in train+ so this\nis a non-trivial backport of I361c90e438e79e180e2a745da82e619347fed13e.\n\nChange-Id: I6afe5078bd285374b3a9311a066ba10883c2ff66\nCloses-Bug: #1845366\n(cherry picked from commit de57975786f80b6aff8d3145071277c05359e79c)\n'}]",0,687968,97f3b8b010e7f63925b47af6b262038983763f01,8,4,1,6681,,,0,"Handle empty cert related hostvar info

When certificates are neither generated nor provided (e.g. on update)
related variables would be empty or undefined and need to be handled
accordingly.

Note: this file has been relocated to triple-ansible in train+ so this
is a non-trivial backport of I361c90e438e79e180e2a745da82e619347fed13e.

Change-Id: I6afe5078bd285374b3a9311a066ba10883c2ff66
Closes-Bug: #1845366
(cherry picked from commit de57975786f80b6aff8d3145071277c05359e79c)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/68/687968/1 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/octavia-files.yaml'],1,97f3b8b010e7f63925b47af6b262038983763f01,rocky," private_key_content: ""{{ hostvars[groups['octavia_nodes'][0]]['private_key_content'] | default('') }}"" ca_cert_content: ""{{ hostvars[groups['octavia_nodes'][0]]['ca_cert_content'] | default('') }}"" service_pem_content: ""{{ hostvars[groups['octavia_nodes'][0]]['service_pem_content'] | default('') }}"""," private_key_content: ""{{ hostvars[groups['octavia_nodes'][0]]['private_key_content'] }}"" ca_cert_content: ""{{ hostvars[groups['octavia_nodes'][0]]['ca_cert_content'] }}"" service_pem_content: ""{{ hostvars[groups['octavia_nodes'][0]]['service_pem_content'] }}""",3,3
openstack%2Fswift~master~Ic41b37ac75b5596a8307c4962be86f2a4b0d9731,openstack/swift,master,Ic41b37ac75b5596a8307c4962be86f2a4b0d9731,Consistently use io.BytesIO,MERGED,2019-10-14 21:03:51.000000000,2019-10-15 16:42:18.000000000,2019-10-15 16:39:19.000000000,"[{'_account_id': 597}, {'_account_id': 9625}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 21:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/swift/commit/96fbb7258d2115b886c1051011a04127450d0a96', 'message': 'Consistently use io.BytesIO\n\nChange-Id: Ic41b37ac75b5596a8307c4962be86f2a4b0d9731\n'}, {'number': 2, 'created': '2019-10-15 13:10:49.000000000', 'files': ['test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/common/test_direct_client.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/functional/tests.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_xprofile.py', 'swift/common/wsgi.py', 'test/functional/swift_test_client.py', 'test/unit/common/middleware/s3api/test_s3request.py', 'test/unit/common/test_wsgi.py', 'test/unit/common/test_internal_client.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'test/unit/common/middleware/test_proxy_logging.py', 'swift/common/swob.py', 'test/unit/common/test_swob.py', 'test/unit/common/middleware/s3api/test_acl.py', 'test/unit/common/test_utils.py', 'test/unit/obj/test_ssync_receiver.py'], 'web_link': 'https://opendev.org/openstack/swift/commit/d270596b6766bf59ea8eaa58a7d48dd2b368cf37', 'message': 'Consistently use io.BytesIO\n\nChange-Id: Ic41b37ac75b5596a8307c4962be86f2a4b0d9731\n'}]",1,688571,d270596b6766bf59ea8eaa58a7d48dd2b368cf37,10,3,2,15343,,,0,"Consistently use io.BytesIO

Change-Id: Ic41b37ac75b5596a8307c4962be86f2a4b0d9731
",git fetch https://review.opendev.org/openstack/swift refs/changes/71/688571/2 && git format-patch -1 --stdout FETCH_HEAD,"['test/unit/account/test_server.py', 'test/unit/common/middleware/test_formpost.py', 'test/unit/obj/test_ssync_sender.py', 'test/unit/common/test_direct_client.py', 'test/unit/proxy/test_server.py', 'test/unit/__init__.py', 'test/functional/tests.py', 'test/unit/container/test_server.py', 'test/unit/common/middleware/test_xprofile.py', 'swift/common/wsgi.py', 'test/functional/swift_test_client.py', 'test/unit/common/middleware/s3api/test_s3request.py', 'test/unit/common/test_wsgi.py', 'test/unit/common/test_internal_client.py', 'test/unit/common/middleware/test_bulk.py', 'test/unit/common/middleware/test_slo.py', 'test/unit/common/middleware/test_proxy_logging.py', 'swift/common/swob.py', 'test/unit/common/test_swob.py', 'test/unit/common/middleware/s3api/test_acl.py', 'test/unit/common/test_utils.py', 'test/unit/obj/test_ssync_receiver.py']",22,96fbb7258d2115b886c1051011a04127450d0a96,,"import io class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) line = io.BytesIO.readline(self) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) line = io.BytesIO.readline(self) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) line = io.BytesIO.readline(self) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) line = io.BytesIO.readline(self) class _Wrapper(io.BytesIO): io.BytesIO.__init__(self, value) class _IgnoreReadlineHint(io.BytesIO): io.BytesIO.__init__(self, value) return io.BytesIO.readline(self)"," class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) line = six.BytesIO.readline(self) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) line = six.BytesIO.readline(self) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) line = six.BytesIO.readline(self) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) line = six.BytesIO.readline(self) class _Wrapper(six.BytesIO): six.BytesIO.__init__(self, value) class _IgnoreReadlineHint(six.BytesIO): six.BytesIO.__init__(self, value) return six.BytesIO.readline(self)",61,57
openstack%2Ftripleo-heat-templates~stable%2Frocky~Ic84cc8864c799eaa4273c022b07445ec997a7fc9,openstack/tripleo-heat-templates,stable/rocky,Ic84cc8864c799eaa4273c022b07445ec997a7fc9,Add posibilities to configure OVNNorthboundServerPort in split stacks,MERGED,2019-10-15 08:06:48.000000000,2019-10-15 16:42:17.000000000,2019-10-15 16:42:17.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 08:06:48.000000000', 'files': ['puppet/services/neutron-plugin-ml2-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/2a26c01b2270075e7450c3b750a7c79ab8d7f334', 'message': 'Add posibilities to configure OVNNorthboundServerPort in split stacks\n\nThis changes is need by split stacks when ovn dbs are not colocated\nwith neutron-server to configure correctly OVNNorthboundServerPort.\nWhen neutron api is deployed with ovn dbs on the same node,\novn dbs template set this port. But in other cases when\nthey are not colocated we need to set this port in neutron\nplugin template.\n\nChange-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9\nSigned-off-by: Kamil Sambor <ksambor@redhat.com>\n(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)\n(cherry picked from commit 4eed337552f030892aa837568c723e7130ae93f9)\n'}]",0,688647,2a26c01b2270075e7450c3b750a7c79ab8d7f334,7,5,1,11082,,,0,"Add posibilities to configure OVNNorthboundServerPort in split stacks

This changes is need by split stacks when ovn dbs are not colocated
with neutron-server to configure correctly OVNNorthboundServerPort.
When neutron api is deployed with ovn dbs on the same node,
ovn dbs template set this port. But in other cases when
they are not colocated we need to set this port in neutron
plugin template.

Change-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9
Signed-off-by: Kamil Sambor <ksambor@redhat.com>
(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)
(cherry picked from commit 4eed337552f030892aa837568c723e7130ae93f9)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/47/688647/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/neutron-plugin-ml2-ovn.yaml'],1,2a26c01b2270075e7450c3b750a7c79ab8d7f334,, OVNNorthboundServerPort: description: Port of the OVN Northbound DB server type: number default: 6641 ovn::northbound::port: {get_param: OVNNorthboundServerPort},,5,0
openstack%2Ftripleo-heat-templates~stable%2Fstein~I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79,openstack/tripleo-heat-templates,stable/stein,I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79,Fix placement of Octavia services in roles,MERGED,2019-10-08 07:48:13.000000000,2019-10-15 16:42:14.000000000,2019-10-15 16:42:14.000000000,"[{'_account_id': 3153}, {'_account_id': 11491}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-08 07:48:13.000000000', 'files': ['roles/ControllerAllNovaStandalone.yaml', 'roles/ControllerNovaStandalone.yaml', 'roles/Networker.yaml', 'roles/ControllerOpenstack.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/1e26c7875a22dd34a4009e60b48eb6a29a4945c0', 'message': 'Fix placement of Octavia services in roles\n\nOctavia health manager, worker and housekeeping services belong to\nnetworker nodes.\n\nChange-Id: I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79\n(cherry picked from commit 3fca17839c1840df04f584eb7217fbbe18e386e4)\n'}]",0,687226,1e26c7875a22dd34a4009e60b48eb6a29a4945c0,9,4,1,6469,,,0,"Fix placement of Octavia services in roles

Octavia health manager, worker and housekeeping services belong to
networker nodes.

Change-Id: I014a3a5ac2b0b5f32866fa9d5c09ac7e79475e79
(cherry picked from commit 3fca17839c1840df04f584eb7217fbbe18e386e4)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/687226/1 && git format-patch -1 --stdout FETCH_HEAD,"['roles/ControllerAllNovaStandalone.yaml', 'roles/ControllerNovaStandalone.yaml', 'roles/Networker.yaml', 'roles/ControllerOpenstack.yaml']",4,1e26c7875a22dd34a4009e60b48eb6a29a4945c0,,, - OS::TripleO::Services::OctaviaHealthManager - OS::TripleO::Services::OctaviaHousekeeping - OS::TripleO::Services::OctaviaWorker,6,6
openstack%2Ftripleo-heat-templates~stable%2Fstein~Ic84cc8864c799eaa4273c022b07445ec997a7fc9,openstack/tripleo-heat-templates,stable/stein,Ic84cc8864c799eaa4273c022b07445ec997a7fc9,Add posibilities to configure OVNNorthboundServerPort in split stacks,MERGED,2019-10-15 08:05:03.000000000,2019-10-15 16:42:11.000000000,2019-10-15 16:42:11.000000000,"[{'_account_id': 3153}, {'_account_id': 6681}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 08:05:03.000000000', 'files': ['puppet/services/neutron-plugin-ml2-ovn.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/4eed337552f030892aa837568c723e7130ae93f9', 'message': 'Add posibilities to configure OVNNorthboundServerPort in split stacks\n\nThis changes is need by split stacks when ovn dbs are not colocated\nwith neutron-server to configure correctly OVNNorthboundServerPort.\nWhen neutron api is deployed with ovn dbs on the same node,\novn dbs template set this port. But in other cases when\nthey are not colocated we need to set this port in neutron\nplugin template.\n\nChange-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9\nSigned-off-by: Kamil Sambor <ksambor@redhat.com>\n(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)\n'}]",0,688646,4eed337552f030892aa837568c723e7130ae93f9,7,5,1,11082,,,0,"Add posibilities to configure OVNNorthboundServerPort in split stacks

This changes is need by split stacks when ovn dbs are not colocated
with neutron-server to configure correctly OVNNorthboundServerPort.
When neutron api is deployed with ovn dbs on the same node,
ovn dbs template set this port. But in other cases when
they are not colocated we need to set this port in neutron
plugin template.

Change-Id: Ic84cc8864c799eaa4273c022b07445ec997a7fc9
Signed-off-by: Kamil Sambor <ksambor@redhat.com>
(cherry picked from commit cacb8700d03bd182fb84fe6ab9a99c90aff209c2)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/688646/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet/services/neutron-plugin-ml2-ovn.yaml'],1,4eed337552f030892aa837568c723e7130ae93f9,, OVNNorthboundServerPort: description: Port of the OVN Northbound DB server type: number default: 6641 ovn::northbound::port: {get_param: OVNNorthboundServerPort},,5,0
openstack%2Fsahara-dashboard~master~Ia7665d7af18dd1addf0f7c70992892eacae98d50,openstack/sahara-dashboard,master,Ia7665d7af18dd1addf0f7c70992892eacae98d50,Switch to official Ussuri jobs,MERGED,2019-10-14 07:02:05.000000000,2019-10-15 16:40:38.000000000,2019-10-15 16:40:37.000000000,"[{'_account_id': 8932}, {'_account_id': 10459}, {'_account_id': 22348}, {'_account_id': 27822}]","[{'number': 1, 'created': '2019-10-14 07:02:05.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/sahara-dashboard/commit/5199f8a58d76ab42c7c35bcb6f3e2aa1db5de851', 'message': 'Switch to official Ussuri jobs\n\nChange-Id: Ia7665d7af18dd1addf0f7c70992892eacae98d50\n'}]",0,688343,5199f8a58d76ab42c7c35bcb6f3e2aa1db5de851,8,4,1,29313,,,0,"Switch to official Ussuri jobs

Change-Id: Ia7665d7af18dd1addf0f7c70992892eacae98d50
",git fetch https://review.opendev.org/openstack/sahara-dashboard refs/changes/43/688343/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,5199f8a58d76ab42c7c35bcb6f3e2aa1db5de851,, - openstack-python3-ussuri-jobs-horizon, - openstack-python3-train-jobs-horizon,1,1
openstack%2Fcharm-nova-compute~master~I11e870fff3d590d2ac491292f3f2c68d84a67181,openstack/charm-nova-compute,master,I11e870fff3d590d2ac491292f3f2c68d84a67181,Fix hooks path for all actions,MERGED,2019-06-25 21:02:48.000000000,2019-10-15 16:39:22.000000000,2019-10-15 16:39:22.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-06-25 21:02:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/b13ae2689da42f0f1fa41073ca67082c90924aad', 'message': 'Fix path for openstack-upgrade action\n\nInsert the hooks directory at the beginning of sys.path in order to\nmake it take precedence over other entries, e.g. in the face of\nconflicting charmhelpers packages\n\nChange-Id: I11e870fff3d590d2ac491292f3f2c68d84a67181\nCloses-Bug: 1834254\n'}, {'number': 2, 'created': '2019-10-10 11:24:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/49ee87b85d9396fc0495b511cf924ded846266de', 'message': 'Fix hooks path for all actions\n\nInsert the hooks directory at the beginning of sys.path in order to\nmake it take precedence over other entries, e.g. in the face of\nconflicting charmhelpers packages.\n\nChange-Id: I11e870fff3d590d2ac491292f3f2c68d84a67181\nCloses-Bug: 1834254\n'}, {'number': 3, 'created': '2019-10-10 12:04:04.000000000', 'files': ['actions/pause_resume.py', 'actions/openstack_upgrade.py', 'actions/security_checklist.py', 'actions/hugepagereport.py'], 'web_link': 'https://opendev.org/openstack/charm-nova-compute/commit/4a4908160df6f90b9c6ae1cf315e026db2f50034', 'message': 'Fix hooks path for all actions\n\nInsert the hooks directory at the beginning of sys.path in order to\nmake it take precedence over other entries, e.g. in the face of\nconflicting charmhelpers packages.\n\nChange-Id: I11e870fff3d590d2ac491292f3f2c68d84a67181\nCloses-Bug: 1834254\n'}]",1,667464,4a4908160df6f90b9c6ae1cf315e026db2f50034,23,7,3,15382,,,0,"Fix hooks path for all actions

Insert the hooks directory at the beginning of sys.path in order to
make it take precedence over other entries, e.g. in the face of
conflicting charmhelpers packages.

Change-Id: I11e870fff3d590d2ac491292f3f2c68d84a67181
Closes-Bug: 1834254
",git fetch https://review.opendev.org/openstack/charm-nova-compute refs/changes/64/667464/2 && git format-patch -1 --stdout FETCH_HEAD,['actions/openstack_upgrade.py'],1,b13ae2689da42f0f1fa41073ca67082c90924aad,bug/1834254,"sys.path.insert(1, 'hooks/')",sys.path.append('hooks/'),1,1
openstack%2Fldappool~master~I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f,openstack/ldappool,master,I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f,Follow the PTI for docs,MERGED,2019-09-27 16:53:51.000000000,2019-10-15 16:39:11.000000000,2019-10-15 16:37:20.000000000,"[{'_account_id': 5046}, {'_account_id': 8482}, {'_account_id': 22348}, {'_account_id': 27621}]","[{'number': 1, 'created': '2019-09-27 16:53:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ldappool/commit/435620a016b47bae6206a2ead9e8f86b34fc34f2', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nThis requires using the sphinxcontrib-apidoc plugin rather than the\nautodoc pbr extention. We also remove the reference to the ChangeLog\nfile that is usually generated by pbr and instead refer to the published\nreno release notes. Also fixes the header formatting for the index page,\nas the headers weren't rendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f\n""}, {'number': 2, 'created': '2019-09-27 16:55:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ldappool/commit/14ce00d8bae1cd570d9a33eb05c5c3b66615f794', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nThis requires using the sphinxcontrib-apidoc plugin rather than the\nautodoc pbr extention. We also remove the reference to the ChangeLog\nfile that is usually generated by pbr and instead refer to the published\nreno release notes. Also fixes the header formatting for the index page,\nas the headers weren't rendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f\n""}, {'number': 3, 'created': '2019-10-09 08:05:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/ldappool/commit/75abd398c2a80e589c4e1fc22a94a2438e3fb2d8', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nWe remove the reference to the ChangeLog file that is usually generated\nby pbr and instead refer to the published reno release notes. Also fixes\nthe header formatting for the index page, as the headers weren't\nrendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f\n""}, {'number': 4, 'created': '2019-10-09 13:17:27.000000000', 'files': ['doc/source/index.rst', 'doc/source/history.rst', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/ldappool/commit/8f2f2e3827d36c06932a3e9691f3a75f1cfb94be', 'message': ""Follow the PTI for docs\n\nUse sphinx-build instead of the pbr sphinx extention for building docs\nas instructed by the PTI[1].\n\nWe remove the reference to the ChangeLog file that is usually generated\nby pbr and instead refer to the published reno release notes. Also fixes\nthe header formatting for the index page, as the headers weren't\nrendering at all.\n\n[1] https://governance.openstack.org/tc/reference/pti/python.html\n\nChange-Id: I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f\n""}]",3,685402,8f2f2e3827d36c06932a3e9691f3a75f1cfb94be,16,4,4,27621,,,0,"Follow the PTI for docs

Use sphinx-build instead of the pbr sphinx extention for building docs
as instructed by the PTI[1].

We remove the reference to the ChangeLog file that is usually generated
by pbr and instead refer to the published reno release notes. Also fixes
the header formatting for the index page, as the headers weren't
rendering at all.

[1] https://governance.openstack.org/tc/reference/pti/python.html

Change-Id: I36142eeb1590c551c6df3bd7d0bc7b7a4a8c692f
",git fetch https://review.opendev.org/openstack/ldappool refs/changes/02/685402/4 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/index.rst', 'doc/source/history.rst', 'doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",5,435620a016b47bae6206a2ead9e8f86b34fc34f2,685402, sphinx-build -W -b html -d doc/build/doctrees doc/source doc/build/html, python setup.py build_sphinx,18,10
openstack%2Ftripleo-heat-templates~stable%2Fstein~Ib3c70c136fa4a03b58edc370343a01d657b5b101,openstack/tripleo-heat-templates,stable/stein,Ib3c70c136fa4a03b58edc370343a01d657b5b101,Permit access to Ceph RGW for 'member' role,MERGED,2019-10-15 08:33:24.000000000,2019-10-15 16:38:35.000000000,2019-10-15 16:38:35.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-15 08:33:24.000000000', 'files': ['deployment/ceph-ansible/ceph-rgw.yaml', 'deployment/ceph-ansible/ceph-base.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/7ecd756b7c5eff4ef938fced335d75123749b1f3', 'message': ""Permit access to Ceph RGW for 'member' role\n\nFrom the Rocky release, Keystone is bootstrapped by default [1]\nwith a 'member' role, while previously we used to create at\ndeployment time a role called 'Member'.\n\nRole names are case insensitive in Keystone but Ceph RGW expects\na whitelist of role names to which access is permitted. This change\nadds 'member' to the Ceph RGW whitelist, in addition to 'Member'.\n\n1. https://blueprints.launchpad.net/keystone/+spec/basic-default-roles\n\nChange-Id: Ib3c70c136fa4a03b58edc370343a01d657b5b101\nCloses-Bug: 1847539\n(cherry picked from commit 1357a131c83e0d4c699df5b9230c382a803eb5d7)\n""}]",0,688651,7ecd756b7c5eff4ef938fced335d75123749b1f3,7,3,1,6796,,,0,"Permit access to Ceph RGW for 'member' role

From the Rocky release, Keystone is bootstrapped by default [1]
with a 'member' role, while previously we used to create at
deployment time a role called 'Member'.

Role names are case insensitive in Keystone but Ceph RGW expects
a whitelist of role names to which access is permitted. This change
adds 'member' to the Ceph RGW whitelist, in addition to 'Member'.

1. https://blueprints.launchpad.net/keystone/+spec/basic-default-roles

Change-Id: Ib3c70c136fa4a03b58edc370343a01d657b5b101
Closes-Bug: 1847539
(cherry picked from commit 1357a131c83e0d4c699df5b9230c382a803eb5d7)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/51/688651/1 && git format-patch -1 --stdout FETCH_HEAD,"['deployment/ceph-ansible/ceph-base.yaml', 'deployment/ceph-ansible/ceph-rgw.yaml']",2,7ecd756b7c5eff4ef938fced335d75123749b1f3,," ceph::rgw::keystone::auth::roles: [ 'admin', 'member' ]"," ceph::rgw::keystone::auth::roles: [ 'admin', 'Member' ]",2,2
openstack%2Ftripleo-heat-templates~stable%2Fstein~I66ce37b19dd855e9798a7877494264f6a128d284,openstack/tripleo-heat-templates,stable/stein,I66ce37b19dd855e9798a7877494264f6a128d284,Remove containers before removing associated storage,MERGED,2019-10-04 04:31:41.000000000,2019-10-15 16:37:37.000000000,2019-10-15 16:37:37.000000000,"[{'_account_id': 3153}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-04 04:31:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f60e83ac371ff0e20779f3e15130843733e85581', 'message': ""Remove containers before removing associated storage\n\nWe added --storage option in https://review.opendev.org/#/c/679793/\nwhen removing containers with podman. However, it won't delete the exited\ncontainers, i.e only orphaned storage would be removed with it.\n\nSo, we have to do both 'rm' and 'rm --storage' with podman to ensure\nthat we don't get the container name already used error,\n\nChange-Id: I66ce37b19dd855e9798a7877494264f6a128d284\nDepends-On: https://review.opendev.org/681989\nRelated-Bug: #1840691\n(cherry picked from commit 529ad2d7772ced181d9273d4615d90c86ef3ba41)\n""}, {'number': 2, 'created': '2019-10-11 08:17:00.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/053a5f4fba6c5085adf742b3443ec7aec295f34f', 'message': ""Remove containers before removing associated storage\n\nWe added --storage option in https://review.opendev.org/#/c/679793/\nwhen removing containers with podman. However, it won't delete the exited\ncontainers, i.e only orphaned storage would be removed with it.\n\nSo, we have to do both 'rm' and 'rm --storage' with podman to ensure\nthat we don't get the container name already used error,\n\nChange-Id: I66ce37b19dd855e9798a7877494264f6a128d284\nDepends-On: https://review.opendev.org/681989\nRelated-Bug: #1840691\n(cherry picked from commit 529ad2d7772ced181d9273d4615d90c86ef3ba41)\n""}]",0,686521,053a5f4fba6c5085adf742b3443ec7aec295f34f,23,5,2,8833,,,0,"Remove containers before removing associated storage

We added --storage option in https://review.opendev.org/#/c/679793/
when removing containers with podman. However, it won't delete the exited
containers, i.e only orphaned storage would be removed with it.

So, we have to do both 'rm' and 'rm --storage' with podman to ensure
that we don't get the container name already used error,

Change-Id: I66ce37b19dd855e9798a7877494264f6a128d284
Depends-On: https://review.opendev.org/681989
Related-Bug: #1840691
(cherry picked from commit 529ad2d7772ced181d9273d4615d90c86ef3ba41)
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/21/686521/1 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,f60e83ac371ff0e20779f3e15130843733e85581,," def run_cmd(rm_cli_cmd): subproc = subprocess.Popen(rm_cli_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) cmd_stdout, cmd_stderr = subproc.communicate() if cmd_stdout: log.debug(cmd_stdout) if cmd_stderr and \ cmd_stderr != 'Error response from daemon: ' \ 'No such container: {}\n'.format(name): log.debug(cmd_stderr) rm_cli_cmd.append(name) run_cmd(rm_cli_cmd) # rm --storage is used as a mitigation of rm_storage_cli_cmd = [cli_cmd, 'rm', '--storage'] rm_storage_cli_cmd.append(name) run_cmd(rm_storage_cli_cmd)"," # --storage is used as a mitigation of rm_cli_cmd.extend(['--storage']) rm_cli_cmd.append(name) subproc = subprocess.Popen(rm_cli_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True) cmd_stdout, cmd_stderr = subproc.communicate() if cmd_stdout: log.debug(cmd_stdout) if cmd_stderr and \ cmd_stderr != 'Error response from daemon: ' \ 'No such container: {}\n'.format(name): log.debug(cmd_stderr)",20,14
openstack%2Fpuppet-tripleo~master~If6b19ad05e0f91425f93a1c123947e92cf2ba949,openstack/puppet-tripleo,master,If6b19ad05e0f91425f93a1c123947e92cf2ba949,Allow the IHA OCF and fencing resource to be moved to the nova service user,MERGED,2019-10-11 20:28:51.000000000,2019-10-15 16:37:36.000000000,2019-10-15 16:37:36.000000000,"[{'_account_id': 3153}, {'_account_id': 20172}, {'_account_id': 20778}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 30126}]","[{'number': 1, 'created': '2019-10-11 20:28:51.000000000', 'files': ['manifests/profile/base/pacemaker/instance_ha.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/066a360ee5d966be027130d85d6ab6296dd0d3e5', 'message': 'Allow the IHA OCF and fencing resource to be moved to the nova service user\n\nCurrently both nova evacuate and fence compute in the Instance HA\nsetup of tripleo user the keystone admin user in order to query nova,\nevacuate instances, disable/enable the nova-compute service and\ncall the nova force-down API.\n\nWith this patch we introduce the keystone_tenant parameter which is\nneeded when moving to the nova service user as it is different than\nkeystone_admin in that case.\n\nTested as follows:\n1. Deployed a normal unpatched OSP13 with IHA\n2. Run a redeploy with the following addition:\nparameter_defaults:\n  ExtraConfig:\n    tripleo::profile::base::pacemaker::instance_ha::keystone_password: ""%{hiera(\'nova::keystone::authtoken::password\')}""\n    tripleo::profile::base::pacemaker::instance_ha::keystone_admin: \'nova\'\n    tripleo::profile::base::pacemaker::instance_ha::keystone_tenant: \'service\'\n3. Observe the following:\n3.1. Both the fence_compute and nova evacuate resources have updated attributes\n3.2. IHA still works correctly\n\nChange-Id: If6b19ad05e0f91425f93a1c123947e92cf2ba949\n'}]",0,688198,066a360ee5d966be027130d85d6ab6296dd0d3e5,14,6,1,20172,,,0,"Allow the IHA OCF and fencing resource to be moved to the nova service user

Currently both nova evacuate and fence compute in the Instance HA
setup of tripleo user the keystone admin user in order to query nova,
evacuate instances, disable/enable the nova-compute service and
call the nova force-down API.

With this patch we introduce the keystone_tenant parameter which is
needed when moving to the nova service user as it is different than
keystone_admin in that case.

Tested as follows:
1. Deployed a normal unpatched OSP13 with IHA
2. Run a redeploy with the following addition:
parameter_defaults:
  ExtraConfig:
    tripleo::profile::base::pacemaker::instance_ha::keystone_password: ""%{hiera('nova::keystone::authtoken::password')}""
    tripleo::profile::base::pacemaker::instance_ha::keystone_admin: 'nova'
    tripleo::profile::base::pacemaker::instance_ha::keystone_tenant: 'service'
3. Observe the following:
3.1. Both the fence_compute and nova evacuate resources have updated attributes
3.2. IHA still works correctly

Change-Id: If6b19ad05e0f91425f93a1c123947e92cf2ba949
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/98/688198/1 && git format-patch -1 --stdout FETCH_HEAD,['manifests/profile/base/pacemaker/instance_ha.pp'],1,066a360ee5d966be027130d85d6ab6296dd0d3e5,iha_service_user,"# [*keystone_tenant*] # The keystone tenant # Defaults to hiera('keystone::roles::admin::admin_tenant', 'admin') ## [*deep_compare_fencing*] # (Optional) Boolean, should fence_compute be deep compared in order to # update the existing fencing resource when puppet is being rerun # Defaults to hiera('tripleo::fencing', true) # # [*deep_compare_ocf*] # (Optional) Boolean, should the IHA ocf resource nova evacuate be deep # compared in order to update the resource when puppet is being rerun # Defaults to hiera('pacemaker::resource::ocf::deep_compare', true) # $keystone_tenant = hiera('keystone::roles::admin::admin_tenant', 'admin'), $deep_compare_fencing = hiera('tripleo::fencing', true), $deep_compare_ocf = hiera('pacemaker::resource::ocf::deep_compare', true), deep_compare => $deep_compare_fencing, deep_compare => $deep_compare_ocf, resource_params => ""auth_url=${keystone_endpoint_url} username=${keystone_admin} password=${keystone_password} user_domain=${user_domain} project_domain=${project_domain} tenant_name=${keystone_tenant} region_name=${region_name} ${iha_no_shared_storage}${evacuate_param}"", deep_compare => $deep_compare_ocf,"," resource_params => ""auth_url=${keystone_endpoint_url} username=${keystone_admin} password=${keystone_password} user_domain=${user_domain} project_domain=${project_domain} tenant_name=${keystone_admin} region_name=${region_name} ${iha_no_shared_storage}${evacuate_param}"",",21,1
openstack%2Fopenstack-helm~master~Ic8078537a7317c4132e4b11494e0d827365109d9,openstack/openstack-helm,master,Ic8078537a7317c4132e4b11494e0d827365109d9,Adding deployment guide for Openstack Helm with OVS-DPDK,MERGED,2019-07-12 13:24:27.000000000,2019-10-15 16:36:14.000000000,2019-10-15 16:34:48.000000000,"[{'_account_id': 8898}, {'_account_id': 12281}, {'_account_id': 16353}, {'_account_id': 17499}, {'_account_id': 20466}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23928}, {'_account_id': 27781}, {'_account_id': 28543}, {'_account_id': 28614}, {'_account_id': 28618}, {'_account_id': 29668}, {'_account_id': 30220}]","[{'number': 1, 'created': '2019-07-12 13:24:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/e7641b609897ac7ef890d82171cc90abea27406c', 'message': 'Adding deployment guide for Openstack Helm with OVS-DPDK\n\nThis patch adds a deployment guide for installing Openstack Helm\nwith OVS-DPDK\n\nChange-Id: Ic8078537a7317c4132e4b11494e0d827365109d9\n'}, {'number': 2, 'created': '2019-07-18 09:03:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/48d0069e75bbf41b9da0d5a98e21a5cdc773c6e1', 'message': 'Adding deployment guide for Openstack Helm with OVS-DPDK\n\nThis patch adds a deployment guide for installing Openstack Helm\nwith OVS-DPDK\n\nChange-Id: Ic8078537a7317c4132e4b11494e0d827365109d9\n'}, {'number': 3, 'created': '2019-07-18 09:04:48.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/b76e32c15291ced547ad837c8e22c15d5882b586', 'message': 'Adding deployment guide for Openstack Helm with OVS-DPDK\n\nThis patch adds a deployment guide for installing Openstack Helm\nwith OVS-DPDK\n\nChange-Id: Ic8078537a7317c4132e4b11494e0d827365109d9\n'}, {'number': 4, 'created': '2019-09-11 09:02:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/1ea6d3f40794552b0b6847553749e397529aace0', 'message': 'Adding deployment guide for Openstack Helm with OVS-DPDK\n\nThis patch adds a deployment guide for installing Openstack Helm\nwith OVS-DPDK\n\nChange-Id: Ic8078537a7317c4132e4b11494e0d827365109d9\n'}, {'number': 5, 'created': '2019-10-15 07:53:26.000000000', 'files': ['doc/source/install/developer/index.rst', 'doc/source/install/developer/deploy-ovs-dpdk.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/289feb7f7fdd6287d806cc4f9e5c40e2186725e7', 'message': 'Adding deployment guide for Openstack Helm with OVS-DPDK\n\nThis patch adds a deployment guide for installing Openstack Helm\nwith OVS-DPDK\n\nCo-Authored-By: Georg Kunz <georg.kunz@ericsson.com>\n\nChange-Id: Ic8078537a7317c4132e4b11494e0d827365109d9\n'}]",11,670550,289feb7f7fdd6287d806cc4f9e5c40e2186725e7,29,15,5,30220,,,0,"Adding deployment guide for Openstack Helm with OVS-DPDK

This patch adds a deployment guide for installing Openstack Helm
with OVS-DPDK

Co-Authored-By: Georg Kunz <georg.kunz@ericsson.com>

Change-Id: Ic8078537a7317c4132e4b11494e0d827365109d9
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/50/670550/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/install/developer/index.rst', 'doc/source/install/developer/deploy-ovs-dpdk.rst']",2,e7641b609897ac7ef890d82171cc90abea27406c,dpdk-doc,"=================== Deploy OVS-DPDK =================== Requirements ============ Before deploying Openvswitch with DPDK, ensure that you have sufficient available hugepages on the host OS and the hugepage information is sepcified in the OVS chart. More information can be found in the `Openvswitch documentation <http://docs.openvswitch.org/en/latest/intro/install/dpdk/>`_. Deploy NFS Provisioner ^^^^^^^^^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/040-nfs-provisioner.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/040-nfs-provisioner.sh Deploy MariaDB ^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/050-mariadb.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/050-mariadb.sh Deploy RabbitMQ ^^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/060-rabbitmq.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/060-rabbitmq.sh Deploy Memcached ^^^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/070-memcached.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/070-memcached.sh Deploy Keystone ^^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/080-keystone.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/080-keystone.sh Deploy Heat ^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/090-heat.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/090-heat.sh Deploy Horizon ^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/100-horizon.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/100-horizon.sh Deploy Glance ^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/120-glance.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/120-glance.sh Deploy OpenvSwitch ^^^^^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/140-openvswitch.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/140-openvswitch.sh Deploy Libvirt ^^^^^^^^^^^^^^ .. literalinclude:: ../../../../tools/deployment/developer/dpdk/150-libvirt.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/150-libvirt.sh Deploy Compute Kit (Nova and Neutron) ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ The default configuration of the neutron chart must be adapted according to the underlying hardware. The corresponding configuration parameter is labled with ""CHANGE-ME"" in the script ""160-compute-kit.sh"". Specifically, the ""ovs_dpdk"" configuration section should list all NICs which should be bound to DPDK with their corresponding PCI-IDs. Moreover, the name of each NIC needs to be unique, e.g., dpdk0, dpdk1, etc. .. literalinclude:: ../../../../tools/deployment/developer/dpdk/160-compute-kit.sh :language: shell :lines: 1,17- Alternatively, this step can be performed by running the script directly: .. code-block:: shell ./tools/deployment/developer/dpdk/160-compute-kit.sh ",,163,0
openstack%2Fkayobe~master~I1bd724be7dc77058870f37cb1c9404472fa466ca,openstack/kayobe,master,I1bd724be7dc77058870f37cb1c9404472fa466ca,Install libffi headers,MERGED,2019-10-15 12:36:20.000000000,2019-10-15 16:26:52.000000000,2019-10-15 16:25:05.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 12:36:20.000000000', 'files': ['dev/functions', 'doc/source/installation.rst'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/a3d3649c5ef555bfc73786258030a6986e779cc9', 'message': 'Install libffi headers\n\nThis is to resolve the following issue in CI:\n\n    c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory\n     #include <ffi.h>\n                     ^\n    compilation terminated.\n    error: command \'gcc\' failed with exit status 1\n    ----------------------------------------\nERROR: Command errored out with exit status 1: /home/zuul/kayobe-venv/bin/python -u -c \'import sys, setuptools, tokenize; sys.argv[0] = \'""\'""\'/tmp/pip-install-PV3WhJ/cffi/setup.py\'""\'""\'; __file__=\'""\'""\'/tmp/pip-install-PV3WhJ/cffi/setup.py\'""\'""\';f=getattr(tokenize, \'""\'""\'open\'""\'""\', open)(__file__);code=f.read().replace(\'""\'""\'\\r\\n\'""\'""\', \'""\'""\'\\n\'""\'""\');f.close();exec(compile(code, __file__, \'""\'""\'exec\'""\'""\'))\' install --record /tmp/pip-record-ZvlZVY/install-record.txt --single-version-externally-managed --compile --install-headers /home/zuul/kayobe-venv/include/site/python2.7/cffi Check the logs for full command output.\n\nChange-Id: I1bd724be7dc77058870f37cb1c9404472fa466ca\nsee: https://zuul.opendev.org/t/openstack/build/c20a316a699b4073abf75960634ebfcd\n'}]",0,688697,a3d3649c5ef555bfc73786258030a6986e779cc9,8,2,1,28048,,,0,"Install libffi headers

This is to resolve the following issue in CI:

    c/_cffi_backend.c:15:17: fatal error: ffi.h: No such file or directory
     #include <ffi.h>
                     ^
    compilation terminated.
    error: command 'gcc' failed with exit status 1
    ----------------------------------------
ERROR: Command errored out with exit status 1: /home/zuul/kayobe-venv/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '""'""'/tmp/pip-install-PV3WhJ/cffi/setup.py'""'""'; __file__='""'""'/tmp/pip-install-PV3WhJ/cffi/setup.py'""'""';f=getattr(tokenize, '""'""'open'""'""', open)(__file__);code=f.read().replace('""'""'\r\n'""'""', '""'""'\n'""'""');f.close();exec(compile(code, __file__, '""'""'exec'""'""'))' install --record /tmp/pip-record-ZvlZVY/install-record.txt --single-version-externally-managed --compile --install-headers /home/zuul/kayobe-venv/include/site/python2.7/cffi Check the logs for full command output.

Change-Id: I1bd724be7dc77058870f37cb1c9404472fa466ca
see: https://zuul.opendev.org/t/openstack/build/c20a316a699b4073abf75960634ebfcd
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/97/688697/1 && git format-patch -1 --stdout FETCH_HEAD,"['dev/functions', 'doc/source/installation.rst']",2,a3d3649c5ef555bfc73786258030a6986e779cc9,libffi, $ yum install -y python-devel python-virtualenv gcc libffi-devel $ apt install -y python-dev python-virtualenv gcc libffi-dev, $ yum install -y python-devel python-virtualenv gcc $ apt install -y python-dev python-virtualenv gcc,4,4
openstack%2Freleases~master~I6d049ab6a1b3a69b3aab185dcf13109b70d2a541,openstack/releases,master,I6d049ab6a1b3a69b3aab185dcf13109b70d2a541,Release Tempest 22.1.0,MERGED,2019-10-15 04:30:15.000000000,2019-10-15 16:09:34.000000000,2019-10-15 16:09:34.000000000,"[{'_account_id': 308}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 04:30:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/c793eddf70c72a6d33a7f61bd8cab7d18da5e94f', 'message': 'Release Tempest 22.1.0\n\nAdd new release for Tempest train which include the CLI\ntest framework bug.\n\nChange-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541\n'}, {'number': 2, 'created': '2019-10-15 04:30:36.000000000', 'files': ['deliverables/train/tempest.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/a05548fd34f02280a0caaf5a5c4b75d55a1c4e1c', 'message': 'Release Tempest 22.1.0\n\nAdd new release for Tempest train which include the CLI\ntest framework bug.\n\nChange-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541\n'}]",0,688613,a05548fd34f02280a0caaf5a5c4b75d55a1c4e1c,8,3,2,8556,,,0,"Release Tempest 22.1.0

Add new release for Tempest train which include the CLI
test framework bug.

Change-Id: I6d049ab6a1b3a69b3aab185dcf13109b70d2a541
",git fetch https://review.opendev.org/openstack/releases refs/changes/13/688613/2 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/tempest.yaml'],1,c793eddf70c72a6d33a7f61bd8cab7d18da5e94f,qa-train-release, - projects: - repo: openstack/tempest hash: c93345233e06c173a65a3edcb769c4220386b3bd version: 22.1.0,,4,0
openstack%2Freleases~master~Ia9a92dff0b0cf0d83fb98d5c815c324eb973a3d4,openstack/releases,master,Ia9a92dff0b0cf0d83fb98d5c815c324eb973a3d4,Release tripleoclient 12.3.0 + stable/train,MERGED,2019-10-15 12:11:45.000000000,2019-10-15 16:09:33.000000000,2019-10-15 16:09:32.000000000,"[{'_account_id': 308}, {'_account_id': 9592}, {'_account_id': 11904}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 12:11:45.000000000', 'files': ['deliverables/train/python-tripleoclient.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/32a3be738c75f03f1e5bbfc51f0cf120df6835b0', 'message': ""Release tripleoclient 12.3.0 + stable/train\n\nWe want to branch the tripleoclient first and once we confirm that the\nTripleO CI behaves correctly with the new branch, we'll release and\nbranch the other TripleO repositories.\n\nCo-Authored-By: wes hayutin <whayutin@gmail.com>\nChange-Id: Ia9a92dff0b0cf0d83fb98d5c815c324eb973a3d4\n""}]",0,688690,32a3be738c75f03f1e5bbfc51f0cf120df6835b0,8,4,1,3153,,,0,"Release tripleoclient 12.3.0 + stable/train

We want to branch the tripleoclient first and once we confirm that the
TripleO CI behaves correctly with the new branch, we'll release and
branch the other TripleO repositories.

Co-Authored-By: wes hayutin <whayutin@gmail.com>
Change-Id: Ia9a92dff0b0cf0d83fb98d5c815c324eb973a3d4
",git fetch https://review.opendev.org/openstack/releases refs/changes/90/688690/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/python-tripleoclient.yaml'],1,32a3be738c75f03f1e5bbfc51f0cf120df6835b0,tripleo/train/branch, - version: 12.3.0 projects: - repo: openstack/python-tripleoclient hash: 8ce8b93cbebe2e9eb9cf295b530c53d9d814e590 branches: - location: 12.3.0 name: stable/train,,7,0
openstack%2Fcharms.openstack~master~I9fe18badd78735899f44bc7f0733b8a1b1b40183,openstack/charms.openstack,master,I9fe18badd78735899f44bc7f0733b8a1b1b40183,Add get_password to DatabaseRelationAdapter,MERGED,2019-10-02 14:54:40.000000000,2019-10-15 16:03:57.000000000,2019-10-15 16:03:57.000000000,"[{'_account_id': 935}, {'_account_id': 11805}, {'_account_id': 20805}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-02 14:54:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/d3d2a0fe8bee642d4d81b468918f7f6dc3cab06f', 'message': 'Add updates for placement charm\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\n'}, {'number': 2, 'created': '2019-10-07 20:57:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/220e3aee89bba7474b21de4a1c5b56b7be03e1e4', 'message': 'Add get_password to DatabaseRelationAdapter\n\nget_password will be used initially by the placement charm\nwhen rendering config for database migration.\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\n'}, {'number': 3, 'created': '2019-10-08 17:24:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/e92b2a85a45c9409481f32e9a8987065cfc814e7', 'message': 'Add get_password to DatabaseRelationAdapter\n\nget_password will be used initially by the placement charm\nwhen rendering config for database migration.\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\n'}, {'number': 4, 'created': '2019-10-10 20:15:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/e11594afe924087171b39502aa716354d87d36f0', 'message': 'Add get_password to DatabaseRelationAdapter\n\nget_password will be used initially by the placement charm\nwhen rendering config for database migration.\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\nNeeded-By: https://review.opendev.org/#/c/687915/\n'}, {'number': 5, 'created': '2019-10-15 15:32:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/3cbce677784ee88ede13638c2639008e7187f175', 'message': 'Add get_password to DatabaseRelationAdapter\n\nget_password will be used initially by the placement charm\nwhen rendering config for database migration.\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\nNeeded-By: https://review.opendev.org/#/c/687915/\n'}, {'number': 6, 'created': '2019-10-15 15:33:22.000000000', 'files': ['charms_openstack/adapters.py', 'unit_tests/test_charms_openstack_adapters.py'], 'web_link': 'https://opendev.org/openstack/charms.openstack/commit/a5834054b850ab1de7195fbfde901bf8659f55df', 'message': 'Add get_password to DatabaseRelationAdapter\n\nget_password will be used initially by the placement charm\nwhen rendering config for database migration.\n\nChange-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183\nNeeded-By: https://review.opendev.org/#/c/687915/\n'}]",1,686177,a5834054b850ab1de7195fbfde901bf8659f55df,25,4,6,11805,,,0,"Add get_password to DatabaseRelationAdapter

get_password will be used initially by the placement charm
when rendering config for database migration.

Change-Id: I9fe18badd78735899f44bc7f0733b8a1b1b40183
Needed-By: https://review.opendev.org/#/c/687915/
",git fetch https://review.opendev.org/openstack/charms.openstack refs/changes/77/686177/6 && git format-patch -1 --stdout FETCH_HEAD,['charms_openstack/adapters.py'],1,d3d2a0fe8bee642d4d81b468918f7f6dc3cab06f,charms-train-placement," def get_password(self, prefix=None): if prefix: return self.relation.password(prefix=prefix) return self.password ",,5,0
openstack%2Fopenstack-ansible-os_swift~master~Ic8a752ef71c1205362a4e88a6098d152ca1b307e,openstack/openstack-ansible-os_swift,master,Ic8a752ef71c1205362a4e88a6098d152ca1b307e,update source link in readme,MERGED,2019-10-15 11:31:48.000000000,2019-10-15 16:03:45.000000000,2019-10-15 16:01:20.000000000,"[{'_account_id': 1004}, {'_account_id': 22348}, {'_account_id': 25023}]","[{'number': 1, 'created': '2019-10-15 11:31:48.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_swift/commit/87eb3dc3802c7e7bd5faf55ed50b7eefc4ba2606', 'message': 'update source link in readme\n\nChange-Id: Ic8a752ef71c1205362a4e88a6098d152ca1b307e\n'}]",0,688683,87eb3dc3802c7e7bd5faf55ed50b7eefc4ba2606,8,3,1,30384,,,0,"update source link in readme

Change-Id: Ic8a752ef71c1205362a4e88a6098d152ca1b307e
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_swift refs/changes/83/688683/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,87eb3dc3802c7e7bd5faf55ed50b7eefc4ba2606,, https://opendev.org/openstack/openstack-ansible-os_swift/ https://bugs.launchpad.net/openstack-ansible , https://git.openstack.org/cgit/openstack/openstack-ansible-os_swift/ https://bugs.launchpad.net/openstack-ansible,2,2
openstack%2Fneutron~master~I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91,openstack/neutron,master,I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91,Mock openstacksdk raise_from_response in ironic unit test,MERGED,2019-10-14 15:59:46.000000000,2019-10-15 16:00:57.000000000,2019-10-15 15:58:31.000000000,"[{'_account_id': 1131}, {'_account_id': 9732}, {'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 23851}, {'_account_id': 26622}, {'_account_id': 27654}]","[{'number': 1, 'created': '2019-10-14 15:59:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/7ddb9523e2704ec2902af541c846b2d7f289bda6', 'message': 'Mock openstacksdk exceptions in ironic unit test\n\nMocking the openstacksdk exception method raise_from_response\nto prevent random error messages even in succeded unit\ntests.\nAn example:\nhttps://zuul.opendev.org/t/openstack/build/943c3f89519c44a58e0b5c86ad4efff8/log/job-output.txt#23782-23789\n\nChange-Id: I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91\n'}, {'number': 2, 'created': '2019-10-14 16:00:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/9cd5d6a59012f121ac3fbc1840b142adb4451bc0', 'message': 'Mock openstacksdk raise_from_response in ironic unit test\n\nMocking the openstacksdk exception method raise_from_response\nto prevent random error messages even in succeded unit\ntests.\nAn example:\nhttps://zuul.opendev.org/t/openstack/build/943c3f89519c44a58e0b5c86ad4efff8/log/job-output.txt#23782-23789\n\nChange-Id: I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91\n'}, {'number': 3, 'created': '2019-10-15 08:37:38.000000000', 'files': ['neutron/tests/unit/notifiers/test_ironic.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/dce7af902c4207dcaa062eef7a21da2017fb37c7', 'message': 'Mock openstacksdk raise_from_response in ironic unit test\n\nMocking the openstacksdk exception method raise_from_response\nto prevent random error messages even in succeded unit\ntests.\nAn example:\nhttps://zuul.opendev.org/t/openstack/build/943c3f89519c44a58e0b5c86ad4efff8/log/job-output.txt#23782-23789\n\nChange-Id: I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91\nCloses-Bug: #1848147\n'}]",6,688439,dce7af902c4207dcaa062eef7a21da2017fb37c7,25,9,3,23851,,,0,"Mock openstacksdk raise_from_response in ironic unit test

Mocking the openstacksdk exception method raise_from_response
to prevent random error messages even in succeded unit
tests.
An example:
https://zuul.opendev.org/t/openstack/build/943c3f89519c44a58e0b5c86ad4efff8/log/job-output.txt#23782-23789

Change-Id: I3d9128d6712b4094c0b2ad7e12db9e5a915e3d91
Closes-Bug: #1848147
",git fetch https://review.opendev.org/openstack/neutron refs/changes/39/688439/1 && git format-patch -1 --stdout FETCH_HEAD,['neutron/tests/unit/notifiers/test_ironic.py'],1,7ddb9523e2704ec2902af541c846b2d7f289bda6,mock_os_exc,"from openstack import exceptions as os_exc @mock.patch.object(os_exc, 'raise_from_response', return_value=None) def test_send_events(self, mock_client, mock_os_raise_exc):"," def test_send_events(self, mock_client):",3,1
openstack%2Fopenstack-helm-infra~master~Ie88f74a1e7a84afb3fbca55b500009255b4f6991,openstack/openstack-helm-infra,master,Ie88f74a1e7a84afb3fbca55b500009255b4f6991,Add DPDK check for readiness probe,MERGED,2019-10-06 16:45:40.000000000,2019-10-15 15:53:30.000000000,2019-10-07 19:30:04.000000000,"[{'_account_id': 16353}, {'_account_id': 16881}, {'_account_id': 17900}, {'_account_id': 18250}, {'_account_id': 18256}, {'_account_id': 20466}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 23140}, {'_account_id': 23928}, {'_account_id': 28719}, {'_account_id': 30220}]","[{'number': 1, 'created': '2019-10-06 16:45:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/3576a50e80b4b7ff22ab8bcb9486234d7d23d0f5', 'message': 'Add DPDK check for readiness probe\n\nThis change makes sure that ""ovs-vsctl get Open_vSwitch .\ndpdk_initialized"" is true before making the pod ready\n\nChange-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991\n'}, {'number': 2, 'created': '2019-10-06 16:46:22.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/86d034f2e49ca6f599cc4721d7cc2e833346febd', 'message': 'Add DPDK check for readiness probe\n\nThis change makes sure that ""ovs-vsctl get Open_vSwitch .\ndpdk_initialized"" is true before making the pod ready\n\nChange-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991\n'}, {'number': 3, 'created': '2019-10-07 14:54:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/bfc01fabb9ab75db40432901a13af18a5ec61dbd', 'message': 'Add DPDK check for readiness probe\n\nThis change makes sure that ""ovs-vsctl get Open_vSwitch .\ndpdk_initialized"" is true before making the pod ready\n\nChange-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991\n'}, {'number': 4, 'created': '2019-10-07 15:46:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/433c8a925b4c70b572a30281aaaa8b4bbd149729', 'message': 'Add DPDK check for readiness probe\n\nThis change makes sure that ""ovs-vsctl get Open_vSwitch .\ndpdk_initialized"" is true before making the pod ready\n\nChange-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991\n'}, {'number': 5, 'created': '2019-10-07 16:08:17.000000000', 'files': ['openvswitch/templates/daemonset-ovs-vswitchd.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/926348fe2476051f9ca825916db333f81c0139b7', 'message': 'Add DPDK check for readiness probe\n\nThis change makes sure that ""ovs-vsctl get Open_vSwitch .\ndpdk_initialized"" is true before making the pod ready\n\nChange-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991\n'}]",3,686944,926348fe2476051f9ca825916db333f81c0139b7,20,12,5,18256,,,0,"Add DPDK check for readiness probe

This change makes sure that ""ovs-vsctl get Open_vSwitch .
dpdk_initialized"" is true before making the pod ready

Change-Id: Ie88f74a1e7a84afb3fbca55b500009255b4f6991
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/44/686944/5 && git format-patch -1 --stdout FETCH_HEAD,['openvswitch/templates/daemonset-ovs-vswitchd.yaml'],1,3576a50e80b4b7ff22ab8bcb9486234d7d23d0f5,,{{- if not .Values.conf.ovs_dpdk.enabled }}{{- else }} exec: command: - /bin/bash - -c - '! /usr/bin/ovs-vsctl show | grep -q error: && [ $(ovs-vsctl get Open_vSwitch . dpdk_initialized) == true ]' {{- end }} ,,8,0
openstack%2Fkolla-ansible~master~Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,openstack/kolla-ansible,master,Ic08a8e53a6905a68f0fe26d4b28184e62a64324f,Fix CI failures,MERGED,2019-10-15 11:16:50.000000000,2019-10-15 15:51:31.000000000,2019-10-15 15:49:20.000000000,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 24072}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-10-15 11:16:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/6c79c294c7fd70d134f8e096f052623498506649', 'message': 'Fix yamllint errors in .yamllint file(!)\n\nChange-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f\n'}, {'number': 2, 'created': '2019-10-15 12:15:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/3b747284338c8d35b3daabd646d6f76a4dbc7916', 'message': 'Fix CI failures\n\n1. Fix yamllint errors in .yamllint file(!)\n\nYAML lint is currently failling on its own configuration file,\n.yamllint. This change fixes the issues.\n\n2. Run bindep role in Zuul jobs\n\nThis fixes an issue where libffi is not available.\n\nChange-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f\n'}, {'number': 3, 'created': '2019-10-15 12:28:20.000000000', 'files': ['.yamllint', 'tests/pre.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/e3e5f7f20f4b067142ffecacbe47789eed1d0e3b', 'message': 'Fix CI failures\n\n1. Fix yamllint errors in .yamllint file(!)\n\nYAML lint is currently failling on its own configuration file,\n.yamllint. This change fixes the issues.\n\n2. Run bindep role in Zuul jobs\n\nThis fixes an issue where libffi is not available.\n\nChange-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f\n'}]",2,688679,e3e5f7f20f4b067142ffecacbe47789eed1d0e3b,16,5,3,14826,,,0,"Fix CI failures

1. Fix yamllint errors in .yamllint file(!)

YAML lint is currently failling on its own configuration file,
.yamllint. This change fixes the issues.

2. Run bindep role in Zuul jobs

This fixes an issue where libffi is not available.

Change-Id: Ic08a8e53a6905a68f0fe26d4b28184e62a64324f
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/79/688679/2 && git format-patch -1 --stdout FETCH_HEAD,['.yamllint'],1,6c79c294c7fd70d134f8e096f052623498506649,,--- etc/kolla/globals.yml , etc/kolla/globals.yml,2,1
openstack%2Fcharm-rabbitmq-server~master~I876a90ce58c89e4a760dad88d5a2381d60171037,openstack/charm-rabbitmq-server,master,I876a90ce58c89e4a760dad88d5a2381d60171037,Port Charm RabbitMQ func tests from Amulet to Zaza,MERGED,2019-09-23 05:02:47.000000000,2019-10-15 15:51:27.000000000,2019-10-15 15:51:27.000000000,"[{'_account_id': 20634}, {'_account_id': 20648}, {'_account_id': 20805}, {'_account_id': 22348}, {'_account_id': 26040}, {'_account_id': 30793}]","[{'number': 1, 'created': '2019-09-23 05:02:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/c81128a45717359aa33025b1f94f360d7fff4e55', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nPartial-Bug: #1828424\n'}, {'number': 2, 'created': '2019-09-25 23:48:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/369991247aba78158d978247773f85a43c9d2bf3', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nPartial-Bug: #1828424\n'}, {'number': 3, 'created': '2019-09-26 01:20:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/96815779941f29420e0bf3c866296ed68332e881', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nPartial-Bug: #1828424\n'}, {'number': 4, 'created': '2019-09-29 23:39:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/7c50ff5a700b31cec13cc38ffa88343467787bbd', 'message': ""Port Charm RabbitMQ func tests from Amulet to Zaza\n\nThis MR is half of the work required to port the RabbitMQ charm func\ntests from Amulet to Zaza. The complementary func tests port MR can be\nfound here:\nhttps://github.com/openstack-charmers/zaza-openstack-tests/pull/60\n\nBefore this work can be merged, the above MR needs to be merged, and\nthis review's test-requirements.txt needs to be updated to reference\nthe upstream Zaza Openstack tests Git repo.\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nPartial-Bug: #1828424\n""}, {'number': 5, 'created': '2019-09-30 05:56:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/013bfdf3d0b515b2a1897e7172e04209405d4f0f', 'message': ""Port Charm RabbitMQ func tests from Amulet to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/60\n\nBefore this work can be merged this review's test-requirements.txt\nneeds to be updated to reference the upstream Zaza Openstack tests Git\nrepo.\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nCloses-Bug: #1828424\n""}, {'number': 6, 'created': '2019-09-30 06:11:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/5b9ffa98488aa02828c3de6bc6ecd166c6d3aff6', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/60\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nCloses-Bug: #1828424\n'}, {'number': 7, 'created': '2019-10-07 01:25:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/0ae9bf5a36c41f49324f4b6a13b79f43643a046f', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/60\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nCloses-Bug: #1828424\n'}, {'number': 8, 'created': '2019-10-10 02:07:43.000000000', 'files': ['tests/gate-basic-xenial-pike', 'test-requirements.txt', 'Makefile', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/xenial-queens.yaml', 'tests/bundles/xenial-pike.yaml', 'tests/README.md', 'tests/bundles/bionic-rocky.yaml', 'tests/gate-basic-xenial-mitaka', 'tests/bundles/bionic-queens.yaml', 'tests/dev-basic-disco-stein', 'tests/gate-basic-bionic-stein', 'tests/bundles/xenial-ocata.yaml', 'tests/bundles/disco-stein.yaml', 'tests/gate-basic-xenial-ocata', 'tests/bundles/xenial-mitaka.yaml', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/trusty-mitaka.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/gate-basic-bionic-rocky', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/charm-rabbitmq-server/commit/466ab245578406479e30072a3dcd4c223f3485ef', 'message': 'Port Charm RabbitMQ func tests from Amulet to Zaza\n\nfunc-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/60\n\nChange-Id: I876a90ce58c89e4a760dad88d5a2381d60171037\nCloses-Bug: #1828424\n'}]",9,683846,466ab245578406479e30072a3dcd4c223f3485ef,50,6,8,30793,,,0,"Port Charm RabbitMQ func tests from Amulet to Zaza

func-test-pr: https://github.com/openstack-charmers/zaza-openstack-tests/pull/60

Change-Id: I876a90ce58c89e4a760dad88d5a2381d60171037
Closes-Bug: #1828424
",git fetch https://review.opendev.org/openstack/charm-rabbitmq-server refs/changes/46/683846/7 && git format-patch -1 --stdout FETCH_HEAD,"['tests/gate-basic-xenial-pike', 'test-requirements.txt', 'Makefile', 'tests/gate-basic-trusty-mitaka', 'tests/bundles/xenial-queens.yaml', 'tests/bundles/xenial-pike.yaml', 'tests/README.md', 'tests/bundles/bionic-rocky.yaml', 'tests/gate-basic-xenial-mitaka', 'tests/bundles/bionic-queens.yaml', 'tests/dev-basic-disco-stein', 'tests/gate-basic-bionic-stein', 'tests/bundles/cosmic-rocky.yaml', 'tests/bundles/xenial-ocata.yaml', 'tests/bundles/disco-stein.yaml', 'tests/gate-basic-xenial-ocata', 'tests/bundles/xenial-mitaka.yaml', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/trusty-mitaka.yaml', 'tests/tests.yaml', 'tests/basic_deployment.py', 'tests/dev-basic-cosmic-rocky', 'tests/gate-basic-bionic-queens', 'tests/gate-basic-xenial-queens', 'tests/gate-basic-bionic-rocky', 'tox.ini']",26,c81128a45717359aa33025b1f94f360d7fff4e55,bug/1828424,[testenv:func] basepython = python3 functest-run-suite --keep-model [testenv:func-smoke] basepython = python3 functest-run-suite --keep-model --smoke [testenv:func-dev] basepython = python3 functest-run-suite --keep-model --dev [testenv:func-target] basepython = python3 functest-run-suite --keep-model --bundle {posargs},"[testenv:py27] basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = /bin/true [testenv:func27-noop] # DRY RUN - For Debug basepython = python2.7 bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""gate-*"" -n --no-destroy [testenv:func27] # Charm Functional Test # Run all gate tests which are +x (expected to always pass) basepython = python2.7 bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""gate-*"" --no-destroy [testenv:func27-smoke] # Charm Functional Test # Run a specific test as an Amulet smoke test (expected to always pass) basepython = python2.7 bundletester -vl DEBUG -r json -o func-results.json gate-basic-bionic-stein --no-destroy [testenv:func27-dfs] # Charm Functional Test # Run all deploy-from-source tests which are +x (may not always pass!) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""dfs-*"" --no-destroy [testenv:func27-dev] # Charm Functional Test # Run all development test targets which are +x (may not always pass!) basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = bundletester -vl DEBUG -r json -o func-results.json --test-pattern ""dev-*"" --no-destroy",457,1080
openstack%2Fopenstack-ansible-os_tempest~master~Ibba761551e6bc14c127d9461de2a72e9f0fcb715,openstack/openstack-ansible-os_tempest,master,Ibba761551e6bc14c127d9461de2a72e9f0fcb715,Append the tempest run command output in file,MERGED,2019-10-15 11:33:30.000000000,2019-10-15 15:27:54.000000000,2019-10-15 15:26:30.000000000,"[{'_account_id': 1004}, {'_account_id': 8367}, {'_account_id': 12393}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25023}, {'_account_id': 27379}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-15 11:33:30.000000000', 'files': ['tasks/tempest_run.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-os_tempest/commit/0c49b5c3089d3d2a6eaaa71a5fb8ba94865da2e6', 'message': 'Append the tempest run command output in file\n\nIn CI, when we run full tempest api and scenario tests, it takes\ntime and in most of the time at Execute tempest tasks hits\nTimeout and no ara report got generated. So we have no idea\nwhat tests ate the time.\n\nLogging the tempest result in a file will give more info\non what happened with the tests.\n\nChange-Id: Ibba761551e6bc14c127d9461de2a72e9f0fcb715\nSigned-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>\n'}]",0,688684,0c49b5c3089d3d2a6eaaa71a5fb8ba94865da2e6,12,8,1,12393,,,0,"Append the tempest run command output in file

In CI, when we run full tempest api and scenario tests, it takes
time and in most of the time at Execute tempest tasks hits
Timeout and no ara report got generated. So we have no idea
what tests ate the time.

Logging the tempest result in a file will give more info
on what happened with the tests.

Change-Id: Ibba761551e6bc14c127d9461de2a72e9f0fcb715
Signed-off-by: Chandan Kumar (raukadah) <chkumar@redhat.com>
",git fetch https://review.opendev.org/openstack/openstack-ansible-os_tempest refs/changes/84/688684/1 && git format-patch -1 --stdout FETCH_HEAD,['tasks/tempest_run.yml'],1,0c49b5c3089d3d2a6eaaa71a5fb8ba94865da2e6,tempest_log, --whitelist-file {{ tempest_test_whitelist_file_path }} > {{ tempest_log_dir }}/tempest_run.log, --whitelist-file {{ tempest_test_whitelist_file_path }},1,1
openstack%2Fopenstack-helm-addons~master~I7a22fd50d47e58df19b413ed65ab528e2d78d609,openstack/openstack-helm-addons,master,I7a22fd50d47e58df19b413ed65ab528e2d78d609,Health probe for Ranger-agent pods,MERGED,2019-09-27 22:21:12.000000000,2019-10-15 15:15:59.000000000,2019-10-15 15:15:59.000000000,"[{'_account_id': 17499}, {'_account_id': 17591}, {'_account_id': 17966}, {'_account_id': 18524}, {'_account_id': 19391}, {'_account_id': 20466}, {'_account_id': 21111}, {'_account_id': 22348}, {'_account_id': 22477}, {'_account_id': 22786}, {'_account_id': 23928}, {'_account_id': 24999}, {'_account_id': 28543}, {'_account_id': 29585}]","[{'number': 1, 'created': '2019-09-27 22:21:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/2fc6d94e48359e6e95805707f56956e06176eba9', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 2, 'created': '2019-09-27 22:24:05.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/a002644d071d315d3529abf4db839071df751ffe', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 3, 'created': '2019-09-30 20:16:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/9850bec34ed6227980f4c36b18dc9fe7ff43f648', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 4, 'created': '2019-10-01 15:03:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/bb08748fea167acd1abdfa62e300296ccd6de58c', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 5, 'created': '2019-10-01 15:43:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/b273e969df888886c4f56cd4a5eec9635df10e21', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 6, 'created': '2019-10-01 17:08:11.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6fdba1514496b4c0d7c4d3f09d69c61280f0884a', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 7, 'created': '2019-10-02 19:25:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/d5c138af3534405659cdf6403c926c83c78d8733', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 8, 'created': '2019-10-02 22:01:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/0cac39e5744279dd6f4572788fe01c53f89a440a', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 9, 'created': '2019-10-02 23:28:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/d736b49b8af64d62d4d0b30e7df180d5e63cc794', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 10, 'created': '2019-10-04 04:36:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6c08a7020b0ac286da5af7cf29eb23ffe7ee7c1b', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 11, 'created': '2019-10-04 19:43:17.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/6d1988d7f8f2700d561d75af15901d824566fd03', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 12, 'created': '2019-10-05 00:27:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/76787dc83239c29cb87aa7bc84ec93559e81a9e9', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 13, 'created': '2019-10-07 15:48:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/9176a544e153a35d316132ffdffa916c08bafbaf', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 14, 'created': '2019-10-07 21:05:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/325ef5e04c5fd4a06ac4a01074dec73ab35805cf', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 15, 'created': '2019-10-09 14:27:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/7b77ed2764d7d055a22648937a4f43e21b240f9a', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 16, 'created': '2019-10-11 19:58:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/d647eae8348ac0d2e6dea8abe8cc48aa64a7e6d9', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}, {'number': 17, 'created': '2019-10-11 21:13:55.000000000', 'files': ['tools/gate/scripts/070-deploy-ranger-agent.sh', 'ranger-agent/templates/configmap-bin.yaml', 'ranger-agent/templates/bin/_ranger-agent-test.sh.tpl', 'ranger-agent/templates/deployment-ranger-agent-api.yaml', 'ranger-agent/templates/bin/_health-probe.py.tpl', 'ranger-agent/values.yaml', 'ranger-agent/templates/deployment-ranger-agent-engine.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-helm-addons/commit/3b9adc2bf056b8e3ec5f800e189ebf31d51c0ab4', 'message': ""Health probe for Ranger-agent pods\n\nHealth probe for Ranger-agent pods is used for both liveness\nand readiness probe.\n\nranger-agent-api and ranger-agent-engine pods:\n- Sends an RPC call with a known method to pod's listener\n  queue. Probe is successful if call returns with no error. If\n  listener is not reachable or fails to respond in time, returns\n  failure to probe.\n- Check if the rpc socket status on ranger-agent pods to rabbitmq\n  are in established state.\n\nranger-agent-api pod:\n- Launch a call to pod's open interface. Probe is successful if call\n  returns; otherwise failure if response has error or timed out.\n\nChange-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609\n""}]",20,685501,3b9adc2bf056b8e3ec5f800e189ebf31d51c0ab4,66,14,17,19391,,,0,"Health probe for Ranger-agent pods

Health probe for Ranger-agent pods is used for both liveness
and readiness probe.

ranger-agent-api and ranger-agent-engine pods:
- Sends an RPC call with a known method to pod's listener
  queue. Probe is successful if call returns with no error. If
  listener is not reachable or fails to respond in time, returns
  failure to probe.
- Check if the rpc socket status on ranger-agent pods to rabbitmq
  are in established state.

ranger-agent-api pod:
- Launch a call to pod's open interface. Probe is successful if call
  returns; otherwise failure if response has error or timed out.

Change-Id: I7a22fd50d47e58df19b413ed65ab528e2d78d609
",git fetch https://review.opendev.org/openstack/openstack-helm-addons refs/changes/01/685501/17 && git format-patch -1 --stdout FETCH_HEAD,"['ranger-agent/templates/configmap-bin.yaml', 'ranger-agent/templates/deployment-ranger-agent-api.yaml', 'ranger-agent/templates/bin/_health-probe.py.tpl', 'ranger-agent/templates/deployment-ranger-agent-engine.yaml']",4,2fc6d94e48359e6e95805707f56956e06176eba9,merge_conflict, exec: command: - python - /tmp/health-probe.py - --config-file - /etc/ranger-agent/ranger-agent.conf - --service-name - ranger-agent-engine - --liveness-probe initialDelaySeconds: 120 periodSeconds: 90 timeoutSeconds: 70 readinessProbe: exec: command: - python - /tmp/health-probe.py - --config-file - /etc/ranger-agent/ranger-agent.conf - --service-name - ranger-agent-engine initialDelaySeconds: 80 periodSeconds: 90 timeoutSeconds: 70 mountPath: /tmp/health-probe.py subPath: health-probe.py, exec: command: - /tmp/health-check.sh - engineliveness initialDelaySeconds: 30 timeoutSeconds: 5 readinessProbe: exec: command: - /tmp/health-check.sh - enginereadiness initialDelaySeconds: 30 timeoutSeconds: 5 mountPath: /tmp/health-check.sh subPath: health-check.sh,302,26
openstack%2Fcharm-ceph-proxy~master~I2c8d84fadc11311c622dd308c4694496872dc157,openstack/charm-ceph-proxy,master,I2c8d84fadc11311c622dd308c4694496872dc157,"Sync charm/ceph helpers, tox, and requirements",MERGED,2019-09-30 22:07:27.000000000,2019-10-15 15:14:53.000000000,2019-10-15 15:14:53.000000000,"[{'_account_id': 935}, {'_account_id': 20634}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 20870}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-30 22:07:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/0e419a7b728493ae4373be740db3264cd243ad4a', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 2, 'created': '2019-10-01 02:43:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/4acaf097fc6a7c9237f3df59cc84ab770bf8a9f5', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 3, 'created': '2019-10-01 03:09:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/a8e08dea1385638977885d498ea1174fff6b777d', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 4, 'created': '2019-10-01 14:20:54.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/a4a12241feec1a9d3c079e62326b6ccddc875176', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 5, 'created': '2019-10-10 02:45:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/4c3f2e6bbed58619b641acf5f4c0935e6203ebc9', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 6, 'created': '2019-10-10 13:36:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/ff9de097e1b41646bc9a261dffc7a96b32aa1229', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 7, 'created': '2019-10-10 14:47:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/3753efcbd0f1c7aca30e743a96fe8d470960ea05', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nAlso clean-up mocking issues around apt-pkg replacements in the\nunit tests.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 8, 'created': '2019-10-10 15:56:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/9bebfd7d7639053f65d2dc9e98e9cc3ee55ae7f3', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nAlso clean-up mocking issues around apt-pkg replacements in the\nunit tests.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 9, 'created': '2019-10-10 19:23:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/2c1c63771ee3ba97b989138c05a4a80ea14bbef6', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nAlso clean-up mocking issues around apt-pkg replacements in the\nunit tests.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}, {'number': 10, 'created': '2019-10-14 17:25:45.000000000', 'files': ['charmhelpers/contrib/openstack/utils.py', 'tests/bundles/xenial-ocata.yaml', 'charmhelpers/fetch/__init__.py', 'test-requirements.txt', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tests/bundles/xenial-queens.yaml', 'unit_tests/test_ceph.py', 'charm-helpers-hooks.yaml', 'tests/bundles/bionic-stein.yaml', 'tests/bundles/xenial-pike.yaml', 'files/nagios/check_ceph_status.py', 'tests/bundles/bionic-rocky.yaml', 'tests/bundles/trusty-mitaka.yaml', 'unit_tests/test_ceph_hooks.py', 'charmhelpers/core/host.py', 'requirements.txt', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/openstack/policyd.py', 'tox.ini', 'actions.yaml'], 'web_link': 'https://opendev.org/openstack/charm-ceph-proxy/commit/63c0ebbcd7b70df2fe3969c1bf6a088a2a963a5f', 'message': 'Sync charm/ceph helpers, tox, and requirements\n\nAlso clean up pre-existing pep8 violations in the\nfiles/* dir which was previously not covered by lint testing.\n\nAlso clean-up mocking issues around apt-pkg replacements in the\nunit tests.\n\nAlso fix py35 issue with enabled_manager_modules() function in the\ncharmhelpers library (see\nhttps://github.com/juju/charm-helpers/pull/387).\n\nAlso fix the functional tests bundles so they actually test the\nversion of OpenStack that the bundle indicates.\n\nChange-Id: I2c8d84fadc11311c622dd308c4694496872dc157\n'}]",0,685818,63c0ebbcd7b70df2fe3969c1bf6a088a2a963a5f,47,6,10,20635,,,0,"Sync charm/ceph helpers, tox, and requirements

Also clean up pre-existing pep8 violations in the
files/* dir which was previously not covered by lint testing.

Also clean-up mocking issues around apt-pkg replacements in the
unit tests.

Also fix py35 issue with enabled_manager_modules() function in the
charmhelpers library (see
https://github.com/juju/charm-helpers/pull/387).

Also fix the functional tests bundles so they actually test the
version of OpenStack that the bundle indicates.

Change-Id: I2c8d84fadc11311c622dd308c4694496872dc157
",git fetch https://review.opendev.org/openstack/charm-ceph-proxy refs/changes/18/685818/1 && git format-patch -1 --stdout FETCH_HEAD,"['charmhelpers/contrib/openstack/utils.py', 'charmhelpers/core/host.py', 'requirements.txt', 'charmhelpers/fetch/__init__.py', 'charmhelpers/fetch/ubuntu_apt_pkg.py', 'test-requirements.txt', 'charmhelpers/contrib/hardening/audits/apt.py', 'charmhelpers/contrib/storage/linux/ceph.py', 'charmhelpers/fetch/ubuntu.py', 'charmhelpers/core/host_factory/ubuntu.py', 'tox.ini']",11,0e419a7b728493ae4373be740db3264cd243ad4a,batch-update,"# Classic charm (with zaza): ./tox.ini# within individual charm repos. See the 'global' dir contents for available # choices of tox.ini for OpenStack Charms: # https://github.com/openstack-charmers/release-tools # # TODO: Distill the func test requirements from the lint/unit test # requirements. They are intertwined. Also, Zaza itself should specify # all of its own requirements and if it doesn't, fix it there.envlist = pep8,py3# NOTE: Avoid build/test env pollution by not enabling sitepackages.# NOTE: Avoid false positives by not skipping missing interpreters.commands = stestr run --slowest {posargs}passenv = HOME TERM CS_* OS_* TEST_* deps = -r{toxinidir}/test-requirements.txt[testenv:py3] basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = flake8 {posargs} hooks unit_tests tests actions lib files[testenv:cover] # Technique based heavily upon # https://github.com/openstack/nova/blob/master/tox.ini basepython = python3 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt setenv = {[testenv]setenv} PYTHON=coverage run commands = coverage erase stestr run --slowest {posargs} coverage combine coverage html -d cover coverage xml -o cover/coverage.xml coverage report [coverage:run] branch = True concurrency = multiprocessing parallel = True source = . omit = .tox/* */charmhelpers/* unit_tests/* [testenv:func-noop] basepython = python3 commands = functest-run-suite --help [testenv:func-target] basepython = python3 commands = functest-run-suite --keep-model --bundle {posargs} [flake8] ignore = E402,E226 exclude = */charmhelpers","# Classic charm: ./tox.ini# within individual charm repos.envlist = pep8,py37# NOTE(beisner): Avoid build/test env pollution by not enabling sitepackages.# NOTE(beisner): Avoid false positives by not skipping missing interpreters.commands = stestr run {posargs}passenv = HOME TERM OS_* CS_API_* deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt [testenv:py27] basepython = python2.7 deps = -r{toxinidir}/requirements.txt -r{toxinidir}/test-requirements.txt commands = /bin/truecommands = flake8 {posargs} hooks unit_tests tests actions lib[flake8] ignore = E402,E226 exclude = */charmhelpers",515,79
openstack%2Fopenstack-helm-infra~master~Ide8619dccc25239a712935a1f722a266cfeb5f8a,openstack/openstack-helm-infra,master,Ide8619dccc25239a712935a1f722a266cfeb5f8a,[ceph-osd] Stop zapping the block_db and block_wal partitions,ABANDONED,2019-10-11 14:29:19.000000000,2019-10-15 15:07:27.000000000,,"[{'_account_id': 22348}, {'_account_id': 29974}]","[{'number': 1, 'created': '2019-10-11 14:29:19.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/30bd777e7f6f8e151bc31a585f60e70191288185', 'message': '[ceph-osd] Force disk zap when required.\n\nThis is to enable an option for user to force disk zaping intentionally.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 2, 'created': '2019-10-11 14:30:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/d9420d5db5369f4c2c78be8768962f3c2e9387d1', 'message': '[ceph-osd] Force disk zap when required.\n\nThis is to enable an option for user to force disk zaping intentionally.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 3, 'created': '2019-10-11 15:56:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/f2f5c8958d7fa8a57879491a22e65f94d3b44b5a', 'message': '[ceph-osd] Force disk zap when required.\n\nThis is to enable an option for user to force disk zaping intentionally.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 4, 'created': '2019-10-14 14:46:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ce726948928ab6ed0d1d79755f54a75d2c2063da', 'message': '[ceph-osd] Force disk zap when required.\n\nThis is to enable an option for user to force disk zaping intentionally.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 5, 'created': '2019-10-14 14:46:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/2a265f8f04a1a2985c779e6d7b1737baac91d6d6', 'message': '[ceph-osd] Force disk zap when required.\n\nThis is to enable an option for user to force disk zaping intentionally.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 6, 'created': '2019-10-14 14:53:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/84f9d07ac4e87516c9bc12309da744ade81c2c46', 'message': '[ceph-osd] Stop zapping the block_db and block_wal partitions\n\nThis is to stop zapping block_db and block_wal partitions as it may\nhave parprobe issues since the same disk getting shared by other osds\nfor db and wal partiions.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 7, 'created': '2019-10-14 14:55:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/ed88eb4af1e1db419649678b1f242399f5b40fe1', 'message': '[ceph-osd] Stop zapping the block_db and block_wal partitions\n\nThis is to stop zapping block_db and block_wal partitions as it may\nhave parprobe issues since the same disk getting shared by other osds\nfor db and wal partiions.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 8, 'created': '2019-10-14 14:55:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/29eef4a83590dabdbb231bc961e47cf90a34951d', 'message': '[ceph-osd] Stop zapping the block_db and block_wal partitions\n\nThis is to stop zapping block_db and block_wal partitions as it may\nhave parprobe issues since the same disk getting shared by other osds\nfor db and wal partiions.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}, {'number': 9, 'created': '2019-10-15 15:07:17.000000000', 'files': ['ceph-osd/templates/bin/osd/_init.sh.tpl'], 'web_link': 'https://opendev.org/openstack/openstack-helm-infra/commit/b6edea1e3c4450c30ebafdeafe35ada2b0cca1f0', 'message': '[ceph-osd] Stop zapping the block_db and block_wal partitions\n\nThis is to stop zapping block_db and block_wal partitions as it may\nhave parprobe issues since the same disk getting shared by other osds\nfor db and wal partiions.\n\nChange-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a\n'}]",2,688134,b6edea1e3c4450c30ebafdeafe35ada2b0cca1f0,14,2,9,28372,,,0,"[ceph-osd] Stop zapping the block_db and block_wal partitions

This is to stop zapping block_db and block_wal partitions as it may
have parprobe issues since the same disk getting shared by other osds
for db and wal partiions.

Change-Id: Ide8619dccc25239a712935a1f722a266cfeb5f8a
",git fetch https://review.opendev.org/openstack/openstack-helm-infra refs/changes/34/688134/9 && git format-patch -1 --stdout FETCH_HEAD,"['ceph-osd/templates/daemonset-osd.yaml', 'ceph-osd/values.yaml', 'ceph-osd/templates/bin/osd/_init.sh.tpl']",3,30bd777e7f6f8e151bc31a585f60e70191288185,," if [ ${osdFSID} != ${cephFSID} ] || [ ""${FORCE_DISK_ZAP:-0}"" == 1 ]; then", if [ ${osdFSID} != ${cephFSID} ]; then,5,1
openstack%2Fpbr~master~If596d10413ae93f03a6f4ae87f3073d7f602c439,openstack/pbr,master,If596d10413ae93f03a6f4ae87f3073d7f602c439,Support v1.2.3 versioning,ABANDONED,2018-03-20 20:57:27.000000000,2019-10-15 15:01:47.000000000,,"[{'_account_id': 6524}, {'_account_id': 6928}, {'_account_id': 11682}, {'_account_id': 11952}, {'_account_id': 22348}, {'_account_id': 22623}, {'_account_id': 27201}]","[{'number': 1, 'created': '2018-03-20 20:57:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/pbr/commit/1743f4520260b4b17e36f1ffe48e02dfe6267146', 'message': 'Support v1.2.3 versioning\n\nPer the PBR docs:\npbr supports both bare version tag (e.g. 0.1.0) and version prefixed\nwith v or V (e.g. v0.1.0)\n\nChange-Id: If596d10413ae93f03a6f4ae87f3073d7f602c439\n'}, {'number': 2, 'created': '2018-03-20 20:58:34.000000000', 'files': ['pbr/tests/test_version.py', 'pbr/version.py'], 'web_link': 'https://opendev.org/openstack/pbr/commit/0a68c84e4b07b7243cafe878e3b019a441bc060e', 'message': 'Support v1.2.3 versioning\n\nPer the PBR docs:\npbr supports both bare version tag (e.g. 0.1.0) and version prefixed\nwith v or V (e.g. v0.1.0)\n\nCloses-Bug: 1744478\nChange-Id: If596d10413ae93f03a6f4ae87f3073d7f602c439\n'}]",3,554696,0a68c84e4b07b7243cafe878e3b019a441bc060e,16,7,2,10035,,,0,"Support v1.2.3 versioning

Per the PBR docs:
pbr supports both bare version tag (e.g. 0.1.0) and version prefixed
with v or V (e.g. v0.1.0)

Closes-Bug: 1744478
Change-Id: If596d10413ae93f03a6f4ae87f3073d7f602c439
",git fetch https://review.opendev.org/openstack/pbr refs/changes/96/554696/2 && git format-patch -1 --stdout FETCH_HEAD,"['pbr/tests/test_version.py', 'pbr/version.py']",2,1743f4520260b4b17e36f1ffe48e02dfe6267146,bug/1744478, if version_string.lower().startswith('v'): version_string = version_string[1:],,7,2
openstack%2Fopenstack-ansible-lxc_container_create~stable%2Fpike~I23d18069ac99db92554687475b9e5d8d7e9e13d8,openstack/openstack-ansible-lxc_container_create,stable/pike,I23d18069ac99db92554687475b9e5d8d7e9e13d8,Remove openSUSE Leap 42.3 jobs,MERGED,2019-10-15 05:45:55.000000000,2019-10-15 14:58:49.000000000,2019-10-15 14:58:49.000000000,"[{'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 05:45:55.000000000', 'files': ['zuul.d/project.yaml', 'zuul.d/jobs.yaml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible-lxc_container_create/commit/be247ba507ccbfec6c71e964ea35dc450f9708b9', 'message': ""Remove openSUSE Leap 42.3 jobs\n\nopenSUSE Leap 42.3 is EOL since June 2019, let's remove remaining jobs\nso that we can remove Leap 42.3 from Opendev infrastructure.\n\nChange-Id: I23d18069ac99db92554687475b9e5d8d7e9e13d8\n""}]",0,688620,be247ba507ccbfec6c71e964ea35dc450f9708b9,4,2,1,6547,,,0,"Remove openSUSE Leap 42.3 jobs

openSUSE Leap 42.3 is EOL since June 2019, let's remove remaining jobs
so that we can remove Leap 42.3 from Opendev infrastructure.

Change-Id: I23d18069ac99db92554687475b9e5d8d7e9e13d8
",git fetch https://review.opendev.org/openstack/openstack-ansible-lxc_container_create refs/changes/20/688620/1 && git format-patch -1 --stdout FETCH_HEAD,"['zuul.d/project.yaml', 'zuul.d/jobs.yaml']",2,be247ba507ccbfec6c71e964ea35dc450f9708b9,goodbye_42.3,, name: openstack-ansible-dir-opensuse-423 parent: openstack-ansible-functional nodeset: opensuse-423 vars: tox_env: dir - job:,0,9
openstack%2Fnova~master~Ib3c8d15f8073928a47ee860409a999a06acfc1a1,openstack/nova,master,Ib3c8d15f8073928a47ee860409a999a06acfc1a1,VMware: Update flavor-related metadata on resize,MERGED,2019-09-09 13:25:02.000000000,2019-10-15 14:57:06.000000000,2019-10-15 14:53:59.000000000,"[{'_account_id': 1653}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 14070}, {'_account_id': 14384}, {'_account_id': 15334}, {'_account_id': 15941}, {'_account_id': 16376}, {'_account_id': 16898}, {'_account_id': 22348}, {'_account_id': 23498}, {'_account_id': 26515}, {'_account_id': 29125}, {'_account_id': 29963}]","[{'number': 1, 'created': '2019-09-09 13:25:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/3a726ed07c28c2558aaee864f451f1b34662bdd5', 'message': 'VMware: Update flavor-related metadata upon instance resize\n\nChange-Id: Ib3c8d15f8073928a47ee860409a999a06acfc1a1\nCloses-Bug: #1843265\n'}, {'number': 2, 'created': '2019-09-12 12:17:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/86e9fdca1fe0f93c363d2f85e5cddd4b55e6dd86', 'message': ""VMware: Update flavor-related metadata on resize\n\nUpdate the flavor-related metadata in the VM Notes in vSphere upon\ninstance resize. Otherwise, notes keep holding the previous flavor's\nname and size.\n\nChange-Id: Ib3c8d15f8073928a47ee860409a999a06acfc1a1\nCloses-Bug: #1843265\n""}, {'number': 3, 'created': '2019-09-12 12:26:23.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/nova/commit/cb10ffedfc4d2d9a2ee279129e85741fbc44f349', 'message': ""VMware: Update flavor-related metadata on resize\n\nUpdate the flavor-related metadata in the VM Notes in vSphere upon\ninstance resize. Otherwise, notes keep holding the previous flavor's\nname and size.\n\nChange-Id: Ib3c8d15f8073928a47ee860409a999a06acfc1a1\nCloses-Bug: #1843265\n""}, {'number': 4, 'created': '2019-09-13 08:33:40.000000000', 'files': ['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py'], 'web_link': 'https://opendev.org/openstack/nova/commit/4141bf63af1ea6664db756be859d0bb845a692b9', 'message': ""VMware: Update flavor-related metadata on resize\n\nUpdate the flavor-related metadata in the VM Notes in vSphere upon\ninstance resize. Otherwise, notes keep holding the previous flavor's\nname and size.\n\nChange-Id: Ib3c8d15f8073928a47ee860409a999a06acfc1a1\nCloses-Bug: #1843265\n""}]",7,681004,4141bf63af1ea6664db756be859d0bb845a692b9,49,14,4,29125,,,0,"VMware: Update flavor-related metadata on resize

Update the flavor-related metadata in the VM Notes in vSphere upon
instance resize. Otherwise, notes keep holding the previous flavor's
name and size.

Change-Id: Ib3c8d15f8073928a47ee860409a999a06acfc1a1
Closes-Bug: #1843265
",git fetch https://review.opendev.org/openstack/nova refs/changes/04/681004/3 && git format-patch -1 --stdout FETCH_HEAD,"['nova/virt/vmwareapi/vmops.py', 'nova/tests/unit/virt/vmwareapi/test_vmops.py']",2,3a726ed07c28c2558aaee864f451f1b34662bdd5,bug/1843265," fake_get_metadata.assert_called_once_with(self._context, self._instance, flavor) def test_get_instance_metadata_flavor(self): # Construct a flavor different from instance.flavor flavor_int_meta_fields = ['memory_mb', 'vcpus', 'root_gb', 'ephemeral_gb', 'swap'] flavor = self._instance.flavor.obj_clone() for field in flavor_int_meta_fields: # Set int fields of flavor to instance.flavor value + 1 setattr(flavor, field, getattr(self._instance.flavor, field) + 1) flavor.name = self._instance.flavor.name + '1' metadata = self._vmops._get_instance_metadata( self._context, self._instance, flavor) # Verify metadata contains the values from flavor parameter meta_lines = metadata.split('\n') flavor_meta_fields = flavor_int_meta_fields[:] flavor_meta_fields.append('name') for field in flavor_meta_fields: meta_repr = 'flavor:%s:%s' % (field, getattr(flavor, field)) self.assertIn(meta_repr, meta_lines) ",,30,3
openstack%2Fkuryr-kubernetes~master~I4088ad09efe96b2d395fb892750adcb39abee3a4,openstack/kuryr-kubernetes,master,I4088ad09efe96b2d395fb892750adcb39abee3a4,Add a loadbalancer CRD,MERGED,2019-09-25 14:12:41.000000000,2019-10-15 14:48:53.000000000,2019-10-15 14:47:13.000000000,"[{'_account_id': 10068}, {'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 27032}, {'_account_id': 30963}]","[{'number': 1, 'created': '2019-09-25 14:12:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/7118090903f1b420d63a9e628c2f58d13a82f0fd', 'message': '[WIP]\nAuthor: Sarka Scavnicka\nDate: Wed Sep 25 15:58 2019\nImplements for blueprint Move SVC annotations to CRDs\n\n\tMake a new YAML file in kubernetes_crds folder. This file is a CRD for loadbalancer.\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n'}, {'number': 2, 'created': '2019-09-25 14:29:40.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/10cbbefe4f6c8a90d6a7acd950003ee908ebe891', 'message': ""[WIP] Add a loadbalancer CRD\n\nThis commit adds a new CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations.\n\nTODOs\n- Check if it possible to remove fields(lb_ip, service_pub_ip_info)\nwith the type null\n- Ensure CRD is created on the cluster when using devstack\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 3, 'created': '2019-10-01 12:00:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/acedadd6575ba06fe18d0242e206e6b1abd3d2a7', 'message': ""[WIP] Add a loadbalancer CRD\n\nThis commit adds repair CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also there are some\nchanges in several files to ensure that CRD is created on the cluster\nwhen using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 4, 'created': '2019-10-01 12:10:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/ee19477bf75d28cccfa98e78e5703c3c3b6cb4b7', 'message': ""This commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 5, 'created': '2019-10-01 12:11:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/c6f6400d04eecdc65fd21ee179d5dcb17df1cd4a', 'message': ""Add a loadbalancer CRD\n\nThis commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 6, 'created': '2019-10-02 11:16:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/59c439ad26abf9d2f54f318c1d50d48dccc80a5d', 'message': ""Add a loadbalancer CRD\n\nThis commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 7, 'created': '2019-10-02 11:19:04.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/f33758e1e7eb97dbc47d7407e13821e5175c7432', 'message': ""Add a loadbalancer CRD\n\nThis commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 8, 'created': '2019-10-02 11:35:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/2eaf0b95d30c1f72213fa8295e00dada6546329b', 'message': ""Add a loadbalancer CRD\n\nThis commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}, {'number': 9, 'created': '2019-10-14 12:44:56.000000000', 'files': ['devstack/plugin.sh', 'devstack/lib/kuryr_kubernetes', 'kubernetes_crds/kuryrloadbalancer.yaml', 'kuryr_kubernetes/constants.py', 'kuryr_kubernetes/tests/unit/test_utils.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/48f2d2838bcf7596a96b9a98efaa68265d4a8f16', 'message': ""Add a loadbalancer CRD\n\nThis commit adds CRD to Kuryr that contains informations about\nservice's annotations and endpoints' annotations, also it is\nensured that CRD is created on the cluster when using devstack.\n\nPartially-Implements: blueprint move-svc-annotations-to-crds\n\nChange-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4\n""}]",32,684754,48f2d2838bcf7596a96b9a98efaa68265d4a8f16,35,7,9,30963,,,0,"Add a loadbalancer CRD

This commit adds CRD to Kuryr that contains informations about
service's annotations and endpoints' annotations, also it is
ensured that CRD is created on the cluster when using devstack.

Partially-Implements: blueprint move-svc-annotations-to-crds

Change-Id: I4088ad09efe96b2d395fb892750adcb39abee3a4
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/54/684754/2 && git format-patch -1 --stdout FETCH_HEAD,['kubernetes_crds/kuryrloadbalancer.yaml'],1,7118090903f1b420d63a9e628c2f58d13a82f0fd,bp/move-svc-annotations-to-crds,apiVersion: apiextensions.k8s.io/v1beta1 kind: CustomResourceDefinition metadata: name: kuryrloadbalancers.openstack.org spec: group: openstack.org version: v1 scope: Namespaced names: plural: kuryrloadbalancers singular: kuryrloadbalancer kind: KuryrLoadBalancer shortNames: - klb additionalPrinterColumns: - name: PROJECT-ID type: string description: The ID of the PROJECT associated to the loadbalancer JSONPath: .spec.project_id - name: Age type: date JSONPath: .metadata.creationTimestamp validation: openAPIV3Schema: properties: spec: type: object required: - ip - lb_ip - ports - project_id - security_groups_ids - subnet_id - type properties: ip: type: string lb_ip: type: null ports: type: array items: type: object required: - name - port - protocol - targetPort properties: name: type: string port: type: integer protocol: type: string targetPort: type: integer project_id: type: string security_groups_ids: type: array subnet_id: type: string type: type: string status: type: object required: - listeners - loadbalancer - members - pools - service_pub_ip_info properties: listeners: type: array items: type: object required: - id - loadbalancer_id - name - port - project_id - protocol properties: id: type: string loadbalancer_id: type: string name: type: string port: type: integer project_id: type: string protocol: type: string loadbalancer: type: object required: - id - ip - name - port_id - project_id - provider - security_groups - subnet_id properties: id: type: string ip: type: string name: type: string port_id: type: integer project_id: type: string provider: type: string security_groups: type: array subnet_id: type: string members: type: array items: type: object required: - id - ip - name - pool_id - port - project_id - subnet_id properties: id: type: string ip: type: string name: type: string pool_id: type: string port: type: integer project_id: type: string subnet_id: type: string pools: type: array items: type: object required: - id - listener_id - loadbalancer_id - name - project_id - protocol properties: id: type: string listener_id: type: string loadbalancer_id: type: string name: type: string project_id: type: string protocol: type: string service_pub_ip_info: type: null ,,180,0
openstack%2Fmagnum~master~Iafb8e7b6fb483327a7baf95e9e273662b8918c56,openstack/magnum,master,Iafb8e7b6fb483327a7baf95e9e273662b8918c56,Add wiki Admin guide and Contributing  notes link to README,MERGED,2019-10-04 09:29:51.000000000,2019-10-15 14:36:09.000000000,2019-10-15 14:33:43.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-10-04 09:29:51.000000000', 'files': ['README.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/c54f86b4635a009d88e045b1f7e113447cf32a48', 'message': 'Add wiki Admin guide and Contributing  notes link to README\n\nChange-Id: Iafb8e7b6fb483327a7baf95e9e273662b8918c56\n'}]",0,686558,c54f86b4635a009d88e045b1f7e113447cf32a48,9,4,1,27190,,,0,"Add wiki Admin guide and Contributing  notes link to README

Change-Id: Iafb8e7b6fb483327a7baf95e9e273662b8918c56
",git fetch https://review.opendev.org/openstack/magnum refs/changes/58/686558/1 && git format-patch -1 --stdout FETCH_HEAD,['README.rst'],1,c54f86b4635a009d88e045b1f7e113447cf32a48,,* **Free software:** under the `Apache license <http://www.apache.org/licenses/LICENSE-2.0>` * **Wiki:** https://wiki.openstack.org/wiki/Magnum_* **Admin guide:** https://docs.openstack.org/magnum/latest/admin/index.html* **Contributing:** https://docs.openstack.org/magnum/latest/contributor/index.html,* **Free software:** under the `Apache license <http://www.apache.org/licenses/LICENSE-2.0>`_,4,1
openstack%2Fmagnum~master~Ie70bc00f5617ef94c39c9faea7d39617ee01b07b,openstack/magnum,master,Ie70bc00f5617ef94c39c9faea7d39617ee01b07b,Convert fixed_subnet name to uuid for OCCM,MERGED,2019-01-09 14:42:57.000000000,2019-10-15 14:34:56.000000000,2019-10-15 14:33:36.000000000,"[{'_account_id': 6484}, {'_account_id': 14826}, {'_account_id': 17499}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 26297}, {'_account_id': 28022}, {'_account_id': 28543}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-01-09 14:42:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/3aaa72c16f47a3e0f1125fe7a028bb4b7caccb14', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 2, 'created': '2019-01-09 14:56:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/a40bfa767ce4ae02d4a06fef1256ff9d73decd78', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 3, 'created': '2019-01-09 15:00:01.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/87f354761e78cbf409ad7d257f98c16b19844b95', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 4, 'created': '2019-01-09 15:10:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/041a58874d974d1e9ef55e41aef30a3059dcbe99', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 5, 'created': '2019-01-31 12:12:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/e0ae10cfbad0a4a54ac92ba3ad92c1a074063a02', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 6, 'created': '2019-01-31 12:16:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/b3fc599b265840a165d8ec9a572431a4d0122e8a', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 7, 'created': '2019-03-13 11:00:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/7e017c341e027e960e89180f59f9875ff5a03b58', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 8, 'created': '2019-03-13 11:12:47.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/015550e781bdae7901ddcbc5c0ca4b18d6f04dbb', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created if it does not look\nlike a uuid.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 9, 'created': '2019-06-25 09:09:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/8aefd3fdd19355656c0c4ecde616b2deb7a75cb0', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created if it does not look\nlike a uuid.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 10, 'created': '2019-09-24 12:53:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/68ee4fffad3f3ae40c2bd9905516103dd6b0778b', 'message': 'Convert fixed_subnet name to uuid so that OCCM does not error\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created if it does not look\nlike a uuid.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 11, 'created': '2019-09-24 12:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/240be7456ed545ab7534068424cee1311e3c1448', 'message': 'Convert fixed_subnet name to id for OCCM\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created.\n\nWithout this patch, there is a chance OCCM fails to start in come cases\nwhen fixed_subnet is rendered as name.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 12, 'created': '2019-09-24 14:11:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/62f666d4b54158169d7403e7da1f273f949720d8', 'message': 'Convert fixed_subnet name to uuid for OCCM\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created.\n\nWithout this patch, there is a chance OCCM fails to start in come cases\nwhen fixed_subnet is rendered as name.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 13, 'created': '2019-10-11 12:43:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum/commit/5d3783494618075541c6f6a0925c93aba6263842', 'message': 'Convert fixed_subnet name to uuid for OCCM\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created.\n\nWithout this patch, there is a chance OCCM fails to start in come cases\nwhen fixed_subnet is rendered as name.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}, {'number': 14, 'created': '2019-10-11 12:49:44.000000000', 'files': ['magnum/drivers/heat/k8s_template_def.py', 'magnum/common/neutron.py', 'magnum/tests/unit/drivers/test_template_definition.py', 'magnum/tests/unit/common/test_neutron.py', 'magnum/tests/unit/conductor/handlers/test_k8s_cluster_conductor.py', 'magnum/common/exception.py'], 'web_link': 'https://opendev.org/openstack/magnum/commit/97dbd49d8207fdac49605fe138e4c68dfb9eb0d1', 'message': 'Convert fixed_subnet name to uuid for OCCM\n\nSince OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,\nconvert fixed_subnet name to uuid when a cluster is created.\n\nWithout this patch, there is a chance OCCM fails to start in come cases\nwhen fixed_subnet is rendered as name.\n\nStory: 2002652\nTask: 28816\n\nChange-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b\n'}]",10,629514,97dbd49d8207fdac49605fe138e4c68dfb9eb0d1,37,9,14,28022,,,0,"Convert fixed_subnet name to uuid for OCCM

Since OpenStack Cloud Controller Manager only accepts fixed_subnet uuid,
convert fixed_subnet name to uuid when a cluster is created.

Without this patch, there is a chance OCCM fails to start in come cases
when fixed_subnet is rendered as name.

Story: 2002652
Task: 28816

Change-Id: Ie70bc00f5617ef94c39c9faea7d39617ee01b07b
",git fetch https://review.opendev.org/openstack/magnum refs/changes/14/629514/12 && git format-patch -1 --stdout FETCH_HEAD,['magnum/drivers/heat/k8s_template_def.py'],1,3aaa72c16f47a3e0f1125fe7a028bb4b7caccb14,fixed-subnet-uuid," neutron = osc.neutron() if neutron.list_subnets(id=cluster_template.fixed_subnet).get('subnets', False): cluster_template.fixed_subnet = neutron.list_subnets(name=cluster_template.fixed_subnet).get('subnets').pop().get('id') ",,4,0
openstack%2Fmagnum~master~Ibe5c810ace34f7cc2c6c9e0625227bea56fdf63c,openstack/magnum,master,Ibe5c810ace34f7cc2c6c9e0625227bea56fdf63c,Update master for stable/train,MERGED,2019-09-27 17:03:38.000000000,2019-10-15 14:33:42.000000000,2019-10-15 14:33:42.000000000,"[{'_account_id': 6484}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27781}]","[{'number': 1, 'created': '2019-09-27 17:03:38.000000000', 'files': ['releasenotes/source/train.rst', 'releasenotes/source/index.rst'], 'web_link': 'https://opendev.org/openstack/magnum/commit/60a79510ba24b6e258f63c638c70f9cec5476320', 'message': 'Update master for stable/train\n\nAdd file to the reno documentation build to show release notes for\nstable/train.\n\nUse pbr instruction to increment the minor version number\nautomatically so that master versions are higher than the versions on\nstable/train.\n\nChange-Id: Ibe5c810ace34f7cc2c6c9e0625227bea56fdf63c\nSem-Ver: feature\n'}]",0,685414,60a79510ba24b6e258f63c638c70f9cec5476320,8,4,1,22816,,,0,"Update master for stable/train

Add file to the reno documentation build to show release notes for
stable/train.

Use pbr instruction to increment the minor version number
automatically so that master versions are higher than the versions on
stable/train.

Change-Id: Ibe5c810ace34f7cc2c6c9e0625227bea56fdf63c
Sem-Ver: feature
",git fetch https://review.opendev.org/openstack/magnum refs/changes/14/685414/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/train.rst', 'releasenotes/source/index.rst']",2,60a79510ba24b6e258f63c638c70f9cec5476320,reno-train, train,,7,0
openstack%2Fmagnum-tempest-plugin~master~I802feec03e5c0e93854266c51b596043bf3f4c45,openstack/magnum-tempest-plugin,master,I802feec03e5c0e93854266c51b596043bf3f4c45,Replace git.openstack.org URLs with opendev.org URLs,MERGED,2019-04-23 10:47:24.000000000,2019-10-15 14:33:41.000000000,2019-10-15 14:33:41.000000000,"[{'_account_id': 6484}, {'_account_id': 8064}, {'_account_id': 17130}, {'_account_id': 18955}, {'_account_id': 20498}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 28022}, {'_account_id': 28614}, {'_account_id': 28743}, {'_account_id': 30356}, {'_account_id': 30413}]","[{'number': 1, 'created': '2019-04-23 10:47:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/ee88786a8aced5edb8da2dae8d2c38aebe236543', 'message': 'Replace git.openstack.org URLs with opendev.org URLs\n\nChange-Id: I802feec03e5c0e93854266c51b596043bf3f4c45\n'}, {'number': 2, 'created': '2019-04-23 10:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/f264b1364ccf7a9b3418f1ef3aa0b5112a9f0075', 'message': 'Replace git.openstack.org URLs with opendev.org URLs\n\nChange-Id: I802feec03e5c0e93854266c51b596043bf3f4c45\n'}, {'number': 3, 'created': '2019-06-04 09:03:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/ea9fb321ffcece33e7833540d1fc1a40824fd35b', 'message': 'Replace git.openstack.org URLs with opendev.org URLs\n\n1. Replace git.openstack.org URLs with opendev.org URLs\n2. Update some urls to latest\n\nChange-Id: I802feec03e5c0e93854266c51b596043bf3f4c45\n'}, {'number': 4, 'created': '2019-10-13 09:00:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/76265158e5e464e365296a137c9615722992cd89', 'message': 'Replace git.openstack.org URLs with opendev.org URLs\n\n1. Replace git.openstack.org URLs with opendev.org URLs\n2. Update some urls to latest\n\nChange-Id: I802feec03e5c0e93854266c51b596043bf3f4c45\n'}, {'number': 5, 'created': '2019-10-13 09:00:29.000000000', 'files': ['CONTRIBUTING.rst', 'README.rst', 'setup.cfg', 'tox.ini', 'doc/source/installation.rst'], 'web_link': 'https://opendev.org/openstack/magnum-tempest-plugin/commit/d558880e7762680c8be9870c87fd0aece0b7d567', 'message': 'Replace git.openstack.org URLs with opendev.org URLs\n\n1. Replace git.openstack.org URLs with opendev.org URLs\n2. Update some urls to latest\n\nChange-Id: I802feec03e5c0e93854266c51b596043bf3f4c45\n'}]",1,654947,d558880e7762680c8be9870c87fd0aece0b7d567,25,12,5,22165,,,0,"Replace git.openstack.org URLs with opendev.org URLs

1. Replace git.openstack.org URLs with opendev.org URLs
2. Update some urls to latest

Change-Id: I802feec03e5c0e93854266c51b596043bf3f4c45
",git fetch https://review.opendev.org/openstack/magnum-tempest-plugin refs/changes/47/654947/1 && git format-patch -1 --stdout FETCH_HEAD,"['README.rst', 'setup.cfg', 'tox.ini', 'doc/source/installation.rst']",4,ee88786a8aced5edb8da2dae8d2c38aebe236543,, $ git clone https://opendev.org/openstack/magnum-tempest-plugin, $ git clone https://git.openstack.org/cgit/openstack/magnum-tempest-plugin,4,4
openstack%2Fneutron~master~I6b1ba3fbab381164e5e9d59a5ea95c283acbe151,openstack/neutron,master,I6b1ba3fbab381164e5e9d59a5ea95c283acbe151,Fix misspell word,MERGED,2019-10-15 01:48:32.000000000,2019-10-15 14:32:33.000000000,2019-10-15 08:46:52.000000000,"[{'_account_id': 11975}, {'_account_id': 16376}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-10-15 01:48:32.000000000', 'files': ['doc/source/admin/deploy-ovs-ha-dvr.rst'], 'web_link': 'https://opendev.org/openstack/neutron/commit/6b52e361f0eae01e67b1d9be47faee36b0627efe', 'message': 'Fix misspell word\n\nChange-Id: I6b1ba3fbab381164e5e9d59a5ea95c283acbe151\n'}]",0,688595,6b52e361f0eae01e67b1d9be47faee36b0627efe,10,5,1,30717,,,0,"Fix misspell word

Change-Id: I6b1ba3fbab381164e5e9d59a5ea95c283acbe151
",git fetch https://review.opendev.org/openstack/neutron refs/changes/95/688595/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/source/admin/deploy-ovs-ha-dvr.rst'],1,6b52e361f0eae01e67b1d9be47faee36b0627efe,,"#. In the ``openvswitch_agent.ini`` file, enable distributed routing.","#. In the ``openswitch_agent.ini`` file, enable distributed routing.",1,1
openstack%2Ftempest~master~I21cf35157f185a661ae0f9088a7d04ec4b80d564,openstack/tempest,master,I21cf35157f185a661ae0f9088a7d04ec4b80d564,Fetch journal log after tempest jobs,ABANDONED,2019-05-29 08:41:13.000000000,2019-10-15 14:14:00.000000000,,"[{'_account_id': 5689}, {'_account_id': 11975}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-05-29 08:41:13.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/bb8812e97e2af2c16c277a4c30d302d7c9443eb4', 'message': 'Fetch journal log after tempest jobs\n\nJournal log from test node may be useful for debug issues e.g. with\nkeepalived, dnsmasq and neutron-keepalived-state-change processes.\n\nDepends-On: https://review.openstack.org/#/c/643733/\nChange-Id: I21cf35157f185a661ae0f9088a7d04ec4b80d564\n'}, {'number': 2, 'created': '2019-05-30 09:14:08.000000000', 'files': ['playbooks/post-tempest.yaml'], 'web_link': 'https://opendev.org/openstack/tempest/commit/4b400d07d93ee7d3ff1d6bc1c6e8a4aaf1a6010c', 'message': 'Fetch journal log after tempest jobs\n\nJournal log from test node may be useful for debug issues e.g. with\nkeepalived, dnsmasq and neutron-keepalived-state-change processes.\n\nDepends-On: https://review.opendev.org/#/c/643733/\n\nChange-Id: I21cf35157f185a661ae0f9088a7d04ec4b80d564\n'}]",0,661915,4b400d07d93ee7d3ff1d6bc1c6e8a4aaf1a6010c,16,3,2,11975,,,0,"Fetch journal log after tempest jobs

Journal log from test node may be useful for debug issues e.g. with
keepalived, dnsmasq and neutron-keepalived-state-change processes.

Depends-On: https://review.opendev.org/#/c/643733/

Change-Id: I21cf35157f185a661ae0f9088a7d04ec4b80d564
",git fetch https://review.opendev.org/openstack/tempest refs/changes/15/661915/2 && git format-patch -1 --stdout FETCH_HEAD,['playbooks/post-tempest.yaml'],1,bb8812e97e2af2c16c277a4c30d302d7c9443eb4,store_journal, - role: fetch-journal-log,,1,0
openstack%2Fmanila~master~Ia3ee253e49e1cdc8baf684d18846cc56f534285f,openstack/manila,master,Ia3ee253e49e1cdc8baf684d18846cc56f534285f,DNM - test extend scenario with IPv6,ABANDONED,2019-10-15 12:12:10.000000000,2019-10-15 14:07:19.000000000,,[{'_account_id': 15831}],"[{'number': 1, 'created': '2019-10-15 12:12:10.000000000', 'files': ['DNM', 'contrib/ci/post_test_hook.sh', '.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/manila/commit/337088f7ed5d4445f48a0afb647f400a167e96d9', 'message': 'DNM - test extend scenario with IPv6\n\nRun just the extend scenario tests, and only on\njobs where IPv6 is enabled.\n\nCheck the conjecture that the VM created to mount shares\nis being creaated IPv4 only so that when an IPv6 export\nlocation is selected for the mount the test will fail.\n\nCode inspection suggests that self.ipv6_enabled is never\nTrue in the scenario test and that the first export location\nfor a share is used for the mount attempt regardless of whether\nthe VM doing the mount and the network from the VM to the\nshare server are IPv6 capable.\n\nChange-Id: Ia3ee253e49e1cdc8baf684d18846cc56f534285f\nDepends-On: https://review.opendev.org/688286\n'}]",0,688691,337088f7ed5d4445f48a0afb647f400a167e96d9,3,1,1,9003,,,0,"DNM - test extend scenario with IPv6

Run just the extend scenario tests, and only on
jobs where IPv6 is enabled.

Check the conjecture that the VM created to mount shares
is being creaated IPv4 only so that when an IPv6 export
location is selected for the mount the test will fail.

Code inspection suggests that self.ipv6_enabled is never
True in the scenario test and that the first export location
for a share is used for the mount attempt regardless of whether
the VM doing the mount and the network from the VM to the
share server are IPv6 capable.

Change-Id: Ia3ee253e49e1cdc8baf684d18846cc56f534285f
Depends-On: https://review.opendev.org/688286
",git fetch https://review.opendev.org/openstack/manila refs/changes/91/688691/1 && git format-patch -1 --stdout FETCH_HEAD,"['DNM', 'contrib/ci/post_test_hook.sh', '.zuul.yaml']",3,337088f7ed5d4445f48a0afb647f400a167e96d9,, - manila-tempest-minimal-dsvm-cephfs-nfs, templates: - publish-openstack-docs-pti - openstack-cover-jobs - openstack-lower-constraints-jobs - openstack-python-jobs - openstack-python3-train-jobs - check-requirements - release-notes-jobs-python3 - periodic-stable-jobs - manila-tox-genconfig - manila-tempest-dsvm-mysql-generic: voting: false - manila-tempest-dsvm-postgres-container: voting: false - manila-tempest-dsvm-postgres-zfsonlinux: voting: false - manila-tempest-dsvm-postgres-generic-singlebackend: voting: false - manila-tempest-dsvm-generic-no-share-servers: voting: false - manila-tempest-dsvm-scenario: voting: false - manila-tempest-minimal-dsvm-cephfs-native: voting: false - manila-tempest-minimal-dsvm-cephfs-nfs: voting: false - manila-tempest-dsvm-glusterfs-nfs: voting: false - manila-tempest-dsvm-glusterfs-native: voting: false - manila-tempest-minimal-dsvm-dummy # Through the Train release we need to keep some python2 coverage. - manila-tempest-minimal-dsvm-dummy-py2 - manila-grenade: voting: false - manila-rally-no-ss: voting: false - manila-rally-ss: voting: false - openstack-tox-pylint: voting: false timeout: 5400 - openstack-tox-cover: voting: false,3,46
openstack%2Fpuppet-openstack_spec_helper~stable%2Fqueens~I935a7e242b3586e2ffc5815ed1d3fd316b62f53b,openstack/puppet-openstack_spec_helper,stable/queens,I935a7e242b3586e2ffc5815ed1d3fd316b62f53b,Pin dry-inflector to 0.1.2 for ruby <= 2.4.0,MERGED,2019-10-15 07:27:47.000000000,2019-10-15 14:02:15.000000000,2019-10-15 14:02:15.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 07:27:47.000000000', 'files': ['puppet-openstack_spec_helper.gemspec'], 'web_link': 'https://opendev.org/openstack/puppet-openstack_spec_helper/commit/2adefc9435793413ecd8959f02f3a993e6ddb0d5', 'message': 'Pin dry-inflector to 0.1.2 for ruby <= 2.4.0\n\nFails since 0.2.0 that was released today requires ruby >= 2.4.0.\nSee failure in [1].\n\n[1]https://review.opendev.org/#/c/687845/\n\nChange-Id: I935a7e242b3586e2ffc5815ed1d3fd316b62f53b\nCloses-Bug: #1847945\n(cherry picked from commit d38ed711f1cc1de9f66e8f71a6bdff96e1273051)\n'}]",0,688640,2adefc9435793413ecd8959f02f3a993e6ddb0d5,8,4,1,16137,,,0,"Pin dry-inflector to 0.1.2 for ruby <= 2.4.0

Fails since 0.2.0 that was released today requires ruby >= 2.4.0.
See failure in [1].

[1]https://review.opendev.org/#/c/687845/

Change-Id: I935a7e242b3586e2ffc5815ed1d3fd316b62f53b
Closes-Bug: #1847945
(cherry picked from commit d38ed711f1cc1de9f66e8f71a6bdff96e1273051)
",git fetch https://review.opendev.org/openstack/puppet-openstack_spec_helper refs/changes/40/688640/1 && git format-patch -1 --stdout FETCH_HEAD,['puppet-openstack_spec_helper.gemspec'],1,2adefc9435793413ecd8959f02f3a993e6ddb0d5,bug/1847945," # NOTE(zhongshengping): Pin dry-inflector to 0.1.2 as 0.2.0 requires ruby >= 2.4.0 dry_inflector_version = RUBY_VERSION < '2.4.0' ? '~> 0.1.2' : '>= 0.1.2' spec.add_dependency 'dry-inflector', dry_inflector_version ",,4,0
openstack%2Fpuppet-cloudkitty~stable%2Ftrain~Ibe29f321a05e083900c1837216810463f218b0d9,openstack/puppet-cloudkitty,stable/train,Ibe29f321a05e083900c1837216810463f218b0d9,Switch to Train,MERGED,2019-10-15 07:34:55.000000000,2019-10-15 14:01:41.000000000,2019-10-15 14:01:41.000000000,"[{'_account_id': 3153}, {'_account_id': 9414}, {'_account_id': 16137}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 07:34:55.000000000', 'files': ['Gemfile'], 'web_link': 'https://opendev.org/openstack/puppet-cloudkitty/commit/95be4dadde5aabafc2dd7bca9746d0af9da0a161', 'message': 'Switch to Train\n\nChange-Id: Ibe29f321a05e083900c1837216810463f218b0d9\n'}]",0,688642,95be4dadde5aabafc2dd7bca9746d0af9da0a161,9,4,1,16137,,,0,"Switch to Train

Change-Id: Ibe29f321a05e083900c1837216810463f218b0d9
",git fetch https://review.opendev.org/openstack/puppet-cloudkitty refs/changes/42/688642/1 && git format-patch -1 --stdout FETCH_HEAD,['Gemfile'],1,95be4dadde5aabafc2dd7bca9746d0af9da0a161,," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper', :branch => 'stable/train',"," :git => 'https://opendev.org/openstack/puppet-openstack_spec_helper',",2,1
openstack%2Fkayobe-config-dev~master~I2e52053cdd02d55b7b83bd880372de7b87dcab63,openstack/kayobe-config-dev,master,I2e52053cdd02d55b7b83bd880372de7b87dcab63,DNM: Switch to CentOS based IPA images,ABANDONED,2019-10-10 08:56:44.000000000,2019-10-15 13:57:13.000000000,,"[{'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-10-10 08:56:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/b40bd0d7cbf1e5be8cf89bf6fd53b9ba4e8b79c4', 'message': 'Switch IPA image back to coreos\n\nCI is currently failing to boot baremetal instances. This is to check\nif the coreos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\n'}, {'number': 2, 'created': '2019-10-10 09:12:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/48cbc67a8090419eb0412d16169ffd55f31d89a8', 'message': 'Switch IPA image back to coreos\n\nCI is currently failing to boot baremetal instances. This is to check\nif the coreos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\n'}, {'number': 3, 'created': '2019-10-11 16:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/86aa5ebac5a53389d5a1a6bd30b5929ed9d9bbdc', 'message': 'DNM: Switch to CentOS based IPA images\n\nCI is currently failing to boot baremetal instances. This is to check\nif the centos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\nDepends-On: https://review.opendev.org/#/c/688102/\n'}, {'number': 4, 'created': '2019-10-11 16:55:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/835f34470407421ed2c4d949ead0549e0ca7b68a', 'message': 'DNM: Switch to CentOS based IPA images\n\nCI is currently failing to boot baremetal instances. This is to check\nif the centos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\nDepends-On: https://review.opendev.org/#/c/688102/\n'}, {'number': 5, 'created': '2019-10-14 09:25:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/2d43999872faaa02e75e838a53005331f14e8e45', 'message': 'DNM: Switch to CentOS based IPA images\n\nCI is currently failing to boot baremetal instances. This is to check\nif the centos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\nDepends-On: https://review.opendev.org/688102\nDepends-On: https://review.opendev.org/688359\n'}, {'number': 6, 'created': '2019-10-15 12:23:50.000000000', 'files': ['etc/kayobe/ipa.yml'], 'web_link': 'https://opendev.org/openstack/kayobe-config-dev/commit/16b3a42d5779a9bd57047f1cb428f90d7789446c', 'message': 'DNM: Switch to CentOS based IPA images\n\nCI is currently failing to boot baremetal instances. This is to check\nif the centos IPA images are any more reliable.\n\nChange-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63\nDepends-On: https://review.opendev.org/688102\nDepends-On: https://review.opendev.org/688359\nDepends-On: https://review.opendev.org/688694\n'}]",0,687830,16b3a42d5779a9bd57047f1cb428f90d7789446c,15,2,6,28048,,,0,"DNM: Switch to CentOS based IPA images

CI is currently failing to boot baremetal instances. This is to check
if the centos IPA images are any more reliable.

Change-Id: I2e52053cdd02d55b7b83bd880372de7b87dcab63
Depends-On: https://review.opendev.org/688102
Depends-On: https://review.opendev.org/688359
Depends-On: https://review.opendev.org/688694
",git fetch https://review.opendev.org/openstack/kayobe-config-dev refs/changes/30/687830/6 && git format-patch -1 --stdout FETCH_HEAD,['etc/kayobe/ipa.yml'],1,b40bd0d7cbf1e5be8cf89bf6fd53b9ba4e8b79c4,coreos,"ipa_kernel_upstream_url: ""https://tarballs.openstack.org/ironic-python-agent/coreos/files/coreos_production_pxe-{{ ipa_images_upstream_url_suffix }}.vmlinuz""ipa_ramdisk_upstream_url: ""https://tarballs.openstack.org/ironic-python-agent/coreos/files/coreos_production_pxe_image-oem-{{ ipa_images_upstream_url_suffix }}.cpio.gz""","ipa_kernel_upstream_url: ""https://tarballs.openstack.org/ironic-python-agent/tinyipa/files/tinyipa{{ ipa_images_upstream_url_suffix }}.vmlinuz""ipa_ramdisk_upstream_url: ""https://tarballs.openstack.org/ironic-python-agent/tinyipa/files/tinyipa{{ ipa_images_upstream_url_suffix }}.gz""",2,2
openstack%2Fkayobe~master~I5727b0df4fa07b2775a58e50c48bae465f98f743,openstack/kayobe,master,I5727b0df4fa07b2775a58e50c48bae465f98f743,Increase RAM for baremetal compute nodes,ABANDONED,2019-10-15 12:22:44.000000000,2019-10-15 13:53:23.000000000,,"[{'_account_id': 14826}, {'_account_id': 22348}, {'_account_id': 28048}]","[{'number': 1, 'created': '2019-10-15 12:22:44.000000000', 'files': ['dev/tenks-deploy-config-compute.yml'], 'web_link': 'https://opendev.org/openstack/kayobe/commit/be3ff3788c258d44cb1f334a48c6bd00f3cefd69', 'message': 'Increase RAM for baremetal compute nodes\n\nThis allows us to the use the CentOS based images which are\nmore RAM hungry.\n\nChange-Id: I5727b0df4fa07b2775a58e50c48bae465f98f743\n'}]",1,688694,be3ff3788c258d44cb1f334a48c6bd00f3cefd69,7,3,1,28048,,,0,"Increase RAM for baremetal compute nodes

This allows us to the use the CentOS based images which are
more RAM hungry.

Change-Id: I5727b0df4fa07b2775a58e50c48bae465f98f743
",git fetch https://review.opendev.org/openstack/kayobe refs/changes/94/688694/1 && git format-patch -1 --stdout FETCH_HEAD,['dev/tenks-deploy-config-compute.yml'],1,be3ff3788c258d44cb1f334a48c6bd00f3cefd69,up-ram, # CentOS based IPA images require more ram. The unpacked size of the ramdisk 1.2GiB. memory_mb: 4096, memory_mb: 1024,2,1
openstack%2Fneutron~master~I8e910a55a2a9b01fd7d8554e0c68be70f795fbcd,openstack/neutron,master,I8e910a55a2a9b01fd7d8554e0c68be70f795fbcd,DNM Test if Fedora job will work on F29,ABANDONED,2019-09-10 10:45:12.000000000,2019-10-15 13:41:17.000000000,,"[{'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-09-10 10:45:12.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron/commit/f02ab81131f31be98f18979ceb7bab3319eeb104', 'message': 'DNM Test if Fedora job will work on F29\n\nDepends-On: https://review.opendev.org/#/c/662529/\nChange-Id: I8e910a55a2a9b01fd7d8554e0c68be70f795fbcd\n'}]",0,681213,f02ab81131f31be98f18979ceb7bab3319eeb104,6,5,1,11975,,,0,"DNM Test if Fedora job will work on F29

Depends-On: https://review.opendev.org/#/c/662529/
Change-Id: I8e910a55a2a9b01fd7d8554e0c68be70f795fbcd
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/681213/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,f02ab81131f31be98f18979ceb7bab3319eeb104,bug/1843413, # Lets check if it will work on F29,,1,0
openstack%2Fpatrole~master~Iece73a3300f62441165e9d06b00f68753f2b2006,openstack/patrole,master,Iece73a3300f62441165e9d06b00f68753f2b2006,DNM Test Neutron fix for flavor service profile rbac,ABANDONED,2019-09-17 07:15:15.000000000,2019-10-15 13:40:59.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-17 07:15:15.000000000', 'files': ['patrole_tempest_plugin/tests/api/network/test_flavor_service_profile_rbac.py'], 'web_link': 'https://opendev.org/openstack/patrole/commit/5257f034b8bfa09565aec222ee76cfc6d69f611f', 'message': 'DNM Test Neutron fix for flavor service profile rbac\n\nDepends-On: https://review.opendev.org/#/c/682391/\n\nChange-Id: Iece73a3300f62441165e9d06b00f68753f2b2006\nRelated-Bug: #1843290\n'}]",0,682561,5257f034b8bfa09565aec222ee76cfc6d69f611f,3,1,1,11975,,,0,"DNM Test Neutron fix for flavor service profile rbac

Depends-On: https://review.opendev.org/#/c/682391/

Change-Id: Iece73a3300f62441165e9d06b00f68753f2b2006
Related-Bug: #1843290
",git fetch https://review.opendev.org/openstack/patrole refs/changes/61/682561/1 && git format-patch -1 --stdout FETCH_HEAD,['patrole_tempest_plugin/tests/api/network/test_flavor_service_profile_rbac.py'],1,5257f034b8bfa09565aec222ee76cfc6d69f611f,bug/1843290, # NOTE(slaweq): Let's check if this will now pass,,1,0
openstack%2Fcharm-gnocchi~master~I347c4049cfcd087469b438e6787f4b1fe1b4fb25,openstack/charm-gnocchi,master,I347c4049cfcd087469b438e6787f4b1fe1b4fb25,Improves README file,MERGED,2019-10-09 18:33:32.000000000,2019-10-15 13:39:49.000000000,2019-10-15 13:39:49.000000000,"[{'_account_id': 2424}, {'_account_id': 10058}, {'_account_id': 20635}, {'_account_id': 20648}, {'_account_id': 22348}, {'_account_id': 30561}]","[{'number': 1, 'created': '2019-10-09 18:33:32.000000000', 'files': ['src/README.md'], 'web_link': 'https://opendev.org/openstack/charm-gnocchi/commit/f4be451a98f5f34a9cb979edf3218b165b48affa', 'message': ""Improves README file\n\nAfter deploying Gnocchi, the service stays blocked until you run\n'juju run-action  ceilometer/0 ceilometer-upgrade'. So, we should add\nthis to the charm help.\n\nChange-Id: I347c4049cfcd087469b438e6787f4b1fe1b4fb25\n""}]",4,687648,f4be451a98f5f34a9cb979edf3218b165b48affa,13,6,1,10058,,,0,"Improves README file

After deploying Gnocchi, the service stays blocked until you run
'juju run-action  ceilometer/0 ceilometer-upgrade'. So, we should add
this to the charm help.

Change-Id: I347c4049cfcd087469b438e6787f4b1fe1b4fb25
",git fetch https://review.opendev.org/openstack/charm-gnocchi refs/changes/48/687648/1 && git format-patch -1 --stdout FETCH_HEAD,['src/README.md'],1,f4be451a98f5f34a9cb979edf3218b165b48affa,improving-readme, Gnocchi then needs to be initialized with the current ceilometer data: juju run-action <ceilometer unit leader> ceilometer-upgrade,,4,0
openstack%2Fopenstack-ansible~master~Ic4bfb03c11ea79c0e0c9adf3e3d2443c3f5c0154,openstack/openstack-ansible,master,Ic4bfb03c11ea79c0e0c9adf3e3d2443c3f5c0154,Update memcached_servers regex to match one or more chars,MERGED,2019-10-09 16:46:26.000000000,2019-10-15 13:08:09.000000000,2019-10-15 13:04:13.000000000,"[{'_account_id': 22348}, {'_account_id': 27781}, {'_account_id': 28008}, {'_account_id': 28619}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-10-09 16:46:26.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/cec450d45493eaa49ae1476e32ab55c8b6c33777', 'message': 'Update memcached_servers regex to match one or more items\n\nPreviously this matched zero or more, and on debian buster systems this\ngenerates the following, which breaks keystone.\n\nmemcached_servers: ""172.29.237.133:11211:11211""\n\nChange-Id: Ic4bfb03c11ea79c0e0c9adf3e3d2443c3f5c0154\n'}, {'number': 2, 'created': '2019-10-09 16:46:55.000000000', 'files': ['inventory/group_vars/all/infra.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/190f0d8d9faa1fd019e0373d94c0e27e6f78138f', 'message': 'Update memcached_servers regex to match one or more chars\n\nPreviously this matched zero or more, and on debian buster systems this\ngenerates the following, which breaks keystone.\n\nmemcached_servers: ""172.29.237.133:11211:11211""\n\nChange-Id: Ic4bfb03c11ea79c0e0c9adf3e3d2443c3f5c0154\n'}]",0,687620,190f0d8d9faa1fd019e0373d94c0e27e6f78138f,12,5,2,25023,,,0,"Update memcached_servers regex to match one or more chars

Previously this matched zero or more, and on debian buster systems this
generates the following, which breaks keystone.

memcached_servers: ""172.29.237.133:11211:11211""

Change-Id: Ic4bfb03c11ea79c0e0c9adf3e3d2443c3f5c0154
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/20/687620/1 && git format-patch -1 --stdout FETCH_HEAD,['inventory/group_vars/all/infra.yml'],1,cec450d45493eaa49ae1476e32ab55c8b6c33777,osa-buster," | map('regex_replace', '(.+)' ,'\1:' ~ memcached_port)"," | map('regex_replace', '(.*)' ,'\1:' ~ memcached_port)",1,1
openstack%2Fironic-python-agent-builder~master~Ifa3df2d9bcecb4a27805a4f455dda360670d66ff,openstack/ironic-python-agent-builder,master,Ifa3df2d9bcecb4a27805a4f455dda360670d66ff,DNM testing the CI,ABANDONED,2019-10-14 08:30:46.000000000,2019-10-15 13:07:25.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-10-14 08:30:46.000000000', 'files': ['dib/ironic-python-agent-ramdisk/element-deps'], 'web_link': 'https://opendev.org/openstack/ironic-python-agent-builder/commit/36cc852eabe5606fc71fcfceea015fb1b760ee77', 'message': 'DNM testing the CI\n\nChange-Id: Ifa3df2d9bcecb4a27805a4f455dda360670d66ff\nDepends-On: https://review.opendev.org/#/c/688321/\n'}]",0,688352,36cc852eabe5606fc71fcfceea015fb1b760ee77,3,1,1,10239,,,0,"DNM testing the CI

Change-Id: Ifa3df2d9bcecb4a27805a4f455dda360670d66ff
Depends-On: https://review.opendev.org/#/c/688321/
",git fetch https://review.opendev.org/openstack/ironic-python-agent-builder refs/changes/52/688352/1 && git format-patch -1 --stdout FETCH_HEAD,['dib/ironic-python-agent-ramdisk/element-deps'],1,36cc852eabe5606fc71fcfceea015fb1b760ee77,test,,,1,0
openstack%2Fcloudkitty-tempest-plugin~master~Ib10a6ffe9e0dd6c628f05588b463230139bf42c8,openstack/cloudkitty-tempest-plugin,master,Ib10a6ffe9e0dd6c628f05588b463230139bf42c8,Split tests between the two current CloudKitty API versions,MERGED,2019-10-02 16:25:39.000000000,2019-10-15 13:06:30.000000000,2019-10-15 13:06:30.000000000,"[{'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-10-02 16:25:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/bc93fb6be7fb25abc66db4f1baefaa04f8ea267c', 'message': 'Split tests between the two current CloudKitty API versions\n\nFor convenience we split the tests between the two current versions\nof CloudKitty.\n\nChange-Id: Ib10a6ffe9e0dd6c628f05588b463230139bf42c8\nStory: 2006578\nTask: 36895\n'}, {'number': 2, 'created': '2019-10-09 15:15:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/1ca4f09c24687ccca07a1908ae058f9b298d4296', 'message': 'Split tests between the two current CloudKitty API versions\n\nFor convenience we split the tests between the two current versions\nof CloudKitty.\n\nChange-Id: Ib10a6ffe9e0dd6c628f05588b463230139bf42c8\nStory: 2006578\nTask: 36895\n'}, {'number': 3, 'created': '2019-10-11 09:23:27.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/c973cdf5d5bcc22101c2c53b590e9699f04a401f', 'message': 'Split tests between the two current CloudKitty API versions\n\nFor convenience we split the tests between the two current versions\nof CloudKitty.\n\nChange-Id: Ib10a6ffe9e0dd6c628f05588b463230139bf42c8\nStory: 2006578\nTask: 36895\n'}, {'number': 4, 'created': '2019-10-11 13:23:22.000000000', 'files': ['cloudkitty_tempest_plugin/tests/api/v1/test_cloudkitty_api.py', 'cloudkitty_tempest_plugin/tests/api/v1/__init__.py', 'cloudkitty_tempest_plugin/tests/api/v2/__init__.py', 'cloudkitty_tempest_plugin/tests/api/base.py', 'cloudkitty_tempest_plugin/tests/api/v1/test_pyscript_api.py', 'cloudkitty_tempest_plugin/tests/api/v1/test_hashmap_api.py', 'cloudkitty_tempest_plugin/services/client.py'], 'web_link': 'https://opendev.org/openstack/cloudkitty-tempest-plugin/commit/0d0a5a7e4ab159c8fa41b1d1449e9982909ceaee', 'message': 'Split tests between the two current CloudKitty API versions\n\nFor convenience we split the tests between the two current versions\nof CloudKitty.\n\nChange-Id: Ib10a6ffe9e0dd6c628f05588b463230139bf42c8\nStory: 2006578\nTask: 36895\n'}]",5,686210,0d0a5a7e4ab159c8fa41b1d1449e9982909ceaee,14,3,4,29503,,,0,"Split tests between the two current CloudKitty API versions

For convenience we split the tests between the two current versions
of CloudKitty.

Change-Id: Ib10a6ffe9e0dd6c628f05588b463230139bf42c8
Story: 2006578
Task: 36895
",git fetch https://review.opendev.org/openstack/cloudkitty-tempest-plugin refs/changes/10/686210/3 && git format-patch -1 --stdout FETCH_HEAD,"['cloudkitty_tempest_plugin/tests/api/v1/test_cloudkitty_api.py', 'cloudkitty_tempest_plugin/tests/api/v1/__init__.py', 'cloudkitty_tempest_plugin/tests/api/v2/__init__.py', 'cloudkitty_tempest_plugin/tests/api/base.py', 'cloudkitty_tempest_plugin/tests/api/v1/test_pyscript_api.py', 'cloudkitty_tempest_plugin/tests/api/v1/test_hashmap_api.py', 'cloudkitty_tempest_plugin/services/client.py']",7,bc93fb6be7fb25abc66db4f1baefaa04f8ea267c,versioning,"from tempest.lib.common import rest_client class BaseRatingClient(rest_client.RestClient): class RatingClientV1(BaseRatingClient): """"""Implementation of cloudkittyclient for testing purposes"""""" api_version = 'v1' class RatingClientV2(RatingClientV1): """"""Implementation of cloudkittyclient for testing purposes"""""" api_version = 'v2' class Manager(manager.Manager): rating_clients = { 'v1': RatingClientV1, 'v2': RatingClientV2, } rating_params = { 'service': CONF.rating_plugin.service_name, 'region': CONF.identity.region, 'endpoint_type': CONF.rating_plugin.endpoint_type, } def __init__(self, credentials=None, service=None): super(Manager, self).__init__(credentials) self.rating_clients = { 'v1': RatingClientV1(self.auth_provider, **self.rating_params), 'v2': RatingClientV2(self.auth_provider, **self.rating_params), } def get_rating_client(self, api_version='v2'): if api_version not in self.rating_clients: raise ValueError('API version must be one of the following: {}', self.rating_client.keys()) return self.rating_clients[api_version]","from tempest.lib.common import rest_clientCLOUDKITTY_API_VERSION = 'v1' class RatingClient(rest_client.RestClient): api_version = 'v1' class Manager(manager.Manager): rating_params = { 'service': CONF.rating_plugin.service_name, 'region': CONF.identity.region, 'endpoint_type': CONF.rating_plugin.endpoint_type, } def __init__(self, credentials=None, service=None): super(Manager, self).__init__(credentials) self.set_rating_client() def set_rating_client(self): self.rating_client = RatingClient(self.auth_provider, **self.rating_params)",43,28
openstack%2Fopenstack-ansible~master~I01718f822c1af6058fd12c340502c5a89a9d0948,openstack/openstack-ansible,master,I01718f822c1af6058fd12c340502c5a89a9d0948,Disable firewalld for AIO build,MERGED,2019-10-14 15:45:35.000000000,2019-10-15 13:06:27.000000000,2019-10-15 13:04:11.000000000,"[{'_account_id': 15993}, {'_account_id': 22348}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-14 15:45:35.000000000', 'files': ['tests/roles/bootstrap-host/tasks/prepare_networking.yml'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/01fc5fad3cabb757718e5f91d5f0669ada1adce3', 'message': 'Disable firewalld for AIO build\n\nUse the same method as kolla-ansible\n\nChange-Id: I01718f822c1af6058fd12c340502c5a89a9d0948\n'}]",0,688431,01fc5fad3cabb757718e5f91d5f0669ada1adce3,8,3,1,25023,,,0,"Disable firewalld for AIO build

Use the same method as kolla-ansible

Change-Id: I01718f822c1af6058fd12c340502c5a89a9d0948
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/31/688431/1 && git format-patch -1 --stdout FETCH_HEAD,['tests/roles/bootstrap-host/tasks/prepare_networking.yml'],1,01fc5fad3cabb757718e5f91d5f0669ada1adce3,,"- name: Check if firewalld is installed command: rpm -q firewalld register: firewalld_check changed_when: false failed_when: firewalld_check.rc > 1 args: warn: false when: ansible_os_family == 'RedHat' - name: Disable firewalld become: True service: name: ""{{ item }}"" enabled: false state: stopped with_items: - firewalld when: - ansible_os_family == 'RedHat' - firewalld_check.rc == 0 ",,21,0
openstack%2Ftripleo-heat-templates~master~I3891da45e665727ab6d767514f9d24cb06da6b50,openstack/tripleo-heat-templates,master,I3891da45e665727ab6d767514f9d24cb06da6b50,Podman 1.4.1 drops json-file in favor of k8s-file,MERGED,2019-06-19 05:47:46.000000000,2019-10-15 13:02:31.000000000,2019-06-24 15:53:50.000000000,"[{'_account_id': 360}, {'_account_id': 3153}, {'_account_id': 6926}, {'_account_id': 8833}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 25402}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-06-19 05:47:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/521e63f5a51da71c8f2b0403dc8310ffa36ea3a0', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/666223\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n'}, {'number': 2, 'created': '2019-06-20 06:40:44.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/406383469cf6bee69094602ef879170848f2a9e1', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/666223\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n'}, {'number': 3, 'created': '2019-06-20 19:09:29.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/d277489b34baedae49410823b5edb4180fa8a46e', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/666223\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n'}, {'number': 4, 'created': '2019-06-24 05:35:16.000000000', 'files': ['common/container-puppet.py'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/55e1eac8920c8ecb987bcc6b6edeb723956fd40c', 'message': 'Podman 1.4.1 drops json-file in favor of k8s-file\n\nWhile this new name makes more sense than the ""json-file"" which wasn\'t a\njson, it breaks podman invocations[0] in TripleO.\n\nAlso, moved the configuration snipped to the podman dedicated block,\nsince docker doesn\'t have that driver[1].\n\n[0] https://github.com/containers/libpod/issues/3363\n[1] https://docs.docker.com/config/containers/logging/configure/\n\nDepends-On: https://review.opendev.org/666223\nChange-Id: I3891da45e665727ab6d767514f9d24cb06da6b50\n'}]",0,666226,55e1eac8920c8ecb987bcc6b6edeb723956fd40c,30,9,4,28223,,,0,"Podman 1.4.1 drops json-file in favor of k8s-file

While this new name makes more sense than the ""json-file"" which wasn't a
json, it breaks podman invocations[0] in TripleO.

Also, moved the configuration snipped to the podman dedicated block,
since docker doesn't have that driver[1].

[0] https://github.com/containers/libpod/issues/3363
[1] https://docs.docker.com/config/containers/logging/configure/

Depends-On: https://review.opendev.org/666223
Change-Id: I3891da45e665727ab6d767514f9d24cb06da6b50
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/26/666226/4 && git format-patch -1 --stdout FETCH_HEAD,['common/container-puppet.py'],1,521e63f5a51da71c8f2b0403dc8310ffa36ea3a0,container-puppet/logging," logging = ['--log-driver', 'k8s-file', '--log-opt',"," '--log-driver', 'json-file', logging = ['--log-opt',",2,2
openstack%2Fcharm-swift-storage~master~I121af845bf11c22052479a497b196a4670021256,openstack/charm-swift-storage,master,I121af845bf11c22052479a497b196a4670021256,py3: Switch packages to Python 3 for train and later,MERGED,2019-09-04 21:48:34.000000000,2019-10-15 12:54:33.000000000,2019-10-15 12:54:33.000000000,"[{'_account_id': 935}, {'_account_id': 7730}, {'_account_id': 11805}, {'_account_id': 20648}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-09-04 21:48:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/cfe6fdfd3746fc742bfe226db720a0acea356c81', 'message': 'py3: Switch to Py3 for train and add bionic-train tests\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n  * Add bionic-train functional tests.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}, {'number': 2, 'created': '2019-09-05 00:53:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/edb663fb67a38f53d72b95ab77fa6669d85c07ab', 'message': 'py3: Switch packages to Python 3 for train and later\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}, {'number': 3, 'created': '2019-09-09 21:01:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/a3e6266f87abda1c49419f1785e56070ffd97473', 'message': 'py3: Switch packages to Python 3 for train and later\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}, {'number': 4, 'created': '2019-09-10 12:36:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/60a190d8c744247da8360d117a50d09a018b3c3d', 'message': 'py3: Switch packages to Python 3 for train and later\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n\nAlso add OS_* to tox.ini to allow functional tests to execute.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}, {'number': 5, 'created': '2019-10-09 14:03:57.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/900f8ffb22773fbef16d42426fcca0e3355bde19', 'message': 'py3: Switch packages to Python 3 for train and later\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n\nAlso add OS_* to tox.ini to allow functional tests to execute.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}, {'number': 6, 'created': '2019-10-14 08:30:07.000000000', 'files': ['unit_tests/test_swift_storage_relations.py', 'unit_tests/test_swift_storage_utils.py', 'tox.ini', 'hooks/swift_storage_hooks.py', 'lib/swift_storage_utils.py'], 'web_link': 'https://opendev.org/openstack/charm-swift-storage/commit/fb6e21b51f2d24b19a29d9a81ecf44d72e192bee', 'message': 'py3: Switch packages to Python 3 for train and later\n\nSwitch package install to Python 3 for OpenStack Train and later.\n\nWhen upgrading, remove any python-* packages that were explicitly\ninstallated and then autoremove --purge any dependencies that are\nno longer required.\n\nThis patch also includes the following related changes:\n  * Use the common files package, swift, rather than python-swift\n    when using a package name to determine release.\n\nAlso add OS_* to tox.ini to allow functional tests to execute.\n\nChange-Id: I121af845bf11c22052479a497b196a4670021256\n'}]",1,680227,fb6e21b51f2d24b19a29d9a81ecf44d72e192bee,35,5,6,11805,,,0,"py3: Switch packages to Python 3 for train and later

Switch package install to Python 3 for OpenStack Train and later.

When upgrading, remove any python-* packages that were explicitly
installated and then autoremove --purge any dependencies that are
no longer required.

This patch also includes the following related changes:
  * Use the common files package, swift, rather than python-swift
    when using a package name to determine release.

Also add OS_* to tox.ini to allow functional tests to execute.

Change-Id: I121af845bf11c22052479a497b196a4670021256
",git fetch https://review.opendev.org/openstack/charm-swift-storage refs/changes/27/680227/6 && git format-patch -1 --stdout FETCH_HEAD,"['unit_tests/test_swift_storage_relations.py', 'tests/gate-basic-bionic-train', 'unit_tests/test_swift_storage_utils.py', 'tox.ini', 'hooks/swift_storage_hooks.py', 'lib/swift_storage_utils.py']",6,cfe6fdfd3746fc742bfe226db720a0acea356c81,charm-train," apt_update, apt_install, apt_purge, apt_autoremove, filter_missing_packages, status_set, CompareOpenStackReleases, reset_os_release, os_release, 'gdisk', 'lvm2', 'swift', 'swift-account', 'swift-container', 'swift-object', 'python-jinja2', 'python-psutil', 'xfsprogs', ] PY3_PACKAGES = [ 'python3-jinja2', 'python3-psutil', 'python3-six', 'python3-swift', ] PURGE_PACKAGES = [ 'python-jinja2', 'python-psutil', 'python-swift', release = get_os_codename_package('swift', fatal=False) or 'essex'def determine_packages(release): """"""Determine what packages are needed for a given OpenStack release."""""" cmp_openstack = CompareOpenStackReleases(release) pkgs = PACKAGES[:] if cmp_openstack >= 'train': pkgs = [p for p in pkgs if not p.startswith('python-')] pkgs.extend(PY3_PACKAGES) return pkgs def determine_purge_packages(): ''' Determine list of packages that where previously installed which are no longer needed. :returns: list of package names ''' cmp_openstack = CompareOpenStackReleases(os_release('swift')) if cmp_openstack >= 'train': return PURGE_PACKAGES return [] def remove_old_packages(): '''Purge any packages that need to be removed. :returns: bool Whether packages were removed. ''' installed_packages = filter_missing_packages(determine_purge_packages()) if installed_packages: log('Removing apt packages') status_set('maintenance', 'Removing apt packages') apt_purge(installed_packages, fatal=True) apt_autoremove(purge=True, fatal=True) return bool(installed_packages) reset_os_release() apt_install(packages=determine_packages(new_src), options=dpkg_opts, fatal=True) remove_old_packages()"," apt_update 'swift', 'swift-account', 'swift-container', 'swift-object', 'xfsprogs', 'gdisk', 'lvm2', 'python-jinja2', 'python-psutil', release = get_os_codename_package('python-swift', fatal=False) or 'essex'",166,17
openstack%2Fdevstack-gate~master~If90b8a06a9160f966d54202fed5391604d663182,openstack/devstack-gate,master,If90b8a06a9160f966d54202fed5391604d663182,Work around cffi install error,ABANDONED,2019-10-15 12:28:22.000000000,2019-10-15 12:53:24.000000000,,"[{'_account_id': 8731}, {'_account_id': 9029}, {'_account_id': 13988}]","[{'number': 1, 'created': '2019-10-15 12:28:22.000000000', 'files': ['devstack-vm-gate-wrap.sh'], 'web_link': 'https://opendev.org/openstack/devstack-gate/commit/279e3f284ce8ac55a8ce71221c90bf6831b98bab', 'message': ""Work around cffi install error\n\ncffi-1.13.0  doesn't install properly see\nhttps://zuul.opendev.org/t/openstack/build/c082d27a252140ef9d1384876d745dcc/log/job-output.txt#2913\n\nChange-Id: If90b8a06a9160f966d54202fed5391604d663182\n""}]",0,688696,279e3f284ce8ac55a8ce71221c90bf6831b98bab,3,3,1,19134,,,0,"Work around cffi install error

cffi-1.13.0  doesn't install properly see
https://zuul.opendev.org/t/openstack/build/c082d27a252140ef9d1384876d745dcc/log/job-output.txt#2913

Change-Id: If90b8a06a9160f966d54202fed5391604d663182
",git fetch https://review.opendev.org/openstack/devstack-gate refs/changes/96/688696/1 && git format-patch -1 --stdout FETCH_HEAD,['devstack-vm-gate-wrap.sh'],1,279e3f284ce8ac55a8ce71221c90bf6831b98bab,cffi-workaround,# Workaround for cffi-1.13.0 not installed properly /tmp/ansible/bin/pip install cffi==1.12.3,,2,0
openstack%2Freleases~master~Ifdd95e455f5def02adeff5b77a4399690acc026a,openstack/releases,master,Ifdd95e455f5def02adeff5b77a4399690acc026a,Create Train milestone for OSA,MERGED,2019-10-11 07:20:12.000000000,2019-10-15 12:33:14.000000000,2019-10-15 12:33:14.000000000,"[{'_account_id': 308}, {'_account_id': 1004}, {'_account_id': 11904}, {'_account_id': 17068}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 28543}, {'_account_id': 28619}]","[{'number': 1, 'created': '2019-10-11 07:20:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/releases/commit/5ff372b2cd379a33064104dd2d50dda429574da9', 'message': 'Create Train milestone for OSA\n\nDepends-On: https://review.opendev.org/681002\nChange-Id: Ifdd95e455f5def02adeff5b77a4399690acc026a\n'}, {'number': 2, 'created': '2019-10-11 07:22:15.000000000', 'files': ['deliverables/train/openstack-ansible.yaml'], 'web_link': 'https://opendev.org/openstack/releases/commit/9713bacd1887bb9d61919e5664ccb33a9076f325', 'message': 'Create Train milestone for OSA\n\nDepends-On: https://review.opendev.org/681002\nChange-Id: Ifdd95e455f5def02adeff5b77a4399690acc026a\n'}]",0,688051,9713bacd1887bb9d61919e5664ccb33a9076f325,13,8,2,28619,,,0,"Create Train milestone for OSA

Depends-On: https://review.opendev.org/681002
Change-Id: Ifdd95e455f5def02adeff5b77a4399690acc026a
",git fetch https://review.opendev.org/openstack/releases refs/changes/51/688051/1 && git format-patch -1 --stdout FETCH_HEAD,['deliverables/train/openstack-ansible.yaml'],1,5ff372b2cd379a33064104dd2d50dda429574da9,release_osa, - Projects become more re-usable outside of the full OpenStack-Ansible deploymentreleases: - version: 20.0.0.0b1 projects: - repo: openstack/openstack-ansible hash: 440bc86cd12338e467a9cd41fb18542913ee89f4, - Projects become more re-usable outside of the full OpenStack-Ansible deployment,7,1
openstack%2Ftripleo-heat-templates~master~I67a06d9288115d78bab8be46d42e23f82492d230,openstack/tripleo-heat-templates,master,I67a06d9288115d78bab8be46d42e23f82492d230,Scenario 010 multinode fixups,ABANDONED,2019-10-10 16:05:15.000000000,2019-10-15 12:32:52.000000000,,"[{'_account_id': 6681}, {'_account_id': 22348}, {'_account_id': 23181}]","[{'number': 1, 'created': '2019-10-10 16:05:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/17d1e3ead45b4904f258758a97dc3cbb1a77e50c', 'message': 'Scenario 010 multinode fixups\n\nWhile we currently running this as voting or in the gate, we should keep\nit in working state in the event we want to add to some occasional queue\nto catch those problems that seem not to occur on standalone.\n\nChange-Id: I67a06d9288115d78bab8be46d42e23f82492d230\n'}, {'number': 2, 'created': '2019-10-10 17:52:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/f4ee90640f0a92fb38db33e8a809ab30ffcea021', 'message': 'Scenario 010 multinode fixups\n\nWhile we currently running this as voting or in the gate, we should keep\nit in working state in the event we want to add to some occasional queue\nto catch those problems that seem not to occur on standalone.\n\nChange-Id: I67a06d9288115d78bab8be46d42e23f82492d230\n'}, {'number': 3, 'created': '2019-10-15 12:28:43.000000000', 'files': ['ci/environments/scenario010-multinode-containers.yaml'], 'web_link': 'https://opendev.org/openstack/tripleo-heat-templates/commit/0001af9bd04d428b1168b93416c75275439c4f56', 'message': 'Scenario 010 multinode fixups\n\nWhile we currently running this as voting or in the gate, we should keep\nit in working state in the event we want to add to some occasional queue\nto catch those problems that seem not to occur on standalone.\n\nChange-Id: I67a06d9288115d78bab8be46d42e23f82492d230\n'}]",0,687946,0001af9bd04d428b1168b93416c75275439c4f56,9,3,3,6681,,,0,"Scenario 010 multinode fixups

While we currently running this as voting or in the gate, we should keep
it in working state in the event we want to add to some occasional queue
to catch those problems that seem not to occur on standalone.

Change-Id: I67a06d9288115d78bab8be46d42e23f82492d230
",git fetch https://review.opendev.org/openstack/tripleo-heat-templates refs/changes/46/687946/1 && git format-patch -1 --stdout FETCH_HEAD,['ci/environments/scenario010-multinode-containers.yaml'],1,17d1e3ead45b4904f258758a97dc3cbb1a77e50c,, OS::TripleO::Services::OsloMessagingRpc: ../../deployment/rabbitmq/rabbitmq-messaging-rpc-pacemaker-puppet.yaml OS::TripleO::Services::OsloMessagingNotify: ../../deployment/rabbitmq/rabbitmq-messaging-notify-shared-puppet.yaml devices: - /dev/loop3 journal_size: 512 CephAnsiblePlaybookVerbosity: 1 CephAnsibleEnvironmentVariables: ANSIBLE_SSH_RETRIES: '4' DEFAULT_FORKS: '3', osd_objectstore: bluestore osd_scenario: lvm lvm_volumes: - data: ceph_lv_data data_vg: ceph_vg db: ceph_lv_db db_vg: ceph_vg wal: ceph_lv_wal wal_vg: ceph_vg,9,9
openstack%2Fcloudkitty-dashboard~master~Id48d23c5cd0fb031ba4c8ce40be900185858d89c,openstack/cloudkitty-dashboard,master,Id48d23c5cd0fb031ba4c8ce40be900185858d89c,Use Horizon project template for django jobs,MERGED,2019-10-09 15:50:24.000000000,2019-10-15 12:31:27.000000000,2019-10-15 12:27:58.000000000,"[{'_account_id': 1736}, {'_account_id': 22348}, {'_account_id': 23060}, {'_account_id': 27822}, {'_account_id': 29503}]","[{'number': 1, 'created': '2019-10-09 15:50:24.000000000', 'files': ['.zuul.yaml', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/cloudkitty-dashboard/commit/44d0eae809994503e7311af5e85fbe59e3032c94', 'message': ""Use Horizon project template for django jobs\n\nHorizon defined a project template 'horizon-non-primary-django-jobs'\nfor django jobs. This patch use that template to run django jobs\nhere. For information please refer [1]\n\n[1] https://review.opendev.org/#/c/681969/\n\nChange-Id: Id48d23c5cd0fb031ba4c8ce40be900185858d89c\n""}]",0,687603,44d0eae809994503e7311af5e85fbe59e3032c94,12,5,1,29313,,,0,"Use Horizon project template for django jobs

Horizon defined a project template 'horizon-non-primary-django-jobs'
for django jobs. This patch use that template to run django jobs
here. For information please refer [1]

[1] https://review.opendev.org/#/c/681969/

Change-Id: Id48d23c5cd0fb031ba4c8ce40be900185858d89c
",git fetch https://review.opendev.org/openstack/cloudkitty-dashboard refs/changes/03/687603/1 && git format-patch -1 --stdout FETCH_HEAD,"['.zuul.yaml', 'tox.ini']",2,44d0eae809994503e7311af5e85fbe59e3032c94,django22,"envlist = py27,py36,py37,py3-{dj111,dj22},pypy,pep8commands = dj111: pip install django>=1.11,<2 dj22: pip install django>=2.2,<2.3 stestr run --slowest {posargs}","envlist = py27,py36,py37,pypy,pep8commands = stestr run --slowest {posargs}",6,2
openstack%2Fpython-swiftclient~master~I126469a3ee98d804c91f6be6c4306d65671332a8,openstack/python-swiftclient,master,I126469a3ee98d804c91f6be6c4306d65671332a8,Add ability to exclude file from upload.,NEW,2018-05-15 10:31:56.000000000,2019-10-15 12:18:58.000000000,,"[{'_account_id': 3}, {'_account_id': 330}, {'_account_id': 1179}, {'_account_id': 18614}, {'_account_id': 22348}, {'_account_id': 26690}, {'_account_id': 27623}]","[{'number': 1, 'created': '2018-05-15 10:31:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/51064ee03331e3a99105dc5c87a3f9f7cd968ae5', 'message': ""Add ability to exclude file from upload.\n\nImplemented the fix to support '--exclude' option to\nexclude the specified file type to upload.\n\nChange-Id: I126469a3ee98d804c91f6be6c4306d65671332a8\nCloses-Bug: #1532885\n""}, {'number': 2, 'created': '2018-07-31 06:46:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/22494a1f7243c6a3d0a1504bf6b89fed4452189b', 'message': ""Add ability to exclude file from upload.\n\nImplemented the fix to support '--exclude' option to\nexclude the specified file type to upload.\n\nChange-Id: I126469a3ee98d804c91f6be6c4306d65671332a8\nCloses-Bug: #1532885\n""}, {'number': 3, 'created': '2018-08-02 08:06:00.000000000', 'files': ['swiftclient/shell.py', 'tests/unit/test_service.py', 'swiftclient/service.py'], 'web_link': 'https://opendev.org/openstack/python-swiftclient/commit/ac4c7b89cc9ce3cfc0f2c6d735bd6c47213f9d72', 'message': ""Add ability to exclude file from upload.\n\nImplemented the fix to support '--exclude' option to\nexclude the specified file type to upload.\n\nChange-Id: I126469a3ee98d804c91f6be6c4306d65671332a8\nCloses-Bug: #1532885\n""}]",2,568547,ac4c7b89cc9ce3cfc0f2c6d735bd6c47213f9d72,24,7,3,26690,,,0,"Add ability to exclude file from upload.

Implemented the fix to support '--exclude' option to
exclude the specified file type to upload.

Change-Id: I126469a3ee98d804c91f6be6c4306d65671332a8
Closes-Bug: #1532885
",git fetch https://review.opendev.org/openstack/python-swiftclient refs/changes/47/568547/1 && git format-patch -1 --stdout FETCH_HEAD,"['swiftclient/shell.py', 'tests/unit/test_service.py', 'swiftclient/service.py']",3,51064ee03331e3a99105dc5c87a3f9f7cd968ae5,bug/1532885,"import fnmatch 'exclude_pattern': None, 'dir_marker': False, # Only for None sources 'exclude_pattern': None if options['exclude_pattern'] is not None: if fnmatch.fnmatch(obj, options['exclude_pattern']): res.update({ 'success': True, 'status': 'object-excluded' }) return res ", 'dir_marker': False # Only for None sources,86,5
openstack%2Ftraining-guides~master~I35a153814663b2ca776b1f1abd479733387bd1ac,openstack/training-guides,master,I35a153814663b2ca776b1f1abd479733387bd1ac,Imported Translations from Zanata,MERGED,2019-10-15 10:19:52.000000000,2019-10-15 11:58:24.000000000,2019-10-15 11:56:36.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 10:19:52.000000000', 'files': ['doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po'], 'web_link': 'https://opendev.org/openstack/training-guides/commit/ebafda12677bfb4549ec0566d5af8d4635cefa72', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I35a153814663b2ca776b1f1abd479733387bd1ac\n'}]",0,688671,ebafda12677bfb4549ec0566d5af8d4635cefa72,7,2,1,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I35a153814663b2ca776b1f1abd479733387bd1ac
",git fetch https://review.opendev.org/openstack/training-guides refs/changes/71/688671/1 && git format-patch -1 --stdout FETCH_HEAD,['doc/upstream-training/source/locale/ko_KR/LC_MESSAGES/upstream-training.po'],1,ebafda12677bfb4549ec0566d5af8d4635cefa72,zanata/translations,"# SeongSoo Cho <ppiyakk2@printf.kr>, 2019. #zanata""POT-Creation-Date: 2019-10-12 09:37+0000\n""""PO-Revision-Date: 2019-10-14 11:42+0000\n"" ""Last-Translator: SeongSoo Cho <ppiyakk2@printf.kr>\n""msgid ""**Friday, October 18, 2019**"" msgstr ""**2019년 10월 18일 금요일**"" msgid "":ref:`upstream-training-day`"" msgstr "":ref: `upstream-training-day`"" msgid ""Bangalore,"" msgstr ""방갈로르,"" msgid ""India"" msgstr ""인도"" msgid ""October 18, 2019"" msgstr ""2019년 10월 18일"" msgid ""OpenStack Upstream Training Day Bangalore"" msgstr ""OpenStack Upstream Training Day 방갈로르"" msgid ""See YOU in Bangalore!"" msgstr ""방갈로르에서 만나요!"" msgid ""Upstream Training Day"" msgstr ""Upstream Training Day"" ""`Etherpad for OpenStack Upstream Training Day Bangalore <https://etherpad."" ""openstack.org/p/upstream-institute-india-2019>`_"" msgstr """" ""`Etherpad for OpenStack Upstream Training Day Bangalore <https://etherpad."" ""openstack.org/p/upstream-institute-india-2019>`_"" msgid """"""`OpenStack Upstream Training Day <https://www.meetup.com/Indian-OpenStack-"" ""User-Group/events/265173622/>`_ event site"" msgstr """" ""`OpenStack Upstream Training Day <https://www.meetup.com/Indian-OpenStack-"" ""User-Group/events/265173622/>`_ event site"" msgid """"","""POT-Creation-Date: 2019-10-10 21:43+0000\n""""PO-Revision-Date: 2019-10-07 02:48+0000\n"" ""Last-Translator: Ian Y. Choi <ianyrchoi@gmail.com>\n""",42,3
openstack%2Fhorizon~master~I937fa2a14bb483d87f057b3e8be219ecdc9363eb,openstack/horizon,master,I937fa2a14bb483d87f057b3e8be219ecdc9363eb,Use quoting for CSV Writing,MERGED,2019-08-29 00:03:20.000000000,2019-10-15 11:47:29.000000000,2019-10-15 11:46:05.000000000,"[{'_account_id': 841}, {'_account_id': 1736}, {'_account_id': 4264}, {'_account_id': 10273}, {'_account_id': 17499}, {'_account_id': 22348}, {'_account_id': 27822}, {'_account_id': 28935}, {'_account_id': 29313}]","[{'number': 1, 'created': '2019-08-29 00:03:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/a0e875cabd580957433f3b6c1d75d740b26879af', 'message': ""Use quoting for CSV Writing (security)\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 2, 'created': '2019-08-29 07:16:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/4fe1a573cdac5be1078e7a4ca1b80c205af8c930', 'message': ""Use quoting for CSV Writing (security)\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 3, 'created': '2019-09-03 19:42:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/44c8c672437ed263ad864bd8ffc3df02aaa2fb1d', 'message': ""Use quoting for CSV Writing (security)\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 4, 'created': '2019-09-04 19:52:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/8d5fd03defbc1be768db10e51a312b70553e12a8', 'message': ""Use quoting for CSV Writing (security)\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nCloses-Bug: #1842749\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 5, 'created': '2019-09-09 10:51:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/40235d839857578b3055c67782e663e6bfb5d809', 'message': ""Use quoting for CSV Writing\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nCloses-Bug: #1842749\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 6, 'created': '2019-09-30 20:29:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/horizon/commit/1a279f633830f593bff7a673fa323a264d38dd97', 'message': ""Use quoting for CSV Writing\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nCloses-Bug: #1842749\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}, {'number': 7, 'created': '2019-10-11 19:52:08.000000000', 'files': ['horizon/utils/csvbase.py', 'openstack_dashboard/dashboards/identity/projects/tests.py', 'openstack_dashboard/dashboards/admin/instances/tests.py', 'openstack_dashboard/dashboards/admin/overview/tests.py', 'openstack_dashboard/dashboards/project/instances/tests.py', 'openstack_dashboard/test/test_data/nova_data.py'], 'web_link': 'https://opendev.org/openstack/horizon/commit/70629916fe32df61018fd122711e6b036b53c811', 'message': ""Use quoting for CSV Writing\n\nAn attacker could create an instance with a malicious name beginning\nwith an equals sign (=) or at sign (‘@’).\nThese are both recognized in Excel as metacharacters for a formula. The\nattacker can create an instance name that includes a payload that will\nexecute code such as:\n=cmd|' /C calc'!A0\nThis payload opens the calculator program when the resulting CSV is\nopened on a Windows machine with Microsoft Excel. An attacker could\neasily substitute this payload with another that runs any arbitrary\nshell commands.\n\nQuote the CSV output so this is no longer a possibility.\n\nCloses-Bug: #1842749\nChange-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb\n""}]",0,679161,70629916fe32df61018fd122711e6b036b53c811,36,9,7,10273,,,0,"Use quoting for CSV Writing

An attacker could create an instance with a malicious name beginning
with an equals sign (=) or at sign (‘@’).
These are both recognized in Excel as metacharacters for a formula. The
attacker can create an instance name that includes a payload that will
execute code such as:
=cmd|' /C calc'!A0
This payload opens the calculator program when the resulting CSV is
opened on a Windows machine with Microsoft Excel. An attacker could
easily substitute this payload with another that runs any arbitrary
shell commands.

Quote the CSV output so this is no longer a possibility.

Closes-Bug: #1842749
Change-Id: I937fa2a14bb483d87f057b3e8be219ecdc9363eb
",git fetch https://review.opendev.org/openstack/horizon refs/changes/61/679161/6 && git format-patch -1 --stdout FETCH_HEAD,['horizon/utils/csvbase.py'],1,a0e875cabd580957433f3b6c1d75d740b26879af,bug/1842749," self.writer = DictWriter(self.out, columns, quoting=csv.QUOTE_ALL) self.writer = writer(self.out, quoting=csv.QUOTE_ALL)"," self.writer = DictWriter(self.out, columns) self.writer = writer(self.out)",2,2
openstack%2Fheat-dashboard~master~I5cfdfa81de73cc51343c1948866cc5be2646f746,openstack/heat-dashboard,master,I5cfdfa81de73cc51343c1948866cc5be2646f746,[WIP] Generate PDF documentation,ABANDONED,2019-10-15 11:27:27.000000000,2019-10-15 11:31:14.000000000,,[{'_account_id': 29313}],"[{'number': 1, 'created': '2019-10-15 11:27:27.000000000', 'files': ['doc/source/conf.py', 'doc/requirements.txt', 'tox.ini'], 'web_link': 'https://opendev.org/openstack/heat-dashboard/commit/93037acdeb4913ca0a0eeee2879fe859c47adc91', 'message': ""[WIP] Generate PDF documentation\n\nThis commit adds a new tox target to build PDF documentation.\nIt's a part of community goal, see storyboard for more\ninformation.\n\nChange-Id: I5cfdfa81de73cc51343c1948866cc5be2646f746\nStory: 2006083\nTask: 34856\n""}]",0,688682,93037acdeb4913ca0a0eeee2879fe859c47adc91,2,1,1,841,,,0,"[WIP] Generate PDF documentation

This commit adds a new tox target to build PDF documentation.
It's a part of community goal, see storyboard for more
information.

Change-Id: I5cfdfa81de73cc51343c1948866cc5be2646f746
Story: 2006083
Task: 34856
",git fetch https://review.opendev.org/openstack/heat-dashboard refs/changes/82/688682/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/conf.py', 'doc/requirements.txt', 'tox.ini']",3,93037acdeb4913ca0a0eeee2879fe859c47adc91,build-pdf-docs,[testenv:pdf-docs] basepython = python3 envdir = {toxworkdir}/docs deps = {[testenv:docs]deps} whitelist_externals = make commands = sphinx-build -W -b latex doc/source doc/build/pdf make -C doc/build/pdf ,,25,2
openstack%2Fnetworking-ovn~stable%2Fqueens~I3e9d62ffc5eab396e983c0769e53d2d1f35644f6,openstack/networking-ovn,stable/queens,I3e9d62ffc5eab396e983c0769e53d2d1f35644f6,Do not lose router logical port upon subnet add on the external net,MERGED,2019-10-10 22:57:33.000000000,2019-10-15 11:27:27.000000000,2019-10-15 11:27:27.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}, {'_account_id': 23804}]","[{'number': 1, 'created': '2019-10-10 22:57:33.000000000', 'files': ['networking_ovn/tests/functional/test_router.py', 'networking_ovn/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/919eaabd5d94ed4838ba9c471b5a2e31fd5f08e1', 'message': 'Do not lose router logical port upon subnet add on the external net\n\nPrior to this patch, logical port used by the router to the external\nnetwork was lost if subnet was added to that network. That was\ncaused by missing explicit delete call in DelLRouterPortCommand.\n\nAlso added functional test to exercise this particular code path:\n  test_router::test_gateway_chassis_with_subnet_changes()\n\nCloses-Bug: #1843485\nCo-authored-by: Daniel Alvarez <dalvarez@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\n\nChange-Id: I3e9d62ffc5eab396e983c0769e53d2d1f35644f6\n(cherry picked from commit 92142f3165806527e33a4544162ad4eb301e8436)\n'}]",0,688003,919eaabd5d94ed4838ba9c471b5a2e31fd5f08e1,9,5,1,11952,,,0,"Do not lose router logical port upon subnet add on the external net

Prior to this patch, logical port used by the router to the external
network was lost if subnet was added to that network. That was
caused by missing explicit delete call in DelLRouterPortCommand.

Also added functional test to exercise this particular code path:
  test_router::test_gateway_chassis_with_subnet_changes()

Closes-Bug: #1843485
Co-authored-by: Daniel Alvarez <dalvarez@redhat.com>
Co-authored-by: Terry Wilson <twilson@redhat.com>
Signed-off-by: Flavio Fernandes <flaviof@redhat.com>

Change-Id: I3e9d62ffc5eab396e983c0769e53d2d1f35644f6
(cherry picked from commit 92142f3165806527e33a4544162ad4eb301e8436)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/03/688003/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/test_router.py', 'networking_ovn/ovsdb/commands.py']",2,919eaabd5d94ed4838ba9c471b5a2e31fd5f08e1,bug/1843485, lrouter_port.delete(),,87,1
openstack%2Fopenstack-chef-repo~master~I255a7b6f437c0bba2ec1fda8fedf34780a60fc66,openstack/openstack-chef-repo,master,I255a7b6f437c0bba2ec1fda8fedf34780a60fc66,update source link in readme,ABANDONED,2019-10-15 03:11:47.000000000,2019-10-15 10:47:06.000000000,,"[{'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-15 03:11:47.000000000', 'files': ['README.md'], 'web_link': 'https://opendev.org/openstack/openstack-chef-repo/commit/bc942a6eb39025c63187fba222310d69c8bfef87', 'message': 'update source link in readme\n\nChange-Id: I255a7b6f437c0bba2ec1fda8fedf34780a60fc66\n'}]",0,688608,bc942a6eb39025c63187fba222310d69c8bfef87,4,2,1,30384,,,0,"update source link in readme

Change-Id: I255a7b6f437c0bba2ec1fda8fedf34780a60fc66
",git fetch https://review.opendev.org/openstack/openstack-chef-repo refs/changes/08/688608/1 && git format-patch -1 --stdout FETCH_HEAD,['README.md'],1,bc942a6eb39025c63187fba222310d69c8bfef87,,"For the replacement to this repository, see https://opendev.org/openstack/openstack-chef/","For the replacement to this repository, see https://git.openstack.org/cgit/openstack/openstack-chef",1,1
openstack%2Fneutron-lib~master~I429a00fc4f0f6614f0addc576262622aa2c415f5,openstack/neutron-lib,master,I429a00fc4f0f6614f0addc576262622aa2c415f5,Fix rendering of api-ref main page,MERGED,2019-10-14 20:46:29.000000000,2019-10-15 10:47:04.000000000,2019-10-15 10:45:54.000000000,"[{'_account_id': 841}, {'_account_id': 1131}, {'_account_id': 8313}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:46:29.000000000', 'files': ['api-ref/source/v2/index.rst'], 'web_link': 'https://opendev.org/openstack/neutron-lib/commit/af5e2aa7dcff40e0bb4b5aeb447843c4978cb0d1', 'message': ""Fix rendering of api-ref main page\n\nDue to missing empty lines in LBaaS v2 section on main\npage of Neutron's api-ref it was rendered incorrectly and\nsections which are after LBaaS section on this page were not\nrendered properly too.\n\nThis patch fixes this issue.\n\nTrivialFix\n\nChange-Id: I429a00fc4f0f6614f0addc576262622aa2c415f5\nCloses-Bug: #1848023\n""}]",0,688561,af5e2aa7dcff40e0bb4b5aeb447843c4978cb0d1,9,4,1,11975,,,0,"Fix rendering of api-ref main page

Due to missing empty lines in LBaaS v2 section on main
page of Neutron's api-ref it was rendered incorrectly and
sections which are after LBaaS section on this page were not
rendered properly too.

This patch fixes this issue.

TrivialFix

Change-Id: I429a00fc4f0f6614f0addc576262622aa2c415f5
Closes-Bug: #1848023
",git fetch https://review.opendev.org/openstack/neutron-lib refs/changes/61/688561/1 && git format-patch -1 --stdout FETCH_HEAD,['api-ref/source/v2/index.rst'],1,af5e2aa7dcff40e0bb4b5aeb447843c4978cb0d1,bug/1848023,,,3,0
openstack%2Fkuryr-kubernetes~master~I9095ced11f78eb1ae2890883fa6da4df74213480,openstack/kuryr-kubernetes,master,I9095ced11f78eb1ae2890883fa6da4df74213480,Fix CNI_COMMAND=VERSION case,MERGED,2019-10-11 11:48:08.000000000,2019-10-15 10:43:37.000000000,2019-10-15 10:42:04.000000000,"[{'_account_id': 11600}, {'_account_id': 14352}, {'_account_id': 17499}, {'_account_id': 22165}, {'_account_id': 22348}, {'_account_id': 23567}, {'_account_id': 28543}]","[{'number': 1, 'created': '2019-10-11 11:48:08.000000000', 'files': ['kuryr_kubernetes/cni/main.py', 'kuryr_kubernetes/config.py'], 'web_link': 'https://opendev.org/openstack/kuryr-kubernetes/commit/76fa78cfdea39795d927d6f639bd6224d9c2dc04', 'message': 'Fix CNI_COMMAND=VERSION case\n\nIn case of VERSION command k8s v1.16 and higher sends\nonly {""cniVersion"": ""0.4.0""} to the stdio, but kuryr-cni\nexpected cni-conf with kuryr_conf field.\n\nAlso k8s expects json in the stdio, but logs was also there.\nSo need to strictly redirect it into stderr in this case.\n\nIt\'s a work around, because maintanable way here is to use\ngolang\'s version based on containernetworking library.\n\nChange-Id: I9095ced11f78eb1ae2890883fa6da4df74213480\nSigned-off-by: Alexey Perevalov <a.perevalov@samsung.com>\n'}]",0,688108,76fa78cfdea39795d927d6f639bd6224d9c2dc04,20,7,1,28396,,,0,"Fix CNI_COMMAND=VERSION case

In case of VERSION command k8s v1.16 and higher sends
only {""cniVersion"": ""0.4.0""} to the stdio, but kuryr-cni
expected cni-conf with kuryr_conf field.

Also k8s expects json in the stdio, but logs was also there.
So need to strictly redirect it into stderr in this case.

It's a work around, because maintanable way here is to use
golang's version based on containernetworking library.

Change-Id: I9095ced11f78eb1ae2890883fa6da4df74213480
Signed-off-by: Alexey Perevalov <a.perevalov@samsung.com>
",git fetch https://review.opendev.org/openstack/kuryr-kubernetes refs/changes/08/688108/1 && git format-patch -1 --stdout FETCH_HEAD,"['kuryr_kubernetes/cni/main.py', 'kuryr_kubernetes/config.py']",2,76fa78cfdea39795d927d6f639bd6224d9c2dc04,," if os.environ.get('CNI_COMMAND') == 'VERSION': CONF.set_default('use_stderr', True)",,4,1
openstack%2Fnetworking-ovn~stable%2Frocky~I3e9d62ffc5eab396e983c0769e53d2d1f35644f6,openstack/networking-ovn,stable/rocky,I3e9d62ffc5eab396e983c0769e53d2d1f35644f6,Do not lose router logical port upon subnet add on the external net,MERGED,2019-10-10 22:56:54.000000000,2019-10-15 10:32:48.000000000,2019-10-15 10:32:48.000000000,"[{'_account_id': 1131}, {'_account_id': 6773}, {'_account_id': 21798}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-10 22:56:54.000000000', 'files': ['networking_ovn/tests/functional/test_router.py', 'networking_ovn/ovsdb/commands.py'], 'web_link': 'https://opendev.org/openstack/networking-ovn/commit/bac75284f4600ebcc81e3a8decf9d21e35fa78f3', 'message': 'Do not lose router logical port upon subnet add on the external net\n\nPrior to this patch, logical port used by the router to the external\nnetwork was lost if subnet was added to that network. That was\ncaused by missing explicit delete call in DelLRouterPortCommand.\n\nAlso added functional test to exercise this particular code path:\n  test_router::test_gateway_chassis_with_subnet_changes()\n\nCloses-Bug: #1843485\nCo-authored-by: Daniel Alvarez <dalvarez@redhat.com>\nCo-authored-by: Terry Wilson <twilson@redhat.com>\nSigned-off-by: Flavio Fernandes <flaviof@redhat.com>\n\nChange-Id: I3e9d62ffc5eab396e983c0769e53d2d1f35644f6\n(cherry picked from commit 92142f3165806527e33a4544162ad4eb301e8436)\n'}]",0,688002,bac75284f4600ebcc81e3a8decf9d21e35fa78f3,9,4,1,11952,,,0,"Do not lose router logical port upon subnet add on the external net

Prior to this patch, logical port used by the router to the external
network was lost if subnet was added to that network. That was
caused by missing explicit delete call in DelLRouterPortCommand.

Also added functional test to exercise this particular code path:
  test_router::test_gateway_chassis_with_subnet_changes()

Closes-Bug: #1843485
Co-authored-by: Daniel Alvarez <dalvarez@redhat.com>
Co-authored-by: Terry Wilson <twilson@redhat.com>
Signed-off-by: Flavio Fernandes <flaviof@redhat.com>

Change-Id: I3e9d62ffc5eab396e983c0769e53d2d1f35644f6
(cherry picked from commit 92142f3165806527e33a4544162ad4eb301e8436)
",git fetch https://review.opendev.org/openstack/networking-ovn refs/changes/02/688002/1 && git format-patch -1 --stdout FETCH_HEAD,"['networking_ovn/tests/functional/test_router.py', 'networking_ovn/ovsdb/commands.py']",2,bac75284f4600ebcc81e3a8decf9d21e35fa78f3,bug/1843485, lrouter_port.delete(),,87,1
openstack%2Fproject-config~master~Iad4ba12e843e452882da5ff6f45cfcfd88a76ff8,openstack/project-config,master,Iad4ba12e843e452882da5ff6f45cfcfd88a76ff8,Retire puppet-yum - remove gate jobs,MERGED,2019-10-14 20:47:08.000000000,2019-10-15 09:49:41.000000000,2019-10-15 09:49:41.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:47:08.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/b9706c00097ecf3b97adad9e408293228c045799', 'message': 'Retire puppet-yum - remove gate jobs\n\nFirst thing we need to do is remove gating jobs.\n\nChange-Id: Iad4ba12e843e452882da5ff6f45cfcfd88a76ff8\n'}]",0,688563,b9706c00097ecf3b97adad9e408293228c045799,8,3,1,2,,,0,"Retire puppet-yum - remove gate jobs

First thing we need to do is remove gating jobs.

Change-Id: Iad4ba12e843e452882da5ff6f45cfcfd88a76ff8
",git fetch https://review.opendev.org/openstack/project-config refs/changes/63/688563/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,b9706c00097ecf3b97adad9e408293228c045799,infra-centos-7, - noop-jobs, - infra-puppet-check-jobs - infra-puppet-apply-jobs - puppet-beaker-jobs-xenial-infra check: queue: system-config gate: queue: system-config,1,7
openstack%2Fproject-config~master~Iea26a368576fdebe04768e46c359d89bbbda1a16,openstack/project-config,master,Iea26a368576fdebe04768e46c359d89bbbda1a16,Stop running centos-7 puppet jobs,MERGED,2019-10-14 20:39:01.000000000,2019-10-15 09:47:33.000000000,2019-10-15 09:47:33.000000000,"[{'_account_id': 1}, {'_account_id': 4146}, {'_account_id': 6547}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:39:01.000000000', 'files': ['zuul.d/projects.yaml'], 'web_link': 'https://opendev.org/openstack/project-config/commit/37d48b16fc86592e78de229e5c05412da49ec149', 'message': ""Stop running centos-7 puppet jobs\n\nWe don't run centos-7 servers anymore.\n\nChange-Id: Iea26a368576fdebe04768e46c359d89bbbda1a16\n""}]",1,688560,37d48b16fc86592e78de229e5c05412da49ec149,9,4,1,2,,,0,"Stop running centos-7 puppet jobs

We don't run centos-7 servers anymore.

Change-Id: Iea26a368576fdebe04768e46c359d89bbbda1a16
",git fetch https://review.opendev.org/openstack/project-config refs/changes/60/688560/1 && git format-patch -1 --stdout FETCH_HEAD,['zuul.d/projects.yaml'],1,37d48b16fc86592e78de229e5c05412da49ec149,infra-centos-7,, - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra - puppet-beaker-jobs-centos-7-infra,0,72
openstack%2Ftripleo-validations~master~I3c45fc39cf6b5be493484ee97b1b212f060ebb05,openstack/tripleo-validations,master,I3c45fc39cf6b5be493484ee97b1b212f060ebb05,Fix Ironic Authentication exception,MERGED,2019-10-14 10:51:38.000000000,2019-10-15 09:45:22.000000000,2019-10-15 09:45:21.000000000,"[{'_account_id': 3153}, {'_account_id': 10239}, {'_account_id': 14985}, {'_account_id': 17888}, {'_account_id': 22348}, {'_account_id': 25877}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-14 10:51:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/5c372a6d3d712d256b1ab7e485fb6173a999222d', 'message': '[WIP] Fix Ironic Authentication exception\n\n\'keystoneauth1.exceptions.auth_plugins.MissingRequiredOptions\'>,\noriginal message: Auth plugin requires parameters which were not given:\nauth_url""\n\nChange-Id: I3c45fc39cf6b5be493484ee97b1b212f060ebb05\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 2, 'created': '2019-10-14 14:01:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/222217a4fbfa4ee9649e60749fe703e7e459530b', 'message': 'Fix Ironic Authentication exception\n\nSince Train, it is now mandatory to pass a keystoneauth Session object\ninto ``ironicclient.v1.client.Client`` and ``ironicclient.client.get_client``\n\nChange-Id: I3c45fc39cf6b5be493484ee97b1b212f060ebb05\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}, {'number': 3, 'created': '2019-10-14 14:43:53.000000000', 'files': ['tripleo_validations/utils.py'], 'web_link': 'https://opendev.org/openstack/tripleo-validations/commit/b1d1af33d45f265637e3a2686d2a8c62451a198f', 'message': 'Fix Ironic Authentication exception\n\nSince Train, it is now mandatory to pass a keystoneauth Session object\ninto ``ironicclient.v1.client.Client`` and ``ironicclient.client.get_client``\n\nThis patch also cleans up useless code in ``get_ironic_client`` method.\n\nChange-Id: I3c45fc39cf6b5be493484ee97b1b212f060ebb05\nSigned-off-by: Gael Chamoulaud <gchamoul@redhat.com>\n'}]",0,688383,b1d1af33d45f265637e3a2686d2a8c62451a198f,12,7,3,11491,,,0,"Fix Ironic Authentication exception

Since Train, it is now mandatory to pass a keystoneauth Session object
into ``ironicclient.v1.client.Client`` and ``ironicclient.client.get_client``

This patch also cleans up useless code in ``get_ironic_client`` method.

Change-Id: I3c45fc39cf6b5be493484ee97b1b212f060ebb05
Signed-off-by: Gael Chamoulaud <gchamoul@redhat.com>
",git fetch https://review.opendev.org/openstack/tripleo-validations refs/changes/83/688383/3 && git format-patch -1 --stdout FETCH_HEAD,['lookup_plugins/ironic_nodes.py'],1,5c372a6d3d712d256b1ab7e485fb6173a999222d,dynamic_argument_spec,"from ironicclient import client session = utils.get_auth_session(variables) ironic = client.get_client(1, session=session)", ironic = utils.get_ironic_client(variables),3,1
openstack%2Fopenstack-ansible~master~I4c290fa85af852aa808effd236a332666cc953e3,openstack/openstack-ansible,master,I4c290fa85af852aa808effd236a332666cc953e3,Imported Translations from Zanata,MERGED,2019-10-12 07:50:43.000000000,2019-10-15 09:30:48.000000000,2019-10-15 09:28:54.000000000,"[{'_account_id': 6547}, {'_account_id': 22348}, {'_account_id': 28619}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-10-12 07:50:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/09fc02495a21586c3024206e9437eeb82b137242', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4c290fa85af852aa808effd236a332666cc953e3\n'}, {'number': 2, 'created': '2019-10-14 08:43:03.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/2d8b8a4d5f2c327073d838a918e77c1c68ef121f', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4c290fa85af852aa808effd236a332666cc953e3\n'}, {'number': 3, 'created': '2019-10-15 08:39:22.000000000', 'files': ['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'doc/source/locale/de/LC_MESSAGES/doc-reference.po', 'doc/source/locale/id/LC_MESSAGES/doc-admin.po', 'doc/source/locale/de/LC_MESSAGES/doc-admin.po'], 'web_link': 'https://opendev.org/openstack/openstack-ansible/commit/c390f13eab8745827f5a54ca8eea30134340832d', 'message': 'Imported Translations from Zanata\n\nFor more information about this automatic import see:\nhttps://docs.openstack.org/i18n/latest/reviewing-translation-import.html\n\nChange-Id: I4c290fa85af852aa808effd236a332666cc953e3\n'}]",1,688255,c390f13eab8745827f5a54ca8eea30134340832d,13,4,3,11131,,,0,"Imported Translations from Zanata

For more information about this automatic import see:
https://docs.openstack.org/i18n/latest/reviewing-translation-import.html

Change-Id: I4c290fa85af852aa808effd236a332666cc953e3
",git fetch https://review.opendev.org/openstack/openstack-ansible refs/changes/55/688255/1 && git format-patch -1 --stdout FETCH_HEAD,"['releasenotes/source/locale/id/LC_MESSAGES/releasenotes.po', 'doc/source/locale/id/LC_MESSAGES/doc-admin.po', 'doc/source/locale/de/LC_MESSAGES/doc-admin.po']",3,09fc02495a21586c3024206e9437eeb82b137242,zanata/translations,"""POT-Creation-Date: 2019-10-11 09:50+0000\n""""PO-Revision-Date: 2019-03-25 02:07+0000\n""","""POT-Creation-Date: 2019-08-13 21:03+0000\n""""PO-Revision-Date: 2019-03-25 02:11+0000\n""msgid ""We can now go ahead with the upgrade of all the OpenStack components."" msgstr """" ""Wir können jetzt weitermachen mit der Aktualisierung aller OpenStack "" ""Komponenten."" msgid """" ""We can now go ahead with the upgrade of all the infrastructure components. "" ""To ensure that rabbitmq and mariadb are upgraded, we pass the appropriate "" ""flags."" msgstr """" ""Wir können jetzt weitermachen mit der Aktualisierung aller "" ""Infrastrukturkomponenten. Um sicherzustellen, dass rabbitmq und mariadb "" ""aktualisiert werden, wir führen die enstprechenden Flags mit aus."" ""With this complete, we can no restart the mariadb containers one at a time, "" ""ensuring that each is started, responding, and synchronized with the other "" ""nodes in the cluster before moving on to the next steps. This step allows "" ""the LXC container configuration that you applied earlier to take effect, "" ""ensuring that the containers are restarted in a controlled fashion."" msgstr """" ""Mit diesem Abschluss können wir nicht alle mariadb-Container gleichzeitig "" ""sondern einzeln nacheinander neu starten und sicherstellen, dass jeder "" ""Container gestartet wird, antwortet und mit den anderen Knoten im Cluster "" ""synchronisiert wird, bevor mit den nächsten Schritten fortgefahren wird. "" ""Durch diesen Schritt kann die zuvor angewendete LXC-Containerkonfiguration "" ""wirksam werden, um sicherzustellen, dass die Container kontrolliert neu "" ""gestartet werden."" msgid """"",105,51
openstack%2Fshade~stable%2Fstein~Ie41226c8b2ae21f7cbd57b5ecdd63423c8dc0426,openstack/shade,stable/stein,Ie41226c8b2ae21f7cbd57b5ecdd63423c8dc0426,Remove openSUSE 15.0 job,MERGED,2019-10-14 20:48:11.000000000,2019-10-15 09:19:27.000000000,2019-10-15 09:16:14.000000000,"[{'_account_id': 4146}, {'_account_id': 13252}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:48:11.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/shade/commit/61841a06a1585ee086b796c4fc803c5ade56119e', 'message': ""Remove openSUSE 15.0 job\n\nWe don't need to test this, the other platforms are sufficient.\n\nChange-Id: Ie41226c8b2ae21f7cbd57b5ecdd63423c8dc0426\n""}]",0,688564,61841a06a1585ee086b796c4fc803c5ade56119e,8,3,1,6547,,,0,"Remove openSUSE 15.0 job

We don't need to test this, the other platforms are sufficient.

Change-Id: Ie41226c8b2ae21f7cbd57b5ecdd63423c8dc0426
",git fetch https://review.opendev.org/openstack/shade refs/changes/64/688564/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,61841a06a1585ee086b796c4fc803c5ade56119e,,, - bifrost-integration-tinyipa-opensuse-150: voting: false,0,2
openstack%2Fneutron~master~I93f35eade6aa081160902d9d47278123815c04d1,openstack/neutron,master,I93f35eade6aa081160902d9d47278123815c04d1,Handle ports assigned to routers without routerports,MERGED,2019-09-05 13:42:38.000000000,2019-10-15 09:11:23.000000000,2019-10-02 03:36:30.000000000,"[{'_account_id': 1131}, {'_account_id': 9531}, {'_account_id': 9732}, {'_account_id': 9845}, {'_account_id': 11975}, {'_account_id': 15752}, {'_account_id': 16376}, {'_account_id': 16688}, {'_account_id': 22348}, {'_account_id': 26622}]","[{'number': 1, 'created': '2019-09-05 13:42:38.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/27eeb5693517614ba629db4d9a247e02505fc2d3', 'message': '[WIP] Stale routerports\n\nCloses-Bug: #routerports\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 2, 'created': '2019-09-06 10:25:52.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/39419d1bdb0843e9f164888eb308dd72d1542c74', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 3, 'created': '2019-09-07 09:29:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/c39f59b5522394beea9f2774c40059a0fa7474d2', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 4, 'created': '2019-09-10 05:41:49.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/09854721283facf67494bbd21bbe1c41d258ae72', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 5, 'created': '2019-09-11 07:08:33.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/2e111ae274b809dd511233b97acac2b3e255d2a3', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 6, 'created': '2019-09-11 08:58:31.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/e30bad31c74a44b54c4afc48b916a6b0e93d1a59', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 7, 'created': '2019-09-12 09:57:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/001c605a0788dd9d7e4fcf5246053e205afb950d', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 8, 'created': '2019-09-13 10:43:09.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/neutron/commit/300ea14a6dd2cdbc5b5562f4dd92c8826b63ab0e', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}, {'number': 9, 'created': '2019-09-20 16:17:41.000000000', 'files': ['neutron/db/l3_db.py', 'neutron/objects/ports.py', 'neutron/tests/unit/db/test_l3_db.py'], 'web_link': 'https://opendev.org/openstack/neutron/commit/c952b5960001faf98186b630fde75deafe5a7b8f', 'message': 'Handle ports assigned to routers without routerports\n\nIn the case of having a port attached to a router but the routerport\nregister is missing (as seen in the bug reported), this patch retrieves\nthe full list of ports attached to a router, filtering by router ID\nand network ID or port ID. In case of having a port attached to this\nrouter with missing routerport register, a warning message is logged.\n\nCloses-Bug: #1842937\n\nChange-Id: I93f35eade6aa081160902d9d47278123815c04d1\n'}]",7,680413,c952b5960001faf98186b630fde75deafe5a7b8f,83,10,9,16688,,,0,"Handle ports assigned to routers without routerports

In the case of having a port attached to a router but the routerport
register is missing (as seen in the bug reported), this patch retrieves
the full list of ports attached to a router, filtering by router ID
and network ID or port ID. In case of having a port attached to this
router with missing routerport register, a warning message is logged.

Closes-Bug: #1842937

Change-Id: I93f35eade6aa081160902d9d47278123815c04d1
",git fetch https://review.opendev.org/openstack/neutron refs/changes/13/680413/2 && git format-patch -1 --stdout FETCH_HEAD,"['neutron/db/l3_db.py', 'neutron/objects/ports.py', 'neutron/tests/unit/db/test_l3_db.py']",3,27eeb5693517614ba629db4d9a247e02505fc2d3,bug/1842937,"# class TestL3_NAT_dbonly_mixin(base.BaseTestCase): # def setUp(self): # super(TestL3_NAT_dbonly_mixin, self).setUp() # self.db = l3_db.L3_NAT_dbonly_mixin() # # def test__each_port_having_fixed_ips_none(self): # """"""Be sure the method returns an empty list when None is passed"""""" # filtered = l3_db.L3_NAT_dbonly_mixin._each_port_having_fixed_ips(None) # self.assertEqual([], list(filtered)) # # def test__new__passes_args(self): # class T(l3_db.L3_NAT_db_mixin): # def __init__(self, *args, **kwargs): # self.args = args # self.kwargs = kwargs # # t = T(1, 2, a=3) # self.assertEqual((1, 2), t.args) # self.assertEqual({'a': 3}, t.kwargs) # # def test__each_port_having_fixed_ips(self): # """"""Basic test that ports without fixed ips are filtered out"""""" # ports = [{'id': 'a', 'fixed_ips': [mock.sentinel.fixedip]}, # {'id': 'b'}] # filtered = l3_db.L3_NAT_dbonly_mixin._each_port_having_fixed_ips(ports) # ids = [p['id'] for p in filtered] # self.assertEqual(['a'], ids) # # def test__get_subnets_by_network_no_query(self): # """"""Basic test that no query is performed if no Ports are passed"""""" # context = mock.Mock() # with mock.patch.object(directory, 'get_plugin') as get_p: # self.db._get_subnets_by_network_list(context, []) # self.assertFalse(context.session.query.called) # self.assertFalse(get_p.called) # # def test__get_subnets_by_network(self): # """"""Basic test that the right query is called"""""" # context = mock.MagicMock() # query = context.session.query().outerjoin().filter() # query.__iter__.return_value = [(mock.sentinel.subnet_db, # mock.sentinel.address_scope_id)] # # with mock.patch.object(directory, 'get_plugin') as get_p: # get_p()._make_subnet_dict.return_value = { # 'network_id': mock.sentinel.network_id} # subnets = self.db._get_subnets_by_network_list( # context, [mock.sentinel.network_id]) # self.assertEqual({ # mock.sentinel.network_id: [{ # 'address_scope_id': mock.sentinel.address_scope_id, # 'network_id': mock.sentinel.network_id}]}, subnets) # # def test__get_mtus_by_network_list(self): # """"""Basic test that the query get_networks is correctly"""""" # network = {'id': mock.sentinel.network_id, # 'name': mock.sentinel.name, # 'mtu': mock.sentinel.mtu} # with mock.patch.object(directory, 'get_plugin') as get_p: # get_p().get_networks.return_value = [network] # result = self.db._get_mtus_by_network_list( # mock.sentinel.context, [mock.sentinel.network_id]) # get_p().get_networks.assert_called_once_with( # mock.sentinel.context, # filters={'id': [mock.sentinel.network_id]}, # fields=['id', 'mtu']) # self.assertEqual({mock.sentinel.network_id: mock.sentinel.mtu}, # result) # # def test__populate_ports_for_subnets_none(self): # """"""Basic test that the method runs correctly with no ports"""""" # ports = [] # with mock.patch.object(directory, 'get_plugin') as get_p: # get_p().get_networks.return_value = [] # self.db._populate_mtu_and_subnets_for_ports(mock.sentinel.context, # ports) # self.assertEqual([], ports) # # @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, # '_get_subnets_by_network_list') # def test__populate_ports_for_subnets(self, get_subnets_by_network): # cidr = ""2001:db8::/64"" # subnet = {'id': mock.sentinel.subnet_id, # 'cidr': cidr, # 'gateway_ip': mock.sentinel.gateway_ip, # 'dns_nameservers': mock.sentinel.dns_nameservers, # 'ipv6_ra_mode': mock.sentinel.ipv6_ra_mode, # 'subnetpool_id': mock.sentinel.subnetpool_id, # 'address_scope_id': mock.sentinel.address_scope_id} # get_subnets_by_network.return_value = {'net_id': [subnet]} # # ports = [{'network_id': 'net_id', # 'id': 'port_id', # 'fixed_ips': [{'subnet_id': mock.sentinel.subnet_id}]}] # with mock.patch.object(directory, 'get_plugin') as get_p: # get_p().get_networks.return_value = [{'id': 'net_id', 'mtu': 1446}] # self.db._populate_mtu_and_subnets_for_ports(mock.sentinel.context, # ports) # keys = ('id', 'cidr', 'gateway_ip', 'ipv6_ra_mode', # 'subnetpool_id', 'dns_nameservers') # address_scopes = {4: None, 6: mock.sentinel.address_scope_id} # self.assertEqual([{'extra_subnets': [], # 'fixed_ips': [{'subnet_id': # mock.sentinel.subnet_id, # 'prefixlen': 64}], # 'id': 'port_id', # 'mtu': 1446, # 'network_id': 'net_id', # 'subnets': [{k: subnet[k] for k in keys}], # 'address_scopes': address_scopes}], ports) # # def test__get_sync_floating_ips_no_query(self): # """"""Basic test that no query is performed if no router ids are passed"""""" # db = l3_db.L3_NAT_dbonly_mixin() # context = mock.Mock() # db._get_sync_floating_ips(context, []) # self.assertFalse(context.session.query.called) # # @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_make_floatingip_dict') # def test__make_floatingip_dict_with_scope(self, make_fip_dict): # db = l3_db.L3_NAT_dbonly_mixin() # make_fip_dict.return_value = {'id': mock.sentinel.fip_ip} # result = db._make_floatingip_dict_with_scope( # mock.sentinel.floating_ip_db, mock.sentinel.address_scope_id) # self.assertEqual({ # 'fixed_ip_address_scope': mock.sentinel.address_scope_id, # 'id': mock.sentinel.fip_ip}, result) # # def test__unique_floatingip_iterator(self): # context = mock.MagicMock() # query = mock.MagicMock() # query.order_by().__iter__.return_value = [ # ({'id': 'id1'}, 'scope1'), # ({'id': 'id1'}, 'scope1'), # ({'id': 'id2'}, 'scope2'), # ({'id': 'id2'}, 'scope2'), # ({'id': 'id2'}, 'scope2'), # ({'id': 'id3'}, 'scope3')] # query.reset_mock() # with mock.patch.object( # l3_obj.FloatingIP, '_load_object', # side_effect=({'id': 'id1'}, {'id': 'id2'}, {'id': 'id3'})): # result = list( # l3_obj.FloatingIP._unique_floatingip_iterator(context, query)) # query.order_by.assert_called_once_with(l3_models.FloatingIP.id) # self.assertEqual([({'id': 'id1'}, 'scope1'), # ({'id': 'id2'}, 'scope2'), # ({'id': 'id3'}, 'scope3')], result) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_deletion_port_not_found(self, gp): # # port not found doesn't prevent # gp.return_value.get_port.side_effect = n_exc.PortNotFound(port_id='1') # self.db.prevent_l3_port_deletion(None, None) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_device_owner_not_router(self, gp): # # ignores other device owners # gp.return_value.get_port.return_value = {'device_owner': 'cat'} # self.db.prevent_l3_port_deletion(None, None) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_no_fixed_ips(self, gp): # # without fixed IPs is allowed # gp.return_value.get_port.return_value = { # 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, 'fixed_ips': [], # 'id': 'f' # } # self.db.prevent_l3_port_deletion(None, None) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_no_router(self, gp): # # without router is allowed # gp.return_value.get_port.return_value = { # 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, # 'device_id': '44', 'id': 'f', # 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} # self.db.get_router = mock.Mock() # self.db.get_router.side_effect = l3_exc.RouterNotFound(router_id='44') # self.db.prevent_l3_port_deletion(mock.Mock(), None) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_existing_router(self, gp): # gp.return_value.get_port.return_value = { # 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, # 'device_id': 'some_router', 'id': 'f', # 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} # self.db.get_router = mock.Mock() # with testtools.ExpectedException(n_exc.ServicePortInUse): # self.db.prevent_l3_port_deletion(mock.Mock(), None) # # @mock.patch.object(directory, 'get_plugin') # def test_prevent_l3_port_existing_floating_ip(self, gp): # ctx = context.get_admin_context() # gp.return_value.get_port.return_value = { # 'device_owner': n_const.DEVICE_OWNER_FLOATINGIP, # 'device_id': 'some_flip', 'id': 'f', # 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} # with mock.patch.object(l3_obj.FloatingIP, 'objects_exist', # return_value=mock.Mock()),\ # testtools.ExpectedException(n_exc.ServicePortInUse): # # self.db.prevent_l3_port_deletion(ctx, None) # # @mock.patch.object(directory, 'get_plugin') # def test_subscribe_address_scope_of_subnetpool(self, gp): # l3_db.L3RpcNotifierMixin() # registry.publish(resources.SUBNETPOOL_ADDRESS_SCOPE, # events.AFTER_UPDATE, mock.ANY, # payload=events.DBEventPayload( # mock.MagicMock(), resource_id='fake_id')) # self.assertTrue(gp.return_value.notify_routers_updated.called) # # def test__check_and_get_fip_assoc_with_extra_association_no_change(self): # fip = {'extra_key': 'value'} # context = mock.MagicMock() # floatingip_obj = l3_obj.FloatingIP( # context, # id=uuidutils.generate_uuid(), # floating_network_id=uuidutils.generate_uuid(), # floating_ip_address=netaddr.IPAddress('8.8.8.8'), # fixed_port_id=uuidutils.generate_uuid(), # floating_port_id=uuidutils.generate_uuid()) # with mock.patch.object( # l3_db.L3_NAT_dbonly_mixin, # '_get_assoc_data', # return_value=('1', '2', '3')) as mock_get_assoc_data: # self.db._check_and_get_fip_assoc(context, fip, floatingip_obj) # context.session.query.assert_not_called() # mock_get_assoc_data.assert_called_once_with( # mock.ANY, fip, floatingip_obj) # # def test__notify_attaching_interface(self): # with mock.patch.object(l3_db.registry, 'notify') as mock_notify: # context = mock.MagicMock() # router_id = 'router_id' # net_id = 'net_id' # router_db = mock.Mock() # router_db.id = router_id # port = {'network_id': net_id} # intf = {} # self.db._notify_attaching_interface(context, router_db, port, intf) # kwargs = {'context': context, 'router_id': router_id, # 'network_id': net_id, 'interface_info': intf, # 'router_db': router_db, 'port': port} # mock_notify.assert_called_once_with( # resources.ROUTER_INTERFACE, events.BEFORE_CREATE, self.db, # **kwargs) # # def test__create_gw_port(self): # router_id = '2afb8434-7380-43a2-913f-ba3a5ad5f349' # router = l3_models.Router(id=router_id) # new_network_id = 'net-id' # ext_ips = [{'subnet_id': 'subnet-id', 'ip_address': '1.1.1.1'}] # gw_port = {'fixed_ips': [{'subnet_id': 'subnet-id', # 'ip_address': '1.1.1.1'}], # 'id': '8742d007-6f05-4b7e-abdb-11818f608959'} # ctx = context.get_admin_context() # # with mock.patch.object(directory, 'get_plugin') as get_p, \ # mock.patch.object(get_p(), 'get_subnets_by_network', # return_value=mock.ANY), \ # mock.patch.object(get_p(), '_get_port', # return_value=gw_port), \ # mock.patch.object(l3_db.L3_NAT_dbonly_mixin, # '_check_for_dup_router_subnets') as cfdrs,\ # mock.patch.object(plugin_utils, 'create_port', # return_value=gw_port), \ # mock.patch.object(ctx.session, 'add'), \ # mock.patch.object(base_obj.NeutronDbObject, 'create'), \ # mock.patch.object(l3_db.registry, 'publish') as mock_notify: # # self.db._create_gw_port(ctx, router_id=router_id, # router=router, # new_network_id=new_network_id, # ext_ips=ext_ips) # # expected_gw_ips = ['1.1.1.1'] # # self.assertTrue(cfdrs.called) # mock_notify.assert_called_with( # resources.ROUTER_GATEWAY, events.AFTER_CREATE, # self.db._create_gw_port, payload=mock.ANY) # cb_payload = mock_notify.mock_calls[1][2]['payload'] # self.assertEqual(ctx, cb_payload.context) # self.assertEqual(expected_gw_ips, # cb_payload.metadata.get('gateway_ips')) # self.assertEqual(new_network_id, # cb_payload.metadata.get('network_id')) # self.assertEqual(router_id, cb_payload.resource_id) # # # class L3_NAT_db_mixin(base.BaseTestCase): # def setUp(self): # super(L3_NAT_db_mixin, self).setUp() # self.db = l3_db.L3_NAT_db_mixin() # # def _test_create_router(self, external_gateway_info=None): # router_db = l3_models.Router(id='123') # router_dict = {'id': '123', 'tenant_id': '456', # 'external_gateway_info': external_gateway_info} # # Need to use a copy here as the create_router method pops the gateway # # information # router_input = {'router': router_dict.copy()} # # with mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_create_router_db', # return_value=router_db) as crd,\ # mock.patch.object(l3_db.L3_NAT_dbonly_mixin, # '_make_router_dict', # return_value=router_dict),\ # mock.patch.object(l3_db.L3_NAT_dbonly_mixin, # '_update_router_gw_info') as urgi,\ # mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_get_router', # return_value=router_db),\ # mock.patch.object(l3_db.L3_NAT_db_mixin, # 'notify_router_updated') as nru: # # self.db.create_router(mock.Mock(), router_input) # self.assertTrue(crd.called) # if external_gateway_info: # self.assertTrue(urgi.called) # self.assertTrue(nru.called) # else: # self.assertFalse(urgi.called) # self.assertFalse(nru.called) # # def test_create_router_no_gateway(self): # self._test_create_router() # # def test_create_router_gateway(self): # ext_gateway_info = {'network_id': 'net-id', 'enable_snat': True, # 'external_fixed_ips': [ # {'subnet_id': 'subnet-id', # 'ip_address': 'ip'}]} # self._test_create_router(ext_gateway_info) # # def test_add_router_interface_no_interface_info(self): # router_db = l3_models.Router(id='123') # with mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_get_router', # return_value=router_db): # self.assertRaises( # n_exc.BadRequest, # self.db.add_router_interface, mock.Mock(), router_db.id) from neutron_lib.plugins import constants as plugin_constants from neutron.db import agents_db from neutron.db import l3_db from neutron.db import l3_dvr_db from neutron.db import l3_dvrscheduler_db from neutron.db.models import l3 as l3_models from neutron.db import models_v2 from neutron.objects import agent as agent_obj from neutron.objects import l3agent as rb_obj from neutron.objects import router as router_obj from neutron.tests.unit.db import test_db_base_plugin_v2 from neutron.tests.unit.extensions import test_l3 class FakeL3Plugin(l3_db.L3_NAT_dbonly_mixin): pass class L3TestCase(test_db_base_plugin_v2.NeutronDbPluginV2TestCase): def setUp(self, *args, **kwargs): super(L3TestCase, self).setUp(plugin='ml2') self.core_plugin = directory.get_plugin() self.ctx = context.get_admin_context() self.mixin = FakeL3Plugin() directory.add_plugin(plugin_constants.L3, self.mixin) #self.fmt = 'json' def _create_router(self, router): with self.ctx.session.begin(subtransactions=True): return self.mixin.create_router(self.ctx, router) def create_port(self, net_id, port_info): with self.ctx.session.begin(subtransactions=True): return self._make_port(self.fmt, net_id, **port_info) def test__create_router_db(self): router = {'router': {'name': 'foo_router', 'admin_state_up': True, 'tenant_id': 'foo_tenant'}} # if distributed is not None: # router['distributed'] = distributed with self.ctx.session.begin(subtransactions=True): kwargs = {} net = self._make_network(self.fmt , 'net1', True, **kwargs) subnet = self._make_subnet(self.fmt, net, '1.1.1.1', '1.1.1.0/24', **kwargs) router = self._create_router(router) fixed_ips = [{'subnet_id': subnet['subnet']['id'], 'ip_address': '1.1.1.10'}] port = self.create_port(net['network']['id'], {'fixed_ips': fixed_ips}) ##{'fixed_ips': fixed_ips}) #with self.ctx.session.begin(subtransactions=True) as ctx: # with mock.patch.object(self.mixin, '_check_router_port') as \ # mock_check_router_port: # mock_check_router_port.return_value = { # 'id': port['port']['id'], # 'device_owner': 'neutron', # 'fixed_ips': [], # 'network_id': net1['network']['id'], # 'tenant_id': port['port']['project_id']} ri = self.mixin.add_router_interface( self.ctx, router['id'], interface_info={'port_id': port['port']['id']}) # Check routerport_obj = router_obj.RouterPort.get_object( self.ctx, port_id=port['port']['id'], router_id=router['id']) _router_obj = router_obj.Router.get_object(self.ctx, id=router['id']) # Delete routerport #routerport_obj.delete() # remove by port interface_info = {'port_id': port['port']['id']} self.mixin.remove_router_interface(self.ctx, router['id'], interface_info) # Check _router_obj = router_obj.Router.get_object(self.ctx, id=router['id']) rport_obj = router_obj.RouterPort.get_object( self.ctx, port_id=port['port']['id'], router_id=router['id']) a=1 #self.assertEqual(expected, result.extra_attributes['distributed']) # def test_create_router_db_centralized(self): # self._test__create_router_db(expected=False, distributed=False) # a=1","class TestL3_NAT_dbonly_mixin(base.BaseTestCase): def setUp(self): super(TestL3_NAT_dbonly_mixin, self).setUp() self.db = l3_db.L3_NAT_dbonly_mixin() def test__each_port_having_fixed_ips_none(self): """"""Be sure the method returns an empty list when None is passed"""""" filtered = l3_db.L3_NAT_dbonly_mixin._each_port_having_fixed_ips(None) self.assertEqual([], list(filtered)) def test__new__passes_args(self): class T(l3_db.L3_NAT_db_mixin): def __init__(self, *args, **kwargs): self.args = args self.kwargs = kwargs t = T(1, 2, a=3) self.assertEqual((1, 2), t.args) self.assertEqual({'a': 3}, t.kwargs) def test__each_port_having_fixed_ips(self): """"""Basic test that ports without fixed ips are filtered out"""""" ports = [{'id': 'a', 'fixed_ips': [mock.sentinel.fixedip]}, {'id': 'b'}] filtered = l3_db.L3_NAT_dbonly_mixin._each_port_having_fixed_ips(ports) ids = [p['id'] for p in filtered] self.assertEqual(['a'], ids) def test__get_subnets_by_network_no_query(self): """"""Basic test that no query is performed if no Ports are passed"""""" context = mock.Mock() with mock.patch.object(directory, 'get_plugin') as get_p: self.db._get_subnets_by_network_list(context, []) self.assertFalse(context.session.query.called) self.assertFalse(get_p.called) def test__get_subnets_by_network(self): """"""Basic test that the right query is called"""""" context = mock.MagicMock() query = context.session.query().outerjoin().filter() query.__iter__.return_value = [(mock.sentinel.subnet_db, mock.sentinel.address_scope_id)] with mock.patch.object(directory, 'get_plugin') as get_p: get_p()._make_subnet_dict.return_value = { 'network_id': mock.sentinel.network_id} subnets = self.db._get_subnets_by_network_list( context, [mock.sentinel.network_id]) self.assertEqual({ mock.sentinel.network_id: [{ 'address_scope_id': mock.sentinel.address_scope_id, 'network_id': mock.sentinel.network_id}]}, subnets) def test__get_mtus_by_network_list(self): """"""Basic test that the query get_networks is correctly"""""" network = {'id': mock.sentinel.network_id, 'name': mock.sentinel.name, 'mtu': mock.sentinel.mtu} with mock.patch.object(directory, 'get_plugin') as get_p: get_p().get_networks.return_value = [network] result = self.db._get_mtus_by_network_list( mock.sentinel.context, [mock.sentinel.network_id]) get_p().get_networks.assert_called_once_with( mock.sentinel.context, filters={'id': [mock.sentinel.network_id]}, fields=['id', 'mtu']) self.assertEqual({mock.sentinel.network_id: mock.sentinel.mtu}, result) def test__populate_ports_for_subnets_none(self): """"""Basic test that the method runs correctly with no ports"""""" ports = [] with mock.patch.object(directory, 'get_plugin') as get_p: get_p().get_networks.return_value = [] self.db._populate_mtu_and_subnets_for_ports(mock.sentinel.context, ports) self.assertEqual([], ports) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_get_subnets_by_network_list') def test__populate_ports_for_subnets(self, get_subnets_by_network): cidr = ""2001:db8::/64"" subnet = {'id': mock.sentinel.subnet_id, 'cidr': cidr, 'gateway_ip': mock.sentinel.gateway_ip, 'dns_nameservers': mock.sentinel.dns_nameservers, 'ipv6_ra_mode': mock.sentinel.ipv6_ra_mode, 'subnetpool_id': mock.sentinel.subnetpool_id, 'address_scope_id': mock.sentinel.address_scope_id} get_subnets_by_network.return_value = {'net_id': [subnet]} ports = [{'network_id': 'net_id', 'id': 'port_id', 'fixed_ips': [{'subnet_id': mock.sentinel.subnet_id}]}] with mock.patch.object(directory, 'get_plugin') as get_p: get_p().get_networks.return_value = [{'id': 'net_id', 'mtu': 1446}] self.db._populate_mtu_and_subnets_for_ports(mock.sentinel.context, ports) keys = ('id', 'cidr', 'gateway_ip', 'ipv6_ra_mode', 'subnetpool_id', 'dns_nameservers') address_scopes = {4: None, 6: mock.sentinel.address_scope_id} self.assertEqual([{'extra_subnets': [], 'fixed_ips': [{'subnet_id': mock.sentinel.subnet_id, 'prefixlen': 64}], 'id': 'port_id', 'mtu': 1446, 'network_id': 'net_id', 'subnets': [{k: subnet[k] for k in keys}], 'address_scopes': address_scopes}], ports) def test__get_sync_floating_ips_no_query(self): """"""Basic test that no query is performed if no router ids are passed"""""" db = l3_db.L3_NAT_dbonly_mixin() context = mock.Mock() db._get_sync_floating_ips(context, []) self.assertFalse(context.session.query.called) @mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_make_floatingip_dict') def test__make_floatingip_dict_with_scope(self, make_fip_dict): db = l3_db.L3_NAT_dbonly_mixin() make_fip_dict.return_value = {'id': mock.sentinel.fip_ip} result = db._make_floatingip_dict_with_scope( mock.sentinel.floating_ip_db, mock.sentinel.address_scope_id) self.assertEqual({ 'fixed_ip_address_scope': mock.sentinel.address_scope_id, 'id': mock.sentinel.fip_ip}, result) def test__unique_floatingip_iterator(self): context = mock.MagicMock() query = mock.MagicMock() query.order_by().__iter__.return_value = [ ({'id': 'id1'}, 'scope1'), ({'id': 'id1'}, 'scope1'), ({'id': 'id2'}, 'scope2'), ({'id': 'id2'}, 'scope2'), ({'id': 'id2'}, 'scope2'), ({'id': 'id3'}, 'scope3')] query.reset_mock() with mock.patch.object( l3_obj.FloatingIP, '_load_object', side_effect=({'id': 'id1'}, {'id': 'id2'}, {'id': 'id3'})): result = list( l3_obj.FloatingIP._unique_floatingip_iterator(context, query)) query.order_by.assert_called_once_with(l3_models.FloatingIP.id) self.assertEqual([({'id': 'id1'}, 'scope1'), ({'id': 'id2'}, 'scope2'), ({'id': 'id3'}, 'scope3')], result) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_deletion_port_not_found(self, gp): # port not found doesn't prevent gp.return_value.get_port.side_effect = n_exc.PortNotFound(port_id='1') self.db.prevent_l3_port_deletion(None, None) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_device_owner_not_router(self, gp): # ignores other device owners gp.return_value.get_port.return_value = {'device_owner': 'cat'} self.db.prevent_l3_port_deletion(None, None) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_no_fixed_ips(self, gp): # without fixed IPs is allowed gp.return_value.get_port.return_value = { 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, 'fixed_ips': [], 'id': 'f' } self.db.prevent_l3_port_deletion(None, None) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_no_router(self, gp): # without router is allowed gp.return_value.get_port.return_value = { 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, 'device_id': '44', 'id': 'f', 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} self.db.get_router = mock.Mock() self.db.get_router.side_effect = l3_exc.RouterNotFound(router_id='44') self.db.prevent_l3_port_deletion(mock.Mock(), None) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_existing_router(self, gp): gp.return_value.get_port.return_value = { 'device_owner': n_const.DEVICE_OWNER_ROUTER_INTF, 'device_id': 'some_router', 'id': 'f', 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} self.db.get_router = mock.Mock() with testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(mock.Mock(), None) @mock.patch.object(directory, 'get_plugin') def test_prevent_l3_port_existing_floating_ip(self, gp): ctx = context.get_admin_context() gp.return_value.get_port.return_value = { 'device_owner': n_const.DEVICE_OWNER_FLOATINGIP, 'device_id': 'some_flip', 'id': 'f', 'fixed_ips': [{'ip_address': '1.1.1.1', 'subnet_id': '4'}]} with mock.patch.object(l3_obj.FloatingIP, 'objects_exist', return_value=mock.Mock()),\ testtools.ExpectedException(n_exc.ServicePortInUse): self.db.prevent_l3_port_deletion(ctx, None) @mock.patch.object(directory, 'get_plugin') def test_subscribe_address_scope_of_subnetpool(self, gp): l3_db.L3RpcNotifierMixin() registry.publish(resources.SUBNETPOOL_ADDRESS_SCOPE, events.AFTER_UPDATE, mock.ANY, payload=events.DBEventPayload( mock.MagicMock(), resource_id='fake_id')) self.assertTrue(gp.return_value.notify_routers_updated.called) def test__check_and_get_fip_assoc_with_extra_association_no_change(self): fip = {'extra_key': 'value'} context = mock.MagicMock() floatingip_obj = l3_obj.FloatingIP( context, id=uuidutils.generate_uuid(), floating_network_id=uuidutils.generate_uuid(), floating_ip_address=netaddr.IPAddress('8.8.8.8'), fixed_port_id=uuidutils.generate_uuid(), floating_port_id=uuidutils.generate_uuid()) with mock.patch.object( l3_db.L3_NAT_dbonly_mixin, '_get_assoc_data', return_value=('1', '2', '3')) as mock_get_assoc_data: self.db._check_and_get_fip_assoc(context, fip, floatingip_obj) context.session.query.assert_not_called() mock_get_assoc_data.assert_called_once_with( mock.ANY, fip, floatingip_obj) def test__notify_attaching_interface(self): with mock.patch.object(l3_db.registry, 'notify') as mock_notify: context = mock.MagicMock() router_id = 'router_id' net_id = 'net_id' router_db = mock.Mock() router_db.id = router_id port = {'network_id': net_id} intf = {} self.db._notify_attaching_interface(context, router_db, port, intf) kwargs = {'context': context, 'router_id': router_id, 'network_id': net_id, 'interface_info': intf, 'router_db': router_db, 'port': port} mock_notify.assert_called_once_with( resources.ROUTER_INTERFACE, events.BEFORE_CREATE, self.db, **kwargs) def test__create_gw_port(self): router_id = '2afb8434-7380-43a2-913f-ba3a5ad5f349' router = l3_models.Router(id=router_id) new_network_id = 'net-id' ext_ips = [{'subnet_id': 'subnet-id', 'ip_address': '1.1.1.1'}] gw_port = {'fixed_ips': [{'subnet_id': 'subnet-id', 'ip_address': '1.1.1.1'}], 'id': '8742d007-6f05-4b7e-abdb-11818f608959'} ctx = context.get_admin_context() with mock.patch.object(directory, 'get_plugin') as get_p, \ mock.patch.object(get_p(), 'get_subnets_by_network', return_value=mock.ANY), \ mock.patch.object(get_p(), '_get_port', return_value=gw_port), \ mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_check_for_dup_router_subnets') as cfdrs,\ mock.patch.object(plugin_utils, 'create_port', return_value=gw_port), \ mock.patch.object(ctx.session, 'add'), \ mock.patch.object(base_obj.NeutronDbObject, 'create'), \ mock.patch.object(l3_db.registry, 'publish') as mock_notify: self.db._create_gw_port(ctx, router_id=router_id, router=router, new_network_id=new_network_id, ext_ips=ext_ips) expected_gw_ips = ['1.1.1.1'] self.assertTrue(cfdrs.called) mock_notify.assert_called_with( resources.ROUTER_GATEWAY, events.AFTER_CREATE, self.db._create_gw_port, payload=mock.ANY) cb_payload = mock_notify.mock_calls[1][2]['payload'] self.assertEqual(ctx, cb_payload.context) self.assertEqual(expected_gw_ips, cb_payload.metadata.get('gateway_ips')) self.assertEqual(new_network_id, cb_payload.metadata.get('network_id')) self.assertEqual(router_id, cb_payload.resource_id) class L3_NAT_db_mixin(base.BaseTestCase): def setUp(self): super(L3_NAT_db_mixin, self).setUp() self.db = l3_db.L3_NAT_db_mixin() def _test_create_router(self, external_gateway_info=None): router_db = l3_models.Router(id='123') router_dict = {'id': '123', 'tenant_id': '456', 'external_gateway_info': external_gateway_info} # Need to use a copy here as the create_router method pops the gateway # information router_input = {'router': router_dict.copy()} with mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_create_router_db', return_value=router_db) as crd,\ mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_make_router_dict', return_value=router_dict),\ mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_update_router_gw_info') as urgi,\ mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_get_router', return_value=router_db),\ mock.patch.object(l3_db.L3_NAT_db_mixin, 'notify_router_updated') as nru: self.db.create_router(mock.Mock(), router_input) self.assertTrue(crd.called) if external_gateway_info: self.assertTrue(urgi.called) self.assertTrue(nru.called) else: self.assertFalse(urgi.called) self.assertFalse(nru.called) def test_create_router_no_gateway(self): self._test_create_router() def test_create_router_gateway(self): ext_gateway_info = {'network_id': 'net-id', 'enable_snat': True, 'external_fixed_ips': [ {'subnet_id': 'subnet-id', 'ip_address': 'ip'}]} self._test_create_router(ext_gateway_info) def test_add_router_interface_no_interface_info(self): router_db = l3_models.Router(id='123') with mock.patch.object(l3_db.L3_NAT_dbonly_mixin, '_get_router', return_value=router_db): self.assertRaises( n_exc.BadRequest, self.db.add_router_interface, mock.Mock(), router_db.id)",520,381
openstack%2Fcinder~master~I9499fcefd236e1fa0c7c980d3e40265a9a118bb3,openstack/cinder,master,I9499fcefd236e1fa0c7c980d3e40265a9a118bb3,Fix issue of getting detail backups list info,MERGED,2019-07-26 06:51:45.000000000,2019-10-15 08:48:26.000000000,2019-10-15 08:46:49.000000000,"[{'_account_id': 1736}, {'_account_id': 4523}, {'_account_id': 7198}, {'_account_id': 9008}, {'_account_id': 10118}, {'_account_id': 11904}, {'_account_id': 12016}, {'_account_id': 12017}, {'_account_id': 12033}, {'_account_id': 12369}, {'_account_id': 13144}, {'_account_id': 14384}, {'_account_id': 15386}, {'_account_id': 15941}, {'_account_id': 16897}, {'_account_id': 18120}, {'_account_id': 19933}, {'_account_id': 20284}, {'_account_id': 21863}, {'_account_id': 21884}, {'_account_id': 21976}, {'_account_id': 22126}, {'_account_id': 22248}, {'_account_id': 22348}, {'_account_id': 23613}, {'_account_id': 24814}, {'_account_id': 24815}, {'_account_id': 24921}, {'_account_id': 25243}, {'_account_id': 25678}, {'_account_id': 26077}, {'_account_id': 26537}, {'_account_id': 27615}, {'_account_id': 27781}, {'_account_id': 28706}, {'_account_id': 28801}, {'_account_id': 29716}]","[{'number': 1, 'created': '2019-07-26 06:51:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/d1affdaf44b43ed05f3a2bdf50bff94a0a0c317e', 'message': 'Fix issue of getting detail backups list info\n\nosapi_max_limit: The maximum number of items that a collection\nresource returns in a single response.\nIf we have more than osapi_max_limit and want to list detail\nbackups info, we will generate the next link, we must set detail\nfor the url.\n\nChange-Id: I9499fcefd236e1fa0c7c980d3e40265a9a118bb3\nClose-Bug: 1837967\n'}, {'number': 2, 'created': '2019-08-02 03:01:50.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cinder/commit/8781ccae7334a98241a6e22a46eebc10be754596', 'message': 'Fix issue of getting detail backups list info\n\nosapi_max_limit: The maximum number of items that a collection\nresource returns in a single response.\nIf we have more than osapi_max_limit and want to list detail\nbackups info, we will generate the next link, we must set detail\nfor the url.\n\nChange-Id: I9499fcefd236e1fa0c7c980d3e40265a9a118bb3\nClose-Bug: 1837967\n'}, {'number': 3, 'created': '2019-08-02 03:19:01.000000000', 'files': ['cinder/tests/unit/api/contrib/test_backups.py', 'cinder/api/views/backups.py'], 'web_link': 'https://opendev.org/openstack/cinder/commit/63aebb5dea06acbd54814287da70eabc4c7f065b', 'message': 'Fix issue of getting detail backups list info\n\nosapi_max_limit: The maximum number of items that a collection\nresource returns in a single response.\nIf we have more than osapi_max_limit and want to list detail\nbackups info, we will generate the next link, we must set detail\nfor the url.\n\nChange-Id: I9499fcefd236e1fa0c7c980d3e40265a9a118bb3\nClose-Bug: 1837967\n'}]",3,672887,63aebb5dea06acbd54814287da70eabc4c7f065b,69,37,3,28706,,,0,"Fix issue of getting detail backups list info

osapi_max_limit: The maximum number of items that a collection
resource returns in a single response.
If we have more than osapi_max_limit and want to list detail
backups info, we will generate the next link, we must set detail
for the url.

Change-Id: I9499fcefd236e1fa0c7c980d3e40265a9a118bb3
Close-Bug: 1837967
",git fetch https://review.opendev.org/openstack/cinder refs/changes/87/672887/2 && git format-patch -1 --stdout FETCH_HEAD,['cinder/api/views/backups.py'],1,d1affdaf44b43ed05f3a2bdf50bff94a0a0c317e,bug/1837967," return self._list_view(self.detail, request, backups, backup_count, self._collection_name + '/detail') def _list_view(self, func, request, backups, backup_count, coll_name=_collection_name): coll_name,"," return self._list_view(self.detail, request, backups, backup_count) def _list_view(self, func, request, backups, backup_count): self._collection_name,",5,3
openstack%2Ftempest~master~I804c490d459c3cccfafac96c95312b9ea12bf262,openstack/tempest,master,I804c490d459c3cccfafac96c95312b9ea12bf262,Modify the fake date,MERGED,2019-09-18 07:28:21.000000000,2019-10-15 08:48:08.000000000,2019-10-15 08:46:54.000000000,"[{'_account_id': 5689}, {'_account_id': 22348}, {'_account_id': 23186}]","[{'number': 1, 'created': '2019-09-18 07:28:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tempest/commit/8fefed67852031db4c22a5f90314b8acfcbfaa2f', 'message': 'Modify the fake date\n\nModify the fake date according to the API document described\n\nChange-Id: I804c490d459c3cccfafac96c95312b9ea12bf262\n'}, {'number': 2, 'created': '2019-10-10 01:33:54.000000000', 'files': ['tempest/tests/lib/services/volume/v3/test_volumes_client.py'], 'web_link': 'https://opendev.org/openstack/tempest/commit/1d1133557d59dbdaaa34d40f1365d644ab40d3b3', 'message': 'Modify the fake date\n\nModify the fake date according to the API document described\n\nChange-Id: I804c490d459c3cccfafac96c95312b9ea12bf262\n'}]",2,682811,1d1133557d59dbdaaa34d40f1365d644ab40d3b3,10,3,2,30643,,,0,"Modify the fake date

Modify the fake date according to the API document described

Change-Id: I804c490d459c3cccfafac96c95312b9ea12bf262
",git fetch https://review.opendev.org/openstack/tempest refs/changes/11/682811/1 && git format-patch -1 --stdout FETCH_HEAD,['tempest/tests/lib/services/volume/v3/test_volumes_client.py'],1,8fefed67852031db4c22a5f90314b8acfcbfaa2f,branch," ""total_size"": 4, ""total_count"": 4, ""metadata"": { ""key1"": [""value1"", ""value2""], ""key2"": [""value2""] } ""name"": ""metadata1"" ""key1"": ""value1"", ""key2"": ""value2"""," ""total_size"": 20, ""total_count"": 5 ""key1"": ""value1"" ""container_format"": ""bare"", ""min_ram"": ""0"", ""disk_format"": ""raw"", ""image_name"": ""xly-ubuntu16-server"", ""image_id"": ""3e087b0c-10c5-4255-b147-6e8e9dbad6fc"", ""checksum"": ""008f5d22fe3cb825d714da79607a90f9"", ""min_disk"": ""0"", ""size"": ""8589934592""",9,11
openstack%2Fopenstack-helm~master~Ib94b7ea15466b91799cac3879628e1c76ffbf5a7,openstack/openstack-helm,master,Ib94b7ea15466b91799cac3879628e1c76ffbf5a7,Adding troubleshooting guide for OVS with DPDK,ABANDONED,2019-07-03 12:35:36.000000000,2019-10-15 08:45:57.000000000,,"[{'_account_id': 8749}, {'_account_id': 12281}, {'_account_id': 16353}, {'_account_id': 17068}, {'_account_id': 17966}, {'_account_id': 21883}, {'_account_id': 22348}, {'_account_id': 23928}, {'_account_id': 26297}, {'_account_id': 28743}, {'_account_id': 29668}, {'_account_id': 30220}, {'_account_id': 30232}, {'_account_id': 30356}]","[{'number': 1, 'created': '2019-07-03 12:35:36.000000000', 'files': ['doc/source/troubleshooting/index.rst', 'doc/source/troubleshooting/dpdk.rst'], 'web_link': 'https://opendev.org/openstack/openstack-helm/commit/948ccb13c9d3f01c97dc1ac222711fac3aa59f3b', 'message': 'Adding troubleshooting guide for OVS with DPDK\n\nAdding a troubeshooting guide for OVS with DPDK to the documentation.\n\nChange-Id: Ib94b7ea15466b91799cac3879628e1c76ffbf5a7\n'}]",2,668893,948ccb13c9d3f01c97dc1ac222711fac3aa59f3b,13,14,1,16353,,,0,"Adding troubleshooting guide for OVS with DPDK

Adding a troubeshooting guide for OVS with DPDK to the documentation.

Change-Id: Ib94b7ea15466b91799cac3879628e1c76ffbf5a7
",git fetch https://review.opendev.org/openstack/openstack-helm refs/changes/93/668893/1 && git format-patch -1 --stdout FETCH_HEAD,"['doc/source/troubleshooting/index.rst', 'doc/source/troubleshooting/dpdk.rst']",2,948ccb13c9d3f01c97dc1ac222711fac3aa59f3b,dpdk-doc,"==== DPDK ==== A correct DPDK configuration depends heavily on the specific hardware resources and its configuration. This section provides troubleshooting information for common configuration issues. Hugepage configuration of host OS --------------------------------- Before deploying Openvswitch with DPDK, check the amount and type of available hugepages on the host OS. .. code-block:: shell cat /proc/meminfo | grep Huge AnonHugePages: 0 kB ShmemHugePages: 0 kB HugePages_Total: 8 HugePages_Free: 6 HugePages_Rsvd: 0 HugePages_Surp: 0 Hugepagesize: 1048576 kB In this example, 8 hugepages of 1G size have been allocated. 2 of those are being used and 6 are still available. More information on how to allocate and configure hugepages on the host OS can be found in the `Openvswitch documentation <http://docs.openvswitch.org/en/latest/intro/install/dpdk/>`_. Enable hugepages in OVS chart ----------------------------- Kubernetes handles hugepages as separate resources of a pod. More information on hugepages can be found in the `Kubernetes documentation <https://kubernetes.io/docs/tasks/manage-hugepages/scheduling-hugepages/>`_. In order to allow OVS inside a pod to make use of hugepages, the corresponding type and amount of hugepages must be specified in the resource section of the OVS chart's values.yaml: .. code-block:: yaml resources: enabled: false ovs: db: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" vswitchd: requests: memory: ""128Mi"" cpu: ""100m"" limits: memory: ""1024Mi"" cpu: ""2000m"" # set resources to enabled and specify one of the following when using dpdk hugepages-1Gi: ""1Gi"" # hugepages-2Mi: ""512Mi"" If OVS fails to start up because of no hugepages are available, check the configuration of the OVS daemonset. Older versions of helm-toolkit were not able to render hugepage configuration into the Kubernetes manifest and just removed the hugepage attributes. If no hugepage configuration is defined for the OVS daemonset, consider using a newer version of helm-toolkit. .. code-block:: shell kubectl get daemonset openvswitch-vswitchd -n openstack -o yaml [...] resources: limits: cpu: ""2"" hugepages-1Gi: 1Gi memory: 1Gi requests: cpu: 100m memory: 128Mi [...] Adding a DPDK port to Openvswitch fails --------------------------------------- When adding a DPDK port (a NIC bound to DPDK) to OVS fails, one source of error is related to an incorrect configuration with regards to the NUMA topology of the underlying hardware. Every NIC is connected to one specific NUMA socket. In order to use a NIC as DPDK port in OVS, the OVS configuration regarding hugepages and PMD threas needs to match the NUMA topology. The NUMA socket a given NIC is connected to can be found in the ovs-vswitchd log: .. code-block:: kubectl logs -n openstack openvswitch-vswitchd-6h928 [...] 2019-07-02T13:42:06Z|00016|dpdk|INFO|EAL: PCI device 0000:00:04.0 on NUMA socket 1 2019-07-02T13:42:06Z|00018|dpdk|INFO|EAL: probe driver: 1af4:1000 net_virtio [...] In this example, the NIC with PCI-ID 0000:00:04.0 is connected to NUMA socket 1. As a result, this NIC can only be used by OVS if 1. hugepages have been allocated on NUMA socket 1 by OVS, and 2. PMD threads have been assigned to NUMA socket 1. To allocate hugepages to NUMA sockets in OVS, ensure that the ``socket_memory`` attribute in values.yaml specifies a value for the corresponding NUMA socket. In the following example, OVS will use one 1G hugepage for NUMA socket 0 and socket 1. .. code-block:: socket_memory: 1024,1024 To allocate PMD threads to NUMA sockets in OVS, ensure that the ``pmd_cpu_mask`` attribute in values.yaml includes CPU sockets on the corresponding NUMA socket. In the example below, the mask of 0xf covers the first 4 CPU cores which are dsitributed across NUMA sockets 0 and 1. .. code-block:: pmd_cpu_mask: 0xf The mapping of CPU cores to NUMA sockets can be determined by means of ``lspci``, for instance: .. code-block:: shell lspci | grep NUMA NUMA node(s): 2 NUMA node0 CPU(s): 0,2,4,6,8,10,12,14 NUMA node1 CPU(s): 1,3,5,7,9,11,13,15 More information can be found in the `Openvswitch documentation <http://docs.openvswitch.org/en/latest/intro/install/dpdk/>`_. ",,145,0
openstack%2Fneutron-tempest-plugin~master~I46941743adde455a2fd16bddafc70d2c4cb07815,openstack/neutron-tempest-plugin,master,I46941743adde455a2fd16bddafc70d2c4cb07815,DNM: Test queens jobs on bionic,ABANDONED,2019-09-16 11:35:23.000000000,2019-10-15 08:39:11.000000000,,[{'_account_id': 22348}],"[{'number': 1, 'created': '2019-09-16 11:35:23.000000000', 'files': ['.zuul.yaml'], 'web_link': 'https://opendev.org/openstack/neutron-tempest-plugin/commit/91fa4d22174a898913b624c0cb118e4c7adc4a7b', 'message': 'DNM: Test queens jobs on bionic\n\nChange-Id: I46941743adde455a2fd16bddafc70d2c4cb07815\n'}]",0,682345,91fa4d22174a898913b624c0cb118e4c7adc4a7b,3,1,1,13252,,,0,"DNM: Test queens jobs on bionic

Change-Id: I46941743adde455a2fd16bddafc70d2c4cb07815
",git fetch https://review.opendev.org/openstack/neutron-tempest-plugin refs/changes/45/682345/1 && git format-patch -1 --stdout FETCH_HEAD,['.zuul.yaml'],1,91fa4d22174a898913b624c0cb118e4c7adc4a7b,test-bionic, nodeset: openstack-two-node-bionic nodeset: openstack-single-node-bionic # - build-openstack-docs-pti # - neutron-tempest-plugin-jobs # - neutron-tempest-plugin-jobs-rocky # - neutron-tempest-plugin-jobs-stein # - check-requirements # - tempest-plugin-jobs # - release-notes-jobs-python3 # check: # jobs: # - neutron-tempest-plugin-sfc # - neutron-tempest-plugin-bgpvpn-bagpipe # - neutron-tempest-plugin-fwaas, nodeset: openstack-single-node-xenial nodeset: openstack-single-node-xenial nodeset: openstack-single-node-xenial nodeset: openstack-two-node-xenial nodeset: openstack-single-node-xenial - build-openstack-docs-pti - neutron-tempest-plugin-jobs - neutron-tempest-plugin-jobs-rocky - neutron-tempest-plugin-jobs-stein - check-requirements - tempest-plugin-jobs - release-notes-jobs-python3 check: jobs: - neutron-tempest-plugin-sfc - neutron-tempest-plugin-bgpvpn-bagpipe - neutron-tempest-plugin-fwaas,14,17
openstack%2Fbifrost~stable%2Focata~I55a1d9db940cf5fa2c35421db7add015ae334563,openstack/bifrost,stable/ocata,I55a1d9db940cf5fa2c35421db7add015ae334563,Update links for opendev,MERGED,2019-10-14 20:24:45.000000000,2019-10-15 08:39:09.000000000,2019-10-15 08:38:06.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:24:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/41028c96a299827a458636c3b93d4231a537e745', 'message': 'Update links for opendev\n\nThe most important bits are updating shade references to remove\nthe openstack-infra. The other git urls will work through the\nredirect, but cleaning them up is just nicer.\n\nThis removes two comments that reference files that no longer\nexist due to config generation.\n\nAlso, fix some random use of github for cloning openstack repos,\nsince the github mirror is best-effort only.\n\nConflicts:\n\tREADME.rst\n\tdoc/source/user/troubleshooting.rst\n\tplaybooks/roles/bifrost-create-dib-image/README.md\n\tplaybooks/roles/bifrost-ironic-install/defaults/main.yml\n\tplaybooks/roles/bifrost-prep-for-install/README.md\n\tplaybooks/roles/bifrost-prep-for-install/defaults/main.yml\n\tplaybooks/test-bifrost.yaml\n\treleasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml\n\ttox.ini\n\nChange-Id: I55a1d9db940cf5fa2c35421db7add015ae334563\nNeeded-By: https://review.opendev.org/654056\n(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)\n'}, {'number': 2, 'created': '2019-10-14 21:32:22.000000000', 'files': ['playbooks/roles/bifrost-prep-for-install/README.md', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'README.vagrant.rst', 'playbooks/roles/ironic-enroll-dynamic/README.md', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'CONTRIBUTING.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic.conf.j2', 'releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml', 'troubleshooting.rst', 'tox.ini', 'playbooks/roles/bifrost-create-dib-image/README.md', 'playbooks/roles/bifrost-keystone-install/defaults/main.yml', 'playbooks/roles/bifrost-openstack-ci-prep/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e112521d048248ad07c950bc13292df240189f89', 'message': 'Update links for opendev\n\nThe most important bits are updating shade references to remove\nthe openstack-infra. The other git urls will work through the\nredirect, but cleaning them up is just nicer.\n\nThis removes two comments that reference files that no longer\nexist due to config generation.\n\nAlso, fix some random use of github for cloning openstack repos,\nsince the github mirror is best-effort only.\n\nConflicts:\n\tREADME.rst\n\tdoc/source/user/troubleshooting.rst\n\tplaybooks/roles/bifrost-create-dib-image/README.md\n\tplaybooks/roles/bifrost-ironic-install/defaults/main.yml\n\tplaybooks/roles/bifrost-prep-for-install/README.md\n\tplaybooks/roles/bifrost-prep-for-install/defaults/main.yml\n\tplaybooks/test-bifrost.yaml\n\treleasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml\n\ttox.ini\n\nChange-Id: I55a1d9db940cf5fa2c35421db7add015ae334563\nNeeded-By: https://review.opendev.org/654056\n(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)\n'}]",1,688556,e112521d048248ad07c950bc13292df240189f89,9,3,2,11655,,,0,"Update links for opendev

The most important bits are updating shade references to remove
the openstack-infra. The other git urls will work through the
redirect, but cleaning them up is just nicer.

This removes two comments that reference files that no longer
exist due to config generation.

Also, fix some random use of github for cloning openstack repos,
since the github mirror is best-effort only.

Conflicts:
	README.rst
	doc/source/user/troubleshooting.rst
	playbooks/roles/bifrost-create-dib-image/README.md
	playbooks/roles/bifrost-ironic-install/defaults/main.yml
	playbooks/roles/bifrost-prep-for-install/README.md
	playbooks/roles/bifrost-prep-for-install/defaults/main.yml
	playbooks/test-bifrost.yaml
	releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml
	tox.ini

Change-Id: I55a1d9db940cf5fa2c35421db7add015ae334563
Needed-By: https://review.opendev.org/654056
(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/56/688556/2 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-prep-for-install/README.md', 'doc/source/install/index.rst', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'README.vagrant.rst', 'doc/source/user/howto.rst', 'playbooks/roles/ironic-enroll-dynamic/README.md', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'CONTRIBUTING.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic.conf.j2', 'releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml', 'troubleshooting.rst', 'tox.ini', 'playbooks/roles/bifrost-create-dib-image/README.md', 'playbooks/roles/bifrost-keystone-install/defaults/main.yml', 'playbooks/roles/bifrost-openstack-ci-prep/README.md']",17,41028c96a299827a458636c3b93d4231a537e745,, shade_git_url: /opt/git/openstack/shade, shade_git_url: /opt/git/openstack-infra/shade,644,43
openstack%2Fbifrost~stable%2Fpike~I55a1d9db940cf5fa2c35421db7add015ae334563,openstack/bifrost,stable/pike,I55a1d9db940cf5fa2c35421db7add015ae334563,Update links for opendev,MERGED,2019-10-14 20:20:43.000000000,2019-10-15 08:39:09.000000000,2019-10-15 08:38:05.000000000,"[{'_account_id': 2}, {'_account_id': 10239}, {'_account_id': 22348}]","[{'number': 1, 'created': '2019-10-14 20:20:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/bifrost/commit/cf2c4a8c8029e8d9be4530012cca4287239b926a', 'message': 'Update links for opendev\n\nThe most important bits are updating shade references to remove\nthe openstack-infra. The other git urls will work through the\nredirect, but cleaning them up is just nicer.\n\nThis removes two comments that reference files that no longer\nexist due to config generation.\n\nAlso, fix some random use of github for cloning openstack repos,\nsince the github mirror is best-effort only.\n\nConflicts:\n\tREADME.rst\n\tdoc/source/user/troubleshooting.rst\n\tplaybooks/roles/bifrost-create-dib-image/README.md\n\tplaybooks/roles/bifrost-ironic-install/defaults/main.yml\n\tplaybooks/roles/bifrost-prep-for-install/README.md\n\tplaybooks/roles/bifrost-prep-for-install/defaults/main.yml\n\tplaybooks/test-bifrost.yaml\n\treleasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml\n\ttox.ini\n\nChange-Id: I55a1d9db940cf5fa2c35421db7add015ae334563\nNeeded-By: https://review.opendev.org/654056\n(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)\n'}, {'number': 2, 'created': '2019-10-14 20:22:08.000000000', 'files': ['playbooks/roles/bifrost-prep-for-install/README.md', 'doc/source/install/index.rst', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'README.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'doc/source/user/howto.rst', 'playbooks/roles/ironic-enroll-dynamic/README.md', 'doc/source/user/vagrant.rst', 'doc/source/user/troubleshooting.rst', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'CONTRIBUTING.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic.conf.j2', 'releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml', 'tox.ini', 'playbooks/roles/bifrost-create-dib-image/README.md', 'playbooks/roles/bifrost-keystone-install/defaults/main.yml', 'playbooks/roles/bifrost-openstack-ci-prep/README.md'], 'web_link': 'https://opendev.org/openstack/bifrost/commit/e81491c6f3617fc5a1488206f43ce489754464a3', 'message': 'Update links for opendev\n\nThe most important bits are updating shade references to remove\nthe openstack-infra. The other git urls will work through the\nredirect, but cleaning them up is just nicer.\n\nThis removes two comments that reference files that no longer\nexist due to config generation.\n\nAlso, fix some random use of github for cloning openstack repos,\nsince the github mirror is best-effort only.\n\nConflicts:\n\tREADME.rst\n\tdoc/source/user/troubleshooting.rst\n\tplaybooks/roles/bifrost-create-dib-image/README.md\n\tplaybooks/roles/bifrost-ironic-install/defaults/main.yml\n\tplaybooks/roles/bifrost-prep-for-install/README.md\n\tplaybooks/roles/bifrost-prep-for-install/defaults/main.yml\n\tplaybooks/test-bifrost.yaml\n\treleasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml\n\ttox.ini\n\nChange-Id: I55a1d9db940cf5fa2c35421db7add015ae334563\nNeeded-By: https://review.opendev.org/654056\n(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)\n'}]",0,688554,e81491c6f3617fc5a1488206f43ce489754464a3,8,3,2,11655,,,0,"Update links for opendev

The most important bits are updating shade references to remove
the openstack-infra. The other git urls will work through the
redirect, but cleaning them up is just nicer.

This removes two comments that reference files that no longer
exist due to config generation.

Also, fix some random use of github for cloning openstack repos,
since the github mirror is best-effort only.

Conflicts:
	README.rst
	doc/source/user/troubleshooting.rst
	playbooks/roles/bifrost-create-dib-image/README.md
	playbooks/roles/bifrost-ironic-install/defaults/main.yml
	playbooks/roles/bifrost-prep-for-install/README.md
	playbooks/roles/bifrost-prep-for-install/defaults/main.yml
	playbooks/test-bifrost.yaml
	releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml
	tox.ini

Change-Id: I55a1d9db940cf5fa2c35421db7add015ae334563
Needed-By: https://review.opendev.org/654056
(cherry picked from commit ec852a3fad9e879f69e790abe3d0a99bbd8472a5)
",git fetch https://review.opendev.org/openstack/bifrost refs/changes/54/688554/1 && git format-patch -1 --stdout FETCH_HEAD,"['playbooks/roles/bifrost-prep-for-install/README.md', 'doc/source/install/index.rst', 'playbooks/roles/bifrost-ironic-install/defaults/main.yml', 'playbooks/test-bifrost.yaml', 'README.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic-inspector.conf.j2', 'doc/source/user/howto.rst', 'playbooks/roles/ironic-enroll-dynamic/README.md', 'doc/source/user/vagrant.rst', 'doc/source/user/troubleshooting.rst', 'playbooks/roles/bifrost-prep-for-install/defaults/main.yml', 'CONTRIBUTING.rst', 'playbooks/roles/bifrost-ironic-install/templates/ironic.conf.j2', 'releasenotes/notes/support-staging-drivers-1c398a56dde9b240.yaml', 'tox.ini', 'playbooks/roles/bifrost-create-dib-image/README.md', 'playbooks/roles/bifrost-keystone-install/defaults/main.yml', 'playbooks/roles/bifrost-openstack-ci-prep/README.md']",18,cf2c4a8c8029e8d9be4530012cca4287239b926a,, shade_git_url: /opt/git/openstack/shade, shade_git_url: /opt/git/openstack-infra/shade,41,49
openstack%2Fglance~master~I215fd6d7e6f31bfc956fd88c13a73883dcf040c9,openstack/glance,master,I215fd6d7e6f31bfc956fd88c13a73883dcf040c9,[WIP] Refactoring of tests,ABANDONED,2016-07-05 08:12:43.000000000,2019-10-15 08:38:56.000000000,,"[{'_account_id': 11391}, {'_account_id': 14676}, {'_account_id': 19016}]","[{'number': 1, 'created': '2016-07-05 08:12:43.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/22ae80a848f91bac56452423a2fe8955e5678617', 'message': 'Refactoring of tests\n\nadded base\n\nChange-Id: I215fd6d7e6f31bfc956fd88c13a73883dcf040c9\n'}, {'number': 2, 'created': '2016-07-07 09:03:51.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/af2a930199cf00510970877fe8c119a09610cf25', 'message': 'Refactoring of tests\n\nadded base\n\nChange-Id: I215fd6d7e6f31bfc956fd88c13a73883dcf040c9\n'}, {'number': 3, 'created': '2016-07-07 12:05:51.000000000', 'files': ['glance/tests/functional/glare/base.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f38c5de500449dfa2c8ca40a093e82c215303e09', 'message': '[WIP] Refactoring of tests\n\nAdded base\n\nChange-Id: I215fd6d7e6f31bfc956fd88c13a73883dcf040c9\n'}]",6,337530,f38c5de500449dfa2c8ca40a093e82c215303e09,11,3,3,19016,,,0,"[WIP] Refactoring of tests

Added base

Change-Id: I215fd6d7e6f31bfc956fd88c13a73883dcf040c9
",git fetch https://review.opendev.org/openstack/glance refs/changes/30/337530/1 && git format-patch -1 --stdout FETCH_HEAD,['glance/tests/functional/glare/base.py'],1,22ae80a848f91bac56452423a2fe8955e5678617,(detached,"# Copyright 2016 OpenStack Foundation # All Rights Reserved. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. import uuid from oslo_serialization import jsonutils import requests from glance.tests import functional glare_urls = { 'create_list': '/sample_artifact', 'update_get_delete': 'sample_artifact/{artifact_id}', 'upload_download': '/sample_artifact/{artifact_id}/{prop}', 'test': '/sample_artifact/{path}', 'aaa': '/v{version}/artifacts/{type_name}/v{type_version}/{artifact_id}' '/{blob_property}', } class Base(functional.FunctionalTest): users = { 'user1': { 'id': str(uuid.uuid4()), 'tenant_id': str(uuid.uuid4()), 'token': str(uuid.uuid4()), 'role': 'member' }, 'user2': { 'id': str(uuid.uuid4()), 'tenant_id': str(uuid.uuid4()), 'token': str(uuid.uuid4()), 'role': 'member' }, 'admin': { 'id': str(uuid.uuid4()), 'tenant_id': str(uuid.uuid4()), 'token': str(uuid.uuid4()), 'role': 'admin' } } def setUp(self): super(Base, self).setUp() self._set_user('user1') self.glare_server.deployment_flavor = 'noauth' self.glare_server.artifact_type_name = 'sample_artifact' self.glare_server.custom_artifact_type_path = ( 'glance.tests.functional.glare.sample_artifact') self.start_servers(**self.__dict__.copy()) def tearDown(self): self.stop_servers() self._reset_database(self.api_server.sql_connection) super(Base, self).tearDown() def _url(self, path): if 'schemas' in path: return 'http://127.0.0.1:%d/%s' % (self.glare_port, path) else: return 'http://127.0.0.1:%d/artifacts/%s' % (self.glare_port, path) def _set_user(self, username): if username not in self.users: raise KeyError self.current_user = username def _headers(self, custom_headers=None): base_headers = { 'X-Identity-Status': 'Confirmed', 'X-Auth-Token': self.users[self.current_user]['token'], 'X-User-Id': self.users[self.current_user]['id'], 'X-Tenant-Id': self.users[self.current_user]['tenant_id'], 'X-Project-Id': self.users[self.current_user]['tenant_id'], 'X-Roles': self.users[self.current_user]['role'], } base_headers.update(custom_headers or {}) return base_headers def _check_artifact_method(self, method, url, data=None, status=200, headers=None): if not headers: headers = self._headers() else: headers = self._headers(headers) headers.setdefault(""Content-Type"", ""application/json"") if 'application/json' in headers['Content-Type'] and data is not None: data = jsonutils.dumps(data) response = getattr(requests, method)(self._url(url), headers=headers, data=data) self.assertEqual(status, response.status_code) if status >= 400: return response.text if ""application/json"" in response.headers[""content-type""]: return jsonutils.loads(response.text) return response.text def _get(self, url, status=200): return self._check_artifact_method(""get"", url, status=status) def create_artifact(self, name, version, status=201, **kwargs): kwargs.update({'name': name, 'version': version}) url = glare_urls['create_list'] return self._check_artifact_method('post', url, kwargs or {}, status=status) def get(self, art_id, status=200): url = glare_urls['update_get_delete'].format(artifact_id=art_id) return self._check_artifact_method('get', url=url, status=status) def list(self): url = glare_urls['create_list'] return self._check_artifact_method('get', url=url) def update(self, art_id, remove_props=None, status=200, **kwargs): headers = {'Content-Type': 'application/json-patch+json'} url = glare_urls['update_get_delete'].format(artifact_id=art_id) art_obj = self.get(art_id) patch = [] if remove_props: for prop in remove_props: if prop not in kwargs: patch.append({'op': 'remove', 'path': '/{}'.format(prop)}) for prop, value in kwargs.iteritems(): patch.append({'op': '{}'.format('replace' if prop in art_obj else 'add'), 'value': '{}'.format(value), 'path': '/{}'.format(prop)}) return self._check_artifact_method(""patch"", url, patch, headers=headers, status=status) def activate(self, art_id, status=200): headers = {'Content-Type': 'application/json-patch+json'} url = glare_urls['update_get_delete'].format(artifact_id=art_id) patch = [{'op': 'replace', 'path': '/status', 'value': 'active'}] return self._check_artifact_method(""patch"", url, patch, headers=headers, status=status) def deactivate(self, art_id, status=200): headers = {'Content-Type': 'application/json-patch+json'} url = glare_urls['update_get_delete'].format(artifact_id=art_id) patch = [{'op': 'replace', 'path': '/status', 'value': 'deactivated'}] return self._check_artifact_method(""patch"", url, patch, headers=headers, status=status) def upload_blob(self, art_id, blob_prop, blob_data, status=200): headers = {'Content-Type': 'application/octet-stream'} url = glare_urls['upload_download'].format(artifact_id=art_id, prop=blob_prop) return self._check_artifact_method(""put"", url, blob_data, status=status, headers=headers) def download_blob(self, art_id, blob_prop, status=200): headers = {'Content-Type': 'application/octet-stream'} url = glare_urls['upload_download'].format(artifact_id=art_id, prop=blob_prop) return self._check_artifact_method(""get"", url, status=status, headers=headers) def delete_artifact(self, art_id, status=200): url = glare_urls['update_get_delete'].format(artifact_id=art_id) self._check_artifact_method('delete', url=url, status=status) ",,192,0
openstack%2Fglance~master~I49f8b53d3a0a187fef7cda450f8e00099164b704,openstack/glance,master,I49f8b53d3a0a187fef7cda450f8e00099164b704,Add distinction layer,NEW,2016-01-25 14:46:32.000000000,2019-10-15 08:37:49.000000000,,"[{'_account_id': 2537}, {'_account_id': 5314}, {'_account_id': 6484}, {'_account_id': 7575}, {'_account_id': 8871}, {'_account_id': 9303}, {'_account_id': 11391}, {'_account_id': 14676}, {'_account_id': 16658}, {'_account_id': 16683}, {'_account_id': 17043}]","[{'number': 1, 'created': '2016-01-25 14:46:32.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ed6e4756635d632f0c272ac2661bbd66af896448', 'message': 'Add transaction layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 2, 'created': '2016-02-02 12:42:56.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/94cf86794e5aa4e1c882153dc4d1cdbde59fca00', 'message': 'Add transaction layer\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 3, 'created': '2016-02-08 08:50:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/80d78f75ce10616001a314b6126545220d5bb52f', 'message': 'Add transaction layer\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 4, 'created': '2016-02-09 09:24:08.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2c15de1d9f0624d9898f835c813884ab8a653880', 'message': 'Add transaction layer\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 5, 'created': '2016-02-09 10:49:39.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ba2018ec6c02555135eed8e5a899e4e10da48a3d', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 6, 'created': '2016-02-12 17:17:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/cb56519f496b148fb5e17bbac0c576d531605e32', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 7, 'created': '2016-02-14 20:59:20.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e6068eec7185665c15cfbb9aa37d3305c5c47002', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 8, 'created': '2016-02-15 18:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/4e5ae29dac23dacb7b2eec91408cd50cef4f8a98', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 9, 'created': '2016-02-16 20:03:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/da989ac89d6b790eef396295256b4e2b56927457', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 10, 'created': '2016-02-26 11:57:45.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/7f3d4748961ae78d751e1f0e8a9f3e5926980ef5', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 11, 'created': '2016-02-26 15:33:02.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/8af5d561d9d7e87a15531e666991f22941cb3e96', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 12, 'created': '2016-03-11 14:40:14.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/915bbd8996887f824e6428a38076276b700f3a17', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 13, 'created': '2016-03-11 14:55:25.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a09b17ec5607a321f5e1183d3e6c3092cc37bcad', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 14, 'created': '2016-03-11 17:41:35.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/716c08d22d9eccf8df6f5d8e7c4c1e1aa9709f36', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 15, 'created': '2016-03-16 14:12:42.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/fd25cf6b31ca54c2353a9244e71e4a5eadf6125f', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 16, 'created': '2016-03-24 17:20:58.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/59f4261ad58ba79e48a0e0c9f3f5d060b9f97edb', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 17, 'created': '2016-04-19 12:29:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e863a07d006a2d90cbc1abd6178da3caba63b8b0', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 18, 'created': '2016-04-22 12:43:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/1bab20d8ba11d38a2db939447c6e4dcdd3805795', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 19, 'created': '2016-04-22 17:35:59.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ca4b4fed6e9a5d0cf25a57b0121cdb0f331279e8', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 20, 'created': '2016-04-28 17:15:55.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/24a724d50ee73325f5bd9344376f193fc60f930f', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 21, 'created': '2016-04-29 11:40:15.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/aa331c1872f5c6348a6697842de125d3ce3e575b', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 22, 'created': '2016-05-04 17:32:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/2bbcb080d72f40356c4970faecb55e587fa4c8dd', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 23, 'created': '2016-05-06 06:46:18.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/5551f4767c0ce2efdfece89c00cc2a48ea04a19a', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 24, 'created': '2016-05-06 18:13:24.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ab28bb731e76457065a4648763c490871072fcbb', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 and Artifact architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 25, 'created': '2016-05-12 13:31:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/a9d5e8cb0db683156bdd2271baaafb721186b2f0', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-transaction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 26, 'created': '2016-05-26 12:52:12.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/636722750d1d3350bff913da945607df1203f7c2', 'message': 'Add transaction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding transaction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-transaction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 27, 'created': '2016-06-06 09:18:10.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/d02e62dd9c39a71465072cf7c4cac56114033c4d', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 28, 'created': '2016-06-06 12:07:37.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/ad991358f844a44fa9a5339a6e2966f97f3ac4ab', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 29, 'created': '2016-06-17 11:50:21.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/271b186af54027e12ac7fb55806b4367a6d08c6f', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 30, 'created': '2016-06-29 15:13:36.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/9efdf95a574d024b0af7be96fe421959d3f6daa8', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 31, 'created': '2016-07-15 12:09:06.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/e1d508a5bd93e1509572ed392a0f17ef6bad8807', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 32, 'created': '2016-07-15 12:33:00.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/3818f57961afa781e43cd710881283ecd3a8ae38', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 33, 'created': '2016-07-26 19:42:28.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/61acfe8a2c39d5df7ca18a7cdc0081ae093965d4', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 34, 'created': '2016-07-27 14:18:41.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/980545de8d6155f5033f98fd9deb6936ee7c1e7f', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 35, 'created': '2016-08-01 08:59:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/glance/commit/c0c983d6210b3abeee96a1bb02036430f564c741', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}, {'number': 36, 'created': '2016-08-12 14:23:57.000000000', 'files': ['glance/tests/unit/test_db.py', 'glance/tests/unit/test_distinction.py', 'glance/db/simple/api.py', 'glance/db/__init__.py', 'glance/gateway.py', 'glance/db/sqlalchemy/api.py', 'glance/distinction.py'], 'web_link': 'https://opendev.org/openstack/glance/commit/f3137401c06041473d1e6e95b159589c7fb4b214', 'message': 'Add distinction layer\n\nCurrent Glance Images v2 architectures have a defect\nassociated with risks of race conditions arising under heavy load\non the system. Besides this, there is an issue of unreasonably\nincreased load on the database when updating, and also an issue\nwith changing the status of the image. These issues do not appear\nat low load, but in the future, with wider use, it can lead to\nserious problems, such as loss of information and unstable\nbehaviour.\nTo improve the stability and performance it is suggested to make\nchanges in the domain by adding distinction layer, which will\nstore all changes of the object and pass to DB only modified\nattributes.\n\nCloses-bug: #1371728\nCloses-bug: #1372564\n\nImplements bp: add-distinction-layer\n\nChange-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704\n'}]",55,272118,f3137401c06041473d1e6e95b159589c7fb4b214,106,11,36,16658,,,0,"Add distinction layer

Current Glance Images v2 architectures have a defect
associated with risks of race conditions arising under heavy load
on the system. Besides this, there is an issue of unreasonably
increased load on the database when updating, and also an issue
with changing the status of the image. These issues do not appear
at low load, but in the future, with wider use, it can lead to
serious problems, such as loss of information and unstable
behaviour.
To improve the stability and performance it is suggested to make
changes in the domain by adding distinction layer, which will
store all changes of the object and pass to DB only modified
attributes.

Closes-bug: #1371728
Closes-bug: #1372564

Implements bp: add-distinction-layer

Change-Id: I49f8b53d3a0a187fef7cda450f8e00099164b704
",git fetch https://review.opendev.org/openstack/glance refs/changes/18/272118/33 && git format-patch -1 --stdout FETCH_HEAD,"['glance/transaction.py', 'glance/db/__init__.py', 'glance/gateway.py']",3,ed6e4756635d632f0c272ac2661bbd66af896448,bug/1371728,"import glance.transaction transaction_image_factory = glance.transaction.ImageFactoryProxy( image_factory, context) transaction_image_factory, context, self.store_api, self.store_utils) transaction_image_repo = glance.transaction.ImageRepoProxy( image_repo, context) transaction_image_repo, context, self.store_api, self.store_utils)"," image_factory, context, self.store_api, self.store_utils) image_repo, context, self.store_api, self.store_utils)",89,23
openstack%2Ftripleo-common~stable%2Fstein~I60507eba9884a0660fe269da5ad27b0e57a70ca8,openstack/tripleo-common,stable/stein,I60507eba9884a0660fe269da5ad27b0e57a70ca8,Make executor type dynamic,MERGED,2019-10-11 20:42:46.000000000,2019-10-15 08:33:57.000000000,2019-10-15 08:32:08.000000000,"[{'_account_id': 3153}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 28223}]","[{'number': 1, 'created': '2019-10-11 20:42:46.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/96a06a1dfc24a4ea8e9489daf933c2e120aa14c4', 'message': ""Make executor type dynamic\n\nWhen we run the tripleo-container-image-prepare script, it performs\nbetter under python2 when the process leverages a ProcessPoolExecutor.\nRather than using threading, we should be using processes to handle the\nimage upload processing. Currently when we're processing the images, we\nend up being single threaded due to the GIL when processing the data. By\nswitching to the ProcessPoolExecutor, we eliminate the locking that is\noccuring during the data processing as it'll be handled in each process.\n\nUnfortunately, we cannot leverage the ProcessPoolExecutor when the same\ncode is run under Mistral. In order to make the code work for both\nmethods, we need to make the execution type dynamic. This change creates\ntwo types of lock objects that are used to determine what type of\nexecutor to ultimately use when processing the images for uploading.\n\nAdditionally this change limits the number of concurrent image upload\nprocesses to 4 if using the ProcessPoolExecutor and caps the number of\nthreads at a max of 8 based on (cpu count / 2)\n\n Conflicts:\n\ttripleo_common/image/image_uploader.py\n\nChange-Id: I60507eba9884a0660fe269da5ad27b0e57a70ca8\nRelated-Bug: #1844446\n(cherry picked from commit 60afc0eec44f698dd95d9d6ec80dad94a4b07329)\n""}, {'number': 2, 'created': '2019-10-14 00:34:30.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/c1a7a7fc226758d2b5a7e4c8cb4a02930081e6f1', 'message': ""Make executor type dynamic\n\nWhen we run the tripleo-container-image-prepare script, it performs\nbetter under python2 when the process leverages a ProcessPoolExecutor.\nRather than using threading, we should be using processes to handle the\nimage upload processing. Currently when we're processing the images, we\nend up being single threaded due to the GIL when processing the data. By\nswitching to the ProcessPoolExecutor, we eliminate the locking that is\noccuring during the data processing as it'll be handled in each process.\n\nUnfortunately, we cannot leverage the ProcessPoolExecutor when the same\ncode is run under Mistral. In order to make the code work for both\nmethods, we need to make the execution type dynamic. This change creates\ntwo types of lock objects that are used to determine what type of\nexecutor to ultimately use when processing the images for uploading.\n\nAdditionally this change limits the number of concurrent image upload\nprocesses to 4 if using the ProcessPoolExecutor and caps the number of\nthreads at a max of 8 based on (cpu count / 2)\n\n Conflicts:\n\ttripleo_common/image/image_uploader.py\n\nChange-Id: I60507eba9884a0660fe269da5ad27b0e57a70ca8\nRelated-Bug: #1844446\n(cherry picked from commit 60afc0eec44f698dd95d9d6ec80dad94a4b07329)\n""}, {'number': 3, 'created': '2019-10-15 02:28:39.000000000', 'files': ['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/kolla_builder.py', 'scripts/tripleo-container-image-prepare', 'tripleo_common/utils/locks/processlock.py', 'tripleo_common/utils/locks/__init__.py', 'tripleo_common/utils/locks/threadinglock.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/tests/image/test_kolla_builder.py', 'tripleo_common/utils/locks/base.py'], 'web_link': 'https://opendev.org/openstack/tripleo-common/commit/7994173916ec2b4fd5885944120ce3896b2bd413', 'message': ""Make executor type dynamic\n\nWhen we run the tripleo-container-image-prepare script, it performs\nbetter under python2 when the process leverages a ProcessPoolExecutor.\nRather than using threading, we should be using processes to handle the\nimage upload processing. Currently when we're processing the images, we\nend up being single threaded due to the GIL when processing the data. By\nswitching to the ProcessPoolExecutor, we eliminate the locking that is\noccuring during the data processing as it'll be handled in each process.\n\nUnfortunately, we cannot leverage the ProcessPoolExecutor when the same\ncode is run under Mistral. In order to make the code work for both\nmethods, we need to make the execution type dynamic. This change creates\ntwo types of lock objects that are used to determine what type of\nexecutor to ultimately use when processing the images for uploading.\n\nAdditionally this change limits the number of concurrent image upload\nprocesses to 4 if using the ProcessPoolExecutor and caps the number of\nthreads at a max of 8 based on (cpu count / 2)\n\n Conflicts:\n\ttripleo_common/image/image_uploader.py\n\nChange-Id: I60507eba9884a0660fe269da5ad27b0e57a70ca8\nRelated-Bug: #1844446\n(cherry picked from commit 60afc0eec44f698dd95d9d6ec80dad94a4b07329)\n""}]",0,688201,7994173916ec2b4fd5885944120ce3896b2bd413,26,4,3,14985,,,0,"Make executor type dynamic

When we run the tripleo-container-image-prepare script, it performs
better under python2 when the process leverages a ProcessPoolExecutor.
Rather than using threading, we should be using processes to handle the
image upload processing. Currently when we're processing the images, we
end up being single threaded due to the GIL when processing the data. By
switching to the ProcessPoolExecutor, we eliminate the locking that is
occuring during the data processing as it'll be handled in each process.

Unfortunately, we cannot leverage the ProcessPoolExecutor when the same
code is run under Mistral. In order to make the code work for both
methods, we need to make the execution type dynamic. This change creates
two types of lock objects that are used to determine what type of
executor to ultimately use when processing the images for uploading.

Additionally this change limits the number of concurrent image upload
processes to 4 if using the ProcessPoolExecutor and caps the number of
threads at a max of 8 based on (cpu count / 2)

 Conflicts:
	tripleo_common/image/image_uploader.py

Change-Id: I60507eba9884a0660fe269da5ad27b0e57a70ca8
Related-Bug: #1844446
(cherry picked from commit 60afc0eec44f698dd95d9d6ec80dad94a4b07329)
",git fetch https://review.opendev.org/openstack/tripleo-common refs/changes/01/688201/2 && git format-patch -1 --stdout FETCH_HEAD,"['tripleo_common/tests/image/test_image_uploader.py', 'tripleo_common/image/kolla_builder.py', 'scripts/tripleo-container-image-prepare', 'tripleo_common/utils/locks/processlock.py', 'tripleo_common/utils/locks/__init__.py', 'tripleo_common/image/image_uploader.py', 'tripleo_common/utils/locks/threadinglock.py', 'tripleo_common/tests/image/test_kolla_builder.py', 'tripleo_common/utils/locks/base.py']",9,96a06a1dfc24a4ea8e9489daf933c2e120aa14c4,bug/1844446-stable/stein,"# Copyright 2019 Red Hat, Inc. # # Licensed under the Apache License, Version 2.0 (the ""License""); you may # not use this file except in compliance with the License. You may obtain # a copy of the License at # # http://www.apache.org/licenses/LICENSE-2.0 # # Unless required by applicable law or agreed to in writing, software # distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT # WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the # License for the specific language governing permissions and limitations # under the License. class BaseLock(object): def get_lock(self): return self._lock def objects(self): return self._objects ",,183,55
openstack%2Fkolla-ansible~master~I5ded328485855f3f3d4390282040b0d89d08d997,openstack/kolla-ansible,master,I5ded328485855f3f3d4390282040b0d89d08d997,HAProxy backend connection limits,MERGED,2019-08-13 16:10:34.000000000,2019-10-15 08:15:56.000000000,2019-08-27 12:58:07.000000000,"[{'_account_id': 14826}, {'_account_id': 16006}, {'_account_id': 22348}, {'_account_id': 22629}, {'_account_id': 27781}, {'_account_id': 30491}]","[{'number': 1, 'created': '2019-08-13 16:10:34.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/4988e768d67ffde31f70c814898f99982e351fb0', 'message': ""HAProxy backend connection limits\n\nThe default connection limits for backends is 2000\nhowever, mariadb defaults to a max of 10000 conections,\ntherefore changing this limit to match the mariadb limit.\n\n'haproxy_max_connections' also needs to be bumped\nfor this to work.\n\nChange-Id: I5ded328485855f3f3d4390282040b0d89d08d997\n""}, {'number': 2, 'created': '2019-08-14 10:44:47.000000000', 'files': ['releasenotes/notes/increase-haproxy-max-connections-df6aff5c82fdef24.yaml', 'ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml'], 'web_link': 'https://opendev.org/openstack/kolla-ansible/commit/46f9ad3a96d9a30a6741781cb0b47550cdb23e4f', 'message': ""HAProxy backend connection limits\n\nThe default connection limits for backends is 2000\nhowever, mariadb defaults to a max of 10000 conections,\ntherefore changing this limit to match the mariadb limit.\n\n'haproxy_max_connections' also needs to be bumped\nfor this to work.\n\nChange-Id: I5ded328485855f3f3d4390282040b0d89d08d997\n""}]",1,676232,46f9ad3a96d9a30a6741781cb0b47550cdb23e4f,15,6,2,29543,,,0,"HAProxy backend connection limits

The default connection limits for backends is 2000
however, mariadb defaults to a max of 10000 conections,
therefore changing this limit to match the mariadb limit.

'haproxy_max_connections' also needs to be bumped
for this to work.

Change-Id: I5ded328485855f3f3d4390282040b0d89d08d997
",git fetch https://review.opendev.org/openstack/kolla-ansible refs/changes/32/676232/1 && git format-patch -1 --stdout FETCH_HEAD,"['ansible/roles/haproxy/templates/haproxy_main.cfg.j2', 'ansible/roles/haproxy/defaults/main.yml']",2,4988e768d67ffde31f70c814898f99982e351fb0,bump-haproxy-max-connections,haproxy_max_connections: 40000# Matches the mariabd 10000 max connections limit haproxy_defaults_max_connections: 10000,haproxy_max_connections: 4000,4,1
openstack%2Fcyborg~master~I0c72307bc8593b0575ab2fdbc67df04519851cfc,openstack/cyborg,master,I0c72307bc8593b0575ab2fdbc67df04519851cfc,try to avoid to access ExtARQ DB twice,NEW,2019-10-12 04:09:16.000000000,2019-10-15 08:11:15.000000000,,"[{'_account_id': 14131}, {'_account_id': 22348}, {'_account_id': 25738}]","[{'number': 1, 'created': '2019-10-12 04:09:16.000000000', 'files': [], 'web_link': 'https://opendev.org/openstack/cyborg/commit/42e733453831daedb2950213c3c8fd8522ee55cf', 'message': 'try to avoid to access ExtARQ DB twice\n\ncast ExtARQ to FPGAExtARQ to avoid one more db access\n\nChange-Id: I0c72307bc8593b0575ab2fdbc67df04519851cfc\n'}, {'number': 2, 'created': '2019-10-14 14:01:33.000000000', 'files': ['cyborg/common/constants.py', 'cyborg/objects/extarq/ext_arq_job.py', 'cyborg/tests/unit/fake_extarq.py', 'cyborg/tests/unit/objects/test_extarq.py'], 'web_link': 'https://opendev.org/openstack/cyborg/commit/4707e9f59ede0f2d9e2531a597259f3fb3a6970f', 'message': 'try to avoid to access ExtARQ DB twice\n\ncast ExtARQ to FPGAExtARQ to avoid one more db access\n\nChange-Id: I0c72307bc8593b0575ab2fdbc67df04519851cfc\n'}]",0,688229,4707e9f59ede0f2d9e2531a597259f3fb3a6970f,9,3,2,14131,,,0,"try to avoid to access ExtARQ DB twice

cast ExtARQ to FPGAExtARQ to avoid one more db access

Change-Id: I0c72307bc8593b0575ab2fdbc67df04519851cfc
",git fetch https://review.opendev.org/openstack/cyborg refs/changes/29/688229/2 && git format-patch -1 --stdout FETCH_HEAD,"['cyborg/objects/extarq/ext_arq_job.py', 'cyborg/tests/unit/objects/test_extarq.py']",2,42e733453831daedb2950213c3c8fd8522ee55cf,bug-fix," mock_get.side_effect = [obj_fpga_extarq, obj_fpga_extarq] mock_get.side_effect = [obj_fpga_extarq, obj_fpga_extarq]"," mock_get.side_effect = [obj_extarq, obj_fpga_extarq] mock_get.side_effect = [obj_extarq, obj_fpga_extarq]",4,3
openstack%2Fpuppet-tripleo~master~I4e53a4a3464940660473bcbe74e30507a69a4019,openstack/puppet-tripleo,master,I4e53a4a3464940660473bcbe74e30507a69a4019,pacemaker: add support for Hash vs List in container environment,MERGED,2019-10-11 21:59:49.000000000,2019-10-15 08:09:46.000000000,2019-10-15 08:09:46.000000000,"[{'_account_id': 3153}, {'_account_id': 14985}, {'_account_id': 22348}, {'_account_id': 23181}, {'_account_id': 26297}, {'_account_id': 28543}, {'_account_id': 28935}]","[{'number': 1, 'created': '2019-10-11 21:59:49.000000000', 'files': ['manifests/profile/pacemaker/cinder/volume_bundle.pp', 'manifests/profile/pacemaker/manila/share_bundle.pp', 'manifests/profile/pacemaker/cinder/backup_bundle.pp'], 'web_link': 'https://opendev.org/openstack/puppet-tripleo/commit/f8d9dfb497cc9683c7b8f2a0fce302d296328317', 'message': 'pacemaker: add support for Hash vs List in container environment\n\nWe are transitioning from an array to an hash for the container\nenvironment of each container:\nI894f339cdf03bc2a93c588f826f738b0b851a3ad\n\nMainly to make it consummable by Ansible later; where the\npodman_container module needs a dict instead of a list.\n\nThis patch just changes the default, and also adds support for an Hash\ninstead of a List, but still supporting the List.\n\nChange-Id: I4e53a4a3464940660473bcbe74e30507a69a4019\n'}]",0,688216,f8d9dfb497cc9683c7b8f2a0fce302d296328317,22,7,1,3153,,,0,"pacemaker: add support for Hash vs List in container environment

We are transitioning from an array to an hash for the container
environment of each container:
I894f339cdf03bc2a93c588f826f738b0b851a3ad

Mainly to make it consummable by Ansible later; where the
podman_container module needs a dict instead of a list.

This patch just changes the default, and also adds support for an Hash
instead of a List, but still supporting the List.

Change-Id: I4e53a4a3464940660473bcbe74e30507a69a4019
",git fetch https://review.opendev.org/openstack/puppet-tripleo refs/changes/16/688216/1 && git format-patch -1 --stdout FETCH_HEAD,"['manifests/profile/pacemaker/cinder/volume_bundle.pp', 'manifests/profile/pacemaker/manila/share_bundle.pp', 'manifests/profile/pacemaker/cinder/backup_bundle.pp']",3,f8d9dfb497cc9683c7b8f2a0fce302d296328317,dict,"# (Optional) List or Hash of environment variables set in the docker container # Defaults to {'KOLLA_CONFIG_STRATEGY' => 'COPY_ALWAYS'} $docker_environment = {'KOLLA_CONFIG_STRATEGY' => 'COPY_ALWAYS'}, if is_hash($docker_environment) { $docker_env = join($docker_environment.map |$index, $value| { ""-e ${index}=${value}"" }, ' ') } else { $docker_env_arr = delete(any2array($docker_environment), '').flatten() $docker_env = join($docker_env_arr.map |$var| { ""-e ${var}"" }, ' ') } ","# (Optional) The list of environment variables set in the docker container # Defaults to ['KOLLA_CONFIG_STRATEGY=COPY_ALWAYS'] $docker_environment = ['KOLLA_CONFIG_STRATEGY=COPY_ALWAYS'], $docker_env_arr = delete(any2array($docker_environment), '').flatten() $docker_env = join($docker_env_arr.map |$var| { ""-e ${var}"" }, ' ')",29,15
